{"buggy_code": ["// Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// =============================================================================\n#include <algorithm>\n#include <iterator>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/device_base.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_stream.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_summary.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/refcount.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\nconst char* const kExampleWeightsName = \"example_weights\";\nconst char* const kMaxElementsName = \"max_elements\";\nconst char* const kGenerateQuantiles = \"generate_quantiles\";\nconst char* const kNumBucketsName = \"num_buckets\";\nconst char* const kEpsilonName = \"epsilon\";\nconst char* const kBucketBoundariesName = \"bucket_boundaries\";\nconst char* const kBucketsName = \"buckets\";\nconst char* const kSummariesName = \"summaries\";\nconst char* const kNumStreamsName = \"num_streams\";\nconst char* const kNumFeaturesName = \"num_features\";\nconst char* const kFloatFeaturesName = \"float_values\";\nconst char* const kResourceHandleName = \"quantile_stream_resource_handle\";\n\nusing QuantileStreamResource = BoostedTreesQuantileStreamResource;\nusing QuantileStream =\n    boosted_trees::quantiles::WeightedQuantilesStream<float, float>;\nusing QuantileSummary =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float, float>;\nusing QuantileSummaryEntry =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float,\n                                                       float>::SummaryEntry;\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateBoundaries(const QuantileStream& stream,\n                                      const int64_t num_boundaries) {\n  std::vector<float> boundaries = stream.GenerateBoundaries(num_boundaries);\n\n  // Uniquify elements as we may get dupes.\n  auto end_it = std::unique(boundaries.begin(), boundaries.end());\n  boundaries.resize(std::distance(boundaries.begin(), end_it));\n  return boundaries;\n}\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateQuantiles(const QuantileStream& stream,\n                                     const int64_t num_quantiles) {\n  // Do not de-dup boundaries. Exactly num_quantiles+1 boundary values\n  // will be returned.\n  std::vector<float> boundaries = stream.GenerateQuantiles(num_quantiles - 1);\n  CHECK_EQ(boundaries.size(), num_quantiles);\n  return boundaries;\n}\n\nstd::vector<float> GetBuckets(const int32_t feature,\n                              const OpInputList& buckets_list) {\n  const auto& buckets = buckets_list[feature].flat<float>();\n  std::vector<float> buckets_vector(buckets.data(),\n                                    buckets.data() + buckets.size());\n  return buckets_vector;\n}\n\nREGISTER_RESOURCE_HANDLE_KERNEL(BoostedTreesQuantileStreamResource);\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"IsBoostedTreesQuantileStreamResourceInitialized\").Device(DEVICE_CPU),\n    IsResourceInitialized<BoostedTreesQuantileStreamResource>);\n\nclass BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n public:\n  explicit BoostedTreesCreateQuantileStreamResourceOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kMaxElementsName, &max_elements_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }\n\n private:\n  // An upper bound on the number of entries that the summaries might have\n  // for a feature.\n  int64 max_elements_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesCreateQuantileStreamResource\").Device(DEVICE_CPU),\n    BoostedTreesCreateQuantileStreamResourceOp);\n\nclass BoostedTreesMakeQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesMakeQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n\n    // Parse example weights and get batch size.\n    const Tensor* example_weights_t;\n    OP_REQUIRES_OK(context,\n                   context->input(kExampleWeightsName, &example_weights_t));\n    DCHECK(float_features_list.size() > 0) << \"Got empty feature list\";\n    auto example_weights = example_weights_t->flat<float>();\n    const int64_t weight_size = example_weights.size();\n    const int64_t batch_size = float_features_list[0].flat<float>().size();\n    OP_REQUIRES(\n        context, weight_size == 1 || weight_size == batch_size,\n        errors::InvalidArgument(strings::Printf(\n            \"Weights should be a single value or same size as features.\")));\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        const auto feature_values = float_features_list[index].flat<float>();\n        QuantileStream stream(epsilon, batch_size + 1);\n        // Run quantile summary generation.\n        for (int64_t j = 0; j < batch_size; j++) {\n          stream.PushEntry(feature_values(j), (weight_size > 1)\n                                                  ? example_weights(j)\n                                                  : example_weights(0));\n        }\n        stream.Finalize();\n        const auto summary_entry_list = stream.GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        OP_REQUIRES_OK(\n            context,\n            summaries_output_list.allocate(\n                index,\n                TensorShape({static_cast<int64>(summary_entry_list.size()), 4}),\n                &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_entry_list.size(); row++) {\n          const auto& entry = summary_entry_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * batch_size;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesMakeQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesMakeQuantileSummariesOp);\n\nclass BoostedTreesFlushQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesFlushQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        QuantileStream* stream = stream_resource->stream(index);\n        stream->Finalize();\n\n        const auto summary_list = stream->GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        const int64_t summary_list_size =\n            static_cast<int64>(summary_list.size());\n        OP_REQUIRES_OK(context, summaries_output_list.allocate(\n                                    index, TensorShape({summary_list_size, 4}),\n                                    &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_list_size; row++) {\n          const auto& entry = summary_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n    stream_resource->ResetStreams();\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesFlushQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesFlushQuantileSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceAddSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceAddSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpInputList summaries_list;\n    OP_REQUIRES_OK(context,\n                   context->input_list(kSummariesName, &summaries_list));\n    int32_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(static_cast<int>(num_streams), summaries_list.size());\n\n    auto do_quantile_add_summary = [&](const int64_t begin, const int64_t end) {\n      // Iterating all features.\n      for (int64_t feature_idx = begin; feature_idx < end; ++feature_idx) {\n        QuantileStream* stream = stream_resource->stream(feature_idx);\n        if (stream->IsFinalized()) {\n          VLOG(1) << \"QuantileStream has already been finalized for feature\"\n                  << feature_idx << \".\";\n          continue;\n        }\n        const Tensor& summaries = summaries_list[feature_idx];\n        const auto summary_values = summaries.matrix<float>();\n        const auto& tensor_shape = summaries.shape();\n        const int64_t entries_size = tensor_shape.dim_size(0);\n        CHECK_EQ(tensor_shape.dim_size(1), 4);\n        std::vector<QuantileSummaryEntry> summary_entries;\n        summary_entries.reserve(entries_size);\n        for (int64_t i = 0; i < entries_size; i++) {\n          float value = summary_values(i, 0);\n          float weight = summary_values(i, 1);\n          float min_rank = summary_values(i, 2);\n          float max_rank = summary_values(i, 3);\n          QuantileSummaryEntry entry(value, weight, min_rank, max_rank);\n          summary_entries.push_back(entry);\n        }\n        stream_resource->stream(feature_idx)->PushSummary(summary_entries);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_add_summary);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceAddSummaries\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceAddSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceDeserializeOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceDeserializeOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumStreamsName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    core::RefCountPtr<QuantileStreamResource> streams_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, HandleFromInput(context, 0),\n                                           &streams_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*streams_resource->mutex());\n\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n\n    auto do_quantile_deserialize = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const Tensor& bucket_boundaries_t = bucket_boundaries_list[stream_idx];\n        const auto& bucket_boundaries = bucket_boundaries_t.vec<float>();\n        std::vector<float> result;\n        result.reserve(bucket_boundaries.size());\n        for (size_t i = 0; i < bucket_boundaries.size(); ++i) {\n          result.push_back(bucket_boundaries(i));\n        }\n        streams_resource->set_boundaries(result, stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_deserialize);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceDeserialize\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceDeserializeOp);\n\nclass BoostedTreesQuantileStreamResourceFlushOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceFlushOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context,\n                   context->GetAttr(kGenerateQuantiles, &generate_quantiles_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const Tensor* num_buckets_t;\n    OP_REQUIRES_OK(context, context->input(kNumBucketsName, &num_buckets_t));\n    const int64_t num_buckets = num_buckets_t->scalar<int64>()();\n    const int64_t num_streams = stream_resource->num_streams();\n\n    auto do_quantile_flush = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; ++stream_idx) {\n        QuantileStream* stream = stream_resource->stream(stream_idx);\n        stream->Finalize();\n        stream_resource->set_boundaries(\n            generate_quantiles_ ? GenerateQuantiles(*stream, num_buckets)\n                                : GenerateBoundaries(*stream, num_buckets),\n            stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_flush);\n\n    stream_resource->ResetStreams();\n    stream_resource->set_buckets_ready(true);\n  }\n\n private:\n  bool generate_quantiles_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceFlush\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceFlushOp);\n\nclass BoostedTreesQuantileStreamResourceGetBucketBoundariesOp\n    : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceGetBucketBoundariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const int64_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(num_features_, num_streams);\n    OpOutputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketBoundariesName,\n                                                 &bucket_boundaries_list));\n\n    auto do_quantile_get_buckets = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const auto& boundaries = stream_resource->boundaries(stream_idx);\n        Tensor* bucket_boundaries_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       bucket_boundaries_list.allocate(\n                           stream_idx, {static_cast<int64>(boundaries.size())},\n                           &bucket_boundaries_t));\n        auto* quantiles_flat = bucket_boundaries_t->flat<float>().data();\n        memcpy(quantiles_flat, boundaries.data(),\n               sizeof(float) * boundaries.size());\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_get_buckets);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceGetBucketBoundaries\")\n        .Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceGetBucketBoundariesOp);\n\n// Given the calculated quantiles thresholds and input data, this operation\n// converts the input features into the buckets (categorical values), depending\n// on which quantile they fall into.\nclass BoostedTreesBucketizeOp : public OpKernel {\n public:\n  explicit BoostedTreesBucketizeOp(OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n    OP_REQUIRES(context,\n                tensorflow::TensorShapeUtils::IsVector(\n                    bucket_boundaries_list[0].shape()),\n                errors::InvalidArgument(\n                    strings::Printf(\"Buckets should be flat vectors.\")));\n    OpOutputList buckets_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketsName, &buckets_list));\n\n    auto do_quantile_get_quantiles = [&](const int64_t begin,\n                                         const int64_t end) {\n      // Iterating over all resources\n      for (int64_t feature_idx = begin; feature_idx < end; feature_idx++) {\n        const Tensor& values_tensor = float_features_list[feature_idx];\n        const int64_t num_values = values_tensor.dim_size(0);\n\n        Tensor* output_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       buckets_list.allocate(\n                           feature_idx, TensorShape({num_values}), &output_t));\n        auto output = output_t->flat<int32>();\n\n        const std::vector<float>& bucket_boundaries_vector =\n            GetBuckets(feature_idx, bucket_boundaries_list);\n        auto flat_values = values_tensor.flat<float>();\n        const auto& iter_begin = bucket_boundaries_vector.begin();\n        const auto& iter_end = bucket_boundaries_vector.end();\n        for (int64_t instance = 0; instance < num_values; instance++) {\n          if (iter_begin == iter_end) {\n            output(instance) = 0;\n            continue;\n          }\n          const float value = flat_values(instance);\n          auto bucket_iter = std::lower_bound(iter_begin, iter_end, value);\n          if (bucket_iter == iter_end) {\n            --bucket_iter;\n          }\n          const int32_t bucket = static_cast<int32>(bucket_iter - iter_begin);\n          // Bucket id.\n          output(instance) = bucket;\n        }\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_get_quantiles);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"BoostedTreesBucketize\").Device(DEVICE_CPU),\n                        BoostedTreesBucketizeOp);\n\n}  // namespace tensorflow\n"], "fixing_code": ["// Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// =============================================================================\n#include <algorithm>\n#include <iterator>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/device_base.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_stream.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_summary.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/refcount.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\nconst char* const kExampleWeightsName = \"example_weights\";\nconst char* const kMaxElementsName = \"max_elements\";\nconst char* const kGenerateQuantiles = \"generate_quantiles\";\nconst char* const kNumBucketsName = \"num_buckets\";\nconst char* const kEpsilonName = \"epsilon\";\nconst char* const kBucketBoundariesName = \"bucket_boundaries\";\nconst char* const kBucketsName = \"buckets\";\nconst char* const kSummariesName = \"summaries\";\nconst char* const kNumStreamsName = \"num_streams\";\nconst char* const kNumFeaturesName = \"num_features\";\nconst char* const kFloatFeaturesName = \"float_values\";\nconst char* const kResourceHandleName = \"quantile_stream_resource_handle\";\n\nusing QuantileStreamResource = BoostedTreesQuantileStreamResource;\nusing QuantileStream =\n    boosted_trees::quantiles::WeightedQuantilesStream<float, float>;\nusing QuantileSummary =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float, float>;\nusing QuantileSummaryEntry =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float,\n                                                       float>::SummaryEntry;\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateBoundaries(const QuantileStream& stream,\n                                      const int64_t num_boundaries) {\n  std::vector<float> boundaries = stream.GenerateBoundaries(num_boundaries);\n\n  // Uniquify elements as we may get dupes.\n  auto end_it = std::unique(boundaries.begin(), boundaries.end());\n  boundaries.resize(std::distance(boundaries.begin(), end_it));\n  return boundaries;\n}\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateQuantiles(const QuantileStream& stream,\n                                     const int64_t num_quantiles) {\n  // Do not de-dup boundaries. Exactly num_quantiles+1 boundary values\n  // will be returned.\n  std::vector<float> boundaries = stream.GenerateQuantiles(num_quantiles - 1);\n  CHECK_EQ(boundaries.size(), num_quantiles);\n  return boundaries;\n}\n\nstd::vector<float> GetBuckets(const int32_t feature,\n                              const OpInputList& buckets_list) {\n  const auto& buckets = buckets_list[feature].flat<float>();\n  std::vector<float> buckets_vector(buckets.data(),\n                                    buckets.data() + buckets.size());\n  return buckets_vector;\n}\n\nREGISTER_RESOURCE_HANDLE_KERNEL(BoostedTreesQuantileStreamResource);\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"IsBoostedTreesQuantileStreamResourceInitialized\").Device(DEVICE_CPU),\n    IsResourceInitialized<BoostedTreesQuantileStreamResource>);\n\nclass BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n public:\n  explicit BoostedTreesCreateQuantileStreamResourceOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kMaxElementsName, &max_elements_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n    OP_REQUIRES(context, num_streams >= 0,\n                errors::InvalidArgument(\n                    \"Num_streams input cannot be a negative integer\"));\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }\n\n private:\n  // An upper bound on the number of entries that the summaries might have\n  // for a feature.\n  int64 max_elements_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesCreateQuantileStreamResource\").Device(DEVICE_CPU),\n    BoostedTreesCreateQuantileStreamResourceOp);\n\nclass BoostedTreesMakeQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesMakeQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n\n    // Parse example weights and get batch size.\n    const Tensor* example_weights_t;\n    OP_REQUIRES_OK(context,\n                   context->input(kExampleWeightsName, &example_weights_t));\n    DCHECK(float_features_list.size() > 0) << \"Got empty feature list\";\n    auto example_weights = example_weights_t->flat<float>();\n    const int64_t weight_size = example_weights.size();\n    const int64_t batch_size = float_features_list[0].flat<float>().size();\n    OP_REQUIRES(\n        context, weight_size == 1 || weight_size == batch_size,\n        errors::InvalidArgument(strings::Printf(\n            \"Weights should be a single value or same size as features.\")));\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        const auto feature_values = float_features_list[index].flat<float>();\n        QuantileStream stream(epsilon, batch_size + 1);\n        // Run quantile summary generation.\n        for (int64_t j = 0; j < batch_size; j++) {\n          stream.PushEntry(feature_values(j), (weight_size > 1)\n                                                  ? example_weights(j)\n                                                  : example_weights(0));\n        }\n        stream.Finalize();\n        const auto summary_entry_list = stream.GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        OP_REQUIRES_OK(\n            context,\n            summaries_output_list.allocate(\n                index,\n                TensorShape({static_cast<int64>(summary_entry_list.size()), 4}),\n                &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_entry_list.size(); row++) {\n          const auto& entry = summary_entry_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * batch_size;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesMakeQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesMakeQuantileSummariesOp);\n\nclass BoostedTreesFlushQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesFlushQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        QuantileStream* stream = stream_resource->stream(index);\n        stream->Finalize();\n\n        const auto summary_list = stream->GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        const int64_t summary_list_size =\n            static_cast<int64>(summary_list.size());\n        OP_REQUIRES_OK(context, summaries_output_list.allocate(\n                                    index, TensorShape({summary_list_size, 4}),\n                                    &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_list_size; row++) {\n          const auto& entry = summary_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n    stream_resource->ResetStreams();\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesFlushQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesFlushQuantileSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceAddSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceAddSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpInputList summaries_list;\n    OP_REQUIRES_OK(context,\n                   context->input_list(kSummariesName, &summaries_list));\n    int32_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(static_cast<int>(num_streams), summaries_list.size());\n\n    auto do_quantile_add_summary = [&](const int64_t begin, const int64_t end) {\n      // Iterating all features.\n      for (int64_t feature_idx = begin; feature_idx < end; ++feature_idx) {\n        QuantileStream* stream = stream_resource->stream(feature_idx);\n        if (stream->IsFinalized()) {\n          VLOG(1) << \"QuantileStream has already been finalized for feature\"\n                  << feature_idx << \".\";\n          continue;\n        }\n        const Tensor& summaries = summaries_list[feature_idx];\n        const auto summary_values = summaries.matrix<float>();\n        const auto& tensor_shape = summaries.shape();\n        const int64_t entries_size = tensor_shape.dim_size(0);\n        CHECK_EQ(tensor_shape.dim_size(1), 4);\n        std::vector<QuantileSummaryEntry> summary_entries;\n        summary_entries.reserve(entries_size);\n        for (int64_t i = 0; i < entries_size; i++) {\n          float value = summary_values(i, 0);\n          float weight = summary_values(i, 1);\n          float min_rank = summary_values(i, 2);\n          float max_rank = summary_values(i, 3);\n          QuantileSummaryEntry entry(value, weight, min_rank, max_rank);\n          summary_entries.push_back(entry);\n        }\n        stream_resource->stream(feature_idx)->PushSummary(summary_entries);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_add_summary);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceAddSummaries\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceAddSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceDeserializeOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceDeserializeOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumStreamsName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    core::RefCountPtr<QuantileStreamResource> streams_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, HandleFromInput(context, 0),\n                                           &streams_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*streams_resource->mutex());\n\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n\n    auto do_quantile_deserialize = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const Tensor& bucket_boundaries_t = bucket_boundaries_list[stream_idx];\n        const auto& bucket_boundaries = bucket_boundaries_t.vec<float>();\n        std::vector<float> result;\n        result.reserve(bucket_boundaries.size());\n        for (size_t i = 0; i < bucket_boundaries.size(); ++i) {\n          result.push_back(bucket_boundaries(i));\n        }\n        streams_resource->set_boundaries(result, stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_deserialize);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceDeserialize\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceDeserializeOp);\n\nclass BoostedTreesQuantileStreamResourceFlushOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceFlushOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context,\n                   context->GetAttr(kGenerateQuantiles, &generate_quantiles_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const Tensor* num_buckets_t;\n    OP_REQUIRES_OK(context, context->input(kNumBucketsName, &num_buckets_t));\n    const int64_t num_buckets = num_buckets_t->scalar<int64>()();\n    const int64_t num_streams = stream_resource->num_streams();\n\n    auto do_quantile_flush = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; ++stream_idx) {\n        QuantileStream* stream = stream_resource->stream(stream_idx);\n        stream->Finalize();\n        stream_resource->set_boundaries(\n            generate_quantiles_ ? GenerateQuantiles(*stream, num_buckets)\n                                : GenerateBoundaries(*stream, num_buckets),\n            stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_flush);\n\n    stream_resource->ResetStreams();\n    stream_resource->set_buckets_ready(true);\n  }\n\n private:\n  bool generate_quantiles_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceFlush\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceFlushOp);\n\nclass BoostedTreesQuantileStreamResourceGetBucketBoundariesOp\n    : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceGetBucketBoundariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const int64_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(num_features_, num_streams);\n    OpOutputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketBoundariesName,\n                                                 &bucket_boundaries_list));\n\n    auto do_quantile_get_buckets = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const auto& boundaries = stream_resource->boundaries(stream_idx);\n        Tensor* bucket_boundaries_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       bucket_boundaries_list.allocate(\n                           stream_idx, {static_cast<int64>(boundaries.size())},\n                           &bucket_boundaries_t));\n        auto* quantiles_flat = bucket_boundaries_t->flat<float>().data();\n        memcpy(quantiles_flat, boundaries.data(),\n               sizeof(float) * boundaries.size());\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_get_buckets);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceGetBucketBoundaries\")\n        .Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceGetBucketBoundariesOp);\n\n// Given the calculated quantiles thresholds and input data, this operation\n// converts the input features into the buckets (categorical values), depending\n// on which quantile they fall into.\nclass BoostedTreesBucketizeOp : public OpKernel {\n public:\n  explicit BoostedTreesBucketizeOp(OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n    OP_REQUIRES(context,\n                tensorflow::TensorShapeUtils::IsVector(\n                    bucket_boundaries_list[0].shape()),\n                errors::InvalidArgument(\n                    strings::Printf(\"Buckets should be flat vectors.\")));\n    OpOutputList buckets_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketsName, &buckets_list));\n\n    auto do_quantile_get_quantiles = [&](const int64_t begin,\n                                         const int64_t end) {\n      // Iterating over all resources\n      for (int64_t feature_idx = begin; feature_idx < end; feature_idx++) {\n        const Tensor& values_tensor = float_features_list[feature_idx];\n        const int64_t num_values = values_tensor.dim_size(0);\n\n        Tensor* output_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       buckets_list.allocate(\n                           feature_idx, TensorShape({num_values}), &output_t));\n        auto output = output_t->flat<int32>();\n\n        const std::vector<float>& bucket_boundaries_vector =\n            GetBuckets(feature_idx, bucket_boundaries_list);\n        auto flat_values = values_tensor.flat<float>();\n        const auto& iter_begin = bucket_boundaries_vector.begin();\n        const auto& iter_end = bucket_boundaries_vector.end();\n        for (int64_t instance = 0; instance < num_values; instance++) {\n          if (iter_begin == iter_end) {\n            output(instance) = 0;\n            continue;\n          }\n          const float value = flat_values(instance);\n          auto bucket_iter = std::lower_bound(iter_begin, iter_end, value);\n          if (bucket_iter == iter_end) {\n            --bucket_iter;\n          }\n          const int32_t bucket = static_cast<int32>(bucket_iter - iter_begin);\n          // Bucket id.\n          output(instance) = bucket;\n        }\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_get_quantiles);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"BoostedTreesBucketize\").Device(DEVICE_CPU),\n                        BoostedTreesBucketizeOp);\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/boosted_trees/quantile_ops.cc"], "buggy_code_start_loc": [118], "buggy_code_end_loc": [118], "fixing_code_start_loc": [119], "fixing_code_end_loc": [122], "type": "CWE-681", "message": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-37661", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-12T21:15:08.867", "lastModified": "2021-08-18T21:09:13.300", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico. En las versiones afectadas un atacante puede causar una denegaci\u00f3n de servicio en \"boosted_trees_create_quantile_stream_resource\" usando argumentos negativos. La [implementaci\u00f3n](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) no comprueba que \"num_streams\" s\u00f3lo contenga n\u00fameros no negativos. A su vez, [esto resulta en usar este valor para asignar memoria](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). Sin embargo, \"reserve\" recibe un entero sin signo, por lo que se presenta una conversi\u00f3n impl\u00edcita de un valor negativo a un grande positivo sin signo. Esto resulta en un bloqueo de la biblioteca est\u00e1ndar. Hemos parcheado el problema en el commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.6.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.5.1, TensorFlow versi\u00f3n 2.4.3, y TensorFlow versi\u00f3n 2.3.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango de soporte."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-681"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-681"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.4", "matchCriteriaId": "0F83C081-51CC-415F-A8C0-0A44C75E2CD6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.3", "matchCriteriaId": "BD3F2BF8-EBA9-42BF-8F9B-D918B880B15A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.5.0:*:*:*:*:*:*:*", "matchCriteriaId": "D03E99A7-4E3D-427D-A156-C0713E9FB02A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "70FA6E48-6C57-40CA-809F-4E3D07CBF348"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "42187561-E491-434D-828C-F36701446634"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "C66B61C8-450A-4C5E-9174-F970D6DEE778"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gf88-j2mg-cc82", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992"}}