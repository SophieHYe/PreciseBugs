{"buggy_code": ["/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"absl/container/flat_hash_set.h\"\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_split.h\"\n#include \"absl/strings/string_view.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/util/einsum_op_util.h\"\n\nnamespace tensorflow {\n\nnamespace shape_inference {\n\n// The V2 version computes windowed output size with arbitrary dilation_rate and\n// explicit padding, while the original version only handles the cases where\n// dilation_rates equal to 1 and the padding is SAME or VALID.\nStatus GetWindowedOutputSizeFromDimsV2(\n    shape_inference::InferenceContext* c,\n    shape_inference::DimensionHandle input_size,\n    shape_inference::DimensionOrConstant filter_size, int64_t dilation_rate,\n    int64_t stride, Padding padding_type, int64_t padding_before,\n    int64_t padding_after, shape_inference::DimensionHandle* output_size) {\n  if (stride <= 0) {\n    return errors::InvalidArgument(\"Stride must be > 0, but got \", stride);\n  }\n\n  if (dilation_rate < 1) {\n    return errors::InvalidArgument(\"Dilation rate must be >= 1, but got \",\n                                   dilation_rate);\n  }\n\n  // See also the parallel implementation in GetWindowedOutputSizeVerbose.\n  switch (padding_type) {\n    case Padding::VALID:\n      padding_before = padding_after = 0;\n      TF_FALLTHROUGH_INTENDED;\n    case Padding::EXPLICIT:\n      TF_RETURN_IF_ERROR(\n          c->Add(input_size, padding_before + padding_after, &input_size));\n      if (dilation_rate > 1) {\n        DimensionHandle window_size;\n        TF_RETURN_IF_ERROR(\n            c->Subtract(c->MakeDim(filter_size), 1, &window_size));\n        TF_RETURN_IF_ERROR(\n            c->Multiply(window_size, dilation_rate, &window_size));\n        TF_RETURN_IF_ERROR(c->Add(window_size, 1, &window_size));\n        TF_RETURN_IF_ERROR(c->Subtract(input_size, window_size, output_size));\n      } else {\n        TF_RETURN_IF_ERROR(c->Subtract(input_size, filter_size, output_size));\n      }\n      TF_RETURN_IF_ERROR(c->Add(*output_size, stride, output_size));\n      TF_RETURN_IF_ERROR(c->Divide(*output_size, stride,\n                                   /*evenly_divisible=*/false, output_size));\n      break;\n    case Padding::SAME:\n      TF_RETURN_IF_ERROR(c->Add(input_size, stride - 1, output_size));\n      TF_RETURN_IF_ERROR(c->Divide(*output_size, stride,\n                                   /*evenly_divisible=*/false, output_size));\n      break;\n  }\n  return Status::OK();\n}\n\nStatus GetWindowedOutputSizeFromDims(\n    shape_inference::InferenceContext* c,\n    shape_inference::DimensionHandle input_size,\n    shape_inference::DimensionOrConstant filter_size, int64_t stride,\n    Padding padding_type, shape_inference::DimensionHandle* output_size) {\n  if (padding_type == Padding::EXPLICIT) {\n    return errors::Internal(\n        \"GetWindowedOutputSizeFromDims does not handle EXPLICIT padding; call \"\n        \"GetWindowedOutputSizeFromDimsV2 instead\");\n  }\n  return GetWindowedOutputSizeFromDimsV2(c, input_size, filter_size,\n                                         /*dilation_rate=*/1, stride,\n                                         padding_type,\n                                         // Give dummy values of -1 to\n                                         // padding_before and padding_after,\n                                         // since explicit padding is not used.\n                                         -1, -1, output_size);\n}\n\nStatus UnchangedShape(shape_inference::InferenceContext* c) {\n  c->set_output(0, c->input(0));\n  auto* handle_data = c->input_handle_shapes_and_types(0);\n  if (handle_data != nullptr) {\n    c->set_output_handle_shapes_and_types(0, *handle_data);\n  }\n  return Status::OK();\n}\n\nStatus MatMulShape(shape_inference::InferenceContext* c) {\n  ShapeHandle a;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &a));\n\n  ShapeHandle b;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &b));\n\n  bool transpose_a, transpose_b;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"transpose_a\", &transpose_a));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"transpose_b\", &transpose_b));\n  DimensionHandle output_rows = transpose_a ? c->Dim(a, 1) : c->Dim(a, 0);\n  DimensionHandle output_cols = transpose_b ? c->Dim(b, 0) : c->Dim(b, 1);\n\n  // Validate that the inner shapes are compatible.\n  DimensionHandle inner_a = transpose_a ? c->Dim(a, 0) : c->Dim(a, 1);\n  DimensionHandle inner_b = transpose_b ? c->Dim(b, 1) : c->Dim(b, 0);\n  DimensionHandle merged;\n  TF_RETURN_IF_ERROR(c->Merge(inner_a, inner_b, &merged));\n\n  c->set_output(0, c->Matrix(output_rows, output_cols));\n  return Status::OK();\n}\n\nnamespace {\n\n// Validate that an Einsum subscript contains exactly one or zero ellipsis; and\n// that periods (.) occur only within an ellipses (...).\nStatus ValidateEinsumEllipsis(absl::string_view subscript,\n                              bool* found_ellipsis) {\n  const int num_periods = absl::c_count(subscript, '.');\n  if (num_periods != 0 && num_periods != 3) {\n    return errors::InvalidArgument(\n        \"Expected at most one ellipsis (...), but found \", num_periods,\n        \" periods (.) in the input subscript: \", subscript);\n  }\n  if (num_periods == 3 && !absl::StrContains(subscript, \"...\")) {\n    return errors::InvalidArgument(\n        \"Periods found outside of ellipsis in subscript: \", subscript);\n  }\n  *found_ellipsis = num_periods > 0;\n  return Status::OK();\n}\n\n}  // namespace\n\nStatus EinsumShape(shape_inference::InferenceContext* c) {\n  // We assume that the equation has a valid format. Either (x),(y)->(z)\n  // or (x)->(z), where each of (x), (y) and (z) are concatenation of zero or\n  // more latin alphabets and contains at most one ellipsis ('...').\n  string equation;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"equation\", &equation));\n  gtl::InlinedVector<string, 2> input_labels;\n  string output_labels;\n  TF_RETURN_IF_ERROR(\n      ParseEinsumEquation(equation, &input_labels, &output_labels));\n\n  if (c->num_inputs() == 0 || c->num_inputs() > 2) {\n    return errors::InvalidArgument(\"Expected either 1 or 2 inputs but got: \",\n                                   c->num_inputs());\n  }\n  const int input_labels_size = input_labels.size();\n  if (c->num_inputs() != input_labels_size) {\n    return errors::InvalidArgument(\"Expected \", input_labels.size(),\n                                   \" inputs for equation \", equation,\n                                   \" but got: \", c->num_inputs());\n  }\n\n  // Validate input subscripts, build the label to dimension mapping and obtain\n  // the broadcast shapes that map to ellipsis.\n  absl::flat_hash_map<char, DimensionHandle> label_to_dimension;\n  gtl::InlinedVector<ShapeHandle, 2> input_bcast_shapes(c->num_inputs());\n  for (int i = 0, end = c->num_inputs(); i < end; ++i) {\n    bool has_ellipsis = false;\n    TF_RETURN_IF_ERROR(ValidateEinsumEllipsis(input_labels[i], &has_ellipsis));\n    ShapeHandle input_shape = c->input(i);\n    // Validate that the input rank is sufficient for the given number of named\n    // labels.\n    if (c->RankKnown(input_shape)) {\n      if (has_ellipsis) {\n        const int num_named_labels =\n            static_cast<int>(input_labels[i].size()) - 3;\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->WithRankAtLeast(input_shape, num_named_labels, &input_shape),\n            \" for \", i, \"th input and equation: \", equation);\n      } else {\n        const int num_named_labels = static_cast<int>(input_labels[i].size());\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->WithRank(input_shape, num_named_labels, &input_shape), \" for \",\n            i, \"th input and equation: \", equation);\n      }\n    }\n\n    bool seen_ellipsis = false;\n    input_bcast_shapes[i] = c->Scalar();\n    // Run through the input labels; populate label_to_dimension mapping and\n    // compute the broadcast shapes corresponding to the ellipsis (if present).\n    for (int label_idx = 0, end = input_labels[i].size(); label_idx < end;\n         ++label_idx) {\n      const char label = input_labels[i][label_idx];\n      // Calculate the input axis that the current label is referring to. After\n      // the ellipsis, the axis may be found by using negative indices; i.e the\n      // (rank - k)th dimension corresponds to the (num_labels - k)th label.\n      const int64_t axis_before_ellipsis = label_idx;\n      const int64_t axis_after_ellipsis =\n          c->RankKnown(input_shape)\n              ? label_idx + c->Rank(input_shape) - input_labels[i].size()\n              : -1;\n\n      // Populate the input broadcast shape when we encounter an ellipsis (...).\n      if (label == '.') {\n        if (!c->RankKnown(input_shape)) {\n          input_bcast_shapes[i] = c->UnknownShape();\n        } else {\n          // The broadcast shape runs till the named label right after the\n          // ellipsis, the label with index (label_idx + 3).\n          TF_RETURN_IF_ERROR(c->Subshape(input_shape, axis_before_ellipsis,\n                                         axis_after_ellipsis + 3,\n                                         &input_bcast_shapes[i]));\n        }\n        label_idx += 2;  // Skip the rest of the ellipsis.\n        seen_ellipsis = true;\n        continue;\n      }\n      // Obtain the dimension that the current label corresponds to.\n      int64_t axis = seen_ellipsis ? axis_after_ellipsis : axis_before_ellipsis;\n      DimensionHandle new_dim = c->RankKnown(input_shape)\n                                    ? c->Dim(input_shape, axis)\n                                    : c->UnknownDim();\n      // If we've seen this label before, make sure previous and current\n      // dimensions are compatible.\n      if (label_to_dimension.contains(label)) {\n        DimensionHandle merged;\n        TF_RETURN_IF_ERROR(\n            c->Merge(label_to_dimension[label], new_dim, &merged));\n        label_to_dimension[label] = merged;\n      } else {\n        label_to_dimension[label] = new_dim;\n      }\n    }\n  }\n\n  // For two inputs, broadcast the two input broadcast shapes to create the\n  // output broadcast shape. For one input, just copy the single broadcast\n  // shape.\n  ShapeHandle output_bcast_shape;\n  if (input_bcast_shapes.size() == 1) {\n    output_bcast_shape = input_bcast_shapes[0];\n  } else if (input_bcast_shapes.size() == 2) {\n    TF_RETURN_IF_ERROR(BroadcastBinaryOpOutputShapeFnHelper(\n        c, input_bcast_shapes[0], input_bcast_shapes[1], true,\n        &output_bcast_shape));\n  }\n\n  bool output_has_ellipsis = false;\n  TF_RETURN_IF_ERROR(\n      ValidateEinsumEllipsis(output_labels, &output_has_ellipsis));\n  if (output_has_ellipsis) {\n    // If the output subscript has ellipsis and the output broadcast rank is\n    // unknown, then the output shape should have unknown rank.\n    if (!c->RankKnown(output_bcast_shape)) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n  } else {\n    // If the output subscripts don't have ellipsis then make sure the output\n    // broadcasting shape is empty.\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        c->WithRankAtMost(output_bcast_shape, 0, &output_bcast_shape),\n        \" for einsum equation '\", equation,\n        \"' without ellipsis (...) in the output subscripts where input(s) have \"\n        \"non-empty broadcasting shape\");\n    output_bcast_shape = c->Scalar();\n  }\n\n  // Create the output shape from output labels and label_to_dimension mapping.\n  std::vector<DimensionHandle> output_dims;\n  for (int label_idx = 0, end = output_labels.size(); label_idx < end;\n       ++label_idx) {\n    const char label = output_labels[label_idx];\n    // Append the output_bcast_shape when the ellipsis is encountered.\n    if (label == '.') {\n      for (int k = 0; k < c->Rank(output_bcast_shape); ++k) {\n        output_dims.push_back(c->Dim(output_bcast_shape, k));\n      }\n      label_idx += 2;  // Skip the rest of the ellipsis.\n      continue;\n    }\n    auto dimension_it = label_to_dimension.find(label);\n    if (dimension_it == label_to_dimension.end()) {\n      return errors::InvalidArgument(\n          \"Einsum output subscripts for equation '\", equation, \"' has label '\",\n          label, \"' which is not present in the input subscripts\");\n    }\n    output_dims.push_back(dimension_it->second);\n  }\n  c->set_output(0, c->MakeShape(output_dims));\n  return Status::OK();\n}\n\nStatus BatchMatMulV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle a_shape;\n  ShapeHandle b_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &a_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 2, &b_shape));\n\n  // Determine output rows and columns.\n  bool adj_x;\n  bool adj_y;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_x\", &adj_x));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_y\", &adj_y));\n  DimensionHandle output_rows = c->Dim(a_shape, adj_x ? -1 : -2);\n  DimensionHandle output_cols = c->Dim(b_shape, adj_y ? -2 : -1);\n\n  // Inner dimensions should be compatible.\n  DimensionHandle inner_merged;\n  TF_RETURN_IF_ERROR(c->Merge(c->Dim(a_shape, adj_x ? -2 : -1),\n                              c->Dim(b_shape, adj_y ? -1 : -2), &inner_merged));\n\n  // Batch dimensions should broadcast with each other.\n  ShapeHandle a_batch_shape;\n  ShapeHandle b_batch_shape;\n  ShapeHandle output_batch_shape;\n  TF_RETURN_IF_ERROR(c->Subshape(a_shape, 0, -2, &a_batch_shape));\n  TF_RETURN_IF_ERROR(c->Subshape(b_shape, 0, -2, &b_batch_shape));\n\n  TF_RETURN_IF_ERROR(BroadcastBinaryOpOutputShapeFnHelper(\n      c, a_batch_shape, b_batch_shape, true, &output_batch_shape));\n\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->Concatenate(\n      output_batch_shape, c->Matrix(output_rows, output_cols), &output_shape));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus BatchMatMulShape(shape_inference::InferenceContext* c) {\n  ShapeHandle a_shape;\n  ShapeHandle b_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &a_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 2, &b_shape));\n\n  // Determine output rows and cols.\n  bool adj_x;\n  bool adj_y;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_x\", &adj_x));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_y\", &adj_y));\n  DimensionHandle output_rows = c->Dim(a_shape, adj_x ? -1 : -2);\n  DimensionHandle output_cols = c->Dim(b_shape, adj_y ? -2 : -1);\n\n  // Batch dims match between inputs.\n  ShapeHandle a_batch_dims;\n  ShapeHandle b_batch_dims;\n  ShapeHandle batch_dims;\n  TF_RETURN_IF_ERROR(c->Subshape(a_shape, 0, -2, &a_batch_dims));\n  TF_RETURN_IF_ERROR(c->Subshape(b_shape, 0, -2, &b_batch_dims));\n  TF_RETURN_IF_ERROR(c->Merge(a_batch_dims, b_batch_dims, &batch_dims));\n\n  // Assert inner dims match.\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(c->Merge(c->Dim(a_shape, adj_x ? -2 : -1),\n                              c->Dim(b_shape, adj_y ? -1 : -2), &unused));\n\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(batch_dims, c->Matrix(output_rows, output_cols), &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\n// --------------------------------------------------------------------------\n\nStatus BiasAddShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  if (s.ok() && data_format == \"NCHW\") {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 3, &input_shape));\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  }\n\n  ShapeHandle bias_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &bias_shape));\n  DimensionHandle bias_dim = c->Dim(bias_shape, 0);\n\n  // If rank unknown, return unknown shape.\n  if (!c->RankKnown(input_shape)) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Output has the same shape as the input, and matches the length of\n  // the bias in its bias dimension.\n  ShapeHandle output_shape;\n  if (s.ok() && data_format == \"NCHW\") {\n    // Merge the length of bias_shape into the third to last dimension\n    ShapeHandle first;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 0, 1, &first));\n\n    ShapeHandle last;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 2, &last));\n\n    DimensionHandle input_bias_dim = c->Dim(input_shape, 1);\n    DimensionHandle merged_bias_dim;\n    TF_RETURN_IF_ERROR(c->Merge(input_bias_dim, bias_dim, &merged_bias_dim));\n    ShapeHandle merged_bias = c->Vector(merged_bias_dim);\n\n    ShapeHandle temp;\n    TF_RETURN_IF_ERROR(c->Concatenate(first, merged_bias, &temp));\n    TF_RETURN_IF_ERROR(c->Concatenate(temp, last, &output_shape));\n  } else {\n    ShapeHandle all_but_bias;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 0, -1, &all_but_bias));\n\n    DimensionHandle input_bias_dim = c->Dim(input_shape, -1);\n    DimensionHandle merged_bias_dim;\n    TF_RETURN_IF_ERROR(c->Merge(input_bias_dim, bias_dim, &merged_bias_dim));\n\n    ShapeHandle merged_bias = c->Vector(merged_bias_dim);\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(all_but_bias, merged_bias, &output_shape));\n  }\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus BiasAddGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  if (s.ok() && data_format == \"NCHW\") {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 3, &input_shape));\n    c->set_output(0, c->Vector(c->Dim(input_shape, 1)));\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n    c->set_output(0, c->Vector(c->Dim(input_shape, -1)));\n  }\n\n  return Status::OK();\n}\n\nStatus CheckFormatConstraintsOnShape(const TensorFormat tensor_format,\n                                     const ShapeHandle shape_handle,\n                                     const string& tensor_name,\n                                     shape_inference::InferenceContext* c) {\n  if (tensor_format == FORMAT_NCHW_VECT_C) {\n    // Check that the vect dim has size 4 or 32.\n    const int num_dims = c->Rank(shape_handle);\n    DimensionHandle vect_dim = c->Dim(\n        shape_handle, GetTensorInnerFeatureDimIndex(num_dims, tensor_format));\n    int64_t vect_dim_val = c->Value(vect_dim);\n    if (vect_dim_val != 4 && vect_dim_val != 32) {\n      return errors::InvalidArgument(\n          \"VECT_C dimension must be 4 or 32, but is \", vect_dim_val);\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus DatasetIteratorShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 0, &unused));\n  std::vector<PartialTensorShape> output_shapes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"output_shapes\", &output_shapes));\n  const int output_shapes_size = output_shapes.size();\n  if (output_shapes_size != c->num_outputs()) {\n    return errors::InvalidArgument(\n        \"`output_shapes` must be the same length as `output_types` (\",\n        output_shapes.size(), \" vs. \", c->num_outputs());\n  }\n  for (size_t i = 0; i < output_shapes.size(); ++i) {\n    shape_inference::ShapeHandle output_shape_handle;\n    TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(\n        output_shapes[i], &output_shape_handle));\n    c->set_output(static_cast<int>(i), output_shape_handle);\n  }\n  return Status::OK();\n}\n\nStatus MakeShapeFromFormat(TensorFormat format, DimensionOrConstant N,\n                           const std::vector<DimensionOrConstant>& spatial,\n                           DimensionOrConstant C, ShapeHandle* out,\n                           shape_inference::InferenceContext* context) {\n  const int num_dims = GetTensorDimsFromSpatialDims(spatial.size(), format);\n  std::vector<DimensionHandle> dims_actual(num_dims);\n  dims_actual[GetTensorBatchDimIndex(num_dims, format)] = context->MakeDim(N);\n  int outer_c_index = GetTensorFeatureDimIndex(num_dims, format);\n  dims_actual[outer_c_index] = context->MakeDim(C);\n  if (format == FORMAT_NCHW_VECT_C) {\n    dims_actual[GetTensorInnerFeatureDimIndex(num_dims, format)] =\n        context->MakeDim(4);\n  } else if (format == FORMAT_NHWC_VECT_W) {\n    dims_actual[GetTensorInnerWidthDimIndex(num_dims, format)] =\n        context->MakeDim(4);\n  }\n  for (int spatial_dim = 0, end = spatial.size(); spatial_dim < end;\n       spatial_dim++) {\n    dims_actual[GetTensorSpatialDimIndex(num_dims, format, spatial_dim)] =\n        context->MakeDim(spatial[spatial_dim]);\n  }\n  *out = context->MakeShape(dims_actual);\n  return Status::OK();\n}\n\nStatus DimensionsFromShape(ShapeHandle shape, TensorFormat format,\n                           DimensionHandle* batch_dim,\n                           gtl::MutableArraySlice<DimensionHandle> spatial_dims,\n                           DimensionHandle* filter_dim,\n                           InferenceContext* context) {\n  const int32_t rank =\n      GetTensorDimsFromSpatialDims(spatial_dims.size(), format);\n  // Batch.\n  *batch_dim = context->Dim(shape, GetTensorBatchDimIndex(rank, format));\n  // Spatial.\n  for (int spatial_dim_index = 0, end = spatial_dims.size();\n       spatial_dim_index < end; ++spatial_dim_index) {\n    spatial_dims[spatial_dim_index] = context->Dim(\n        shape, GetTensorSpatialDimIndex(rank, format, spatial_dim_index));\n  }\n  // Channel.\n  *filter_dim = context->Dim(shape, GetTensorFeatureDimIndex(rank, format));\n  if (format == FORMAT_NCHW_VECT_C) {\n    TF_RETURN_IF_ERROR(context->Multiply(\n        *filter_dim,\n        context->Dim(shape, GetTensorInnerFeatureDimIndex(rank, format)),\n        filter_dim));\n  }\n  return Status::OK();\n}\n\n// vect_size must be provided if format is NCHW_VECT_C.\nStatus ShapeFromDimensions(DimensionHandle batch_dim,\n                           gtl::ArraySlice<DimensionHandle> spatial_dims,\n                           DimensionHandle filter_dim, TensorFormat format,\n                           absl::optional<DimensionHandle> vect_size,\n                           InferenceContext* context, ShapeHandle* shape) {\n  const int32_t rank =\n      GetTensorDimsFromSpatialDims(spatial_dims.size(), format);\n  std::vector<DimensionHandle> out_dims(rank);\n\n  // Batch.\n  out_dims[tensorflow::GetTensorBatchDimIndex(rank, format)] = batch_dim;\n  // Spatial.\n  for (int spatial_dim_index = 0, end = spatial_dims.size();\n       spatial_dim_index < end; ++spatial_dim_index) {\n    out_dims[tensorflow::GetTensorSpatialDimIndex(\n        rank, format, spatial_dim_index)] = spatial_dims[spatial_dim_index];\n  }\n  // Channel.\n  if (format == tensorflow::FORMAT_NCHW_VECT_C) {\n    // When format is NCHW_VECT_C, factor the feature map count into the outer\n    // feature count and the inner feature count (4 or 32).\n    CHECK(vect_size.has_value());  // Crash ok.\n    TF_RETURN_IF_ERROR(context->Divide(\n        filter_dim, *vect_size, /*evenly_divisible=*/true,\n        &out_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)]));\n    out_dims[GetTensorInnerFeatureDimIndex(rank, format)] = *vect_size;\n  } else {\n    out_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)] = filter_dim;\n  }\n\n  *shape = context->MakeShape(out_dims);\n  return tensorflow::Status::OK();\n}\n\nnamespace {\n\nStatus Conv2DShapeImpl(shape_inference::InferenceContext* c,\n                       bool supports_explicit_padding) {\n  string data_format_str, filter_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  if (!c->GetAttr(\"filter_format\", &filter_format_str).ok()) {\n    filter_format_str = \"HWIO\";\n  }\n\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  FilterTensorFormat filter_format;\n  if (!FilterFormatFromString(filter_format_str, &filter_format)) {\n    return errors::InvalidArgument(\"Invalid filter format string: \",\n                                   filter_format_str);\n  }\n\n  constexpr int num_spatial_dims = 2;\n  const int rank = GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n  ShapeHandle conv_input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &conv_input_shape));\n  TF_RETURN_IF_ERROR(CheckFormatConstraintsOnShape(\n      data_format, conv_input_shape, \"conv_input\", c));\n\n  // The filter rank should match the input (4 for NCHW, 5 for NCHW_VECT_C).\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &filter_shape));\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, filter_shape, \"filter\", c));\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"Conv2D requires the dilation attribute to contain 4 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  // strides.size() should be 4 (NCHW) even if the input is 5 (NCHW_VECT_C).\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\"Conv2D on data format \", data_format_str,\n                                   \" requires the stride attribute to contain\"\n                                   \" 4 values, but got: \",\n                                   strides.size());\n  }\n\n  const int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  const int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  const int32_t dilation_rows = GetTensorDim(dilations, data_format, 'H');\n  const int32_t dilation_cols = GetTensorDim(dilations, data_format, 'W');\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle input_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> input_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      conv_input_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(input_spatial_dims), &input_depth_dim, c));\n\n  DimensionHandle output_depth_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'O'));\n  DimensionHandle filter_rows_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'H'));\n  DimensionHandle filter_cols_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'W'));\n  DimensionHandle filter_input_depth_dim;\n  if (filter_format == FORMAT_OIHW_VECT_I) {\n    TF_RETURN_IF_ERROR(c->Multiply(\n        c->Dim(filter_shape,\n               GetFilterDimIndex<num_spatial_dims>(filter_format, 'I')),\n        c->Dim(filter_shape,\n               GetFilterTensorInnerInputChannelsDimIndex(rank, filter_format)),\n        &filter_input_depth_dim));\n  } else {\n    filter_input_depth_dim = c->Dim(\n        filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'I'));\n  }\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status s = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!s.ok() && !errors::IsNotFound(s)) {\n      return s;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    CHECK(padding != Padding::EXPLICIT);  // Crash ok.\n  }\n\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[0], filter_rows_dim, dilation_rows, stride_rows,\n      padding, pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[1], filter_cols_dim, dilation_cols, stride_cols,\n      padding, pad_cols_before, pad_cols_after, &output_cols));\n\n  absl::optional<DimensionHandle> vect_size;\n  if (data_format == FORMAT_NCHW_VECT_C) {\n    vect_size.emplace(c->Dim(conv_input_shape,\n                             GetTensorInnerFeatureDimIndex(rank, data_format)));\n  }\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, {output_rows, output_cols}, output_depth_dim, data_format,\n      vect_size, c, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\n}  // namespace\n\n// Shape function for Conv2D-like operations that support explicit padding.\nStatus Conv2DShapeWithExplicitPadding(shape_inference::InferenceContext* c) {\n  return Conv2DShapeImpl(c, true);\n}\n\n// Shape function for Conv2D-like operations that do not support explicit\n// padding.\nStatus Conv2DShape(shape_inference::InferenceContext* c) {\n  return Conv2DShapeImpl(c, false);\n}\n\n// TODO(mjanusz): Unify all conv/pooling shape functions.\nStatus Conv3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 5, &filter_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the dilation attribute to contain 5 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the stride attribute to contain 5 values, but got: \",\n        strides.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t dilation_planes, dilation_rows, dilation_cols;\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    dilation_planes = dilations[2];\n    dilation_cols = dilations[3];\n    dilation_rows = dilations[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_planes = dilations[1];\n    dilation_cols = dilations[2];\n    dilation_rows = dilations[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle input_depth_dim = c->Dim(input_shape, 4);\n\n  DimensionHandle filter_planes_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 1);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 2);\n  DimensionHandle filter_input_depth_dim = c->Dim(filter_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(filter_shape, 4);\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n  DimensionHandle output_planes, output_rows, output_cols;\n\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_planes_dim, filter_planes_dim, dilation_planes, stride_planes,\n      padding, -1, -1, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding, -1,\n      -1, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding, -1,\n      -1, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus Conv2DBackpropInputShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n\n  // For the rest of this function, output_grad_* describes out_backprop and\n  // input_grad_* describes in_backprop.\n  ShapeHandle output_grad_shape = c->input(2);\n  TF_RETURN_IF_ERROR(c->WithRank(output_grad_shape, 4, &output_grad_shape));\n  ShapeHandle filter_shape = c->input(1);\n  TF_RETURN_IF_ERROR(c->WithRank(filter_shape, 4, &filter_shape));\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle output_grad_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> output_grad_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      output_grad_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(output_grad_spatial_dims), &output_grad_depth_dim, c));\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(\n      c->Merge(output_grad_depth_dim, c->Dim(filter_shape, 3), &unused));\n\n  ShapeHandle specified_input_grad_shape;\n  TF_RETURN_IF_ERROR(\n      c->MakeShapeFromShapeTensor(0, &specified_input_grad_shape));\n  if (c->Rank(specified_input_grad_shape) == InferenceContext::kUnknownRank) {\n    TF_RETURN_IF_ERROR(c->WithRank(specified_input_grad_shape, 4,\n                                   &specified_input_grad_shape));\n  }\n\n  // input_grad_depth_dim doesn't equal c->Dim(filter_shape,2) when the number\n  // of groups is larger than 1. If input_sizes is a 4D shape, we collect\n  // input_grad_depth_dim from input_sizes; otherwise we compute it as\n  // c->Dim(filter_shape,2).\n  DimensionHandle input_grad_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> specified_input_grad_spatial_dims(2);\n  int specified_input_grad_rank = c->Rank(specified_input_grad_shape);\n  if (specified_input_grad_rank == 4) {\n    DimensionHandle specified_batch_size_dim;\n    TF_RETURN_IF_ERROR(DimensionsFromShape(\n        specified_input_grad_shape, data_format, &specified_batch_size_dim,\n        absl::MakeSpan(specified_input_grad_spatial_dims),\n        &input_grad_depth_dim, c));\n    TF_RETURN_IF_ERROR(\n        c->Merge(specified_batch_size_dim, batch_size_dim, &unused));\n  } else if (specified_input_grad_rank == 2) {\n    specified_input_grad_spatial_dims[0] =\n        c->Dim(specified_input_grad_shape, 0);\n    specified_input_grad_spatial_dims[1] =\n        c->Dim(specified_input_grad_shape, 1);\n    input_grad_depth_dim = c->Dim(filter_shape, 2);\n  } else {\n    return errors::InvalidArgument(\n        \"Conv2DBackpropInput requires input_sizes to contain 4 values or 2 \"\n        \"values, but got: \",\n        specified_input_grad_rank);\n  }\n\n  ShapeHandle input_grad_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, specified_input_grad_spatial_dims, input_grad_depth_dim,\n      data_format, /*vect_size=*/absl::nullopt, c, &input_grad_shape));\n  c->set_output(0, input_grad_shape);\n  return Status::OK();\n}\n\nStatus Conv2DBackpropFilterWithBiasShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n  if (s.ok() && data_format == \"NCHW\") {\n    c->set_output(1, c->Vector(c->Dim(input_shape, -3)));\n  } else {\n    c->set_output(1, c->Vector(c->Dim(input_shape, -1)));\n  }\n  ShapeHandle sh;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &sh));\n  TF_RETURN_IF_ERROR(c->WithRank(sh, 4, &sh));\n  c->set_output(0, sh);\n  return Status::OK();\n}\n\nnamespace {\n\nStatus DepthwiseConv2DNativeShapeImpl(shape_inference::InferenceContext* c,\n                                      bool supports_explicit_padding) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 4, &filter_shape));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"DepthwiseConv2D requires the stride attribute to contain 4 values, \"\n        \"but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> dilations;\n  if (!c->GetAttr(\"dilations\", &dilations).ok()) {\n    dilations.resize(4, 1);\n  }\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"DepthwiseConv2D requires the dilations attribute to contain 4 values, \"\n        \"but got: \",\n        dilations.size());\n  }\n\n  string data_format_str;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  TensorFormat data_format;\n  if (!s.ok() || !FormatFromString(data_format_str, &data_format)) {\n    data_format = FORMAT_NHWC;\n  }\n  int32_t stride_rows;\n  int32_t stride_cols;\n  int32_t dilation_rows;\n  int32_t dilation_cols;\n  if (data_format == FORMAT_NCHW) {\n    // Canonicalize input shape to NHWC so the shape inference code below can\n    // process it.\n    input_shape =\n        c->MakeShape({{c->Dim(input_shape, 0), c->Dim(input_shape, 2),\n                       c->Dim(input_shape, 3), c->Dim(input_shape, 1)}});\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_rows = dilations[2];\n    dilation_cols = dilations[3];\n  } else {\n    stride_rows = strides[1];\n    stride_cols = strides[2];\n    dilation_rows = dilations[1];\n    dilation_cols = dilations[2];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 2);\n\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 1);\n  DimensionHandle input_depth = c->Dim(filter_shape, 2);\n  DimensionHandle depth_multiplier = c->Dim(filter_shape, 3);\n\n  // Check that the input depths are compatible.\n  TF_RETURN_IF_ERROR(\n      c->Merge(c->Dim(input_shape, 3), input_depth, &input_depth));\n\n  DimensionHandle output_depth;\n  TF_RETURN_IF_ERROR(c->Multiply(input_depth, depth_multiplier, &output_depth));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status status = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!status.ok() && !errors::IsNotFound(status)) {\n      return status;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    DCHECK(padding != Padding::EXPLICIT);\n  }\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding,\n      pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding,\n      pad_cols_before, pad_cols_after, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == FORMAT_NCHW) {\n    output_shape =\n        c->MakeShape({batch_size_dim, output_depth, output_rows, output_cols});\n  } else {\n    output_shape =\n        c->MakeShape({batch_size_dim, output_rows, output_cols, output_depth});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\n};  // namespace\n\nStatus DepthwiseConv2DNativeShape(shape_inference::InferenceContext* c) {\n  return DepthwiseConv2DNativeShapeImpl(c, false);\n}\n\nStatus DepthwiseConv2DNativeShapeWithExplicitPadding(\n    shape_inference::InferenceContext* c) {\n  return DepthwiseConv2DNativeShapeImpl(c, true);\n}\n\nStatus AvgPoolShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"AvgPool requires the stride attribute to contain 4 values, but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"AvgPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n\n  DimensionHandle output_rows, output_cols;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols}, depth_dim,\n                                         &output_shape, c));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus AvgPoolGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &s));\n  TF_RETURN_IF_ERROR(c->WithRank(s, 4, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus FusedBatchNormShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &x));\n\n  bool is_training;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"is_training\", &is_training));\n  float exponential_avg_factor;\n  if (!c->GetAttr(\"exponential_avg_factor\", &exponential_avg_factor).ok()) {\n    exponential_avg_factor = 1.0f;  // default value\n  }\n  int number_inputs = (is_training && exponential_avg_factor == 1.0f) ? 3 : 5;\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(x, channel_dim_index);\n\n  // covers scale, offset, and if is_training is false, mean, variance\n  for (int i = 1; i < number_inputs; ++i) {\n    ShapeHandle vec;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 1, &vec));\n    TF_RETURN_IF_ERROR(c->Merge(channel_dim, c->Dim(vec, 0), &channel_dim));\n  }\n\n  ShapeHandle y;\n  TF_RETURN_IF_ERROR(c->ReplaceDim(x, channel_dim_index, channel_dim, &y));\n  c->set_output(0, y);\n  ShapeHandle vector_shape = c->Vector(channel_dim);\n  c->set_output(1, vector_shape);\n  c->set_output(2, vector_shape);\n  c->set_output(3, vector_shape);\n  c->set_output(4, vector_shape);\n  return Status::OK();\n}\n\nStatus FusedBatchNormV3Shape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormShape(c));\n  c->set_output(5, c->UnknownShape());\n  return Status::OK();\n}\n\nStatus FusedBatchNormExShape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormV3Shape(c));\n\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &x));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(4, data_format);\n  DimensionHandle channel_dim = c->Dim(x, channel_dim_index);\n\n  // This is a cuDNN implementation constraint.\n  if (c->ValueKnown(channel_dim) && c->Value(channel_dim) % 4 != 0) {\n    return errors::InvalidArgument(\n        \"_FusedBatchNormEx channel dimension must be divisible by 4.\");\n  }\n\n  return Status::OK();\n}\n\nStatus FusedBatchNormGradShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle y_backprop;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &y_backprop));\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &x));\n\n  bool is_training;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"is_training\", &is_training));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(y_backprop, channel_dim_index);\n  TF_RETURN_IF_ERROR(\n      c->Merge(channel_dim, c->Dim(x, channel_dim_index), &channel_dim));\n\n  // covers scale, mean (reserve_space_1), variance (reserve_space_2)\n  for (int i = 2; i < 5; ++i) {\n    ShapeHandle vec;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 1, &vec));\n    TF_RETURN_IF_ERROR(c->Merge(channel_dim, c->Dim(vec, 0), &channel_dim));\n  }\n\n  ShapeHandle x_backprop;\n  TF_RETURN_IF_ERROR(\n      c->ReplaceDim(y_backprop, channel_dim_index, channel_dim, &x_backprop));\n  c->set_output(0, x_backprop);\n  c->set_output(1, c->Vector(channel_dim));\n  c->set_output(2, c->Vector(channel_dim));\n  c->set_output(3, c->Vector(0));\n  c->set_output(4, c->Vector(0));\n  return Status::OK();\n}\n\nStatus FusedBatchNormGradExShape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormGradShape(c));\n\n  int num_side_inputs;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"num_side_inputs\", &num_side_inputs));\n  if (num_side_inputs == 0) {\n    return Status::OK();\n  }\n\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle y_backprop;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &y_backprop));\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &x));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(y_backprop, channel_dim_index);\n  TF_RETURN_IF_ERROR(\n      c->Merge(channel_dim, c->Dim(x, channel_dim_index), &channel_dim));\n\n  ShapeHandle side_input_backprop;\n  TF_RETURN_IF_ERROR(c->ReplaceDim(y_backprop, channel_dim_index, channel_dim,\n                                   &side_input_backprop));\n\n  c->set_output(5, side_input_backprop);\n  return Status::OK();\n}\n\nStatus ReadDiagIndex(InferenceContext* c, const Tensor* diag_index_tensor,\n                     int32* lower_diag_index, int32* upper_diag_index) {\n  // This function assumes that the shape of diag_index_tensor is fully defined.\n  if (diag_index_tensor->dims() == 0) {\n    *lower_diag_index = diag_index_tensor->scalar<int32>()();\n    *upper_diag_index = *lower_diag_index;\n  } else {\n    int32_t num_elements = diag_index_tensor->dim_size(0);\n    if (num_elements == 1) {\n      *lower_diag_index = diag_index_tensor->vec<int32>()(0);\n      *upper_diag_index = *lower_diag_index;\n    } else if (num_elements == 2) {\n      *lower_diag_index = diag_index_tensor->vec<int32>()(0);\n      *upper_diag_index = diag_index_tensor->vec<int32>()(1);\n    } else {\n      return errors::InvalidArgument(\n          \"diag_index must be a vector with one or two elements. It has \",\n          num_elements, \" elements.\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus MatrixDiagPartV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape, diag_index_shape, unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &diag_index_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_shape));\n\n  const Tensor* diag_index_tensor = c->input_tensor(1);\n  if (!c->RankKnown(input_shape) || !c->FullyDefined(diag_index_shape) ||\n      diag_index_tensor == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                   &upper_diag_index));\n  if (lower_diag_index > upper_diag_index) {\n    return errors::InvalidArgument(\n        \"lower_diag_index is greater than upper_diag_index\");\n  }\n\n  // Validates lower_diag_index and upper_diag_index.\n  const int32_t input_rank = c->Rank(input_shape);\n  const int32_t num_rows = c->Value(c->Dim(input_shape, input_rank - 2));\n  const int32_t num_cols = c->Value(c->Dim(input_shape, input_rank - 1));\n  int32_t max_diag_len = InferenceContext::kUnknownDim;\n  if (num_rows != InferenceContext::kUnknownDim &&\n      num_cols != InferenceContext::kUnknownDim) {\n    if (lower_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n        (-num_rows >= lower_diag_index || lower_diag_index >= num_cols)) {\n      return errors::InvalidArgument(\"lower_diag_index is out of bound.\");\n    }\n    if (upper_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n        (-num_rows >= upper_diag_index || upper_diag_index >= num_cols)) {\n      return errors::InvalidArgument(\"upper_diag_index is out of bound.\");\n    }\n    max_diag_len = std::min(num_rows + std::min(upper_diag_index, 0),\n                            num_cols - std::max(lower_diag_index, 0));\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.reserve(input_rank - 2);\n  for (int i = 0; i < input_rank - 2; ++i) {\n    dims.push_back(c->Dim(input_shape, i));\n  }\n  if (lower_diag_index < upper_diag_index) {\n    dims.push_back(c->MakeDim(upper_diag_index - lower_diag_index + 1));\n  }\n  dims.push_back(c->MakeDim(max_diag_len));\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus MatrixDiagV2Shape(shape_inference::InferenceContext* c) {\n  // Checks input ranks.\n  ShapeHandle input_shape, diag_index_shape, unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &diag_index_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 0, &unused_shape));\n\n  // Reads the diagonal indices.\n  const Tensor* diag_index_tensor = c->input_tensor(1);\n  if (!c->RankKnown(input_shape) || !c->FullyDefined(diag_index_shape) ||\n      diag_index_tensor == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                   &upper_diag_index));\n  if (lower_diag_index > upper_diag_index) {\n    return errors::InvalidArgument(\n        \"lower_diag_index is greater than upper_diag_index\");\n  }\n\n  // Checks if the number of diagonals provided matches what we imply from\n  // lower_diag_index and upper_diag_index.\n  const int32_t input_rank = c->Rank(input_shape);\n  if (lower_diag_index < upper_diag_index) {\n    const int32_t num_diags = c->Value(c->Dim(input_shape, input_rank - 2));\n    const int32_t other_dim = c->Value(c->Dim(input_shape, input_rank - 1));\n\n    if (num_diags != (upper_diag_index - lower_diag_index + 1)) {\n      return errors::InvalidArgument(\n          \"The number of rows of `diagonal` doesn't match the number of \"\n          \"diagonals implied from `d_lower` and `d_upper`.\\n\",\n          \"num_diags = \", num_diags, \", d_lower = \", lower_diag_index,\n          \", d_upper = \", upper_diag_index, \" \", input_rank, \" \", other_dim);\n    }\n  }\n\n  // Reads num_rows and num_cols.\n  const Tensor* num_rows_tensor = c->input_tensor(2);\n  const Tensor* num_cols_tensor = c->input_tensor(3);\n  int64_t num_rows = -1;\n  int64_t num_cols = -1;\n  if (num_rows_tensor != nullptr) {\n    TF_RETURN_IF_ERROR(c->GetScalarFromTensor(num_rows_tensor, &num_rows));\n  }\n  if (num_cols_tensor != nullptr) {\n    TF_RETURN_IF_ERROR(c->GetScalarFromTensor(num_cols_tensor, &num_cols));\n  }\n\n  // Infers the missing num_rows or num_cols: If both are missing, assume\n  // output is square. Otherwise, use the smallest possible value. Also\n  // validates the provided values.\n  const int32_t max_diag_len = c->Value(c->Dim(input_shape, input_rank - 1));\n  const int32_t min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n  const int32_t min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n  if (num_rows == -1 && num_cols == -1) {  // Special case.\n    num_rows = std::max(min_num_rows, min_num_cols);\n    num_cols = num_rows;\n  }\n  if (num_rows == -1) {\n    num_rows = min_num_rows;\n  } else if (num_rows < min_num_rows) {\n    return errors::InvalidArgument(\"num_rows is too small\");\n  }\n  if (num_cols == -1) {\n    num_cols = min_num_cols;\n  } else if (num_cols < min_num_cols) {\n    return errors::InvalidArgument(\"num_cols is too small.\");\n  }\n  // At least one of them must match the minimum length.\n  if (num_rows != min_num_rows && num_cols != min_num_cols) {\n    return errors::InvalidArgument(\n        \"num_rows and num_cols are not consistent with lower_diag_index, \"\n        \"upper_diag_index, and the length of the given diagonals.\\n\",\n        \"num_rows = \", num_rows, \" != min_num_rows = \", min_num_rows,\n        \", num_cols = \", num_cols, \" != min_num_cols = \", min_num_cols);\n  }\n\n  // Sets output shape.\n  ShapeHandle output_shape;\n  const DimensionHandle output_row_dim = c->MakeDim(num_rows);\n  const DimensionHandle output_col_dim = c->MakeDim(num_cols);\n  if (lower_diag_index == upper_diag_index) {\n    TF_RETURN_IF_ERROR(c->ReplaceDim(input_shape, input_rank - 1,\n                                     output_row_dim, &output_shape));\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(output_shape, c->Vector(output_col_dim), &output_shape));\n  } else {\n    TF_RETURN_IF_ERROR(c->ReplaceDim(input_shape, input_rank - 2,\n                                     output_row_dim, &output_shape));\n    TF_RETURN_IF_ERROR(c->ReplaceDim(output_shape, input_rank - 1,\n                                     output_col_dim, &output_shape));\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MatrixSetDiagV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape, diag_shape, diag_index_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &diag_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(2), 1, &diag_index_shape));\n\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  bool diag_index_known = false;\n  const Tensor* diag_index_tensor = c->input_tensor(2);\n  if (diag_index_tensor != nullptr && c->FullyDefined(diag_index_shape)) {\n    diag_index_known = true;\n    TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                     &upper_diag_index));\n    if (lower_diag_index > upper_diag_index) {\n      return errors::InvalidArgument(\n          \"lower_diag_index is greater than upper_diag_index\");\n    }\n  }\n\n  // Do more checks when input rank is known.\n  if (c->RankKnown(input_shape)) {\n    int32_t input_rank = c->Rank(input_shape);\n\n    // If diag_index is set, we know the exact rank of diagonal.\n    if (diag_index_known) {\n      TF_RETURN_IF_ERROR(c->WithRank(\n          c->input(1),\n          (lower_diag_index == upper_diag_index) ? input_rank - 1 : input_rank,\n          &diag_shape));\n    } else {\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(c->input(1), input_rank - 1, &diag_shape));\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtMost(c->input(1), input_rank, &diag_shape));\n    }\n\n    // Validates lower_diag_index and upper_diag_index.\n    const int32_t num_rows = c->Value(c->Dim(input_shape, input_rank - 2));\n    const int32_t num_cols = c->Value(c->Dim(input_shape, input_rank - 1));\n    if (num_rows != InferenceContext::kUnknownDim &&\n        num_cols != InferenceContext::kUnknownDim) {\n      if (lower_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n          (-num_rows >= lower_diag_index || lower_diag_index >= num_cols)) {\n        return errors::InvalidArgument(\"lower_diag_index is out of bound.\");\n      }\n      if (upper_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n          (-num_rows >= upper_diag_index || upper_diag_index >= num_cols)) {\n        return errors::InvalidArgument(\"upper_diag_index is out of bound.\");\n      }\n    }\n  }\n\n  ShapeHandle output_shape = input_shape;\n  if (c->RankKnown(diag_shape) && !c->FullyDefined(input_shape)) {\n    // Try to infer parts of shape from diag.\n    ShapeHandle diag_prefix;\n    TF_RETURN_IF_ERROR(c->Subshape(\n        diag_shape, 0, (lower_diag_index == upper_diag_index) ? -1 : -2,\n        &diag_prefix));\n\n    // The inner matrices can be rectangular, so we can't pinpoint their\n    // exact height and width by just lower_diag_index, upper_diag_index,\n    // and the longest length of given diagonals.\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(diag_prefix, c->UnknownShapeOfRank(2), &diag_shape));\n    TF_RETURN_IF_ERROR(c->Merge(input_shape, diag_shape, &output_shape));\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPoolShapeImpl(shape_inference::InferenceContext* c,\n                        bool supports_explicit_padding) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the stride attribute to contain 4 values, but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_depth = GetTensorDim(strides, data_format, 'C');\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_depth = GetTensorDim(kernel_sizes, data_format, 'C');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle in_depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status status = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!status.ok() && !errors::IsNotFound(status)) {\n      return status;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    DCHECK(padding != Padding::EXPLICIT);\n  }\n\n  ShapeHandle output_shape;\n  DimensionHandle output_rows, output_cols, output_depth;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, kernel_rows, /*dilation_rate=*/1, stride_rows, padding,\n      pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, kernel_cols, /*dilation_rate=*/1, stride_cols, padding,\n      pad_cols_before, pad_cols_after, &output_cols));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_depth_dim, kernel_depth, /*dilation_rate=*/1, stride_depth, padding,\n      /*pad_before*/ 0, /*pad_after*/ 0, &output_depth));\n\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols},\n                                         output_depth, &output_shape, c));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPoolShape(shape_inference::InferenceContext* c) {\n  return MaxPoolShapeImpl(c, /*supports_explicit_padding=*/false);\n}\n\nStatus MaxPoolGradShape(shape_inference::InferenceContext* c) {\n  return UnchangedShapeWithRank(c, 4);\n}\n\nStatus MaxPoolShapeWithExplicitPadding(shape_inference::InferenceContext* c) {\n  return MaxPoolShapeImpl(c, /*supports_explicit_padding=*/true);\n}\n\nStatus MaxPoolV2Shape(shape_inference::InferenceContext* c, int num_inputs) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> kernel_sizes;\n  std::vector<int32> strides;\n\n  if (c->num_inputs() + 2 == num_inputs) {\n    TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n\n    TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  } else {\n    // Verify shape of ksize and strides input.\n    ShapeHandle size;\n    DimensionHandle unused;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(c->num_inputs() - 2), 1, &size));\n    TF_RETURN_IF_ERROR(c->WithValue(c->Dim(size, 0), 4, &unused));\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(c->num_inputs() - 1), 1, &size));\n    TF_RETURN_IF_ERROR(c->WithValue(c->Dim(size, 0), 4, &unused));\n\n    const Tensor* kernel_sizes_tensor = c->input_tensor(c->num_inputs() - 2);\n    if (kernel_sizes_tensor == nullptr) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n    kernel_sizes.resize(kernel_sizes_tensor->shape().num_elements());\n    auto kernel_sizes_vec = kernel_sizes_tensor->flat<int32>();\n    std::copy_n(&kernel_sizes_vec(0), kernel_sizes.size(),\n                kernel_sizes.begin());\n\n    const Tensor* strides_tensor = c->input_tensor(c->num_inputs() - 1);\n    if (strides_tensor == nullptr) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n    strides.resize(strides_tensor->shape().num_elements());\n    auto strides_vec = strides_tensor->flat<int32>();\n    std::copy_n(&strides_vec(0), strides.size(), strides.begin());\n  }\n\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the stride attribute to contain 4 values, but \"\n        \"got: \",\n        strides.size());\n  }\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_depth = GetTensorDim(strides, data_format, 'C');\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_depth = GetTensorDim(kernel_sizes, data_format, 'C');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle in_depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  ShapeHandle output_shape;\n  DimensionHandle output_rows, output_cols, output_depth;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_depth_dim, kernel_depth, stride_depth, padding, &output_depth));\n\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols},\n                                         output_depth, &output_shape, c));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus Pool3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Pool3D ops require the stride attribute to contain 5 values, but \"\n        \"got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 5) {\n    return errors::InvalidArgument(\n        \"Pool3D requires the ksize attribute to contain 5 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t kernel_planes, kernel_rows, kernel_cols;\n\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    kernel_planes = kernel_sizes[2];\n    kernel_rows = kernel_sizes[3];\n    kernel_cols = kernel_sizes[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    kernel_planes = kernel_sizes[1];\n    kernel_rows = kernel_sizes[2];\n    kernel_cols = kernel_sizes[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(input_shape, 4);\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n  DimensionHandle output_planes, output_rows, output_cols;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_planes_dim, kernel_planes, stride_planes, padding, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPool3DGradShape(shape_inference::InferenceContext* c) {\n  return UnchangedShapeWithRank(c, 5);\n}\n\nStatus AvgPool3DGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &s));\n  TF_RETURN_IF_ERROR(c->WithRank(s, 5, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus UnknownShape(shape_inference::InferenceContext* c) {\n  for (int i = 0; i < c->num_outputs(); ++i) {\n    c->set_output(i, c->UnknownShape());\n  }\n  return Status::OK();\n}\n\ntemplate <typename T>\nStatus ReductionShapeHelper(const Tensor* reduction_indices_t,\n                            const int32_t input_rank,\n                            std::set<int64_t>* true_indices) {\n  auto reduction_indices = reduction_indices_t->flat<T>();\n  for (int i = 0; i < reduction_indices_t->NumElements(); ++i) {\n    const T reduction_index = reduction_indices(i);\n    if (reduction_index < -input_rank || reduction_index >= input_rank) {\n      return errors::InvalidArgument(\"Invalid reduction dimension \",\n                                     reduction_index, \" for input with \",\n                                     input_rank, \" dimensions.\");\n    }\n\n    auto wrapped_index = reduction_index;\n    if (wrapped_index < 0) {\n      wrapped_index += input_rank;\n    }\n\n    true_indices->insert(wrapped_index);\n  }\n  return Status::OK();\n}\n\nStatus ReductionShape(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n\n  ShapeHandle indices;\n  // Older versions of TensorFlow accidentally allowed higher rank tensors like\n  // [[1,2]] or [[1],[2]] to represent axis=[1,2].\n  if (c->graph_def_version() < 21) {\n    indices = c->input(1);\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &indices));\n  }\n\n  bool keep_dims;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* reduction_indices_t = c->input_tensor(1);\n  if (reduction_indices_t == nullptr || !c->RankKnown(input)) {\n    // If we do not have the reduction values at runtime, or the\n    // rank of the input, we don't know the output shape.\n\n    if (keep_dims && c->RankKnown(input)) {\n      // output rank matches input input if <keep_dims>.\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(input)));\n      return Status::OK();\n    } else {\n      return shape_inference::UnknownShape(c);\n    }\n  }\n\n  const int32_t input_rank = c->Rank(input);\n  std::set<int64_t> true_indices;\n  if (reduction_indices_t->dtype() == DataType::DT_INT32) {\n    TF_RETURN_IF_ERROR(ReductionShapeHelper<int32>(reduction_indices_t,\n                                                   input_rank, &true_indices));\n  } else if (reduction_indices_t->dtype() == DataType::DT_INT64) {\n    TF_RETURN_IF_ERROR(ReductionShapeHelper<int64_t>(\n        reduction_indices_t, input_rank, &true_indices));\n  } else {\n    return errors::InvalidArgument(\n        \"reduction_indices can only be int32 or int64\");\n  }\n\n  std::vector<DimensionHandle> dims;\n  for (int i = 0; i < input_rank; ++i) {\n    if (true_indices.count(i) > 0) {\n      if (keep_dims) {\n        dims.emplace_back(c->MakeDim(1));\n      }\n    } else {\n      dims.emplace_back(c->Dim(input, i));\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    // Return an unknown shape with same rank as inputs, or an unknown rank\n    // if no input's rank is known.\n\n    // Find rank.\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        // Check that all the inputs are of the correct rank.\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    // Build result of <rank> different unknown dims.\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n\n  // Merge all the non-concat dims, and sum the concat dim to make an output\n  // shape.\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n\n  // Minimum required number of dimensions.\n  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  // no dimensions.\n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus ConcatShape(InferenceContext* c, int num_inputs_to_concat) {\n  return ConcatShapeHelper(c, 1 /* start_value_index */,\n                           1 + num_inputs_to_concat /* end_value_index */,\n                           0 /* dim_index */);\n}\n\nStatus ConcatV2Shape(InferenceContext* c) {\n  return ConcatShapeHelper(c, 0 /* start_value_index */,\n                           c->num_inputs() - 1 /* end_value_index */,\n                           c->num_inputs() - 1 /* dim_index */);\n}\n\nStatus QuantizedConcatV2Shape(InferenceContext* c, int num_inputs_to_concat) {\n  return ConcatShapeHelper(c, 0 /* start_value_index */,\n                           num_inputs_to_concat /* end_value_index */,\n                           num_inputs_to_concat /* dim_index */);\n}\n\nStatus BroadcastBinaryOpOutputShapeFnHelper(InferenceContext* c,\n                                            ShapeHandle shape_x,\n                                            ShapeHandle shape_y,\n                                            bool incompatible_shape_error,\n                                            ShapeHandle* out) {\n  CHECK_NOTNULL(out);\n  if (!c->RankKnown(shape_x) || !c->RankKnown(shape_y)) {\n    *out = c->UnknownShape();\n    return Status::OK();\n  }\n  const int32_t rank_x = c->Rank(shape_x);\n  const int32_t rank_y = c->Rank(shape_y);\n  const int32_t rank_out = std::max(rank_x, rank_y);\n\n  // To compute the broadcast dimensions, we zip together shape_x and shape_y\n  // and\n  // pad with 1 to make them the same length.\n  std::vector<DimensionHandle> dims;\n  DimensionHandle dim_one;\n  if (rank_x != rank_y) dim_one = c->MakeDim(1);\n  for (int i = 0; i < rank_out; ++i) {\n    const auto dim_x = i < (rank_out - rank_x)\n                           ? dim_one\n                           : c->Dim(shape_x, i - (rank_out - rank_x));\n    const bool dim_y_is_one = (i < (rank_out - rank_y));\n    const auto dim_y =\n        dim_y_is_one ? dim_one : c->Dim(shape_y, i - (rank_out - rank_y));\n    if (!c->ValueKnown(dim_x) || !c->ValueKnown(dim_y)) {\n      // One or both dimensions is unknown.\n      //\n      // - If either dimension is greater than 1, we assume that the program is\n      // correct, and the other dimension will be broadcast to match it.\n      // TODO(cwhipkey): For shape inference, if we eliminate the shape checks\n      // in C++ op code, we must still assert that the unknown dim is either 1\n      // or the same as the known dim.\n      // - If either dimension is 1, the other dimension is the output.\n      // - If both are unknown then dimension is unknown\n      if (c->Value(dim_x) > 1) {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(dim_x);\n      } else if (c->Value(dim_y) > 1) {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(dim_y);\n      } else if (c->Value(dim_x) == 1) {\n        dims.push_back(dim_y);\n      } else if (c->Value(dim_y) == 1) {\n        dims.push_back(dim_x);\n      } else if (dim_y.SameHandle(dim_x)) {\n        dims.push_back(dim_x);\n      } else if (!c->ValueKnown(dim_x) && !c->ValueKnown(dim_y)) {\n        dims.push_back(c->UnknownDim());\n      } else {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(c->UnknownDim());\n      }\n    } else if (c->Value(dim_x) == 1 || c->Value(dim_y) == 1) {\n      if (c->Value(dim_x) == 1 && !dim_y_is_one) {\n        // We will broadcast dim_x to dim_y.\n        dims.push_back(dim_y);\n      } else {\n        DCHECK_EQ(c->Value(dim_y), 1);\n        // We will broadcast dim_y to dim_x.\n        dims.push_back(dim_x);\n      }\n    } else {\n      DimensionHandle dim;\n      Status s = c->Merge(dim_x, dim_y, &dim);\n      if (!s.ok()) {\n        if (!incompatible_shape_error) {\n          *out = c->MakeShape({});\n          return Status::OK();\n        }\n        return s;\n      }\n      dims.push_back(dim);\n    }\n  }\n\n  *out = c->MakeShape(dims);\n  return Status::OK();\n}\n\nStatus RandomShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nStatus UnsortedSegmentReductionShapeFn(InferenceContext* c) {\n  ShapeHandle s_data = c->input(0);\n  ShapeHandle s_segment_ids = c->input(1);\n  ShapeHandle s_num_segments = c->input(2);\n  TF_RETURN_IF_ERROR(c->WithRank(s_num_segments, 0, &s_num_segments));\n\n  ShapeHandle out;\n\n  // Leading dimensions of data must be compatible with dimensions of\n  // <s_segment_ids>.\n  if (c->RankKnown(s_segment_ids)) {\n    TF_RETURN_IF_ERROR(\n        c->MergePrefix(s_data, s_segment_ids, &s_data, &s_segment_ids));\n\n    // Get the value of the num_segments input tensor.\n    DimensionHandle num_segments_dim;\n    TF_RETURN_IF_ERROR(c->MakeDimForScalarInput(2, &num_segments_dim));\n\n    // Output is {segment_id_rank} + s_data[segment_id_rank:].\n    ShapeHandle s_data_suffix;\n    TF_RETURN_IF_ERROR(\n        c->Subshape(s_data, c->Rank(s_segment_ids), &s_data_suffix));\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(c->Vector(num_segments_dim), s_data_suffix, &out));\n  } else {\n    out = c->UnknownShape();\n  }\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nnamespace {\n\n// This SliceHelper processes the output shape of the `slice`\n// when the tensor of `sizes` is available.\ntemplate <typename T>\nStatus SliceHelper(InferenceContext* c, ShapeHandle begin_value,\n                   const Tensor* sizes_value,\n                   std::vector<DimensionHandle>* dims) {\n  auto sizes_vec = sizes_value->vec<T>();\n  for (int i = 0; i < sizes_value->NumElements(); ++i) {\n    DimensionHandle dim = c->Dim(c->input(0), i);\n    if (sizes_vec(i) != -1) {\n      auto dim_val = c->Value(dim);\n      if (sizes_vec(i) < 0) {\n        return errors::InvalidArgument(\n            \"Out of bounds slicing on dimension \", i, \" of length \", dim_val,\n            \": sizes vector cannot be < -1, but was \", sizes_vec(i));\n      }\n\n      dims->emplace_back(c->MakeDim(sizes_vec(i)));\n    } else {\n      DimensionHandle result;\n      TF_RETURN_IF_ERROR(c->Subtract(dim, c->Dim(begin_value, i), &result));\n      dims->emplace_back(result);\n    }\n  }\n\n  return Status::OK();\n}\n}  // namespace\n\nStatus SliceShape(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle begin_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &begin_shape));\n  ShapeHandle sizes_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &sizes_shape));\n\n  // Merge to check compatibility of begin and sizes tensors.\n  TF_RETURN_IF_ERROR(c->Merge(begin_shape, sizes_shape, &begin_shape));\n\n  DimensionHandle ndims = c->Dim(begin_shape, 0);\n  if (c->ValueKnown(ndims)) {\n    TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(ndims), &input));\n  }\n\n  // NOTE(mrry): Use MakeShapeFromShapeTensor to handle partially-known\n  // values, even though the `begin` value does not represent a shape.\n  ShapeHandle begin_value;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &begin_value));\n\n  // We check the tensor value here and will only use\n  // `MakeShapeFromShapeTensor` when `sizes_value` is null.\n  // The reason is that `sizes` might contain -1, which can't\n  // be represented (-1 in the ShapeHandle would mean \"unknown\").\n  const Tensor* sizes_value = c->input_tensor(2);\n\n  if (sizes_value != nullptr) {\n    TF_RETURN_IF_ERROR(\n        c->WithRank(begin_value, sizes_value->NumElements(), &begin_value));\n    std::vector<DimensionHandle> dims;\n    // If the begin and sizes tensors are available, then\n    // we can be precise about the shape of the output.\n    if (sizes_value->dtype() == DT_INT64) {\n      TF_RETURN_IF_ERROR(\n          SliceHelper<int64_t>(c, begin_value, sizes_value, &dims));\n    } else {\n      TF_RETURN_IF_ERROR(\n          SliceHelper<int32>(c, begin_value, sizes_value, &dims));\n    }\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  } else {\n    // In case `sizes` is not available (`sizes_value` is null),\n    // we could try to use `MakeShapeFromShapeTensor` here.\n    // If sizes contain -1, we will simply consider it as `Unknown`.\n    // This is less than ideal but still an improvement of shape inference.\n    // The following is an example that returns [None, 1, None] with this\n    // code path:\n    //   z = tf.zeros((1, 2, 3))\n    //   m = tf.slice(z, [0, 0, 0], [tf.constant(1) + 0, 1, -1])\n    //   m.get_shape().as_list()\n    ShapeHandle sizes_value;\n    TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &sizes_value));\n    if (c->RankKnown(sizes_value)) {\n      TF_RETURN_IF_ERROR(\n          c->WithRank(begin_value, c->Rank(sizes_value), &begin_value));\n      std::vector<DimensionHandle> dims;\n      dims.reserve(c->Rank(sizes_value));\n      for (int i = 0; i < c->Rank(sizes_value); ++i) {\n        dims.emplace_back(c->Dim(sizes_value, i));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    }\n    // We might know the rank of the input.\n    if (c->RankKnown(input)) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(input)));\n      return Status::OK();\n    } else {\n      return shape_inference::UnknownShape(c);\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus ValidateSparseTensor(InferenceContext* c, ShapeHandle indices_shape,\n                            ShapeHandle values_shape, ShapeHandle shape_shape) {\n  // Validate ranks.\n  ShapeHandle unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(indices_shape, 2, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(values_shape, 1, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(shape_shape, 1, &unused_shape));\n\n  // Number of elements in indices and values must match.\n  DimensionHandle num_index_elements_dim = c->Dim(indices_shape, 0);\n  if (c->ValueKnown(num_index_elements_dim)) {\n    DimensionHandle num_values_elements_dim = c->Dim(values_shape, 0);\n    if (c->ValueKnown(num_values_elements_dim)) {\n      int64_t num_index_elements = c->Value(num_index_elements_dim);\n      int64_t num_values_elements = c->Value(num_values_elements_dim);\n      if (num_index_elements != num_values_elements) {\n        return errors::InvalidArgument(\"Number of elements in index (\",\n                                       num_index_elements, \") and values (\",\n                                       num_values_elements, \") do not match.\");\n      }\n    }\n  }\n\n  // Rank embedded in indices must match shape.\n  DimensionHandle index_rank_dim = c->Dim(indices_shape, 1);\n  if (c->ValueKnown(index_rank_dim)) {\n    DimensionHandle shape_rank_dim = c->Dim(shape_shape, 0);\n    if (c->ValueKnown(shape_rank_dim)) {\n      int64_t index_rank = c->Value(index_rank_dim);\n      int32_t shape_rank = c->Value(shape_rank_dim);\n      if (index_rank != shape_rank) {\n        return errors::InvalidArgument(\"Index rank (\", index_rank,\n                                       \") and shape rank (\", shape_rank,\n                                       \") do not match.\");\n      }\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus ValidateVariableResourceHandle(\n    InferenceContext* c, std::vector<ShapeAndType>* shape_and_type) {\n  auto* handle_data = c->input_handle_shapes_and_types(0);\n  if (handle_data == nullptr || handle_data->empty()) {\n    shape_and_type->emplace_back(c->UnknownShape(), DT_INVALID);\n  } else {\n    *shape_and_type = *handle_data;\n    DataType value_dtype;\n    TF_RETURN_IF_ERROR(c->GetAttr(\"dtype\", &value_dtype));\n    if (shape_and_type->at(0).dtype != value_dtype) {\n      return errors::InvalidArgument(\n          \"Trying to read variable with wrong dtype. \"\n          \"Expected \",\n          DataTypeString(shape_and_type->at(0).dtype), \" got \",\n          DataTypeString(value_dtype));\n    }\n  }\n  return Status::OK();\n}\n\nStatus GatherNdShape(InferenceContext* c) {\n  ShapeHandle params;\n  std::vector<ShapeAndType> handle_shape_and_type;\n  if (c->input_handle_shapes_and_types(0) != nullptr) {\n    TF_RETURN_IF_ERROR(\n        ValidateVariableResourceHandle(c, &handle_shape_and_type));\n    params = handle_shape_and_type[0].shape;\n  } else {\n    params = c->input(0);\n  }\n  ShapeHandle indices;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &indices));\n  DimensionHandle r_dim = c->Dim(indices, -1);\n\n  if (!c->RankKnown(params) || !c->ValueKnown(r_dim)) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  if (c->Value(r_dim) > c->Rank(params)) {\n    return errors::InvalidArgument(\n        \"indices.shape[-1] must be <= params.rank, but saw indices shape: \",\n        c->DebugString(indices), \" and params shape: \", c->DebugString(params));\n  }\n\n  // Remove r_dim from indices to get output.\n  ShapeHandle indices_slice;\n  ShapeHandle params_slice;\n  TF_RETURN_IF_ERROR(c->Subshape(indices, 0, -1, &indices_slice));\n  TF_RETURN_IF_ERROR(c->Subshape(params, c->Value(r_dim), &params_slice));\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->Concatenate(indices_slice, params_slice, &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nStatus ScatterNdShapeHelper(InferenceContext* c, ShapeHandle indices_shape,\n                            ShapeHandle updates_shape,\n                            ShapeHandle input_shape) {\n  if (c->Value(c->NumElements(input_shape)) == 0 &&\n      (c->Value(c->NumElements(indices_shape)) > 0 ||\n       c->Value(c->NumElements(updates_shape)) > 0)) {\n    return errors::InvalidArgument(\n        \"Indices and updates specified for empty input\");\n  }\n\n  if (c->RankKnown(indices_shape) && c->RankKnown(updates_shape)) {\n    const int64_t outer_dims = c->Rank(indices_shape) - 1;\n    const DimensionHandle ixdim = c->Dim(indices_shape, -1);\n\n    // We can only do more validation if the last dimension of indices\n    // is a known value.\n    if (c->ValueKnown(ixdim)) {\n      int64_t ix = c->Value(ixdim);\n      ShapeHandle unused;\n      ShapeHandle prefix_indices;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(indices_shape, 0, outer_dims, &prefix_indices));\n      ShapeHandle prefix_updates;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(updates_shape, 0, outer_dims, &prefix_updates));\n\n      Status s = c->Merge(prefix_indices, prefix_updates, &unused);\n      if (!s.ok()) {\n        return errors::InvalidArgument(\n            \"Dimensions [0,\", outer_dims,\n            \") of indices[shape=\", c->DebugString(indices_shape),\n            \"] = \", c->DebugString(prefix_indices),\n            \" must match dimensions [0,\", outer_dims,\n            \") of updates[shape=\", c->DebugString(updates_shape),\n            \"] = \", c->DebugString(prefix_updates), \": \", s.error_message());\n      }\n\n      ShapeHandle suffix_output;\n      TF_RETURN_IF_ERROR(c->Subshape(input_shape, ix, &suffix_output));\n      ShapeHandle suffix_updates;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(updates_shape, outer_dims, &suffix_updates));\n      s = c->Merge(suffix_output, suffix_updates, &unused);\n      if (!s.ok()) {\n        return errors::InvalidArgument(\n            \"Dimensions [\", ix, \",\", c->Rank(input_shape),\n            \") of input[shape=\", c->DebugString(input_shape),\n            \"] = \", c->DebugString(suffix_output), \" must match dimensions [\",\n            outer_dims, \",\", c->Rank(updates_shape),\n            \") of updates[shape=\", c->DebugString(updates_shape),\n            \"] = \", c->DebugString(suffix_updates), \": \", s.error_message());\n      }\n    }\n  }\n\n  if (c->input_handle_shapes_and_types(0) == nullptr && c->num_outputs() > 0) {\n    // This is called for tf.scatter_nd; output is a tensor with this shape.\n    c->set_output(0, input_shape);\n  }\n  return Status::OK();\n}\n\nStatus ExplicitShape(InferenceContext* c) {\n  PartialTensorShape shape;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus ExplicitShapes(InferenceContext* c) {\n  std::vector<PartialTensorShape> shapes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"shapes\", &shapes));\n  if (shapes.empty()) {\n    return errors::Internal(\"shapes attribute is empty\");\n  }\n  for (int i = 0, end = shapes.size(); i < end; ++i) {\n    ShapeHandle output_shape;\n    TF_RETURN_IF_ERROR(\n        c->MakeShapeFromPartialTensorShape(shapes[i], &output_shape));\n    c->set_output(i, output_shape);\n  }\n  return Status::OK();\n}\n\nStatus SparseReduceShapeFn(InferenceContext* c) {\n  // Input 0: input_indices\n  // Input 1: input_values\n  // Input 2: input_shape\n  // Input 3: reduction_axes\n  // Attr: keep_dims\n  bool keep_dims = false;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* shape_tensor = c->input_tensor(2);\n  const Tensor* axes_tensor = c->input_tensor(3);\n  if (shape_tensor != nullptr && axes_tensor != nullptr) {\n    auto shape_vec = shape_tensor->flat<int64_t>();\n    auto axes_vec = axes_tensor->flat<int32>();\n\n    int64_t ndims = shape_vec.size();\n    absl::flat_hash_set<int64_t> axes;\n    if (ndims == 0)\n      return errors::InvalidArgument(\n          \"Number of dims in shape tensor must not be 0\");\n    for (int i = 0; i < axes_vec.size(); i++) {\n      axes.insert((axes_vec(i) + ndims) % ndims);\n    }\n\n    std::vector<DimensionHandle> dims;\n    if (keep_dims) {\n      dims.reserve(ndims);\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        } else {\n          dims.push_back(c->MakeDim(1));\n        }\n      }\n    } else {\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        }\n      }\n    }\n\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  return UnknownShape(c);\n}\n\nStatus QuantizedConv2DShape(InferenceContext* c) {\n  TF_RETURN_IF_ERROR(shape_inference::Conv2DShape(c));\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(5), 0, &unused));\n  c->set_output(1, c->Scalar());\n  c->set_output(2, c->Scalar());\n  return Status::OK();\n}\n\nStatus QuantizedAvgPoolShape(InferenceContext* c) {\n  TF_RETURN_IF_ERROR(shape_inference::AvgPoolShape(c));\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n  c->set_output(1, c->Scalar());\n  c->set_output(2, c->Scalar());\n  return Status::OK();\n}\n\nStatus QuantizeV2Shape(InferenceContext* c) {\n  int axis = -1;\n  Status s = c->GetAttr(\"axis\", &axis);\n  if (!s.ok() && s.code() != error::NOT_FOUND) {\n    return s;\n  }\n  const int minmax_rank = (axis == -1) ? 0 : 1;\n  TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n  ShapeHandle minmax;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n  if (axis != -1) {\n    ShapeHandle input;\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n    DimensionHandle depth;\n    TF_RETURN_IF_ERROR(\n        c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n  }\n  c->set_output(1, minmax);\n  c->set_output(2, minmax);\n  return Status::OK();\n}\n\nStatus ReduceScatterShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle in = c->input(0);\n  if (!c->RankKnown(in)) {\n    // Input shape unknown, so set unknown output shape.\n    c->set_output(0, in);\n    return Status::OK();\n  }\n\n  shape_inference::ShapeHandle group_assignment_shape = c->input(1);\n  if (c->Rank(group_assignment_shape) != 2)\n    return errors::InvalidArgument(\n        \"ReduceScatter group_assignment should be rank 2\");\n\n  const Tensor* scatter_dimension = c->input_tensor(2);\n  if (!scatter_dimension) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int64_t scatter_dim;\n  TF_RETURN_IF_ERROR(c->GetScalarFromTensor(scatter_dimension, &scatter_dim));\n\n  std::vector<shape_inference::DimensionHandle> out_dims;\n  out_dims.reserve(c->Rank(in));\n  for (int i = 0; i < c->Rank(in); ++i) {\n    // If the dimension is the scatter_dimension, then divide the dimension\n    // by the partition size in the group_assignment.\n    if (i == scatter_dim) {\n      shape_inference::DimensionHandle dim = c->Dim(in, i);\n      shape_inference::DimensionHandle out_dim;\n      TF_RETURN_IF_ERROR(c->Divide(dim, c->Dim(group_assignment_shape, 1),\n                                   /*evenly_divisible=*/true, &out_dim));\n      out_dims.push_back(out_dim);\n    } else {\n      out_dims.emplace_back(c->Dim(in, i));\n    }\n  }\n  c->set_output(0, c->MakeShape(out_dims));\n  return Status::OK();\n}\n\n}  // namespace shape_inference\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"absl/container/flat_hash_set.h\"\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_split.h\"\n#include \"absl/strings/string_view.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/util/einsum_op_util.h\"\n\nnamespace tensorflow {\n\nnamespace shape_inference {\n\n// The V2 version computes windowed output size with arbitrary dilation_rate and\n// explicit padding, while the original version only handles the cases where\n// dilation_rates equal to 1 and the padding is SAME or VALID.\nStatus GetWindowedOutputSizeFromDimsV2(\n    shape_inference::InferenceContext* c,\n    shape_inference::DimensionHandle input_size,\n    shape_inference::DimensionOrConstant filter_size, int64_t dilation_rate,\n    int64_t stride, Padding padding_type, int64_t padding_before,\n    int64_t padding_after, shape_inference::DimensionHandle* output_size) {\n  if (stride <= 0) {\n    return errors::InvalidArgument(\"Stride must be > 0, but got \", stride);\n  }\n\n  if (dilation_rate < 1) {\n    return errors::InvalidArgument(\"Dilation rate must be >= 1, but got \",\n                                   dilation_rate);\n  }\n\n  // See also the parallel implementation in GetWindowedOutputSizeVerbose.\n  switch (padding_type) {\n    case Padding::VALID:\n      padding_before = padding_after = 0;\n      TF_FALLTHROUGH_INTENDED;\n    case Padding::EXPLICIT:\n      TF_RETURN_IF_ERROR(\n          c->Add(input_size, padding_before + padding_after, &input_size));\n      if (dilation_rate > 1) {\n        DimensionHandle window_size;\n        TF_RETURN_IF_ERROR(\n            c->Subtract(c->MakeDim(filter_size), 1, &window_size));\n        TF_RETURN_IF_ERROR(\n            c->Multiply(window_size, dilation_rate, &window_size));\n        TF_RETURN_IF_ERROR(c->Add(window_size, 1, &window_size));\n        TF_RETURN_IF_ERROR(c->Subtract(input_size, window_size, output_size));\n      } else {\n        TF_RETURN_IF_ERROR(c->Subtract(input_size, filter_size, output_size));\n      }\n      TF_RETURN_IF_ERROR(c->Add(*output_size, stride, output_size));\n      TF_RETURN_IF_ERROR(c->Divide(*output_size, stride,\n                                   /*evenly_divisible=*/false, output_size));\n      break;\n    case Padding::SAME:\n      TF_RETURN_IF_ERROR(c->Add(input_size, stride - 1, output_size));\n      TF_RETURN_IF_ERROR(c->Divide(*output_size, stride,\n                                   /*evenly_divisible=*/false, output_size));\n      break;\n  }\n  return Status::OK();\n}\n\nStatus GetWindowedOutputSizeFromDims(\n    shape_inference::InferenceContext* c,\n    shape_inference::DimensionHandle input_size,\n    shape_inference::DimensionOrConstant filter_size, int64_t stride,\n    Padding padding_type, shape_inference::DimensionHandle* output_size) {\n  if (padding_type == Padding::EXPLICIT) {\n    return errors::Internal(\n        \"GetWindowedOutputSizeFromDims does not handle EXPLICIT padding; call \"\n        \"GetWindowedOutputSizeFromDimsV2 instead\");\n  }\n  return GetWindowedOutputSizeFromDimsV2(c, input_size, filter_size,\n                                         /*dilation_rate=*/1, stride,\n                                         padding_type,\n                                         // Give dummy values of -1 to\n                                         // padding_before and padding_after,\n                                         // since explicit padding is not used.\n                                         -1, -1, output_size);\n}\n\nStatus UnchangedShape(shape_inference::InferenceContext* c) {\n  c->set_output(0, c->input(0));\n  auto* handle_data = c->input_handle_shapes_and_types(0);\n  if (handle_data != nullptr) {\n    c->set_output_handle_shapes_and_types(0, *handle_data);\n  }\n  return Status::OK();\n}\n\nStatus MatMulShape(shape_inference::InferenceContext* c) {\n  ShapeHandle a;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &a));\n\n  ShapeHandle b;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &b));\n\n  bool transpose_a, transpose_b;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"transpose_a\", &transpose_a));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"transpose_b\", &transpose_b));\n  DimensionHandle output_rows = transpose_a ? c->Dim(a, 1) : c->Dim(a, 0);\n  DimensionHandle output_cols = transpose_b ? c->Dim(b, 0) : c->Dim(b, 1);\n\n  // Validate that the inner shapes are compatible.\n  DimensionHandle inner_a = transpose_a ? c->Dim(a, 0) : c->Dim(a, 1);\n  DimensionHandle inner_b = transpose_b ? c->Dim(b, 1) : c->Dim(b, 0);\n  DimensionHandle merged;\n  TF_RETURN_IF_ERROR(c->Merge(inner_a, inner_b, &merged));\n\n  c->set_output(0, c->Matrix(output_rows, output_cols));\n  return Status::OK();\n}\n\nnamespace {\n\n// Validate that an Einsum subscript contains exactly one or zero ellipsis; and\n// that periods (.) occur only within an ellipses (...).\nStatus ValidateEinsumEllipsis(absl::string_view subscript,\n                              bool* found_ellipsis) {\n  const int num_periods = absl::c_count(subscript, '.');\n  if (num_periods != 0 && num_periods != 3) {\n    return errors::InvalidArgument(\n        \"Expected at most one ellipsis (...), but found \", num_periods,\n        \" periods (.) in the input subscript: \", subscript);\n  }\n  if (num_periods == 3 && !absl::StrContains(subscript, \"...\")) {\n    return errors::InvalidArgument(\n        \"Periods found outside of ellipsis in subscript: \", subscript);\n  }\n  *found_ellipsis = num_periods > 0;\n  return Status::OK();\n}\n\n}  // namespace\n\nStatus EinsumShape(shape_inference::InferenceContext* c) {\n  // We assume that the equation has a valid format. Either (x),(y)->(z)\n  // or (x)->(z), where each of (x), (y) and (z) are concatenation of zero or\n  // more latin alphabets and contains at most one ellipsis ('...').\n  string equation;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"equation\", &equation));\n  gtl::InlinedVector<string, 2> input_labels;\n  string output_labels;\n  TF_RETURN_IF_ERROR(\n      ParseEinsumEquation(equation, &input_labels, &output_labels));\n\n  if (c->num_inputs() == 0 || c->num_inputs() > 2) {\n    return errors::InvalidArgument(\"Expected either 1 or 2 inputs but got: \",\n                                   c->num_inputs());\n  }\n  const int input_labels_size = input_labels.size();\n  if (c->num_inputs() != input_labels_size) {\n    return errors::InvalidArgument(\"Expected \", input_labels.size(),\n                                   \" inputs for equation \", equation,\n                                   \" but got: \", c->num_inputs());\n  }\n\n  // Validate input subscripts, build the label to dimension mapping and obtain\n  // the broadcast shapes that map to ellipsis.\n  absl::flat_hash_map<char, DimensionHandle> label_to_dimension;\n  gtl::InlinedVector<ShapeHandle, 2> input_bcast_shapes(c->num_inputs());\n  for (int i = 0, end = c->num_inputs(); i < end; ++i) {\n    bool has_ellipsis = false;\n    TF_RETURN_IF_ERROR(ValidateEinsumEllipsis(input_labels[i], &has_ellipsis));\n    ShapeHandle input_shape = c->input(i);\n    // Validate that the input rank is sufficient for the given number of named\n    // labels.\n    if (c->RankKnown(input_shape)) {\n      if (has_ellipsis) {\n        const int num_named_labels =\n            static_cast<int>(input_labels[i].size()) - 3;\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->WithRankAtLeast(input_shape, num_named_labels, &input_shape),\n            \" for \", i, \"th input and equation: \", equation);\n      } else {\n        const int num_named_labels = static_cast<int>(input_labels[i].size());\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->WithRank(input_shape, num_named_labels, &input_shape), \" for \",\n            i, \"th input and equation: \", equation);\n      }\n    }\n\n    bool seen_ellipsis = false;\n    input_bcast_shapes[i] = c->Scalar();\n    // Run through the input labels; populate label_to_dimension mapping and\n    // compute the broadcast shapes corresponding to the ellipsis (if present).\n    for (int label_idx = 0, end = input_labels[i].size(); label_idx < end;\n         ++label_idx) {\n      const char label = input_labels[i][label_idx];\n      // Calculate the input axis that the current label is referring to. After\n      // the ellipsis, the axis may be found by using negative indices; i.e the\n      // (rank - k)th dimension corresponds to the (num_labels - k)th label.\n      const int64_t axis_before_ellipsis = label_idx;\n      const int64_t axis_after_ellipsis =\n          c->RankKnown(input_shape)\n              ? label_idx + c->Rank(input_shape) - input_labels[i].size()\n              : -1;\n\n      // Populate the input broadcast shape when we encounter an ellipsis (...).\n      if (label == '.') {\n        if (!c->RankKnown(input_shape)) {\n          input_bcast_shapes[i] = c->UnknownShape();\n        } else {\n          // The broadcast shape runs till the named label right after the\n          // ellipsis, the label with index (label_idx + 3).\n          TF_RETURN_IF_ERROR(c->Subshape(input_shape, axis_before_ellipsis,\n                                         axis_after_ellipsis + 3,\n                                         &input_bcast_shapes[i]));\n        }\n        label_idx += 2;  // Skip the rest of the ellipsis.\n        seen_ellipsis = true;\n        continue;\n      }\n      // Obtain the dimension that the current label corresponds to.\n      int64_t axis = seen_ellipsis ? axis_after_ellipsis : axis_before_ellipsis;\n      DimensionHandle new_dim = c->RankKnown(input_shape)\n                                    ? c->Dim(input_shape, axis)\n                                    : c->UnknownDim();\n      // If we've seen this label before, make sure previous and current\n      // dimensions are compatible.\n      if (label_to_dimension.contains(label)) {\n        DimensionHandle merged;\n        TF_RETURN_IF_ERROR(\n            c->Merge(label_to_dimension[label], new_dim, &merged));\n        label_to_dimension[label] = merged;\n      } else {\n        label_to_dimension[label] = new_dim;\n      }\n    }\n  }\n\n  // For two inputs, broadcast the two input broadcast shapes to create the\n  // output broadcast shape. For one input, just copy the single broadcast\n  // shape.\n  ShapeHandle output_bcast_shape;\n  if (input_bcast_shapes.size() == 1) {\n    output_bcast_shape = input_bcast_shapes[0];\n  } else if (input_bcast_shapes.size() == 2) {\n    TF_RETURN_IF_ERROR(BroadcastBinaryOpOutputShapeFnHelper(\n        c, input_bcast_shapes[0], input_bcast_shapes[1], true,\n        &output_bcast_shape));\n  }\n\n  bool output_has_ellipsis = false;\n  TF_RETURN_IF_ERROR(\n      ValidateEinsumEllipsis(output_labels, &output_has_ellipsis));\n  if (output_has_ellipsis) {\n    // If the output subscript has ellipsis and the output broadcast rank is\n    // unknown, then the output shape should have unknown rank.\n    if (!c->RankKnown(output_bcast_shape)) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n  } else {\n    // If the output subscripts don't have ellipsis then make sure the output\n    // broadcasting shape is empty.\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        c->WithRankAtMost(output_bcast_shape, 0, &output_bcast_shape),\n        \" for einsum equation '\", equation,\n        \"' without ellipsis (...) in the output subscripts where input(s) have \"\n        \"non-empty broadcasting shape\");\n    output_bcast_shape = c->Scalar();\n  }\n\n  // Create the output shape from output labels and label_to_dimension mapping.\n  std::vector<DimensionHandle> output_dims;\n  for (int label_idx = 0, end = output_labels.size(); label_idx < end;\n       ++label_idx) {\n    const char label = output_labels[label_idx];\n    // Append the output_bcast_shape when the ellipsis is encountered.\n    if (label == '.') {\n      for (int k = 0; k < c->Rank(output_bcast_shape); ++k) {\n        output_dims.push_back(c->Dim(output_bcast_shape, k));\n      }\n      label_idx += 2;  // Skip the rest of the ellipsis.\n      continue;\n    }\n    auto dimension_it = label_to_dimension.find(label);\n    if (dimension_it == label_to_dimension.end()) {\n      return errors::InvalidArgument(\n          \"Einsum output subscripts for equation '\", equation, \"' has label '\",\n          label, \"' which is not present in the input subscripts\");\n    }\n    output_dims.push_back(dimension_it->second);\n  }\n  c->set_output(0, c->MakeShape(output_dims));\n  return Status::OK();\n}\n\nStatus BatchMatMulV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle a_shape;\n  ShapeHandle b_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &a_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 2, &b_shape));\n\n  // Determine output rows and columns.\n  bool adj_x;\n  bool adj_y;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_x\", &adj_x));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_y\", &adj_y));\n  DimensionHandle output_rows = c->Dim(a_shape, adj_x ? -1 : -2);\n  DimensionHandle output_cols = c->Dim(b_shape, adj_y ? -2 : -1);\n\n  // Inner dimensions should be compatible.\n  DimensionHandle inner_merged;\n  TF_RETURN_IF_ERROR(c->Merge(c->Dim(a_shape, adj_x ? -2 : -1),\n                              c->Dim(b_shape, adj_y ? -1 : -2), &inner_merged));\n\n  // Batch dimensions should broadcast with each other.\n  ShapeHandle a_batch_shape;\n  ShapeHandle b_batch_shape;\n  ShapeHandle output_batch_shape;\n  TF_RETURN_IF_ERROR(c->Subshape(a_shape, 0, -2, &a_batch_shape));\n  TF_RETURN_IF_ERROR(c->Subshape(b_shape, 0, -2, &b_batch_shape));\n\n  TF_RETURN_IF_ERROR(BroadcastBinaryOpOutputShapeFnHelper(\n      c, a_batch_shape, b_batch_shape, true, &output_batch_shape));\n\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->Concatenate(\n      output_batch_shape, c->Matrix(output_rows, output_cols), &output_shape));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus BatchMatMulShape(shape_inference::InferenceContext* c) {\n  ShapeHandle a_shape;\n  ShapeHandle b_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &a_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 2, &b_shape));\n\n  // Determine output rows and cols.\n  bool adj_x;\n  bool adj_y;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_x\", &adj_x));\n  TF_RETURN_IF_ERROR(c->GetAttr(\"adj_y\", &adj_y));\n  DimensionHandle output_rows = c->Dim(a_shape, adj_x ? -1 : -2);\n  DimensionHandle output_cols = c->Dim(b_shape, adj_y ? -2 : -1);\n\n  // Batch dims match between inputs.\n  ShapeHandle a_batch_dims;\n  ShapeHandle b_batch_dims;\n  ShapeHandle batch_dims;\n  TF_RETURN_IF_ERROR(c->Subshape(a_shape, 0, -2, &a_batch_dims));\n  TF_RETURN_IF_ERROR(c->Subshape(b_shape, 0, -2, &b_batch_dims));\n  TF_RETURN_IF_ERROR(c->Merge(a_batch_dims, b_batch_dims, &batch_dims));\n\n  // Assert inner dims match.\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(c->Merge(c->Dim(a_shape, adj_x ? -2 : -1),\n                              c->Dim(b_shape, adj_y ? -1 : -2), &unused));\n\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(batch_dims, c->Matrix(output_rows, output_cols), &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\n// --------------------------------------------------------------------------\n\nStatus BiasAddShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  if (s.ok() && data_format == \"NCHW\") {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 3, &input_shape));\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  }\n\n  ShapeHandle bias_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &bias_shape));\n  DimensionHandle bias_dim = c->Dim(bias_shape, 0);\n\n  // If rank unknown, return unknown shape.\n  if (!c->RankKnown(input_shape)) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Output has the same shape as the input, and matches the length of\n  // the bias in its bias dimension.\n  ShapeHandle output_shape;\n  if (s.ok() && data_format == \"NCHW\") {\n    // Merge the length of bias_shape into the third to last dimension\n    ShapeHandle first;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 0, 1, &first));\n\n    ShapeHandle last;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 2, &last));\n\n    DimensionHandle input_bias_dim = c->Dim(input_shape, 1);\n    DimensionHandle merged_bias_dim;\n    TF_RETURN_IF_ERROR(c->Merge(input_bias_dim, bias_dim, &merged_bias_dim));\n    ShapeHandle merged_bias = c->Vector(merged_bias_dim);\n\n    ShapeHandle temp;\n    TF_RETURN_IF_ERROR(c->Concatenate(first, merged_bias, &temp));\n    TF_RETURN_IF_ERROR(c->Concatenate(temp, last, &output_shape));\n  } else {\n    ShapeHandle all_but_bias;\n    TF_RETURN_IF_ERROR(c->Subshape(input_shape, 0, -1, &all_but_bias));\n\n    DimensionHandle input_bias_dim = c->Dim(input_shape, -1);\n    DimensionHandle merged_bias_dim;\n    TF_RETURN_IF_ERROR(c->Merge(input_bias_dim, bias_dim, &merged_bias_dim));\n\n    ShapeHandle merged_bias = c->Vector(merged_bias_dim);\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(all_but_bias, merged_bias, &output_shape));\n  }\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus BiasAddGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  if (s.ok() && data_format == \"NCHW\") {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 3, &input_shape));\n    c->set_output(0, c->Vector(c->Dim(input_shape, 1)));\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n    c->set_output(0, c->Vector(c->Dim(input_shape, -1)));\n  }\n\n  return Status::OK();\n}\n\nStatus CheckFormatConstraintsOnShape(const TensorFormat tensor_format,\n                                     const ShapeHandle shape_handle,\n                                     const string& tensor_name,\n                                     shape_inference::InferenceContext* c) {\n  if (tensor_format == FORMAT_NCHW_VECT_C) {\n    // Check that the vect dim has size 4 or 32.\n    const int num_dims = c->Rank(shape_handle);\n    DimensionHandle vect_dim = c->Dim(\n        shape_handle, GetTensorInnerFeatureDimIndex(num_dims, tensor_format));\n    int64_t vect_dim_val = c->Value(vect_dim);\n    if (vect_dim_val != 4 && vect_dim_val != 32) {\n      return errors::InvalidArgument(\n          \"VECT_C dimension must be 4 or 32, but is \", vect_dim_val);\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus DatasetIteratorShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 0, &unused));\n  std::vector<PartialTensorShape> output_shapes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"output_shapes\", &output_shapes));\n  const int output_shapes_size = output_shapes.size();\n  if (output_shapes_size != c->num_outputs()) {\n    return errors::InvalidArgument(\n        \"`output_shapes` must be the same length as `output_types` (\",\n        output_shapes.size(), \" vs. \", c->num_outputs());\n  }\n  for (size_t i = 0; i < output_shapes.size(); ++i) {\n    shape_inference::ShapeHandle output_shape_handle;\n    TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(\n        output_shapes[i], &output_shape_handle));\n    c->set_output(static_cast<int>(i), output_shape_handle);\n  }\n  return Status::OK();\n}\n\nStatus MakeShapeFromFormat(TensorFormat format, DimensionOrConstant N,\n                           const std::vector<DimensionOrConstant>& spatial,\n                           DimensionOrConstant C, ShapeHandle* out,\n                           shape_inference::InferenceContext* context) {\n  const int num_dims = GetTensorDimsFromSpatialDims(spatial.size(), format);\n  std::vector<DimensionHandle> dims_actual(num_dims);\n  dims_actual[GetTensorBatchDimIndex(num_dims, format)] = context->MakeDim(N);\n  int outer_c_index = GetTensorFeatureDimIndex(num_dims, format);\n  dims_actual[outer_c_index] = context->MakeDim(C);\n  if (format == FORMAT_NCHW_VECT_C) {\n    dims_actual[GetTensorInnerFeatureDimIndex(num_dims, format)] =\n        context->MakeDim(4);\n  } else if (format == FORMAT_NHWC_VECT_W) {\n    dims_actual[GetTensorInnerWidthDimIndex(num_dims, format)] =\n        context->MakeDim(4);\n  }\n  for (int spatial_dim = 0, end = spatial.size(); spatial_dim < end;\n       spatial_dim++) {\n    dims_actual[GetTensorSpatialDimIndex(num_dims, format, spatial_dim)] =\n        context->MakeDim(spatial[spatial_dim]);\n  }\n  *out = context->MakeShape(dims_actual);\n  return Status::OK();\n}\n\nStatus DimensionsFromShape(ShapeHandle shape, TensorFormat format,\n                           DimensionHandle* batch_dim,\n                           gtl::MutableArraySlice<DimensionHandle> spatial_dims,\n                           DimensionHandle* filter_dim,\n                           InferenceContext* context) {\n  const int32_t rank =\n      GetTensorDimsFromSpatialDims(spatial_dims.size(), format);\n  // Batch.\n  *batch_dim = context->Dim(shape, GetTensorBatchDimIndex(rank, format));\n  // Spatial.\n  for (int spatial_dim_index = 0, end = spatial_dims.size();\n       spatial_dim_index < end; ++spatial_dim_index) {\n    spatial_dims[spatial_dim_index] = context->Dim(\n        shape, GetTensorSpatialDimIndex(rank, format, spatial_dim_index));\n  }\n  // Channel.\n  *filter_dim = context->Dim(shape, GetTensorFeatureDimIndex(rank, format));\n  if (format == FORMAT_NCHW_VECT_C) {\n    TF_RETURN_IF_ERROR(context->Multiply(\n        *filter_dim,\n        context->Dim(shape, GetTensorInnerFeatureDimIndex(rank, format)),\n        filter_dim));\n  }\n  return Status::OK();\n}\n\n// vect_size must be provided if format is NCHW_VECT_C.\nStatus ShapeFromDimensions(DimensionHandle batch_dim,\n                           gtl::ArraySlice<DimensionHandle> spatial_dims,\n                           DimensionHandle filter_dim, TensorFormat format,\n                           absl::optional<DimensionHandle> vect_size,\n                           InferenceContext* context, ShapeHandle* shape) {\n  const int32_t rank =\n      GetTensorDimsFromSpatialDims(spatial_dims.size(), format);\n  std::vector<DimensionHandle> out_dims(rank);\n\n  // Batch.\n  out_dims[tensorflow::GetTensorBatchDimIndex(rank, format)] = batch_dim;\n  // Spatial.\n  for (int spatial_dim_index = 0, end = spatial_dims.size();\n       spatial_dim_index < end; ++spatial_dim_index) {\n    out_dims[tensorflow::GetTensorSpatialDimIndex(\n        rank, format, spatial_dim_index)] = spatial_dims[spatial_dim_index];\n  }\n  // Channel.\n  if (format == tensorflow::FORMAT_NCHW_VECT_C) {\n    // When format is NCHW_VECT_C, factor the feature map count into the outer\n    // feature count and the inner feature count (4 or 32).\n    CHECK(vect_size.has_value());  // Crash ok.\n    TF_RETURN_IF_ERROR(context->Divide(\n        filter_dim, *vect_size, /*evenly_divisible=*/true,\n        &out_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)]));\n    out_dims[GetTensorInnerFeatureDimIndex(rank, format)] = *vect_size;\n  } else {\n    out_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)] = filter_dim;\n  }\n\n  *shape = context->MakeShape(out_dims);\n  return tensorflow::Status::OK();\n}\n\nnamespace {\n\nStatus Conv2DShapeImpl(shape_inference::InferenceContext* c,\n                       bool supports_explicit_padding) {\n  string data_format_str, filter_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  if (!c->GetAttr(\"filter_format\", &filter_format_str).ok()) {\n    filter_format_str = \"HWIO\";\n  }\n\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  FilterTensorFormat filter_format;\n  if (!FilterFormatFromString(filter_format_str, &filter_format)) {\n    return errors::InvalidArgument(\"Invalid filter format string: \",\n                                   filter_format_str);\n  }\n\n  constexpr int num_spatial_dims = 2;\n  const int rank = GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n  ShapeHandle conv_input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &conv_input_shape));\n  TF_RETURN_IF_ERROR(CheckFormatConstraintsOnShape(\n      data_format, conv_input_shape, \"conv_input\", c));\n\n  // The filter rank should match the input (4 for NCHW, 5 for NCHW_VECT_C).\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &filter_shape));\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, filter_shape, \"filter\", c));\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"Conv2D requires the dilation attribute to contain 4 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  // strides.size() should be 4 (NCHW) even if the input is 5 (NCHW_VECT_C).\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\"Conv2D on data format \", data_format_str,\n                                   \" requires the stride attribute to contain\"\n                                   \" 4 values, but got: \",\n                                   strides.size());\n  }\n\n  const int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  const int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  const int32_t dilation_rows = GetTensorDim(dilations, data_format, 'H');\n  const int32_t dilation_cols = GetTensorDim(dilations, data_format, 'W');\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle input_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> input_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      conv_input_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(input_spatial_dims), &input_depth_dim, c));\n\n  DimensionHandle output_depth_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'O'));\n  DimensionHandle filter_rows_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'H'));\n  DimensionHandle filter_cols_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'W'));\n  DimensionHandle filter_input_depth_dim;\n  if (filter_format == FORMAT_OIHW_VECT_I) {\n    TF_RETURN_IF_ERROR(c->Multiply(\n        c->Dim(filter_shape,\n               GetFilterDimIndex<num_spatial_dims>(filter_format, 'I')),\n        c->Dim(filter_shape,\n               GetFilterTensorInnerInputChannelsDimIndex(rank, filter_format)),\n        &filter_input_depth_dim));\n  } else {\n    filter_input_depth_dim = c->Dim(\n        filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'I'));\n  }\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status s = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!s.ok() && !errors::IsNotFound(s)) {\n      return s;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    CHECK(padding != Padding::EXPLICIT);  // Crash ok.\n  }\n\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[0], filter_rows_dim, dilation_rows, stride_rows,\n      padding, pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[1], filter_cols_dim, dilation_cols, stride_cols,\n      padding, pad_cols_before, pad_cols_after, &output_cols));\n\n  absl::optional<DimensionHandle> vect_size;\n  if (data_format == FORMAT_NCHW_VECT_C) {\n    vect_size.emplace(c->Dim(conv_input_shape,\n                             GetTensorInnerFeatureDimIndex(rank, data_format)));\n  }\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, {output_rows, output_cols}, output_depth_dim, data_format,\n      vect_size, c, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\n}  // namespace\n\n// Shape function for Conv2D-like operations that support explicit padding.\nStatus Conv2DShapeWithExplicitPadding(shape_inference::InferenceContext* c) {\n  return Conv2DShapeImpl(c, true);\n}\n\n// Shape function for Conv2D-like operations that do not support explicit\n// padding.\nStatus Conv2DShape(shape_inference::InferenceContext* c) {\n  return Conv2DShapeImpl(c, false);\n}\n\n// TODO(mjanusz): Unify all conv/pooling shape functions.\nStatus Conv3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 5, &filter_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the dilation attribute to contain 5 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the stride attribute to contain 5 values, but got: \",\n        strides.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t dilation_planes, dilation_rows, dilation_cols;\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    dilation_planes = dilations[2];\n    dilation_cols = dilations[3];\n    dilation_rows = dilations[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_planes = dilations[1];\n    dilation_cols = dilations[2];\n    dilation_rows = dilations[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle input_depth_dim = c->Dim(input_shape, 4);\n\n  DimensionHandle filter_planes_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 1);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 2);\n  DimensionHandle filter_input_depth_dim = c->Dim(filter_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(filter_shape, 4);\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n  DimensionHandle output_planes, output_rows, output_cols;\n\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_planes_dim, filter_planes_dim, dilation_planes, stride_planes,\n      padding, -1, -1, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding, -1,\n      -1, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding, -1,\n      -1, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus Conv2DBackpropInputShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n\n  // For the rest of this function, output_grad_* describes out_backprop and\n  // input_grad_* describes in_backprop.\n  ShapeHandle output_grad_shape = c->input(2);\n  TF_RETURN_IF_ERROR(c->WithRank(output_grad_shape, 4, &output_grad_shape));\n  ShapeHandle filter_shape = c->input(1);\n  TF_RETURN_IF_ERROR(c->WithRank(filter_shape, 4, &filter_shape));\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle output_grad_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> output_grad_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      output_grad_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(output_grad_spatial_dims), &output_grad_depth_dim, c));\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(\n      c->Merge(output_grad_depth_dim, c->Dim(filter_shape, 3), &unused));\n\n  ShapeHandle specified_input_grad_shape;\n  TF_RETURN_IF_ERROR(\n      c->MakeShapeFromShapeTensor(0, &specified_input_grad_shape));\n  if (c->Rank(specified_input_grad_shape) == InferenceContext::kUnknownRank) {\n    TF_RETURN_IF_ERROR(c->WithRank(specified_input_grad_shape, 4,\n                                   &specified_input_grad_shape));\n  }\n\n  // input_grad_depth_dim doesn't equal c->Dim(filter_shape,2) when the number\n  // of groups is larger than 1. If input_sizes is a 4D shape, we collect\n  // input_grad_depth_dim from input_sizes; otherwise we compute it as\n  // c->Dim(filter_shape,2).\n  DimensionHandle input_grad_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> specified_input_grad_spatial_dims(2);\n  int specified_input_grad_rank = c->Rank(specified_input_grad_shape);\n  if (specified_input_grad_rank == 4) {\n    DimensionHandle specified_batch_size_dim;\n    TF_RETURN_IF_ERROR(DimensionsFromShape(\n        specified_input_grad_shape, data_format, &specified_batch_size_dim,\n        absl::MakeSpan(specified_input_grad_spatial_dims),\n        &input_grad_depth_dim, c));\n    TF_RETURN_IF_ERROR(\n        c->Merge(specified_batch_size_dim, batch_size_dim, &unused));\n  } else if (specified_input_grad_rank == 2) {\n    specified_input_grad_spatial_dims[0] =\n        c->Dim(specified_input_grad_shape, 0);\n    specified_input_grad_spatial_dims[1] =\n        c->Dim(specified_input_grad_shape, 1);\n    input_grad_depth_dim = c->Dim(filter_shape, 2);\n  } else {\n    return errors::InvalidArgument(\n        \"Conv2DBackpropInput requires input_sizes to contain 4 values or 2 \"\n        \"values, but got: \",\n        specified_input_grad_rank);\n  }\n\n  ShapeHandle input_grad_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, specified_input_grad_spatial_dims, input_grad_depth_dim,\n      data_format, /*vect_size=*/absl::nullopt, c, &input_grad_shape));\n  c->set_output(0, input_grad_shape);\n  return Status::OK();\n}\n\nStatus Conv2DBackpropFilterWithBiasShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  // Fetch the data_format attribute, which may not exist.\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n  if (s.ok() && data_format == \"NCHW\") {\n    c->set_output(1, c->Vector(c->Dim(input_shape, -3)));\n  } else {\n    c->set_output(1, c->Vector(c->Dim(input_shape, -1)));\n  }\n  ShapeHandle sh;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &sh));\n  TF_RETURN_IF_ERROR(c->WithRank(sh, 4, &sh));\n  c->set_output(0, sh);\n  return Status::OK();\n}\n\nnamespace {\n\nStatus DepthwiseConv2DNativeShapeImpl(shape_inference::InferenceContext* c,\n                                      bool supports_explicit_padding) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 4, &filter_shape));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"DepthwiseConv2D requires the stride attribute to contain 4 values, \"\n        \"but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> dilations;\n  if (!c->GetAttr(\"dilations\", &dilations).ok()) {\n    dilations.resize(4, 1);\n  }\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"DepthwiseConv2D requires the dilations attribute to contain 4 values, \"\n        \"but got: \",\n        dilations.size());\n  }\n\n  string data_format_str;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  TensorFormat data_format;\n  if (!s.ok() || !FormatFromString(data_format_str, &data_format)) {\n    data_format = FORMAT_NHWC;\n  }\n  int32_t stride_rows;\n  int32_t stride_cols;\n  int32_t dilation_rows;\n  int32_t dilation_cols;\n  if (data_format == FORMAT_NCHW) {\n    // Canonicalize input shape to NHWC so the shape inference code below can\n    // process it.\n    input_shape =\n        c->MakeShape({{c->Dim(input_shape, 0), c->Dim(input_shape, 2),\n                       c->Dim(input_shape, 3), c->Dim(input_shape, 1)}});\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_rows = dilations[2];\n    dilation_cols = dilations[3];\n  } else {\n    stride_rows = strides[1];\n    stride_cols = strides[2];\n    dilation_rows = dilations[1];\n    dilation_cols = dilations[2];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 2);\n\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 1);\n  DimensionHandle input_depth = c->Dim(filter_shape, 2);\n  DimensionHandle depth_multiplier = c->Dim(filter_shape, 3);\n\n  // Check that the input depths are compatible.\n  TF_RETURN_IF_ERROR(\n      c->Merge(c->Dim(input_shape, 3), input_depth, &input_depth));\n\n  DimensionHandle output_depth;\n  TF_RETURN_IF_ERROR(c->Multiply(input_depth, depth_multiplier, &output_depth));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status status = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!status.ok() && !errors::IsNotFound(status)) {\n      return status;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    DCHECK(padding != Padding::EXPLICIT);\n  }\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding,\n      pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding,\n      pad_cols_before, pad_cols_after, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == FORMAT_NCHW) {\n    output_shape =\n        c->MakeShape({batch_size_dim, output_depth, output_rows, output_cols});\n  } else {\n    output_shape =\n        c->MakeShape({batch_size_dim, output_rows, output_cols, output_depth});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\n};  // namespace\n\nStatus DepthwiseConv2DNativeShape(shape_inference::InferenceContext* c) {\n  return DepthwiseConv2DNativeShapeImpl(c, false);\n}\n\nStatus DepthwiseConv2DNativeShapeWithExplicitPadding(\n    shape_inference::InferenceContext* c) {\n  return DepthwiseConv2DNativeShapeImpl(c, true);\n}\n\nStatus AvgPoolShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"AvgPool requires the stride attribute to contain 4 values, but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"AvgPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n\n  DimensionHandle output_rows, output_cols;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols}, depth_dim,\n                                         &output_shape, c));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus AvgPoolGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &s));\n  TF_RETURN_IF_ERROR(c->WithRank(s, 4, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus FusedBatchNormShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &x));\n\n  bool is_training;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"is_training\", &is_training));\n  float exponential_avg_factor;\n  if (!c->GetAttr(\"exponential_avg_factor\", &exponential_avg_factor).ok()) {\n    exponential_avg_factor = 1.0f;  // default value\n  }\n  int number_inputs = (is_training && exponential_avg_factor == 1.0f) ? 3 : 5;\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(x, channel_dim_index);\n\n  // covers scale, offset, and if is_training is false, mean, variance\n  for (int i = 1; i < number_inputs; ++i) {\n    ShapeHandle vec;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 1, &vec));\n    TF_RETURN_IF_ERROR(c->Merge(channel_dim, c->Dim(vec, 0), &channel_dim));\n  }\n\n  ShapeHandle y;\n  TF_RETURN_IF_ERROR(c->ReplaceDim(x, channel_dim_index, channel_dim, &y));\n  c->set_output(0, y);\n  ShapeHandle vector_shape = c->Vector(channel_dim);\n  c->set_output(1, vector_shape);\n  c->set_output(2, vector_shape);\n  c->set_output(3, vector_shape);\n  c->set_output(4, vector_shape);\n  return Status::OK();\n}\n\nStatus FusedBatchNormV3Shape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormShape(c));\n  c->set_output(5, c->UnknownShape());\n  return Status::OK();\n}\n\nStatus FusedBatchNormExShape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormV3Shape(c));\n\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &x));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(4, data_format);\n  DimensionHandle channel_dim = c->Dim(x, channel_dim_index);\n\n  // This is a cuDNN implementation constraint.\n  if (c->ValueKnown(channel_dim) && c->Value(channel_dim) % 4 != 0) {\n    return errors::InvalidArgument(\n        \"_FusedBatchNormEx channel dimension must be divisible by 4.\");\n  }\n\n  return Status::OK();\n}\n\nStatus FusedBatchNormGradShape(shape_inference::InferenceContext* c) {\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle y_backprop;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &y_backprop));\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &x));\n\n  bool is_training;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"is_training\", &is_training));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(y_backprop, channel_dim_index);\n  TF_RETURN_IF_ERROR(\n      c->Merge(channel_dim, c->Dim(x, channel_dim_index), &channel_dim));\n\n  // covers scale, mean (reserve_space_1), variance (reserve_space_2)\n  for (int i = 2; i < 5; ++i) {\n    ShapeHandle vec;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 1, &vec));\n    TF_RETURN_IF_ERROR(c->Merge(channel_dim, c->Dim(vec, 0), &channel_dim));\n  }\n\n  ShapeHandle x_backprop;\n  TF_RETURN_IF_ERROR(\n      c->ReplaceDim(y_backprop, channel_dim_index, channel_dim, &x_backprop));\n  c->set_output(0, x_backprop);\n  c->set_output(1, c->Vector(channel_dim));\n  c->set_output(2, c->Vector(channel_dim));\n  c->set_output(3, c->Vector(0));\n  c->set_output(4, c->Vector(0));\n  return Status::OK();\n}\n\nStatus FusedBatchNormGradExShape(shape_inference::InferenceContext* c) {\n  TF_RETURN_IF_ERROR(FusedBatchNormGradShape(c));\n\n  int num_side_inputs;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"num_side_inputs\", &num_side_inputs));\n  if (num_side_inputs == 0) {\n    return Status::OK();\n  }\n\n  string data_format_str;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  const int rank =\n      (data_format_str == \"NDHWC\" || data_format_str == \"NCDHW\") ? 5 : 4;\n  ShapeHandle y_backprop;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &y_backprop));\n  ShapeHandle x;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &x));\n\n  int channel_dim_index = GetTensorFeatureDimIndex(rank, data_format);\n  DimensionHandle channel_dim = c->Dim(y_backprop, channel_dim_index);\n  TF_RETURN_IF_ERROR(\n      c->Merge(channel_dim, c->Dim(x, channel_dim_index), &channel_dim));\n\n  ShapeHandle side_input_backprop;\n  TF_RETURN_IF_ERROR(c->ReplaceDim(y_backprop, channel_dim_index, channel_dim,\n                                   &side_input_backprop));\n\n  c->set_output(5, side_input_backprop);\n  return Status::OK();\n}\n\nStatus ReadDiagIndex(InferenceContext* c, const Tensor* diag_index_tensor,\n                     int32* lower_diag_index, int32* upper_diag_index) {\n  // This function assumes that the shape of diag_index_tensor is fully defined.\n  if (diag_index_tensor->dims() == 0) {\n    *lower_diag_index = diag_index_tensor->scalar<int32>()();\n    *upper_diag_index = *lower_diag_index;\n  } else {\n    int32_t num_elements = diag_index_tensor->dim_size(0);\n    if (num_elements == 1) {\n      *lower_diag_index = diag_index_tensor->vec<int32>()(0);\n      *upper_diag_index = *lower_diag_index;\n    } else if (num_elements == 2) {\n      *lower_diag_index = diag_index_tensor->vec<int32>()(0);\n      *upper_diag_index = diag_index_tensor->vec<int32>()(1);\n    } else {\n      return errors::InvalidArgument(\n          \"diag_index must be a vector with one or two elements. It has \",\n          num_elements, \" elements.\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus MatrixDiagPartV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape, diag_index_shape, unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &diag_index_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_shape));\n\n  const Tensor* diag_index_tensor = c->input_tensor(1);\n  if (!c->RankKnown(input_shape) || !c->FullyDefined(diag_index_shape) ||\n      diag_index_tensor == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                   &upper_diag_index));\n  if (lower_diag_index > upper_diag_index) {\n    return errors::InvalidArgument(\n        \"lower_diag_index is greater than upper_diag_index\");\n  }\n\n  // Validates lower_diag_index and upper_diag_index.\n  const int32_t input_rank = c->Rank(input_shape);\n  const int32_t num_rows = c->Value(c->Dim(input_shape, input_rank - 2));\n  const int32_t num_cols = c->Value(c->Dim(input_shape, input_rank - 1));\n  int32_t max_diag_len = InferenceContext::kUnknownDim;\n  if (num_rows != InferenceContext::kUnknownDim &&\n      num_cols != InferenceContext::kUnknownDim) {\n    if (lower_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n        (-num_rows >= lower_diag_index || lower_diag_index >= num_cols)) {\n      return errors::InvalidArgument(\"lower_diag_index is out of bound.\");\n    }\n    if (upper_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n        (-num_rows >= upper_diag_index || upper_diag_index >= num_cols)) {\n      return errors::InvalidArgument(\"upper_diag_index is out of bound.\");\n    }\n    max_diag_len = std::min(num_rows + std::min(upper_diag_index, 0),\n                            num_cols - std::max(lower_diag_index, 0));\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.reserve(input_rank - 2);\n  for (int i = 0; i < input_rank - 2; ++i) {\n    dims.push_back(c->Dim(input_shape, i));\n  }\n  if (lower_diag_index < upper_diag_index) {\n    dims.push_back(c->MakeDim(upper_diag_index - lower_diag_index + 1));\n  }\n  dims.push_back(c->MakeDim(max_diag_len));\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus MatrixDiagV2Shape(shape_inference::InferenceContext* c) {\n  // Checks input ranks.\n  ShapeHandle input_shape, diag_index_shape, unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &diag_index_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 0, &unused_shape));\n\n  // Reads the diagonal indices.\n  const Tensor* diag_index_tensor = c->input_tensor(1);\n  if (!c->RankKnown(input_shape) || !c->FullyDefined(diag_index_shape) ||\n      diag_index_tensor == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                   &upper_diag_index));\n  if (lower_diag_index > upper_diag_index) {\n    return errors::InvalidArgument(\n        \"lower_diag_index is greater than upper_diag_index\");\n  }\n\n  // Checks if the number of diagonals provided matches what we imply from\n  // lower_diag_index and upper_diag_index.\n  const int32_t input_rank = c->Rank(input_shape);\n  if (lower_diag_index < upper_diag_index) {\n    const int32_t num_diags = c->Value(c->Dim(input_shape, input_rank - 2));\n    const int32_t other_dim = c->Value(c->Dim(input_shape, input_rank - 1));\n\n    if (num_diags != (upper_diag_index - lower_diag_index + 1)) {\n      return errors::InvalidArgument(\n          \"The number of rows of `diagonal` doesn't match the number of \"\n          \"diagonals implied from `d_lower` and `d_upper`.\\n\",\n          \"num_diags = \", num_diags, \", d_lower = \", lower_diag_index,\n          \", d_upper = \", upper_diag_index, \" \", input_rank, \" \", other_dim);\n    }\n  }\n\n  // Reads num_rows and num_cols.\n  const Tensor* num_rows_tensor = c->input_tensor(2);\n  const Tensor* num_cols_tensor = c->input_tensor(3);\n  int64_t num_rows = -1;\n  int64_t num_cols = -1;\n  if (num_rows_tensor != nullptr) {\n    TF_RETURN_IF_ERROR(c->GetScalarFromTensor(num_rows_tensor, &num_rows));\n  }\n  if (num_cols_tensor != nullptr) {\n    TF_RETURN_IF_ERROR(c->GetScalarFromTensor(num_cols_tensor, &num_cols));\n  }\n\n  // Infers the missing num_rows or num_cols: If both are missing, assume\n  // output is square. Otherwise, use the smallest possible value. Also\n  // validates the provided values.\n  const int32_t max_diag_len = c->Value(c->Dim(input_shape, input_rank - 1));\n  const int32_t min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n  const int32_t min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n  if (num_rows == -1 && num_cols == -1) {  // Special case.\n    num_rows = std::max(min_num_rows, min_num_cols);\n    num_cols = num_rows;\n  }\n  if (num_rows == -1) {\n    num_rows = min_num_rows;\n  } else if (num_rows < min_num_rows) {\n    return errors::InvalidArgument(\"num_rows is too small\");\n  }\n  if (num_cols == -1) {\n    num_cols = min_num_cols;\n  } else if (num_cols < min_num_cols) {\n    return errors::InvalidArgument(\"num_cols is too small.\");\n  }\n  // At least one of them must match the minimum length.\n  if (num_rows != min_num_rows && num_cols != min_num_cols) {\n    return errors::InvalidArgument(\n        \"num_rows and num_cols are not consistent with lower_diag_index, \"\n        \"upper_diag_index, and the length of the given diagonals.\\n\",\n        \"num_rows = \", num_rows, \" != min_num_rows = \", min_num_rows,\n        \", num_cols = \", num_cols, \" != min_num_cols = \", min_num_cols);\n  }\n\n  // Sets output shape.\n  ShapeHandle output_shape;\n  const DimensionHandle output_row_dim = c->MakeDim(num_rows);\n  const DimensionHandle output_col_dim = c->MakeDim(num_cols);\n  if (lower_diag_index == upper_diag_index) {\n    TF_RETURN_IF_ERROR(c->ReplaceDim(input_shape, input_rank - 1,\n                                     output_row_dim, &output_shape));\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(output_shape, c->Vector(output_col_dim), &output_shape));\n  } else {\n    TF_RETURN_IF_ERROR(c->ReplaceDim(input_shape, input_rank - 2,\n                                     output_row_dim, &output_shape));\n    TF_RETURN_IF_ERROR(c->ReplaceDim(output_shape, input_rank - 1,\n                                     output_col_dim, &output_shape));\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MatrixSetDiagV2Shape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape, diag_shape, diag_index_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &diag_shape));\n  TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(2), 1, &diag_index_shape));\n\n  int32_t lower_diag_index = 0;\n  int32_t upper_diag_index = 0;\n  bool diag_index_known = false;\n  const Tensor* diag_index_tensor = c->input_tensor(2);\n  if (diag_index_tensor != nullptr && c->FullyDefined(diag_index_shape)) {\n    diag_index_known = true;\n    TF_RETURN_IF_ERROR(ReadDiagIndex(c, diag_index_tensor, &lower_diag_index,\n                                     &upper_diag_index));\n    if (lower_diag_index > upper_diag_index) {\n      return errors::InvalidArgument(\n          \"lower_diag_index is greater than upper_diag_index\");\n    }\n  }\n\n  // Do more checks when input rank is known.\n  if (c->RankKnown(input_shape)) {\n    int32_t input_rank = c->Rank(input_shape);\n\n    // If diag_index is set, we know the exact rank of diagonal.\n    if (diag_index_known) {\n      TF_RETURN_IF_ERROR(c->WithRank(\n          c->input(1),\n          (lower_diag_index == upper_diag_index) ? input_rank - 1 : input_rank,\n          &diag_shape));\n    } else {\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(c->input(1), input_rank - 1, &diag_shape));\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtMost(c->input(1), input_rank, &diag_shape));\n    }\n\n    // Validates lower_diag_index and upper_diag_index.\n    const int32_t num_rows = c->Value(c->Dim(input_shape, input_rank - 2));\n    const int32_t num_cols = c->Value(c->Dim(input_shape, input_rank - 1));\n    if (num_rows != InferenceContext::kUnknownDim &&\n        num_cols != InferenceContext::kUnknownDim) {\n      if (lower_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n          (-num_rows >= lower_diag_index || lower_diag_index >= num_cols)) {\n        return errors::InvalidArgument(\"lower_diag_index is out of bound.\");\n      }\n      if (upper_diag_index != 0 &&  // For when num_rows or num_cols == 0.\n          (-num_rows >= upper_diag_index || upper_diag_index >= num_cols)) {\n        return errors::InvalidArgument(\"upper_diag_index is out of bound.\");\n      }\n    }\n  }\n\n  ShapeHandle output_shape = input_shape;\n  if (c->RankKnown(diag_shape) && !c->FullyDefined(input_shape)) {\n    // Try to infer parts of shape from diag.\n    ShapeHandle diag_prefix;\n    TF_RETURN_IF_ERROR(c->Subshape(\n        diag_shape, 0, (lower_diag_index == upper_diag_index) ? -1 : -2,\n        &diag_prefix));\n\n    // The inner matrices can be rectangular, so we can't pinpoint their\n    // exact height and width by just lower_diag_index, upper_diag_index,\n    // and the longest length of given diagonals.\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(diag_prefix, c->UnknownShapeOfRank(2), &diag_shape));\n    TF_RETURN_IF_ERROR(c->Merge(input_shape, diag_shape, &output_shape));\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPoolShapeImpl(shape_inference::InferenceContext* c,\n                        bool supports_explicit_padding) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the stride attribute to contain 4 values, but got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_depth = GetTensorDim(strides, data_format, 'C');\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_depth = GetTensorDim(kernel_sizes, data_format, 'C');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle in_depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64_t> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status status = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!status.ok() && !errors::IsNotFound(status)) {\n      return status;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    DCHECK(padding != Padding::EXPLICIT);\n  }\n\n  ShapeHandle output_shape;\n  DimensionHandle output_rows, output_cols, output_depth;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, kernel_rows, /*dilation_rate=*/1, stride_rows, padding,\n      pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, kernel_cols, /*dilation_rate=*/1, stride_cols, padding,\n      pad_cols_before, pad_cols_after, &output_cols));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_depth_dim, kernel_depth, /*dilation_rate=*/1, stride_depth, padding,\n      /*pad_before*/ 0, /*pad_after*/ 0, &output_depth));\n\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols},\n                                         output_depth, &output_shape, c));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPoolShape(shape_inference::InferenceContext* c) {\n  return MaxPoolShapeImpl(c, /*supports_explicit_padding=*/false);\n}\n\nStatus MaxPoolGradShape(shape_inference::InferenceContext* c) {\n  return UnchangedShapeWithRank(c, 4);\n}\n\nStatus MaxPoolShapeWithExplicitPadding(shape_inference::InferenceContext* c) {\n  return MaxPoolShapeImpl(c, /*supports_explicit_padding=*/true);\n}\n\nStatus MaxPoolV2Shape(shape_inference::InferenceContext* c, int num_inputs) {\n  string data_format_str;\n  TensorFormat data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format_str);\n  if (s.ok()) {\n    FormatFromString(data_format_str, &data_format);\n  } else {\n    data_format = FORMAT_NHWC;\n  }\n\n  const int rank = (data_format == FORMAT_NCHW_VECT_C) ? 5 : 4;\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, input_shape, \"input\", c));\n\n  std::vector<int32> kernel_sizes;\n  std::vector<int32> strides;\n\n  if (c->num_inputs() + 2 == num_inputs) {\n    TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n\n    TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  } else {\n    // Verify shape of ksize and strides input.\n    ShapeHandle size;\n    DimensionHandle unused;\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(c->num_inputs() - 2), 1, &size));\n    TF_RETURN_IF_ERROR(c->WithValue(c->Dim(size, 0), 4, &unused));\n    TF_RETURN_IF_ERROR(c->WithRank(c->input(c->num_inputs() - 1), 1, &size));\n    TF_RETURN_IF_ERROR(c->WithValue(c->Dim(size, 0), 4, &unused));\n\n    const Tensor* kernel_sizes_tensor = c->input_tensor(c->num_inputs() - 2);\n    if (kernel_sizes_tensor == nullptr) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n    kernel_sizes.resize(kernel_sizes_tensor->shape().num_elements());\n    auto kernel_sizes_vec = kernel_sizes_tensor->flat<int32>();\n    std::copy_n(&kernel_sizes_vec(0), kernel_sizes.size(),\n                kernel_sizes.begin());\n\n    const Tensor* strides_tensor = c->input_tensor(c->num_inputs() - 1);\n    if (strides_tensor == nullptr) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    }\n    strides.resize(strides_tensor->shape().num_elements());\n    auto strides_vec = strides_tensor->flat<int32>();\n    std::copy_n(&strides_vec(0), strides.size(), strides.begin());\n  }\n\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the stride attribute to contain 4 values, but \"\n        \"got: \",\n        strides.size());\n  }\n  if (kernel_sizes.size() != 4) {\n    return errors::InvalidArgument(\n        \"MaxPool requires the ksize attribute to contain 4 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_depth = GetTensorDim(strides, data_format, 'C');\n  int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  int32_t kernel_depth = GetTensorDim(kernel_sizes, data_format, 'C');\n  int32_t kernel_rows = GetTensorDim(kernel_sizes, data_format, 'H');\n  int32_t kernel_cols = GetTensorDim(kernel_sizes, data_format, 'W');\n\n  constexpr int num_spatial_dims = 2;\n  DimensionHandle batch_size_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n  DimensionHandle in_rows_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n  DimensionHandle in_cols_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n  DimensionHandle in_depth_dim = c->Dim(\n      input_shape, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  ShapeHandle output_shape;\n  DimensionHandle output_rows, output_cols, output_depth;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_depth_dim, kernel_depth, stride_depth, padding, &output_depth));\n\n  TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size_dim,\n                                         {output_rows, output_cols},\n                                         output_depth, &output_shape, c));\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus Pool3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Pool3D ops require the stride attribute to contain 5 values, but \"\n        \"got: \",\n        strides.size());\n  }\n\n  std::vector<int32> kernel_sizes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"ksize\", &kernel_sizes));\n  if (kernel_sizes.size() != 5) {\n    return errors::InvalidArgument(\n        \"Pool3D requires the ksize attribute to contain 5 values, but got: \",\n        kernel_sizes.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t kernel_planes, kernel_rows, kernel_cols;\n\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    kernel_planes = kernel_sizes[2];\n    kernel_rows = kernel_sizes[3];\n    kernel_cols = kernel_sizes[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    kernel_planes = kernel_sizes[1];\n    kernel_rows = kernel_sizes[2];\n    kernel_cols = kernel_sizes[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(input_shape, 4);\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  // TODO(mrry,shlens): Raise an error if the stride would cause\n  // information in the input to be ignored. This will require a change\n  // in the kernel implementation.\n  DimensionHandle output_planes, output_rows, output_cols;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_planes_dim, kernel_planes, stride_planes, padding, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(\n      c, in_cols_dim, kernel_cols, stride_cols, padding, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus MaxPool3DGradShape(shape_inference::InferenceContext* c) {\n  return UnchangedShapeWithRank(c, 5);\n}\n\nStatus AvgPool3DGradShape(shape_inference::InferenceContext* c) {\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &s));\n  TF_RETURN_IF_ERROR(c->WithRank(s, 5, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus UnknownShape(shape_inference::InferenceContext* c) {\n  for (int i = 0; i < c->num_outputs(); ++i) {\n    c->set_output(i, c->UnknownShape());\n  }\n  return Status::OK();\n}\n\ntemplate <typename T>\nStatus ReductionShapeHelper(const Tensor* reduction_indices_t,\n                            const int32_t input_rank,\n                            std::set<int64_t>* true_indices) {\n  auto reduction_indices = reduction_indices_t->flat<T>();\n  for (int i = 0; i < reduction_indices_t->NumElements(); ++i) {\n    const T reduction_index = reduction_indices(i);\n    if (reduction_index < -input_rank || reduction_index >= input_rank) {\n      return errors::InvalidArgument(\"Invalid reduction dimension \",\n                                     reduction_index, \" for input with \",\n                                     input_rank, \" dimensions.\");\n    }\n\n    auto wrapped_index = reduction_index;\n    if (wrapped_index < 0) {\n      wrapped_index += input_rank;\n    }\n\n    true_indices->insert(wrapped_index);\n  }\n  return Status::OK();\n}\n\nStatus ReductionShape(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n\n  ShapeHandle indices;\n  // Older versions of TensorFlow accidentally allowed higher rank tensors like\n  // [[1,2]] or [[1],[2]] to represent axis=[1,2].\n  if (c->graph_def_version() < 21) {\n    indices = c->input(1);\n  } else {\n    TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &indices));\n  }\n\n  bool keep_dims;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* reduction_indices_t = c->input_tensor(1);\n  if (reduction_indices_t == nullptr || !c->RankKnown(input)) {\n    // If we do not have the reduction values at runtime, or the\n    // rank of the input, we don't know the output shape.\n\n    if (keep_dims && c->RankKnown(input)) {\n      // output rank matches input input if <keep_dims>.\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(input)));\n      return Status::OK();\n    } else {\n      return shape_inference::UnknownShape(c);\n    }\n  }\n\n  const int32_t input_rank = c->Rank(input);\n  std::set<int64_t> true_indices;\n  if (reduction_indices_t->dtype() == DataType::DT_INT32) {\n    TF_RETURN_IF_ERROR(ReductionShapeHelper<int32>(reduction_indices_t,\n                                                   input_rank, &true_indices));\n  } else if (reduction_indices_t->dtype() == DataType::DT_INT64) {\n    TF_RETURN_IF_ERROR(ReductionShapeHelper<int64_t>(\n        reduction_indices_t, input_rank, &true_indices));\n  } else {\n    return errors::InvalidArgument(\n        \"reduction_indices can only be int32 or int64\");\n  }\n\n  std::vector<DimensionHandle> dims;\n  for (int i = 0; i < input_rank; ++i) {\n    if (true_indices.count(i) > 0) {\n      if (keep_dims) {\n        dims.emplace_back(c->MakeDim(1));\n      }\n    } else {\n      dims.emplace_back(c->Dim(input, i));\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus ConcatShapeHelper(InferenceContext* c, int start_value_index,\n                         int end_value_index, int dim_index) {\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(dim_index), 0, &unused));\n  const Tensor* concat_dim_t = c->input_tensor(dim_index);\n  if (concat_dim_t == nullptr) {\n    // Return an unknown shape with same rank as inputs, or an unknown rank\n    // if no input's rank is known.\n\n    // Find rank.\n    int32_t rank = InferenceContext::kUnknownRank;\n    for (int i = start_value_index; i < end_value_index; ++i) {\n      if (rank == InferenceContext::kUnknownRank) rank = c->Rank(c->input(i));\n      if (rank != InferenceContext::kUnknownRank) {\n        break;\n      }\n    }\n    if (rank == InferenceContext::kUnknownRank) {\n      c->set_output(0, c->UnknownShape());\n      return Status::OK();\n    } else if (rank == 0) {\n      return errors::InvalidArgument(\n          \"Can't concatenate scalars (use tf.stack instead)\");\n    } else {\n      for (int i = start_value_index; i < end_value_index; ++i) {\n        // Check that all the inputs are of the correct rank.\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), rank, &unused));\n      }\n    }\n    // Build result of <rank> different unknown dims.\n    std::vector<DimensionHandle> dims;\n    dims.reserve(rank);\n    for (int i = 0; i < rank; ++i) dims.push_back(c->UnknownDim());\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n\n  // Merge all the non-concat dims, and sum the concat dim to make an output\n  // shape.\n  int64_t concat_dim;\n  if (concat_dim_t->dtype() == DT_INT32) {\n    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));\n  } else {\n    concat_dim = concat_dim_t->flat<int64_t>()(0);\n  }\n\n  // Minimum required number of dimensions.\n  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;\n\n  ShapeHandle output_before;\n  ShapeHandle output_after;\n\n  ShapeHandle input = c->input(end_value_index - 1);\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n  TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &output_before));\n  DimensionHandle output_middle = c->Dim(input, concat_dim);\n  if (concat_dim == -1) {\n    output_after = c->Scalar();  // no dimensions.\n  } else {\n    TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &output_after));\n  }\n\n  for (int i = end_value_index - 2; i >= start_value_index; --i) {\n    ShapeHandle before;\n    ShapeHandle after;\n    input = c->input(i);\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));\n    TF_RETURN_IF_ERROR(c->Subshape(input, 0, concat_dim, &before));\n    DimensionHandle middle = c->Dim(input, concat_dim);\n    if (concat_dim == -1) {\n      after = c->Scalar();\n    } else {\n      TF_RETURN_IF_ERROR(c->Subshape(input, concat_dim + 1, &after));\n    }\n\n    TF_RETURN_IF_ERROR(c->Merge(before, output_before, &output_before));\n    TF_RETURN_IF_ERROR(c->Add(output_middle, middle, &output_middle));\n    TF_RETURN_IF_ERROR(c->Merge(after, output_after, &output_after));\n  }\n\n  ShapeHandle s;\n  TF_RETURN_IF_ERROR(\n      c->Concatenate(output_before, c->Vector(output_middle), &s));\n  TF_RETURN_IF_ERROR(c->Concatenate(s, output_after, &s));\n  c->set_output(0, s);\n  return Status::OK();\n}\n\nStatus ConcatShape(InferenceContext* c, int num_inputs_to_concat) {\n  return ConcatShapeHelper(c, 1 /* start_value_index */,\n                           1 + num_inputs_to_concat /* end_value_index */,\n                           0 /* dim_index */);\n}\n\nStatus ConcatV2Shape(InferenceContext* c) {\n  return ConcatShapeHelper(c, 0 /* start_value_index */,\n                           c->num_inputs() - 1 /* end_value_index */,\n                           c->num_inputs() - 1 /* dim_index */);\n}\n\nStatus QuantizedConcatV2Shape(InferenceContext* c, int num_inputs_to_concat) {\n  return ConcatShapeHelper(c, 0 /* start_value_index */,\n                           num_inputs_to_concat /* end_value_index */,\n                           num_inputs_to_concat /* dim_index */);\n}\n\nStatus BroadcastBinaryOpOutputShapeFnHelper(InferenceContext* c,\n                                            ShapeHandle shape_x,\n                                            ShapeHandle shape_y,\n                                            bool incompatible_shape_error,\n                                            ShapeHandle* out) {\n  CHECK_NOTNULL(out);\n  if (!c->RankKnown(shape_x) || !c->RankKnown(shape_y)) {\n    *out = c->UnknownShape();\n    return Status::OK();\n  }\n  const int32_t rank_x = c->Rank(shape_x);\n  const int32_t rank_y = c->Rank(shape_y);\n  const int32_t rank_out = std::max(rank_x, rank_y);\n\n  // To compute the broadcast dimensions, we zip together shape_x and shape_y\n  // and\n  // pad with 1 to make them the same length.\n  std::vector<DimensionHandle> dims;\n  DimensionHandle dim_one;\n  if (rank_x != rank_y) dim_one = c->MakeDim(1);\n  for (int i = 0; i < rank_out; ++i) {\n    const auto dim_x = i < (rank_out - rank_x)\n                           ? dim_one\n                           : c->Dim(shape_x, i - (rank_out - rank_x));\n    const bool dim_y_is_one = (i < (rank_out - rank_y));\n    const auto dim_y =\n        dim_y_is_one ? dim_one : c->Dim(shape_y, i - (rank_out - rank_y));\n    if (!c->ValueKnown(dim_x) || !c->ValueKnown(dim_y)) {\n      // One or both dimensions is unknown.\n      //\n      // - If either dimension is greater than 1, we assume that the program is\n      // correct, and the other dimension will be broadcast to match it.\n      // TODO(cwhipkey): For shape inference, if we eliminate the shape checks\n      // in C++ op code, we must still assert that the unknown dim is either 1\n      // or the same as the known dim.\n      // - If either dimension is 1, the other dimension is the output.\n      // - If both are unknown then dimension is unknown\n      if (c->Value(dim_x) > 1) {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(dim_x);\n      } else if (c->Value(dim_y) > 1) {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(dim_y);\n      } else if (c->Value(dim_x) == 1) {\n        dims.push_back(dim_y);\n      } else if (c->Value(dim_y) == 1) {\n        dims.push_back(dim_x);\n      } else if (dim_y.SameHandle(dim_x)) {\n        dims.push_back(dim_x);\n      } else if (!c->ValueKnown(dim_x) && !c->ValueKnown(dim_y)) {\n        dims.push_back(c->UnknownDim());\n      } else {\n        if (!incompatible_shape_error) {\n          *out = c->UnknownShape();\n          return Status::OK();\n        }\n        dims.push_back(c->UnknownDim());\n      }\n    } else if (c->Value(dim_x) == 1 || c->Value(dim_y) == 1) {\n      if (c->Value(dim_x) == 1 && !dim_y_is_one) {\n        // We will broadcast dim_x to dim_y.\n        dims.push_back(dim_y);\n      } else {\n        DCHECK_EQ(c->Value(dim_y), 1);\n        // We will broadcast dim_y to dim_x.\n        dims.push_back(dim_x);\n      }\n    } else {\n      DimensionHandle dim;\n      Status s = c->Merge(dim_x, dim_y, &dim);\n      if (!s.ok()) {\n        if (!incompatible_shape_error) {\n          *out = c->MakeShape({});\n          return Status::OK();\n        }\n        return s;\n      }\n      dims.push_back(dim);\n    }\n  }\n\n  *out = c->MakeShape(dims);\n  return Status::OK();\n}\n\nStatus RandomShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nStatus UnsortedSegmentReductionShapeFn(InferenceContext* c) {\n  ShapeHandle s_data = c->input(0);\n  ShapeHandle s_segment_ids = c->input(1);\n  ShapeHandle s_num_segments = c->input(2);\n  TF_RETURN_IF_ERROR(c->WithRank(s_num_segments, 0, &s_num_segments));\n\n  ShapeHandle out;\n\n  // Leading dimensions of data must be compatible with dimensions of\n  // <s_segment_ids>.\n  if (c->RankKnown(s_segment_ids)) {\n    TF_RETURN_IF_ERROR(\n        c->MergePrefix(s_data, s_segment_ids, &s_data, &s_segment_ids));\n\n    // Get the value of the num_segments input tensor.\n    DimensionHandle num_segments_dim;\n    TF_RETURN_IF_ERROR(c->MakeDimForScalarInput(2, &num_segments_dim));\n\n    // Output is {segment_id_rank} + s_data[segment_id_rank:].\n    ShapeHandle s_data_suffix;\n    TF_RETURN_IF_ERROR(\n        c->Subshape(s_data, c->Rank(s_segment_ids), &s_data_suffix));\n    TF_RETURN_IF_ERROR(\n        c->Concatenate(c->Vector(num_segments_dim), s_data_suffix, &out));\n  } else {\n    out = c->UnknownShape();\n  }\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nnamespace {\n\n// This SliceHelper processes the output shape of the `slice`\n// when the tensor of `sizes` is available.\ntemplate <typename T>\nStatus SliceHelper(InferenceContext* c, ShapeHandle begin_value,\n                   const Tensor* sizes_value,\n                   std::vector<DimensionHandle>* dims) {\n  auto sizes_vec = sizes_value->vec<T>();\n  for (int i = 0; i < sizes_value->NumElements(); ++i) {\n    DimensionHandle dim = c->Dim(c->input(0), i);\n    if (sizes_vec(i) != -1) {\n      auto dim_val = c->Value(dim);\n      if (sizes_vec(i) < 0) {\n        return errors::InvalidArgument(\n            \"Out of bounds slicing on dimension \", i, \" of length \", dim_val,\n            \": sizes vector cannot be < -1, but was \", sizes_vec(i));\n      }\n\n      dims->emplace_back(c->MakeDim(sizes_vec(i)));\n    } else {\n      DimensionHandle result;\n      TF_RETURN_IF_ERROR(c->Subtract(dim, c->Dim(begin_value, i), &result));\n      dims->emplace_back(result);\n    }\n  }\n\n  return Status::OK();\n}\n}  // namespace\n\nStatus SliceShape(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle begin_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &begin_shape));\n  ShapeHandle sizes_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &sizes_shape));\n\n  // Merge to check compatibility of begin and sizes tensors.\n  TF_RETURN_IF_ERROR(c->Merge(begin_shape, sizes_shape, &begin_shape));\n\n  DimensionHandle ndims = c->Dim(begin_shape, 0);\n  if (c->ValueKnown(ndims)) {\n    TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(ndims), &input));\n  }\n\n  // NOTE(mrry): Use MakeShapeFromShapeTensor to handle partially-known\n  // values, even though the `begin` value does not represent a shape.\n  ShapeHandle begin_value;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &begin_value));\n\n  // We check the tensor value here and will only use\n  // `MakeShapeFromShapeTensor` when `sizes_value` is null.\n  // The reason is that `sizes` might contain -1, which can't\n  // be represented (-1 in the ShapeHandle would mean \"unknown\").\n  const Tensor* sizes_value = c->input_tensor(2);\n\n  if (sizes_value != nullptr) {\n    TF_RETURN_IF_ERROR(\n        c->WithRank(begin_value, sizes_value->NumElements(), &begin_value));\n    std::vector<DimensionHandle> dims;\n    // If the begin and sizes tensors are available, then\n    // we can be precise about the shape of the output.\n    if (sizes_value->dtype() == DT_INT64) {\n      TF_RETURN_IF_ERROR(\n          SliceHelper<int64_t>(c, begin_value, sizes_value, &dims));\n    } else {\n      TF_RETURN_IF_ERROR(\n          SliceHelper<int32>(c, begin_value, sizes_value, &dims));\n    }\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  } else {\n    // In case `sizes` is not available (`sizes_value` is null),\n    // we could try to use `MakeShapeFromShapeTensor` here.\n    // If sizes contain -1, we will simply consider it as `Unknown`.\n    // This is less than ideal but still an improvement of shape inference.\n    // The following is an example that returns [None, 1, None] with this\n    // code path:\n    //   z = tf.zeros((1, 2, 3))\n    //   m = tf.slice(z, [0, 0, 0], [tf.constant(1) + 0, 1, -1])\n    //   m.get_shape().as_list()\n    ShapeHandle sizes_value;\n    TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &sizes_value));\n    if (c->RankKnown(sizes_value)) {\n      TF_RETURN_IF_ERROR(\n          c->WithRank(begin_value, c->Rank(sizes_value), &begin_value));\n      std::vector<DimensionHandle> dims;\n      dims.reserve(c->Rank(sizes_value));\n      for (int i = 0; i < c->Rank(sizes_value); ++i) {\n        dims.emplace_back(c->Dim(sizes_value, i));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    }\n    // We might know the rank of the input.\n    if (c->RankKnown(input)) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(input)));\n      return Status::OK();\n    } else {\n      return shape_inference::UnknownShape(c);\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus ValidateSparseTensor(InferenceContext* c, ShapeHandle indices_shape,\n                            ShapeHandle values_shape, ShapeHandle shape_shape) {\n  // Validate ranks.\n  ShapeHandle unused_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(indices_shape, 2, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(values_shape, 1, &unused_shape));\n  TF_RETURN_IF_ERROR(c->WithRank(shape_shape, 1, &unused_shape));\n\n  // Number of elements in indices and values must match.\n  DimensionHandle num_index_elements_dim = c->Dim(indices_shape, 0);\n  if (c->ValueKnown(num_index_elements_dim)) {\n    DimensionHandle num_values_elements_dim = c->Dim(values_shape, 0);\n    if (c->ValueKnown(num_values_elements_dim)) {\n      int64_t num_index_elements = c->Value(num_index_elements_dim);\n      int64_t num_values_elements = c->Value(num_values_elements_dim);\n      if (num_index_elements != num_values_elements) {\n        return errors::InvalidArgument(\"Number of elements in index (\",\n                                       num_index_elements, \") and values (\",\n                                       num_values_elements, \") do not match.\");\n      }\n    }\n  }\n\n  // Rank embedded in indices must match shape.\n  DimensionHandle index_rank_dim = c->Dim(indices_shape, 1);\n  if (c->ValueKnown(index_rank_dim)) {\n    DimensionHandle shape_rank_dim = c->Dim(shape_shape, 0);\n    if (c->ValueKnown(shape_rank_dim)) {\n      int64_t index_rank = c->Value(index_rank_dim);\n      int32_t shape_rank = c->Value(shape_rank_dim);\n      if (index_rank != shape_rank) {\n        return errors::InvalidArgument(\"Index rank (\", index_rank,\n                                       \") and shape rank (\", shape_rank,\n                                       \") do not match.\");\n      }\n    }\n  }\n\n  return Status::OK();\n}\n\nStatus ValidateVariableResourceHandle(\n    InferenceContext* c, std::vector<ShapeAndType>* shape_and_type) {\n  auto* handle_data = c->input_handle_shapes_and_types(0);\n  if (handle_data == nullptr || handle_data->empty()) {\n    shape_and_type->emplace_back(c->UnknownShape(), DT_INVALID);\n  } else {\n    *shape_and_type = *handle_data;\n    DataType value_dtype;\n    TF_RETURN_IF_ERROR(c->GetAttr(\"dtype\", &value_dtype));\n    if (shape_and_type->at(0).dtype != value_dtype) {\n      return errors::InvalidArgument(\n          \"Trying to read variable with wrong dtype. \"\n          \"Expected \",\n          DataTypeString(shape_and_type->at(0).dtype), \" got \",\n          DataTypeString(value_dtype));\n    }\n  }\n  return Status::OK();\n}\n\nStatus GatherNdShape(InferenceContext* c) {\n  ShapeHandle params;\n  std::vector<ShapeAndType> handle_shape_and_type;\n  if (c->input_handle_shapes_and_types(0) != nullptr) {\n    TF_RETURN_IF_ERROR(\n        ValidateVariableResourceHandle(c, &handle_shape_and_type));\n    params = handle_shape_and_type[0].shape;\n  } else {\n    params = c->input(0);\n  }\n  ShapeHandle indices;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &indices));\n  DimensionHandle r_dim = c->Dim(indices, -1);\n\n  if (!c->RankKnown(params) || !c->ValueKnown(r_dim)) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  if (c->Value(r_dim) > c->Rank(params)) {\n    return errors::InvalidArgument(\n        \"indices.shape[-1] must be <= params.rank, but saw indices shape: \",\n        c->DebugString(indices), \" and params shape: \", c->DebugString(params));\n  }\n\n  // Remove r_dim from indices to get output.\n  ShapeHandle indices_slice;\n  ShapeHandle params_slice;\n  TF_RETURN_IF_ERROR(c->Subshape(indices, 0, -1, &indices_slice));\n  TF_RETURN_IF_ERROR(c->Subshape(params, c->Value(r_dim), &params_slice));\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->Concatenate(indices_slice, params_slice, &out));\n  c->set_output(0, out);\n  return Status::OK();\n}\n\nStatus ScatterNdShapeHelper(InferenceContext* c, ShapeHandle indices_shape,\n                            ShapeHandle updates_shape,\n                            ShapeHandle input_shape) {\n  if (c->Value(c->NumElements(input_shape)) == 0 &&\n      (c->Value(c->NumElements(indices_shape)) > 0 ||\n       c->Value(c->NumElements(updates_shape)) > 0)) {\n    return errors::InvalidArgument(\n        \"Indices and updates specified for empty input\");\n  }\n\n  if (c->RankKnown(indices_shape) && c->RankKnown(updates_shape)) {\n    const int64_t outer_dims = c->Rank(indices_shape) - 1;\n    const DimensionHandle ixdim = c->Dim(indices_shape, -1);\n\n    // We can only do more validation if the last dimension of indices\n    // is a known value.\n    if (c->ValueKnown(ixdim)) {\n      int64_t ix = c->Value(ixdim);\n      ShapeHandle unused;\n      ShapeHandle prefix_indices;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(indices_shape, 0, outer_dims, &prefix_indices));\n      ShapeHandle prefix_updates;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(updates_shape, 0, outer_dims, &prefix_updates));\n\n      Status s = c->Merge(prefix_indices, prefix_updates, &unused);\n      if (!s.ok()) {\n        return errors::InvalidArgument(\n            \"Dimensions [0,\", outer_dims,\n            \") of indices[shape=\", c->DebugString(indices_shape),\n            \"] = \", c->DebugString(prefix_indices),\n            \" must match dimensions [0,\", outer_dims,\n            \") of updates[shape=\", c->DebugString(updates_shape),\n            \"] = \", c->DebugString(prefix_updates), \": \", s.error_message());\n      }\n\n      ShapeHandle suffix_output;\n      TF_RETURN_IF_ERROR(c->Subshape(input_shape, ix, &suffix_output));\n      ShapeHandle suffix_updates;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(updates_shape, outer_dims, &suffix_updates));\n      s = c->Merge(suffix_output, suffix_updates, &unused);\n      if (!s.ok()) {\n        return errors::InvalidArgument(\n            \"Dimensions [\", ix, \",\", c->Rank(input_shape),\n            \") of input[shape=\", c->DebugString(input_shape),\n            \"] = \", c->DebugString(suffix_output), \" must match dimensions [\",\n            outer_dims, \",\", c->Rank(updates_shape),\n            \") of updates[shape=\", c->DebugString(updates_shape),\n            \"] = \", c->DebugString(suffix_updates), \": \", s.error_message());\n      }\n    }\n  }\n\n  if (c->input_handle_shapes_and_types(0) == nullptr && c->num_outputs() > 0) {\n    // This is called for tf.scatter_nd; output is a tensor with this shape.\n    c->set_output(0, input_shape);\n  }\n  return Status::OK();\n}\n\nStatus ExplicitShape(InferenceContext* c) {\n  PartialTensorShape shape;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}\n\nStatus ExplicitShapes(InferenceContext* c) {\n  std::vector<PartialTensorShape> shapes;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"shapes\", &shapes));\n  if (shapes.empty()) {\n    return errors::Internal(\"shapes attribute is empty\");\n  }\n  for (int i = 0, end = shapes.size(); i < end; ++i) {\n    ShapeHandle output_shape;\n    TF_RETURN_IF_ERROR(\n        c->MakeShapeFromPartialTensorShape(shapes[i], &output_shape));\n    c->set_output(i, output_shape);\n  }\n  return Status::OK();\n}\n\nStatus SparseReduceShapeFn(InferenceContext* c) {\n  // Input 0: input_indices\n  // Input 1: input_values\n  // Input 2: input_shape\n  // Input 3: reduction_axes\n  // Attr: keep_dims\n  bool keep_dims = false;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* shape_tensor = c->input_tensor(2);\n  const Tensor* axes_tensor = c->input_tensor(3);\n  if (shape_tensor != nullptr && axes_tensor != nullptr) {\n    auto shape_vec = shape_tensor->flat<int64_t>();\n    auto axes_vec = axes_tensor->flat<int32>();\n\n    int64_t ndims = shape_vec.size();\n    absl::flat_hash_set<int64_t> axes;\n    if (ndims == 0)\n      return errors::InvalidArgument(\n          \"Number of dims in shape tensor must not be 0\");\n    for (int i = 0; i < axes_vec.size(); i++) {\n      axes.insert((axes_vec(i) + ndims) % ndims);\n    }\n\n    std::vector<DimensionHandle> dims;\n    if (keep_dims) {\n      dims.reserve(ndims);\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        } else {\n          dims.push_back(c->MakeDim(1));\n        }\n      }\n    } else {\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        }\n      }\n    }\n\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  return UnknownShape(c);\n}\n\nStatus QuantizedConv2DShape(InferenceContext* c) {\n  TF_RETURN_IF_ERROR(shape_inference::Conv2DShape(c));\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(4), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(5), 0, &unused));\n  c->set_output(1, c->Scalar());\n  c->set_output(2, c->Scalar());\n  return Status::OK();\n}\n\nStatus QuantizedAvgPoolShape(InferenceContext* c) {\n  TF_RETURN_IF_ERROR(shape_inference::AvgPoolShape(c));\n  ShapeHandle unused;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n  c->set_output(1, c->Scalar());\n  c->set_output(2, c->Scalar());\n  return Status::OK();\n}\n\nStatus QuantizeV2Shape(InferenceContext* c) {\n  int axis = -1;\n  Status s = c->GetAttr(\"axis\", &axis);\n  if (!s.ok() && s.code() != error::NOT_FOUND) {\n    return s;\n  }\n  if (axis < -1) {\n    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\n  }\n  const int minmax_rank = (axis == -1) ? 0 : 1;\n  TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n  ShapeHandle minmax;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n  if (axis != -1) {\n    ShapeHandle input;\n    TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n    DimensionHandle depth;\n    TF_RETURN_IF_ERROR(\n        c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n  }\n  c->set_output(1, minmax);\n  c->set_output(2, minmax);\n  return Status::OK();\n}\n\nStatus ReduceScatterShape(shape_inference::InferenceContext* c) {\n  shape_inference::ShapeHandle in = c->input(0);\n  if (!c->RankKnown(in)) {\n    // Input shape unknown, so set unknown output shape.\n    c->set_output(0, in);\n    return Status::OK();\n  }\n\n  shape_inference::ShapeHandle group_assignment_shape = c->input(1);\n  if (c->Rank(group_assignment_shape) != 2)\n    return errors::InvalidArgument(\n        \"ReduceScatter group_assignment should be rank 2\");\n\n  const Tensor* scatter_dimension = c->input_tensor(2);\n  if (!scatter_dimension) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n  int64_t scatter_dim;\n  TF_RETURN_IF_ERROR(c->GetScalarFromTensor(scatter_dimension, &scatter_dim));\n\n  std::vector<shape_inference::DimensionHandle> out_dims;\n  out_dims.reserve(c->Rank(in));\n  for (int i = 0; i < c->Rank(in); ++i) {\n    // If the dimension is the scatter_dimension, then divide the dimension\n    // by the partition size in the group_assignment.\n    if (i == scatter_dim) {\n      shape_inference::DimensionHandle dim = c->Dim(in, i);\n      shape_inference::DimensionHandle out_dim;\n      TF_RETURN_IF_ERROR(c->Divide(dim, c->Dim(group_assignment_shape, 1),\n                                   /*evenly_divisible=*/true, &out_dim));\n      out_dims.push_back(out_dim);\n    } else {\n      out_dims.emplace_back(c->Dim(in, i));\n    }\n  }\n  c->set_output(0, c->MakeShape(out_dims));\n  return Status::OK();\n}\n\n}  // namespace shape_inference\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/framework/common_shape_fns.cc"], "buggy_code_start_loc": [2561], "buggy_code_end_loc": [2561], "fixing_code_start_loc": [2562], "fixing_code_end_loc": [2565], "type": "CWE-125", "message": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference code for `QuantizeV2` can trigger a read outside of bounds of heap allocated array. This occurs whenever `axis` is a negative value less than `-1`. In this case, we are accessing data before the start of a heap buffer. The code allows `axis` to be an optional argument (`s` would contain an `error::NOT_FOUND` error code). Otherwise, it assumes that `axis` is a valid index into the dimensions of the `input` tensor. If `axis` is less than `-1` then this results in a heap OOB read. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected.", "other": {"cve": {"id": "CVE-2021-41211", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T21:15:08.813", "lastModified": "2021-11-09T15:14:04.520", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference code for `QuantizeV2` can trigger a read outside of bounds of heap allocated array. This occurs whenever `axis` is a negative value less than `-1`. In this case, we are accessing data before the start of a heap buffer. The code allows `axis` to be an optional argument (`s` would contain an `error::NOT_FOUND` error code). Otherwise, it assumes that `axis` is a valid index into the dimensions of the `input` tensor. If `axis` is less than `-1` then this results in a heap OOB read. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas, el c\u00f3digo de inferencia de forma para \"QuantizeV2\" puede desencadenar una lectura fuera de l\u00edmites de la matriz asignada a la pila. Esto ocurre siempre que el \"eje\" es un valor negativo menor que \"1\". En este caso, estamos accediendo a los datos antes del inicio de un buffer de heap. El c\u00f3digo permite que \"axis\" sea un argumento opcional (\"s\" contendr\u00eda un c\u00f3digo de error \"error::NOT_FOUND\"). En caso contrario, asume que \"axis\" es un \u00edndice v\u00e1lido en las dimensiones del tensor \"input\". Si \"axis\" es menor que \"-1\", se produce una lectura OOB de la pila. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n vamos a incluir este commit en TensorFlow versi\u00f3n 2.6.1, ya que esta versi\u00f3n es la \u00fanica que tambi\u00e9n est\u00e1 afectada"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 3.6}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:*:*:*:*:*:*:*", "matchCriteriaId": "651EA851-E660-4E53-9F3E-B6B69D91326B"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/a0d64445116c43cf46a5666bd4eee28e7a82f244", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-cvgx-3v3q-m36c", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/a0d64445116c43cf46a5666bd4eee28e7a82f244"}}