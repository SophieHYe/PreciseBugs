{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/image_ops.cc\n\n#include <cstdint>\n#include <memory>\n\n#define EIGEN_USE_THREADS\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/gif/gif_io.h\"\n#include \"tensorflow/core/lib/jpeg/jpeg_mem.h\"\n#include \"tensorflow/core/lib/png/png_io.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/platform/byte_order.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/util/tensor_bundle/byte_swap.h\"\n\nnamespace tensorflow {\nnamespace {\n\n// Magic bytes (hex) for each image format.\n// https://en.wikipedia.org/wiki/List_of_file_signatures\n// WARNING: Changing `static const` to `constexpr` requires first checking that\n// it works with supported MSVC version.\n// https://docs.microsoft.com/en-us/cpp/cpp/constexpr-cpp?redirectedfrom=MSDN&view=vs-2019\nstatic const char kPngMagicBytes[] = \"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\";\nstatic const char kGifMagicBytes[] = \"\\x47\\x49\\x46\\x38\";\nstatic const char kBmpMagicBytes[] = \"\\x42\\x4d\";\n// The 4th byte of JPEG is '\\xe0' or '\\xe1', so check just the first three.\nstatic const char kJpegMagicBytes[] = \"\\xff\\xd8\\xff\";\n\nenum FileFormat {\n  kUnknownFormat = 0,\n  kPngFormat = 1,\n  kJpgFormat = 2,\n  kGifFormat = 3,\n  kBmpFormat = 4,\n};\n\n// Classify the contents of a file based on starting bytes (the magic number).\nFileFormat ClassifyFileFormat(StringPiece data) {\n  if (absl::StartsWith(data, kJpegMagicBytes)) return kJpgFormat;\n  if (absl::StartsWith(data, kPngMagicBytes)) return kPngFormat;\n  if (absl::StartsWith(data, kGifMagicBytes)) return kGifFormat;\n  if (absl::StartsWith(data, kBmpMagicBytes)) return kBmpFormat;\n  return kUnknownFormat;\n}\n\n// Decode an image. Supported image formats are JPEG, PNG, GIF and BMP. This is\n// a newer version of `DecodeImageOp` for enabling image data parsing to take\n// place in kernels only, reducing security vulnerabilities and redundancy.\nclass DecodeImageV2Op : public OpKernel {\n public:\n  explicit DecodeImageV2Op(OpKernelConstruction* context) : OpKernel(context) {\n    // Keep track of op string information because:\n    // [1] Currently by the API, PNG, JPEG and GIF can decode each other and\n    //     depending on the op type, we need to return either 3-D or 4-D shapes.\n    // [2] Different ops have different attributes. e.g. `DecodeImage` op has\n    //     `expand_animations` attribute that other ops don't.\n    //     `DecodeAndDropJpeg` also has additional attributes.\n    op_type_ = type_string();\n\n    // Validate op type.\n    OP_REQUIRES(context,\n                op_type_ == \"DecodeJpeg\" || op_type_ == \"DecodeAndCropJpeg\" ||\n                    op_type_ == \"DecodePng\" || op_type_ == \"DecodeGif\" ||\n                    op_type_ == \"DecodeBmp\" || op_type_ == \"DecodeImage\",\n                errors::InvalidArgument(\"Bad op type \", op_type_));\n\n    // Get attributes from `DecodeJpeg` and `DecodeAndCropJpeg` op\n    // invocations. For `DecodeImage` op, set JPEG decoding setting to TF\n    // default.\n    if (op_type_ == \"DecodeJpeg\" || op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"ratio\", &flags_.ratio));\n      OP_REQUIRES(context,\n                  flags_.ratio == 1 || flags_.ratio == 2 || flags_.ratio == 4 ||\n                      flags_.ratio == 8,\n                  errors::InvalidArgument(\"ratio must be 1, 2, 4, or 8, got \",\n                                          flags_.ratio));\n      OP_REQUIRES_OK(context, context->GetAttr(\"fancy_upscaling\",\n                                               &flags_.fancy_upscaling));\n      OP_REQUIRES_OK(context,\n                     context->GetAttr(\"try_recover_truncated\",\n                                      &flags_.try_recover_truncated_jpeg));\n      OP_REQUIRES_OK(context,\n                     context->GetAttr(\"acceptable_fraction\",\n                                      &flags_.min_acceptable_fraction));\n      string dct_method;\n      OP_REQUIRES_OK(context, context->GetAttr(\"dct_method\", &dct_method));\n      OP_REQUIRES(\n          context,\n          (dct_method.empty() || dct_method == \"INTEGER_FAST\" ||\n           dct_method == \"INTEGER_ACCURATE\"),\n          errors::InvalidArgument(\"dct_method must be one of \"\n                                  \"{'', 'INTEGER_FAST', 'INTEGER_ACCURATE'}\"));\n      // The TensorFlow-chosen default for JPEG decoding is IFAST, sacrificing\n      // image quality for speed.\n      if (dct_method.empty() || dct_method == \"INTEGER_FAST\") {\n        flags_.dct_method = JDCT_IFAST;\n      } else if (dct_method == \"INTEGER_ACCURATE\") {\n        flags_.dct_method = JDCT_ISLOW;\n      }\n    } else {\n      flags_ = jpeg::UncompressFlags();\n      flags_.dct_method = JDCT_IFAST;\n    }\n\n    // Get `dtype` attribute from `DecodePng` or `DecodeImage` op invocations.\n    if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeImage\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"dtype\", &data_type_));\n      if (op_type_ == \"DecodePng\") {\n        OP_REQUIRES(\n            context,\n            data_type_ == DataType::DT_UINT8 ||\n                data_type_ == DataType::DT_UINT16,\n            errors::InvalidArgument(\n                \"`dtype` for `DecodePng` must be unit8, unit16 but got: \",\n                data_type_));\n      } else {\n        OP_REQUIRES(context,\n                    data_type_ == DataType::DT_UINT8 ||\n                        data_type_ == DataType::DT_UINT16 ||\n                        data_type_ == DataType::DT_FLOAT,\n                    errors::InvalidArgument(\"`dtype` for `DecodeImage` must be \"\n                                            \"unit8, unit16, float but got: \",\n                                            data_type_));\n        OP_REQUIRES_OK(context, context->GetAttr(\"expand_animations\",\n                                                 &expand_animations_));\n      }\n    }\n\n    // Get `channels` attribute for all ops except `DecodeGif` op.\n    // `DecodeGif` doesn't have `channels` attribute but it supports 3\n    // channels by default.\n    if (op_type_ != \"DecodeGif\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"channels\", &channels_));\n      OP_REQUIRES(\n          context,\n          channels_ == 0 || channels_ == 1 || channels_ == 3 || channels_ == 4,\n          errors::InvalidArgument(\"`channels` must be 0, 1, 3 or 4 but got \",\n                                  channels_));\n    } else {\n      channels_ = 3;\n    }\n  }\n\n  // Helper for decoding BMP.\n  inline int32 ByteSwapInt32ForBigEndian(int32_t x) {\n    if (!port::kLittleEndian) {\n      return BYTE_SWAP_32(x);\n    } else {\n      return x;\n    }\n  }\n\n  // Helper for decoding BMP.\n  inline int16 ByteSwapInt16ForBigEndian(int16_t x) {\n    if (!port::kLittleEndian) {\n      return BYTE_SWAP_16(x);\n    } else {\n      return x;\n    }\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& contents = context->input(0);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(contents.shape()),\n        errors::InvalidArgument(\"`contents` must be scalar but got shape\",\n                                contents.shape().DebugString()));\n    const StringPiece input = contents.scalar<tstring>()();\n    OP_REQUIRES(context, !input.empty(),\n                errors::InvalidArgument(\"Input is empty.\"));\n    OP_REQUIRES(context, input.size() <= std::numeric_limits<int>::max(),\n                errors::InvalidArgument(\n                    \"Input contents are too large for int: \", input.size()));\n\n    // Parse magic bytes to determine file format.\n    switch (ClassifyFileFormat(input)) {\n      case kJpgFormat:\n        DecodeJpegV2(context, input);\n        break;\n      case kPngFormat:\n        DecodePngV2(context, input);\n        break;\n      case kGifFormat:\n        DecodeGifV2(context, input);\n        break;\n      case kBmpFormat:\n        DecodeBmpV2(context, input);\n        break;\n      case kUnknownFormat:\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\"Unknown image file format. One of \"\n                                            \"JPEG, PNG, GIF, BMP required.\"));\n        break;\n    }\n  }\n\n  void DecodeJpegV2(OpKernelContext* context, StringPiece input) {\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 1 || channels_ == 3,\n                errors::InvalidArgument(\"JPEG does not support 4 channels\"));\n\n    // Use local copy of flags to avoid race condition as the class member is\n    // shared among different invocations.\n    jpeg::UncompressFlags flags = flags_;\n    flags.components = channels_;\n\n    if (op_type_ == \"DecodeAndCropJpeg\") {\n      flags.crop = true;\n      // Update flags to include crop window.\n      const Tensor& crop_window = context->input(1);\n      OP_REQUIRES(context, crop_window.dims() == 1,\n                  errors::InvalidArgument(\"crop_window must be 1-D, got shape \",\n                                          crop_window.shape().DebugString()));\n      OP_REQUIRES(context, crop_window.dim_size(0) == 4,\n                  errors::InvalidArgument(\"crop_size must have four elements \",\n                                          crop_window.shape().DebugString()));\n      auto crop_window_vec = crop_window.vec<int32>();\n      flags.crop_y = crop_window_vec(0);\n      flags.crop_x = crop_window_vec(1);\n      flags.crop_height = crop_window_vec(2);\n      flags.crop_width = crop_window_vec(3);\n    } else if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode JPEG format using DecodeBmp op. Use \"\n                      \"`decode_jpeg` or `decode_image` instead.\"));\n    }\n\n    // Output tensor and the image buffer size.\n    Tensor* output = nullptr;\n    int buffer_size = 0;\n\n    // Decode JPEG. Directly allocate to the output buffer if data type is\n    // uint8 (to save extra copying). Otherwise, allocate a new uint8 buffer\n    // with buffer size. `jpeg::Uncompress` supports unit8 only.\n    uint8* buffer = jpeg::Uncompress(\n        input.data(), input.size(), flags, nullptr /* nwarn */,\n        [&](int width, int height, int channels) -> uint8* {\n          buffer_size = height * width * channels;\n          Status status;\n          // By the existing API, we support decoding JPEG with `DecodeGif`\n          // op. We need to make sure to return 4-D shapes when using\n          // `DecodeGif`.\n          if (op_type_ == \"DecodeGif\") {\n            status = context->allocate_output(\n                0, TensorShape({1, height, width, channels}), &output);\n          } else {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        });\n\n    OP_REQUIRES(\n        context, buffer,\n        errors::InvalidArgument(\n            \"jpeg::Uncompress failed. Invalid JPEG data or crop window.\"));\n\n    // For when desired data type if unit8, the output buffer is already\n    // allocated during the `jpeg::Uncompress` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert uint8 image data to desired data type.\n    // Use eigen threadpooling to speed up the copy operation.\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }\n\n  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      png::CommonFreeDecode(&decode);\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }\n\n  void DecodeGifV2(OpKernelContext* context, StringPiece input) {\n    // GIF has 3 channels.\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        channels_));\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    // Decode GIF, allocating tensor if dtype is uint8, otherwise defer tensor\n    // allocation til after dtype conversion is done. `gif`::Decode` supports\n    // uint8 only.\n    Tensor* output = nullptr;\n    int buffer_size = 0;\n    string error_string;\n    uint8* buffer = gif::Decode(\n        input.data(), input.size(),\n        [&](int num_frames, int width, int height, int channels) -> uint8* {\n          buffer_size = num_frames * height * width * channels;\n\n          Status status;\n          // By the existing API, we support decoding GIF with `decode_jpeg` or\n          // with `decode_png` if the GIF is a single-frame GIF (non-animated).\n          // We need to make sure to return 3-D shapes when using in this case.\n          if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeJpeg\") {\n            if (num_frames == 1) {\n              status = context->allocate_output(\n                  0, TensorShape({height, width, channels}), &output);\n            } else {\n              status = errors::InvalidArgument(\n                  \"Got \", num_frames, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (op_type_ == \"DecodeGif\" ||\n                     (op_type_ == \"DecodeImage\" && expand_animations_)) {\n            status = context->allocate_output(\n                0, TensorShape({num_frames, height, width, channels}), &output);\n          } else if (op_type_ == \"DecodeImage\" && !expand_animations_) {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          } else {\n            status = errors::InvalidArgument(\"Bad op type \", op_type_);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        },\n        &error_string, expand_animations_);\n\n    OP_REQUIRES(context, buffer,\n                errors::InvalidArgument(\"Invalid GIF data (size \", input.size(),\n                                        \"), \", error_string));\n\n    // For when desired data type is uint8, the output buffer is already\n    // allocated during the `gif::Decode` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert the raw uint8 buffer to desired dtype.\n    // Use eigen threadpooling to speed up the copy operation.\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }\n\n  void DecodeBmpV2(OpKernelContext* context, StringPiece input) {\n    OP_REQUIRES(\n        context, channels_ != 1,\n        errors::InvalidArgument(\n            \"`channels` must be 0, 3 or 4 for BMP, but got \", channels_));\n\n    if (op_type_ != \"DecodeBmp\" && op_type_ != \"DecodeImage\") {\n      if (op_type_ == \"DecodeAndCropJpeg\") {\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\n                        \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                        \"detected BMP.\"));\n      } else {\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\n                        \"Trying to decode BMP format using a wrong op. Use \"\n                        \"`decode_bmp` or `decode_image` instead. Op used: \",\n                        op_type_));\n      }\n    }\n\n    OP_REQUIRES(context, (32 <= input.size()),\n                errors::InvalidArgument(\"Incomplete bmp content, requires at \"\n                                        \"least 32 bytes to find the header \"\n                                        \"size, width, height, and bpp, got \",\n                                        input.size(), \" bytes\"));\n\n    const uint8* img_bytes = reinterpret_cast<const uint8*>(input.data());\n    int32_t header_size_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 10)));\n    const int32_t header_size = ByteSwapInt32ForBigEndian(header_size_);\n    int32_t width_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 18)));\n    const int32_t width = ByteSwapInt32ForBigEndian(width_);\n    int32_t height_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 22)));\n    const int32_t height = ByteSwapInt32ForBigEndian(height_);\n    int16_t bpp_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int16*>(img_bytes + 28)));\n    const int16_t bpp = ByteSwapInt16ForBigEndian(bpp_);\n\n    // `channels_` is desired number of channels. `img_channels` is number of\n    // channels inherent in the image.\n    int img_channels = bpp / 8;\n    OP_REQUIRES(\n        context, (img_channels == 1 || img_channels == 3 || img_channels == 4),\n        errors::InvalidArgument(\n            \"Number of channels inherent in the image must be 1, 3 or 4, was \",\n            img_channels));\n    const int requested_channels = channels_ ? channels_ : img_channels;\n\n    OP_REQUIRES(context, width > 0,\n                errors::InvalidArgument(\"Width must be positive\"));\n    OP_REQUIRES(context, height != 0,\n                errors::InvalidArgument(\"Height must be nonzero\"));\n    OP_REQUIRES(context, header_size >= 0,\n                errors::InvalidArgument(\"header size must be nonnegative\"));\n\n    // The real requirement is < 2^31 minus some headers and channel data,\n    // so rounding down to something that's still ridiculously big.\n    OP_REQUIRES(\n        context,\n        (static_cast<int64_t>(width) * std::abs(static_cast<int64_t>(height))) <\n            static_cast<int64_t>(std::numeric_limits<int32_t>::max() / 8),\n        errors::InvalidArgument(\n            \"Total possible pixel bytes must be less than 2^30\"));\n\n    const int32_t abs_height = abs(height);\n\n    // there may be padding bytes when the width is not a multiple of 4 bytes\n    const int row_size = (img_channels * width + 3) / 4 * 4;\n\n    // Make sure the size of input data matches up with the total size of\n    // headers plus height * row_size.\n    int size_diff = input.size() - header_size - (row_size * abs_height);\n    OP_REQUIRES(\n        context, size_diff == 0,\n        errors::InvalidArgument(\n            \"Input size should match (header_size + row_size * abs_height) but \"\n            \"they differ by \",\n            size_diff));\n\n    const int64_t last_pixel_offset = static_cast<int64_t>(header_size) +\n                                      (abs_height - 1) * row_size +\n                                      (width - 1) * img_channels;\n\n    // [expected file size] = [last pixel offset] + [last pixel size=channels]\n    const int64_t expected_file_size = last_pixel_offset + img_channels;\n\n    OP_REQUIRES(\n        context, (expected_file_size <= input.size()),\n        errors::InvalidArgument(\"Incomplete bmp content, requires at least \",\n                                expected_file_size, \" bytes, got \",\n                                input.size(), \" bytes\"));\n\n    // if height is negative, data layout is top down\n    // otherwise, it's bottom up.\n    bool top_down = (height < 0);\n\n    // Decode image, allocating tensor once the image size is known.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({abs_height, width, requested_channels}), &output));\n\n    const uint8* bmp_pixels = &img_bytes[header_size];\n\n    if (data_type_ == DataType::DT_UINT8) {\n      DecodeBMP(bmp_pixels, row_size, output->flat<uint8>().data(), width,\n                abs_height, requested_channels, img_channels, top_down);\n    } else {\n      std::unique_ptr<uint8[]> buffer(\n          new uint8[height * width * requested_channels]);\n      DecodeBMP(bmp_pixels, row_size, buffer.get(), width, abs_height,\n                requested_channels, img_channels, top_down);\n      TTypes<uint8, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                 requested_channels);\n      // Convert the raw uint8 buffer to desired dtype.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      if (data_type_ == DataType::DT_UINT16) {\n        uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                             (std::numeric_limits<uint8>::max() + 1));\n        // Fill output tensor with desired dtype.\n        output->tensor<uint16, 3>().device(device) = buf.cast<uint16>() * scale;\n      } else if (data_type_ == DataType::DT_FLOAT) {\n        float scale = 1. / std::numeric_limits<uint8>::max();\n        // Fill output tensor with desired dtype.\n        output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n      }\n    }\n  }\n\n private:\n  void DecodeBMP(const uint8* input, const int row_size, uint8* const output,\n                 const int width, const int height, const int output_channels,\n                 const int input_channels, bool top_down);\n\n  int channels_ = 0;\n  DataType data_type_ = DataType::DT_UINT8;\n  bool expand_animations_ = true;\n  jpeg::UncompressFlags flags_;\n  string op_type_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"DecodeJpeg\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodePng\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeGif\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeAndCropJpeg\").Device(DEVICE_CPU),\n                        DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeImage\").Device(DEVICE_CPU),\n                        DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeBmp\").Device(DEVICE_CPU), DecodeImageV2Op);\n\nvoid DecodeImageV2Op::DecodeBMP(const uint8* input, const int row_size,\n                                uint8* const output, const int width,\n                                const int height, const int output_channels,\n                                const int input_channels, bool top_down) {\n  for (int i = 0; i < height; i++) {\n    int src_pos;\n    int dst_pos;\n\n    for (int j = 0; j < width; j++) {\n      if (!top_down) {\n        src_pos = ((height - 1 - i) * row_size) + j * input_channels;\n      } else {\n        src_pos = i * row_size + j * input_channels;\n      }\n\n      dst_pos = (i * width + j) * output_channels;\n\n      switch (input_channels) {\n        case 1:\n          output[dst_pos] = input[src_pos];\n          // Set 2nd and 3rd channels if user requested for 3 or 4 channels.\n          // Repeat 1st channel's value.\n          if (output_channels == 3 || output_channels == 4) {\n            output[dst_pos + 1] = input[src_pos];\n            output[dst_pos + 2] = input[src_pos];\n          }\n          // Set 4th channel (alpha) to maximum value if user requested for\n          // 4 channels.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = UINT8_MAX;\n          }\n          break;\n        case 3:\n          // BGR -> RGB\n          output[dst_pos] = input[src_pos + 2];\n          output[dst_pos + 1] = input[src_pos + 1];\n          output[dst_pos + 2] = input[src_pos];\n          // Set 4th channel (alpha) to maximum value if the user requested for\n          // 4 channels and the input image has 3 channels only.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = UINT8_MAX;\n          }\n          break;\n        case 4:\n          // BGRA -> RGBA\n          output[dst_pos] = input[src_pos + 2];\n          output[dst_pos + 1] = input[src_pos + 1];\n          output[dst_pos + 2] = input[src_pos];\n          // Set 4th channel only if the user requested for 4 channels. If not,\n          // then user requested 3 channels; skip this step.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = input[src_pos + 3];\n          }\n          break;\n        default:\n          LOG(FATAL) << \"Unexpected number of channels: \" << input_channels;\n          break;\n      }\n    }\n  }\n}\n\n}  // namespace\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/image_ops.cc\n\n#include <cstdint>\n#include <memory>\n\n#define EIGEN_USE_THREADS\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/gif/gif_io.h\"\n#include \"tensorflow/core/lib/jpeg/jpeg_mem.h\"\n#include \"tensorflow/core/lib/png/png_io.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/platform/byte_order.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/util/tensor_bundle/byte_swap.h\"\n\nnamespace tensorflow {\nnamespace {\n\n// Magic bytes (hex) for each image format.\n// https://en.wikipedia.org/wiki/List_of_file_signatures\n// WARNING: Changing `static const` to `constexpr` requires first checking that\n// it works with supported MSVC version.\n// https://docs.microsoft.com/en-us/cpp/cpp/constexpr-cpp?redirectedfrom=MSDN&view=vs-2019\nstatic const char kPngMagicBytes[] = \"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\";\nstatic const char kGifMagicBytes[] = \"\\x47\\x49\\x46\\x38\";\nstatic const char kBmpMagicBytes[] = \"\\x42\\x4d\";\n// The 4th byte of JPEG is '\\xe0' or '\\xe1', so check just the first three.\nstatic const char kJpegMagicBytes[] = \"\\xff\\xd8\\xff\";\n\nenum FileFormat {\n  kUnknownFormat = 0,\n  kPngFormat = 1,\n  kJpgFormat = 2,\n  kGifFormat = 3,\n  kBmpFormat = 4,\n};\n\n// Classify the contents of a file based on starting bytes (the magic number).\nFileFormat ClassifyFileFormat(StringPiece data) {\n  if (absl::StartsWith(data, kJpegMagicBytes)) return kJpgFormat;\n  if (absl::StartsWith(data, kPngMagicBytes)) return kPngFormat;\n  if (absl::StartsWith(data, kGifMagicBytes)) return kGifFormat;\n  if (absl::StartsWith(data, kBmpMagicBytes)) return kBmpFormat;\n  return kUnknownFormat;\n}\n\n// Decode an image. Supported image formats are JPEG, PNG, GIF and BMP. This is\n// a newer version of `DecodeImageOp` for enabling image data parsing to take\n// place in kernels only, reducing security vulnerabilities and redundancy.\nclass DecodeImageV2Op : public OpKernel {\n public:\n  explicit DecodeImageV2Op(OpKernelConstruction* context) : OpKernel(context) {\n    // Keep track of op string information because:\n    // [1] Currently by the API, PNG, JPEG and GIF can decode each other and\n    //     depending on the op type, we need to return either 3-D or 4-D shapes.\n    // [2] Different ops have different attributes. e.g. `DecodeImage` op has\n    //     `expand_animations` attribute that other ops don't.\n    //     `DecodeAndDropJpeg` also has additional attributes.\n    op_type_ = type_string();\n\n    // Validate op type.\n    OP_REQUIRES(context,\n                op_type_ == \"DecodeJpeg\" || op_type_ == \"DecodeAndCropJpeg\" ||\n                    op_type_ == \"DecodePng\" || op_type_ == \"DecodeGif\" ||\n                    op_type_ == \"DecodeBmp\" || op_type_ == \"DecodeImage\",\n                errors::InvalidArgument(\"Bad op type \", op_type_));\n\n    // Get attributes from `DecodeJpeg` and `DecodeAndCropJpeg` op\n    // invocations. For `DecodeImage` op, set JPEG decoding setting to TF\n    // default.\n    if (op_type_ == \"DecodeJpeg\" || op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"ratio\", &flags_.ratio));\n      OP_REQUIRES(context,\n                  flags_.ratio == 1 || flags_.ratio == 2 || flags_.ratio == 4 ||\n                      flags_.ratio == 8,\n                  errors::InvalidArgument(\"ratio must be 1, 2, 4, or 8, got \",\n                                          flags_.ratio));\n      OP_REQUIRES_OK(context, context->GetAttr(\"fancy_upscaling\",\n                                               &flags_.fancy_upscaling));\n      OP_REQUIRES_OK(context,\n                     context->GetAttr(\"try_recover_truncated\",\n                                      &flags_.try_recover_truncated_jpeg));\n      OP_REQUIRES_OK(context,\n                     context->GetAttr(\"acceptable_fraction\",\n                                      &flags_.min_acceptable_fraction));\n      string dct_method;\n      OP_REQUIRES_OK(context, context->GetAttr(\"dct_method\", &dct_method));\n      OP_REQUIRES(\n          context,\n          (dct_method.empty() || dct_method == \"INTEGER_FAST\" ||\n           dct_method == \"INTEGER_ACCURATE\"),\n          errors::InvalidArgument(\"dct_method must be one of \"\n                                  \"{'', 'INTEGER_FAST', 'INTEGER_ACCURATE'}\"));\n      // The TensorFlow-chosen default for JPEG decoding is IFAST, sacrificing\n      // image quality for speed.\n      if (dct_method.empty() || dct_method == \"INTEGER_FAST\") {\n        flags_.dct_method = JDCT_IFAST;\n      } else if (dct_method == \"INTEGER_ACCURATE\") {\n        flags_.dct_method = JDCT_ISLOW;\n      }\n    } else {\n      flags_ = jpeg::UncompressFlags();\n      flags_.dct_method = JDCT_IFAST;\n    }\n\n    // Get `dtype` attribute from `DecodePng` or `DecodeImage` op invocations.\n    if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeImage\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"dtype\", &data_type_));\n      if (op_type_ == \"DecodePng\") {\n        OP_REQUIRES(\n            context,\n            data_type_ == DataType::DT_UINT8 ||\n                data_type_ == DataType::DT_UINT16,\n            errors::InvalidArgument(\n                \"`dtype` for `DecodePng` must be unit8, unit16 but got: \",\n                data_type_));\n      } else {\n        OP_REQUIRES(context,\n                    data_type_ == DataType::DT_UINT8 ||\n                        data_type_ == DataType::DT_UINT16 ||\n                        data_type_ == DataType::DT_FLOAT,\n                    errors::InvalidArgument(\"`dtype` for `DecodeImage` must be \"\n                                            \"unit8, unit16, float but got: \",\n                                            data_type_));\n        OP_REQUIRES_OK(context, context->GetAttr(\"expand_animations\",\n                                                 &expand_animations_));\n      }\n    }\n\n    // Get `channels` attribute for all ops except `DecodeGif` op.\n    // `DecodeGif` doesn't have `channels` attribute but it supports 3\n    // channels by default.\n    if (op_type_ != \"DecodeGif\") {\n      OP_REQUIRES_OK(context, context->GetAttr(\"channels\", &channels_));\n      OP_REQUIRES(\n          context,\n          channels_ == 0 || channels_ == 1 || channels_ == 3 || channels_ == 4,\n          errors::InvalidArgument(\"`channels` must be 0, 1, 3 or 4 but got \",\n                                  channels_));\n    } else {\n      channels_ = 3;\n    }\n  }\n\n  // Helper for decoding BMP.\n  inline int32 ByteSwapInt32ForBigEndian(int32_t x) {\n    if (!port::kLittleEndian) {\n      return BYTE_SWAP_32(x);\n    } else {\n      return x;\n    }\n  }\n\n  // Helper for decoding BMP.\n  inline int16 ByteSwapInt16ForBigEndian(int16_t x) {\n    if (!port::kLittleEndian) {\n      return BYTE_SWAP_16(x);\n    } else {\n      return x;\n    }\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& contents = context->input(0);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(contents.shape()),\n        errors::InvalidArgument(\"`contents` must be scalar but got shape\",\n                                contents.shape().DebugString()));\n    const StringPiece input = contents.scalar<tstring>()();\n    OP_REQUIRES(context, !input.empty(),\n                errors::InvalidArgument(\"Input is empty.\"));\n    OP_REQUIRES(context, input.size() <= std::numeric_limits<int>::max(),\n                errors::InvalidArgument(\n                    \"Input contents are too large for int: \", input.size()));\n\n    // Parse magic bytes to determine file format.\n    switch (ClassifyFileFormat(input)) {\n      case kJpgFormat:\n        DecodeJpegV2(context, input);\n        break;\n      case kPngFormat:\n        DecodePngV2(context, input);\n        break;\n      case kGifFormat:\n        DecodeGifV2(context, input);\n        break;\n      case kBmpFormat:\n        DecodeBmpV2(context, input);\n        break;\n      case kUnknownFormat:\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\"Unknown image file format. One of \"\n                                            \"JPEG, PNG, GIF, BMP required.\"));\n        break;\n    }\n  }\n\n  void DecodeJpegV2(OpKernelContext* context, StringPiece input) {\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 1 || channels_ == 3,\n                errors::InvalidArgument(\"JPEG does not support 4 channels\"));\n\n    // Use local copy of flags to avoid race condition as the class member is\n    // shared among different invocations.\n    jpeg::UncompressFlags flags = flags_;\n    flags.components = channels_;\n\n    if (op_type_ == \"DecodeAndCropJpeg\") {\n      flags.crop = true;\n      // Update flags to include crop window.\n      const Tensor& crop_window = context->input(1);\n      OP_REQUIRES(context, crop_window.dims() == 1,\n                  errors::InvalidArgument(\"crop_window must be 1-D, got shape \",\n                                          crop_window.shape().DebugString()));\n      OP_REQUIRES(context, crop_window.dim_size(0) == 4,\n                  errors::InvalidArgument(\"crop_size must have four elements \",\n                                          crop_window.shape().DebugString()));\n      auto crop_window_vec = crop_window.vec<int32>();\n      flags.crop_y = crop_window_vec(0);\n      flags.crop_x = crop_window_vec(1);\n      flags.crop_height = crop_window_vec(2);\n      flags.crop_width = crop_window_vec(3);\n    } else if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode JPEG format using DecodeBmp op. Use \"\n                      \"`decode_jpeg` or `decode_image` instead.\"));\n    }\n\n    // Output tensor and the image buffer size.\n    Tensor* output = nullptr;\n    int buffer_size = 0;\n\n    // Decode JPEG. Directly allocate to the output buffer if data type is\n    // uint8 (to save extra copying). Otherwise, allocate a new uint8 buffer\n    // with buffer size. `jpeg::Uncompress` supports unit8 only.\n    uint8* buffer = jpeg::Uncompress(\n        input.data(), input.size(), flags, nullptr /* nwarn */,\n        [&](int width, int height, int channels) -> uint8* {\n          buffer_size = height * width * channels;\n          Status status;\n          // By the existing API, we support decoding JPEG with `DecodeGif`\n          // op. We need to make sure to return 4-D shapes when using\n          // `DecodeGif`.\n          if (op_type_ == \"DecodeGif\") {\n            status = context->allocate_output(\n                0, TensorShape({1, height, width, channels}), &output);\n          } else {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        });\n\n    OP_REQUIRES(\n        context, buffer,\n        errors::InvalidArgument(\n            \"jpeg::Uncompress failed. Invalid JPEG data or crop window.\"));\n\n    // For when desired data type if unit8, the output buffer is already\n    // allocated during the `jpeg::Uncompress` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert uint8 image data to desired data type.\n    // Use eigen threadpooling to speed up the copy operation.\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }\n\n  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }\n\n  void DecodeGifV2(OpKernelContext* context, StringPiece input) {\n    // GIF has 3 channels.\n    OP_REQUIRES(context, channels_ == 0 || channels_ == 3,\n                errors::InvalidArgument(\"channels must be 0 or 3 for GIF, got \",\n                                        channels_));\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode GIF format using DecodeBmp op. Use \"\n                      \"`decode_gif` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected GIF.\"));\n    }\n\n    // Decode GIF, allocating tensor if dtype is uint8, otherwise defer tensor\n    // allocation til after dtype conversion is done. `gif`::Decode` supports\n    // uint8 only.\n    Tensor* output = nullptr;\n    int buffer_size = 0;\n    string error_string;\n    uint8* buffer = gif::Decode(\n        input.data(), input.size(),\n        [&](int num_frames, int width, int height, int channels) -> uint8* {\n          buffer_size = num_frames * height * width * channels;\n\n          Status status;\n          // By the existing API, we support decoding GIF with `decode_jpeg` or\n          // with `decode_png` if the GIF is a single-frame GIF (non-animated).\n          // We need to make sure to return 3-D shapes when using in this case.\n          if (op_type_ == \"DecodePng\" || op_type_ == \"DecodeJpeg\") {\n            if (num_frames == 1) {\n              status = context->allocate_output(\n                  0, TensorShape({height, width, channels}), &output);\n            } else {\n              status = errors::InvalidArgument(\n                  \"Got \", num_frames, \" frames, but animated gifs \",\n                  \"can only be decoded by tf.io.decode_gif or \",\n                  \"tf.io.decode_image\");\n            }\n          } else if (op_type_ == \"DecodeGif\" ||\n                     (op_type_ == \"DecodeImage\" && expand_animations_)) {\n            status = context->allocate_output(\n                0, TensorShape({num_frames, height, width, channels}), &output);\n          } else if (op_type_ == \"DecodeImage\" && !expand_animations_) {\n            status = context->allocate_output(\n                0, TensorShape({height, width, channels}), &output);\n          } else {\n            status = errors::InvalidArgument(\"Bad op type \", op_type_);\n          }\n          if (!status.ok()) {\n            VLOG(1) << status;\n            context->SetStatus(status);\n            return nullptr;\n          }\n\n          if (data_type_ == DataType::DT_UINT8) {\n            return output->flat<uint8>().data();\n          } else {\n            return new uint8[buffer_size];\n          }\n        },\n        &error_string, expand_animations_);\n\n    OP_REQUIRES(context, buffer,\n                errors::InvalidArgument(\"Invalid GIF data (size \", input.size(),\n                                        \"), \", error_string));\n\n    // For when desired data type is uint8, the output buffer is already\n    // allocated during the `gif::Decode` call above; return.\n    if (data_type_ == DataType::DT_UINT8) {\n      return;\n    }\n    // Make sure we don't forget to deallocate `buffer`.\n    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n\n    // Convert the raw uint8 buffer to desired dtype.\n    // Use eigen threadpooling to speed up the copy operation.\n    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n    const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n    if (data_type_ == DataType::DT_UINT16) {\n      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                           (std::numeric_limits<uint8>::max() + 1));\n      // Fill output tensor with desired dtype.\n      output->flat<uint16>().device(device) =\n          buffer_view.cast<uint16>() * scale;\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      float scale = 1. / std::numeric_limits<uint8>::max();\n      // Fill output tensor with desired dtype.\n      output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n    }\n  }\n\n  void DecodeBmpV2(OpKernelContext* context, StringPiece input) {\n    OP_REQUIRES(\n        context, channels_ != 1,\n        errors::InvalidArgument(\n            \"`channels` must be 0, 3 or 4 for BMP, but got \", channels_));\n\n    if (op_type_ != \"DecodeBmp\" && op_type_ != \"DecodeImage\") {\n      if (op_type_ == \"DecodeAndCropJpeg\") {\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\n                        \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                        \"detected BMP.\"));\n      } else {\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\n                        \"Trying to decode BMP format using a wrong op. Use \"\n                        \"`decode_bmp` or `decode_image` instead. Op used: \",\n                        op_type_));\n      }\n    }\n\n    OP_REQUIRES(context, (32 <= input.size()),\n                errors::InvalidArgument(\"Incomplete bmp content, requires at \"\n                                        \"least 32 bytes to find the header \"\n                                        \"size, width, height, and bpp, got \",\n                                        input.size(), \" bytes\"));\n\n    const uint8* img_bytes = reinterpret_cast<const uint8*>(input.data());\n    int32_t header_size_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 10)));\n    const int32_t header_size = ByteSwapInt32ForBigEndian(header_size_);\n    int32_t width_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 18)));\n    const int32_t width = ByteSwapInt32ForBigEndian(width_);\n    int32_t height_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int32*>(img_bytes + 22)));\n    const int32_t height = ByteSwapInt32ForBigEndian(height_);\n    int16_t bpp_ = internal::SubtleMustCopy(\n        *(reinterpret_cast<const int16*>(img_bytes + 28)));\n    const int16_t bpp = ByteSwapInt16ForBigEndian(bpp_);\n\n    // `channels_` is desired number of channels. `img_channels` is number of\n    // channels inherent in the image.\n    int img_channels = bpp / 8;\n    OP_REQUIRES(\n        context, (img_channels == 1 || img_channels == 3 || img_channels == 4),\n        errors::InvalidArgument(\n            \"Number of channels inherent in the image must be 1, 3 or 4, was \",\n            img_channels));\n    const int requested_channels = channels_ ? channels_ : img_channels;\n\n    OP_REQUIRES(context, width > 0,\n                errors::InvalidArgument(\"Width must be positive\"));\n    OP_REQUIRES(context, height != 0,\n                errors::InvalidArgument(\"Height must be nonzero\"));\n    OP_REQUIRES(context, header_size >= 0,\n                errors::InvalidArgument(\"header size must be nonnegative\"));\n\n    // The real requirement is < 2^31 minus some headers and channel data,\n    // so rounding down to something that's still ridiculously big.\n    OP_REQUIRES(\n        context,\n        (static_cast<int64_t>(width) * std::abs(static_cast<int64_t>(height))) <\n            static_cast<int64_t>(std::numeric_limits<int32_t>::max() / 8),\n        errors::InvalidArgument(\n            \"Total possible pixel bytes must be less than 2^30\"));\n\n    const int32_t abs_height = abs(height);\n\n    // there may be padding bytes when the width is not a multiple of 4 bytes\n    const int row_size = (img_channels * width + 3) / 4 * 4;\n\n    // Make sure the size of input data matches up with the total size of\n    // headers plus height * row_size.\n    int size_diff = input.size() - header_size - (row_size * abs_height);\n    OP_REQUIRES(\n        context, size_diff == 0,\n        errors::InvalidArgument(\n            \"Input size should match (header_size + row_size * abs_height) but \"\n            \"they differ by \",\n            size_diff));\n\n    const int64_t last_pixel_offset = static_cast<int64_t>(header_size) +\n                                      (abs_height - 1) * row_size +\n                                      (width - 1) * img_channels;\n\n    // [expected file size] = [last pixel offset] + [last pixel size=channels]\n    const int64_t expected_file_size = last_pixel_offset + img_channels;\n\n    OP_REQUIRES(\n        context, (expected_file_size <= input.size()),\n        errors::InvalidArgument(\"Incomplete bmp content, requires at least \",\n                                expected_file_size, \" bytes, got \",\n                                input.size(), \" bytes\"));\n\n    // if height is negative, data layout is top down\n    // otherwise, it's bottom up.\n    bool top_down = (height < 0);\n\n    // Decode image, allocating tensor once the image size is known.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({abs_height, width, requested_channels}), &output));\n\n    const uint8* bmp_pixels = &img_bytes[header_size];\n\n    if (data_type_ == DataType::DT_UINT8) {\n      DecodeBMP(bmp_pixels, row_size, output->flat<uint8>().data(), width,\n                abs_height, requested_channels, img_channels, top_down);\n    } else {\n      std::unique_ptr<uint8[]> buffer(\n          new uint8[height * width * requested_channels]);\n      DecodeBMP(bmp_pixels, row_size, buffer.get(), width, abs_height,\n                requested_channels, img_channels, top_down);\n      TTypes<uint8, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                 requested_channels);\n      // Convert the raw uint8 buffer to desired dtype.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      if (data_type_ == DataType::DT_UINT16) {\n        uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n                             (std::numeric_limits<uint8>::max() + 1));\n        // Fill output tensor with desired dtype.\n        output->tensor<uint16, 3>().device(device) = buf.cast<uint16>() * scale;\n      } else if (data_type_ == DataType::DT_FLOAT) {\n        float scale = 1. / std::numeric_limits<uint8>::max();\n        // Fill output tensor with desired dtype.\n        output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n      }\n    }\n  }\n\n private:\n  void DecodeBMP(const uint8* input, const int row_size, uint8* const output,\n                 const int width, const int height, const int output_channels,\n                 const int input_channels, bool top_down);\n\n  int channels_ = 0;\n  DataType data_type_ = DataType::DT_UINT8;\n  bool expand_animations_ = true;\n  jpeg::UncompressFlags flags_;\n  string op_type_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"DecodeJpeg\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodePng\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeGif\").Device(DEVICE_CPU), DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeAndCropJpeg\").Device(DEVICE_CPU),\n                        DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeImage\").Device(DEVICE_CPU),\n                        DecodeImageV2Op);\nREGISTER_KERNEL_BUILDER(Name(\"DecodeBmp\").Device(DEVICE_CPU), DecodeImageV2Op);\n\nvoid DecodeImageV2Op::DecodeBMP(const uint8* input, const int row_size,\n                                uint8* const output, const int width,\n                                const int height, const int output_channels,\n                                const int input_channels, bool top_down) {\n  for (int i = 0; i < height; i++) {\n    int src_pos;\n    int dst_pos;\n\n    for (int j = 0; j < width; j++) {\n      if (!top_down) {\n        src_pos = ((height - 1 - i) * row_size) + j * input_channels;\n      } else {\n        src_pos = i * row_size + j * input_channels;\n      }\n\n      dst_pos = (i * width + j) * output_channels;\n\n      switch (input_channels) {\n        case 1:\n          output[dst_pos] = input[src_pos];\n          // Set 2nd and 3rd channels if user requested for 3 or 4 channels.\n          // Repeat 1st channel's value.\n          if (output_channels == 3 || output_channels == 4) {\n            output[dst_pos + 1] = input[src_pos];\n            output[dst_pos + 2] = input[src_pos];\n          }\n          // Set 4th channel (alpha) to maximum value if user requested for\n          // 4 channels.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = UINT8_MAX;\n          }\n          break;\n        case 3:\n          // BGR -> RGB\n          output[dst_pos] = input[src_pos + 2];\n          output[dst_pos + 1] = input[src_pos + 1];\n          output[dst_pos + 2] = input[src_pos];\n          // Set 4th channel (alpha) to maximum value if the user requested for\n          // 4 channels and the input image has 3 channels only.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = UINT8_MAX;\n          }\n          break;\n        case 4:\n          // BGRA -> RGBA\n          output[dst_pos] = input[src_pos + 2];\n          output[dst_pos + 1] = input[src_pos + 1];\n          output[dst_pos + 2] = input[src_pos];\n          // Set 4th channel only if the user requested for 4 channels. If not,\n          // then user requested 3 channels; skip this step.\n          if (output_channels == 4) {\n            output[dst_pos + 3] = input[src_pos + 3];\n          }\n          break;\n        default:\n          LOG(FATAL) << \"Unexpected number of channels: \" << input_channels;\n          break;\n      }\n    }\n  }\n}\n\n}  // namespace\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/image/decode_image_op.cc"], "buggy_code_start_loc": [342], "buggy_code_end_loc": [343], "fixing_code_start_loc": [341], "fixing_code_end_loc": [341], "type": "CWE-416", "message": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2022-23584", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-04T23:15:14.873", "lastModified": "2022-02-10T17:23:58.667", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range."}, {"lang": "es", "value": "Tensorflow es un Marco de Aprendizaje Autom\u00e1tico de C\u00f3digo Abierto. Un usuario malicioso puede causar un comportamiento de uso de memoria previamente liberada cuando decodifica im\u00e1genes PNG. Despu\u00e9s de llamar a \"png::CommonFreeDecode(&amp;decode)\", los valores de \"decode.width\" y \"decode.height\" est\u00e1n en un estado no especificado. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.8.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.7.1, TensorFlow versi\u00f3n 2.6.3, y TensorFlow versi\u00f3n 2.5.3, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 7.6, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 4.7}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.5.2", "matchCriteriaId": "688150BF-477C-48FC-9AEF-A79AC57A6DDC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndIncluding": "2.6.2", "matchCriteriaId": "C9E69B60-8C97-47E2-9027-9598B8392E5D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.7.0:*:*:*:*:*:*:*", "matchCriteriaId": "2EDFAAB8-799C-4259-9102-944D4760DA2C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/kernels/image/decode_image_op.cc#L339-L346", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-24x4-6qmh-88qg", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b"}}