{"buggy_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#define EIGEN_USE_THREADS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/list_kernels.h\"\n\n#include <algorithm>\n#include <iterator>\n#include <limits>\n#include <memory>\n#include <utility>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/variant.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\nStatus TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n  if (t.shape() == TensorShape({})) {\n    if ((t.dtype() == DT_INT32 && t.scalar<int32>()() == -1) ||\n        (t.dtype() == DT_INT64 && t.scalar<int64_t>()() == -1)) {\n      *out = PartialTensorShape();\n      return OkStatus();\n    }\n    return errors::InvalidArgument(\n        \"The only valid scalar shape tensor is the fully unknown shape \"\n        \"specified as -1.\");\n  } else if (t.shape().dims() != 1) {\n    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n                                   t.shape().dims());\n  }\n  if (t.dtype() == DT_INT32) {\n    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n                                                t.NumElements(), out);\n  } else if (t.dtype() == DT_INT64) {\n    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),\n                                                t.NumElements(), out);\n  }\n  return errors::InvalidArgument(\n      \"Expected an int32 or int64 shape tensor; found \",\n      DataTypeString(t.dtype()));\n}\n\nStatus GetElementShapeFromInput(OpKernelContext* c,\n                                const TensorList& tensor_list, int index,\n                                PartialTensorShape* element_shape) {\n  TF_RETURN_IF_ERROR(TensorShapeFromTensor(c->input(index), element_shape));\n  // Check that `element_shape` and `tensor_list.element_shape` are\n  // compatible and store the merged shape in `element_shape`.\n  PartialTensorShape tmp = *element_shape;\n  TF_RETURN_IF_ERROR(tmp.MergeWith(tensor_list.element_shape, element_shape));\n  return OkStatus();\n}\n\nStatus GetInputList(OpKernelContext* c, int index, const TensorList** list) {\n  if (!TensorShapeUtils::IsScalar(c->input(index).shape())) {\n    return errors::InvalidArgument(\"Input list must be a scalar saw: \",\n                                   c->input(index).shape().DebugString());\n  }\n  const TensorList* l = c->input(index).scalar<Variant>()().get<TensorList>();\n  if (l == nullptr) {\n    return errors::InvalidArgument(\n        \"Input handle is not a list. Saw: '\",\n        c->input(index).scalar<Variant>()().DebugString(), \"'\");\n  }\n  *list = l;\n  return OkStatus();\n}\n\nStatus ForwardInputOrCreateNewList(OpKernelContext* c, int32_t input_index,\n                                   int32_t output_index,\n                                   const TensorList& input_list,\n                                   TensorList** output_list) {\n  // Attempt to forward the input tensor to the output if possible.\n  std::unique_ptr<Tensor> maybe_output = c->forward_input(\n      input_index, output_index, DT_VARIANT, TensorShape{},\n      c->input_memory_type(input_index), AllocatorAttributes());\n  Tensor* output_tensor;\n  if (maybe_output != nullptr && maybe_output->dtype() == DT_VARIANT &&\n      maybe_output->NumElements() == 1) {\n    output_tensor = maybe_output.get();\n    TensorList* tmp_out = output_tensor->scalar<Variant>()().get<TensorList>();\n    if (tmp_out == nullptr) {\n      return errors::InvalidArgument(\n          \"Expected input \", input_index, \" to be a TensorList but saw \",\n          output_tensor->scalar<Variant>()().TypeName());\n    }\n    if (tmp_out->RefCountIsOne()) {\n      // Woohoo, forwarding succeeded!\n      c->set_output(output_index, *output_tensor);\n      *output_list = tmp_out;\n      return OkStatus();\n    }\n  }\n\n  // If forwarding is not possible allocate a new output tensor and copy\n  // the `input_list` to it.\n  AllocatorAttributes attr;\n  attr.set_on_host(true);\n  TF_RETURN_IF_ERROR(\n      c->allocate_output(output_index, {}, &output_tensor, attr));\n  output_tensor->scalar<Variant>()() = input_list.Copy();\n\n  *output_list = output_tensor->scalar<Variant>()().get<TensorList>();\n  return OkStatus();\n}\n\nclass EmptyTensorList : public OpKernel {\n public:\n  explicit EmptyTensorList(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& max_num_elements_t = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(max_num_elements_t.shape()),\n        errors::InvalidArgument(\n            \"max_num_elements expected to be a scalar \",\n            \"but got shape: \", max_num_elements_t.shape().DebugString()));\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape{}, &result, attr));\n    TensorList empty;\n    empty.element_dtype = element_dtype_;\n    empty.max_num_elements = max_num_elements_t.scalar<int32>()();\n    PartialTensorShape element_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeFromTensor(ctx->input(0), &element_shape));\n    empty.element_shape = element_shape;\n    result->scalar<Variant>()() = std::move(empty);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\").Device(DEVICE_CPU),\n                        EmptyTensorList);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"max_num_elements\"),\n                        EmptyTensorList);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"max_num_elements\"),\n                        EmptyTensorList);\n\nclass TensorListPushBack : public OpKernel {\n public:\n  explicit TensorListPushBack(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  ~TensorListPushBack() override {}\n\n  void Compute(OpKernelContext* c) override {\n    const Tensor& input = c->input(1);\n    OP_REQUIRES(c, element_dtype_ == input.dtype(),\n                errors::InvalidArgument(\"Invalid data types; list elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but tried to append \",\n                                        DataTypeString(input.dtype())));\n\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    OP_REQUIRES(c, l->element_shape.IsCompatibleWith(input.shape()),\n                errors::InvalidArgument(\n                    \"Tried to append a tensor with incompatible shape to a \"\n                    \"list. Op element shape: \",\n                    input.shape().DebugString(),\n                    \" list shape: \", l->element_shape.DebugString()));\n    OP_REQUIRES(c, element_dtype_ == l->element_dtype,\n                errors::InvalidArgument(\"Invalid data types; op elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but list elements \",\n                                        DataTypeString(l->element_dtype)));\n\n    if (l->max_num_elements != -1) {\n      OP_REQUIRES(\n          c, l->tensors().size() < l->max_num_elements,\n          errors::InvalidArgument(\"Tried to push item into a full list\",\n                                  \" list size: \", l->tensors().size(),\n                                  \" max_num_elements: \", l->max_num_elements));\n    }\n\n    TensorList* output_list = nullptr;\n    OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n    output_list->tensors().push_back(input);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_CPU),\n                        TensorListPushBack);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_GPU),\n                        TensorListPushBack);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_DEFAULT),\n                        TensorListPushBack);\n\nclass TensorListLength : public OpKernel {\n public:\n  explicit TensorListLength(OpKernelConstruction* c) : OpKernel(c) {}\n  ~TensorListLength() override {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    Tensor* result;\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result));\n    result->scalar<int32>()() = l->tensors().size();\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListLength\").Device(DEVICE_CPU),\n                        TensorListLength);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListLength\").Device(DEVICE_GPU).HostMemory(\"length\"),\n    TensorListLength);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListLength\").Device(DEVICE_DEFAULT).HostMemory(\"length\"),\n    TensorListLength);\n\nclass TensorListElementShape : public OpKernel {\n public:\n  explicit TensorListElementShape(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    Tensor* result;\n    if (l->element_shape.unknown_rank()) {\n      OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape({}), &result));\n      if (result->dtype() == DT_INT32) {\n        result->scalar<int32>()() = -1;\n      } else {\n        result->scalar<int64_t>()() = -1;\n      }\n    } else {\n      OP_REQUIRES_OK(c, c->allocate_output(\n                            0, TensorShape{l->element_shape.dims()}, &result));\n      for (int i = 0; i < l->element_shape.dims(); ++i) {\n        if (result->dtype() == DT_INT32) {\n          result->flat<int32>()(i) = l->element_shape.dim_size(i);\n        } else {\n          result->flat<int64_t>()(i) = l->element_shape.dim_size(i);\n        }\n      }\n    }\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\").Device(DEVICE_CPU),\n                        TensorListElementShape);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\"),\n                        TensorListElementShape);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\"),\n                        TensorListElementShape);\n\nclass TensorListReserve : public OpKernel {\n public:\n  explicit TensorListReserve(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    PartialTensorShape element_shape;\n    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n    int32_t num_elements = c->input(1).scalar<int32>()();\n    OP_REQUIRES(c, num_elements >= 0,\n                errors::InvalidArgument(\"The num_elements to reserve must be a \"\n                                        \"non negative number, but got \",\n                                        num_elements));\n    TensorList output;\n    output.element_shape = element_shape;\n    output.element_dtype = element_dtype_;\n    output.tensors().resize(num_elements, Tensor(DT_INVALID));\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result, attr));\n    result->scalar<Variant>()() = std::move(output);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\").Device(DEVICE_CPU),\n                        TensorListReserve);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"num_elements\"),\n                        TensorListReserve);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"num_elements\"),\n                        TensorListReserve);\n\nclass TensorListResize : public OpKernel {\n public:\n  explicit TensorListResize(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* input_list = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &input_list));\n    int32_t size = c->input(1).scalar<int32>()();\n    OP_REQUIRES(\n        c, size >= 0,\n        errors::InvalidArgument(\n            \"TensorListSlice expects size to be non-negative. Got: \", size));\n\n    std::unique_ptr<Tensor> maybe_result =\n        c->forward_input(0, 0, DT_VARIANT, TensorShape{},\n                         c->input_memory_type(0), AllocatorAttributes());\n    if (maybe_result != nullptr) {\n      TensorList* out = maybe_result->scalar<Variant>()().get<TensorList>();\n      if (out->RefCountIsOne()) {\n        // We are able to forward the input.\n        out->tensors().resize(size, Tensor(DT_INVALID));\n        c->set_output(0, *maybe_result);\n        return;\n      }\n    }\n\n    // We were not able to forward the input.  Will have to resize from scratch.\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result, attr));\n    TensorList output_list;\n    output_list.element_shape = input_list->element_shape;\n    output_list.element_dtype = input_list->element_dtype;\n    output_list.max_num_elements = input_list->max_num_elements;\n    if (size > input_list->tensors().size()) {\n      output_list.tensors().insert(output_list.tensors().begin(),\n                                   input_list->tensors().begin(),\n                                   input_list->tensors().end());\n      // Add DT_INVALID tensors to the end of the list if the requested size\n      // is larger than the list length.\n      output_list.tensors().resize(size, Tensor(DT_INVALID));\n    } else {\n      output_list.tensors().insert(output_list.tensors().begin(),\n                                   input_list->tensors().begin(),\n                                   input_list->tensors().begin() + size);\n    }\n    result->scalar<Variant>()() = std::move(output_list);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListResize\").Device(DEVICE_CPU),\n                        TensorListResize);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListResize\").Device(DEVICE_GPU).HostMemory(\"size\"),\n    TensorListResize);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListResize\").Device(DEVICE_DEFAULT).HostMemory(\"size\"),\n    TensorListResize);\n\nclass TensorListSetItem : public OpKernel {\n public:\n  explicit TensorListSetItem(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    OP_REQUIRES(c, element_dtype_ == l->element_dtype,\n                errors::InvalidArgument(\"Invalid data types; op elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but list elements \",\n                                        DataTypeString(l->element_dtype)));\n    int32_t index = c->input(1).scalar<int32>()();\n    OP_REQUIRES(c, index < l->tensors().size(),\n                errors::InvalidArgument(\"Trying to modify element \", index,\n                                        \" in a list with \", l->tensors().size(),\n                                        \" elements.\"));\n    const Tensor& value = c->input(2);\n    OP_REQUIRES(c, l->element_shape.IsCompatibleWith(value.shape()),\n                errors::InvalidArgument(\n                    \"Tried to set a tensor with incompatible shape at a \"\n                    \"list index. Item element shape: \",\n                    value.shape().DebugString(),\n                    \" list shape: \", l->element_shape.DebugString()));\n    TensorList* output_list = nullptr;\n    OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n    output_list->tensors()[index] = value;\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\").Device(DEVICE_CPU),\n                        TensorListSetItem);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#define REGISTER_TENSOR_LIST_SET_ITEM_GPU(T)                      \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\")               \\\n                              .TypeConstraint<T>(\"element_dtype\") \\\n                              .Device(DEVICE_GPU)                 \\\n                              .HostMemory(\"index\"),               \\\n                          TensorListSetItem);\n\nTF_CALL_GPU_ALL_TYPES(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nTF_CALL_int32(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nTF_CALL_int64(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nREGISTER_TENSOR_LIST_SET_ITEM_GPU(bfloat16)\n#undef REGISTER_TENSOR_LIST_SET_ITEM_GPU\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#define REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT(T)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\")               \\\n                              .TypeConstraint<T>(\"element_dtype\") \\\n                              .Device(DEVICE_DEFAULT)             \\\n                              .HostMemory(\"index\"),               \\\n                          TensorListSetItem);\n\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nTF_CALL_int32(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nTF_CALL_int64(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nREGISTER_TENSOR_LIST_SET_ITEM_DEFAULT(bfloat16)\n#undef REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT\n\nclass TensorListConcatLists : public OpKernel {\n public:\n  explicit TensorListConcatLists(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    const TensorShape& tl_a_shape = c->input(0).shape();\n    const TensorShape& tl_b_shape = c->input(1).shape();\n    OP_REQUIRES(\n        c, tl_a_shape == tl_b_shape,\n        errors::InvalidArgument(\"Incompatible input TensorList tensor shapes: \",\n                                tl_a_shape.DebugString(), \" vs. \",\n                                tl_b_shape.DebugString()));\n    AllocatorAttributes attr;\n    std::unique_ptr<Tensor> tl_alias = c->forward_input(\n        0 /*input_index*/, 0 /*output_index*/, DT_VARIANT, tl_a_shape,\n        DEVICE_MEMORY /* input is always on DEVICE_MEMORY */, attr);\n\n    // tl_a may be aliased by tl_alias.\n    const Tensor& tl_a = c->input(0);\n    const Tensor& tl_b = c->input(1);\n\n    Tensor* output = nullptr;\n    bool ok_to_alias = tl_alias != nullptr;\n    if (tl_alias && tl_alias->dtype() == DT_VARIANT &&\n        tl_alias->NumElements() > 0) {\n      auto tl_a_t = tl_alias->flat<Variant>();\n      for (int64_t i = 0; i < tl_alias->NumElements(); ++i) {\n        TensorList* aliased = tl_a_t(i).get<TensorList>();\n        if (aliased == nullptr || !aliased->RefCountIsOne()) {\n          ok_to_alias = false;\n          break;\n        }\n      }\n      if (ok_to_alias) {\n        c->set_output(0, *tl_alias);\n        output = tl_alias.get();\n      }\n    }\n    if (!ok_to_alias) {\n      // Couldn't alias the entire Tensor.  We'll be conservative and not try\n      // to alias individual batch entries.\n      attr.set_on_host(true);\n      OP_REQUIRES_OK(c, c->allocate_output(0, tl_a_shape, &output, attr));\n    }\n\n    auto output_t = output->flat<Variant>();\n    auto tl_a_t = tl_a.flat<Variant>();\n    auto tl_b_t = tl_b.flat<Variant>();\n\n    for (int64_t i = 0; i < tl_a.NumElements(); ++i) {\n      const TensorList* l_a = tl_a_t(i).get<TensorList>();\n      const TensorList* l_b = tl_b_t(i).get<TensorList>();\n      OP_REQUIRES(\n          c, l_a != nullptr,\n          errors::InvalidArgument(\"input_a is not a TensorList at index \", i,\n                                  \".  Saw: '\", tl_a_t(i).DebugString(), \"'\"));\n      OP_REQUIRES(\n          c, l_b != nullptr,\n          errors::InvalidArgument(\"input_b is not a TensorList at index \", i,\n                                  \".  Saw: '\", tl_b_t(i).DebugString(), \"'\"));\n      OP_REQUIRES(c, l_a->element_dtype == element_dtype_,\n                  errors::InvalidArgument(\n                      \"input_a[\", i, \"].dtype != element_dtype.  Saw: \",\n                      DataTypeString(l_a->element_dtype), \" vs. \",\n                      DataTypeString(element_dtype_)));\n      OP_REQUIRES(c, l_b->element_dtype == element_dtype_,\n                  errors::InvalidArgument(\n                      \"input_b[\", i, \"].dtype != element_dtype.  Saw: \",\n                      DataTypeString(l_b->element_dtype), \" vs. \",\n                      DataTypeString(element_dtype_)));\n      OP_REQUIRES(c, l_a->element_shape.IsIdenticalTo(l_b->element_shape),\n                  errors::InvalidArgument(\n                      \"input_a and input_b TensorList element shapes are not \"\n                      \"identical at index \",\n                      i, \".  Saw \", l_a->element_shape.DebugString(), \" vs. \",\n                      l_b->element_shape.DebugString()));\n      if (ok_to_alias) {\n        TensorList* out = output_t(i).get<TensorList>();\n        std::copy(l_b->tensors().begin(), l_b->tensors().end(),\n                  std::back_inserter(out->tensors()));\n      } else {\n        TensorList out = l_a->Copy();\n        std::copy(l_b->tensors().begin(), l_b->tensors().end(),\n                  std::back_inserter(out.tensors()));\n        output_t(i) = std::move(out);\n      }\n    }\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_CPU),\n                        TensorListConcatLists);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_GPU),\n                        TensorListConcatLists);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_DEFAULT),\n                        TensorListConcatLists);\n\n#define REGISTER_TENSOR_LIST_OPS_CPU(T)                                    \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListStack\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListStack<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGather\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListGather<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcat\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcatV2\")                       \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGetItem\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListGetItem<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPopBack\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListPopBack<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListFromTensor\")                     \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListFromTensor<CPUDevice, T>)              \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatter\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterV2\")                      \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterIntoExistingList\")        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatterIntoExistingList<CPUDevice, T>) \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSplit\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListSplit<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPushBackBatch\")                  \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListPushBackBatch<CPUDevice, T>)\n\nTF_CALL_POD_STRING_TYPES(REGISTER_TENSOR_LIST_OPS_CPU);\nREGISTER_TENSOR_LIST_OPS_CPU(quint8);\nREGISTER_TENSOR_LIST_OPS_CPU(qint8);\nREGISTER_TENSOR_LIST_OPS_CPU(quint16);\nREGISTER_TENSOR_LIST_OPS_CPU(qint16);\nREGISTER_TENSOR_LIST_OPS_CPU(qint32);\nREGISTER_TENSOR_LIST_OPS_CPU(Variant);\n\n#undef REGISTER_TENSOR_LIST_OPS_CPU\n\n#define REGISTER_TENSOR_LIST_OPS_CPU(T)\n\nREGISTER_UNARY_VARIANT_BINARY_OP_FUNCTION(ADD_VARIANT_BINARY_OP, DEVICE_CPU,\n                                          TensorList,\n                                          TensorListBinaryAdd<CPUDevice>);\n\nREGISTER_UNARY_VARIANT_UNARY_OP_FUNCTION(ZEROS_LIKE_VARIANT_UNARY_OP,\n                                         DEVICE_CPU, TensorList,\n                                         TensorListZerosLike<CPUDevice>);\n\nstatic Status TensorListDeviceCopy(\n    const TensorList& from, TensorList* to,\n    const UnaryVariantOpRegistry::AsyncTensorDeviceCopyFn& copy) {\n  to->element_shape = from.element_shape;\n  to->element_dtype = from.element_dtype;\n  to->max_num_elements = from.max_num_elements;\n  to->tensors().reserve(from.tensors().size());\n  for (const Tensor& t : from.tensors()) {\n    to->tensors().emplace_back(t.dtype());\n    if (t.dtype() != DT_INVALID) {\n      TF_RETURN_IF_ERROR(copy(t, &to->tensors().back()));\n    }\n  }\n  return OkStatus();\n}\n\n#define REGISTER_LIST_COPY(DIRECTION)                                         \\\n  INTERNAL_REGISTER_UNARY_VARIANT_DEVICE_COPY_FUNCTION(TensorList, DIRECTION, \\\n                                                       TensorListDeviceCopy)\n\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::HOST_TO_DEVICE);\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::DEVICE_TO_HOST);\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::DEVICE_TO_DEVICE);\n\nREGISTER_UNARY_VARIANT_DECODE_FUNCTION(TensorList, TensorList::kTypeName);\n\n#define REGISTER_TENSOR_LIST_OPS_DEFAULT(T)                                \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListStack\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListStack<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGather\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"indices\")                       \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListGather<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcat\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"lengths\")                       \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcatV2\")                       \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"leading_dims\")                  \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"lengths\")                       \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGetItem\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"index\")                         \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListGetItem<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPopBack\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListPopBack<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPushBackBatch\")                  \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListPushBackBatch<CPUDevice, T>)           \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListFromTensor\")                     \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListFromTensor<CPUDevice, T>)              \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatter\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterV2\")                      \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"num_elements\")                  \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterIntoExistingList\")        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatterIntoExistingList<CPUDevice, T>) \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSplit\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"lengths\"),                      \\\n                          TensorListSplit<CPUDevice, T>)\n\nTF_CALL_int32(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_int64(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_bfloat16(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_TENSOR_LIST_OPS_DEFAULT);\n\n#undef REGISTER_TENSOR_LIST_OPS_DEFAULT\n}  // namespace tensorflow\n", "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for ops which manipulate lists of tensors.\"\"\"\n\n# pylint: disable=g-bad-name\nfrom absl.testing import parameterized\nimport numpy as np  # pylint: disable=unused-import\n\nfrom tensorflow.core.framework import full_type_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.eager import function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import gen_list_ops\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import map_fn\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import string_ops\nfrom tensorflow.python.ops import variable_scope as vs\nfrom tensorflow.python.platform import test\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  def _testPushPop(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    l = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    l, e = self.evaluate((l, e))\n    self.assertAllEqual(l, [])\n    self.assertAllEqual(e, 1.0)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testPushPop(self, max_num_elements):\n    self._testPushPop(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_gpu_only\n  def testPushPopGPU(self, max_num_elements):\n    with context.device(\"gpu:0\"):\n      self._testPushPop(max_num_elements)\n\n  @test_util.run_deprecated_v1\n  def testPushInFullListFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[], max_num_elements=1)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Tried to push item into a full list\"):\n      l = list_ops.tensor_list_push_back(l, 2.)\n      self.evaluate(l)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_deprecated_v1\n  def testPopFromEmptyTensorListFails(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Trying to pop from an empty list\"):\n      l = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.evaluate(l)\n\n  def testPopUninitializedTensorUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n    _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    l = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    l, e = self.evaluate((l, e))\n    self.assertAllEqual(e, np.zeros((2, 3)))\n    self.assertAllEqual(l, np.zeros((3, 2, 3)))\n\n  def testPopUninitializedTensorUseSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    _, e = gen_list_ops.tensor_list_pop_back(\n        l, element_dtype=dtypes.float32, element_shape=[4, 3])\n    self.assertAllEqual(e, np.zeros((4, 3)))\n\n  def testPopUninitializedTensorWithInvalidElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to read an uninitialized tensor but \"\n        \"element_shape is not fully defined\"):\n      _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.evaluate(e)\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 2], num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1,3\\] vs. \\[\\?,2\\]\"):\n      _, e = gen_list_ops.tensor_list_pop_back(\n          l, element_dtype=dtypes.float32, element_shape=[1, 3])\n      self.evaluate(e)\n\n  def testPushGetGrad(self):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=None)\n      c0 = constant_op.constant(5.0)\n      c1 = constant_op.constant([10.0, 20.0])\n      tape.watch(c0)\n      tape.watch(c1)\n      l = list_ops.tensor_list_push_back(l, c0)\n      l = list_ops.tensor_list_push_back(l, c1)\n      t1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t1), [10.0, 20.0])\n      # t1 == c1 so the gradient should be [0., [1., 1.]]\n      # This tests that the gradient of push_back correctly converts DT_INVALID\n      # tensors to zeros. The list returned by the gradient of GetItem will\n      # have only have tensor at index 1 set and others set to DT_INVALID.\n      dt0, dt1 = tape.gradient(t1, [c0, c1])\n      self.assertAllEqual(self.evaluate(dt1), [1.0, 1.0])\n      self.assertEqual(self.evaluate(dt0), 0.0)\n\n  def _testStack(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    if not context.executing_eagerly():\n      self.assertAllEqual(t.shape.as_list(), [None])\n    self.assertAllEqual(self.evaluate(t), [1.0, 2.0])\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testStack(self, max_num_elements):\n    self._testStack(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_gpu_only\n  def testStackGPU(self, max_num_elements):\n    with context.device(\"gpu:0\"):\n      self._testStack(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testStackWithUnknownElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=None,\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [1.0, 2.0])\n\n    # Should raise an error when the element tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Incompatible ranks during merge: 0 vs. 1\"):\n      l = list_ops.tensor_list_push_back(l, constant_op.constant([3.0, 4.0]))\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testStackWithPartiallyDefinedElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[None],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0]))\n\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1.0], [2.0]])\n\n    # Should raise an error when the element tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1\\] vs. \\[2\\]\"):\n      l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0, 3.0]))\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_deprecated_v1\n  def testStackEmptyList(self, max_num_elements):\n    # Should be able to stack empty lists with fully defined element_shape.\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[1, 2],\n        max_num_elements=max_num_elements)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 1, 2))\n\n    # Should not be able to stack empty lists with partially defined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[None, 2],\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n    # Should not be able to stack empty lists with undefined element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=None,\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def _testStackWithUninitializedTensors(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [0., 0., 0.])\n\n  def testStackWithUninitializedTensors(self):\n    self._testStackWithUninitializedTensors()\n\n  @test_util.run_gpu_only\n  def testStackWithUninitializedTensorsGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testStackWithUninitializedTensors()\n\n  def _testStackWithUninitializedTensorsInferShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [1., 2.])\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [[0., 0.], [1., 2.], [0., 0.]])\n\n  def testStackWithUninitializedTensorsInferShape(self):\n    self._testStackWithUninitializedTensorsInferShape()\n\n  @test_util.run_gpu_only\n  def testStackWithUninitializedTensorsInferShapeGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testStackWithUninitializedTensorsInferShape()\n\n  def testStackReservedListWithNoElementsAndPartialElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Tried to stack list which only contains \"\n        \"uninitialized tensors and has a \"\n        \"non-fully-defined element_shape: <unknown>\"):\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testStackUsingSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = gen_list_ops.tensor_list_stack(\n        l, element_dtype=dtypes.float32, element_shape=[])\n    if context.executing_eagerly():\n      self.assertEqual(t.shape.as_list(), [3])\n    else:\n      self.assertEqual(t.shape.as_list(), [None])\n    self.assertAllEqual(self.evaluate(t), np.zeros((3,)))\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testGatherGrad(self, max_num_elements):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[],\n          max_num_elements=max_num_elements)\n      c0 = constant_op.constant(1.0)\n      tape.watch(c0)\n      l = list_ops.tensor_list_push_back(l, c0)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n      t = list_ops.tensor_list_gather(l, [1, 0], element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t), [2.0, 1.0])\n      s = (t[0] + t[1]) * (t[0] + t[1])\n    dt = tape.gradient(s, c0)\n    self.assertAllEqual(self.evaluate(dt), 6.0)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherWithUnknownElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=None,\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([3.0, 4.0]))\n\n    t = list_ops.tensor_list_gather(l, [1, 0], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [2.0, 1.0])\n\n    t = list_ops.tensor_list_gather(l, [2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[3.0, 4.0]])\n\n    # Should raise an error when the requested tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Incompatible ranks during merge: 0 vs. 1\"):\n      t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherWithPartiallyDefinedElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[None],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0, 3.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([4.0, 5.0]))\n\n    t = list_ops.tensor_list_gather(l, [0], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1.0]])\n\n    t = list_ops.tensor_list_gather(l, [1, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[2.0, 3.0], [4.0, 5.0]])\n\n    # Should raise an error when the requested tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1\\] vs. \\[2\\]\"):\n      t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherEmptyList(self, max_num_elements):\n    # Should be able to gather from empty lists with fully defined\n    # element_shape.\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[1, 2],\n        max_num_elements=max_num_elements)\n    t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n    self.assertAllEqual((0, 1, 2), self.evaluate(t).shape)\n\n    # Should not be able to gather from empty lists with partially defined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[None, 2],\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n    # Should not be able to gather from empty lists with undefined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=None,\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testGatherGradWithNonContiguousIndices(self):\n    with backprop.GradientTape(persistent=True) as tape:\n      t = constant_op.constant([1.0, 2.0, 3.0])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      c = constant_op.constant(5.0)\n      tape.watch(c)\n      l = list_ops.tensor_list_set_item(l, 1, c)\n      t = list_ops.tensor_list_gather(l, [1], element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t), [5.0])\n      s = t[0] * t[0]\n    dt = tape.gradient(s, c)\n    self.assertAllEqual(self.evaluate(dt), 10.0)\n    dl = tape.gradient(t, l)\n    dl_length = list_ops.tensor_list_length(dl)\n    self.assertAllEqual(self.evaluate(dl_length), 3)\n\n  def _testGatherWithUninitializedTensors(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [0., 0.])\n\n  def testGatherWithUninitializedTensors(self):\n    self._testGatherWithUninitializedTensors()\n\n  @test_util.run_gpu_only\n  def testGatherWithUninitializedTensorsGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testGatherWithUninitializedTensors()\n\n  def _testGatherWithUninitializedTensorsInferShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [1., 2.])\n    t = list_ops.tensor_list_gather(l, [1, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1., 2.], [0., 0.]])\n\n  def testGatherWithUninitializedTensorsInferShape(self):\n    self._testGatherWithUninitializedTensorsInferShape()\n\n  @test_util.run_gpu_only\n  def testGatherWithUninitializedTensorsInferShapeGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testGatherWithUninitializedTensorsInferShape()\n\n  def testGatherReservedListWithNoElementsAndPartialElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Tried to gather uninitialized tensors from a\"\n        \" list with non-fully-defined element_shape\"):\n      t = list_ops.tensor_list_gather(l, [0], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testGatherUsingSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = gen_list_ops.tensor_list_gather(\n        l, [0, 1, 2], element_dtype=dtypes.float32, element_shape=[])\n    self.assertEqual(t.shape.as_list(), [3])\n    self.assertAllEqual(self.evaluate(t), np.zeros((3,)))\n\n  def testScatterOutputListSize(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_scatter(c0, [1, 3], [])\n    # TensorListScatter should return a list with size largest index + 1.\n    self.assertAllEqual(list_ops.tensor_list_length(l), 4)\n\n  def testScatterOutputListSizeWithNumElementsSpecified(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    l = gen_list_ops.tensor_list_scatter_v2(\n        c0, [1, 3], list_ops._build_element_shape([]), num_elements=5)\n    # TensorListScatter should return a list with size num_elements.\n    self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n\n  def testScatterFailsWhenElementShapeIsNotVector(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      l = gen_list_ops.tensor_list_scatter(\n          # Wrong element_shape. Should be at most rank 1.\n          c0, [1, 3], element_shape=[[1]])\n      self.evaluate(l)\n\n  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          # Wrong element_shape. Should be at most rank 1.\n          c0, [1, 3], element_shape=[[1]], num_elements=2)\n      self.evaluate(l)\n\n  def testScatterFailsWhenIndexLargerThanNumElements(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListScatter: Trying to scatter at index 3 in list with size 3\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          c0, [1, 3], list_ops._build_element_shape([]), num_elements=3)\n      self.evaluate(l)\n\n  def testScatterFailsWithInvalidNumElements(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListScatter expects num_elements >= -1, found: -2\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          c0, [1, 3], list_ops._build_element_shape([]), num_elements=-2)\n      self.evaluate(l)\n\n  def testScatterWithInvalidRowsInInputTensorFails(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Invalid number of rows in input tensor. Expected: 3 Actual: 2\"):\n      l = list_ops.tensor_list_scatter(c0, [1, 0, 2], [])\n      self.evaluate(l)\n\n  def testScatterWithNegativeIndicesFails(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Indices in TensorListScatter must all be non-negative.\"):\n      l = list_ops.tensor_list_scatter(c0, [-1, -2], element_shape=[])\n      self.evaluate(l)\n\n  def testScatterIntoExistingList(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    l = list_ops.tensor_list_scatter(tensor=[1.], indices=[0], element_shape=[])\n    l = list_ops.tensor_list_scatter(\n        tensor=[2., 3.], indices=[1, 2], element_shape=[], input_handle=l)\n    self.assertAllEqual(\n        list_ops.tensor_list_stack(l, element_dtype=dtypes.float32),\n        [1., 2., 3.])\n\n  def testScatterGrad(self):\n    with backprop.GradientTape() as tape:\n      c0 = constant_op.constant([1.0, 2.0])\n      tape.watch(c0)\n      l = list_ops.tensor_list_scatter(c0, [1, 0], element_shape=[])\n      t0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      t1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t0), 2.0)\n      self.assertAllEqual(self.evaluate(t1), 1.0)\n      loss = t0 * t0 + t1 * t1\n    dt = tape.gradient(loss, c0)\n    self.assertAllEqual(self.evaluate(dt), [2., 4.])\n\n  def testScatterWithPartialReadGrad(self):\n    with backprop.GradientTape() as tape:\n      c0 = constant_op.constant([1.0, 2.0])\n      tape.watch(c0)\n      l = list_ops.tensor_list_scatter(c0, [1, 0], element_shape=[])\n      t0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t0), 2.0)\n      loss = t0 * t0\n    dt = tape.gradient(loss, c0)\n    self.assertAllEqual(self.evaluate(dt), [0., 4.])\n\n  def testTensorListFromTensor(self):\n    t = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 1.0)\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 2.0)\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 1.0)\n    self.assertAllEqual(list_ops.tensor_list_length(l), 0)\n\n  def testTensorListFromTensorFailsWhenElementShapeIsNotVector(self):\n    t = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      # Wrong element_shape. Should be at most rank 1.\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[[1]])\n      self.evaluate(l)\n\n  @test_util.run_gpu_only\n  def testFromTensorGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testTensorListFromTensor()\n\n  def testGetSetBool(self):\n    t = constant_op.constant([True, False])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.bool)\n    self.assertAllEqual(self.evaluate(e0), True)\n    l = list_ops.tensor_list_set_item(l, 0, False)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.bool)\n    self.assertAllEqual(self.evaluate(t), [False, False])\n\n  @test_util.run_gpu_only\n  def testGetSetBoolGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testGetSetBool()\n\n  def _testGetSetNumeric(self, dtype):\n    t = constant_op.constant([1.0, 2.0], dtype=dtype)\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtype)\n    self.assertAllEqual(self.evaluate(e0), 1.0)\n    l = list_ops.tensor_list_set_item(\n        l, 0, constant_op.constant(3.0, dtype=dtype))\n    t = list_ops.tensor_list_stack(l, element_dtype=dtype)\n    self.assertAllEqual(self.evaluate(t), [3.0, 2.0])\n\n  @parameterized.parameters([dtypes.float32, dtypes.float64,\n                             dtypes.complex64, dtypes.complex128])\n  def testGetSetNumeric(self, dtype):\n    self._testGetSetNumeric(dtype)\n\n  @parameterized.parameters([dtypes.float32, dtypes.float64,\n                             dtypes.complex64, dtypes.complex128])\n  @test_util.run_gpu_only\n  def testGetSetNumericGPU(self, dtype):\n    with context.device(\"gpu:0\"):\n      self._testGetSetNumeric(dtype)\n\n  def testGetSetReserved(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=2)\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(e0, 0.0)\n    l = list_ops.tensor_list_set_item(l, 0, 3.0)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [3.0, 0.0])\n\n  @test_util.run_gpu_only\n  def testGetSetReservedGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testGetSetReserved()\n\n  def testSetGetGrad(self):\n    with backprop.GradientTape() as tape:\n      t = constant_op.constant(5.)\n      tape.watch(t)\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n      l = list_ops.tensor_list_set_item(l, 1, 2. * t)\n      e = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(e), 10.0)\n    self.assertAllEqual(self.evaluate(tape.gradient(e, t)), 2.0)\n\n  def testGetUninitializedTensorUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 0, 5.)\n    e1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n    e2 = list_ops.tensor_list_get_item(l, 2, element_dtype=dtypes.float32)\n    self.assertEqual(self.evaluate(e1), 0.)\n    self.assertEqual(self.evaluate(e2), 0.)\n\n  def testGetUninitializedTensorUseSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    e0 = gen_list_ops.tensor_list_get_item(\n        l, 0, element_shape=[], element_dtype=dtypes.float32)\n    e1 = gen_list_ops.tensor_list_get_item(\n        l, 1, element_shape=[2, 3], element_dtype=dtypes.float32)\n    self.assertEqual(e0.shape.as_list(), [])\n    self.assertEqual(e1.shape.as_list(), [2, 3])\n    self.assertEqual(self.evaluate(e0), 0.)\n    self.assertAllEqual(self.evaluate(e1), np.zeros((2, 3)))\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    e1 = gen_list_ops.tensor_list_get_item(\n        l, 1, element_shape=[2, 3], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e1), np.zeros((2, 3)))\n\n  def testGetUninitializedTensorWithInvalidElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to read an uninitialized tensor but \"\n        \"element_shape is not fully defined\"):\n      e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.evaluate(e0)\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 2], num_elements=3)\n\n    # In eager mode the shape mismatch is caught in the TensorListGetItem\n    # kernel which raises an InvalidArgumentError.\n    # In graph mode the shape mismatch is caught in the C++ shape inference\n    # which raises a ValueError.\n    if context.executing_eagerly():\n      error_type = errors.InvalidArgumentError\n    else:\n      error_type = ValueError\n    with self.assertRaisesRegex(error_type, r\"shapes\"):\n      e0 = gen_list_ops.tensor_list_get_item(\n          l, 0, element_dtype=dtypes.float32, element_shape=[1, 3])\n      self.evaluate(e0)\n\n  @test_util.run_deprecated_v1\n  @test_util.enable_control_flow_v2\n  def testSkipEagerSetItemIndexOutOfBounds(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[])\n    e0 = constant_op.constant(5.)\n    l = list_ops.tensor_list_set_item(\n        l, 0, 2. * e0, resize_if_index_out_of_bounds=True)\n    l = list_ops.tensor_list_set_item(\n        l, 1, 1., resize_if_index_out_of_bounds=True)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients(t, e0)[0]\n    self.assertAllEqual(self.evaluate(grad), 2.)\n\n  @test_util.run_deprecated_v1\n  def testSetOnEmptyListWithMaxNumElementsFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[], max_num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to modify element 0 in a list with 0 elements.\"):\n      l = list_ops.tensor_list_set_item(l, 0, 1.)\n      self.evaluate(l)\n\n  def testUnknownShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0, 2.0]))\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e), [1.0, 2.0])\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e), 1.0)\n\n  @test_util.run_gpu_only\n  def testCPUGPUCopy(self):\n    t = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    with context.device(\"gpu:0\"):\n      l_gpu = array_ops.identity(l)\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_pop_back(\n                  l_gpu, element_dtype=dtypes.float32)[1]), 2.0)\n    l_cpu = array_ops.identity(l_gpu)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_pop_back(\n                l_cpu, element_dtype=dtypes.float32)[1]), 2.0)\n\n  @test_util.run_gpu_only\n  def testCPUGPUCopyNested(self):\n    t = constant_op.constant([1.0, 2.0])\n    child_l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    l = list_ops.empty_tensor_list(\n        element_shape=constant_op.constant([], dtype=dtypes.int32),\n        element_dtype=dtypes.variant)\n    l = list_ops.tensor_list_push_back(l, child_l)\n    with context.device(\"gpu:0\"):\n      l_gpu = array_ops.identity(l)\n      _, child_l_gpu = list_ops.tensor_list_pop_back(\n          l_gpu, element_dtype=dtypes.variant)\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_pop_back(\n                  child_l_gpu, element_dtype=dtypes.float32)[1]), 2.0)\n    l_cpu = array_ops.identity(l_gpu)\n    _, child_l_cpu = list_ops.tensor_list_pop_back(\n        l_cpu, element_dtype=dtypes.variant)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_pop_back(\n                child_l_cpu, element_dtype=dtypes.float32)[1]), 2.0)\n\n  def testGraphStack(self):\n    with self.cached_session():\n      tl = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([1], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      tl = list_ops.tensor_list_push_back(tl, [1])\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_stack(tl, element_dtype=dtypes.int32)),\n          [[1]])\n\n  def testSkipEagerStackInLoop(self):\n    with self.cached_session():\n      t1 = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      i = constant_op.constant(0, dtype=dtypes.int32)\n\n      def body(i, t1):\n        t1 = list_ops.tensor_list_push_back(t1, i)\n        i += 1\n        return i, t1\n\n      i, t1 = control_flow_ops.while_loop(lambda i, t1: math_ops.less(i, 4),\n                                          body, [i, t1])\n      s1 = list_ops.tensor_list_stack(t1, element_dtype=dtypes.int32)\n      self.assertAllEqual(self.evaluate(s1), [0, 1, 2, 3])\n\n  def testSkipEagerStackSwitchDtype(self):\n    with self.cached_session():\n      list_ = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      m = constant_op.constant([1, 2, 3], dtype=dtypes.float32)\n\n      def body(list_, m):\n        list_ = control_flow_ops.cond(\n            math_ops.equal(list_ops.tensor_list_length(list_), 0),\n            lambda: list_ops.empty_tensor_list(m.shape, m.dtype), lambda: list_)\n        list_ = list_ops.tensor_list_push_back(list_, m)\n        return list_, m\n\n      for _ in range(2):\n        list_, m = body(list_, m)\n\n      s1 = list_ops.tensor_list_stack(list_, element_dtype=dtypes.float32)\n      np_s1 = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.float32)\n      self.assertAllEqual(self.evaluate(s1), np_s1)\n\n  def testSkipEagerStackInLoopSwitchDtype(self):\n    with self.cached_session():\n      t1 = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      i = constant_op.constant(0, dtype=dtypes.float32)\n      m = constant_op.constant([1, 2, 3], dtype=dtypes.float32)\n\n      def body(i, m, t1):\n        t1 = control_flow_ops.cond(\n            math_ops.equal(list_ops.tensor_list_length(t1), 0),\n            lambda: list_ops.empty_tensor_list(m.shape, m.dtype), lambda: t1)\n\n        t1 = list_ops.tensor_list_push_back(t1, m * i)\n        i += 1.0\n        return i, m, t1\n\n      i, m, t1 = control_flow_ops.while_loop(\n          lambda i, m, t1: math_ops.less(i, 4), body, [i, m, t1])\n      s1 = list_ops.tensor_list_stack(t1, element_dtype=dtypes.float32)\n      np_s1 = np.vstack([np.arange(1, 4) * i for i in range(4)])\n      self.assertAllEqual(self.evaluate(s1), np_s1)\n\n  def testSerialize(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        t = constant_op.constant([[1.0], [2.0]])\n        l = list_ops.tensor_list_from_tensor(t, element_shape=[1])\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps, e = list_ops.tensor_list_pop_back(\n            l_ps, element_dtype=dtypes.float32)\n      with ops.device(\"/job:worker\"):\n        worker_e = array_ops.identity(e)\n      self.assertAllEqual(self.evaluate(worker_e), [2.0])\n\n  def testSerializeListWithInvalidTensors(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        l = list_ops.tensor_list_reserve(\n            element_dtype=dtypes.float32, element_shape=[], num_elements=2)\n        l = list_ops.tensor_list_set_item(l, 0, 1.)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps = list_ops.tensor_list_set_item(l_ps, 1, 2.)\n        t = list_ops.tensor_list_stack(l_ps, element_dtype=dtypes.float32)\n      with ops.device(\"/job:worker\"):\n        worker_t = array_ops.identity(t)\n      self.assertAllEqual(self.evaluate(worker_t), [1.0, 2.0])\n\n  def testSerializeListWithUnknownRank(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        t = constant_op.constant([[1.0], [2.0]])\n        l = list_ops.tensor_list_from_tensor(t, element_shape=None)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        element_shape = list_ops.tensor_list_element_shape(\n            l_ps, shape_type=dtypes.int32)\n      with ops.device(\"/job:worker\"):\n        element_shape = array_ops.identity(element_shape)\n      self.assertEqual(self.evaluate(element_shape), -1)\n\n  def testSerializeListWithMaxNumElements(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        l = list_ops.empty_tensor_list(\n            element_shape=None,\n            element_dtype=dtypes.float32,\n            max_num_elements=2)\n        l = list_ops.tensor_list_push_back(l, 1.)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps = list_ops.tensor_list_push_back(l_ps, 2.)\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  \"Tried to push item into a full list\"):\n        with ops.device(\"/job:worker\"):\n          l_worker = array_ops.identity(l_ps)\n          l_worker = list_ops.tensor_list_push_back(l_worker, 3.0)\n          self.evaluate(l_worker)\n\n  def testPushPopGradients(self):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=[])\n      c = constant_op.constant(1.0)\n      tape.watch(c)\n      l = list_ops.tensor_list_push_back(l, c)\n      l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      e = 2 * e\n    self.assertAllEqual(self.evaluate(tape.gradient(e, [c])[0]), 2.0)\n\n  def testStackFromTensorGradients(self):\n    with backprop.GradientTape() as tape:\n      c = constant_op.constant([1.0, 2.0])\n      tape.watch(c)\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      c2 = list_ops.tensor_list_stack(\n          l, element_dtype=dtypes.float32, num_elements=2)\n      result = c2 * 2.0\n    grad = tape.gradient(result, [c])[0]\n    self.assertAllEqual(self.evaluate(grad), [2.0, 2.0])\n\n  def testGetSetGradients(self):\n    with backprop.GradientTape() as tape:\n      c = constant_op.constant([1.0, 2.0])\n      tape.watch(c)\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      c2 = constant_op.constant(3.0)\n      tape.watch(c2)\n      l = list_ops.tensor_list_set_item(l, 0, c2)\n      e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      ee = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      y = e * e + ee * ee\n    grad_c, grad_c2 = tape.gradient(y, [c, c2])\n    self.assertAllEqual(self.evaluate(grad_c), [0.0, 4.0])\n    self.assertAllEqual(self.evaluate(grad_c2), 6.0)\n\n  @test_util.run_deprecated_v1\n  def testSetOutOfBounds(self):\n    c = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    with self.assertRaises(errors.InvalidArgumentError):\n      self.evaluate(list_ops.tensor_list_set_item(l, 20, 3.0))\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSetItemWithMismatchedShapeFails(self):\n    with self.cached_session() as sess:\n      ph = array_ops.placeholder(dtypes.float32)\n      c = constant_op.constant([1.0, 2.0])\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      # Set a placeholder with unknown shape to satisfy the shape inference\n      # at graph building time.\n      l = list_ops.tensor_list_set_item(l, 0, ph)\n      l_0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  \"incompatible shape\"):\n        sess.run(l_0, {ph: [3.0]})\n\n  def testResourceVariableScatterGather(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    v = vs.get_variable(\"var\", initializer=[l] * 10, use_resource=True)\n    v_r_0_stacked = list_ops.tensor_list_stack(v[0], dtypes.float32)\n    self.evaluate(v.initializer)\n    self.assertAllEqual([1.0, 2.0], self.evaluate(v_r_0_stacked))\n    v_r_sparse_stacked = list_ops.tensor_list_stack(\n        v.sparse_read(0), dtypes.float32)\n    self.assertAllEqual([1.0, 2.0], self.evaluate(v_r_sparse_stacked))\n    l_new_0 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l_new_1 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    updated_v = state_ops.scatter_update(v, [3, 5], [l_new_0, l_new_1])\n    updated_v_elems = array_ops.unstack(updated_v)\n    updated_v_stacked = [\n        list_ops.tensor_list_stack(el, dtypes.float32) for el in updated_v_elems\n    ]\n    expected = ([[1.0, 2.0]] * 3 + [[3.0, 4.0], [1.0, 2.0], [5.0, 6.0]] +\n                [[1.0, 2.0]] * 4)\n    self.assertAllEqual(self.evaluate(updated_v_stacked), expected)\n\n  def testResourceVariableScatterGatherInt64(self):\n    c = constant_op.constant([1, 2], dtype=dtypes.int64)\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    v = vs.get_variable(\"var\", initializer=[l] * 10, use_resource=True)\n    v_r_0_stacked = list_ops.tensor_list_stack(v[0], dtypes.int64)\n    self.evaluate(v.initializer)\n    self.assertAllEqual([1, 2], self.evaluate(v_r_0_stacked))\n    v_r_sparse_stacked = list_ops.tensor_list_stack(\n        v.sparse_read(0), dtypes.int64)\n    self.assertAllEqual([1, 2], self.evaluate(v_r_sparse_stacked))\n    c34 = constant_op.constant([3, 4], dtype=dtypes.int64)\n    l_new_0 = list_ops.tensor_list_from_tensor(c34, element_shape=[])\n    c56 = constant_op.constant([5, 6], dtype=dtypes.int64)\n    l_new_1 = list_ops.tensor_list_from_tensor(c56, element_shape=[])\n    updated_v = state_ops.scatter_update(v, [3, 5], [l_new_0, l_new_1])\n    updated_v_elems = array_ops.unstack(updated_v)\n    updated_v_stacked = [\n        list_ops.tensor_list_stack(el, dtypes.int64) for el in updated_v_elems\n    ]\n    expected = ([[1, 2]] * 3 + [[3, 4], [1, 2], [5, 6]] +\n                [[1, 2]] * 4)\n    self.assertAllEqual(self.evaluate(updated_v_stacked), expected)\n\n  @test_util.run_deprecated_v1\n  def testConcat(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l0 = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    l1 = list_ops.tensor_list_from_tensor([-1.0], element_shape=[])\n    l_batch_0 = array_ops.stack([l0, l1])\n    l_batch_1 = array_ops.stack([l1, l0])\n\n    l_concat_01 = list_ops.tensor_list_concat_lists(\n        l_batch_0, l_batch_1, element_dtype=dtypes.float32)\n    l_concat_10 = list_ops.tensor_list_concat_lists(\n        l_batch_1, l_batch_0, element_dtype=dtypes.float32)\n    l_concat_00 = list_ops.tensor_list_concat_lists(\n        l_batch_0, l_batch_0, element_dtype=dtypes.float32)\n    l_concat_11 = list_ops.tensor_list_concat_lists(\n        l_batch_1, l_batch_1, element_dtype=dtypes.float32)\n\n    expected_0 = [[1.0, 2.0], [-1.0]]\n    expected_1 = [[-1.0], [1.0, 2.0]]\n    expected_00 = [[1.0, 2.0, 1.0, 2.0], [-1.0, -1.0]]\n    expected_01 = [[1.0, 2.0, -1.0], [-1.0, 1.0, 2.0]]\n    expected_10 = [[-1.0, 1.0, 2.0], [1.0, 2.0, -1.0]]\n    expected_11 = [[-1.0, -1.0], [1.0, 2.0, 1.0, 2.0]]\n\n    for i, (concat, expected) in enumerate(zip(\n        [l_batch_0, l_batch_1,\n         l_concat_00, l_concat_01, l_concat_10, l_concat_11],\n        [expected_0, expected_1,\n         expected_00, expected_01, expected_10, expected_11])):\n      splitted = array_ops.unstack(concat)\n      splitted_stacked_ret = self.evaluate(\n          (list_ops.tensor_list_stack(splitted[0], dtypes.float32),\n           list_ops.tensor_list_stack(splitted[1], dtypes.float32)))\n      print(\"Test concat %d: %s, %s, %s, %s\"\n            % (i, expected[0], splitted_stacked_ret[0],\n               expected[1], splitted_stacked_ret[1]))\n      self.assertAllClose(expected[0], splitted_stacked_ret[0])\n      self.assertAllClose(expected[1], splitted_stacked_ret[1])\n\n    # Concatenating mismatched shapes fails.\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(\n              l_batch_0,\n              list_ops.empty_tensor_list([], dtypes.float32),\n              element_dtype=dtypes.float32))\n\n    if context.executing_eagerly():\n      expected_error = (\n          errors.InvalidArgumentError,\n          \"element shapes are not identical at index 0\")\n    else:\n      expected_error = (ValueError, \"Shapes must be equal rank\")\n    with self.assertRaisesRegex(*expected_error):\n      l_batch_of_vec_tls = array_ops.stack(\n          [list_ops.tensor_list_from_tensor([[1.0]], element_shape=[1])] * 2)\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(l_batch_0, l_batch_of_vec_tls,\n                                            element_dtype=dtypes.float32))\n\n    if context.executing_eagerly():\n      expected_error = (errors.InvalidArgumentError,\n                        r\"input_b\\[0\\].dtype != element_dtype.\")\n    else:\n      expected_error = (ValueError, \"input_b.type != element_dtype\")\n    with self.assertRaisesRegex(*expected_error):\n      l_batch_of_int_tls = array_ops.stack(\n          [list_ops.tensor_list_from_tensor([1], element_shape=[])] * 2)\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(l_batch_0, l_batch_of_int_tls,\n                                            element_dtype=dtypes.float32))\n\n  @test_util.run_deprecated_v1\n  def testPushBackBatch(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l0 = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    l1 = list_ops.tensor_list_from_tensor([-1.0], element_shape=[])\n    l_batch = array_ops.stack([l0, l1])\n    l_push = list_ops.tensor_list_push_back_batch(l_batch, [3.0, 4.0])\n    l_unstack = array_ops.unstack(l_push)\n    l0_ret = list_ops.tensor_list_stack(l_unstack[0], dtypes.float32)\n    l1_ret = list_ops.tensor_list_stack(l_unstack[1], dtypes.float32)\n    self.assertAllClose([1.0, 2.0, 3.0], self.evaluate(l0_ret))\n    self.assertAllClose([-1.0, 4.0], self.evaluate(l1_ret))\n\n    with ops.control_dependencies([l_push]):\n      l_unstack_orig = array_ops.unstack(l_batch)\n      l0_orig_ret = list_ops.tensor_list_stack(l_unstack_orig[0],\n                                               dtypes.float32)\n      l1_orig_ret = list_ops.tensor_list_stack(l_unstack_orig[1],\n                                               dtypes.float32)\n\n    # Check that without aliasing, push_back_batch still works; and\n    # that it doesn't modify the input.\n    l0_r_v, l1_r_v, l0_orig_v, l1_orig_v = self.evaluate(\n        (l0_ret, l1_ret, l0_orig_ret, l1_orig_ret))\n    self.assertAllClose([1.0, 2.0, 3.0], l0_r_v)\n    self.assertAllClose([-1.0, 4.0], l1_r_v)\n    self.assertAllClose([1.0, 2.0], l0_orig_v)\n    self.assertAllClose([-1.0], l1_orig_v)\n\n    # Pushing back mismatched shapes fails.\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      self.evaluate(list_ops.tensor_list_push_back_batch(l_batch, []))\n\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"incompatible shape to a list at index 0\"):\n      self.evaluate(\n          list_ops.tensor_list_push_back_batch(l_batch, [[3.0], [4.0]]))\n\n    if context.executing_eagerly():\n      expected_error = (errors.InvalidArgumentError, \"Invalid data type\")\n    else:\n      expected_error = (ValueError, \"wrong element dtype\")\n    with self.assertRaisesRegex(*expected_error):\n      self.evaluate(list_ops.tensor_list_push_back_batch(l_batch, [3, 4]))\n\n  def testZerosLike(self):\n    for dtype in (dtypes.uint8, dtypes.uint16, dtypes.int8, dtypes.int16,\n                  dtypes.int32, dtypes.int64, dtypes.float16, dtypes.float32,\n                  dtypes.float64, dtypes.complex64, dtypes.complex128,\n                  dtypes.bool):\n      l_empty = list_ops.empty_tensor_list(\n          element_dtype=dtype, element_shape=[])\n      l_empty_zeros = array_ops.zeros_like(l_empty)\n      t_empty_zeros = list_ops.tensor_list_stack(\n          l_empty_zeros, element_dtype=dtype)\n\n      l_full = list_ops.tensor_list_push_back(l_empty,\n                                              math_ops.cast(0, dtype=dtype))\n      l_full = list_ops.tensor_list_push_back(l_full,\n                                              math_ops.cast(1, dtype=dtype))\n      l_full_zeros = array_ops.zeros_like(l_full)\n      t_full_zeros = list_ops.tensor_list_stack(\n          l_full_zeros, element_dtype=dtype)\n\n      self.assertAllEqual(self.evaluate(t_empty_zeros), [])\n      self.assertAllEqual(\n          self.evaluate(t_full_zeros), np.zeros(\n              (2,), dtype=dtype.as_numpy_dtype))\n\n  def testZerosLikeNested(self):\n    for dtype in (dtypes.uint8, dtypes.uint16, dtypes.int8, dtypes.int16,\n                  dtypes.int32, dtypes.int64, dtypes.float16, dtypes.float32,\n                  dtypes.float64, dtypes.complex64, dtypes.complex128,\n                  dtypes.bool):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.variant, element_shape=[])\n\n      sub_l = list_ops.empty_tensor_list(element_dtype=dtype, element_shape=[])\n      l = list_ops.tensor_list_push_back(l, sub_l)\n      sub_l = list_ops.tensor_list_push_back(sub_l, math_ops.cast(\n          1, dtype=dtype))\n      l = list_ops.tensor_list_push_back(l, sub_l)\n      sub_l = list_ops.tensor_list_push_back(sub_l, math_ops.cast(\n          2, dtype=dtype))\n      l = list_ops.tensor_list_push_back(l, sub_l)\n\n      # l : [[],\n      #      [1],\n      #      [1, 2]]\n      #\n      # l_zeros : [[],\n      #            [0],\n      #            [0, 0]]\n      l_zeros = array_ops.zeros_like(l)\n\n      outputs = []\n      for _ in range(3):\n        l_zeros, out = list_ops.tensor_list_pop_back(\n            l_zeros, element_dtype=dtypes.variant)\n        outputs.append(list_ops.tensor_list_stack(out, element_dtype=dtype))\n\n      # Note: `outputs` contains popped values so the order is reversed.\n      self.assertAllEqual(self.evaluate(outputs[2]), [])\n      self.assertAllEqual(\n          self.evaluate(outputs[1]), np.zeros((1,), dtype=dtype.as_numpy_dtype))\n      self.assertAllEqual(\n          self.evaluate(outputs[0]), np.zeros((2,), dtype=dtype.as_numpy_dtype))\n\n  def testElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    shape = list_ops.tensor_list_element_shape(l, shape_type=dtypes.int32)\n    self.assertEqual(self.evaluate(shape), -1)\n\n  def testZerosLikeUninitialized(self):\n    l0 = list_ops.tensor_list_reserve([], 3, element_dtype=dtypes.float32)\n    l1 = list_ops.tensor_list_set_item(l0, 0, 1.)  # [1., _, _]\n    zeros_1 = array_ops.zeros_like(l1)  # [0., _, _]\n    l2 = list_ops.tensor_list_set_item(l1, 2, 2.)  # [1., _, 2.]\n    zeros_2 = array_ops.zeros_like(l2)  # [0., _, 0.]\n\n    # Gather indices with zeros in `zeros_1`.\n    res_1 = list_ops.tensor_list_gather(\n        zeros_1, [0], element_dtype=dtypes.float32)\n    # Gather indices with zeros in `zeros_2`.\n    res_2 = list_ops.tensor_list_gather(\n        zeros_2, [0, 2], element_dtype=dtypes.float32)\n\n    self.assertAllEqual(self.evaluate(res_1), [0.])\n    self.assertAllEqual(self.evaluate(res_2), [0., 0.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerTensorListGetItemGradAggregation(self):\n    l = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    x = constant_op.constant(1.0)\n    l = list_ops.tensor_list_set_item(l, 0, x)\n    l_read1 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    l_read2 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients([l_read1, l_read2], [x])\n    with self.cached_session() as sess:\n      self.assertSequenceEqual(self.evaluate(grad), [2.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerBuildElementShape(self):\n    fn = list_ops._build_element_shape\n    # Unknown shape -> -1.\n    self.assertEqual(fn(None), -1)\n    self.assertEqual(fn(tensor_shape.unknown_shape()), -1)\n    # Scalar shape -> [] with type int32.\n    self.assertEqual(fn([]).dtype, dtypes.int32)\n    self.assertEqual(fn(tensor_shape.TensorShape([])).dtype, dtypes.int32)\n    self.assertAllEqual(self.evaluate(fn([])), np.array([], np.int32))\n    self.assertAllEqual(\n        self.evaluate(fn(tensor_shape.TensorShape([]))), np.array([], np.int32))\n    # Tensor -> Tensor\n    shape = constant_op.constant(1)\n    self.assertIs(fn(shape), shape)\n    # Shape with unknown dims -> shape list with -1's.\n    shape = [None, 5]\n    self.assertAllEqual(fn(shape), [-1, 5])\n    self.assertAllEqual(fn(tensor_shape.TensorShape(shape)), [-1, 5])\n    # Shape with unknown dims and tensor dims -> shape list with -1's and tensor\n    # dims.\n    t = array_ops.placeholder(dtypes.int32)\n    shape = [None, 5, t]\n    result = fn(shape)\n    self.assertAllEqual(result[:2], [-1, 5])\n    self.assertIs(result[2], t)\n\n  def testAddN(self):\n    l1 = list_ops.tensor_list_from_tensor([1.0, 2.0], element_shape=[])\n    l2 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l3 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    result = math_ops.add_n((l1, l2, l3))\n    result_t = list_ops.tensor_list_stack(result, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(result_t), [9., 12.])\n\n  def testAddNNestedList(self):\n    l1 = list_ops.tensor_list_from_tensor([1.0, 2.0], element_shape=[])\n    l2 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l3 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    l4 = list_ops.tensor_list_from_tensor([7.0, 8.0], element_shape=[])\n    a = list_ops.empty_tensor_list(\n        element_dtype=dtypes.variant, element_shape=[])\n    a = list_ops.tensor_list_push_back(a, l1)\n    a = list_ops.tensor_list_push_back(a, l2)\n    b = list_ops.empty_tensor_list(\n        element_dtype=dtypes.variant, element_shape=[])\n    b = list_ops.tensor_list_push_back(b, l3)\n    b = list_ops.tensor_list_push_back(b, l4)\n    result = math_ops.add_n((a, b))\n    result_0 = list_ops.tensor_list_stack(\n        list_ops.tensor_list_get_item(result, 0, element_dtype=dtypes.variant),\n        element_dtype=dtypes.float32)\n    result_1 = list_ops.tensor_list_stack(\n        list_ops.tensor_list_get_item(result, 1, element_dtype=dtypes.variant),\n        element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(result_0), [6., 8.])\n    self.assertAllEqual(self.evaluate(result_1), [10., 12.])\n\n  def testAddTensorListsFailsIfLeadingDimsMismatch(self):\n    l1 = list_ops.tensor_list_reserve(\n        element_shape=[], element_dtype=dtypes.float32, num_elements=2)\n    l2 = list_ops.tensor_list_reserve(\n        element_shape=[], element_dtype=dtypes.float32, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to add two lists of tensors with different lengths\"):\n      l = math_ops.add_n([l1, l2])\n      self.evaluate(list_ops.tensor_list_stack(l, element_dtype=dtypes.float32))\n\n  @test_util.run_v1_only(\"Uses placeholders\")\n  def testSkipEagerAddTensorListsFailsIfElementShapesMismatch(self):\n    with self.cached_session() as sess:\n      # Use placeholders instead of constant values for shapes to prevent TF's\n      # shape inference from catching this early.\n      l1_element_shape = array_ops.placeholder(dtype=dtypes.int32)\n      l2_element_shape = array_ops.placeholder(dtype=dtypes.int32)\n      l1 = list_ops.tensor_list_reserve(\n          element_shape=l1_element_shape,\n          element_dtype=dtypes.float32,\n          num_elements=3)\n      l2 = list_ops.tensor_list_reserve(\n          element_shape=l2_element_shape,\n          element_dtype=dtypes.float32,\n          num_elements=3)\n      l = math_ops.add_n([l1, l2])\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          \"Trying to add two lists of tensors with incompatible element shapes\"\n      ):\n        sess.run(\n            list_ops.tensor_list_stack(l, element_dtype=dtypes.float32), {\n                l1_element_shape: [],\n                l2_element_shape: [2]\n            })\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerConcatShapeInference(self):\n\n    def BuildTensor(element_shape):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=element_shape)\n      return list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n\n    self.assertIsNone(BuildTensor(None).shape.rank)\n    self.assertAllEqual(BuildTensor([None, 2, 3]).shape.as_list(), [None, 2, 3])\n    self.assertAllEqual(\n        BuildTensor([None, 2, None]).shape.as_list(), [None, 2, None])\n    self.assertAllEqual(BuildTensor([1, 2, 3]).shape.as_list(), [None, 2, 3])\n\n  def testConcatWithFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[2, 2])\n    l = list_ops.tensor_list_push_back(l, [[0., 1.], [2., 3.]])\n    l = list_ops.tensor_list_push_back(l, [[4., 5.], [6., 7.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(\n        self.evaluate(t), [[0., 1.], [2., 3.], [4., 5.], [6., 7.]])\n\n  def testConcatWithNonFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[None, 2])\n    l = list_ops.tensor_list_push_back(l, [[0., 1.]])\n    l = list_ops.tensor_list_push_back(l, [[2., 3.], [4., 5.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[0., 1.], [2., 3.], [4., 5.]])\n\n  def testConcatWithMismatchingTensorShapesFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l = list_ops.tensor_list_push_back(l, [[0., 1.]])\n    l = list_ops.tensor_list_push_back(l, [[2.], [4.]])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, r\"Incompatible shapes during merge: \"\n        r\"\\[2\\] vs. \\[1\\]\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatEmptyListWithFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[5, 2])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 2))\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[None, 2])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 2))\n\n  def testConcatEmptyListWithUnknownElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"All except the first dimension must be fully\"\n        \" defined when concating an empty tensor list\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatEmptyListWithPartiallyDefinedElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[2, None])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"All except the first dimension must be fully\"\n        \" defined when concating an empty tensor list\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatListWithScalarElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=tensor_shape.TensorShape([]))\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Concat requires elements to be at least vectors, \"\n        \"found scalars instead\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatListWithScalarElementsFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l1 = list_ops.tensor_list_push_back(l, 1.)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Concat saw a scalar shape at index 0\"\n        \" but requires at least vectors\"):\n      t = list_ops.tensor_list_concat(l1, element_dtype=dtypes.float32)\n      self.evaluate(t)\n    l1 = list_ops.tensor_list_push_back(l, [1.])\n    l1 = list_ops.tensor_list_push_back(l1, 2.)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Concat saw a scalar shape at index 1\"\n        \" but requires at least vectors\"):\n      t = list_ops.tensor_list_concat(l1, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatWithUninitializedTensorsUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(np.zeros((6, 3)), t)\n\n  def testConcatWithUninitializedTensorsUseProvidedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = list_ops.tensor_list_concat(\n        l, element_dtype=dtypes.float32, element_shape=(2, 3))\n    self.assertAllEqual(np.zeros((6, 3)), t)\n\n  def testConcatWithUninitializedTensorsUseProvidedElementShapeAndLengths(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t, _ = gen_list_ops.tensor_list_concat_v2(\n        l,\n        element_dtype=dtypes.float32,\n        element_shape=list_ops._build_element_shape((None, 3)),\n        leading_dims=[2, 3, 5])\n    self.assertAllEqual(np.zeros((10, 3)), t)\n    l = list_ops.tensor_list_set_item(l, 1, [[2., 3.], [4., 5.], [6., 7.]])\n    t, _ = gen_list_ops.tensor_list_concat_v2(\n        l,\n        element_dtype=dtypes.float32,\n        element_shape=list_ops._build_element_shape((None, 2)),\n        leading_dims=[2, 3, 4])\n    self.assertAllEqual([[0., 0.], [0., 0.], [2., 3.], [4., 5.], [6., 7.],\n                         [0., 0.], [0., 0.], [0., 0.], [0., 0.]], t)\n\n  def testConcatWithUninitializedTensorsInferShapeFromElements(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [[2., 3.], [4., 5.], [6., 7.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual([[0., 0.], [0., 0.], [0., 0.], [2., 3.], [4., 5.],\n                         [6., 7.], [0., 0.], [0., 0.], [0., 0.]], t)\n\n  def testConcatWithUninitializedTensorsFailsIfNoElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Trying to concat list with only uninitialized tensors \"\n        r\"but element_shape_except_first_dim is not fully defined\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatWithUninitializedTensorsFailsIfNoInputLengths(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"List contains uninitialized tensor at index 0\"\n        r\" but leading_dims has only 0 elements.\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testEmptyTensorListInvalidShape(self):\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                r\"Shape must be at most rank 1 but is rank 2\"):\n      t = gen_list_ops.EmptyTensorList(\n          element_shape=array_ops.ones(dtype=dtypes.int32, shape=[1, 0]),\n          max_num_elements=constant_op.constant(1),\n          element_dtype=dtypes.int32)\n      self.evaluate(t)\n\n  def testEvenSplit(self):\n\n    def RunTest(input_tensor, lengths, expected_stacked_output):\n      l = list_ops.tensor_list_split(\n          input_tensor, element_shape=None, lengths=lengths)\n      self.assertAllEqual(\n          list_ops.tensor_list_stack(l, element_dtype=dtypes.float32),\n          expected_stacked_output)\n\n    RunTest([1., 2., 3.], [1, 1, 1], [[1.], [2.], [3.]])\n    RunTest([1., 2., 3., 4.], [2, 2], [[1., 2.], [3., 4.]])\n    RunTest([[1., 2.], [3., 4.]], [1, 1], [[[1., 2.]], [[3., 4.]]])\n\n  def testUnevenSplit(self):\n    l = list_ops.tensor_list_split([1., 2., 3., 4., 5],\n                                   element_shape=None,\n                                   lengths=[3, 2])\n    self.assertAllEqual(list_ops.tensor_list_length(l), 2)\n    self.assertAllEqual(\n        list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32),\n        [1., 2., 3.])\n    self.assertAllEqual(\n        list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32),\n        [4., 5.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithInvalidTensorShapeFails(self):\n    with self.cached_session():\n      tensor = array_ops.placeholder(dtype=dtypes.float32)\n      l = list_ops.tensor_list_split(tensor, element_shape=None, lengths=[1])\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"Tensor must be at least a vector, but saw shape: \\[\\]\"):\n        l.eval({tensor: 1})\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithInvalidLengthsShapeFails(self):\n    with self.cached_session():\n      lengths = array_ops.placeholder(dtype=dtypes.int64)\n      l = list_ops.tensor_list_split([1., 2.],\n                                     element_shape=None,\n                                     lengths=lengths)\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"Expected lengths to be a vector, received shape: \\[\\]\"):\n        l.eval({lengths: 1})\n\n  def testSplitWithInvalidLengthsFails(self):\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                r\"Invalid value in lengths: -1\"):\n      l = list_ops.tensor_list_split([1., 2.],\n                                     element_shape=None,\n                                     lengths=[1, -1])\n      self.evaluate(l)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Attempting to slice \\[0, 3\\] from tensor with length 2\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=None, lengths=[3])\n      self.evaluate(l)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Unused values in tensor. Length of tensor: 2 Values used: 1\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=None, lengths=[1])\n      self.evaluate(l)\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithScalarElementShapeFails(self):\n    with self.assertRaisesRegex(ValueError,\n                                r\"Shapes must be equal rank, but are 1 and 0\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=[], lengths=[1, 1])\n    with self.cached_session():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"TensorListSplit requires element_shape to be at least of rank 1, \"\n          r\"but saw: \\[\\]\"):\n        element_shape = array_ops.placeholder(dtype=dtypes.int32)\n        l = list_ops.tensor_list_split([1., 2.],\n                                       element_shape=element_shape,\n                                       lengths=[1, 1])\n        l.eval({element_shape: []})\n\n  def testEagerOnlySplitWithScalarElementShapeFails(self):\n    if context.executing_eagerly():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"TensorListSplit requires element_shape to be at least of rank 1, \"\n          r\"but saw: \\[\\]\"):\n        list_ops.tensor_list_split([1., 2.], element_shape=[], lengths=[1, 1])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithIncompatibleTensorShapeAndElementShapeFails(self):\n    with self.assertRaisesRegex(ValueError,\n                                r\"Shapes must be equal rank, but are 2 and 1\"):\n      l = list_ops.tensor_list_split([[1.], [2.]],\n                                     element_shape=[1],\n                                     lengths=[1, 1])\n\n    with self.cached_session():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"tensor shape \\[2,1\\] is not compatible with element_shape \\[1\\]\"):\n        element_shape = array_ops.placeholder(dtype=dtypes.int32)\n        l = list_ops.tensor_list_split([[1.], [2.]],\n                                       element_shape=element_shape,\n                                       lengths=[1, 1])\n        l.eval({element_shape: [1]})\n\n  def testEagerOnlySplitWithIncompatibleTensorShapeAndElementShapeFails(self):\n    if context.executing_eagerly():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"tensor shape \\[2,1\\] is not compatible with element_shape \\[1\\]\"):\n        list_ops.tensor_list_split([[1.], [2.]],\n                                   element_shape=[1],\n                                   lengths=[1, 1])\n\n  def testResizeGrow(self):\n    l = list_ops.tensor_list_from_tensor([1., 2.], element_shape=[])\n    l = list_ops.tensor_list_resize(l, 4)\n    self.assertEqual(self.evaluate(list_ops.tensor_list_length(l)), 4)\n    self.assertEqual(\n        self.evaluate(\n            list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)),\n        1.)\n    self.assertEqual(\n        self.evaluate(\n            list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)),\n        2.)\n\n  def testResizeShrink(self):\n    l = list_ops.tensor_list_from_tensor([1., 2., 3.], element_shape=[])\n    l = list_ops.tensor_list_resize(l, 2)\n    self.assertEqual(self.evaluate(list_ops.tensor_list_length(l)), 2)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)),\n        [1., 2.])\n\n  def testResizeWithInvalidSizeFails(self):\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListSlice expects size to be non-negative\"):\n      l = list_ops.tensor_list_from_tensor([1., 2., 3.], element_shape=[])\n      l = list_ops.tensor_list_resize(l, -1)\n      self.evaluate(l)\n\n  @test_util.run_deprecated_v1\n  @test_util.enable_control_flow_v2\n  def testSkipEagerResizeGrad(self):\n    t = constant_op.constant([1., 2., 3.])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    l = list_ops.tensor_list_set_item(\n        l, 3, 4., resize_if_index_out_of_bounds=True)\n    t1 = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients(t1, t)[0]\n    self.assertAllEqual(self.evaluate(grad), [1., 1., 1.])\n\n  def testHandleDataAcrossFunctionCall(self):\n\n    @def_function.function\n    def func():\n      t = constant_op.constant([1., 2., 3.])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      handle_data = resource_variable_ops.get_eager_safe_handle_data(l)\n      self.assertTrue(handle_data.is_set)\n      self.assertEqual(handle_data.shape_and_type[0].type.type_id,\n                       full_type_pb2.TFT_ARRAY)\n      return l\n\n    tensor_list = func()\n    handle_data = resource_variable_ops.get_eager_safe_handle_data(tensor_list)\n    self.assertTrue(handle_data.is_set)\n    self.assertEqual(dtypes.float32, handle_data.shape_and_type[0].dtype)\n    self.assertEqual(handle_data.shape_and_type[0].type.type_id,\n                     full_type_pb2.TFT_ARRAY)\n    element = list_ops.tensor_list_get_item(\n        tensor_list, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(element.shape.as_list(), [])\n\n  @test_util.run_gpu_only\n  def testNestedListDevicetoDeviceCopy(self):\n    if context.num_gpus() < 2:\n      self.skipTest(\"Need at least 2 GPUs for this test, found %d\" %\n                    context.num_gpus())\n    with ops.device(\"gpu:0\"):\n      t = constant_op.constant([1.0, 2.0, 3.0])\n      inner_l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      outer_l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.variant, element_shape=[])\n      outer_l = list_ops.tensor_list_push_back(outer_l, inner_l)\n\n    # Stress test.\n    for _ in range(1024):\n      with ops.device(\"gpu:1\"):\n        outer_l = array_ops.identity(outer_l)\n      with ops.device(\"gpu:0\"):\n        outer_l = array_ops.identity(outer_l)\n\n    with ops.device(\"gpu:1\"):\n      _, inner_l = list_ops.tensor_list_pop_back(\n          outer_l, element_dtype=dtypes.variant)\n      t = list_ops.tensor_list_stack(inner_l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [1.0, 2.0, 3.0])\n\n  def testTensorListStrings(self):\n    @def_function.function\n    def f():\n      return map_fn.map_fn(string_ops.string_upper,\n                           constant_op.constant([\"a\", \"b\", \"c\"]))\n\n    self.assertAllEqual(f(), [b\"A\", b\"B\", b\"C\"])\n\n  def testTensorListStringsNoInline(self):\n    # Generator function output type is a variant with a host-only underlying\n    # data type. \"ColocationGraph::AddHostOnlyDataTypesConstraints\" needs to\n    # have \"deep op inspection\" to be able to correctly place the while loop\n    # generated from map_fn.\n    self.skipTest(\"b/150742232\")\n\n    @function.defun_with_attributes(attributes={\"_noinline\": True})\n    def generator():\n      c = constant_op.constant([\"a\", \"b\", \"c\"])\n      return list_ops.tensor_list_from_tensor(c, element_shape=[])\n\n    @def_function.function\n    def f():\n      l = generator()\n\n      def upper(i):\n        e = list_ops.tensor_list_get_item(l, i, element_dtype=dtypes.string)\n        return string_ops.string_upper(e)\n\n      return map_fn.map_fn(\n          upper, constant_op.constant([0, 1, 2]), dtype=dtypes.string)\n\n    self.assertAllEqual(f(), [b\"A\", b\"B\", b\"C\"])\n\n  def testPopBackGrad(self):\n    # https://github.com/tensorflow/tensorflow/issues/37230\n\n    @def_function.function\n    def g(x):\n      x_prod = constant_op.constant([1.])\n      for unused_i in math_ops.range(3):\n        x_prod = x_prod * x\n      return x_prod\n\n    x = constant_op.constant(1.)\n    with backprop.GradientTape() as t:\n      t.watch(x)\n      with backprop.GradientTape() as tt:\n        tt.watch(x)\n        loss = g(x)\n      jac = tt.gradient(loss, x)\n    hess = t.gradient(jac, x)\n    self.assertAllEqual(hess, 6.)\n\n  def testTensorListElementShapeShapeInference(self):\n\n    @def_function.function\n    def f():\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=None)\n      l_element_shape = list_ops.tensor_list_element_shape(l, dtypes.int32)\n      self.assertIsNone(l_element_shape.shape.rank)\n      shape_l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.int32, element_shape=l_element_shape.shape)\n      shape_l = list_ops.tensor_list_push_back(shape_l, l_element_shape)\n      return list_ops.tensor_list_pop_back(shape_l, dtypes.int32)[1]\n\n    self.assertAllEqual(f(), -1)\n\n  def testElementShapeArgOfTensorListFromTensor(self):\n\n    @def_function.function\n    def f():\n      t = array_ops.ones([3, 3])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[-1])\n      l = list_ops.tensor_list_push_back(l, array_ops.ones([4]))\n      read_val = list_ops.tensor_list_get_item(\n          l, 3, element_dtype=dtypes.float32)\n      self.assertAllEqual(read_val.shape.as_list(), [None])\n      return read_val\n\n    self.assertAllEqual(f(), [1.0, 1.0, 1.0, 1.0])\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "fixing_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#define EIGEN_USE_THREADS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/list_kernels.h\"\n\n#include <algorithm>\n#include <iterator>\n#include <limits>\n#include <memory>\n#include <utility>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/variant.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\nStatus TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n  if (t.shape() == TensorShape({})) {\n    if ((t.dtype() == DT_INT32 && t.scalar<int32>()() == -1) ||\n        (t.dtype() == DT_INT64 && t.scalar<int64_t>()() == -1)) {\n      *out = PartialTensorShape();\n      return OkStatus();\n    }\n    return errors::InvalidArgument(\n        \"The only valid scalar shape tensor is the fully unknown shape \"\n        \"specified as -1.\");\n  } else if (t.shape().dims() != 1) {\n    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n                                   t.shape().dims());\n  }\n  if (t.dtype() == DT_INT32) {\n    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n                                                t.NumElements(), out);\n  } else if (t.dtype() == DT_INT64) {\n    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),\n                                                t.NumElements(), out);\n  }\n  return errors::InvalidArgument(\n      \"Expected an int32 or int64 shape tensor; found \",\n      DataTypeString(t.dtype()));\n}\n\nStatus GetElementShapeFromInput(OpKernelContext* c,\n                                const TensorList& tensor_list, int index,\n                                PartialTensorShape* element_shape) {\n  TF_RETURN_IF_ERROR(TensorShapeFromTensor(c->input(index), element_shape));\n  // Check that `element_shape` and `tensor_list.element_shape` are\n  // compatible and store the merged shape in `element_shape`.\n  PartialTensorShape tmp = *element_shape;\n  TF_RETURN_IF_ERROR(tmp.MergeWith(tensor_list.element_shape, element_shape));\n  return OkStatus();\n}\n\nStatus GetInputList(OpKernelContext* c, int index, const TensorList** list) {\n  if (!TensorShapeUtils::IsScalar(c->input(index).shape())) {\n    return errors::InvalidArgument(\"Input list must be a scalar saw: \",\n                                   c->input(index).shape().DebugString());\n  }\n  const TensorList* l = c->input(index).scalar<Variant>()().get<TensorList>();\n  if (l == nullptr) {\n    return errors::InvalidArgument(\n        \"Input handle is not a list. Saw: '\",\n        c->input(index).scalar<Variant>()().DebugString(), \"'\");\n  }\n  *list = l;\n  return OkStatus();\n}\n\nStatus ForwardInputOrCreateNewList(OpKernelContext* c, int32_t input_index,\n                                   int32_t output_index,\n                                   const TensorList& input_list,\n                                   TensorList** output_list) {\n  // Attempt to forward the input tensor to the output if possible.\n  std::unique_ptr<Tensor> maybe_output = c->forward_input(\n      input_index, output_index, DT_VARIANT, TensorShape{},\n      c->input_memory_type(input_index), AllocatorAttributes());\n  Tensor* output_tensor;\n  if (maybe_output != nullptr && maybe_output->dtype() == DT_VARIANT &&\n      maybe_output->NumElements() == 1) {\n    output_tensor = maybe_output.get();\n    TensorList* tmp_out = output_tensor->scalar<Variant>()().get<TensorList>();\n    if (tmp_out == nullptr) {\n      return errors::InvalidArgument(\n          \"Expected input \", input_index, \" to be a TensorList but saw \",\n          output_tensor->scalar<Variant>()().TypeName());\n    }\n    if (tmp_out->RefCountIsOne()) {\n      // Woohoo, forwarding succeeded!\n      c->set_output(output_index, *output_tensor);\n      *output_list = tmp_out;\n      return OkStatus();\n    }\n  }\n\n  // If forwarding is not possible allocate a new output tensor and copy\n  // the `input_list` to it.\n  AllocatorAttributes attr;\n  attr.set_on_host(true);\n  TF_RETURN_IF_ERROR(\n      c->allocate_output(output_index, {}, &output_tensor, attr));\n  output_tensor->scalar<Variant>()() = input_list.Copy();\n\n  *output_list = output_tensor->scalar<Variant>()().get<TensorList>();\n  return OkStatus();\n}\n\nclass EmptyTensorList : public OpKernel {\n public:\n  explicit EmptyTensorList(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& max_num_elements_t = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(max_num_elements_t.shape()),\n        errors::InvalidArgument(\n            \"max_num_elements expected to be a scalar \",\n            \"but got shape: \", max_num_elements_t.shape().DebugString()));\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape{}, &result, attr));\n    TensorList empty;\n    empty.element_dtype = element_dtype_;\n    empty.max_num_elements = max_num_elements_t.scalar<int32>()();\n    PartialTensorShape element_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeFromTensor(ctx->input(0), &element_shape));\n    empty.element_shape = element_shape;\n    result->scalar<Variant>()() = std::move(empty);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\").Device(DEVICE_CPU),\n                        EmptyTensorList);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"max_num_elements\"),\n                        EmptyTensorList);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"EmptyTensorList\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"max_num_elements\"),\n                        EmptyTensorList);\n\nclass TensorListPushBack : public OpKernel {\n public:\n  explicit TensorListPushBack(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  ~TensorListPushBack() override {}\n\n  void Compute(OpKernelContext* c) override {\n    const Tensor& input = c->input(1);\n    OP_REQUIRES(c, element_dtype_ == input.dtype(),\n                errors::InvalidArgument(\"Invalid data types; list elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but tried to append \",\n                                        DataTypeString(input.dtype())));\n\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    OP_REQUIRES(c, l->element_shape.IsCompatibleWith(input.shape()),\n                errors::InvalidArgument(\n                    \"Tried to append a tensor with incompatible shape to a \"\n                    \"list. Op element shape: \",\n                    input.shape().DebugString(),\n                    \" list shape: \", l->element_shape.DebugString()));\n    OP_REQUIRES(c, element_dtype_ == l->element_dtype,\n                errors::InvalidArgument(\"Invalid data types; op elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but list elements \",\n                                        DataTypeString(l->element_dtype)));\n\n    if (l->max_num_elements != -1) {\n      OP_REQUIRES(\n          c, l->tensors().size() < l->max_num_elements,\n          errors::InvalidArgument(\"Tried to push item into a full list\",\n                                  \" list size: \", l->tensors().size(),\n                                  \" max_num_elements: \", l->max_num_elements));\n    }\n\n    TensorList* output_list = nullptr;\n    OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n    output_list->tensors().push_back(input);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_CPU),\n                        TensorListPushBack);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_GPU),\n                        TensorListPushBack);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListPushBack\").Device(DEVICE_DEFAULT),\n                        TensorListPushBack);\n\nclass TensorListLength : public OpKernel {\n public:\n  explicit TensorListLength(OpKernelConstruction* c) : OpKernel(c) {}\n  ~TensorListLength() override {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    Tensor* result;\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result));\n    result->scalar<int32>()() = l->tensors().size();\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListLength\").Device(DEVICE_CPU),\n                        TensorListLength);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListLength\").Device(DEVICE_GPU).HostMemory(\"length\"),\n    TensorListLength);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListLength\").Device(DEVICE_DEFAULT).HostMemory(\"length\"),\n    TensorListLength);\n\nclass TensorListElementShape : public OpKernel {\n public:\n  explicit TensorListElementShape(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    Tensor* result;\n    if (l->element_shape.unknown_rank()) {\n      OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape({}), &result));\n      if (result->dtype() == DT_INT32) {\n        result->scalar<int32>()() = -1;\n      } else {\n        result->scalar<int64_t>()() = -1;\n      }\n    } else {\n      OP_REQUIRES_OK(c, c->allocate_output(\n                            0, TensorShape{l->element_shape.dims()}, &result));\n      for (int i = 0; i < l->element_shape.dims(); ++i) {\n        if (result->dtype() == DT_INT32) {\n          result->flat<int32>()(i) = l->element_shape.dim_size(i);\n        } else {\n          result->flat<int64_t>()(i) = l->element_shape.dim_size(i);\n        }\n      }\n    }\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\").Device(DEVICE_CPU),\n                        TensorListElementShape);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\"),\n                        TensorListElementShape);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListElementShape\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\"),\n                        TensorListElementShape);\n\nclass TensorListReserve : public OpKernel {\n public:\n  explicit TensorListReserve(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    PartialTensorShape element_shape;\n    OP_REQUIRES_OK(c, TensorShapeFromTensor(c->input(0), &element_shape));\n    OP_REQUIRES(\n        c, TensorShapeUtils::IsScalar(c->input(1).shape()),\n        errors::InvalidArgument(\n            \"The num_elements to reserve must be a tensor size 1, but got \",\n            c->input(1).shape()));\n    int32_t num_elements = c->input(1).scalar<int32>()();\n    OP_REQUIRES(c, num_elements >= 0,\n                errors::InvalidArgument(\"The num_elements to reserve must be a \"\n                                        \"non negative number, but got \",\n                                        num_elements));\n    TensorList output;\n    output.element_shape = element_shape;\n    output.element_dtype = element_dtype_;\n    output.tensors().resize(num_elements, Tensor(DT_INVALID));\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result, attr));\n    result->scalar<Variant>()() = std::move(output);\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\").Device(DEVICE_CPU),\n                        TensorListReserve);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"num_elements\"),\n                        TensorListReserve);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListReserve\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"element_shape\")\n                            .HostMemory(\"num_elements\"),\n                        TensorListReserve);\n\nclass TensorListResize : public OpKernel {\n public:\n  explicit TensorListResize(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* input_list = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &input_list));\n    int32_t size = c->input(1).scalar<int32>()();\n    OP_REQUIRES(\n        c, size >= 0,\n        errors::InvalidArgument(\n            \"TensorListSlice expects size to be non-negative. Got: \", size));\n\n    std::unique_ptr<Tensor> maybe_result =\n        c->forward_input(0, 0, DT_VARIANT, TensorShape{},\n                         c->input_memory_type(0), AllocatorAttributes());\n    if (maybe_result != nullptr) {\n      TensorList* out = maybe_result->scalar<Variant>()().get<TensorList>();\n      if (out->RefCountIsOne()) {\n        // We are able to forward the input.\n        out->tensors().resize(size, Tensor(DT_INVALID));\n        c->set_output(0, *maybe_result);\n        return;\n      }\n    }\n\n    // We were not able to forward the input.  Will have to resize from scratch.\n    Tensor* result;\n    AllocatorAttributes attr;\n    attr.set_on_host(true);\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result, attr));\n    TensorList output_list;\n    output_list.element_shape = input_list->element_shape;\n    output_list.element_dtype = input_list->element_dtype;\n    output_list.max_num_elements = input_list->max_num_elements;\n    if (size > input_list->tensors().size()) {\n      output_list.tensors().insert(output_list.tensors().begin(),\n                                   input_list->tensors().begin(),\n                                   input_list->tensors().end());\n      // Add DT_INVALID tensors to the end of the list if the requested size\n      // is larger than the list length.\n      output_list.tensors().resize(size, Tensor(DT_INVALID));\n    } else {\n      output_list.tensors().insert(output_list.tensors().begin(),\n                                   input_list->tensors().begin(),\n                                   input_list->tensors().begin() + size);\n    }\n    result->scalar<Variant>()() = std::move(output_list);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListResize\").Device(DEVICE_CPU),\n                        TensorListResize);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListResize\").Device(DEVICE_GPU).HostMemory(\"size\"),\n    TensorListResize);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"TensorListResize\").Device(DEVICE_DEFAULT).HostMemory(\"size\"),\n    TensorListResize);\n\nclass TensorListSetItem : public OpKernel {\n public:\n  explicit TensorListSetItem(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    const TensorList* l = nullptr;\n    OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n    OP_REQUIRES(c, element_dtype_ == l->element_dtype,\n                errors::InvalidArgument(\"Invalid data types; op elements \",\n                                        DataTypeString(element_dtype_),\n                                        \" but list elements \",\n                                        DataTypeString(l->element_dtype)));\n    int32_t index = c->input(1).scalar<int32>()();\n    OP_REQUIRES(c, index < l->tensors().size(),\n                errors::InvalidArgument(\"Trying to modify element \", index,\n                                        \" in a list with \", l->tensors().size(),\n                                        \" elements.\"));\n    const Tensor& value = c->input(2);\n    OP_REQUIRES(c, l->element_shape.IsCompatibleWith(value.shape()),\n                errors::InvalidArgument(\n                    \"Tried to set a tensor with incompatible shape at a \"\n                    \"list index. Item element shape: \",\n                    value.shape().DebugString(),\n                    \" list shape: \", l->element_shape.DebugString()));\n    TensorList* output_list = nullptr;\n    OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n    output_list->tensors()[index] = value;\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\").Device(DEVICE_CPU),\n                        TensorListSetItem);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#define REGISTER_TENSOR_LIST_SET_ITEM_GPU(T)                      \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\")               \\\n                              .TypeConstraint<T>(\"element_dtype\") \\\n                              .Device(DEVICE_GPU)                 \\\n                              .HostMemory(\"index\"),               \\\n                          TensorListSetItem);\n\nTF_CALL_GPU_ALL_TYPES(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nTF_CALL_int32(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nTF_CALL_int64(REGISTER_TENSOR_LIST_SET_ITEM_GPU);\nREGISTER_TENSOR_LIST_SET_ITEM_GPU(bfloat16)\n#undef REGISTER_TENSOR_LIST_SET_ITEM_GPU\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#define REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT(T)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSetItem\")               \\\n                              .TypeConstraint<T>(\"element_dtype\") \\\n                              .Device(DEVICE_DEFAULT)             \\\n                              .HostMemory(\"index\"),               \\\n                          TensorListSetItem);\n\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nTF_CALL_int32(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nTF_CALL_int64(REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT);\nREGISTER_TENSOR_LIST_SET_ITEM_DEFAULT(bfloat16)\n#undef REGISTER_TENSOR_LIST_SET_ITEM_DEFAULT\n\nclass TensorListConcatLists : public OpKernel {\n public:\n  explicit TensorListConcatLists(OpKernelConstruction* c) : OpKernel(c) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"element_dtype\", &element_dtype_));\n  }\n\n  void Compute(OpKernelContext* c) override {\n    const TensorShape& tl_a_shape = c->input(0).shape();\n    const TensorShape& tl_b_shape = c->input(1).shape();\n    OP_REQUIRES(\n        c, tl_a_shape == tl_b_shape,\n        errors::InvalidArgument(\"Incompatible input TensorList tensor shapes: \",\n                                tl_a_shape.DebugString(), \" vs. \",\n                                tl_b_shape.DebugString()));\n    AllocatorAttributes attr;\n    std::unique_ptr<Tensor> tl_alias = c->forward_input(\n        0 /*input_index*/, 0 /*output_index*/, DT_VARIANT, tl_a_shape,\n        DEVICE_MEMORY /* input is always on DEVICE_MEMORY */, attr);\n\n    // tl_a may be aliased by tl_alias.\n    const Tensor& tl_a = c->input(0);\n    const Tensor& tl_b = c->input(1);\n\n    Tensor* output = nullptr;\n    bool ok_to_alias = tl_alias != nullptr;\n    if (tl_alias && tl_alias->dtype() == DT_VARIANT &&\n        tl_alias->NumElements() > 0) {\n      auto tl_a_t = tl_alias->flat<Variant>();\n      for (int64_t i = 0; i < tl_alias->NumElements(); ++i) {\n        TensorList* aliased = tl_a_t(i).get<TensorList>();\n        if (aliased == nullptr || !aliased->RefCountIsOne()) {\n          ok_to_alias = false;\n          break;\n        }\n      }\n      if (ok_to_alias) {\n        c->set_output(0, *tl_alias);\n        output = tl_alias.get();\n      }\n    }\n    if (!ok_to_alias) {\n      // Couldn't alias the entire Tensor.  We'll be conservative and not try\n      // to alias individual batch entries.\n      attr.set_on_host(true);\n      OP_REQUIRES_OK(c, c->allocate_output(0, tl_a_shape, &output, attr));\n    }\n\n    auto output_t = output->flat<Variant>();\n    auto tl_a_t = tl_a.flat<Variant>();\n    auto tl_b_t = tl_b.flat<Variant>();\n\n    for (int64_t i = 0; i < tl_a.NumElements(); ++i) {\n      const TensorList* l_a = tl_a_t(i).get<TensorList>();\n      const TensorList* l_b = tl_b_t(i).get<TensorList>();\n      OP_REQUIRES(\n          c, l_a != nullptr,\n          errors::InvalidArgument(\"input_a is not a TensorList at index \", i,\n                                  \".  Saw: '\", tl_a_t(i).DebugString(), \"'\"));\n      OP_REQUIRES(\n          c, l_b != nullptr,\n          errors::InvalidArgument(\"input_b is not a TensorList at index \", i,\n                                  \".  Saw: '\", tl_b_t(i).DebugString(), \"'\"));\n      OP_REQUIRES(c, l_a->element_dtype == element_dtype_,\n                  errors::InvalidArgument(\n                      \"input_a[\", i, \"].dtype != element_dtype.  Saw: \",\n                      DataTypeString(l_a->element_dtype), \" vs. \",\n                      DataTypeString(element_dtype_)));\n      OP_REQUIRES(c, l_b->element_dtype == element_dtype_,\n                  errors::InvalidArgument(\n                      \"input_b[\", i, \"].dtype != element_dtype.  Saw: \",\n                      DataTypeString(l_b->element_dtype), \" vs. \",\n                      DataTypeString(element_dtype_)));\n      OP_REQUIRES(c, l_a->element_shape.IsIdenticalTo(l_b->element_shape),\n                  errors::InvalidArgument(\n                      \"input_a and input_b TensorList element shapes are not \"\n                      \"identical at index \",\n                      i, \".  Saw \", l_a->element_shape.DebugString(), \" vs. \",\n                      l_b->element_shape.DebugString()));\n      if (ok_to_alias) {\n        TensorList* out = output_t(i).get<TensorList>();\n        std::copy(l_b->tensors().begin(), l_b->tensors().end(),\n                  std::back_inserter(out->tensors()));\n      } else {\n        TensorList out = l_a->Copy();\n        std::copy(l_b->tensors().begin(), l_b->tensors().end(),\n                  std::back_inserter(out.tensors()));\n        output_t(i) = std::move(out);\n      }\n    }\n  }\n\n private:\n  DataType element_dtype_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_CPU),\n                        TensorListConcatLists);\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_GPU),\n                        TensorListConcatLists);\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\nREGISTER_KERNEL_BUILDER(Name(\"TensorListConcatLists\").Device(DEVICE_DEFAULT),\n                        TensorListConcatLists);\n\n#define REGISTER_TENSOR_LIST_OPS_CPU(T)                                    \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListStack\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListStack<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGather\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListGather<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcat\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcatV2\")                       \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGetItem\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListGetItem<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPopBack\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListPopBack<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListFromTensor\")                     \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListFromTensor<CPUDevice, T>)              \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatter\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterV2\")                      \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterIntoExistingList\")        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListScatterIntoExistingList<CPUDevice, T>) \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSplit\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListSplit<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPushBackBatch\")                  \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_CPU),                         \\\n                          TensorListPushBackBatch<CPUDevice, T>)\n\nTF_CALL_POD_STRING_TYPES(REGISTER_TENSOR_LIST_OPS_CPU);\nREGISTER_TENSOR_LIST_OPS_CPU(quint8);\nREGISTER_TENSOR_LIST_OPS_CPU(qint8);\nREGISTER_TENSOR_LIST_OPS_CPU(quint16);\nREGISTER_TENSOR_LIST_OPS_CPU(qint16);\nREGISTER_TENSOR_LIST_OPS_CPU(qint32);\nREGISTER_TENSOR_LIST_OPS_CPU(Variant);\n\n#undef REGISTER_TENSOR_LIST_OPS_CPU\n\n#define REGISTER_TENSOR_LIST_OPS_CPU(T)\n\nREGISTER_UNARY_VARIANT_BINARY_OP_FUNCTION(ADD_VARIANT_BINARY_OP, DEVICE_CPU,\n                                          TensorList,\n                                          TensorListBinaryAdd<CPUDevice>);\n\nREGISTER_UNARY_VARIANT_UNARY_OP_FUNCTION(ZEROS_LIKE_VARIANT_UNARY_OP,\n                                         DEVICE_CPU, TensorList,\n                                         TensorListZerosLike<CPUDevice>);\n\nstatic Status TensorListDeviceCopy(\n    const TensorList& from, TensorList* to,\n    const UnaryVariantOpRegistry::AsyncTensorDeviceCopyFn& copy) {\n  to->element_shape = from.element_shape;\n  to->element_dtype = from.element_dtype;\n  to->max_num_elements = from.max_num_elements;\n  to->tensors().reserve(from.tensors().size());\n  for (const Tensor& t : from.tensors()) {\n    to->tensors().emplace_back(t.dtype());\n    if (t.dtype() != DT_INVALID) {\n      TF_RETURN_IF_ERROR(copy(t, &to->tensors().back()));\n    }\n  }\n  return OkStatus();\n}\n\n#define REGISTER_LIST_COPY(DIRECTION)                                         \\\n  INTERNAL_REGISTER_UNARY_VARIANT_DEVICE_COPY_FUNCTION(TensorList, DIRECTION, \\\n                                                       TensorListDeviceCopy)\n\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::HOST_TO_DEVICE);\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::DEVICE_TO_HOST);\nREGISTER_LIST_COPY(VariantDeviceCopyDirection::DEVICE_TO_DEVICE);\n\nREGISTER_UNARY_VARIANT_DECODE_FUNCTION(TensorList, TensorList::kTypeName);\n\n#define REGISTER_TENSOR_LIST_OPS_DEFAULT(T)                                \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListStack\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListStack<CPUDevice, T>)                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGather\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"indices\")                       \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListGather<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcat\")                         \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"lengths\")                       \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListConcatV2\")                       \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .HostMemory(\"leading_dims\")                  \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"lengths\")                       \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListConcat<CPUDevice, T>)                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListGetItem\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"index\")                         \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListGetItem<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPopBack\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListPopBack<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListPushBackBatch\")                  \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT),                     \\\n                          TensorListPushBackBatch<CPUDevice, T>)           \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListFromTensor\")                     \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\"),                \\\n                          TensorListFromTensor<CPUDevice, T>)              \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatter\")                        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterV2\")                      \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"num_elements\")                  \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatter<CPUDevice, T>)                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListScatterIntoExistingList\")        \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"indices\"),                      \\\n                          TensorListScatterIntoExistingList<CPUDevice, T>) \\\n  REGISTER_KERNEL_BUILDER(Name(\"TensorListSplit\")                          \\\n                              .TypeConstraint<T>(\"element_dtype\")          \\\n                              .Device(DEVICE_DEFAULT)                      \\\n                              .HostMemory(\"element_shape\")                 \\\n                              .HostMemory(\"lengths\"),                      \\\n                          TensorListSplit<CPUDevice, T>)\n\nTF_CALL_int32(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_int64(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_bfloat16(REGISTER_TENSOR_LIST_OPS_DEFAULT);\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_TENSOR_LIST_OPS_DEFAULT);\n\n#undef REGISTER_TENSOR_LIST_OPS_DEFAULT\n}  // namespace tensorflow\n", "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for ops which manipulate lists of tensors.\"\"\"\n\n# pylint: disable=g-bad-name\nfrom absl.testing import parameterized\nimport numpy as np  # pylint: disable=unused-import\n\nfrom tensorflow.core.framework import full_type_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.eager import function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import gen_list_ops\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import map_fn\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import string_ops\nfrom tensorflow.python.ops import variable_scope as vs\nfrom tensorflow.python.platform import test\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass ListOpsTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  def _testPushPop(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    l = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    l, e = self.evaluate((l, e))\n    self.assertAllEqual(l, [])\n    self.assertAllEqual(e, 1.0)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testPushPop(self, max_num_elements):\n    self._testPushPop(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_gpu_only\n  def testPushPopGPU(self, max_num_elements):\n    with context.device(\"gpu:0\"):\n      self._testPushPop(max_num_elements)\n\n  @test_util.run_deprecated_v1\n  def testPushInFullListFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[], max_num_elements=1)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Tried to push item into a full list\"):\n      l = list_ops.tensor_list_push_back(l, 2.)\n      self.evaluate(l)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_deprecated_v1\n  def testPopFromEmptyTensorListFails(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Trying to pop from an empty list\"):\n      l = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.evaluate(l)\n\n  def testTensorListReserveWithNonScalarNumElements(self):\n    # list_kernels.cc in tf/core/kernels raises InvalidArgumentError, and\n    # tf_ops_n_z.cc in tf/compiler/mlir/tf/ir raises UnknownError.\n    with self.assertRaises((errors.InvalidArgumentError, errors.UnknownError)):\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32,\n          element_shape=[2, 3],\n          num_elements=constant_op.constant([1, 1]))\n      self.evaluate(l)\n\n  def testPopUninitializedTensorUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n    _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    l = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    l, e = self.evaluate((l, e))\n    self.assertAllEqual(e, np.zeros((2, 3)))\n    self.assertAllEqual(l, np.zeros((3, 2, 3)))\n\n  def testPopUninitializedTensorUseSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    _, e = gen_list_ops.tensor_list_pop_back(\n        l, element_dtype=dtypes.float32, element_shape=[4, 3])\n    self.assertAllEqual(e, np.zeros((4, 3)))\n\n  def testPopUninitializedTensorWithInvalidElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to read an uninitialized tensor but \"\n        \"element_shape is not fully defined\"):\n      _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.evaluate(e)\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 2], num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1,3\\] vs. \\[\\?,2\\]\"):\n      _, e = gen_list_ops.tensor_list_pop_back(\n          l, element_dtype=dtypes.float32, element_shape=[1, 3])\n      self.evaluate(e)\n\n  def testPushGetGrad(self):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=None)\n      c0 = constant_op.constant(5.0)\n      c1 = constant_op.constant([10.0, 20.0])\n      tape.watch(c0)\n      tape.watch(c1)\n      l = list_ops.tensor_list_push_back(l, c0)\n      l = list_ops.tensor_list_push_back(l, c1)\n      t1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t1), [10.0, 20.0])\n      # t1 == c1 so the gradient should be [0., [1., 1.]]\n      # This tests that the gradient of push_back correctly converts DT_INVALID\n      # tensors to zeros. The list returned by the gradient of GetItem will\n      # have only have tensor at index 1 set and others set to DT_INVALID.\n      dt0, dt1 = tape.gradient(t1, [c0, c1])\n      self.assertAllEqual(self.evaluate(dt1), [1.0, 1.0])\n      self.assertEqual(self.evaluate(dt0), 0.0)\n\n  def _testStack(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    if not context.executing_eagerly():\n      self.assertAllEqual(t.shape.as_list(), [None])\n    self.assertAllEqual(self.evaluate(t), [1.0, 2.0])\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testStack(self, max_num_elements):\n    self._testStack(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_gpu_only\n  def testStackGPU(self, max_num_elements):\n    with context.device(\"gpu:0\"):\n      self._testStack(max_num_elements)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testStackWithUnknownElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=None,\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [1.0, 2.0])\n\n    # Should raise an error when the element tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Incompatible ranks during merge: 0 vs. 1\"):\n      l = list_ops.tensor_list_push_back(l, constant_op.constant([3.0, 4.0]))\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testStackWithPartiallyDefinedElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[None],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0]))\n\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1.0], [2.0]])\n\n    # Should raise an error when the element tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1\\] vs. \\[2\\]\"):\n      l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0, 3.0]))\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  @test_util.run_deprecated_v1\n  def testStackEmptyList(self, max_num_elements):\n    # Should be able to stack empty lists with fully defined element_shape.\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[1, 2],\n        max_num_elements=max_num_elements)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 1, 2))\n\n    # Should not be able to stack empty lists with partially defined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[None, 2],\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n    # Should not be able to stack empty lists with undefined element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=None,\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def _testStackWithUninitializedTensors(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [0., 0., 0.])\n\n  def testStackWithUninitializedTensors(self):\n    self._testStackWithUninitializedTensors()\n\n  @test_util.run_gpu_only\n  def testStackWithUninitializedTensorsGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testStackWithUninitializedTensors()\n\n  def _testStackWithUninitializedTensorsInferShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [1., 2.])\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [[0., 0.], [1., 2.], [0., 0.]])\n\n  def testStackWithUninitializedTensorsInferShape(self):\n    self._testStackWithUninitializedTensorsInferShape()\n\n  @test_util.run_gpu_only\n  def testStackWithUninitializedTensorsInferShapeGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testStackWithUninitializedTensorsInferShape()\n\n  def testStackReservedListWithNoElementsAndPartialElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Tried to stack list which only contains \"\n        \"uninitialized tensors and has a \"\n        \"non-fully-defined element_shape: <unknown>\"):\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testStackUsingSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = gen_list_ops.tensor_list_stack(\n        l, element_dtype=dtypes.float32, element_shape=[])\n    if context.executing_eagerly():\n      self.assertEqual(t.shape.as_list(), [3])\n    else:\n      self.assertEqual(t.shape.as_list(), [None])\n    self.assertAllEqual(self.evaluate(t), np.zeros((3,)))\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 2))\n  def testGatherGrad(self, max_num_elements):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[],\n          max_num_elements=max_num_elements)\n      c0 = constant_op.constant(1.0)\n      tape.watch(c0)\n      l = list_ops.tensor_list_push_back(l, c0)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n      t = list_ops.tensor_list_gather(l, [1, 0], element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t), [2.0, 1.0])\n      s = (t[0] + t[1]) * (t[0] + t[1])\n    dt = tape.gradient(s, c0)\n    self.assertAllEqual(self.evaluate(dt), 6.0)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherWithUnknownElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=None,\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([3.0, 4.0]))\n\n    t = list_ops.tensor_list_gather(l, [1, 0], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [2.0, 1.0])\n\n    t = list_ops.tensor_list_gather(l, [2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[3.0, 4.0]])\n\n    # Should raise an error when the requested tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Incompatible ranks during merge: 0 vs. 1\"):\n      t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherWithPartiallyDefinedElementShape(self, max_num_elements):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[None],\n        max_num_elements=max_num_elements)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([2.0, 3.0]))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([4.0, 5.0]))\n\n    t = list_ops.tensor_list_gather(l, [0], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1.0]])\n\n    t = list_ops.tensor_list_gather(l, [1, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[2.0, 3.0], [4.0, 5.0]])\n\n    # Should raise an error when the requested tensors do not all have the same\n    # shape.\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Incompatible shapes during merge: \\[1\\] vs. \\[2\\]\"):\n      t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  @parameterized.named_parameters((\"NoMaxNumElements\", None),\n                                  (\"WithMaxNumElements\", 3))\n  @test_util.run_deprecated_v1\n  def testGatherEmptyList(self, max_num_elements):\n    # Should be able to gather from empty lists with fully defined\n    # element_shape.\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=[1, 2],\n        max_num_elements=max_num_elements)\n    t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n    self.assertAllEqual((0, 1, 2), self.evaluate(t).shape)\n\n    # Should not be able to gather from empty lists with partially defined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[None, 2],\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n    # Should not be able to gather from empty lists with undefined\n    # element_shape.\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"non-fully-defined\"):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=None,\n          max_num_elements=max_num_elements)\n      t = list_ops.tensor_list_gather(l, [], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testGatherGradWithNonContiguousIndices(self):\n    with backprop.GradientTape(persistent=True) as tape:\n      t = constant_op.constant([1.0, 2.0, 3.0])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      c = constant_op.constant(5.0)\n      tape.watch(c)\n      l = list_ops.tensor_list_set_item(l, 1, c)\n      t = list_ops.tensor_list_gather(l, [1], element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t), [5.0])\n      s = t[0] * t[0]\n    dt = tape.gradient(s, c)\n    self.assertAllEqual(self.evaluate(dt), 10.0)\n    dl = tape.gradient(t, l)\n    dl_length = list_ops.tensor_list_length(dl)\n    self.assertAllEqual(self.evaluate(dl_length), 3)\n\n  def _testGatherWithUninitializedTensors(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    t = list_ops.tensor_list_gather(l, [0, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [0., 0.])\n\n  def testGatherWithUninitializedTensors(self):\n    self._testGatherWithUninitializedTensors()\n\n  @test_util.run_gpu_only\n  def testGatherWithUninitializedTensorsGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testGatherWithUninitializedTensors()\n\n  def _testGatherWithUninitializedTensorsInferShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [1., 2.])\n    t = list_ops.tensor_list_gather(l, [1, 2], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[1., 2.], [0., 0.]])\n\n  def testGatherWithUninitializedTensorsInferShape(self):\n    self._testGatherWithUninitializedTensorsInferShape()\n\n  @test_util.run_gpu_only\n  def testGatherWithUninitializedTensorsInferShapeGpu(self):\n    with context.device(\"gpu:0\"):\n      self._testGatherWithUninitializedTensorsInferShape()\n\n  def testGatherReservedListWithNoElementsAndPartialElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Tried to gather uninitialized tensors from a\"\n        \" list with non-fully-defined element_shape\"):\n      t = list_ops.tensor_list_gather(l, [0], element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testGatherUsingSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = gen_list_ops.tensor_list_gather(\n        l, [0, 1, 2], element_dtype=dtypes.float32, element_shape=[])\n    self.assertEqual(t.shape.as_list(), [3])\n    self.assertAllEqual(self.evaluate(t), np.zeros((3,)))\n\n  def testScatterOutputListSize(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_scatter(c0, [1, 3], [])\n    # TensorListScatter should return a list with size largest index + 1.\n    self.assertAllEqual(list_ops.tensor_list_length(l), 4)\n\n  def testScatterOutputListSizeWithNumElementsSpecified(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    l = gen_list_ops.tensor_list_scatter_v2(\n        c0, [1, 3], list_ops._build_element_shape([]), num_elements=5)\n    # TensorListScatter should return a list with size num_elements.\n    self.assertAllEqual(list_ops.tensor_list_length(l), 5)\n\n  def testScatterFailsWhenElementShapeIsNotVector(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      l = gen_list_ops.tensor_list_scatter(\n          # Wrong element_shape. Should be at most rank 1.\n          c0, [1, 3], element_shape=[[1]])\n      self.evaluate(l)\n\n  def testScatterV2FailsWhenElementShapeIsNotVector(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          # Wrong element_shape. Should be at most rank 1.\n          c0, [1, 3], element_shape=[[1]], num_elements=2)\n      self.evaluate(l)\n\n  def testScatterFailsWhenIndexLargerThanNumElements(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListScatter: Trying to scatter at index 3 in list with size 3\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          c0, [1, 3], list_ops._build_element_shape([]), num_elements=3)\n      self.evaluate(l)\n\n  def testScatterFailsWithInvalidNumElements(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListScatter expects num_elements >= -1, found: -2\"):\n      l = gen_list_ops.tensor_list_scatter_v2(\n          c0, [1, 3], list_ops._build_element_shape([]), num_elements=-2)\n      self.evaluate(l)\n\n  def testScatterWithInvalidRowsInInputTensorFails(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Invalid number of rows in input tensor. Expected: 3 Actual: 2\"):\n      l = list_ops.tensor_list_scatter(c0, [1, 0, 2], [])\n      self.evaluate(l)\n\n  def testScatterWithNegativeIndicesFails(self):\n    c0 = constant_op.constant([1.0, 2.0])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Indices in TensorListScatter must all be non-negative.\"):\n      l = list_ops.tensor_list_scatter(c0, [-1, -2], element_shape=[])\n      self.evaluate(l)\n\n  def testScatterIntoExistingList(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    l = list_ops.tensor_list_scatter(tensor=[1.], indices=[0], element_shape=[])\n    l = list_ops.tensor_list_scatter(\n        tensor=[2., 3.], indices=[1, 2], element_shape=[], input_handle=l)\n    self.assertAllEqual(\n        list_ops.tensor_list_stack(l, element_dtype=dtypes.float32),\n        [1., 2., 3.])\n\n  def testScatterGrad(self):\n    with backprop.GradientTape() as tape:\n      c0 = constant_op.constant([1.0, 2.0])\n      tape.watch(c0)\n      l = list_ops.tensor_list_scatter(c0, [1, 0], element_shape=[])\n      t0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      t1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t0), 2.0)\n      self.assertAllEqual(self.evaluate(t1), 1.0)\n      loss = t0 * t0 + t1 * t1\n    dt = tape.gradient(loss, c0)\n    self.assertAllEqual(self.evaluate(dt), [2., 4.])\n\n  def testScatterWithPartialReadGrad(self):\n    with backprop.GradientTape() as tape:\n      c0 = constant_op.constant([1.0, 2.0])\n      tape.watch(c0)\n      l = list_ops.tensor_list_scatter(c0, [1, 0], element_shape=[])\n      t0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(t0), 2.0)\n      loss = t0 * t0\n    dt = tape.gradient(loss, c0)\n    self.assertAllEqual(self.evaluate(dt), [0., 4.])\n\n  def testTensorListFromTensor(self):\n    t = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 1.0)\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 2.0)\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(e, 1.0)\n    self.assertAllEqual(list_ops.tensor_list_length(l), 0)\n\n  def testTensorListFromTensorFailsWhenElementShapeIsNotVector(self):\n    t = constant_op.constant([1.0, 2.0])\n    # In Eager mode, InvalidArgumentError is generated by the Compute function.\n    # In graph mode, ValueError is generated by the shape function.\n    with self.assertRaisesRegex(\n        (errors.InvalidArgumentError, ValueError),\n        \"must be at most rank 1\"):\n      # Wrong element_shape. Should be at most rank 1.\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[[1]])\n      self.evaluate(l)\n\n  @test_util.run_gpu_only\n  def testFromTensorGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testTensorListFromTensor()\n\n  def testGetSetBool(self):\n    t = constant_op.constant([True, False])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.bool)\n    self.assertAllEqual(self.evaluate(e0), True)\n    l = list_ops.tensor_list_set_item(l, 0, False)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.bool)\n    self.assertAllEqual(self.evaluate(t), [False, False])\n\n  @test_util.run_gpu_only\n  def testGetSetBoolGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testGetSetBool()\n\n  def _testGetSetNumeric(self, dtype):\n    t = constant_op.constant([1.0, 2.0], dtype=dtype)\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtype)\n    self.assertAllEqual(self.evaluate(e0), 1.0)\n    l = list_ops.tensor_list_set_item(\n        l, 0, constant_op.constant(3.0, dtype=dtype))\n    t = list_ops.tensor_list_stack(l, element_dtype=dtype)\n    self.assertAllEqual(self.evaluate(t), [3.0, 2.0])\n\n  @parameterized.parameters([dtypes.float32, dtypes.float64,\n                             dtypes.complex64, dtypes.complex128])\n  def testGetSetNumeric(self, dtype):\n    self._testGetSetNumeric(dtype)\n\n  @parameterized.parameters([dtypes.float32, dtypes.float64,\n                             dtypes.complex64, dtypes.complex128])\n  @test_util.run_gpu_only\n  def testGetSetNumericGPU(self, dtype):\n    with context.device(\"gpu:0\"):\n      self._testGetSetNumeric(dtype)\n\n  def testGetSetReserved(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=2)\n    e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(e0, 0.0)\n    l = list_ops.tensor_list_set_item(l, 0, 3.0)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(t, [3.0, 0.0])\n\n  @test_util.run_gpu_only\n  def testGetSetReservedGPU(self):\n    with context.device(\"gpu:0\"):\n      self.testGetSetReserved()\n\n  def testSetGetGrad(self):\n    with backprop.GradientTape() as tape:\n      t = constant_op.constant(5.)\n      tape.watch(t)\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n      l = list_ops.tensor_list_set_item(l, 1, 2. * t)\n      e = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(self.evaluate(e), 10.0)\n    self.assertAllEqual(self.evaluate(tape.gradient(e, t)), 2.0)\n\n  def testGetUninitializedTensorUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 0, 5.)\n    e1 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n    e2 = list_ops.tensor_list_get_item(l, 2, element_dtype=dtypes.float32)\n    self.assertEqual(self.evaluate(e1), 0.)\n    self.assertEqual(self.evaluate(e2), 0.)\n\n  def testGetUninitializedTensorUseSpecifiedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    e0 = gen_list_ops.tensor_list_get_item(\n        l, 0, element_shape=[], element_dtype=dtypes.float32)\n    e1 = gen_list_ops.tensor_list_get_item(\n        l, 1, element_shape=[2, 3], element_dtype=dtypes.float32)\n    self.assertEqual(e0.shape.as_list(), [])\n    self.assertEqual(e1.shape.as_list(), [2, 3])\n    self.assertEqual(self.evaluate(e0), 0.)\n    self.assertAllEqual(self.evaluate(e1), np.zeros((2, 3)))\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    e1 = gen_list_ops.tensor_list_get_item(\n        l, 1, element_shape=[2, 3], element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e1), np.zeros((2, 3)))\n\n  def testGetUninitializedTensorWithInvalidElementShapeFails(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to read an uninitialized tensor but \"\n        \"element_shape is not fully defined\"):\n      e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.evaluate(e0)\n\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 2], num_elements=3)\n\n    # In eager mode the shape mismatch is caught in the TensorListGetItem\n    # kernel which raises an InvalidArgumentError.\n    # In graph mode the shape mismatch is caught in the C++ shape inference\n    # which raises a ValueError.\n    if context.executing_eagerly():\n      error_type = errors.InvalidArgumentError\n    else:\n      error_type = ValueError\n    with self.assertRaisesRegex(error_type, r\"shapes\"):\n      e0 = gen_list_ops.tensor_list_get_item(\n          l, 0, element_dtype=dtypes.float32, element_shape=[1, 3])\n      self.evaluate(e0)\n\n  @test_util.run_deprecated_v1\n  @test_util.enable_control_flow_v2\n  def testSkipEagerSetItemIndexOutOfBounds(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[])\n    e0 = constant_op.constant(5.)\n    l = list_ops.tensor_list_set_item(\n        l, 0, 2. * e0, resize_if_index_out_of_bounds=True)\n    l = list_ops.tensor_list_set_item(\n        l, 1, 1., resize_if_index_out_of_bounds=True)\n    t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients(t, e0)[0]\n    self.assertAllEqual(self.evaluate(grad), 2.)\n\n  @test_util.run_deprecated_v1\n  def testSetOnEmptyListWithMaxNumElementsFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[], max_num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to modify element 0 in a list with 0 elements.\"):\n      l = list_ops.tensor_list_set_item(l, 0, 1.)\n      self.evaluate(l)\n\n  def testUnknownShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n    l = list_ops.tensor_list_push_back(l, constant_op.constant([1.0, 2.0]))\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e), [1.0, 2.0])\n    l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(e), 1.0)\n\n  @test_util.run_gpu_only\n  def testCPUGPUCopy(self):\n    t = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    with context.device(\"gpu:0\"):\n      l_gpu = array_ops.identity(l)\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_pop_back(\n                  l_gpu, element_dtype=dtypes.float32)[1]), 2.0)\n    l_cpu = array_ops.identity(l_gpu)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_pop_back(\n                l_cpu, element_dtype=dtypes.float32)[1]), 2.0)\n\n  @test_util.run_gpu_only\n  def testCPUGPUCopyNested(self):\n    t = constant_op.constant([1.0, 2.0])\n    child_l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    l = list_ops.empty_tensor_list(\n        element_shape=constant_op.constant([], dtype=dtypes.int32),\n        element_dtype=dtypes.variant)\n    l = list_ops.tensor_list_push_back(l, child_l)\n    with context.device(\"gpu:0\"):\n      l_gpu = array_ops.identity(l)\n      _, child_l_gpu = list_ops.tensor_list_pop_back(\n          l_gpu, element_dtype=dtypes.variant)\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_pop_back(\n                  child_l_gpu, element_dtype=dtypes.float32)[1]), 2.0)\n    l_cpu = array_ops.identity(l_gpu)\n    _, child_l_cpu = list_ops.tensor_list_pop_back(\n        l_cpu, element_dtype=dtypes.variant)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_pop_back(\n                child_l_cpu, element_dtype=dtypes.float32)[1]), 2.0)\n\n  def testGraphStack(self):\n    with self.cached_session():\n      tl = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([1], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      tl = list_ops.tensor_list_push_back(tl, [1])\n      self.assertAllEqual(\n          self.evaluate(\n              list_ops.tensor_list_stack(tl, element_dtype=dtypes.int32)),\n          [[1]])\n\n  def testSkipEagerStackInLoop(self):\n    with self.cached_session():\n      t1 = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      i = constant_op.constant(0, dtype=dtypes.int32)\n\n      def body(i, t1):\n        t1 = list_ops.tensor_list_push_back(t1, i)\n        i += 1\n        return i, t1\n\n      i, t1 = control_flow_ops.while_loop(lambda i, t1: math_ops.less(i, 4),\n                                          body, [i, t1])\n      s1 = list_ops.tensor_list_stack(t1, element_dtype=dtypes.int32)\n      self.assertAllEqual(self.evaluate(s1), [0, 1, 2, 3])\n\n  def testSkipEagerStackSwitchDtype(self):\n    with self.cached_session():\n      list_ = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      m = constant_op.constant([1, 2, 3], dtype=dtypes.float32)\n\n      def body(list_, m):\n        list_ = control_flow_ops.cond(\n            math_ops.equal(list_ops.tensor_list_length(list_), 0),\n            lambda: list_ops.empty_tensor_list(m.shape, m.dtype), lambda: list_)\n        list_ = list_ops.tensor_list_push_back(list_, m)\n        return list_, m\n\n      for _ in range(2):\n        list_, m = body(list_, m)\n\n      s1 = list_ops.tensor_list_stack(list_, element_dtype=dtypes.float32)\n      np_s1 = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.float32)\n      self.assertAllEqual(self.evaluate(s1), np_s1)\n\n  def testSkipEagerStackInLoopSwitchDtype(self):\n    with self.cached_session():\n      t1 = list_ops.empty_tensor_list(\n          element_shape=constant_op.constant([], dtype=dtypes.int32),\n          element_dtype=dtypes.int32)\n      i = constant_op.constant(0, dtype=dtypes.float32)\n      m = constant_op.constant([1, 2, 3], dtype=dtypes.float32)\n\n      def body(i, m, t1):\n        t1 = control_flow_ops.cond(\n            math_ops.equal(list_ops.tensor_list_length(t1), 0),\n            lambda: list_ops.empty_tensor_list(m.shape, m.dtype), lambda: t1)\n\n        t1 = list_ops.tensor_list_push_back(t1, m * i)\n        i += 1.0\n        return i, m, t1\n\n      i, m, t1 = control_flow_ops.while_loop(\n          lambda i, m, t1: math_ops.less(i, 4), body, [i, m, t1])\n      s1 = list_ops.tensor_list_stack(t1, element_dtype=dtypes.float32)\n      np_s1 = np.vstack([np.arange(1, 4) * i for i in range(4)])\n      self.assertAllEqual(self.evaluate(s1), np_s1)\n\n  def testSerialize(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        t = constant_op.constant([[1.0], [2.0]])\n        l = list_ops.tensor_list_from_tensor(t, element_shape=[1])\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps, e = list_ops.tensor_list_pop_back(\n            l_ps, element_dtype=dtypes.float32)\n      with ops.device(\"/job:worker\"):\n        worker_e = array_ops.identity(e)\n      self.assertAllEqual(self.evaluate(worker_e), [2.0])\n\n  def testSerializeListWithInvalidTensors(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        l = list_ops.tensor_list_reserve(\n            element_dtype=dtypes.float32, element_shape=[], num_elements=2)\n        l = list_ops.tensor_list_set_item(l, 0, 1.)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps = list_ops.tensor_list_set_item(l_ps, 1, 2.)\n        t = list_ops.tensor_list_stack(l_ps, element_dtype=dtypes.float32)\n      with ops.device(\"/job:worker\"):\n        worker_t = array_ops.identity(t)\n      self.assertAllEqual(self.evaluate(worker_t), [1.0, 2.0])\n\n  def testSerializeListWithUnknownRank(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        t = constant_op.constant([[1.0], [2.0]])\n        l = list_ops.tensor_list_from_tensor(t, element_shape=None)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        element_shape = list_ops.tensor_list_element_shape(\n            l_ps, shape_type=dtypes.int32)\n      with ops.device(\"/job:worker\"):\n        element_shape = array_ops.identity(element_shape)\n      self.assertEqual(self.evaluate(element_shape), -1)\n\n  def testSerializeListWithMaxNumElements(self):\n    worker = test_util.create_local_cluster(num_workers=1, num_ps=1)[0][0]\n    with ops.Graph().as_default(), session.Session(target=worker.target):\n      with ops.device(\"/job:worker\"):\n        l = list_ops.empty_tensor_list(\n            element_shape=None,\n            element_dtype=dtypes.float32,\n            max_num_elements=2)\n        l = list_ops.tensor_list_push_back(l, 1.)\n      with ops.device(\"/job:ps\"):\n        l_ps = array_ops.identity(l)\n        l_ps = list_ops.tensor_list_push_back(l_ps, 2.)\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  \"Tried to push item into a full list\"):\n        with ops.device(\"/job:worker\"):\n          l_worker = array_ops.identity(l_ps)\n          l_worker = list_ops.tensor_list_push_back(l_worker, 3.0)\n          self.evaluate(l_worker)\n\n  def testPushPopGradients(self):\n    with backprop.GradientTape() as tape:\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=[])\n      c = constant_op.constant(1.0)\n      tape.watch(c)\n      l = list_ops.tensor_list_push_back(l, c)\n      l, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      e = 2 * e\n    self.assertAllEqual(self.evaluate(tape.gradient(e, [c])[0]), 2.0)\n\n  def testStackFromTensorGradients(self):\n    with backprop.GradientTape() as tape:\n      c = constant_op.constant([1.0, 2.0])\n      tape.watch(c)\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      c2 = list_ops.tensor_list_stack(\n          l, element_dtype=dtypes.float32, num_elements=2)\n      result = c2 * 2.0\n    grad = tape.gradient(result, [c])[0]\n    self.assertAllEqual(self.evaluate(grad), [2.0, 2.0])\n\n  def testGetSetGradients(self):\n    with backprop.GradientTape() as tape:\n      c = constant_op.constant([1.0, 2.0])\n      tape.watch(c)\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      c2 = constant_op.constant(3.0)\n      tape.watch(c2)\n      l = list_ops.tensor_list_set_item(l, 0, c2)\n      e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      ee = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      y = e * e + ee * ee\n    grad_c, grad_c2 = tape.gradient(y, [c, c2])\n    self.assertAllEqual(self.evaluate(grad_c), [0.0, 4.0])\n    self.assertAllEqual(self.evaluate(grad_c2), 6.0)\n\n  @test_util.run_deprecated_v1\n  def testSetOutOfBounds(self):\n    c = constant_op.constant([1.0, 2.0])\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    with self.assertRaises(errors.InvalidArgumentError):\n      self.evaluate(list_ops.tensor_list_set_item(l, 20, 3.0))\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSetItemWithMismatchedShapeFails(self):\n    with self.cached_session() as sess:\n      ph = array_ops.placeholder(dtypes.float32)\n      c = constant_op.constant([1.0, 2.0])\n      l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n      # Set a placeholder with unknown shape to satisfy the shape inference\n      # at graph building time.\n      l = list_ops.tensor_list_set_item(l, 0, ph)\n      l_0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  \"incompatible shape\"):\n        sess.run(l_0, {ph: [3.0]})\n\n  def testResourceVariableScatterGather(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    v = vs.get_variable(\"var\", initializer=[l] * 10, use_resource=True)\n    v_r_0_stacked = list_ops.tensor_list_stack(v[0], dtypes.float32)\n    self.evaluate(v.initializer)\n    self.assertAllEqual([1.0, 2.0], self.evaluate(v_r_0_stacked))\n    v_r_sparse_stacked = list_ops.tensor_list_stack(\n        v.sparse_read(0), dtypes.float32)\n    self.assertAllEqual([1.0, 2.0], self.evaluate(v_r_sparse_stacked))\n    l_new_0 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l_new_1 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    updated_v = state_ops.scatter_update(v, [3, 5], [l_new_0, l_new_1])\n    updated_v_elems = array_ops.unstack(updated_v)\n    updated_v_stacked = [\n        list_ops.tensor_list_stack(el, dtypes.float32) for el in updated_v_elems\n    ]\n    expected = ([[1.0, 2.0]] * 3 + [[3.0, 4.0], [1.0, 2.0], [5.0, 6.0]] +\n                [[1.0, 2.0]] * 4)\n    self.assertAllEqual(self.evaluate(updated_v_stacked), expected)\n\n  def testResourceVariableScatterGatherInt64(self):\n    c = constant_op.constant([1, 2], dtype=dtypes.int64)\n    l = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    v = vs.get_variable(\"var\", initializer=[l] * 10, use_resource=True)\n    v_r_0_stacked = list_ops.tensor_list_stack(v[0], dtypes.int64)\n    self.evaluate(v.initializer)\n    self.assertAllEqual([1, 2], self.evaluate(v_r_0_stacked))\n    v_r_sparse_stacked = list_ops.tensor_list_stack(\n        v.sparse_read(0), dtypes.int64)\n    self.assertAllEqual([1, 2], self.evaluate(v_r_sparse_stacked))\n    c34 = constant_op.constant([3, 4], dtype=dtypes.int64)\n    l_new_0 = list_ops.tensor_list_from_tensor(c34, element_shape=[])\n    c56 = constant_op.constant([5, 6], dtype=dtypes.int64)\n    l_new_1 = list_ops.tensor_list_from_tensor(c56, element_shape=[])\n    updated_v = state_ops.scatter_update(v, [3, 5], [l_new_0, l_new_1])\n    updated_v_elems = array_ops.unstack(updated_v)\n    updated_v_stacked = [\n        list_ops.tensor_list_stack(el, dtypes.int64) for el in updated_v_elems\n    ]\n    expected = ([[1, 2]] * 3 + [[3, 4], [1, 2], [5, 6]] +\n                [[1, 2]] * 4)\n    self.assertAllEqual(self.evaluate(updated_v_stacked), expected)\n\n  @test_util.run_deprecated_v1\n  def testConcat(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l0 = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    l1 = list_ops.tensor_list_from_tensor([-1.0], element_shape=[])\n    l_batch_0 = array_ops.stack([l0, l1])\n    l_batch_1 = array_ops.stack([l1, l0])\n\n    l_concat_01 = list_ops.tensor_list_concat_lists(\n        l_batch_0, l_batch_1, element_dtype=dtypes.float32)\n    l_concat_10 = list_ops.tensor_list_concat_lists(\n        l_batch_1, l_batch_0, element_dtype=dtypes.float32)\n    l_concat_00 = list_ops.tensor_list_concat_lists(\n        l_batch_0, l_batch_0, element_dtype=dtypes.float32)\n    l_concat_11 = list_ops.tensor_list_concat_lists(\n        l_batch_1, l_batch_1, element_dtype=dtypes.float32)\n\n    expected_0 = [[1.0, 2.0], [-1.0]]\n    expected_1 = [[-1.0], [1.0, 2.0]]\n    expected_00 = [[1.0, 2.0, 1.0, 2.0], [-1.0, -1.0]]\n    expected_01 = [[1.0, 2.0, -1.0], [-1.0, 1.0, 2.0]]\n    expected_10 = [[-1.0, 1.0, 2.0], [1.0, 2.0, -1.0]]\n    expected_11 = [[-1.0, -1.0], [1.0, 2.0, 1.0, 2.0]]\n\n    for i, (concat, expected) in enumerate(zip(\n        [l_batch_0, l_batch_1,\n         l_concat_00, l_concat_01, l_concat_10, l_concat_11],\n        [expected_0, expected_1,\n         expected_00, expected_01, expected_10, expected_11])):\n      splitted = array_ops.unstack(concat)\n      splitted_stacked_ret = self.evaluate(\n          (list_ops.tensor_list_stack(splitted[0], dtypes.float32),\n           list_ops.tensor_list_stack(splitted[1], dtypes.float32)))\n      print(\"Test concat %d: %s, %s, %s, %s\"\n            % (i, expected[0], splitted_stacked_ret[0],\n               expected[1], splitted_stacked_ret[1]))\n      self.assertAllClose(expected[0], splitted_stacked_ret[0])\n      self.assertAllClose(expected[1], splitted_stacked_ret[1])\n\n    # Concatenating mismatched shapes fails.\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(\n              l_batch_0,\n              list_ops.empty_tensor_list([], dtypes.float32),\n              element_dtype=dtypes.float32))\n\n    if context.executing_eagerly():\n      expected_error = (\n          errors.InvalidArgumentError,\n          \"element shapes are not identical at index 0\")\n    else:\n      expected_error = (ValueError, \"Shapes must be equal rank\")\n    with self.assertRaisesRegex(*expected_error):\n      l_batch_of_vec_tls = array_ops.stack(\n          [list_ops.tensor_list_from_tensor([[1.0]], element_shape=[1])] * 2)\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(l_batch_0, l_batch_of_vec_tls,\n                                            element_dtype=dtypes.float32))\n\n    if context.executing_eagerly():\n      expected_error = (errors.InvalidArgumentError,\n                        r\"input_b\\[0\\].dtype != element_dtype.\")\n    else:\n      expected_error = (ValueError, \"input_b.type != element_dtype\")\n    with self.assertRaisesRegex(*expected_error):\n      l_batch_of_int_tls = array_ops.stack(\n          [list_ops.tensor_list_from_tensor([1], element_shape=[])] * 2)\n      self.evaluate(\n          list_ops.tensor_list_concat_lists(l_batch_0, l_batch_of_int_tls,\n                                            element_dtype=dtypes.float32))\n\n  @test_util.run_deprecated_v1\n  def testPushBackBatch(self):\n    c = constant_op.constant([1.0, 2.0], dtype=dtypes.float32)\n    l0 = list_ops.tensor_list_from_tensor(c, element_shape=[])\n    l1 = list_ops.tensor_list_from_tensor([-1.0], element_shape=[])\n    l_batch = array_ops.stack([l0, l1])\n    l_push = list_ops.tensor_list_push_back_batch(l_batch, [3.0, 4.0])\n    l_unstack = array_ops.unstack(l_push)\n    l0_ret = list_ops.tensor_list_stack(l_unstack[0], dtypes.float32)\n    l1_ret = list_ops.tensor_list_stack(l_unstack[1], dtypes.float32)\n    self.assertAllClose([1.0, 2.0, 3.0], self.evaluate(l0_ret))\n    self.assertAllClose([-1.0, 4.0], self.evaluate(l1_ret))\n\n    with ops.control_dependencies([l_push]):\n      l_unstack_orig = array_ops.unstack(l_batch)\n      l0_orig_ret = list_ops.tensor_list_stack(l_unstack_orig[0],\n                                               dtypes.float32)\n      l1_orig_ret = list_ops.tensor_list_stack(l_unstack_orig[1],\n                                               dtypes.float32)\n\n    # Check that without aliasing, push_back_batch still works; and\n    # that it doesn't modify the input.\n    l0_r_v, l1_r_v, l0_orig_v, l1_orig_v = self.evaluate(\n        (l0_ret, l1_ret, l0_orig_ret, l1_orig_ret))\n    self.assertAllClose([1.0, 2.0, 3.0], l0_r_v)\n    self.assertAllClose([-1.0, 4.0], l1_r_v)\n    self.assertAllClose([1.0, 2.0], l0_orig_v)\n    self.assertAllClose([-1.0], l1_orig_v)\n\n    # Pushing back mismatched shapes fails.\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      self.evaluate(list_ops.tensor_list_push_back_batch(l_batch, []))\n\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"incompatible shape to a list at index 0\"):\n      self.evaluate(\n          list_ops.tensor_list_push_back_batch(l_batch, [[3.0], [4.0]]))\n\n    if context.executing_eagerly():\n      expected_error = (errors.InvalidArgumentError, \"Invalid data type\")\n    else:\n      expected_error = (ValueError, \"wrong element dtype\")\n    with self.assertRaisesRegex(*expected_error):\n      self.evaluate(list_ops.tensor_list_push_back_batch(l_batch, [3, 4]))\n\n  def testZerosLike(self):\n    for dtype in (dtypes.uint8, dtypes.uint16, dtypes.int8, dtypes.int16,\n                  dtypes.int32, dtypes.int64, dtypes.float16, dtypes.float32,\n                  dtypes.float64, dtypes.complex64, dtypes.complex128,\n                  dtypes.bool):\n      l_empty = list_ops.empty_tensor_list(\n          element_dtype=dtype, element_shape=[])\n      l_empty_zeros = array_ops.zeros_like(l_empty)\n      t_empty_zeros = list_ops.tensor_list_stack(\n          l_empty_zeros, element_dtype=dtype)\n\n      l_full = list_ops.tensor_list_push_back(l_empty,\n                                              math_ops.cast(0, dtype=dtype))\n      l_full = list_ops.tensor_list_push_back(l_full,\n                                              math_ops.cast(1, dtype=dtype))\n      l_full_zeros = array_ops.zeros_like(l_full)\n      t_full_zeros = list_ops.tensor_list_stack(\n          l_full_zeros, element_dtype=dtype)\n\n      self.assertAllEqual(self.evaluate(t_empty_zeros), [])\n      self.assertAllEqual(\n          self.evaluate(t_full_zeros), np.zeros(\n              (2,), dtype=dtype.as_numpy_dtype))\n\n  def testZerosLikeNested(self):\n    for dtype in (dtypes.uint8, dtypes.uint16, dtypes.int8, dtypes.int16,\n                  dtypes.int32, dtypes.int64, dtypes.float16, dtypes.float32,\n                  dtypes.float64, dtypes.complex64, dtypes.complex128,\n                  dtypes.bool):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.variant, element_shape=[])\n\n      sub_l = list_ops.empty_tensor_list(element_dtype=dtype, element_shape=[])\n      l = list_ops.tensor_list_push_back(l, sub_l)\n      sub_l = list_ops.tensor_list_push_back(sub_l, math_ops.cast(\n          1, dtype=dtype))\n      l = list_ops.tensor_list_push_back(l, sub_l)\n      sub_l = list_ops.tensor_list_push_back(sub_l, math_ops.cast(\n          2, dtype=dtype))\n      l = list_ops.tensor_list_push_back(l, sub_l)\n\n      # l : [[],\n      #      [1],\n      #      [1, 2]]\n      #\n      # l_zeros : [[],\n      #            [0],\n      #            [0, 0]]\n      l_zeros = array_ops.zeros_like(l)\n\n      outputs = []\n      for _ in range(3):\n        l_zeros, out = list_ops.tensor_list_pop_back(\n            l_zeros, element_dtype=dtypes.variant)\n        outputs.append(list_ops.tensor_list_stack(out, element_dtype=dtype))\n\n      # Note: `outputs` contains popped values so the order is reversed.\n      self.assertAllEqual(self.evaluate(outputs[2]), [])\n      self.assertAllEqual(\n          self.evaluate(outputs[1]), np.zeros((1,), dtype=dtype.as_numpy_dtype))\n      self.assertAllEqual(\n          self.evaluate(outputs[0]), np.zeros((2,), dtype=dtype.as_numpy_dtype))\n\n  def testElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    shape = list_ops.tensor_list_element_shape(l, shape_type=dtypes.int32)\n    self.assertEqual(self.evaluate(shape), -1)\n\n  def testZerosLikeUninitialized(self):\n    l0 = list_ops.tensor_list_reserve([], 3, element_dtype=dtypes.float32)\n    l1 = list_ops.tensor_list_set_item(l0, 0, 1.)  # [1., _, _]\n    zeros_1 = array_ops.zeros_like(l1)  # [0., _, _]\n    l2 = list_ops.tensor_list_set_item(l1, 2, 2.)  # [1., _, 2.]\n    zeros_2 = array_ops.zeros_like(l2)  # [0., _, 0.]\n\n    # Gather indices with zeros in `zeros_1`.\n    res_1 = list_ops.tensor_list_gather(\n        zeros_1, [0], element_dtype=dtypes.float32)\n    # Gather indices with zeros in `zeros_2`.\n    res_2 = list_ops.tensor_list_gather(\n        zeros_2, [0, 2], element_dtype=dtypes.float32)\n\n    self.assertAllEqual(self.evaluate(res_1), [0.])\n    self.assertAllEqual(self.evaluate(res_2), [0., 0.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerTensorListGetItemGradAggregation(self):\n    l = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    x = constant_op.constant(1.0)\n    l = list_ops.tensor_list_set_item(l, 0, x)\n    l_read1 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    l_read2 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients([l_read1, l_read2], [x])\n    with self.cached_session() as sess:\n      self.assertSequenceEqual(self.evaluate(grad), [2.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerBuildElementShape(self):\n    fn = list_ops._build_element_shape\n    # Unknown shape -> -1.\n    self.assertEqual(fn(None), -1)\n    self.assertEqual(fn(tensor_shape.unknown_shape()), -1)\n    # Scalar shape -> [] with type int32.\n    self.assertEqual(fn([]).dtype, dtypes.int32)\n    self.assertEqual(fn(tensor_shape.TensorShape([])).dtype, dtypes.int32)\n    self.assertAllEqual(self.evaluate(fn([])), np.array([], np.int32))\n    self.assertAllEqual(\n        self.evaluate(fn(tensor_shape.TensorShape([]))), np.array([], np.int32))\n    # Tensor -> Tensor\n    shape = constant_op.constant(1)\n    self.assertIs(fn(shape), shape)\n    # Shape with unknown dims -> shape list with -1's.\n    shape = [None, 5]\n    self.assertAllEqual(fn(shape), [-1, 5])\n    self.assertAllEqual(fn(tensor_shape.TensorShape(shape)), [-1, 5])\n    # Shape with unknown dims and tensor dims -> shape list with -1's and tensor\n    # dims.\n    t = array_ops.placeholder(dtypes.int32)\n    shape = [None, 5, t]\n    result = fn(shape)\n    self.assertAllEqual(result[:2], [-1, 5])\n    self.assertIs(result[2], t)\n\n  def testAddN(self):\n    l1 = list_ops.tensor_list_from_tensor([1.0, 2.0], element_shape=[])\n    l2 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l3 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    result = math_ops.add_n((l1, l2, l3))\n    result_t = list_ops.tensor_list_stack(result, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(result_t), [9., 12.])\n\n  def testAddNNestedList(self):\n    l1 = list_ops.tensor_list_from_tensor([1.0, 2.0], element_shape=[])\n    l2 = list_ops.tensor_list_from_tensor([3.0, 4.0], element_shape=[])\n    l3 = list_ops.tensor_list_from_tensor([5.0, 6.0], element_shape=[])\n    l4 = list_ops.tensor_list_from_tensor([7.0, 8.0], element_shape=[])\n    a = list_ops.empty_tensor_list(\n        element_dtype=dtypes.variant, element_shape=[])\n    a = list_ops.tensor_list_push_back(a, l1)\n    a = list_ops.tensor_list_push_back(a, l2)\n    b = list_ops.empty_tensor_list(\n        element_dtype=dtypes.variant, element_shape=[])\n    b = list_ops.tensor_list_push_back(b, l3)\n    b = list_ops.tensor_list_push_back(b, l4)\n    result = math_ops.add_n((a, b))\n    result_0 = list_ops.tensor_list_stack(\n        list_ops.tensor_list_get_item(result, 0, element_dtype=dtypes.variant),\n        element_dtype=dtypes.float32)\n    result_1 = list_ops.tensor_list_stack(\n        list_ops.tensor_list_get_item(result, 1, element_dtype=dtypes.variant),\n        element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(result_0), [6., 8.])\n    self.assertAllEqual(self.evaluate(result_1), [10., 12.])\n\n  def testAddTensorListsFailsIfLeadingDimsMismatch(self):\n    l1 = list_ops.tensor_list_reserve(\n        element_shape=[], element_dtype=dtypes.float32, num_elements=2)\n    l2 = list_ops.tensor_list_reserve(\n        element_shape=[], element_dtype=dtypes.float32, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Trying to add two lists of tensors with different lengths\"):\n      l = math_ops.add_n([l1, l2])\n      self.evaluate(list_ops.tensor_list_stack(l, element_dtype=dtypes.float32))\n\n  @test_util.run_v1_only(\"Uses placeholders\")\n  def testSkipEagerAddTensorListsFailsIfElementShapesMismatch(self):\n    with self.cached_session() as sess:\n      # Use placeholders instead of constant values for shapes to prevent TF's\n      # shape inference from catching this early.\n      l1_element_shape = array_ops.placeholder(dtype=dtypes.int32)\n      l2_element_shape = array_ops.placeholder(dtype=dtypes.int32)\n      l1 = list_ops.tensor_list_reserve(\n          element_shape=l1_element_shape,\n          element_dtype=dtypes.float32,\n          num_elements=3)\n      l2 = list_ops.tensor_list_reserve(\n          element_shape=l2_element_shape,\n          element_dtype=dtypes.float32,\n          num_elements=3)\n      l = math_ops.add_n([l1, l2])\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          \"Trying to add two lists of tensors with incompatible element shapes\"\n      ):\n        sess.run(\n            list_ops.tensor_list_stack(l, element_dtype=dtypes.float32), {\n                l1_element_shape: [],\n                l2_element_shape: [2]\n            })\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerConcatShapeInference(self):\n\n    def BuildTensor(element_shape):\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=element_shape)\n      return list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n\n    self.assertIsNone(BuildTensor(None).shape.rank)\n    self.assertAllEqual(BuildTensor([None, 2, 3]).shape.as_list(), [None, 2, 3])\n    self.assertAllEqual(\n        BuildTensor([None, 2, None]).shape.as_list(), [None, 2, None])\n    self.assertAllEqual(BuildTensor([1, 2, 3]).shape.as_list(), [None, 2, 3])\n\n  def testConcatWithFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[2, 2])\n    l = list_ops.tensor_list_push_back(l, [[0., 1.], [2., 3.]])\n    l = list_ops.tensor_list_push_back(l, [[4., 5.], [6., 7.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(\n        self.evaluate(t), [[0., 1.], [2., 3.], [4., 5.], [6., 7.]])\n\n  def testConcatWithNonFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[None, 2])\n    l = list_ops.tensor_list_push_back(l, [[0., 1.]])\n    l = list_ops.tensor_list_push_back(l, [[2., 3.], [4., 5.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t), [[0., 1.], [2., 3.], [4., 5.]])\n\n  def testConcatWithMismatchingTensorShapesFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l = list_ops.tensor_list_push_back(l, [[0., 1.]])\n    l = list_ops.tensor_list_push_back(l, [[2.], [4.]])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, r\"Incompatible shapes during merge: \"\n        r\"\\[2\\] vs. \\[1\\]\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatEmptyListWithFullyDefinedElementShape(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[5, 2])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 2))\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[None, 2])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(self.evaluate(t).shape, (0, 2))\n\n  def testConcatEmptyListWithUnknownElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"All except the first dimension must be fully\"\n        \" defined when concating an empty tensor list\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatEmptyListWithPartiallyDefinedElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=[2, None])\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"All except the first dimension must be fully\"\n        \" defined when concating an empty tensor list\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatListWithScalarElementShapeFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32,\n        element_shape=tensor_shape.TensorShape([]))\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Concat requires elements to be at least vectors, \"\n        \"found scalars instead\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatListWithScalarElementsFails(self):\n    l = list_ops.empty_tensor_list(\n        element_dtype=dtypes.float32, element_shape=None)\n    l1 = list_ops.tensor_list_push_back(l, 1.)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Concat saw a scalar shape at index 0\"\n        \" but requires at least vectors\"):\n      t = list_ops.tensor_list_concat(l1, element_dtype=dtypes.float32)\n      self.evaluate(t)\n    l1 = list_ops.tensor_list_push_back(l, [1.])\n    l1 = list_ops.tensor_list_push_back(l1, 2.)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError, \"Concat saw a scalar shape at index 1\"\n        \" but requires at least vectors\"):\n      t = list_ops.tensor_list_concat(l1, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatWithUninitializedTensorsUseListElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[2, 3], num_elements=3)\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual(np.zeros((6, 3)), t)\n\n  def testConcatWithUninitializedTensorsUseProvidedElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t = list_ops.tensor_list_concat(\n        l, element_dtype=dtypes.float32, element_shape=(2, 3))\n    self.assertAllEqual(np.zeros((6, 3)), t)\n\n  def testConcatWithUninitializedTensorsUseProvidedElementShapeAndLengths(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    t, _ = gen_list_ops.tensor_list_concat_v2(\n        l,\n        element_dtype=dtypes.float32,\n        element_shape=list_ops._build_element_shape((None, 3)),\n        leading_dims=[2, 3, 5])\n    self.assertAllEqual(np.zeros((10, 3)), t)\n    l = list_ops.tensor_list_set_item(l, 1, [[2., 3.], [4., 5.], [6., 7.]])\n    t, _ = gen_list_ops.tensor_list_concat_v2(\n        l,\n        element_dtype=dtypes.float32,\n        element_shape=list_ops._build_element_shape((None, 2)),\n        leading_dims=[2, 3, 4])\n    self.assertAllEqual([[0., 0.], [0., 0.], [2., 3.], [4., 5.], [6., 7.],\n                         [0., 0.], [0., 0.], [0., 0.], [0., 0.]], t)\n\n  def testConcatWithUninitializedTensorsInferShapeFromElements(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    l = list_ops.tensor_list_set_item(l, 1, [[2., 3.], [4., 5.], [6., 7.]])\n    t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n    self.assertAllEqual([[0., 0.], [0., 0.], [0., 0.], [2., 3.], [4., 5.],\n                         [6., 7.], [0., 0.], [0., 0.], [0., 0.]], t)\n\n  def testConcatWithUninitializedTensorsFailsIfNoElementShape(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=None, num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Trying to concat list with only uninitialized tensors \"\n        r\"but element_shape_except_first_dim is not fully defined\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testConcatWithUninitializedTensorsFailsIfNoInputLengths(self):\n    l = list_ops.tensor_list_reserve(\n        element_dtype=dtypes.float32, element_shape=[None, 3], num_elements=3)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"List contains uninitialized tensor at index 0\"\n        r\" but leading_dims has only 0 elements.\"):\n      t = list_ops.tensor_list_concat(l, element_dtype=dtypes.float32)\n      self.evaluate(t)\n\n  def testEmptyTensorListInvalidShape(self):\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                r\"Shape must be at most rank 1 but is rank 2\"):\n      t = gen_list_ops.EmptyTensorList(\n          element_shape=array_ops.ones(dtype=dtypes.int32, shape=[1, 0]),\n          max_num_elements=constant_op.constant(1),\n          element_dtype=dtypes.int32)\n      self.evaluate(t)\n\n  def testEvenSplit(self):\n\n    def RunTest(input_tensor, lengths, expected_stacked_output):\n      l = list_ops.tensor_list_split(\n          input_tensor, element_shape=None, lengths=lengths)\n      self.assertAllEqual(\n          list_ops.tensor_list_stack(l, element_dtype=dtypes.float32),\n          expected_stacked_output)\n\n    RunTest([1., 2., 3.], [1, 1, 1], [[1.], [2.], [3.]])\n    RunTest([1., 2., 3., 4.], [2, 2], [[1., 2.], [3., 4.]])\n    RunTest([[1., 2.], [3., 4.]], [1, 1], [[[1., 2.]], [[3., 4.]]])\n\n  def testUnevenSplit(self):\n    l = list_ops.tensor_list_split([1., 2., 3., 4., 5],\n                                   element_shape=None,\n                                   lengths=[3, 2])\n    self.assertAllEqual(list_ops.tensor_list_length(l), 2)\n    self.assertAllEqual(\n        list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32),\n        [1., 2., 3.])\n    self.assertAllEqual(\n        list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32),\n        [4., 5.])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithInvalidTensorShapeFails(self):\n    with self.cached_session():\n      tensor = array_ops.placeholder(dtype=dtypes.float32)\n      l = list_ops.tensor_list_split(tensor, element_shape=None, lengths=[1])\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"Tensor must be at least a vector, but saw shape: \\[\\]\"):\n        l.eval({tensor: 1})\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithInvalidLengthsShapeFails(self):\n    with self.cached_session():\n      lengths = array_ops.placeholder(dtype=dtypes.int64)\n      l = list_ops.tensor_list_split([1., 2.],\n                                     element_shape=None,\n                                     lengths=lengths)\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"Expected lengths to be a vector, received shape: \\[\\]\"):\n        l.eval({lengths: 1})\n\n  def testSplitWithInvalidLengthsFails(self):\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                r\"Invalid value in lengths: -1\"):\n      l = list_ops.tensor_list_split([1., 2.],\n                                     element_shape=None,\n                                     lengths=[1, -1])\n      self.evaluate(l)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Attempting to slice \\[0, 3\\] from tensor with length 2\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=None, lengths=[3])\n      self.evaluate(l)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Unused values in tensor. Length of tensor: 2 Values used: 1\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=None, lengths=[1])\n      self.evaluate(l)\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithScalarElementShapeFails(self):\n    with self.assertRaisesRegex(ValueError,\n                                r\"Shapes must be equal rank, but are 1 and 0\"):\n      l = list_ops.tensor_list_split([1., 2.], element_shape=[], lengths=[1, 1])\n    with self.cached_session():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"TensorListSplit requires element_shape to be at least of rank 1, \"\n          r\"but saw: \\[\\]\"):\n        element_shape = array_ops.placeholder(dtype=dtypes.int32)\n        l = list_ops.tensor_list_split([1., 2.],\n                                       element_shape=element_shape,\n                                       lengths=[1, 1])\n        l.eval({element_shape: []})\n\n  def testEagerOnlySplitWithScalarElementShapeFails(self):\n    if context.executing_eagerly():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"TensorListSplit requires element_shape to be at least of rank 1, \"\n          r\"but saw: \\[\\]\"):\n        list_ops.tensor_list_split([1., 2.], element_shape=[], lengths=[1, 1])\n\n  @test_util.run_deprecated_v1\n  def testSkipEagerSplitWithIncompatibleTensorShapeAndElementShapeFails(self):\n    with self.assertRaisesRegex(ValueError,\n                                r\"Shapes must be equal rank, but are 2 and 1\"):\n      l = list_ops.tensor_list_split([[1.], [2.]],\n                                     element_shape=[1],\n                                     lengths=[1, 1])\n\n    with self.cached_session():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"tensor shape \\[2,1\\] is not compatible with element_shape \\[1\\]\"):\n        element_shape = array_ops.placeholder(dtype=dtypes.int32)\n        l = list_ops.tensor_list_split([[1.], [2.]],\n                                       element_shape=element_shape,\n                                       lengths=[1, 1])\n        l.eval({element_shape: [1]})\n\n  def testEagerOnlySplitWithIncompatibleTensorShapeAndElementShapeFails(self):\n    if context.executing_eagerly():\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"tensor shape \\[2,1\\] is not compatible with element_shape \\[1\\]\"):\n        list_ops.tensor_list_split([[1.], [2.]],\n                                   element_shape=[1],\n                                   lengths=[1, 1])\n\n  def testResizeGrow(self):\n    l = list_ops.tensor_list_from_tensor([1., 2.], element_shape=[])\n    l = list_ops.tensor_list_resize(l, 4)\n    self.assertEqual(self.evaluate(list_ops.tensor_list_length(l)), 4)\n    self.assertEqual(\n        self.evaluate(\n            list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)),\n        1.)\n    self.assertEqual(\n        self.evaluate(\n            list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)),\n        2.)\n\n  def testResizeShrink(self):\n    l = list_ops.tensor_list_from_tensor([1., 2., 3.], element_shape=[])\n    l = list_ops.tensor_list_resize(l, 2)\n    self.assertEqual(self.evaluate(list_ops.tensor_list_length(l)), 2)\n    self.assertAllEqual(\n        self.evaluate(\n            list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)),\n        [1., 2.])\n\n  def testResizeWithInvalidSizeFails(self):\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"TensorListSlice expects size to be non-negative\"):\n      l = list_ops.tensor_list_from_tensor([1., 2., 3.], element_shape=[])\n      l = list_ops.tensor_list_resize(l, -1)\n      self.evaluate(l)\n\n  @test_util.run_deprecated_v1\n  @test_util.enable_control_flow_v2\n  def testSkipEagerResizeGrad(self):\n    t = constant_op.constant([1., 2., 3.])\n    l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n    l = list_ops.tensor_list_set_item(\n        l, 3, 4., resize_if_index_out_of_bounds=True)\n    t1 = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n    grad = gradients_impl.gradients(t1, t)[0]\n    self.assertAllEqual(self.evaluate(grad), [1., 1., 1.])\n\n  def testHandleDataAcrossFunctionCall(self):\n\n    @def_function.function\n    def func():\n      t = constant_op.constant([1., 2., 3.])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      handle_data = resource_variable_ops.get_eager_safe_handle_data(l)\n      self.assertTrue(handle_data.is_set)\n      self.assertEqual(handle_data.shape_and_type[0].type.type_id,\n                       full_type_pb2.TFT_ARRAY)\n      return l\n\n    tensor_list = func()\n    handle_data = resource_variable_ops.get_eager_safe_handle_data(tensor_list)\n    self.assertTrue(handle_data.is_set)\n    self.assertEqual(dtypes.float32, handle_data.shape_and_type[0].dtype)\n    self.assertEqual(handle_data.shape_and_type[0].type.type_id,\n                     full_type_pb2.TFT_ARRAY)\n    element = list_ops.tensor_list_get_item(\n        tensor_list, 0, element_dtype=dtypes.float32)\n    self.assertAllEqual(element.shape.as_list(), [])\n\n  @test_util.run_gpu_only\n  def testNestedListDevicetoDeviceCopy(self):\n    if context.num_gpus() < 2:\n      self.skipTest(\"Need at least 2 GPUs for this test, found %d\" %\n                    context.num_gpus())\n    with ops.device(\"gpu:0\"):\n      t = constant_op.constant([1.0, 2.0, 3.0])\n      inner_l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      outer_l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.variant, element_shape=[])\n      outer_l = list_ops.tensor_list_push_back(outer_l, inner_l)\n\n    # Stress test.\n    for _ in range(1024):\n      with ops.device(\"gpu:1\"):\n        outer_l = array_ops.identity(outer_l)\n      with ops.device(\"gpu:0\"):\n        outer_l = array_ops.identity(outer_l)\n\n    with ops.device(\"gpu:1\"):\n      _, inner_l = list_ops.tensor_list_pop_back(\n          outer_l, element_dtype=dtypes.variant)\n      t = list_ops.tensor_list_stack(inner_l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [1.0, 2.0, 3.0])\n\n  def testTensorListStrings(self):\n    @def_function.function\n    def f():\n      return map_fn.map_fn(string_ops.string_upper,\n                           constant_op.constant([\"a\", \"b\", \"c\"]))\n\n    self.assertAllEqual(f(), [b\"A\", b\"B\", b\"C\"])\n\n  def testTensorListStringsNoInline(self):\n    # Generator function output type is a variant with a host-only underlying\n    # data type. \"ColocationGraph::AddHostOnlyDataTypesConstraints\" needs to\n    # have \"deep op inspection\" to be able to correctly place the while loop\n    # generated from map_fn.\n    self.skipTest(\"b/150742232\")\n\n    @function.defun_with_attributes(attributes={\"_noinline\": True})\n    def generator():\n      c = constant_op.constant([\"a\", \"b\", \"c\"])\n      return list_ops.tensor_list_from_tensor(c, element_shape=[])\n\n    @def_function.function\n    def f():\n      l = generator()\n\n      def upper(i):\n        e = list_ops.tensor_list_get_item(l, i, element_dtype=dtypes.string)\n        return string_ops.string_upper(e)\n\n      return map_fn.map_fn(\n          upper, constant_op.constant([0, 1, 2]), dtype=dtypes.string)\n\n    self.assertAllEqual(f(), [b\"A\", b\"B\", b\"C\"])\n\n  def testPopBackGrad(self):\n    # https://github.com/tensorflow/tensorflow/issues/37230\n\n    @def_function.function\n    def g(x):\n      x_prod = constant_op.constant([1.])\n      for unused_i in math_ops.range(3):\n        x_prod = x_prod * x\n      return x_prod\n\n    x = constant_op.constant(1.)\n    with backprop.GradientTape() as t:\n      t.watch(x)\n      with backprop.GradientTape() as tt:\n        tt.watch(x)\n        loss = g(x)\n      jac = tt.gradient(loss, x)\n    hess = t.gradient(jac, x)\n    self.assertAllEqual(hess, 6.)\n\n  def testTensorListElementShapeShapeInference(self):\n\n    @def_function.function\n    def f():\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=None)\n      l_element_shape = list_ops.tensor_list_element_shape(l, dtypes.int32)\n      self.assertIsNone(l_element_shape.shape.rank)\n      shape_l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.int32, element_shape=l_element_shape.shape)\n      shape_l = list_ops.tensor_list_push_back(shape_l, l_element_shape)\n      return list_ops.tensor_list_pop_back(shape_l, dtypes.int32)[1]\n\n    self.assertAllEqual(f(), -1)\n\n  def testElementShapeArgOfTensorListFromTensor(self):\n\n    @def_function.function\n    def f():\n      t = array_ops.ones([3, 3])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[-1])\n      l = list_ops.tensor_list_push_back(l, array_ops.ones([4]))\n      read_val = list_ops.tensor_list_get_item(\n          l, 3, element_dtype=dtypes.float32)\n      self.assertAllEqual(read_val.shape.as_list(), [None])\n      return read_val\n\n    self.assertAllEqual(f(), [1.0, 1.0, 1.0, 1.0])\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "filenames": ["tensorflow/core/kernels/list_kernels.cc", "tensorflow/python/kernel_tests/data_structures/list_ops_test.py"], "buggy_code_start_loc": [33, 94], "buggy_code_end_loc": [324, 94], "fixing_code_start_loc": [34, 95], "fixing_code_end_loc": [332, 105], "type": "CWE-617", "message": "TensorFlow is an open source platform for machine learning. In `core/kernels/list_kernels.cc's TensorListReserve`, `num_elements` is assumed to be a tensor of size 1. When a `num_elements` of more than 1 element is provided, then `tf.raw_ops.TensorListReserve` fails the `CHECK_EQ` in `CheckIsAlignedAndSingleElement`. We have patched the issue in GitHub commit b5f6fbfba76576202b72119897561e3bd4f179c7. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35960", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T20:15:10.573", "lastModified": "2022-09-21T17:09:58.763", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In `core/kernels/list_kernels.cc's TensorListReserve`, `num_elements` is assumed to be a tensor of size 1. When a `num_elements` of more than 1 element is provided, then `tf.raw_ops.TensorListReserve` fails the `CHECK_EQ` in `CheckIsAlignedAndSingleElement`. We have patched the issue in GitHub commit b5f6fbfba76576202b72119897561e3bd4f179c7. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En \"core/kernels/list_kernels.cc's TensorListReserve\", se asume que \"num_elements\" es un tensor de tama\u00f1o 1. Cuando se proporciona un \"num_elements\" de m\u00e1s de 1 elemento, entonces \"tf.raw_ops.TensorListReserve\" falla el \"CHECK_EQ\" en \"CheckIsAlignedAndSingleElement\". Hemos parcheado el problema en el commit b5f6fbfba76576202b72119897561e3bd4f179c7 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C4DFBF2D-5283-42F6-8800-D653BFA5CE82"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C3684238-B1B8-4134-9FED-8A3733E1F39B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.9.0:*:*:*:*:*:*:*", "matchCriteriaId": "08DF9052-55EF-4B54-94C6-EC9B4FC87DE1"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/c8ba76d48567aed347508e0552a257641931024d/tensorflow/core/kernels/list_kernels.cc#L322-L325", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/b5f6fbfba76576202b72119897561e3bd4f179c7", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v5xg-3q2c-c2r4", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/b5f6fbfba76576202b72119897561e3bd4f179c7"}}