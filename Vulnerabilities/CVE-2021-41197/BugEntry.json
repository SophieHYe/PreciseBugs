{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/image_ops.cc\n\n#define EIGEN_USE_THREADS\n\n#include \"tensorflow/core/kernels/image/crop_and_resize_op.h\"\n\n#include <functional>\n#include <string>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_reference.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/determinism.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/common_runtime/gpu/gpu_event_mgr.h\"\n#include \"tensorflow/core/platform/stream_executor.h\"\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#if GOOGLE_CUDA\n#include \"tensorflow/stream_executor/cuda/cuda_activation.h\"\nusing stream_executor::cuda::ScopedActivateExecutorContext;\n#elif TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/platform/rocm.h\"\nusing stream_executor::rocm::ScopedActivateExecutorContext;\n#endif\n\nnamespace tensorflow {\nnamespace {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\nusing Callback = std::function<void()>;\n\nstatic inline Status ParseAndCheckBoxSizes(const Tensor& boxes,\n                                           const Tensor& box_index,\n                                           int* num_boxes) {\n  if (boxes.NumElements() == 0 && box_index.NumElements() == 0) {\n    *num_boxes = 0;\n    return Status::OK();\n  }\n  // The shape of 'boxes' is [num_boxes, 4].\n  if (boxes.dims() != 2) {\n    return errors::InvalidArgument(\"boxes must be 2-D\",\n                                   boxes.shape().DebugString());\n  }\n  *num_boxes = boxes.dim_size(0);\n  if (boxes.dim_size(1) != 4) {\n    return errors::InvalidArgument(\"boxes must have 4 columns\");\n  }\n  // The shape of 'box_index' is [num_boxes].\n  if (box_index.dims() != 1) {\n    return errors::InvalidArgument(\"box_index must be 1-D\",\n                                   box_index.shape().DebugString());\n  }\n  if (box_index.dim_size(0) != *num_boxes) {\n    return errors::InvalidArgument(\"box_index has incompatible shape\");\n  }\n  return Status::OK();\n}\n\n// Conditionally calls the compute callback if all values in box_index are in\n// [0, batch_size) then calls done.\ntemplate <typename Device>\ninline void RunIfBoxIndexIsValid(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done);\n\n// Specialization of CheckValidBoxIndex for a CPUDevice.\ntemplate <>\ninline void RunIfBoxIndexIsValid<CPUDevice>(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done) {\n  const int num_boxes = box_index.dimension(0);\n  for (int b = 0; b < num_boxes; ++b) {\n    OP_REQUIRES_ASYNC(\n        context, FastBoundsCheck(box_index(b), batch_size),\n        errors::OutOfRange(\"box_index has values outside [0, batch_size)\"),\n        done);\n  }\n  if (compute) {\n    compute();\n  }\n  if (done) {\n    done();\n  }\n}\n\n}  // namespace\n\ntemplate <typename Device, typename T>\nclass CropAndResizeOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method_));\n    OP_REQUIRES(context, method_ == \"bilinear\" || method_ == \"nearest\",\n                errors::InvalidArgument(\n                    \"method must be 'bilinear' or 'nearest'\", method_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"extrapolation_value\",\n                                             &extrapolation_value_));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'image' is [batch_size, image_height, image_width,\n    // channels].\n    const Tensor& image = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(1);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(2);\n    // The shape of 'crop_size' is [2].\n    const Tensor& crop_size = context->input(3);\n\n    // Validate inputs dimensions.\n    OP_REQUIRES_ASYNC(context, image.dims() == 4,\n                      errors::InvalidArgument(\"input image must be 4-D\",\n                                              image.shape().DebugString()),\n                      done);\n    const int batch_size = image.dim_size(0);\n    const int image_height = image.dim_size(1);\n    const int image_width = image.dim_size(2);\n    const int depth = image.dim_size(3);\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n\n    OP_REQUIRES_ASYNC(context, crop_size.dims() == 1,\n                      errors::InvalidArgument(\"crop_size must be 1-D\",\n                                              crop_size.shape().DebugString()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, crop_size.dim_size(0) == 2,\n        errors::InvalidArgument(\"crop_size must have two elements\",\n                                crop_size.shape().DebugString()),\n        done);\n\n    // Copy and validate crop sizes.\n    auto crop_size_vec = crop_size.vec<int32>();\n    const int crop_height = internal::SubtleMustCopy(crop_size_vec(0));\n    const int crop_width = internal::SubtleMustCopy(crop_size_vec(1));\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"crop dimensions must be positive\"), done);\n\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->allocate_output(\n            0, TensorShape({num_boxes, crop_height, crop_width, depth}),\n            &output),\n        done);\n\n    auto compute_callback = [this, context, output]() {\n      const Tensor& image = context->input(0);\n      const Tensor& boxes = context->input(1);\n      const Tensor& box_index = context->input(2);\n      const bool status = functor::CropAndResize<Device, T>()(\n          context, image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), method_, extrapolation_value_,\n          output->tensor<float, 4>());\n\n      if (!status) {\n        context->SetStatus(\n            errors::Internal(\"Failed to launch CropAndResizeKernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n\n private:\n  float extrapolation_value_;\n  string method_;\n};\n\n// Partial specialization of CropAndResize functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResize<CPUDevice, T> {\n  bool operator()(OpKernelContext* context,\n                  typename TTypes<T, 4>::ConstTensor image,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  const string& method_name, float extrapolation_value,\n                  typename TTypes<float, 4>::Tensor crops) {\n    const int batch_size = image.dimension(0);\n    const int image_height = image.dimension(1);\n    const int image_width = image.dimension(2);\n\n    const int num_boxes = crops.dimension(0);\n    const int crop_height = crops.dimension(1);\n    const int crop_width = crops.dimension(2);\n    const int depth = crops.dimension(3);\n\n    // Since `functor::CropAndResize` operates on float, we first validate\n    // that we don't overflow (since overflow causes undefined behavior which\n    // could result in segfault in this scenario).\n    const Eigen::Tensor<bool, 0, Eigen::RowMajor> only_finite_elements =\n        boxes.isfinite().all();\n    if (!only_finite_elements()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Boxes contains at least one element that is not finite\"));\n      return false;\n    }\n\n    // Sharding across boxes.\n    auto CropAndResizePerBox = [&](int64_t start_box, int64_t limit_box) {\n      for (int b = start_box; b < limit_box; ++b) {\n        const float y1 = boxes(b, 0);\n        const float x1 = boxes(b, 1);\n        const float y2 = boxes(b, 2);\n        const float x2 = boxes(b, 3);\n\n        const int32_t b_in = box_index(b);\n        if (!FastBoundsCheck(b_in, batch_size)) {\n          continue;\n        }\n\n        const float height_scale =\n            (crop_height > 1)\n                ? (y2 - y1) * (image_height - 1) / (crop_height - 1)\n                : 0;\n        const float width_scale =\n            (crop_width > 1) ? (x2 - x1) * (image_width - 1) / (crop_width - 1)\n                             : 0;\n\n        for (int y = 0; y < crop_height; ++y) {\n          const float in_y = (crop_height > 1)\n                                 ? y1 * (image_height - 1) + y * height_scale\n                                 : 0.5 * (y1 + y2) * (image_height - 1);\n          if (in_y < 0 || in_y > image_height - 1) {\n            for (int x = 0; x < crop_width; ++x) {\n              for (int d = 0; d < depth; ++d) {\n                crops(b, y, x, d) = extrapolation_value;\n              }\n            }\n            continue;\n          }\n          if (method_name == \"bilinear\") {\n            const int top_y_index = floorf(in_y);\n            const int bottom_y_index = ceilf(in_y);\n            const float y_lerp = in_y - top_y_index;\n\n            for (int x = 0; x < crop_width; ++x) {\n              const float in_x = (crop_width > 1)\n                                     ? x1 * (image_width - 1) + x * width_scale\n                                     : 0.5 * (x1 + x2) * (image_width - 1);\n              if (in_x < 0 || in_x > image_width - 1) {\n                for (int d = 0; d < depth; ++d) {\n                  crops(b, y, x, d) = extrapolation_value;\n                }\n                continue;\n              }\n              const int left_x_index = floorf(in_x);\n              const int right_x_index = ceilf(in_x);\n              const float x_lerp = in_x - left_x_index;\n\n              for (int d = 0; d < depth; ++d) {\n                const float top_left(static_cast<float>(\n                    image(b_in, top_y_index, left_x_index, d)));\n                const float top_right(static_cast<float>(\n                    image(b_in, top_y_index, right_x_index, d)));\n                const float bottom_left(static_cast<float>(\n                    image(b_in, bottom_y_index, left_x_index, d)));\n                const float bottom_right(static_cast<float>(\n                    image(b_in, bottom_y_index, right_x_index, d)));\n                const float top = top_left + (top_right - top_left) * x_lerp;\n                const float bottom =\n                    bottom_left + (bottom_right - bottom_left) * x_lerp;\n                crops(b, y, x, d) = top + (bottom - top) * y_lerp;\n              }\n            }\n          } else {  // method == \"nearest\"\n            for (int x = 0; x < crop_width; ++x) {\n              const float in_x = (crop_width > 1)\n                                     ? x1 * (image_width - 1) + x * width_scale\n                                     : 0.5 * (x1 + x2) * (image_width - 1);\n              if (in_x < 0 || in_x > image_width - 1) {\n                for (int d = 0; d < depth; ++d) {\n                  crops(b, y, x, d) = extrapolation_value;\n                }\n                continue;\n              }\n              const int closest_x_index = roundf(in_x);\n              const int closest_y_index = roundf(in_y);\n              for (int d = 0; d < depth; ++d) {\n                crops(b, y, x, d) = static_cast<float>(\n                    image(b_in, closest_y_index, closest_x_index, d));\n              }\n            }\n          }\n        }\n      }\n    };\n\n    // A rough estimation of the cost for each cropped box.\n    double cost_per_pixel =\n        depth * (Eigen::TensorOpCost::AddCost<float>() * 6 +\n                 Eigen::TensorOpCost::MulCost<float>() * 3 +\n                 Eigen::TensorOpCost::CastCost<T, float>() * 4) +\n        (Eigen::TensorOpCost::AddCost<float>() * 2 +\n         Eigen::TensorOpCost::AddCost<float>() * 3);\n    if (method_name == \"nearest\") {\n      cost_per_pixel = depth * Eigen::TensorOpCost::CastCost<T, float>() +\n                       Eigen::TensorOpCost::AddCost<float>() * 4 +\n                       Eigen::TensorOpCost::MulCost<float>() * 4;\n    }\n    const double cost_per_box = crop_height * crop_width * cost_per_pixel;\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n    Shard(worker_threads.num_threads, worker_threads.workers, num_boxes,\n          cost_per_box, CropAndResizePerBox);\n\n    return true;\n  }\n};\n\n}  // namespace functor\n\ntemplate <typename Device, typename T>\nclass CropAndResizeGradImageOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeGradImageOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method_));\n    OP_REQUIRES(context, method_ == \"bilinear\" || method_ == \"nearest\",\n                errors::InvalidArgument(\n                    \"method must be 'bilinear' or 'nearest'\", method_));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'grads' is [num_boxes, crop_height, crop_width, depth].\n    const Tensor& grads = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(1);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(2);\n    // The shape of 'image_size' is [4].\n    const Tensor& image_size = context->input(3);\n\n    // Validate input shapes.\n    OP_REQUIRES_ASYNC(context, grads.dims() == 4,\n                      errors::InvalidArgument(\"grads image must be 4-D\",\n                                              grads.shape().DebugString()),\n                      done);\n    const int crop_height = grads.dim_size(1);\n    const int crop_width = grads.dim_size(2);\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"grads dimensions must be positive\"), done);\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(0) == num_boxes,\n        errors::InvalidArgument(\"boxes and grads have incompatible shape\"),\n        done);\n\n    OP_REQUIRES_ASYNC(context, image_size.dims() == 1,\n                      errors::InvalidArgument(\"image_size must be 1-D\",\n                                              image_size.shape().DebugString()),\n                      done);\n    OP_REQUIRES_ASYNC(context, image_size.dim_size(0) == 4,\n                      errors::InvalidArgument(\"image_size must have 4 elements\",\n                                              image_size.shape().DebugString()),\n                      done);\n    auto image_size_vec = image_size.vec<int32>();\n    const int batch_size = internal::SubtleMustCopy(image_size_vec(0));\n    const int image_height = internal::SubtleMustCopy(image_size_vec(1));\n    const int image_width = internal::SubtleMustCopy(image_size_vec(2));\n    const int depth = internal::SubtleMustCopy(image_size_vec(3));\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(3) == depth,\n        errors::InvalidArgument(\"image_size and grads are incompatible\"), done);\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES_ASYNC(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"Deterministic GPU implementation of CropAndResizeBackpropImage\"\n              \" not available.\"),\n          done);\n    }\n\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->allocate_output(\n            0, TensorShape({batch_size, image_height, image_width, depth}),\n            &output),\n        done);\n\n    auto compute_callback = [this, context, output]() {\n      const Tensor& grads = context->input(0);\n      const Tensor& boxes = context->input(1);\n      const Tensor& box_index = context->input(2);\n      const bool status = functor::CropAndResizeBackpropImage<Device, T>()(\n          context, grads.tensor<float, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), output->tensor<T, 4>(), method_);\n\n      if (!status) {\n        context->SetStatus(errors::Internal(\n            \"Failed to launch CropAndResizeBackpropImage kernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n\n private:\n  string method_;\n};\n\n// Partial specialization of CropAndResizeBackpropImage functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResizeBackpropImage<CPUDevice, T> {\n  bool operator()(const OpKernelContext* context,\n                  typename TTypes<float, 4>::ConstTensor grads,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  typename TTypes<T, 4>::Tensor grads_image,\n                  const string& method_name) {\n    const int batch_size = grads_image.dimension(0);\n    const int image_height = grads_image.dimension(1);\n    const int image_width = grads_image.dimension(2);\n\n    const int num_boxes = grads.dimension(0);\n    const int crop_height = grads.dimension(1);\n    const int crop_width = grads.dimension(2);\n    const int depth = grads.dimension(3);\n\n    grads_image.setZero();\n\n    auto CropAndResizeBackImgPerBox = [&](int64_t start_box,\n                                          int64_t limit_box) {\n      for (int b = start_box; b < limit_box; ++b) {\n        const float y1 = boxes(b, 0);\n        const float x1 = boxes(b, 1);\n        const float y2 = boxes(b, 2);\n        const float x2 = boxes(b, 3);\n\n        const int32_t b_in = box_index(b);\n        if (!FastBoundsCheck(b_in, batch_size)) {\n          continue;\n        }\n\n        const float height_scale =\n            (crop_height > 1)\n                ? (y2 - y1) * (image_height - 1) / (crop_height - 1)\n                : 0;\n        const float width_scale =\n            (crop_width > 1) ? (x2 - x1) * (image_width - 1) / (crop_width - 1)\n                             : 0;\n\n        for (int y = 0; y < crop_height; ++y) {\n          const float in_y = (crop_height > 1)\n                                 ? y1 * (image_height - 1) + y * height_scale\n                                 : 0.5 * (y1 + y2) * (image_height - 1);\n          if (in_y < 0 || in_y > image_height - 1) {\n            continue;\n          }\n          const int top_y_index = floorf(in_y);\n          const int bottom_y_index = ceilf(in_y);\n          const float y_lerp = in_y - top_y_index;\n\n          for (int x = 0; x < crop_width; ++x) {\n            const float in_x = (crop_width > 1)\n                                   ? x1 * (image_width - 1) + x * width_scale\n                                   : 0.5 * (x1 + x2) * (image_width - 1);\n            if (in_x < 0 || in_x > image_width - 1) {\n              continue;\n            }\n\n            if (method_name == \"bilinear\") {\n              const int left_x_index = floorf(in_x);\n              const int right_x_index = ceilf(in_x);\n              const float x_lerp = in_x - left_x_index;\n\n              for (int d = 0; d < depth; ++d) {\n                const float dtop = (1 - y_lerp) * grads(b, y, x, d);\n                grads_image(b_in, top_y_index, left_x_index, d) +=\n                    static_cast<T>((1 - x_lerp) * dtop);\n                grads_image(b_in, top_y_index, right_x_index, d) +=\n                    static_cast<T>(x_lerp * dtop);\n                const float dbottom = y_lerp * grads(b, y, x, d);\n                grads_image(b_in, bottom_y_index, left_x_index, d) +=\n                    static_cast<T>((1 - x_lerp) * dbottom);\n                grads_image(b_in, bottom_y_index, right_x_index, d) +=\n                    static_cast<T>(x_lerp * dbottom);\n              }\n            } else {  // method_name == \"nearest\"\n              for (int d = 0; d < depth; ++d) {\n                int closest_x_index = roundf(in_x);\n                int closest_y_index = roundf(in_y);\n                grads_image(b_in, closest_y_index, closest_x_index, d) +=\n                    static_cast<T>(grads(b, y, x, d));\n              }\n            }\n          }\n        }\n      }\n    };\n\n    // A rough estimation of the cost for each cropped box.\n    // Including calculation cost in the depth loop and pixel loop.\n    const double cost_per_pixel =\n        (method_name == \"bilinear\"\n             ? depth * (Eigen::TensorOpCost::AddCost<float>() * 7 +\n                        Eigen::TensorOpCost::MulCost<float>() * 6 +\n                        Eigen::TensorOpCost::CastCost<T, float>() * 4) +\n                   Eigen::TensorOpCost::AddCost<float>() * 4\n             : depth * (Eigen::TensorOpCost::AddCost<float>() +\n                        Eigen::TensorOpCost::CastCost<T, float>()) +\n                   Eigen::TensorOpCost::AddCost<float>() * 3);\n\n    const double cost_per_box = crop_height * crop_width * cost_per_pixel;\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Sharding introduces nondeterminism when the gradients associated with\n    // more than two crops backprop into the same element in the source image.\n    int max_threads = OpDeterminismRequired() ? 1 : worker_threads.num_threads;\n\n    Shard(max_threads, worker_threads.workers, num_boxes, cost_per_box,\n          CropAndResizeBackImgPerBox);\n\n    return true;\n  }\n};\n\n}  // namespace functor\n\ntemplate <typename Device, typename T>\nclass CropAndResizeGradBoxesOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeGradBoxesOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    string method;\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method));\n    OP_REQUIRES(context, method == \"bilinear\",\n                errors::InvalidArgument(\"method must be 'bilinear'\", method));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'grads' is [num_boxes, crop_height, crop_width, depth].\n    const Tensor& grads = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(2);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(3);\n    // The shape of 'image' is [batch_size, image_height, image_width, depth].\n    const Tensor& image = context->input(1);\n\n    // Validate input shapes.\n    OP_REQUIRES_ASYNC(context, grads.dims() == 4,\n                      errors::InvalidArgument(\"grads image must be 4-D\",\n                                              grads.shape().DebugString()),\n                      done);\n    const int crop_height = grads.dim_size(1);\n    const int crop_width = grads.dim_size(2);\n    const int depth = grads.dim_size(3);\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"grads dimensions must be positive\"), done);\n\n    OP_REQUIRES_ASYNC(context, image.dims() == 4,\n                      errors::InvalidArgument(\"input image must be 4-D\",\n                                              image.shape().DebugString()),\n                      done);\n    const int batch_size = image.dim_size(0);\n    const int image_height = image.dim_size(1);\n    const int image_width = image.dim_size(2);\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    OP_REQUIRES_ASYNC(context, image.dim_size(3) == depth,\n                      errors::InvalidArgument(\"image, grads depth differ\"),\n                      done);\n\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(0) == num_boxes,\n        errors::InvalidArgument(\"boxes and grads have incompatible shape\"),\n        done);\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES_ASYNC(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"Deterministic GPU implementation of CropAndResizeBackpropBoxes\"\n              \" not available.\"),\n          done);\n    }\n\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->allocate_output(0, TensorShape({num_boxes, 4}), &output),\n        done);\n\n    auto compute_callback = [context, output]() {\n      const Tensor& grads = context->input(0);\n      const Tensor& image = context->input(1);\n      const Tensor& boxes = context->input(2);\n      const Tensor& box_index = context->input(3);\n      const bool status = functor::CropAndResizeBackpropBoxes<Device, T>()(\n          context->eigen_device<Device>(), grads.tensor<float, 4>(),\n          image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), output->tensor<float, 2>());\n      if (!status) {\n        context->SetStatus(errors::Internal(\n            \"Failed to launch CropAndResizeBackpropBoxes kernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n};\n\n// Partial specialization of CropAndResizeBackpropBoxes functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResizeBackpropBoxes<CPUDevice, T> {\n  bool operator()(const CPUDevice& d,\n                  typename TTypes<float, 4>::ConstTensor grads,\n                  typename TTypes<T, 4>::ConstTensor image,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  typename TTypes<float, 2>::Tensor grads_boxes) {\n    const int batch_size = image.dimension(0);\n    const int image_height = image.dimension(1);\n    const int image_width = image.dimension(2);\n\n    const int num_boxes = grads.dimension(0);\n    const int crop_height = grads.dimension(1);\n    const int crop_width = grads.dimension(2);\n    const int depth = grads.dimension(3);\n\n    grads_boxes.setZero();\n\n    for (int b = 0; b < num_boxes; ++b) {\n      const float y1 = boxes(b, 0);\n      const float x1 = boxes(b, 1);\n      const float y2 = boxes(b, 2);\n      const float x2 = boxes(b, 3);\n\n      const int32_t b_in = box_index(b);\n      if (!FastBoundsCheck(b_in, batch_size)) {\n        continue;\n      }\n\n      const float height_ratio =\n          (crop_height > 1)\n              ? static_cast<float>(image_height - 1) / (crop_height - 1)\n              : 0;\n      const float width_ratio =\n          (crop_width > 1)\n              ? static_cast<float>(image_width - 1) / (crop_width - 1)\n              : 0;\n\n      const float height_scale =\n          (crop_height > 1) ? (y2 - y1) * height_ratio : 0;\n      const float width_scale = (crop_width > 1) ? (x2 - x1) * width_ratio : 0;\n\n      for (int y = 0; y < crop_height; ++y) {\n        const float in_y = (crop_height > 1)\n                               ? y1 * (image_height - 1) + y * height_scale\n                               : 0.5 * (y1 + y2) * (image_height - 1);\n        if (in_y < 0 || in_y > image_height - 1) {\n          continue;\n        }\n        const int top_y_index = floorf(in_y);\n        const int bottom_y_index = ceilf(in_y);\n        const float y_lerp = in_y - top_y_index;\n\n        for (int x = 0; x < crop_width; ++x) {\n          const float in_x = (crop_width > 1)\n                                 ? x1 * (image_width - 1) + x * width_scale\n                                 : 0.5 * (x1 + x2) * (image_width - 1);\n          if (in_x < 0 || in_x > image_width - 1) {\n            continue;\n          }\n          const int left_x_index = floorf(in_x);\n          const int right_x_index = ceilf(in_x);\n          const float x_lerp = in_x - left_x_index;\n\n          for (int d = 0; d < depth; ++d) {\n            const float top_left(\n                static_cast<float>(image(b_in, top_y_index, left_x_index, d)));\n            const float top_right(\n                static_cast<float>(image(b_in, top_y_index, right_x_index, d)));\n            const float bottom_left(static_cast<float>(\n                image(b_in, bottom_y_index, left_x_index, d)));\n            const float bottom_right(static_cast<float>(\n                image(b_in, bottom_y_index, right_x_index, d)));\n            // Compute the image gradient.\n            float image_grad_y = (1 - x_lerp) * (bottom_left - top_left) +\n                                 x_lerp * (bottom_right - top_right);\n            float image_grad_x = (1 - y_lerp) * (top_right - top_left) +\n                                 y_lerp * (bottom_right - bottom_left);\n            // Modulate the image gradient with the incoming gradient.\n            const float top_grad = grads(b, y, x, d);\n            image_grad_y *= top_grad;\n            image_grad_x *= top_grad;\n            // dy1, dy2\n            if (crop_height > 1) {\n              grads_boxes(b, 0) +=\n                  image_grad_y * (image_height - 1 - y * height_ratio);\n              grads_boxes(b, 2) += image_grad_y * (y * height_ratio);\n            } else {\n              grads_boxes(b, 0) += image_grad_y * 0.5 * (image_height - 1);\n              grads_boxes(b, 2) += image_grad_y * 0.5 * (image_height - 1);\n            }\n            // dx1, dx2\n            if (crop_width > 1) {\n              grads_boxes(b, 1) +=\n                  image_grad_x * (image_width - 1 - x * width_ratio);\n              grads_boxes(b, 3) += image_grad_x * (x * width_ratio);\n            } else {\n              grads_boxes(b, 1) += image_grad_x * 0.5 * (image_width - 1);\n              grads_boxes(b, 3) += image_grad_x * 0.5 * (image_width - 1);\n            }\n          }\n        }\n      }\n    }\n    return true;\n  }\n};\n\n}  // namespace functor\n\n#define REGISTER_KERNEL(T)                                \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResize\")           \\\n                              .Device(DEVICE_CPU)         \\\n                              .TypeConstraint<T>(\"T\")     \\\n                              .HostMemory(\"crop_size\"),   \\\n                          CropAndResizeOp<CPUDevice, T>); \\\n                                                          \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradBoxes\")  \\\n                              .Device(DEVICE_CPU)         \\\n                              .TypeConstraint<T>(\"T\"),    \\\n                          CropAndResizeGradBoxesOp<CPUDevice, T>);\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#define REGISTER_KERNEL(T)                               \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradImage\") \\\n                              .Device(DEVICE_CPU)        \\\n                              .TypeConstraint<T>(\"T\")    \\\n                              .HostMemory(\"image_size\"), \\\n                          CropAndResizeGradImageOp<CPUDevice, T>);\n\nTF_CALL_half(REGISTER_KERNEL);\nTF_CALL_float(REGISTER_KERNEL);\nTF_CALL_double(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n// Forward declaration of the CheckValidBoxIndexHelper specialization for GPU.\nnamespace functor {\ntemplate <>\nvoid CheckValidBoxIndexHelper<GPUDevice>::operator()(\n    const GPUDevice& d, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, typename TTypes<bool, 0>::Tensor isvalid);\nextern template struct CheckValidBoxIndexHelper<GPUDevice>;\n}  // namespace functor\n\nnamespace {\n\n// Specialization of CheckValidBoxIndex for a GPUDevice.\ntemplate <>\ninline void RunIfBoxIndexIsValid<GPUDevice>(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done) {\n  const int num_boxes = box_index.dimension(0);\n  if (num_boxes == 0) {\n    compute();\n    done();\n    return;\n  }\n\n  Tensor isvalid_dev_tensor;\n  OP_REQUIRES_OK_ASYNC(\n      context,\n      context->allocate_temp(DataTypeToEnum<bool>::value, TensorShape({}),\n                             &isvalid_dev_tensor),\n      done);\n  typename TTypes<bool, 0>::Tensor isvalid_dev =\n      isvalid_dev_tensor.tensor<bool, 0>();\n\n  // Run the actual box check on the device.\n  functor::CheckValidBoxIndexHelper<GPUDevice>()(\n      context->eigen_device<GPUDevice>(), box_index, batch_size, isvalid_dev);\n\n  // Copy the result back to the host.\n  auto* stream = context->op_device_context()->stream();\n  OP_REQUIRES_ASYNC(context, stream,\n                    errors::Internal(\"No GPU stream available.\"), done);\n  Tensor isvalid_host_tensor;\n  // Use pinned host memory on the host to avoid unnecessary\n  // synchronization.\n  AllocatorAttributes alloc_attr;\n  alloc_attr.set_on_host(true);\n  alloc_attr.set_gpu_compatible(true);\n  OP_REQUIRES_OK_ASYNC(\n      context,\n      context->allocate_temp(DataTypeToEnum<bool>::value, TensorShape({}),\n                             &isvalid_host_tensor, alloc_attr),\n      done);\n  se::DeviceMemoryBase wrapped(isvalid_dev.data(), sizeof(bool));\n  const bool status =\n      stream\n          ->ThenMemcpy(\n              isvalid_host_tensor.scalar<bool>().data() /* destination */,\n              wrapped /* source */, sizeof(bool))\n          .ok();\n  OP_REQUIRES_ASYNC(\n      context, status,\n      errors::Internal(\"Failed to launch copy of isvalid from device to host.\"),\n      done);\n\n  // We capture both temporary tensors to prevent them from being deallocated\n  // when ComputeAsync returns and before the closure runs.\n  TensorReference isvalid_dev_ref(isvalid_dev_tensor);\n  auto wrapped_callback = [context, isvalid_host_tensor, isvalid_dev_ref,\n                           compute, done]() {\n    auto stream = context->op_device_context()->stream();\n    ScopedActivateExecutorContext scoped_activation{stream->parent()};\n    const bool isvalid = isvalid_host_tensor.scalar<bool>()();\n    isvalid_dev_ref.Unref();\n    OP_REQUIRES_ASYNC(\n        context, isvalid,\n        errors::OutOfRange(\"box_index has values outside [0, batch_size)\"),\n        done);\n    compute();\n    done();\n  };\n\n  context->device()->tensorflow_gpu_device_info()->event_mgr->ThenExecute(\n      stream, wrapped_callback);\n}\n\n}  // namespace\n\n#define REGISTER_KERNEL(T)                                         \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResize\")                    \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\")              \\\n                              .HostMemory(\"crop_size\"),            \\\n                          CropAndResizeOp<GPUDevice, T>);          \\\n                                                                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradImage\")           \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\")              \\\n                              .HostMemory(\"image_size\"),           \\\n                          CropAndResizeGradImageOp<GPUDevice, T>); \\\n                                                                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradBoxes\")           \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\"),             \\\n                          CropAndResizeGradBoxesOp<GPUDevice, T>);\n\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for tensorflow.ops.image_ops.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport colorsys\nimport contextlib\nimport functools\nimport itertools\nimport math\nimport os\nimport time\n\nfrom absl.testing import parameterized\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.compat import compat\nfrom tensorflow.python.data.experimental.ops import get_single_element\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import config as tf_config\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import gen_image_ops\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import image_ops_impl\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import random_ops\nfrom tensorflow.python.ops import stateless_random_ops\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import googletest\nfrom tensorflow.python.platform import test\n\n\nclass RGBToHSVTest(test_util.TensorFlowTestCase):\n\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to HSV and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_hsv(batch0)\n        batch2 = image_ops.hsv_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_hsv, split0))\n        split2 = list(map(image_ops.hsv_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1)\n      self.assertAllClose(batch2, join2)\n      self.assertAllClose(batch2, inp)\n\n  def testRGBToHSVRoundTrip(self):\n    data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    for nptype in [np.float32, np.float64]:\n      rgb_np = np.array(data, dtype=nptype).reshape([2, 2, 3]) / 255.\n      with self.cached_session():\n        hsv = image_ops.rgb_to_hsv(rgb_np)\n        rgb = image_ops.hsv_to_rgb(hsv)\n        rgb_tf = self.evaluate(rgb)\n      self.assertAllClose(rgb_tf, rgb_np)\n\n\nclass RGBToYIQTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_without_tensor_float_32(\n      \"Calls rgb_to_yiq and yiq_to_rgb, which use matmul\")\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to YIQ and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_yiq(batch0)\n        batch2 = image_ops.yiq_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_yiq, split0))\n        split2 = list(map(image_ops.yiq_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, join2, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, inp, rtol=1e-4, atol=1e-4)\n\n\nclass RGBToYUVTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_without_tensor_float_32(\n      \"Calls rgb_to_yuv and yuv_to_rgb, which use matmul\")\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to YUV and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_yuv(batch0)\n        batch2 = image_ops.yuv_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_yuv, split0))\n        split2 = list(map(image_ops.yuv_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, join2, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, inp, rtol=1e-4, atol=1e-4)\n\n\nclass GrayscaleToRGBTest(test_util.TensorFlowTestCase):\n\n  def _RGBToGrayscale(self, images):\n    is_batch = True\n    if len(images.shape) == 3:\n      is_batch = False\n      images = np.expand_dims(images, axis=0)\n    out_shape = images.shape[0:3] + (1,)\n    out = np.zeros(shape=out_shape, dtype=np.uint8)\n    for batch in xrange(images.shape[0]):\n      for y in xrange(images.shape[1]):\n        for x in xrange(images.shape[2]):\n          red = images[batch, y, x, 0]\n          green = images[batch, y, x, 1]\n          blue = images[batch, y, x, 2]\n          gray = 0.2989 * red + 0.5870 * green + 0.1140 * blue\n          out[batch, y, x, 0] = int(gray)\n    if not is_batch:\n      out = np.squeeze(out, axis=0)\n    return out\n\n  def _TestRGBToGrayscale(self, x_np):\n    y_np = self._RGBToGrayscale(x_np)\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.rgb_to_grayscale(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBasicRGBToGrayscale(self):\n    # 4-D input with batch dimension.\n    x_np = np.array(\n        [[1, 2, 3], [4, 10, 1]], dtype=np.uint8).reshape([1, 1, 2, 3])\n    self._TestRGBToGrayscale(x_np)\n\n    # 3-D input with no batch dimension.\n    x_np = np.array([[1, 2, 3], [4, 10, 1]], dtype=np.uint8).reshape([1, 2, 3])\n    self._TestRGBToGrayscale(x_np)\n\n  def testBasicGrayscaleToRGB(self):\n    # 4-D input with batch dimension.\n    x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 1, 2, 1])\n    y_np = np.array(\n        [[1, 1, 1], [2, 2, 2]], dtype=np.uint8).reshape([1, 1, 2, 3])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.grayscale_to_rgb(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n    # 3-D input with no batch dimension.\n    x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 2, 1])\n    y_np = np.array([[1, 1, 1], [2, 2, 2]], dtype=np.uint8).reshape([1, 2, 3])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.grayscale_to_rgb(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testGrayscaleToRGBInputValidation(self):\n    # tests whether the grayscale_to_rgb function raises\n    # an exception if the input images' last dimension is\n    # not of size 1, i.e. the images have shape\n    # [batch size, height, width] or [height, width]\n\n    # tests if an exception is raised if a three dimensional\n    # input is used, i.e. the images have shape [batch size, height, width]\n    with self.cached_session():\n      # 3-D input with batch dimension.\n      x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 1, 2])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # this is the error message we expect the function to raise\n      err_msg = \"Last dimension of a grayscale image should be size 1\"\n      with self.assertRaisesRegex(ValueError, err_msg):\n        image_ops.grayscale_to_rgb(x_tf)\n\n    # tests if an exception is raised if a two dimensional\n    # input is used, i.e. the images have shape [height, width]\n    with self.cached_session():\n      # 1-D input without batch dimension.\n      x_np = np.array([[1, 2]], dtype=np.uint8).reshape([2])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # this is the error message we expect the function to raise\n      err_msg = \"must be at least two-dimensional\"\n      with self.assertRaisesRegex(ValueError, err_msg):\n        image_ops.grayscale_to_rgb(x_tf)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Shape inference works and produces expected output where possible\n      rgb_shape = [7, None, 19, 3]\n      gray_shape = rgb_shape[:-1] + [1]\n      with self.cached_session():\n        rgb_tf = array_ops.placeholder(dtypes.uint8, shape=rgb_shape)\n        gray = image_ops.rgb_to_grayscale(rgb_tf)\n        self.assertEqual(gray_shape, gray.get_shape().as_list())\n\n      with self.cached_session():\n        gray_tf = array_ops.placeholder(dtypes.uint8, shape=gray_shape)\n        rgb = image_ops.grayscale_to_rgb(gray_tf)\n        self.assertEqual(rgb_shape, rgb.get_shape().as_list())\n\n      # Shape inference does not break for unknown shapes\n      with self.cached_session():\n        rgb_tf_unknown = array_ops.placeholder(dtypes.uint8)\n        gray_unknown = image_ops.rgb_to_grayscale(rgb_tf_unknown)\n        self.assertFalse(gray_unknown.get_shape())\n\n      with self.cached_session():\n        gray_tf_unknown = array_ops.placeholder(dtypes.uint8)\n        rgb_unknown = image_ops.grayscale_to_rgb(gray_tf_unknown)\n        self.assertFalse(rgb_unknown.get_shape())\n\n\nclass AdjustGamma(test_util.TensorFlowTestCase):\n\n  def test_adjust_gamma_less_zero_float32(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 1.0, (8, 8))\n      x_np = np.array(x_data, dtype=np.float32)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image_ops.adjust_gamma(x, gamma=-1)\n\n  def test_adjust_gamma_less_zero_uint8(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 255, (8, 8))\n      x_np = np.array(x_data, dtype=np.uint8)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image_ops.adjust_gamma(x, gamma=-1)\n\n  def test_adjust_gamma_less_zero_tensor(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 1.0, (8, 8))\n      x_np = np.array(x_data, dtype=np.float32)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = constant_op.constant(-1.0, dtype=dtypes.float32)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image = image_ops.adjust_gamma(x, gamma=y)\n        self.evaluate(image)\n\n  def _test_adjust_gamma_uint8(self, gamma):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for uint8 images\n    \"\"\"\n    with self.cached_session():\n      x_np = np.random.uniform(0, 255, (8, 8)).astype(np.uint8)\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_gamma(x, gamma=gamma)\n      y_tf = np.trunc(self.evaluate(y))\n\n      # calculate gamma correction using numpy\n      # firstly, transform uint8 to float representation\n      # then perform correction\n      y_np = np.power(x_np / 255.0, gamma)\n      # convert correct numpy image back to uint8 type\n      y_np = np.trunc(np.clip(y_np * 255.5, 0, 255.0))\n\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def _test_adjust_gamma_float32(self, gamma):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for float32 images\n    \"\"\"\n    with self.cached_session():\n      x_np = np.random.uniform(0, 1.0, (8, 8))\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_gamma(x, gamma=gamma)\n      y_tf = self.evaluate(y)\n\n      y_np = np.clip(np.power(x_np, gamma), 0, 1.0)\n\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def test_adjust_gamma_one_float32(self):\n    \"\"\"Same image should be returned for gamma equal to one\"\"\"\n    self._test_adjust_gamma_float32(1.0)\n\n  def test_adjust_gamma_one_uint8(self):\n    self._test_adjust_gamma_uint8(1.0)\n\n  def test_adjust_gamma_zero_uint8(self):\n    \"\"\"White image should be returned for gamma equal\n\n    to zero for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=0.0)\n\n  def test_adjust_gamma_less_one_uint8(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to half for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=0.5)\n\n  def test_adjust_gamma_greater_one_uint8(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=1.0)\n\n  def test_adjust_gamma_less_one_float32(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to half for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(0.5)\n\n  def test_adjust_gamma_greater_one_float32(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to two for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(1.0)\n\n  def test_adjust_gamma_zero_float32(self):\n    \"\"\"White image should be returned for gamma equal\n\n    to zero for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(0.0)\n\n\nclass AdjustHueTest(test_util.TensorFlowTestCase):\n\n  def testAdjustNegativeHue(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = -0.25\n    y_data = [0, 13, 1, 54, 226, 59, 8, 234, 150, 255, 39, 1]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testAdjustPositiveHue(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = 0.25\n    y_data = [13, 0, 11, 226, 54, 221, 234, 8, 92, 1, 217, 255]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBatchAdjustHue(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = 0.25\n    y_data = [13, 0, 11, 226, 54, 221, 234, 8, 92, 1, 217, 255]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def _adjustHueNp(self, x_np, delta_h):\n    self.assertEqual(x_np.shape[-1], 3)\n    x_v = x_np.reshape([-1, 3])\n    y_v = np.ndarray(x_v.shape, dtype=x_v.dtype)\n    channel_count = x_v.shape[0]\n    for i in xrange(channel_count):\n      r = x_v[i][0]\n      g = x_v[i][1]\n      b = x_v[i][2]\n      h, s, v = colorsys.rgb_to_hsv(r, g, b)\n      h += delta_h\n      h = math.fmod(h + 10.0, 1.0)\n      r, g, b = colorsys.hsv_to_rgb(h, s, v)\n      y_v[i][0] = r\n      y_v[i][1] = g\n      y_v[i][2] = b\n    return y_v.reshape(x_np.shape)\n\n  def _adjustHueTf(self, x_np, delta_h):\n    with self.cached_session():\n      x = constant_op.constant(x_np)\n      y = image_ops.adjust_hue(x, delta_h)\n      y_tf = self.evaluate(y)\n    return y_tf\n\n  def testAdjustRandomHue(self):\n    x_shapes = [\n        [2, 2, 3],\n        [4, 2, 3],\n        [2, 4, 3],\n        [2, 5, 3],\n        [1000, 1, 3],\n    ]\n    test_styles = [\n        \"all_random\",\n        \"rg_same\",\n        \"rb_same\",\n        \"gb_same\",\n        \"rgb_same\",\n    ]\n    for x_shape in x_shapes:\n      for test_style in test_styles:\n        x_np = np.random.rand(*x_shape) * 255.\n        delta_h = np.random.rand() * 2.0 - 1.0\n        if test_style == \"all_random\":\n          pass\n        elif test_style == \"rg_same\":\n          x_np[..., 1] = x_np[..., 0]\n        elif test_style == \"rb_same\":\n          x_np[..., 2] = x_np[..., 0]\n        elif test_style == \"gb_same\":\n          x_np[..., 2] = x_np[..., 1]\n        elif test_style == \"rgb_same\":\n          x_np[..., 1] = x_np[..., 0]\n          x_np[..., 2] = x_np[..., 0]\n        else:\n          raise AssertionError(\"Invalid test style: %s\" % (test_style))\n        y_np = self._adjustHueNp(x_np, delta_h)\n        y_tf = self._adjustHueTf(x_np, delta_h)\n        self.assertAllClose(y_tf, y_np, rtol=2e-5, atol=1e-5)\n\n  def testInvalidShapes(self):\n    fused = False\n    if not fused:\n      # The tests are known to pass with the fused adjust_hue. We will enable\n      # them when the fused implementation is the default.\n      return\n    x_np = np.random.rand(2, 3) * 255.\n    delta_h = np.random.rand() * 2.0 - 1.0\n    fused = False\n    with self.assertRaisesRegex(ValueError, \"Shape must be at least rank 3\"):\n      self._adjustHueTf(x_np, delta_h)\n    x_np = np.random.rand(4, 2, 4) * 255.\n    delta_h = np.random.rand() * 2.0 - 1.0\n    with self.assertRaisesOpError(\"input must have 3 channels\"):\n      self._adjustHueTf(x_np, delta_h)\n\n\nclass FlipImageBenchmark(test.Benchmark):\n\n  def _benchmarkFlipLeftRight(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkFlipLeftRight_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkFlipLeftRight_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def _benchmarkRandomFlipLeftRight(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.random_flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkRandomFlipLeftRight_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkRandomFlipLeftRight_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def _benchmarkBatchedRandomFlipLeftRight(self, device, cpu_count):\n    image_shape = [16, 299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.random_flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkBatchedRandomFlipLeftRight_16_299_299_3_%s step_time: \"\n          \"%.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkBatchedRandomFlipLeftRight_16_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkFlipLeftRightCpu1(self):\n    self._benchmarkFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkFlipLeftRightCpuAll(self):\n    self._benchmarkFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkFlipLeftRightGpu(self):\n    self._benchmarkFlipLeftRight(test.gpu_device_name(), None)\n\n  def benchmarkRandomFlipLeftRightCpu1(self):\n    self._benchmarkRandomFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkRandomFlipLeftRightCpuAll(self):\n    self._benchmarkRandomFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkRandomFlipLeftRightGpu(self):\n    self._benchmarkRandomFlipLeftRight(test.gpu_device_name(), None)\n\n  def benchmarkBatchedRandomFlipLeftRightCpu1(self):\n    self._benchmarkBatchedRandomFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkBatchedRandomFlipLeftRightCpuAll(self):\n    self._benchmarkBatchedRandomFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkBatchedRandomFlipLeftRightGpu(self):\n    self._benchmarkBatchedRandomFlipLeftRight(test.gpu_device_name(), None)\n\n\nclass AdjustHueBenchmark(test.Benchmark):\n\n  def _benchmarkAdjustHue(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with self.benchmark_session(config=config, device=device) as sess:\n      inputs = variables.Variable(\n          random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n          trainable=False,\n          dtype=dtypes.float32)\n      delta = constant_op.constant(0.1, dtype=dtypes.float32)\n      outputs = image_ops.adjust_hue(inputs, delta)\n      run_op = control_flow_ops.group(outputs)\n      self.evaluate(variables.global_variables_initializer())\n      for i in xrange(warmup_rounds + benchmark_rounds):\n        if i == warmup_rounds:\n          start = time.time()\n        self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkAdjustHue_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkAdjustHue_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkAdjustHueCpu1(self):\n    self._benchmarkAdjustHue(\"/cpu:0\", 1)\n\n  def benchmarkAdjustHueCpuAll(self):\n    self._benchmarkAdjustHue(\"/cpu:0\", None)\n\n  def benchmarkAdjustHueGpu(self):\n    self._benchmarkAdjustHue(test.gpu_device_name(), None)\n\n\nclass AdjustSaturationBenchmark(test.Benchmark):\n\n  def _benchmarkAdjustSaturation(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with self.benchmark_session(config=config, device=device) as sess:\n      inputs = variables.Variable(\n          random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n          trainable=False,\n          dtype=dtypes.float32)\n      delta = constant_op.constant(0.1, dtype=dtypes.float32)\n      outputs = image_ops.adjust_saturation(inputs, delta)\n      run_op = control_flow_ops.group(outputs)\n      self.evaluate(variables.global_variables_initializer())\n      for _ in xrange(warmup_rounds):\n        self.evaluate(run_op)\n      start = time.time()\n      for _ in xrange(benchmark_rounds):\n        self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkAdjustSaturation_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkAdjustSaturation_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkAdjustSaturationCpu1(self):\n    self._benchmarkAdjustSaturation(\"/cpu:0\", 1)\n\n  def benchmarkAdjustSaturationCpuAll(self):\n    self._benchmarkAdjustSaturation(\"/cpu:0\", None)\n\n  def benchmarkAdjustSaturationGpu(self):\n    self._benchmarkAdjustSaturation(test.gpu_device_name(), None)\n\n\nclass ResizeBilinearBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_bilinear(\n            img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          name=(\"resize_bilinear_%s_%s_%s\" % (image_size[0], image_size[1],\n                                              num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n\nclass ResizeBicubicBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_bicubic(\n            img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          min_iters=20,\n          name=(\"resize_bicubic_%s_%s_%s\" % (image_size[0], image_size[1],\n                                             num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n  def benchmarkSimilar4Channel(self):\n    self._benchmarkResize((183, 229), 4)\n\n  def benchmarkScaleUp4Channel(self):\n    self._benchmarkResize((141, 186), 4)\n\n  def benchmarkScaleDown4Channel(self):\n    self._benchmarkResize((749, 603), 4)\n\n\nclass ResizeAreaBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_area(img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          name=(\"resize_area_%s_%s_%s\" % (image_size[0], image_size[1],\n                                          num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n\nclass AdjustSaturationTest(test_util.TensorFlowTestCase):\n\n  def testHalfSaturation(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 0.5\n    y_data = [6, 9, 13, 140, 180, 226, 135, 121, 234, 172, 255, 128]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testTwiceSaturation(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 2.0\n    y_data = [0, 5, 13, 0, 106, 226, 30, 0, 234, 89, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBatchSaturation(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 0.5\n    y_data = [6, 9, 13, 140, 180, 226, 135, 121, 234, 172, 255, 128]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def _adjustSaturationNp(self, x_np, scale):\n    self.assertEqual(x_np.shape[-1], 3)\n    x_v = x_np.reshape([-1, 3])\n    y_v = np.ndarray(x_v.shape, dtype=x_v.dtype)\n    channel_count = x_v.shape[0]\n    for i in xrange(channel_count):\n      r = x_v[i][0]\n      g = x_v[i][1]\n      b = x_v[i][2]\n      h, s, v = colorsys.rgb_to_hsv(r, g, b)\n      s *= scale\n      s = min(1.0, max(0.0, s))\n      r, g, b = colorsys.hsv_to_rgb(h, s, v)\n      y_v[i][0] = r\n      y_v[i][1] = g\n      y_v[i][2] = b\n    return y_v.reshape(x_np.shape)\n\n  def testAdjustRandomSaturation(self):\n    x_shapes = [\n        [2, 2, 3],\n        [4, 2, 3],\n        [2, 4, 3],\n        [2, 5, 3],\n        [1000, 1, 3],\n    ]\n    test_styles = [\n        \"all_random\",\n        \"rg_same\",\n        \"rb_same\",\n        \"gb_same\",\n        \"rgb_same\",\n    ]\n    with self.cached_session():\n      for x_shape in x_shapes:\n        for test_style in test_styles:\n          x_np = np.random.rand(*x_shape) * 255.\n          scale = np.random.rand()\n          if test_style == \"all_random\":\n            pass\n          elif test_style == \"rg_same\":\n            x_np[..., 1] = x_np[..., 0]\n          elif test_style == \"rb_same\":\n            x_np[..., 2] = x_np[..., 0]\n          elif test_style == \"gb_same\":\n            x_np[..., 2] = x_np[..., 1]\n          elif test_style == \"rgb_same\":\n            x_np[..., 1] = x_np[..., 0]\n            x_np[..., 2] = x_np[..., 0]\n          else:\n            raise AssertionError(\"Invalid test style: %s\" % (test_style))\n          y_baseline = self._adjustSaturationNp(x_np, scale)\n          y_fused = self.evaluate(image_ops.adjust_saturation(x_np, scale))\n          self.assertAllClose(y_fused, y_baseline, rtol=2e-5, atol=1e-5)\n\n\nclass FlipTransposeRotateTest(test_util.TensorFlowTestCase,\n                              parameterized.TestCase):\n\n  def testInvolutionLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(image_ops.flip_left_right(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionLeftRightWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(image_ops.flip_left_right(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testLeftRightWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    y_np = np.array(\n        [[[3, 2, 1], [3, 2, 1]], [[3, 2, 1], [3, 2, 1]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testRandomFlipLeftRightStateful(self):\n    # Test random flip with single seed (stateful).\n    with ops.Graph().as_default():\n      x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n      seed = 42\n\n      with self.cached_session():\n        x_tf = constant_op.constant(x_np, shape=x_np.shape)\n        y = image_ops.random_flip_left_right(x_tf, seed=seed)\n        self.assertTrue(y.op.name.startswith(\"random_flip_left_right\"))\n\n        count_flipped = 0\n        count_unflipped = 0\n        for _ in range(100):\n          y_tf = self.evaluate(y)\n          if y_tf[0][0] == 1:\n            self.assertAllEqual(y_tf, x_np)\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf, y_np)\n            count_flipped += 1\n\n        # 100 trials\n        # Mean: 50\n        # Std Dev: ~5\n        # Six Sigma: 50 - (5 * 6) = 20\n        self.assertGreaterEqual(count_flipped, 20)\n        self.assertGreaterEqual(count_unflipped, 20)\n\n  def testRandomFlipLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_left_right(x_tf, seed=seed))\n        if y_tf[0][0] == 1:\n          self.assertAllEqual(y_tf, x_np)\n          count_unflipped += 1\n        else:\n          self.assertAllEqual(y_tf, y_np)\n          count_flipped += 1\n\n      self.assertEqual(count_flipped, 45)\n      self.assertEqual(count_unflipped, 55)\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  @parameterized.named_parameters(\n      (\"_RandomFlipLeftRight\", image_ops.stateless_random_flip_left_right),\n      (\"_RandomFlipUpDown\", image_ops.stateless_random_flip_up_down),\n  )\n  def testRandomFlipStateless(self, func):\n    with test_util.use_gpu():\n      x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[3, 2, 1], [6, 5, 4]], dtype=np.uint8).reshape([2, 3, 1])\n      if \"RandomFlipUpDown\" in self.id():\n        y_np = np.array(\n            [[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      iterations = 2\n      flip_counts = [None for _ in range(iterations)]\n      flip_sequences = [\"\" for _ in range(iterations)]\n      test_seed = (1, 2)\n      split_seeds = stateless_random_ops.split(test_seed, 10)\n      seeds_list = self.evaluate(split_seeds)\n      for i in range(iterations):\n        count_flipped = 0\n        count_unflipped = 0\n        flip_seq = \"\"\n        for seed in seeds_list:\n          y_tf = func(x_tf, seed=seed)\n          y_tf_eval = self.evaluate(y_tf)\n          if y_tf_eval[0][0] == 1:\n            self.assertAllEqual(y_tf_eval, x_np)\n            count_unflipped += 1\n            flip_seq += \"U\"\n          else:\n            self.assertAllEqual(y_tf_eval, y_np)\n            count_flipped += 1\n            flip_seq += \"F\"\n\n        flip_counts[i] = (count_flipped, count_unflipped)\n        flip_sequences[i] = flip_seq\n\n      # Verify that results are deterministic.\n      for i in range(1, iterations):\n        self.assertAllEqual(flip_counts[0], flip_counts[i])\n        self.assertAllEqual(flip_sequences[0], flip_sequences[i])\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  @parameterized.named_parameters(\n      (\"_RandomFlipLeftRight\", image_ops.stateless_random_flip_left_right),\n      (\"_RandomFlipUpDown\", image_ops.stateless_random_flip_up_down)\n  )\n  def testRandomFlipStatelessWithBatch(self, func):\n    with test_util.use_gpu():\n      batch_size = 16\n\n      # create single item of test data\n      x_np_raw = np.array(\n          [[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([1, 2, 3, 1])\n      y_np_raw = np.array(\n          [[3, 2, 1], [6, 5, 4]], dtype=np.uint8).reshape([1, 2, 3, 1])\n      if \"RandomFlipUpDown\" in self.id():\n        y_np_raw = np.array(\n            [[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([1, 2, 3, 1])\n\n      # create batched test data\n      x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n      y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      iterations = 2\n      flip_counts = [None for _ in range(iterations)]\n      flip_sequences = [\"\" for _ in range(iterations)]\n      test_seed = (1, 2)\n      split_seeds = stateless_random_ops.split(test_seed, 10)\n      seeds_list = self.evaluate(split_seeds)\n      for i in range(iterations):\n        count_flipped = 0\n        count_unflipped = 0\n        flip_seq = \"\"\n        for seed in seeds_list:\n          y_tf = func(x_tf, seed=seed)\n          y_tf_eval = self.evaluate(y_tf)\n          for j in range(batch_size):\n            if y_tf_eval[j][0][0] == 1:\n              self.assertAllEqual(y_tf_eval[j], x_np[j])\n              count_unflipped += 1\n              flip_seq += \"U\"\n            else:\n              self.assertAllEqual(y_tf_eval[j], y_np[j])\n              count_flipped += 1\n              flip_seq += \"F\"\n\n        flip_counts[i] = (count_flipped, count_unflipped)\n        flip_sequences[i] = flip_seq\n\n      for i in range(1, iterations):\n        self.assertAllEqual(flip_counts[0], flip_counts[i])\n        self.assertAllEqual(flip_sequences[0], flip_sequences[i])\n\n  def testRandomFlipLeftRightWithBatch(self):\n    batch_size = 16\n    seed = 42\n\n    # create single item of test data\n    x_np_raw = np.array(\n        [[1, 2, 3], [1, 2, 3]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n    y_np_raw = np.array(\n        [[3, 2, 1], [3, 2, 1]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n\n    # create batched test data\n    x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n    y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_left_right(x_tf, seed=seed))\n\n        # check every element of the batch\n        for i in range(batch_size):\n          if y_tf[i][0][0] == 1:\n            self.assertAllEqual(y_tf[i], x_np[i])\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf[i], y_np[i])\n            count_flipped += 1\n\n      self.assertEqual(count_flipped, 772)\n      self.assertEqual(count_unflipped, 828)\n\n  def testInvolutionUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(image_ops.flip_up_down(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionUpDownWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(image_ops.flip_up_down(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testUpDownWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    y_np = np.array(\n        [[[4, 5, 6], [1, 2, 3]], [[10, 11, 12], [7, 8, 9]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testRandomFlipUpDownStateful(self):\n    # Test random flip with single seed (stateful).\n    with ops.Graph().as_default():\n      x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n      seed = 42\n\n      with self.cached_session():\n        x_tf = constant_op.constant(x_np, shape=x_np.shape)\n        y = image_ops.random_flip_up_down(x_tf, seed=seed)\n        self.assertTrue(y.op.name.startswith(\"random_flip_up_down\"))\n        count_flipped = 0\n        count_unflipped = 0\n        for _ in range(100):\n          y_tf = self.evaluate(y)\n          if y_tf[0][0] == 1:\n            self.assertAllEqual(y_tf, x_np)\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf, y_np)\n            count_flipped += 1\n\n        # 100 trials\n        # Mean: 50\n        # Std Dev: ~5\n        # Six Sigma: 50 - (5 * 6) = 20\n        self.assertGreaterEqual(count_flipped, 20)\n        self.assertGreaterEqual(count_unflipped, 20)\n\n  def testRandomFlipUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_up_down(x_tf, seed=seed))\n        if y_tf[0][0] == 1:\n          self.assertAllEqual(y_tf, x_np)\n          count_unflipped += 1\n        else:\n          self.assertAllEqual(y_tf, y_np)\n          count_flipped += 1\n\n      self.assertEqual(count_flipped, 45)\n      self.assertEqual(count_unflipped, 55)\n\n  def testRandomFlipUpDownWithBatch(self):\n    batch_size = 16\n    seed = 42\n\n    # create single item of test data\n    x_np_raw = np.array(\n        [[1, 2, 3], [4, 5, 6]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n    y_np_raw = np.array(\n        [[4, 5, 6], [1, 2, 3]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n\n    # create batched test data\n    x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n    y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_up_down(x_tf, seed=seed))\n\n        # check every element of the batch\n        for i in range(batch_size):\n          if y_tf[i][0][0] == 1:\n            self.assertAllEqual(y_tf[i], x_np[i])\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf[i], y_np[i])\n            count_flipped += 1\n\n      self.assertEqual(count_flipped, 772)\n      self.assertEqual(count_unflipped, 828)\n\n  def testInvolutionTranspose(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(image_ops.transpose(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionTransposeWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(image_ops.transpose(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testTranspose(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[1, 4], [2, 5], [3, 6]], dtype=np.uint8).reshape([3, 2, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testTransposeWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    y_np = np.array(\n        [[[1, 4], [2, 5], [3, 6]], [[7, 10], [8, 11], [9, 12]]],\n        dtype=np.uint8).reshape([2, 3, 2, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testPartialShapes(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      p_unknown_rank = array_ops.placeholder(dtypes.uint8)\n      p_unknown_dims_3 = array_ops.placeholder(\n          dtypes.uint8, shape=[None, None, None])\n      p_unknown_dims_4 = array_ops.placeholder(\n          dtypes.uint8, shape=[None, None, None, None])\n      p_unknown_width = array_ops.placeholder(dtypes.uint8, shape=[64, None, 3])\n      p_unknown_batch = array_ops.placeholder(\n          dtypes.uint8, shape=[None, 64, 64, 3])\n      p_wrong_rank = array_ops.placeholder(dtypes.uint8, shape=[None, None])\n      p_zero_dim = array_ops.placeholder(dtypes.uint8, shape=[64, 0, 3])\n\n      #Ops that support 3D input\n      for op in [\n          image_ops.flip_left_right, image_ops.flip_up_down,\n          image_ops.random_flip_left_right, image_ops.random_flip_up_down,\n          image_ops.transpose, image_ops.rot90\n      ]:\n        transformed_unknown_rank = op(p_unknown_rank)\n        self.assertIsNone(transformed_unknown_rank.get_shape().ndims)\n        transformed_unknown_dims_3 = op(p_unknown_dims_3)\n        self.assertEqual(3, transformed_unknown_dims_3.get_shape().ndims)\n        transformed_unknown_width = op(p_unknown_width)\n        self.assertEqual(3, transformed_unknown_width.get_shape().ndims)\n\n        with self.assertRaisesRegex(ValueError, \"must be > 0\"):\n          op(p_zero_dim)\n\n      #Ops that support 4D input\n      for op in [\n          image_ops.flip_left_right, image_ops.flip_up_down,\n          image_ops.random_flip_left_right, image_ops.random_flip_up_down,\n          image_ops.transpose, image_ops.rot90\n      ]:\n        transformed_unknown_dims_4 = op(p_unknown_dims_4)\n        self.assertEqual(4, transformed_unknown_dims_4.get_shape().ndims)\n        transformed_unknown_batch = op(p_unknown_batch)\n        self.assertEqual(4, transformed_unknown_batch.get_shape().ndims)\n        with self.assertRaisesRegex(ValueError,\n                                    \"must be at least three-dimensional\"):\n          op(p_wrong_rank)\n\n  def testRot90GroupOrder(self):\n    image = np.arange(24, dtype=np.uint8).reshape([2, 4, 3])\n    with self.cached_session():\n      rotated = image\n      for _ in xrange(4):\n        rotated = image_ops.rot90(rotated)\n      self.assertAllEqual(image, self.evaluate(rotated))\n\n  def testRot90GroupOrderWithBatch(self):\n    image = np.arange(48, dtype=np.uint8).reshape([2, 2, 4, 3])\n    with self.cached_session():\n      rotated = image\n      for _ in xrange(4):\n        rotated = image_ops.rot90(rotated)\n      self.assertAllEqual(image, self.evaluate(rotated))\n\n  def testRot90NumpyEquivalence(self):\n    image = np.arange(24, dtype=np.uint8).reshape([2, 4, 3])\n    with self.cached_session():\n      for k in xrange(4):\n        y_np = np.rot90(image, k=k)\n        self.assertAllEqual(\n            y_np, self.evaluate(image_ops.rot90(image, k)))\n\n  def testRot90NumpyEquivalenceWithBatch(self):\n    image = np.arange(48, dtype=np.uint8).reshape([2, 2, 4, 3])\n    with self.cached_session():\n      for k in xrange(4):\n        y_np = np.rot90(image, k=k, axes=(1, 2))\n        self.assertAllEqual(\n            y_np, self.evaluate(image_ops.rot90(image, k)))\n\n  def testFlipImageUnknownShape(self):\n    expected_output = constant_op.constant([[[[3, 4, 5], [0, 1, 2]],\n                                             [[9, 10, 11], [6, 7, 8]]]])\n\n    def generator():\n      image_input = np.array(\n          [[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]], np.int32)\n      yield image_input\n\n    dataset = dataset_ops.Dataset.from_generator(\n        generator,\n        output_types=dtypes.int32,\n        output_shapes=tensor_shape.TensorShape([1, 2, 2, 3]))\n    dataset = dataset.map(image_ops.flip_left_right)\n\n    image_flipped_via_dataset_map = get_single_element.get_single_element(\n        dataset.take(1))\n    self.assertAllEqual(image_flipped_via_dataset_map, expected_output)\n\n\nclass AdjustContrastTest(test_util.TensorFlowTestCase):\n\n  def _testContrast(self, x_np, y_np, contrast_factor):\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_contrast(x, contrast_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def testDoubleContrastUint8(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 0, 62, 169, 255, 28, 0, 255, 135, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def testDoubleContrastFloat(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float64).reshape(x_shape) / 255.\n\n    y_data = [\n        -45.25, -90.75, -92.5, 62.75, 169.25, 333.5, 28.75, -84.75, 349.5,\n        134.75, 409.25, -116.5\n    ]\n    y_np = np.array(y_data, dtype=np.float64).reshape(x_shape) / 255.\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def testHalfContrastUint8(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [22, 52, 65, 49, 118, 172, 41, 54, 176, 67, 178, 59]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=0.5)\n\n  def testBatchDoubleContrast(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 0, 81, 200, 255, 10, 0, 255, 116, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def _adjustContrastNp(self, x_np, contrast_factor):\n    mean = np.mean(x_np, (1, 2), keepdims=True)\n    y_np = mean + contrast_factor * (x_np - mean)\n    return y_np\n\n  def _adjustContrastTf(self, x_np, contrast_factor):\n    with self.cached_session():\n      x = constant_op.constant(x_np)\n      y = image_ops.adjust_contrast(x, contrast_factor)\n      y_tf = self.evaluate(y)\n    return y_tf\n\n  def testRandomContrast(self):\n    x_shapes = [\n        [1, 2, 2, 3],\n        [2, 1, 2, 3],\n        [1, 2, 2, 3],\n        [2, 5, 5, 3],\n        [2, 1, 1, 3],\n    ]\n    for x_shape in x_shapes:\n      x_np = np.random.rand(*x_shape) * 255.\n      contrast_factor = np.random.rand() * 2.0 + 0.1\n      y_np = self._adjustContrastNp(x_np, contrast_factor)\n      y_tf = self._adjustContrastTf(x_np, contrast_factor)\n      self.assertAllClose(y_tf, y_np, rtol=1e-5, atol=1e-5)\n\n  def testContrastFactorShape(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"contrast_factor must be scalar|\"\n                                \"Shape must be rank 0 but is rank 1\"):\n      image_ops.adjust_contrast(x_np, [2.0])\n\n  @test_util.run_all_in_graph_and_eager_modes\n  def testDeterminismUnimplementedExceptionThrowing(self):\n    \"\"\"Test d9m-unimplemented exception-throwing when op-determinism is enabled.\n\n    This test depends upon other tests, tests which do not enable\n    op-determinism, to ensure that determinism-unimplemented exceptions are not\n    erroneously thrown when op-determinism is not enabled.\n    \"\"\"\n    if test_util.is_xla_enabled():\n      self.skipTest('XLA implementation does not raise exception')\n    with self.session(), test_util.deterministic_ops():\n      input_shape = (1, 2, 2, 1)\n      on_gpu = len(tf_config.list_physical_devices(\"GPU\"))\n      # AdjustContrast seems to now be inaccessible via the Python API.\n      # AdjustContrastv2 only supports float16 and float32 on GPU, and other\n      # types are converted to and from float32 at the Python level before\n      # AdjustContrastv2 is called.\n      dtypes_to_test = [\n          dtypes.uint8, dtypes.int8, dtypes.int16, dtypes.int32, dtypes.float32,\n          dtypes.float64\n      ]\n      if on_gpu:\n        dtypes_to_test.append(dtypes.float16)\n        ctx_mgr = self.assertRaisesRegex(\n            errors.UnimplementedError,\n            \"A deterministic GPU implementation of AdjustContrastv2 is not\" +\n            \" currently available.\")\n      else:\n        ctx_mgr = contextlib.suppress()\n      for dtype in dtypes_to_test:\n        input_images = array_ops.zeros(input_shape, dtype=dtype)\n        contrast_factor = 1.\n        with ctx_mgr:\n          output_images = image_ops.adjust_contrast(input_images,\n                                                    contrast_factor)\n          self.evaluate(output_images)\n\n\nclass AdjustBrightnessTest(test_util.TensorFlowTestCase):\n\n  def _testBrightness(self, x_np, y_np, delta, tol=1e-6):\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_brightness(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, tol)\n\n  def testPositiveDeltaUint8(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 255, 11]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testBrightness(x_np, y_np, delta=10. / 255.)\n\n  def testPositiveDeltaFloat32(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float32).reshape(x_shape) / 255.\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 265, 11]\n    y_np = np.array(y_data, dtype=np.float32).reshape(x_shape) / 255.\n\n    self._testBrightness(x_np, y_np, delta=10. / 255.)\n\n  def testPositiveDeltaFloat16(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float16).reshape(x_shape) / 255.\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 265, 11]\n    y_np = np.array(y_data, dtype=np.float16).reshape(x_shape) / 255.\n\n    self._testBrightness(x_np, y_np, delta=10. / 255., tol=1e-3)\n\n  def testNegativeDelta(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 3, 44, 125, 216, 27, 0, 224, 80, 245, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testBrightness(x_np, y_np, delta=-10. / 255.)\n\n\nclass PerImageWhiteningTest(test_util.TensorFlowTestCase,\n                            parameterized.TestCase):\n\n  def _NumpyPerImageWhitening(self, x):\n    num_pixels = np.prod(x.shape)\n    mn = np.mean(x)\n    std = np.std(x)\n    stddev = max(std, 1.0 / math.sqrt(num_pixels))\n\n    y = x.astype(np.float32)\n    y -= mn\n    y /= stddev\n    return y\n\n  @parameterized.named_parameters([(\"_int8\", np.int8), (\"_int16\", np.int16),\n                                   (\"_int32\", np.int32), (\"_int64\", np.int64),\n                                   (\"_uint8\", np.uint8), (\"_uint16\", np.uint16),\n                                   (\"_uint32\", np.uint32),\n                                   (\"_uint64\", np.uint64),\n                                   (\"_float32\", np.float32)])\n  def testBasic(self, data_type):\n    x_shape = [13, 9, 3]\n    x_np = np.arange(0, np.prod(x_shape), dtype=data_type).reshape(x_shape)\n    y_np = self._NumpyPerImageWhitening(x_np)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, dtype=data_type, shape=x_shape)\n      y = image_ops.per_image_standardization(x)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, atol=1e-4)\n\n  def testUniformImage(self):\n    im_np = np.ones([19, 19, 3]).astype(np.float32) * 249\n    im = constant_op.constant(im_np)\n    whiten = image_ops.per_image_standardization(im)\n    with self.cached_session():\n      whiten_np = self.evaluate(whiten)\n      self.assertFalse(np.any(np.isnan(whiten_np)))\n\n  def testBatchWhitening(self):\n    imgs_np = np.random.uniform(0., 255., [4, 24, 24, 3])\n    whiten_np = [self._NumpyPerImageWhitening(img) for img in imgs_np]\n    with self.cached_session():\n      imgs = constant_op.constant(imgs_np)\n      whiten = image_ops.per_image_standardization(imgs)\n      whiten_tf = self.evaluate(whiten)\n      for w_tf, w_np in zip(whiten_tf, whiten_np):\n        self.assertAllClose(w_tf, w_np, atol=1e-4)\n\n\nclass CropToBoundingBoxTest(test_util.TensorFlowTestCase):\n\n  def _CropToBoundingBox(self, x, offset_height, offset_width, target_height,\n                         target_width, use_tensor_inputs):\n    if use_tensor_inputs:\n      offset_height = ops.convert_to_tensor(offset_height)\n      offset_width = ops.convert_to_tensor(offset_width)\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    y = image_ops.crop_to_bounding_box(x_tensor, offset_height, offset_width,\n                                       target_height, target_width)\n\n    with self.cached_session():\n      return self.evaluate(y)\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     offset_height,\n                     offset_width,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._CropToBoundingBox(x, offset_height, offset_width,\n                                     target_height, target_width,\n                                     use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    offset_height,\n                    offset_width,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._CropToBoundingBox(x, offset_height, offset_width, target_height,\n                                target_width, use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.crop_to_bounding_box(image, 0, 0, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n    self._assertReturns(x, x_shape, 0, 0, x, x_shape)\n\n  def testCrop(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    offset_height, offset_width = [1, 0]\n    y_shape = [2, 3, 1]\n    y = [4, 5, 6, 7, 8, 9]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 1]\n    y_shape = [3, 2, 1]\n    y = [2, 3, 5, 6, 8, 9]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y_shape = [2, 3, 1]\n    y = [1, 2, 3, 4, 5, 6]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y_shape = [3, 2, 1]\n    y = [1, 2, 4, 5, 7, 8]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    offset_height, offset_width = [0, 0]\n    target_height, target_width = [2, 2]\n\n    for x_shape in ([3, 5], [1, 3, 5, 1, 1]):\n      self._assertRaises(x, x_shape, offset_height, offset_width, target_height,\n                         target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    # Each line is a test configuration:\n    #   x_shape, target_height, target_width\n    test_config = (([0, 2, 2], 1, 1), ([2, 0, 2], 1, 1), ([2, 2, 0], 1, 1),\n                   ([0, 2, 2], 0, 1), ([2, 0, 2], 1, 0))\n    offset_height, offset_width = [0, 0]\n    x = []\n\n    for x_shape, target_height, target_width in test_config:\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n      # Multiple assertion could fail, but the evaluation order is arbitrary.\n      # Match gainst generic pattern.\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParams(self):\n    x_shape = [4, 4, 1]\n    x = np.zeros(x_shape)\n\n    # Each line is a test configuration:\n    #   (offset_height, offset_width, target_height, target_width), err_msg\n    test_config = (\n        ([-1, 0, 3, 3], \"offset_height must be >= 0\"),\n        ([0, -1, 3, 3], \"offset_width must be >= 0\"),\n        ([0, 0, 0, 3], \"target_height must be > 0\"),\n        ([0, 0, 3, 0], \"target_width must be > 0\"),\n        ([2, 0, 3, 3], r\"height must be >= target \\+ offset\"),\n        ([0, 2, 3, 3], r\"width must be >= target \\+ offset\"))\n\n    for params, err_msg in test_config:\n      self._assertRaises(x, x_shape, *params, err_msg=err_msg)\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[55, 66, 3])\n      y = image_ops.crop_to_bounding_box(image, 0, 0, 55, 66)\n      self.assertTrue(y.name.startswith(\"crop_to_bounding_box\"))\n\n\nclass CentralCropTest(test_util.TensorFlowTestCase):\n\n  def _assertShapeInference(self, pre_shape, fraction, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.central_crop(image, fraction)\n    if post_shape is None:\n      self.assertEqual(y.get_shape().dims, None)\n    else:\n      self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shapes = [[13, 9, 3], [5, 13, 9, 3]]\n    for x_shape in x_shapes:\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          x = constant_op.constant(x_np, shape=x_shape)\n          y = image_ops.central_crop(x, 1.0)\n          y_tf = self.evaluate(y)\n          self.assertAllEqual(y_tf, x_np)\n\n  def testCropping(self):\n    x_shape = [4, 8, 1]\n    x_np = np.array(\n        [[1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8]],\n        dtype=np.int32).reshape(x_shape)\n    y_np = np.array([[3, 4, 5, 6], [3, 4, 5, 6]]).reshape([2, 4, 1])\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        x = constant_op.constant(x_np, shape=x_shape)\n        y = image_ops.central_crop(x, 0.5)\n        y_tf = self.evaluate(y)\n        self.assertAllEqual(y_tf, y_np)\n        self.assertAllEqual(y_tf.shape, y_np.shape)\n\n    x_shape = [2, 4, 8, 1]\n    x_np = np.array(\n        [[1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [8, 7, 6, 5, 4, 3, 2, 1], [8, 7, 6, 5, 4, 3, 2, 1],\n         [8, 7, 6, 5, 4, 3, 2, 1], [8, 7, 6, 5, 4, 3, 2, 1]],\n        dtype=np.int32).reshape(x_shape)\n    y_np = np.array([[[3, 4, 5, 6], [3, 4, 5, 6]],\n                     [[6, 5, 4, 3], [6, 5, 4, 3]]]).reshape([2, 2, 4, 1])\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.central_crop(x, 0.5)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n      self.assertAllEqual(y_tf.shape, y_np.shape)\n\n  def testCropping2(self):\n    # Test case for 10315\n    x_shapes = [[240, 320, 3], [5, 240, 320, 3]]\n    expected_y_shapes = [[80, 106, 3], [5, 80, 106, 3]]\n\n    for x_shape, y_shape in zip(x_shapes, expected_y_shapes):\n      x_np = np.zeros(x_shape, dtype=np.int32)\n      y_np = np.zeros(y_shape, dtype=np.int32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          y_tf = self.evaluate(image_ops.central_crop(x_np, 0.33))\n          self.assertAllEqual(y_tf, y_np)\n          self.assertAllEqual(y_tf.shape, y_np.shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test no-op fraction=1.0, with 3-D tensors.\n      self._assertShapeInference([50, 60, 3], 1.0, [50, 60, 3])\n      self._assertShapeInference([None, 60, 3], 1.0, [None, 60, 3])\n      self._assertShapeInference([50, None, 3], 1.0, [50, None, 3])\n      self._assertShapeInference([None, None, 3], 1.0, [None, None, 3])\n      self._assertShapeInference([50, 60, None], 1.0, [50, 60, None])\n      self._assertShapeInference([None, None, None], 1.0, [None, None, None])\n\n      # Test no-op fraction=0.5, with 3-D tensors.\n      self._assertShapeInference([50, 60, 3], 0.5, [26, 30, 3])\n      self._assertShapeInference([None, 60, 3], 0.5, [None, 30, 3])\n      self._assertShapeInference([50, None, 3], 0.5, [26, None, 3])\n      self._assertShapeInference([None, None, 3], 0.5, [None, None, 3])\n      self._assertShapeInference([50, 60, None], 0.5, [26, 30, None])\n      self._assertShapeInference([None, None, None], 0.5, [None, None, None])\n\n      # Test no-op fraction=1.0, with 4-D tensors.\n      self._assertShapeInference([5, 50, 60, 3], 1.0, [5, 50, 60, 3])\n      self._assertShapeInference([5, None, 60, 3], 1.0, [5, None, 60, 3])\n      self._assertShapeInference([5, 50, None, 3], 1.0, [5, 50, None, 3])\n      self._assertShapeInference([5, None, None, 3], 1.0, [5, None, None, 3])\n      self._assertShapeInference([5, 50, 60, None], 1.0, [5, 50, 60, None])\n      self._assertShapeInference([5, None, None, None], 1.0,\n                                 [5, None, None, None])\n      self._assertShapeInference([None, None, None, None], 1.0,\n                                 [None, None, None, None])\n\n      # Test no-op fraction=0.5, with 4-D tensors.\n      self._assertShapeInference([5, 50, 60, 3], 0.5, [5, 26, 30, 3])\n      self._assertShapeInference([5, None, 60, 3], 0.5, [5, None, 30, 3])\n      self._assertShapeInference([5, 50, None, 3], 0.5, [5, 26, None, 3])\n      self._assertShapeInference([5, None, None, 3], 0.5, [5, None, None, 3])\n      self._assertShapeInference([5, 50, 60, None], 0.5, [5, 26, 30, None])\n      self._assertShapeInference([5, None, None, None], 0.5,\n                                 [5, None, None, None])\n      self._assertShapeInference([None, None, None, None], 0.5,\n                                 [None, None, None, None])\n\n  def testErrorOnInvalidCentralCropFractionValues(self):\n    x_shape = [13, 9, 3]\n    x_np = np.ones(x_shape, dtype=np.float32)\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        x = constant_op.constant(x_np, shape=x_shape)\n        with self.assertRaises(ValueError):\n          _ = image_ops.central_crop(x, 0.0)\n        with self.assertRaises(ValueError):\n          _ = image_ops.central_crop(x, 1.01)\n\n  def testErrorOnInvalidShapes(self):\n    x_shapes = [None, [], [3], [3, 9], [3, 9, 3, 9, 3]]\n    for x_shape in x_shapes:\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          x = constant_op.constant(x_np, shape=x_shape)\n          with self.assertRaises(ValueError):\n            _ = image_ops.central_crop(x, 0.5)\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      x_shape = [13, 9, 3]\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          y = image_ops.central_crop(x_np, 1.0)\n          self.assertTrue(y.op.name.startswith(\"central_crop\"))\n\n  def testCentralFractionTensor(self):\n    # Test case for GitHub issue 45324.\n    x_shape = [240, 320, 3]\n    y_shape = [80, 106, 3]\n\n    @def_function.function(autograph=False)\n    def f(x, central_fraction):\n      return image_ops.central_crop(x, central_fraction)\n\n    x_np = np.zeros(x_shape, dtype=np.int32)\n    y_np = np.zeros(y_shape, dtype=np.int32)\n    y_tf = self.evaluate(f(x_np, constant_op.constant(0.33)))\n    self.assertAllEqual(y_tf, y_np)\n    self.assertAllEqual(y_tf.shape, y_np.shape)\n\n\nclass PadToBoundingBoxTest(test_util.TensorFlowTestCase,\n                           parameterized.TestCase):\n\n  def _PadToBoundingBox(self, x, offset_height, offset_width, target_height,\n                        target_width, use_tensor_inputs):\n    if use_tensor_inputs:\n      offset_height = ops.convert_to_tensor(offset_height)\n      offset_width = ops.convert_to_tensor(offset_width)\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    @def_function.function\n    def pad_bbox(*args):\n      return image_ops.pad_to_bounding_box(*args)\n\n    with self.cached_session():\n      return self.evaluate(pad_bbox(x_tensor, offset_height, offset_width,\n                                    target_height, target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     offset_height,\n                     offset_width,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._PadToBoundingBox(x, offset_height, offset_width,\n                                    target_height, target_width,\n                                    use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    offset_height,\n                    offset_width,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._PadToBoundingBox(x, offset_height, offset_width, target_height,\n                               target_width, use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.pad_to_bounding_box(image, 0, 0, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testInt64(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    y = [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y_shape = [4, 3, 1]\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    i = constant_op.constant([1, 0, 4, 3], dtype=dtypes.int64)\n    y_tf = image_ops.pad_to_bounding_box(x, i[0], i[1], i[2], i[3])\n    with self.cached_session():\n      self.assertAllClose(y, self.evaluate(y_tf))\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n    offset_height, offset_width = [0, 0]\n    self._assertReturns(x, x_shape, offset_height, offset_width, x, x_shape)\n\n  def testPadding(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    offset_height, offset_width = [1, 0]\n    y = [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y_shape = [4, 3, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 1]\n    y = [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]\n    y_shape = [3, 4, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0]\n    y_shape = [4, 3, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y = [1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0]\n    y_shape = [3, 4, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    offset_height, offset_width = [0, 0]\n    target_height, target_width = [2, 2]\n\n    for x_shape in ([3, 5], [1, 3, 5, 1, 1]):\n      self._assertRaises(x, x_shape, offset_height, offset_width, target_height,\n                         target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    # Each line is a test configuration:\n    #   x_shape, target_height, target_width\n    test_config = (([0, 2, 2], 2, 2), ([2, 0, 2], 2, 2), ([2, 2, 0], 2, 2))\n    offset_height, offset_width = [0, 0]\n    x = []\n\n    for x_shape, target_height, target_width in test_config:\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n\n      # The original error message does not contain back slashes. However, they\n      # are added by either the assert op or the runtime. If this behavior\n      # changes in the future, the match string will also needs to be changed.\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of \\\\'image.shape\\\\' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParamsScalarInputs(self):\n    # In this test, inputs do not get converted to tensors before calling the\n    # tf.function. The error message here is raised in python\n    # since the python function has direct access to the scalars.\n    x_shape = [3, 3, 1]\n    x = np.zeros(x_shape)\n\n    # Each line is a test configuration:\n    #   offset_height, offset_width, target_height, target_width, err_msg\n    test_config = (\n        (-1, 0, 4, 4,\n         \"offset_height must be >= 0\"),\n        (0, -1, 4, 4,\n         \"offset_width must be >= 0\"),\n        (2, 0, 4, 4,\n         \"height must be <= target - offset\"),\n        (0, 2, 4, 4,\n         \"width must be <= target - offset\"))\n    for config_item in test_config:\n      self._assertRaises(\n          x, x_shape, *config_item, use_tensor_inputs_options=[False])\n\n  def testBadParamsTensorInputsEager(self):\n    # In this test inputs get converted to EagerTensors before calling the\n    # tf.function. The error message here is raised in python\n    # since the python function has direct access to the tensor's values.\n    with context.eager_mode():\n      x_shape = [3, 3, 1]\n      x = np.zeros(x_shape)\n\n      # Each line is a test configuration:\n      #   offset_height, offset_width, target_height, target_width, err_msg\n      test_config = (\n          (-1, 0, 4, 4,\n           \"offset_height must be >= 0\"),\n          (0, -1, 4, 4,\n           \"offset_width must be >= 0\"),\n          (2, 0, 4, 4,\n           \"height must be <= target - offset\"),\n          (0, 2, 4, 4,\n           \"width must be <= target - offset\"))\n      for config_item in test_config:\n        self._assertRaises(\n            x, x_shape, *config_item, use_tensor_inputs_options=[True])\n\n  @parameterized.named_parameters([(\"OffsetHeight\", (-1, 0, 4, 4)),\n                                   (\"OffsetWidth\", (0, -1, 4, 4)),\n                                   (\"Height\", (2, 0, 4, 4)),\n                                   (\"Width\", (0, 2, 4, 4))])\n  def testBadParamsTensorInputsGraph(self, config):\n    # In this test inputs get converted to tensors before calling the\n    # tf.function. The error message here is raised during shape inference.\n    with context.graph_mode():\n      x_shape = [3, 3, 1]\n      x = np.zeros(x_shape)\n      self._assertRaises(\n          x,\n          x_shape,\n          *config,\n          \"Paddings must be non-negative\",\n          use_tensor_inputs_options=[True])\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[55, 66, 3])\n      y = image_ops.pad_to_bounding_box(image, 0, 0, 55, 66)\n      self.assertTrue(y.op.name.startswith(\"pad_to_bounding_box\"))\n\n\nclass SelectDistortedCropBoxTest(test_util.TensorFlowTestCase):\n\n  def _testSampleDistortedBoundingBox(self, image, bounding_box,\n                                      min_object_covered, aspect_ratio_range,\n                                      area_range):\n    original_area = float(np.prod(image.shape))\n    bounding_box_area = float((bounding_box[3] - bounding_box[1]) *\n                              (bounding_box[2] - bounding_box[0]))\n\n    image_size_np = np.array(image.shape, dtype=np.int32)\n    bounding_box_np = (\n        np.array(bounding_box, dtype=np.float32).reshape([1, 1, 4]))\n\n    aspect_ratios = []\n    area_ratios = []\n\n    fraction_object_covered = []\n\n    num_iter = 1000\n    with self.cached_session():\n      image_tf = constant_op.constant(image, shape=image.shape)\n      image_size_tf = constant_op.constant(\n          image_size_np, shape=image_size_np.shape)\n      bounding_box_tf = constant_op.constant(\n          bounding_box_np, dtype=dtypes.float32, shape=bounding_box_np.shape)\n\n      begin, size, _ = image_ops.sample_distorted_bounding_box(\n          image_size=image_size_tf,\n          bounding_boxes=bounding_box_tf,\n          min_object_covered=min_object_covered,\n          aspect_ratio_range=aspect_ratio_range,\n          area_range=area_range)\n      y = array_ops.strided_slice(image_tf, begin, begin + size)\n\n      for _ in xrange(num_iter):\n        y_tf = self.evaluate(y)\n        crop_height = y_tf.shape[0]\n        crop_width = y_tf.shape[1]\n        aspect_ratio = float(crop_width) / float(crop_height)\n        area = float(crop_width * crop_height)\n\n        aspect_ratios.append(aspect_ratio)\n        area_ratios.append(area / original_area)\n        fraction_object_covered.append(float(np.sum(y_tf)) / bounding_box_area)\n\n      # min_object_covered as tensor\n      min_object_covered_t = ops.convert_to_tensor(min_object_covered)\n      begin, size, _ = image_ops.sample_distorted_bounding_box(\n          image_size=image_size_tf,\n          bounding_boxes=bounding_box_tf,\n          min_object_covered=min_object_covered_t,\n          aspect_ratio_range=aspect_ratio_range,\n          area_range=area_range)\n      y = array_ops.strided_slice(image_tf, begin, begin + size)\n\n      for _ in xrange(num_iter):\n        y_tf = self.evaluate(y)\n        crop_height = y_tf.shape[0]\n        crop_width = y_tf.shape[1]\n        aspect_ratio = float(crop_width) / float(crop_height)\n        area = float(crop_width * crop_height)\n\n        aspect_ratios.append(aspect_ratio)\n        area_ratios.append(area / original_area)\n        fraction_object_covered.append(float(np.sum(y_tf)) / bounding_box_area)\n\n    # Ensure that each entry is observed within 3 standard deviations.\n    # num_bins = 10\n    # aspect_ratio_hist, _ = np.histogram(aspect_ratios,\n    #                                     bins=num_bins,\n    #                                     range=aspect_ratio_range)\n    # mean = np.mean(aspect_ratio_hist)\n    # stddev = np.sqrt(mean)\n    # TODO(wicke, shlens, dga): Restore this test so that it is no longer flaky.\n    # TODO(irving): Since the rejection probability is not independent of the\n    # aspect ratio, the aspect_ratio random value is not exactly uniformly\n    # distributed in [min_aspect_ratio, max_aspect_ratio).  This test should be\n    # fixed to reflect the true statistical property, then tightened to enforce\n    # a stricter bound.  Or, ideally, the sample_distorted_bounding_box Op\n    # be fixed to not use rejection sampling and generate correctly uniform\n    # aspect ratios.\n    # self.assertAllClose(aspect_ratio_hist,\n    #                     [mean] * num_bins, atol=3.6 * stddev)\n\n    # The resulting crop will not be uniformly distributed in area. In practice,\n    # we find that the area skews towards the small sizes. Instead, we perform\n    # a weaker test to ensure that the area ratios are merely within the\n    # specified bounds.\n    self.assertLessEqual(max(area_ratios), area_range[1])\n    self.assertGreaterEqual(min(area_ratios), area_range[0])\n\n    # For reference, here is what the distribution of area ratios look like.\n    area_ratio_hist, _ = np.histogram(area_ratios, bins=10, range=area_range)\n    print(\"area_ratio_hist \", area_ratio_hist)\n\n    # Ensure that fraction_object_covered is satisfied.\n    # TODO(wicke, shlens, dga): Restore this test so that it is no longer flaky.\n    # self.assertGreaterEqual(min(fraction_object_covered), min_object_covered)\n\n  def testWholeImageBoundingBox(self):\n    height = 40\n    width = 50\n    image_size = [height, width, 1]\n    bounding_box = [0.0, 0.0, 1.0, 1.0]\n    image = np.arange(\n        0, np.prod(image_size), dtype=np.int32).reshape(image_size)\n    self._testSampleDistortedBoundingBox(\n        image,\n        bounding_box,\n        min_object_covered=0.1,\n        aspect_ratio_range=(0.75, 1.33),\n        area_range=(0.05, 1.0))\n\n  def testWithBoundingBox(self):\n    height = 40\n    width = 50\n    x_shape = [height, width, 1]\n    image = np.zeros(x_shape, dtype=np.int32)\n\n    # Create an object with 1's in a region with area A and require that\n    # the total pixel values >= 0.1 * A.\n    min_object_covered = 0.1\n\n    xmin = 2\n    ymin = 3\n    xmax = 12\n    ymax = 13\n    for x in np.arange(xmin, xmax + 1, 1):\n      for y in np.arange(ymin, ymax + 1, 1):\n        image[x, y] = 1\n\n    # Bounding box is specified as (ymin, xmin, ymax, xmax) in\n    # relative coordinates.\n    bounding_box = (float(ymin) / height, float(xmin) / width,\n                    float(ymax) / height, float(xmax) / width)\n\n    self._testSampleDistortedBoundingBox(\n        image,\n        bounding_box=bounding_box,\n        min_object_covered=min_object_covered,\n        aspect_ratio_range=(0.75, 1.33),\n        area_range=(0.05, 1.0))\n\n  def testSampleDistortedBoundingBoxShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        image_size = constant_op.constant(\n            [40, 50, 1], shape=[3], dtype=dtypes.int32)\n        bounding_box = constant_op.constant(\n            [[[0.0, 0.0, 1.0, 1.0]]],\n            shape=[1, 1, 4],\n            dtype=dtypes.float32,\n        )\n        begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n            image_size=image_size,\n            bounding_boxes=bounding_box,\n            min_object_covered=0.1,\n            aspect_ratio_range=(0.75, 1.33),\n            area_range=(0.05, 1.0))\n\n        # Test that the shapes are correct.\n        self.assertAllEqual([3], begin.get_shape().as_list())\n        self.assertAllEqual([3], end.get_shape().as_list())\n        self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n        # Actual run to make sure shape is correct inside Compute().\n        begin = self.evaluate(begin)\n        end = self.evaluate(end)\n        bbox_for_drawing = self.evaluate(bbox_for_drawing)\n\n        begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n            image_size=image_size,\n            bounding_boxes=bounding_box,\n            min_object_covered=array_ops.placeholder(dtypes.float32),\n            aspect_ratio_range=(0.75, 1.33),\n            area_range=(0.05, 1.0))\n\n        # Test that the shapes are correct.\n        self.assertAllEqual([3], begin.get_shape().as_list())\n        self.assertAllEqual([3], end.get_shape().as_list())\n        self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n\n  def testDefaultMinObjectCovered(self):\n    # By default min_object_covered=0.1 if not provided\n    with self.cached_session():\n      image_size = constant_op.constant(\n          [40, 50, 1], shape=[3], dtype=dtypes.int32)\n      bounding_box = constant_op.constant(\n          [[[0.0, 0.0, 1.0, 1.0]]],\n          shape=[1, 1, 4],\n          dtype=dtypes.float32,\n      )\n      begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n          image_size=image_size,\n          bounding_boxes=bounding_box,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n      self.assertAllEqual([3], begin.get_shape().as_list())\n      self.assertAllEqual([3], end.get_shape().as_list())\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n      # Actual run to make sure shape is correct inside Compute().\n      begin = self.evaluate(begin)\n      end = self.evaluate(end)\n      bbox_for_drawing = self.evaluate(bbox_for_drawing)\n\n  def _testStatelessSampleDistortedBoundingBox(self, image, bounding_box,\n                                               min_object_covered,\n                                               aspect_ratio_range, area_range):\n    with test_util.use_gpu():\n      original_area = float(np.prod(image.shape))\n      bounding_box_area = float((bounding_box[3] - bounding_box[1]) *\n                                (bounding_box[2] - bounding_box[0]))\n\n      image_size_np = np.array(image.shape, dtype=np.int32)\n      bounding_box_np = (\n          np.array(bounding_box, dtype=np.float32).reshape([1, 1, 4]))\n\n      iterations = 2\n      test_seeds = [(1, 2), (3, 4), (5, 6)]\n\n      for seed in test_seeds:\n        aspect_ratios = []\n        area_ratios = []\n        fraction_object_covered = []\n        for _ in range(iterations):\n          image_tf = constant_op.constant(image, shape=image.shape)\n          image_size_tf = constant_op.constant(\n              image_size_np, shape=image_size_np.shape)\n          bounding_box_tf = constant_op.constant(bounding_box_np,\n                                                 dtype=dtypes.float32,\n                                                 shape=bounding_box_np.shape)\n          begin, size, _ = image_ops.stateless_sample_distorted_bounding_box(\n              image_size=image_size_tf,\n              bounding_boxes=bounding_box_tf,\n              seed=seed,\n              min_object_covered=min_object_covered,\n              aspect_ratio_range=aspect_ratio_range,\n              area_range=area_range)\n          y = array_ops.strided_slice(image_tf, begin, begin + size)\n          y_tf = self.evaluate(y)\n          crop_height = y_tf.shape[0]\n          crop_width = y_tf.shape[1]\n          aspect_ratio = float(crop_width) / float(crop_height)\n          area = float(crop_width * crop_height)\n          aspect_ratios.append(aspect_ratio)\n          area_ratio = area / original_area\n          area_ratios.append(area_ratio)\n          fraction_object_covered.append(\n              float(np.sum(y_tf)) / bounding_box_area)\n\n        # Check that `area_ratio` is within valid range.\n        self.assertLessEqual(area_ratio, area_range[1])\n        self.assertGreaterEqual(area_ratio, area_range[0])\n\n        # Each array should consist of one value just repeated `iteration` times\n        # because the same seed is used.\n        self.assertEqual(len(set(aspect_ratios)), 1)\n        self.assertEqual(len(set(area_ratios)), 1)\n        self.assertEqual(len(set(fraction_object_covered)), 1)\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testWholeImageBoundingBoxStateless(self):\n    height = 40\n    width = 50\n    image_size = [height, width, 1]\n    bounding_box = [0.0, 0.0, 1.0, 1.0]\n    image = np.arange(\n        0, np.prod(image_size), dtype=np.int32).reshape(image_size)\n    for min_obj_covered in [0.1, constant_op.constant(0.1)]:\n      self._testStatelessSampleDistortedBoundingBox(\n          image,\n          bounding_box,\n          min_object_covered=min_obj_covered,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testWithBoundingBoxStateless(self):\n    height = 40\n    width = 50\n    x_shape = [height, width, 1]\n    image = np.zeros(x_shape, dtype=np.int32)\n\n    xmin = 2\n    ymin = 3\n    xmax = 12\n    ymax = 13\n    for x in np.arange(xmin, xmax + 1, 1):\n      for y in np.arange(ymin, ymax + 1, 1):\n        image[x, y] = 1\n\n    # Bounding box is specified as (ymin, xmin, ymax, xmax) in\n    # relative coordinates.\n    bounding_box = (float(ymin) / height, float(xmin) / width,\n                    float(ymax) / height, float(xmax) / width)\n\n    # Test both scalar and tensor input for `min_object_covered`.\n    for min_obj_covered in [0.1, constant_op.constant(0.1)]:\n      self._testStatelessSampleDistortedBoundingBox(\n          image,\n          bounding_box=bounding_box,\n          min_object_covered=min_obj_covered,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n  def testSampleDistortedBoundingBoxShapeStateless(self):\n    with test_util.use_gpu():\n      image_size = constant_op.constant(\n          [40, 50, 1], shape=[3], dtype=dtypes.int32)\n      bounding_box = constant_op.constant(\n          [[[0.0, 0.0, 1.0, 1.0]]],\n          shape=[1, 1, 4],\n          dtype=dtypes.float32,\n      )\n\n      bbox_func = functools.partial(\n          image_ops.stateless_sample_distorted_bounding_box,\n          image_size=image_size,\n          bounding_boxes=bounding_box,\n          min_object_covered=0.1,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n      # Check error is raised with wrong seed shapes.\n      for seed in [1, (1, 2, 3)]:\n        with self.assertRaises((ValueError, errors.InvalidArgumentError)):\n          begin, end, bbox_for_drawing = bbox_func(seed=seed)\n\n      test_seed = (1, 2)\n      begin, end, bbox_for_drawing = bbox_func(seed=test_seed)\n\n      # Test that the shapes are correct.\n      self.assertAllEqual([3], begin.get_shape().as_list())\n      self.assertAllEqual([3], end.get_shape().as_list())\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n\n      # Actual run to make sure shape is correct inside Compute().\n      begin = self.evaluate(begin)\n      end = self.evaluate(end)\n      bbox_for_drawing = self.evaluate(bbox_for_drawing)\n      self.assertAllEqual([3], begin.shape)\n      self.assertAllEqual([3], end.shape)\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.shape)\n\n\nclass ResizeImagesV2Test(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  METHODS = [\n      image_ops.ResizeMethod.BILINEAR, image_ops.ResizeMethod.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethod.BICUBIC, image_ops.ResizeMethod.AREA,\n      image_ops.ResizeMethod.LANCZOS3, image_ops.ResizeMethod.LANCZOS5,\n      image_ops.ResizeMethod.GAUSSIAN, image_ops.ResizeMethod.MITCHELLCUBIC\n  ]\n\n  # Some resize methods, such as Gaussian, are non-interpolating in that they\n  # change the image even if there is no scale change, for some test, we only\n  # check the value on the value preserving methods.\n  INTERPOLATING_METHODS = [\n      image_ops.ResizeMethod.BILINEAR, image_ops.ResizeMethod.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethod.BICUBIC, image_ops.ResizeMethod.AREA,\n      image_ops.ResizeMethod.LANCZOS3, image_ops.ResizeMethod.LANCZOS5\n  ]\n\n  TYPES = [\n      np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.float16,\n      np.float32, np.float64\n  ]\n\n  def _assertShapeInference(self, pre_shape, size, post_shape):\n    # Try single image resize\n    single_image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_images_v2(single_image, size)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n    # Try batch images resize with known batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[99] + pre_shape)\n    y = image_ops.resize_images_v2(images, size)\n    self.assertEqual(y.get_shape().as_list(), [99] + post_shape)\n    # Try batch images resize with unknown batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[None] + pre_shape)\n    y = image_ops.resize_images_v2(images, size)\n    self.assertEqual(y.get_shape().as_list(), [None] + post_shape)\n\n  def shouldRunOnGPU(self, method, nptype):\n    if (method == image_ops.ResizeMethod.NEAREST_NEIGHBOR and\n        nptype in [np.float32, np.float64]):\n      return True\n    else:\n      return False\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testNoOp(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    target_height = 6\n    target_width = 4\n\n    for nptype in self.TYPES:\n      img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n      for method in self.METHODS:\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                         method)\n          yshape = array_ops.shape(y)\n          resized, newshape = self.evaluate([y, yshape])\n          self.assertAllEqual(img_shape, newshape)\n          if method in self.INTERPOLATING_METHODS:\n            self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                       self.METHODS[0])\n        yshape = array_ops.shape(y)\n        newshape = self.evaluate(yshape)\n        self.assertAllEqual(single_shape, newshape)\n\n  # half_pixel_centers unsupported in ResizeBilinear\n  @test_util.disable_xla(\"b/127616992\")\n  def testTensorArguments(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    def resize_func(t, new_size, method):\n      return image_ops.resize_images_v2(t, new_size, method)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = resize_func(image, [6, 4], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = resize_func(image, [6, 4], self.METHODS[0])\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(single_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_single, atol=1e-5)\n\n    # Incorrect shape.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant(4)\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([1, 2, 3])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n\n    # Incorrect dtypes.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([6.0, 4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, 4.0], image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [None, 4], image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, None], image_ops.ResizeMethod.BILINEAR)\n\n  def testReturnDtypeV1(self):\n    # Shape inference in V1.\n    with ops.Graph().as_default():\n      target_shapes = [[6, 4], [3, 2],\n                       [\n                           array_ops.placeholder(dtypes.int32),\n                           array_ops.placeholder(dtypes.int32)\n                       ]]\n      for nptype in self.TYPES:\n        image = array_ops.placeholder(nptype, shape=[1, 6, 4, 1])\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            y = image_ops.resize_images_v2(image, target_shape, method)\n            if method == image_ops.ResizeMethod.NEAREST_NEIGHBOR:\n              expected_dtype = image.dtype\n            else:\n              expected_dtype = dtypes.float32\n            self.assertEqual(y.dtype, expected_dtype)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  def testReturnDtypeV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def test_dtype(image, target_shape, target_method):\n        y = image_ops.resize_images_v2(image, target_shape, target_method)\n        if method == image_ops.ResizeMethod.NEAREST_NEIGHBOR:\n          expected_dtype = image.dtype\n        else:\n          expected_dtype = dtypes.float32\n\n        self.assertEqual(y.dtype, expected_dtype)\n\n      target_shapes = [[6, 4],\n                       [3, 2],\n                       [tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32),\n                        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)]]\n\n      for nptype in self.TYPES:\n        image = tensor_spec.TensorSpec(shape=[1, 6, 4, 1], dtype=nptype)\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            with test_util.run_functions_eagerly(run_func_eagerly):\n              test_dtype.get_concrete_function(image, target_shape, method)\n\n  # half_pixel_centers not supported by XLA\n  @test_util.disable_xla(\"b/127616992\")\n  def testSumTensor(self):\n    img_shape = [1, 6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    # Test size where width is specified as a tensor which is a sum\n    # of two tensors.\n    width_1 = constant_op.constant(1)\n    width_2 = constant_op.constant(3)\n    width = math_ops.add(width_1, width_2)\n    height = constant_op.constant(6)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = image_ops.resize_images_v2(image, [height, width], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeDown(self):\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    expected_data = [127, 64, 64, 127, 50, 100]\n    target_height = 3\n    target_width = 2\n\n    # Test out 3-D and 4-D image shapes.\n    img_shapes = [[1, 6, 4, 1], [6, 4, 1]]\n    target_shapes = [[1, target_height, target_width, 1],\n                     [target_height, target_width, 1]]\n\n    for target_shape, img_shape in zip(target_shapes, img_shapes):\n\n      for nptype in self.TYPES:\n        img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n        for method in self.METHODS:\n          if test.is_gpu_available() and self.shouldRunOnGPU(method, nptype):\n            with self.cached_session():\n              image = constant_op.constant(img_np, shape=img_shape)\n              y = image_ops.resize_images_v2(\n                  image, [target_height, target_width], method)\n              expected = np.array(expected_data).reshape(target_shape)\n              resized = self.evaluate(y)\n              self.assertAllClose(resized, expected, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeUp(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethod.BILINEAR] = [\n        64.0, 56.0, 40.0, 32.0, 56.0, 52.0, 44.0, 40.0, 40.0, 44.0, 52.0, 56.0,\n        36.5, 45.625, 63.875, 73.0, 45.5, 56.875, 79.625, 91.0, 50.0, 62.5,\n        87.5, 100.0\n    ]\n    expected_data[image_ops.ResizeMethod.NEAREST_NEIGHBOR] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethod.AREA] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethod.LANCZOS3] = [\n        75.8294, 59.6281, 38.4313, 22.23, 60.6851, 52.0037, 40.6454, 31.964,\n        35.8344, 41.0779, 47.9383, 53.1818, 24.6968, 43.0769, 67.1244, 85.5045,\n        35.7939, 56.4713, 83.5243, 104.2017, 44.8138, 65.1949, 91.8603, 112.2413\n    ]\n    expected_data[image_ops.ResizeMethod.LANCZOS5] = [\n        77.5699, 60.0223, 40.6694, 23.1219, 61.8253, 51.2369, 39.5593, 28.9709,\n        35.7438, 40.8875, 46.5604, 51.7041, 21.5942, 43.5299, 67.7223, 89.658,\n        32.1213, 56.784, 83.984, 108.6467, 44.5802, 66.183, 90.0082, 111.6109\n    ]\n    expected_data[image_ops.ResizeMethod.GAUSSIAN] = [\n        61.1087, 54.6926, 41.3074, 34.8913, 54.6926, 51.4168, 44.5832, 41.3074,\n        41.696, 45.2456, 52.6508, 56.2004, 39.4273, 47.0526, 62.9602, 70.5855,\n        47.3008, 57.3042, 78.173, 88.1764, 51.4771, 62.3638, 85.0752, 95.9619\n    ]\n    expected_data[image_ops.ResizeMethod.BICUBIC] = [\n        70.1453, 59.0252, 36.9748, 25.8547, 59.3195, 53.3386, 41.4789, 35.4981,\n        36.383, 41.285, 51.0051, 55.9071, 30.2232, 42.151, 65.8032, 77.731,\n        41.6492, 55.823, 83.9288, 98.1026, 47.0363, 62.2744, 92.4903, 107.7284\n    ]\n    expected_data[image_ops.ResizeMethod.MITCHELLCUBIC] = [\n        66.0382, 56.6079, 39.3921, 29.9618, 56.7255, 51.9603, 43.2611, 38.4959,\n        39.1828, 43.4664, 51.2864, 55.57, 34.6287, 45.1812, 64.4458, 74.9983,\n        43.8523, 56.8078, 80.4594, 93.4149, 48.9943, 63.026, 88.6422, 102.6739\n    ]\n    for nptype in self.TYPES:\n      for method in expected_data:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                         method)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-04)\n\n  # XLA doesn't implement half_pixel_centers\n  @test_util.disable_xla(\"b/127616992\")\n  def testLegacyBicubicMethodsMatchNewMethods(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    methods_to_test = ((gen_image_ops.resize_bilinear, \"triangle\"),\n                       (gen_image_ops.resize_bicubic, \"keyscubic\"))\n    for legacy_method, new_method in methods_to_test:\n      with self.cached_session():\n        img_np = np.array(data, dtype=np.float32).reshape(img_shape)\n        image = constant_op.constant(img_np, shape=img_shape)\n        legacy_result = legacy_method(\n            image,\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.int32),\n            half_pixel_centers=True)\n        scale = (\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.float32) /\n            math_ops.cast(array_ops.shape(image)[1:3], dtype=dtypes.float32))\n        new_result = gen_image_ops.scale_and_translate(\n            image,\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.int32),\n            scale,\n            array_ops.zeros([2]),\n            kernel_type=new_method,\n            antialias=False)\n        self.assertAllClose(\n            self.evaluate(legacy_result), self.evaluate(new_result), atol=1e-04)\n\n  def testResizeDownArea(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 64, 32, 16, 8, 4, 4, 8, 16, 32, 64, 128, 128, 64, 32, 16, 8, 4, 5,\n        10, 15, 20, 25, 30, 30, 25, 20, 15, 10, 5, 5, 10, 15, 20, 25, 30\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 4\n    target_width = 4\n    expected_data = [\n        73, 33, 23, 39, 73, 33, 23, 39, 14, 16, 19, 21, 14, 16, 19, 21\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                     image_ops.ResizeMethod.AREA)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      resized = self.evaluate(y)\n      self.assertAllClose(resized, expected, atol=1)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testCompareNearestNeighbor(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        img_np = np.arange(\n            0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=input_shape)\n          new_size = constant_op.constant([target_height, target_width])\n          out_op = image_ops.resize_images_v2(\n              image, new_size, image_ops.ResizeMethod.NEAREST_NEIGHBOR)\n          gpu_val = self.evaluate(out_op)\n        with self.cached_session(use_gpu=False):\n          image = constant_op.constant(img_np, shape=input_shape)\n          new_size = constant_op.constant([target_height, target_width])\n          out_op = image_ops.resize_images_v2(\n              image, new_size, image_ops.ResizeMethod.NEAREST_NEIGHBOR)\n          cpu_val = self.evaluate(out_op)\n        self.assertAllClose(cpu_val, gpu_val, rtol=1e-5, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testBfloat16MultipleOps(self):\n    target_height = 8\n    target_width = 12\n    img = np.random.uniform(0, 100, size=(30, 10, 2)).astype(np.float32)\n    img_bf16 = ops.convert_to_tensor(img, dtype=\"bfloat16\")\n    new_size = constant_op.constant([target_height, target_width])\n    img_methods = [\n        image_ops.ResizeMethod.BILINEAR,\n        image_ops.ResizeMethod.NEAREST_NEIGHBOR, image_ops.ResizeMethod.BICUBIC,\n        image_ops.ResizeMethod.AREA\n    ]\n    for method in img_methods:\n      out_op_bf16 = image_ops.resize_images_v2(img_bf16, new_size, method)\n      out_op_f32 = image_ops.resize_images_v2(img, new_size, method)\n      bf16_val = self.evaluate(out_op_bf16)\n      f32_val = self.evaluate(out_op_f32)\n      self.assertAllClose(bf16_val, f32_val, rtol=1e-2, atol=1e-2)\n\n  def testCompareBilinear(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        img_np = np.arange(\n            0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n        value = {}\n        for use_gpu in [True, False]:\n          with self.cached_session(use_gpu=use_gpu):\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(image, new_size,\n                                             image_ops.ResizeMethod.BILINEAR)\n            value[use_gpu] = self.evaluate(out_op)\n        self.assertAllClose(value[True], value[False], rtol=1e-5, atol=1e-5)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([55, 66, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([50, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([None, None, None], [55, 66], [55, 66, None])\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        single_image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n        y = image_ops.resize_images(single_image, [55, 66])\n        self.assertTrue(y.op.name.startswith(\"resize\"))\n\n  def _ResizeImageCall(self, x, max_h, max_w, preserve_aspect_ratio,\n                       use_tensor_inputs):\n    if use_tensor_inputs:\n      target_max = ops.convert_to_tensor([max_h, max_w])\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      target_max = (max_h, max_w)\n      x_tensor = x\n\n    def resize_func(t,\n                    target_max=target_max,\n                    preserve_aspect_ratio=preserve_aspect_ratio):\n      return image_ops.resize_images(\n          t, ops.convert_to_tensor(target_max),\n          preserve_aspect_ratio=preserve_aspect_ratio)\n\n    with self.cached_session():\n      return self.evaluate(resize_func(x_tensor))\n\n  def _assertResizeEqual(self,\n                         x,\n                         x_shape,\n                         y,\n                         y_shape,\n                         preserve_aspect_ratio=True,\n                         use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertResizeCheckShape(self,\n                              x,\n                              x_shape,\n                              target_shape,\n                              y_shape,\n                              preserve_aspect_ratio=True,\n                              use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width = target_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.zeros(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertShapeEqual(y, ops.convert_to_tensor(y_tf))\n\n  def testPreserveAspectRatioMultipleImages(self):\n    x_shape = [10, 100, 80, 10]\n    x = np.random.uniform(size=x_shape)\n    for preserve_aspect_ratio in [True, False]:\n      with self.subTest(preserve_aspect_ratio=preserve_aspect_ratio):\n        expect_shape = [10, 250, 200, 10] if preserve_aspect_ratio \\\n            else [10, 250, 250, 10]\n        self._assertResizeCheckShape(\n            x,\n            x_shape, [250, 250],\n            expect_shape,\n            preserve_aspect_ratio=preserve_aspect_ratio)\n\n  def testPreserveAspectRatioNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeEqual(x, x_shape, x, x_shape)\n\n  def testPreserveAspectRatioSmaller(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [50, 50, 10])\n\n  def testPreserveAspectRatioSmallerMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [10, 50, 50, 10])\n\n  def testPreserveAspectRatioLarger(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [150, 200], [150, 150, 10])\n\n  def testPreserveAspectRatioSameRatio(self):\n    x_shape = [1920, 1080, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [3840, 2160], [3840, 2160, 3])\n\n  def testPreserveAspectRatioSquare(self):\n    x_shape = [299, 299, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [320, 320], [320, 320, 3])\n\n  def testLargeDim(self):\n    with self.session():\n      with self.assertRaises(errors.InternalError):\n        x = np.ones((5, 1, 1, 2))\n        v = image_ops.resize_images_v2(x, [1610637938, 1610637938],\n                                       image_ops.ResizeMethod.BILINEAR)\n        _ = self.evaluate(v)\n\n\nclass ResizeImagesTest(test_util.TensorFlowTestCase,\n                       parameterized.TestCase):\n\n  METHODS = [\n      image_ops.ResizeMethodV1.BILINEAR,\n      image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethodV1.BICUBIC, image_ops.ResizeMethodV1.AREA\n  ]\n\n  TYPES = [\n      np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.float16,\n      np.float32, np.float64\n  ]\n\n  def _assertShapeInference(self, pre_shape, size, post_shape):\n    # Try single image resize\n    single_image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_images(single_image, size)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n    # Try batch images resize with known batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[99] + pre_shape)\n    y = image_ops.resize_images(images, size)\n    self.assertEqual(y.get_shape().as_list(), [99] + post_shape)\n    # Try batch images resize with unknown batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[None] + pre_shape)\n    y = image_ops.resize_images(images, size)\n    self.assertEqual(y.get_shape().as_list(), [None] + post_shape)\n\n  def shouldRunOnGPU(self, method, nptype):\n    if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR and\n        nptype in [np.float32, np.float64]):\n      return True\n    else:\n      return False\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testNoOp(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    target_height = 6\n    target_width = 4\n\n    for nptype in self.TYPES:\n      img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n      for method in self.METHODS:\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(image, [target_height, target_width],\n                                      method)\n          yshape = array_ops.shape(y)\n          resized, newshape = self.evaluate([y, yshape])\n          self.assertAllEqual(img_shape, newshape)\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = image_ops.resize_images(image, [target_height, target_width],\n                                    self.METHODS[0])\n        yshape = array_ops.shape(y)\n        newshape = self.evaluate(yshape)\n        self.assertAllEqual(single_shape, newshape)\n\n  def testTensorArguments(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n\n    def resize_func(t, new_size, method):\n      return image_ops.resize_images(t, new_size, method)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = resize_func(image, [6, 4], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        self.assertAllClose(resized, img_np, atol=1e-5)\n\n    # Resizing with a single image must leave the shape unchanged also.\n    with self.cached_session():\n      img_single = img_np.reshape(single_shape)\n      image = constant_op.constant(img_single, shape=single_shape)\n      y = resize_func(image, [6, 4], self.METHODS[0])\n      yshape = array_ops.shape(y)\n      resized, newshape = self.evaluate([y, yshape])\n      self.assertAllEqual(single_shape, newshape)\n      self.assertAllClose(resized, img_single, atol=1e-5)\n\n    # Incorrect shape.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant(4)\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([1, 2, 3])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n\n    # Incorrect dtypes.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([6.0, 4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, 4.0], image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [None, 4], image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, None], image_ops.ResizeMethodV1.BILINEAR)\n\n  def testReturnDtypeV1(self):\n    # Shape inference in V1.\n    with ops.Graph().as_default():\n      target_shapes = [[6, 4], [3, 2], [\n          array_ops.placeholder(dtypes.int32),\n          array_ops.placeholder(dtypes.int32)\n      ]]\n      for nptype in self.TYPES:\n        image = array_ops.placeholder(nptype, shape=[1, 6, 4, 1])\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            y = image_ops.resize_images(image, target_shape, method)\n            if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR or\n                target_shape == image.shape[1:3]):\n              expected_dtype = image.dtype\n            else:\n              expected_dtype = dtypes.float32\n            self.assertEqual(y.dtype, expected_dtype)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  def testReturnDtypeV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def test_dtype(image, target_shape, target_method):\n        y = image_ops.resize_images(image, target_shape, target_method)\n        if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR or\n            target_shape == image.shape[1:3]):\n          expected_dtype = image.dtype\n        else:\n          expected_dtype = dtypes.float32\n\n        self.assertEqual(y.dtype, expected_dtype)\n\n      target_shapes = [[6, 4],\n                       [3, 2],\n                       [tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32),\n                        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)]]\n\n      for nptype in self.TYPES:\n        image = tensor_spec.TensorSpec(shape=[1, 6, 4, 1], dtype=nptype)\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            with test_util.run_functions_eagerly(run_func_eagerly):\n              test_dtype.get_concrete_function(image, target_shape, method)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testSumTensor(self):\n    img_shape = [1, 6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    # Test size where width is specified as a tensor which is a sum\n    # of two tensors.\n    width_1 = constant_op.constant(1)\n    width_2 = constant_op.constant(3)\n    width = math_ops.add(width_1, width_2)\n    height = constant_op.constant(6)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session() as sess:\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = image_ops.resize_images(image, [height, width], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        self.assertAllClose(resized, img_np, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeDown(self):\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    expected_data = [127, 64, 64, 127, 50, 100]\n    target_height = 3\n    target_width = 2\n\n    # Test out 3-D and 4-D image shapes.\n    img_shapes = [[1, 6, 4, 1], [6, 4, 1]]\n    target_shapes = [[1, target_height, target_width, 1],\n                     [target_height, target_width, 1]]\n\n    for target_shape, img_shape in zip(target_shapes, img_shapes):\n\n      for nptype in self.TYPES:\n        img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n        for method in self.METHODS:\n          if test.is_gpu_available() and self.shouldRunOnGPU(method, nptype):\n            with self.cached_session():\n              image = constant_op.constant(img_np, shape=img_shape)\n              y = image_ops.resize_images(image, [target_height, target_width],\n                                          method)\n              expected = np.array(expected_data).reshape(target_shape)\n              resized = self.evaluate(y)\n              self.assertAllClose(resized, expected, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeUpAlignCornersFalse(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethodV1.BILINEAR] = [\n        64.0, 48.0, 32.0, 32.0, 48.0, 48.0, 48.0, 48.0, 32.0, 48.0, 64.0, 64.0,\n        41.0, 61.5, 82.0, 82.0, 50.0, 75.0, 100.0, 100.0, 50.0, 75.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.NEAREST_NEIGHBOR] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.AREA] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n\n    for nptype in self.TYPES:\n      for method in [\n          image_ops.ResizeMethodV1.BILINEAR,\n          image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n          image_ops.ResizeMethodV1.AREA\n      ]:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(\n              image, [target_height, target_width], method, align_corners=False)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-05)\n\n  def testResizeUpAlignCornersTrue(self):\n    img_shape = [1, 3, 2, 1]\n    data = [6, 3, 3, 6, 6, 9]\n    target_height = 5\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethodV1.BILINEAR] = [\n        6.0, 5.0, 4.0, 3.0, 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 5.0, 6.0, 4.5, 5.5,\n        6.5, 7.5, 6.0, 7.0, 8.0, 9.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.NEAREST_NEIGHBOR] = [\n        6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0,\n        9.0, 9.0, 6.0, 6.0, 9.0, 9.0\n    ]\n    # TODO(b/37749740): Improve alignment of ResizeMethodV1.AREA when\n    # align_corners=True.\n    expected_data[image_ops.ResizeMethodV1.AREA] = [\n        6.0, 6.0, 6.0, 3.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 6.0, 3.0, 3.0,\n        3.0, 6.0, 6.0, 6.0, 6.0, 9.0\n    ]\n\n    for nptype in self.TYPES:\n      for method in [\n          image_ops.ResizeMethodV1.BILINEAR,\n          image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n          image_ops.ResizeMethodV1.AREA\n      ]:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(\n              image, [target_height, target_width], method, align_corners=True)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-05)\n\n  def testResizeUpBicubic(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 128, 64, 64, 128, 128, 64, 64, 64, 64, 128, 128, 64, 64, 128, 128,\n        50, 50, 100, 100, 50, 50, 100, 100, 50, 50, 100, 100, 50, 50, 100, 100,\n        50, 50, 100, 100\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 8\n    target_width = 8\n    expected_data = [\n        128, 135, 96, 55, 64, 114, 134, 128, 78, 81, 68, 52, 57, 118, 144, 136,\n        55, 49, 79, 109, 103, 89, 83, 84, 74, 70, 95, 122, 115, 69, 49, 55, 100,\n        105, 75, 43, 50, 89, 105, 100, 57, 54, 74, 96, 91, 65, 55, 58, 70, 69,\n        75, 81, 80, 72, 69, 70, 105, 112, 75, 36, 45, 92, 111, 105\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images(image, [target_height, target_width],\n                                  image_ops.ResizeMethodV1.BICUBIC)\n      resized = self.evaluate(y)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      self.assertAllClose(resized, expected, atol=1)\n\n  def testResizeDownArea(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 64, 32, 16, 8, 4, 4, 8, 16, 32, 64, 128, 128, 64, 32, 16, 8, 4, 5,\n        10, 15, 20, 25, 30, 30, 25, 20, 15, 10, 5, 5, 10, 15, 20, 25, 30\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 4\n    target_width = 4\n    expected_data = [\n        73, 33, 23, 39, 73, 33, 23, 39, 14, 16, 19, 21, 14, 16, 19, 21\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images(image, [target_height, target_width],\n                                  image_ops.ResizeMethodV1.AREA)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      resized = self.evaluate(y)\n      self.assertAllClose(resized, expected, atol=1)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testCompareNearestNeighbor(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        for align_corners in [True, False]:\n          img_np = np.arange(\n              0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n          with self.cached_session():\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(\n                image,\n                new_size,\n                image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n                align_corners=align_corners)\n            gpu_val = self.evaluate(out_op)\n          with self.cached_session(use_gpu=False):\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(\n                image,\n                new_size,\n                image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n                align_corners=align_corners)\n            cpu_val = self.evaluate(out_op)\n          self.assertAllClose(cpu_val, gpu_val, rtol=1e-5, atol=1e-5)\n\n  def testCompareBilinear(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        for align_corners in [True, False]:\n          img_np = np.arange(\n              0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n          value = {}\n          for use_gpu in [True, False]:\n            with self.cached_session(use_gpu=use_gpu):\n              image = constant_op.constant(img_np, shape=input_shape)\n              new_size = constant_op.constant([target_height, target_width])\n              out_op = image_ops.resize_images(\n                  image,\n                  new_size,\n                  image_ops.ResizeMethodV1.BILINEAR,\n                  align_corners=align_corners)\n              value[use_gpu] = self.evaluate(out_op)\n          self.assertAllClose(value[True], value[False], rtol=1e-5, atol=1e-5)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([55, 66, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([50, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([None, None, None], [55, 66], [55, 66, None])\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img_shape = [1, 3, 2, 1]\n      with self.cached_session():\n        single_image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n        y = image_ops.resize_images(single_image, [55, 66])\n        self.assertTrue(y.op.name.startswith(\"resize\"))\n\n  def _ResizeImageCall(self, x, max_h, max_w, preserve_aspect_ratio,\n                       use_tensor_inputs):\n    if use_tensor_inputs:\n      target_max = ops.convert_to_tensor([max_h, max_w])\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      target_max = [max_h, max_w]\n      x_tensor = x\n\n    y = image_ops.resize_images(\n        x_tensor, target_max, preserve_aspect_ratio=preserve_aspect_ratio)\n\n    with self.cached_session():\n      return self.evaluate(y)\n\n  def _assertResizeEqual(self, x, x_shape, y, y_shape,\n                         preserve_aspect_ratio=True,\n                         use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertResizeCheckShape(self, x, x_shape, target_shape,\n                              y_shape, preserve_aspect_ratio=True,\n                              use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width = target_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.zeros(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertShapeEqual(y, ops.convert_to_tensor(y_tf))\n\n  def testPreserveAspectRatioMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [250, 250], [10, 250, 250, 10],\n                                 preserve_aspect_ratio=False)\n\n  def testPreserveAspectRatioNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeEqual(x, x_shape, x, x_shape)\n\n  def testPreserveAspectRatioSmaller(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [50, 50, 10])\n\n  def testPreserveAspectRatioSmallerMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [10, 50, 50, 10])\n\n  def testPreserveAspectRatioLarger(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [150, 200], [150, 150, 10])\n\n  def testPreserveAspectRatioSameRatio(self):\n    x_shape = [1920, 1080, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [3840, 2160], [3840, 2160, 3])\n\n  def testPreserveAspectRatioSquare(self):\n    x_shape = [299, 299, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [320, 320], [320, 320, 3])\n\n\nclass ResizeImageWithPadV1Test(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithPad(self, x, target_height, target_width,\n                          use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    with self.cached_session():\n      return self.evaluate(\n          image_ops.resize_image_with_pad_v1(x_tensor, target_height,\n                                             target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithPad(x, target_height, target_width,\n                                      use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithPad(x, target_height, target_width,\n                                 use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_pad_v1(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test with 3-D tensors.\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n      # Test with 4-D tensors.\n      self._assertShapeInference([5, 55, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, 66, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, 50, 60, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, None, None, None], 55, 66,\n                                 [5, 55, 66, None])\n      self._assertShapeInference([None, None, None, None], 55, 66,\n                                 [None, 55, 66, None])\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Reduce vertical dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 3, 0]\n    y_shape = [1, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Reduce horizontal dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [1, 3, 0, 0]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [1, 3]\n    y_shape = [1, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n\n# half_pixel_centers not supported by XLA\n@test_util.for_all_test_methods(test_util.disable_xla, \"b/127616992\")\nclass ResizeImageWithPadV2Test(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithPad(self, x, target_height, target_width,\n                          use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    with self.cached_session():\n      return self.evaluate(\n          image_ops.resize_image_with_pad_v2(x_tensor, target_height,\n                                             target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithPad(x, target_height, target_width,\n                                      use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithPad(x, target_height, target_width,\n                                 use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_pad_v1(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test with 3-D tensors.\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n      # Test with 4-D tensors.\n      self._assertShapeInference([5, 55, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, 66, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, 50, 60, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, None, None, None], 55, 66,\n                                 [5, 55, 66, None])\n      self._assertShapeInference([None, None, None, None], 55, 66,\n                                 [None, 55, 66, None])\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Reduce vertical dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 3.5, 5.5, 0]\n    y_shape = [1, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Reduce horizontal dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [3.5, 5.5, 0, 0]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [3.5, 5.5]\n    y_shape = [1, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n\nclass ResizeImageWithCropOrPadTest(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithCropOrPad(self, x, target_height, target_width,\n                                use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    @def_function.function\n    def resize_crop_or_pad(*args):\n      return image_ops.resize_image_with_crop_or_pad(*args)\n\n    with self.cached_session():\n      return self.evaluate(\n          resize_crop_or_pad(x_tensor, target_height, target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithCropOrPad(x, target_height, target_width,\n                                            use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithCropOrPad(x, target_height, target_width,\n                                       use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_crop_or_pad(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Pad even along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 2, 3, 4, 0, 0, 5, 6, 7, 8, 0]\n    y_shape = [2, 6, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad odd along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 2, 3, 4, 0, 0, 0, 5, 6, 7, 8, 0, 0]\n    y_shape = [2, 7, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad even along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0]\n    y_shape = [4, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad odd along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0]\n    y_shape = [5, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testCrop(self):\n    # Crop even along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [2, 3, 6, 7]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop odd along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    x_shape = [2, 6, 1]\n\n    y = [2, 3, 4, 8, 9, 10]\n    y_shape = [2, 3, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop even along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [4, 2, 1]\n\n    y = [3, 4, 5, 6]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop odd along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n    x_shape = [8, 2, 1]\n\n    y = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    y_shape = [5, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testCropAndPad(self):\n    # Pad along row but crop along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 2, 3, 6, 7, 0, 0]\n    y_shape = [4, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop along row but pad along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [4, 2, 1]\n\n    y = [0, 3, 4, 0, 0, 5, 6, 0]\n    y_shape = [2, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    target_height, target_width = [4, 4]\n\n    for x_shape in ([3, 5],):\n      self._assertRaises(x, x_shape, target_height, target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n    for x_shape in ([1, 3, 5, 1, 1],):\n      self._assertRaises(x, x_shape, target_height, target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    target_height, target_width = [1, 1]\n    x = []\n\n    for x_shape in ([0, 2, 2], [2, 0, 2], [2, 2, 0]):\n      self._assertRaises(\n          x,\n          x_shape,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n\n      # The original error message does not contain back slashes. However, they\n      # are added by either the assert op or the runtime. If this behavior\n      # changes in the future, the match string will also needs to be changed.\n      self._assertRaises(\n          x,\n          x_shape,\n          target_height,\n          target_width,\n          \"inner 3 dims of \\\\'image.shape\\\\' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParams(self):\n    x_shape = [4, 4, 1]\n    x = np.zeros(x_shape)\n\n    # target_height <= 0\n    target_height, target_width = [0, 5]\n    self._assertRaises(x, x_shape, target_height, target_width,\n                       \"target_height must be > 0\")\n\n    # target_width <= 0\n    target_height, target_width = [5, 0]\n    self._assertRaises(x, x_shape, target_height, target_width,\n                       \"target_width must be > 0\")\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n      y = image_ops.resize_image_with_crop_or_pad(image, 55, 66)\n      self.assertTrue(y.op.name.startswith(\"resize_image_with_crop_or_pad\"))\n\n\ndef simple_color_ramp():\n  \"\"\"Build a simple color ramp RGB image.\"\"\"\n  w, h = 256, 200\n  i = np.arange(h)[:, None]\n  j = np.arange(w)\n  image = np.empty((h, w, 3), dtype=np.uint8)\n  image[:, :, 0] = i\n  image[:, :, 1] = j\n  image[:, :, 2] = (i + j) >> 1\n  return image\n\n\nclass JpegTest(test_util.TensorFlowTestCase):\n\n  # TODO(irving): Add self.assertAverageLess or similar to test_util\n  def averageError(self, image0, image1):\n    self.assertEqual(image0.shape, image1.shape)\n    image0 = image0.astype(int)  # Avoid overflow\n    return np.abs(image0 - image1).sum() / np.prod(image0.shape)\n\n  def testExisting(self):\n    # Read a real jpeg and verify shape\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1.jpg\")\n    with self.cached_session():\n      jpeg0 = io_ops.read_file(path)\n      image0 = image_ops.decode_jpeg(jpeg0)\n      image1 = image_ops.decode_jpeg(image_ops.encode_jpeg(image0))\n      jpeg0, image0, image1 = self.evaluate([jpeg0, image0, image1])\n      self.assertEqual(len(jpeg0), 3771)\n      self.assertEqual(image0.shape, (256, 128, 3))\n      self.assertLess(self.averageError(image0, image1), 1.4)\n\n  def testCmyk(self):\n    # Confirm that CMYK reads in as RGB\n    base = \"tensorflow/core/lib/jpeg/testdata\"\n    rgb_path = os.path.join(base, \"jpeg_merge_test1.jpg\")\n    cmyk_path = os.path.join(base, \"jpeg_merge_test1_cmyk.jpg\")\n    shape = 256, 128, 3\n    for channels in 3, 0:\n      with self.cached_session():\n        rgb = image_ops.decode_jpeg(\n            io_ops.read_file(rgb_path), channels=channels)\n        cmyk = image_ops.decode_jpeg(\n            io_ops.read_file(cmyk_path), channels=channels)\n        rgb, cmyk = self.evaluate([rgb, cmyk])\n        self.assertEqual(rgb.shape, shape)\n        self.assertEqual(cmyk.shape, shape)\n        error = self.averageError(rgb, cmyk)\n        self.assertLess(error, 4)\n\n  def testCropAndDecodeJpeg(self):\n    with self.cached_session() as sess:\n      # Encode it, then decode it, then encode it\n      base = \"tensorflow/core/lib/jpeg/testdata\"\n      jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n\n      h, w, _ = 256, 128, 3\n      crop_windows = [[0, 0, 5, 5], [0, 0, 5, w], [0, 0, h, 5],\n                      [h - 6, w - 5, 6, 5], [6, 5, 15, 10], [0, 0, h, w]]\n      for crop_window in crop_windows:\n        # Explicit two stages: decode + crop.\n        image1 = image_ops.decode_jpeg(jpeg0)\n        y, x, h, w = crop_window\n        image1_crop = image_ops.crop_to_bounding_box(image1, y, x, h, w)\n\n        # Combined decode+crop.\n        image2 = image_ops.decode_and_crop_jpeg(jpeg0, crop_window, channels=3)\n\n        # Combined decode+crop should have the same shape inference on image\n        # sizes.\n        image1_shape = image1_crop.get_shape().as_list()\n        image2_shape = image2.get_shape().as_list()\n        self.assertAllEqual(image1_shape, image2_shape)\n\n        # CropAndDecode should be equal to DecodeJpeg+Crop.\n        image1_crop, image2 = self.evaluate([image1_crop, image2])\n        self.assertAllEqual(image1_crop, image2)\n\n  def testCropAndDecodeJpegWithInvalidCropWindow(self):\n    with self.cached_session() as sess:\n      # Encode it, then decode it, then encode it\n      base = \"tensorflow/core/lib/jpeg/testdata\"\n      jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n\n      h, w, _ = 256, 128, 3\n      # Invalid crop windows.\n      crop_windows = [[-1, 11, 11, 11], [11, -1, 11, 11], [11, 11, -1, 11],\n                      [11, 11, 11, -1], [11, 11, 0, 11], [11, 11, 11, 0],\n                      [0, 0, h + 1, w], [0, 0, h, w + 1]]\n      for crop_window in crop_windows:\n        with self.assertRaisesRegex(\n            (ValueError, errors.InvalidArgumentError),\n            \"Invalid JPEG data or crop window\"):\n          result = image_ops.decode_and_crop_jpeg(jpeg0, crop_window)\n          self.evaluate(result)\n\n  def testSynthetic(self):\n    with self.cached_session():\n      # Encode it, then decode it, then encode it\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_ACCURATE\")\n      image2 = image_ops.decode_jpeg(\n          image_ops.encode_jpeg(image1), dct_method=\"INTEGER_ACCURATE\")\n      jpeg0, image0, image1, image2 = self.evaluate(\n          [jpeg0, image0, image1, image2])\n\n      # The decoded-encoded image should be similar to the input\n      self.assertLess(self.averageError(image0, image1), 0.6)\n\n      # We should be very close to a fixpoint\n      self.assertLess(self.averageError(image1, image2), 0.02)\n\n      # Smooth ramps compress well (input size is 153600)\n      self.assertGreaterEqual(len(jpeg0), 5000)\n      self.assertLessEqual(len(jpeg0), 6000)\n\n  def testSyntheticFasterAlgorithm(self):\n    with self.cached_session():\n      # Encode it, then decode it, then encode it\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_FAST\")\n      image2 = image_ops.decode_jpeg(\n          image_ops.encode_jpeg(image1), dct_method=\"INTEGER_FAST\")\n      jpeg0, image0, image1, image2 = self.evaluate(\n          [jpeg0, image0, image1, image2])\n\n      # The decoded-encoded image should be similar to the input, but\n      # note this is worse than the slower algorithm because it is\n      # less accurate.\n      self.assertLess(self.averageError(image0, image1), 0.95)\n\n      # Repeated compression / decompression will have a higher error\n      # with a lossier algorithm.\n      self.assertLess(self.averageError(image1, image2), 1.05)\n\n      # Smooth ramps compress well (input size is 153600)\n      self.assertGreaterEqual(len(jpeg0), 5000)\n      self.assertLessEqual(len(jpeg0), 6000)\n\n  def testDefaultDCTMethodIsIntegerFast(self):\n    with self.cached_session():\n      # Compare decoding with both dct_option=INTEGER_FAST and\n      # default.  They should be the same.\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_FAST\")\n      image2 = image_ops.decode_jpeg(jpeg0)\n      image1, image2 = self.evaluate([image1, image2])\n\n      # The images should be the same.\n      self.assertAllClose(image1, image2)\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        jpeg = constant_op.constant(\"nonsense\")\n        for channels in 0, 1, 3:\n          image = image_ops.decode_jpeg(jpeg, channels=channels)\n          self.assertEqual(image.get_shape().as_list(),\n                           [None, None, channels or None])\n\n  def testExtractJpegShape(self):\n    # Read a real jpeg and verify shape.\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1.jpg\")\n    with self.cached_session():\n      jpeg = io_ops.read_file(path)\n      # Extract shape without decoding.\n      image_shape = self.evaluate(image_ops.extract_jpeg_shape(jpeg))\n      self.assertAllEqual(image_shape, [256, 128, 3])\n\n  def testExtractJpegShapeforCmyk(self):\n    # Read a cmyk jpeg image, and verify its shape.\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1_cmyk.jpg\")\n    with self.cached_session():\n      jpeg = io_ops.read_file(path)\n      image_shape = self.evaluate(image_ops.extract_jpeg_shape(jpeg))\n      # Cmyk jpeg image has 4 channels.\n      self.assertAllEqual(image_shape, [256, 128, 4])\n\n  def testRandomJpegQuality(self):\n    # Previous implementation of random_jpeg_quality had a bug.\n    # This unit test tests the fixed version, but due to forward compatibility\n    # this test can only be done when fixed version is used.\n    # Test jpeg quality dynamic randomization.\n    with ops.Graph().as_default(), self.test_session():\n      np.random.seed(7)\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      random_jpeg_image = image_ops.random_jpeg_quality(image, 40, 100)\n      with self.cached_session() as sess:\n        # Test randomization.\n        random_jpeg_images = [sess.run(random_jpeg_image) for _ in range(5)]\n        are_images_equal = []\n        for i in range(1, len(random_jpeg_images)):\n          # Most of them should be different if randomization is occurring\n          # correctly.\n          are_images_equal.append(\n              np.array_equal(random_jpeg_images[0], random_jpeg_images[i]))\n        self.assertFalse(all(are_images_equal))\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testStatelessRandomJpegQuality(self):\n    # Test deterministic randomness in jpeg quality by checking that the same\n    # sequence of jpeg quality adjustments are returned each round given the\n    # same seed.\n    with test_util.use_gpu():\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      jpeg_quality = (40, 100)\n      seeds_list = [(1, 2), (3, 4)]\n\n      iterations = 2\n      random_jpeg_images_all = [[] for _ in range(iterations)]\n      for random_jpeg_images in random_jpeg_images_all:\n        for seed in seeds_list:\n          distorted_jpeg = image_ops.stateless_random_jpeg_quality(\n              image, jpeg_quality[0], jpeg_quality[1], seed=seed)\n          # Verify that the random jpeg image is different from the original\n          # jpeg image.\n          self.assertNotAllEqual(image, distorted_jpeg)\n          random_jpeg_images.append(self.evaluate(distorted_jpeg))\n\n      # Verify that the results are identical given the same seed.\n      for i in range(1, iterations):\n        self.assertAllEqual(random_jpeg_images_all[0],\n                            random_jpeg_images_all[i])\n\n  def testAdjustJpegQuality(self):\n    # Test if image_ops.adjust_jpeg_quality works when jpeq quality\n    # is an int (not tensor) for backward compatibility.\n    with ops.Graph().as_default(), self.test_session():\n      np.random.seed(7)\n      jpeg_quality = np.random.randint(40, 100)\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      adjust_jpeg_quality_image = image_ops.adjust_jpeg_quality(\n          image, jpeg_quality)\n      with self.cached_session() as sess:\n        sess.run(adjust_jpeg_quality_image)\n\n  def testAdjustJpegQualityShape(self):\n    with self.cached_session():\n      image = constant_op.constant(\n          np.arange(24, dtype=np.uint8).reshape([2, 4, 3]))\n      adjusted_image = image_ops.adjust_jpeg_quality(image, 80)\n      adjusted_image.shape.assert_is_compatible_with([None, None, 3])\n\n\nclass PngTest(test_util.TensorFlowTestCase):\n\n  def testExisting(self):\n    # Read some real PNGs, converting to different channel numbers\n    prefix = \"tensorflow/core/lib/png/testdata/\"\n    inputs = ((1, \"lena_gray.png\"), (4, \"lena_rgba.png\"),\n              (3, \"lena_palette.png\"), (4, \"lena_palette_trns.png\"))\n    for channels_in, filename in inputs:\n      for channels in 0, 1, 3, 4:\n        with self.cached_session():\n          png0 = io_ops.read_file(prefix + filename)\n          image0 = image_ops.decode_png(png0, channels=channels)\n          png0, image0 = self.evaluate([png0, image0])\n          self.assertEqual(image0.shape, (26, 51, channels or channels_in))\n          if channels == channels_in:\n            image1 = image_ops.decode_png(image_ops.encode_png(image0))\n            self.assertAllEqual(image0, self.evaluate(image1))\n\n  def testSynthetic(self):\n    with self.cached_session():\n      # Encode it, then decode it\n      image0 = constant_op.constant(simple_color_ramp())\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n\n      # PNG is lossless\n      self.assertAllEqual(image0, image1)\n\n      # Smooth ramps compress well, but not too well\n      self.assertGreaterEqual(len(png0), 400)\n      self.assertLessEqual(len(png0), 750)\n\n  def testSyntheticUint16(self):\n    with self.cached_session():\n      # Encode it, then decode it\n      image0 = constant_op.constant(simple_color_ramp(), dtype=dtypes.uint16)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0, dtype=dtypes.uint16)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n\n      # PNG is lossless\n      self.assertAllEqual(image0, image1)\n\n      # Smooth ramps compress well, but not too well\n      self.assertGreaterEqual(len(png0), 800)\n      self.assertLessEqual(len(png0), 1500)\n\n  def testSyntheticTwoChannel(self):\n    with self.cached_session():\n      # Strip the b channel from an rgb image to get a two-channel image.\n      gray_alpha = simple_color_ramp()[:, :, 0:2]\n      image0 = constant_op.constant(gray_alpha)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n      self.assertEqual(2, image0.shape[-1])\n      self.assertAllEqual(image0, image1)\n\n  def testSyntheticTwoChannelUint16(self):\n    with self.cached_session():\n      # Strip the b channel from an rgb image to get a two-channel image.\n      gray_alpha = simple_color_ramp()[:, :, 0:2]\n      image0 = constant_op.constant(gray_alpha, dtype=dtypes.uint16)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0, dtype=dtypes.uint16)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n      self.assertEqual(2, image0.shape[-1])\n      self.assertAllEqual(image0, image1)\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        png = constant_op.constant(\"nonsense\")\n        for channels in 0, 1, 3:\n          image = image_ops.decode_png(png, channels=channels)\n          self.assertEqual(image.get_shape().as_list(),\n                           [None, None, channels or None])\n\n\nclass GifTest(test_util.TensorFlowTestCase):\n\n  def _testValid(self, filename):\n    # Read some real GIFs\n    prefix = \"tensorflow/core/lib/gif/testdata/\"\n    WIDTH = 20\n    HEIGHT = 40\n    STRIDE = 5\n    shape = (12, HEIGHT, WIDTH, 3)\n\n    with self.cached_session():\n      gif0 = io_ops.read_file(prefix + filename)\n      image0 = image_ops.decode_gif(gif0)\n      gif0, image0 = self.evaluate([gif0, image0])\n\n      self.assertEqual(image0.shape, shape)\n\n      for frame_idx, frame in enumerate(image0):\n        gt = np.zeros(shape[1:], dtype=np.uint8)\n        start = frame_idx * STRIDE\n        end = (frame_idx + 1) * STRIDE\n        print(frame_idx)\n        if end <= WIDTH:\n          gt[:, start:end, :] = 255\n        else:\n          start -= WIDTH\n          end -= WIDTH\n          gt[start:end, :, :] = 255\n\n        self.assertAllClose(frame, gt)\n\n  def testValid(self):\n    self._testValid(\"scan.gif\")\n    self._testValid(\"optimized.gif\")\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        gif = constant_op.constant(\"nonsense\")\n        image = image_ops.decode_gif(gif)\n        self.assertEqual(image.get_shape().as_list(), [None, None, None, 3])\n\n  def testAnimatedGif(self):\n    # Test if all frames in the animated GIF file is properly decoded.\n    with self.cached_session():\n      base = \"tensorflow/core/lib/gif/testdata\"\n      gif = io_ops.read_file(os.path.join(base, \"pendulum_sm.gif\"))\n      gt_frame0 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame0.png\"))\n      gt_frame1 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame1.png\"))\n      gt_frame2 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame2.png\"))\n\n      image = image_ops.decode_gif(gif)\n      frame0 = image_ops.decode_png(gt_frame0)\n      frame1 = image_ops.decode_png(gt_frame1)\n      frame2 = image_ops.decode_png(gt_frame2)\n      image, frame0, frame1, frame2 = self.evaluate([image, frame0, frame1,\n                                                     frame2])\n      # Compare decoded gif frames with ground-truth data.\n      self.assertAllEqual(image[0], frame0)\n      self.assertAllEqual(image[1], frame1)\n      self.assertAllEqual(image[2], frame2)\n\n\nclass ConvertImageTest(test_util.TensorFlowTestCase):\n\n  def _convert(self, original, original_dtype, output_dtype, expected):\n    x_np = np.array(original, dtype=original_dtype.as_numpy_dtype())\n    y_np = np.array(expected, dtype=output_dtype.as_numpy_dtype())\n\n    with self.cached_session():\n      image = constant_op.constant(x_np)\n      y = image_ops.convert_image_dtype(image, output_dtype)\n      self.assertTrue(y.dtype == output_dtype)\n      self.assertAllClose(y, y_np, atol=1e-5)\n      if output_dtype in [\n          dtypes.float32, dtypes.float64, dtypes.int32, dtypes.int64\n      ]:\n        y_saturate = image_ops.convert_image_dtype(\n            image, output_dtype, saturate=True)\n        self.assertTrue(y_saturate.dtype == output_dtype)\n        self.assertAllClose(y_saturate, y_np, atol=1e-5)\n\n  def testNoConvert(self):\n    # Tests with Tensor.op requires a graph.\n    with ops.Graph().as_default():\n      # Make sure converting to the same data type creates only an identity op\n      with self.cached_session():\n        image = constant_op.constant([1], dtype=dtypes.uint8)\n        image_ops.convert_image_dtype(image, dtypes.uint8)\n        y = image_ops.convert_image_dtype(image, dtypes.uint8)\n        self.assertEqual(y.op.type, \"Identity\")\n        self.assertEqual(y.op.inputs[0], image)\n\n  def testConvertBetweenInteger(self):\n    # Make sure converting to between integer types scales appropriately\n    with self.cached_session():\n      self._convert([0, 255], dtypes.uint8, dtypes.int16, [0, 255 * 128])\n      self._convert([0, 32767], dtypes.int16, dtypes.uint8, [0, 255])\n      self._convert([0, 2**32], dtypes.int64, dtypes.int32, [0, 1])\n      self._convert([0, 1], dtypes.int32, dtypes.int64, [0, 2**32])\n\n  def testConvertBetweenFloat(self):\n    # Make sure converting to between float types does nothing interesting\n    with self.cached_session():\n      self._convert([-1.0, 0, 1.0, 200000], dtypes.float32, dtypes.float64,\n                    [-1.0, 0, 1.0, 200000])\n      self._convert([-1.0, 0, 1.0, 200000], dtypes.float64, dtypes.float32,\n                    [-1.0, 0, 1.0, 200000])\n\n  def testConvertBetweenIntegerAndFloat(self):\n    # Make sure converting from and to a float type scales appropriately\n    with self.cached_session():\n      self._convert([0, 1, 255], dtypes.uint8, dtypes.float32,\n                    [0, 1.0 / 255.0, 1])\n      self._convert([0, 1.1 / 255.0, 1], dtypes.float32, dtypes.uint8,\n                    [0, 1, 255])\n\n  def testConvertBetweenInt16AndInt8(self):\n    with self.cached_session():\n      # uint8, uint16\n      self._convert([0, 255 * 256], dtypes.uint16, dtypes.uint8, [0, 255])\n      self._convert([0, 255], dtypes.uint8, dtypes.uint16, [0, 255 * 256])\n      # int8, uint16\n      self._convert([0, 127 * 2 * 256], dtypes.uint16, dtypes.int8, [0, 127])\n      self._convert([0, 127], dtypes.int8, dtypes.uint16, [0, 127 * 2 * 256])\n      # int16, uint16\n      self._convert([0, 255 * 256], dtypes.uint16, dtypes.int16, [0, 255 * 128])\n      self._convert([0, 255 * 128], dtypes.int16, dtypes.uint16, [0, 255 * 256])\n\n\nclass TotalVariationTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests the function total_variation() in image_ops.\n\n  We test a few small handmade examples, as well as\n  some larger examples using an equivalent numpy\n  implementation of the total_variation() function.\n\n  We do NOT test for overflows and invalid / edge-case arguments.\n  \"\"\"\n\n  def _test(self, x_np, y_np):\n    \"\"\"Test that the TensorFlow implementation of\n    total_variation(x_np) calculates the values in y_np.\n\n    Note that these may be float-numbers so we only test\n    for approximate equality within some narrow error-bound.\n    \"\"\"\n\n    # Create a TensorFlow session.\n    with self.cached_session():\n      # Add a constant to the TensorFlow graph that holds the input.\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # Add ops for calculating the total variation using TensorFlow.\n      y = image_ops.total_variation(images=x_tf)\n\n      # Run the TensorFlow session to calculate the result.\n      y_tf = self.evaluate(y)\n\n      # Assert that the results are as expected within\n      # some small error-bound in case they are float-values.\n      self.assertAllClose(y_tf, y_np)\n\n  def _total_variation_np(self, x_np):\n    \"\"\"Calculate the total variation of x_np using numpy.\n    This implements the same function as TensorFlow but\n    using numpy instead.\n\n    Args:\n        x_np: Numpy array with 3 or 4 dimensions.\n    \"\"\"\n\n    dim = len(x_np.shape)\n\n    if dim == 3:\n      # Calculate differences for neighboring pixel-values using slices.\n      dif1 = x_np[1:, :, :] - x_np[:-1, :, :]\n      dif2 = x_np[:, 1:, :] - x_np[:, :-1, :]\n\n      # Sum for all axis.\n      sum_axis = None\n    elif dim == 4:\n      # Calculate differences for neighboring pixel-values using slices.\n      dif1 = x_np[:, 1:, :, :] - x_np[:, :-1, :, :]\n      dif2 = x_np[:, :, 1:, :] - x_np[:, :, :-1, :]\n\n      # Only sum for the last 3 axis.\n      sum_axis = (1, 2, 3)\n    else:\n      # This should not occur in this test-code.\n      pass\n\n    tot_var = np.sum(np.abs(dif1), axis=sum_axis) + \\\n              np.sum(np.abs(dif2), axis=sum_axis)\n\n    return tot_var\n\n  def _test_tensorflow_vs_numpy(self, x_np):\n    \"\"\"Test the TensorFlow implementation against a numpy implementation.\n\n    Args:\n        x_np: Numpy array with 3 or 4 dimensions.\n    \"\"\"\n\n    # Calculate the y-values using the numpy implementation.\n    y_np = self._total_variation_np(x_np)\n\n    self._test(x_np, y_np)\n\n  def _generateArray(self, shape):\n    \"\"\"Generate an array of the given shape for use in testing.\n    The numbers are calculated as the cumulative sum, which\n    causes the difference between neighboring numbers to vary.\"\"\"\n\n    # Flattened length of the array.\n    flat_len = np.prod(shape)\n\n    a = np.array(range(flat_len), dtype=int)\n    a = np.cumsum(a)\n    a = a.reshape(shape)\n\n    return a\n\n  # TODO(b/133851381): re-enable this test.\n  def disabledtestTotalVariationNumpy(self):\n    \"\"\"Test the TensorFlow implementation against a numpy implementation.\n    The two implementations are very similar so it is possible that both\n    have the same bug, which would not be detected by this test. It is\n    therefore necessary to test with manually crafted data as well.\"\"\"\n\n    # Generate a test-array.\n    # This is an 'image' with 100x80 pixels and 3 color channels.\n    a = self._generateArray(shape=(100, 80, 3))\n\n    # Test the TensorFlow implementation vs. numpy implementation.\n    # We use a numpy implementation to check the results that are\n    # calculated using TensorFlow are correct.\n    self._test_tensorflow_vs_numpy(a)\n    self._test_tensorflow_vs_numpy(a + 1)\n    self._test_tensorflow_vs_numpy(-a)\n    self._test_tensorflow_vs_numpy(1.1 * a)\n\n    # Expand to a 4-dim array.\n    b = a[np.newaxis, :]\n\n    # Combine several variations of the image into a single 4-dim array.\n    multi = np.vstack((b, b + 1, -b, 1.1 * b))\n\n    # Test that the TensorFlow function can also handle 4-dim arrays.\n    self._test_tensorflow_vs_numpy(multi)\n\n  def testTotalVariationHandmade(self):\n    \"\"\"Test the total variation for a few handmade examples.\"\"\"\n\n    # We create an image that is 2x2 pixels with 3 color channels.\n    # The image is very small so we can check the result by hand.\n\n    # Red color channel.\n    # The following are the sum of absolute differences between the pixels.\n    # sum row dif = (4-1) + (7-2) = 3 + 5 = 8\n    # sum col dif = (2-1) + (7-4) = 1 + 3 = 4\n    r = [[1, 2], [4, 7]]\n\n    # Blue color channel.\n    # sum row dif = 18 + 29 = 47\n    # sum col dif = 7 + 18 = 25\n    g = [[11, 18], [29, 47]]\n\n    # Green color channel.\n    # sum row dif = 120 + 193 = 313\n    # sum col dif = 47 + 120 = 167\n    b = [[73, 120], [193, 313]]\n\n    # Combine the 3 color channels into a single 3-dim array.\n    # The shape is (2, 2, 3) corresponding to (height, width and color).\n    a = np.dstack((r, g, b))\n\n    # Total variation for this image.\n    # Sum of all pixel differences = 8 + 4 + 47 + 25 + 313 + 167 = 564\n    tot_var = 564\n\n    # Calculate the total variation using TensorFlow and assert it is correct.\n    self._test(a, tot_var)\n\n    # If we add 1 to all pixel-values then the total variation is unchanged.\n    self._test(a + 1, tot_var)\n\n    # If we negate all pixel-values then the total variation is unchanged.\n    self._test(-a, tot_var)  # pylint: disable=invalid-unary-operand-type\n\n    # Scale the pixel-values by a float. This scales the total variation as\n    # well.\n    b = 1.1 * a\n    self._test(b, 1.1 * tot_var)\n\n    # Scale by another float.\n    c = 1.2 * a\n    self._test(c, 1.2 * tot_var)\n\n    # Combine these 3 images into a single array of shape (3, 2, 2, 3)\n    # where the first dimension is for the image-number.\n    multi = np.vstack((a[np.newaxis, :], b[np.newaxis, :], c[np.newaxis, :]))\n\n    # Check that TensorFlow correctly calculates the total variation\n    # for each image individually and returns the correct array.\n    self._test(multi, tot_var * np.array([1.0, 1.1, 1.2]))\n\n\nclass FormatTest(test_util.TensorFlowTestCase):\n\n  def testFormats(self):\n    prefix = \"tensorflow/core/lib\"\n    paths = (\"png/testdata/lena_gray.png\", \"jpeg/testdata/jpeg_merge_test1.jpg\",\n             \"gif/testdata/lena.gif\")\n    decoders = {\n        \"jpeg\": functools.partial(image_ops.decode_jpeg, channels=3),\n        \"png\": functools.partial(image_ops.decode_png, channels=3),\n        \"gif\": lambda s: array_ops.squeeze(image_ops.decode_gif(s), axis=0),\n    }\n    with self.cached_session():\n      for path in paths:\n        contents = self.evaluate(io_ops.read_file(os.path.join(prefix, path)))\n        images = {}\n        for name, decode in decoders.items():\n          image = self.evaluate(decode(contents))\n          self.assertEqual(image.ndim, 3)\n          for prev_name, prev in images.items():\n            print(\"path %s, names %s %s, shapes %s %s\" %\n                  (path, name, prev_name, image.shape, prev.shape))\n            self.assertAllEqual(image, prev)\n          images[name] = image\n\n  def testError(self):\n    path = \"tensorflow/core/lib/gif/testdata/scan.gif\"\n    with self.cached_session():\n      for decode in image_ops.decode_jpeg, image_ops.decode_png:\n        with self.assertRaisesOpError(r\"Got 12 frames\"):\n          decode(io_ops.read_file(path)).eval()\n\n\nclass CombinedNonMaxSuppressionTest(test_util.TensorFlowTestCase):\n\n  # NOTE(b/142795960): parameterized tests do not work well with tf.tensor\n  # inputs. Due to failures, creating another test `testInvalidTensorInput`\n  # which is identical to this one except that the input here is a scalar as\n  # opposed to a tensor.\n  def testInvalidPyInput(self):\n    boxes_np = [[[[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]]]\n    scores_np = [[[0.9, 0.75, 0.6, 0.95, 0.5, 0.3]]]\n    max_output_size_per_class = 5\n    max_total_size = 2**31\n    with self.assertRaisesRegex(\n        (TypeError, ValueError),\n        \"type int64 that does not match expected type of int32|\"\n        \"Tensor conversion requested dtype int32 for Tensor with dtype int64\"):\n      image_ops.combined_non_max_suppression(\n          boxes=boxes_np,\n          scores=scores_np,\n          max_output_size_per_class=max_output_size_per_class,\n          max_total_size=max_total_size)\n\n  # NOTE(b/142795960): parameterized tests do not work well with tf.tensor\n  # inputs. Due to failures, creating another this test which is identical to\n  # `testInvalidPyInput` except that the input is a tensor here as opposed\n  # to a scalar.\n  def testInvalidTensorInput(self):\n    boxes_np = [[[[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]]]\n    scores_np = [[[0.9, 0.75, 0.6, 0.95, 0.5, 0.3]]]\n    max_output_size_per_class = 5\n    max_total_size = ops.convert_to_tensor(2**31)\n    with self.assertRaisesRegex(\n        (TypeError, ValueError),\n        \"type int64 that does not match expected type of int32|\"\n        \"Tensor conversion requested dtype int32 for Tensor with dtype int64\"):\n      image_ops.combined_non_max_suppression(\n          boxes=boxes_np,\n          scores=scores_np,\n          max_output_size_per_class=max_output_size_per_class,\n          max_total_size=max_total_size)\n\n\nclass NonMaxSuppressionTest(test_util.TensorFlowTestCase):\n\n  def testNonMaxSuppression(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 3\n    iou_threshold_np = 0.5\n    with self.cached_session():\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices = image_ops.non_max_suppression(\n          boxes, scores, max_output_size, iou_threshold)\n      self.assertAllClose(selected_indices, [3, 0, 5])\n\n  def testInvalidShape(self):\n\n    def nms_func(box, score, iou_thres, score_thres):\n      return image_ops.non_max_suppression(box, score, iou_thres, score_thres)\n\n    iou_thres = 3\n    score_thres = 0.5\n\n    # The boxes should be 2D of shape [num_boxes, 4].\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 2 but is rank 1\"):\n      boxes = constant_op.constant([0.0, 0.0, 1.0, 1.0])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Dimension must be 4 but is 3\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The boxes is of shape [num_boxes, 4], and the scores is\n    # of shape [num_boxes]. So an error will be thrown.\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Dimensions must be equal, but are 1 and 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9, 0.75])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The scores should be 1D of shape [num_boxes].\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 1 but is rank 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([[0.9]])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The max_output_size should be a scalar (0-D).\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 0 but is rank 1\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, [iou_thres], score_thres)\n\n    # The iou_threshold should be a scalar (0-D).\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 0 but is rank 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, [[score_thres]])\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testTensors(self):\n    with context.eager_mode():\n      boxes_tensor = constant_op.constant([[6.625, 6.688, 272., 158.5],\n                                           [6.625, 6.75, 270.5, 158.4],\n                                           [5.375, 5., 272., 157.5]])\n      scores_tensor = constant_op.constant([0.84, 0.7944, 0.7715])\n      max_output_size = 100\n      iou_threshold = 0.5\n      score_threshold = 0.3\n      soft_nms_sigma = 0.25\n      pad_to_max_output_size = False\n\n      # gen_image_ops.non_max_suppression_v5.\n      for dtype in [np.float16, np.float32]:\n        boxes = math_ops.cast(boxes_tensor, dtype=dtype)\n        scores = math_ops.cast(scores_tensor, dtype=dtype)\n        _, _, num_selected = gen_image_ops.non_max_suppression_v5(\n            boxes, scores, max_output_size, iou_threshold, score_threshold,\n            soft_nms_sigma, pad_to_max_output_size)\n        self.assertEqual(num_selected.numpy(), 1)\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testDataTypes(self):\n    # Test case for GitHub issue 20199.\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 3\n    iou_threshold_np = 0.5\n    score_threshold_np = float(\"-inf\")\n    # Note: There are multiple versions of non_max_suppression v2, v3, v4.\n    # gen_image_ops.non_max_suppression_v2:\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        selected_indices = gen_image_ops.non_max_suppression_v2(\n            boxes, scores, max_output_size, iou_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v3\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        selected_indices = gen_image_ops.non_max_suppression_v3(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v4.\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        selected_indices, _ = gen_image_ops.non_max_suppression_v4(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v5.\n    soft_nms_sigma_np = float(0.0)\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        soft_nms_sigma = constant_op.constant(soft_nms_sigma_np, dtype=dtype)\n        selected_indices, _, _ = gen_image_ops.non_max_suppression_v5(\n            boxes, scores, max_output_size, iou_threshold, score_threshold,\n            soft_nms_sigma)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n\n  def testZeroIOUThreshold(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [1., 1., 1., 1., 1., 1.]\n    max_output_size_np = 3\n    iou_threshold_np = 0.0\n    with self.cached_session():\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices = image_ops.non_max_suppression(\n          boxes, scores, max_output_size, iou_threshold)\n      self.assertAllClose(selected_indices, [0, 3, 5])\n\n\nclass NonMaxSuppressionWithScoresTest(test_util.TensorFlowTestCase):\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersWithSoftNMS(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 6\n    iou_threshold_np = 0.5\n    score_threshold_np = 0.0\n    soft_nms_sigma_np = 0.5\n    boxes = constant_op.constant(boxes_np)\n    scores = constant_op.constant(scores_np)\n    max_output_size = constant_op.constant(max_output_size_np)\n    iou_threshold = constant_op.constant(iou_threshold_np)\n    score_threshold = constant_op.constant(score_threshold_np)\n    soft_nms_sigma = constant_op.constant(soft_nms_sigma_np)\n    selected_indices, selected_scores = \\\n        image_ops.non_max_suppression_with_scores(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            score_threshold,\n            soft_nms_sigma)\n    selected_indices, selected_scores = self.evaluate(\n        [selected_indices, selected_scores])\n    self.assertAllClose(selected_indices, [3, 0, 1, 5, 4, 2])\n    self.assertAllClose(selected_scores,\n                        [0.95, 0.9, 0.384, 0.3, 0.256, 0.197],\n                        rtol=1e-2, atol=1e-2)\n\n\nclass NonMaxSuppressionPaddedTest(test_util.TensorFlowTestCase,\n                                  parameterized.TestCase):\n\n  @test_util.disable_xla(\n      \"b/141236442: \"\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersV1(self):\n    with ops.Graph().as_default():\n      boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n      scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n      max_output_size_np = 5\n      iou_threshold_np = 0.5\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices_padded, num_valid_padded = \\\n          image_ops.non_max_suppression_padded(\n              boxes,\n              scores,\n              max_output_size,\n              iou_threshold,\n              pad_to_max_output_size=True)\n      selected_indices, num_valid = image_ops.non_max_suppression_padded(\n          boxes,\n          scores,\n          max_output_size,\n          iou_threshold,\n          pad_to_max_output_size=False)\n      # The output shape of the padded operation must be fully defined.\n      self.assertEqual(selected_indices_padded.shape.is_fully_defined(), True)\n      self.assertEqual(selected_indices.shape.is_fully_defined(), False)\n      with self.cached_session():\n        self.assertAllClose(selected_indices_padded, [3, 0, 5, 0, 0])\n        self.assertEqual(num_valid_padded.eval(), 3)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n        self.assertEqual(num_valid.eval(), 3)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  @test_util.disable_xla(\n      \"b/141236442: \"\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def func(boxes, scores, max_output_size, iou_threshold):\n        boxes = constant_op.constant(boxes_np)\n        scores = constant_op.constant(scores_np)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np)\n\n        yp, nvp = image_ops.non_max_suppression_padded(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            pad_to_max_output_size=True)\n\n        y, n = image_ops.non_max_suppression_padded(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            pad_to_max_output_size=False)\n\n        # The output shape of the padded operation must be fully defined.\n        self.assertEqual(yp.shape.is_fully_defined(), True)\n        self.assertEqual(y.shape.is_fully_defined(), False)\n\n        return yp, nvp, y, n\n\n      boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n      scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n      max_output_size_np = 5\n      iou_threshold_np = 0.5\n\n      selected_indices_padded, num_valid_padded, selected_indices, num_valid = \\\n          func(boxes_np, scores_np, max_output_size_np, iou_threshold_np)\n\n      with self.cached_session():\n        with test_util.run_functions_eagerly(run_func_eagerly):\n          self.assertAllClose(selected_indices_padded, [3, 0, 5, 0, 0])\n          self.assertEqual(self.evaluate(num_valid_padded), 3)\n          self.assertAllClose(selected_indices, [3, 0, 5])\n          self.assertEqual(self.evaluate(num_valid), 3)\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromContinuousOverLapV1(self):\n    with ops.Graph().as_default():\n      boxes_np = [[0, 0, 1, 1], [0, 0.2, 1, 1.2], [0, 0.4, 1, 1.4],\n                  [0, 0.6, 1, 1.6], [0, 0.8, 1, 1.8], [0, 2, 1, 2]]\n      scores_np = [0.9, 0.75, 0.6, 0.5, 0.4, 0.3]\n      max_output_size_np = 3\n      iou_threshold_np = 0.5\n      score_threshold_np = 0.1\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      score_threshold = constant_op.constant(score_threshold_np)\n      selected_indices, num_valid = image_ops.non_max_suppression_padded(\n          boxes,\n          scores,\n          max_output_size,\n          iou_threshold,\n          score_threshold)\n      # The output shape of the padded operation must be fully defined.\n      self.assertEqual(selected_indices.shape.is_fully_defined(), False)\n      with self.cached_session():\n        self.assertAllClose(selected_indices, [0, 2, 4])\n        self.assertEqual(num_valid.eval(), 3)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromContinuousOverLapV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def func(boxes, scores, max_output_size, iou_threshold, score_threshold):\n        boxes = constant_op.constant(boxes)\n        scores = constant_op.constant(scores)\n        max_output_size = constant_op.constant(max_output_size)\n        iou_threshold = constant_op.constant(iou_threshold)\n        score_threshold = constant_op.constant(score_threshold)\n\n        y, nv = image_ops.non_max_suppression_padded(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n\n        # The output shape of the padded operation must be fully defined.\n        self.assertEqual(y.shape.is_fully_defined(), False)\n\n        return y, nv\n\n      boxes_np = [[0, 0, 1, 1], [0, 0.2, 1, 1.2], [0, 0.4, 1, 1.4],\n                  [0, 0.6, 1, 1.6], [0, 0.8, 1, 1.8], [0, 2, 1, 2]]\n      scores_np = [0.9, 0.75, 0.6, 0.5, 0.4, 0.3]\n      max_output_size_np = 3\n      iou_threshold_np = 0.5\n      score_threshold_np = 0.1\n      selected_indices, num_valid = func(boxes_np, scores_np,\n                                         max_output_size_np, iou_threshold_np,\n                                         score_threshold_np)\n      with self.cached_session():\n        with test_util.run_functions_eagerly(run_func_eagerly):\n          self.assertAllClose(selected_indices, [0, 2, 4])\n          self.assertEqual(self.evaluate(num_valid), 3)\n\n  def testInvalidDtype(self):\n    boxes_np = [[4.0, 6.0, 3.0, 6.0],\n                [2.0, 1.0, 5.0, 4.0],\n                [9.0, 0.0, 9.0, 9.0]]\n    scores = [5.0, 6.0, 5.0]\n    max_output_size = 2**31\n    with self.assertRaisesRegex(\n        (TypeError, ValueError), \"type int64 that does not match type int32\"):\n      boxes = constant_op.constant(boxes_np)\n      image_ops.non_max_suppression_padded(boxes, scores, max_output_size)\n\n\nclass NonMaxSuppressionWithOverlapsTest(test_util.TensorFlowTestCase):\n\n  def testSelectOneFromThree(self):\n    overlaps_np = [\n        [1.0, 0.7, 0.2],\n        [0.7, 1.0, 0.0],\n        [0.2, 0.0, 1.0],\n    ]\n    scores_np = [0.7, 0.9, 0.1]\n    max_output_size_np = 3\n\n    overlaps = constant_op.constant(overlaps_np)\n    scores = constant_op.constant(scores_np)\n    max_output_size = constant_op.constant(max_output_size_np)\n    overlap_threshold = 0.6\n    score_threshold = 0.4\n\n    selected_indices = image_ops.non_max_suppression_with_overlaps(\n        overlaps, scores, max_output_size, overlap_threshold, score_threshold)\n\n    with self.cached_session():\n      self.assertAllClose(selected_indices, [1])\n\n\nclass VerifyCompatibleImageShapesTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests utility function used by ssim() and psnr().\"\"\"\n\n  def testWrongDims(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img = array_ops.placeholder(dtype=dtypes.float32)\n      img_np = np.array((2, 2))\n\n      with self.cached_session() as sess:\n        _, _, checks = image_ops_impl._verify_compatible_image_shapes(img, img)\n        with self.assertRaises(errors.InvalidArgumentError):\n          sess.run(checks, {img: img_np})\n\n  def testShapeMismatch(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img1 = array_ops.placeholder(dtype=dtypes.float32)\n      img2 = array_ops.placeholder(dtype=dtypes.float32)\n\n      img1_np = np.array([1, 2, 2, 1])\n      img2_np = np.array([1, 3, 3, 1])\n\n      with self.cached_session() as sess:\n        _, _, checks = image_ops_impl._verify_compatible_image_shapes(\n            img1, img2)\n        with self.assertRaises(errors.InvalidArgumentError):\n          sess.run(checks, {img1: img1_np, img2: img2_np})\n\n\nclass PSNRTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for PSNR.\"\"\"\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/psnr/testdata\", filename))\n    im = image_ops.decode_jpeg(content, dct_method=\"INTEGER_ACCURATE\")\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      q20 = self._LoadTestImage(sess, \"cat_q20.jpg\")\n      q72 = self._LoadTestImage(sess, \"cat_q72.jpg\")\n      q95 = self._LoadTestImage(sess, \"cat_q95.jpg\")\n      return q20, q72, q95\n\n  def _PSNR_NumPy(self, orig, target, max_value):\n    \"\"\"Numpy implementation of PSNR.\"\"\"\n    mse = ((orig - target) ** 2).mean(axis=(-3, -2, -1))\n    return 20 * np.log10(max_value) - 10 * np.log10(mse)\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testPSNRSingleImage(self):\n    image1 = self._RandomImage((8, 8, 1), 1)\n    image2 = self._RandomImage((8, 8, 1), 1)\n    psnr = self._PSNR_NumPy(image1, image2, 1)\n\n    with self.cached_session():\n      tf_image1 = constant_op.constant(image1, shape=image1.shape,\n                                       dtype=dtypes.float32)\n      tf_image2 = constant_op.constant(image2, shape=image2.shape,\n                                       dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_image1, tf_image2, 1.0, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testPSNRMultiImage(self):\n    image1 = self._RandomImage((10, 8, 8, 1), 1)\n    image2 = self._RandomImage((10, 8, 8, 1), 1)\n    psnr = self._PSNR_NumPy(image1, image2, 1)\n\n    with self.cached_session():\n      tf_image1 = constant_op.constant(image1, shape=image1.shape,\n                                       dtype=dtypes.float32)\n      tf_image2 = constant_op.constant(image2, shape=image2.shape,\n                                       dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_image1, tf_image2, 1, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testGoldenPSNR(self):\n    q20, q72, q95 = self._LoadTestImages()\n\n    # Verify NumPy implementation first.\n    # Golden values are generated using GNU Octave's psnr() function.\n    psnr1 = self._PSNR_NumPy(q20, q72, 1)\n    self.assertNear(30.321, psnr1, 0.001, msg=\"q20.dtype=\" + str(q20.dtype))\n    psnr2 = self._PSNR_NumPy(q20, q95, 1)\n    self.assertNear(29.994, psnr2, 0.001)\n    psnr3 = self._PSNR_NumPy(q72, q95, 1)\n    self.assertNear(35.302, psnr3, 0.001)\n\n    # Test TensorFlow implementation.\n    with self.cached_session():\n      tf_q20 = constant_op.constant(q20, shape=q20.shape, dtype=dtypes.float32)\n      tf_q72 = constant_op.constant(q72, shape=q72.shape, dtype=dtypes.float32)\n      tf_q95 = constant_op.constant(q95, shape=q95.shape, dtype=dtypes.float32)\n      tf_psnr1 = self.evaluate(image_ops.psnr(tf_q20, tf_q72, 1, \"psnr1\"))\n      tf_psnr2 = self.evaluate(image_ops.psnr(tf_q20, tf_q95, 1, \"psnr2\"))\n      tf_psnr3 = self.evaluate(image_ops.psnr(tf_q72, tf_q95, 1, \"psnr3\"))\n      self.assertAllClose(psnr1, tf_psnr1, atol=0.001)\n      self.assertAllClose(psnr2, tf_psnr2, atol=0.001)\n      self.assertAllClose(psnr3, tf_psnr3, atol=0.001)\n\n  def testInfinity(self):\n    q20, _, _ = self._LoadTestImages()\n    psnr = self._PSNR_NumPy(q20, q20, 1)\n    with self.cached_session():\n      tf_q20 = constant_op.constant(q20, shape=q20.shape, dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_q20, tf_q20, 1, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testInt(self):\n    img1 = self._RandomImage((10, 8, 8, 1), 255)\n    img2 = self._RandomImage((10, 8, 8, 1), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    psnr_uint8 = image_ops.psnr(img1, img2, 255)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    psnr_float32 = image_ops.psnr(img1, img2, 1.0)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(psnr_uint8), self.evaluate(psnr_float32), atol=0.001)\n\n\nclass SSIMTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for SSIM.\"\"\"\n\n  _filenames = [\"checkerboard1.png\",\n                \"checkerboard2.png\",\n                \"checkerboard3.png\",]\n\n  _ssim = np.asarray([[1.000000, 0.230880, 0.231153],\n                      [0.230880, 1.000000, 0.996828],\n                      [0.231153, 0.996828, 1.000000]])\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/ssim/testdata\", filename))\n    im = image_ops.decode_png(content)\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      return [self._LoadTestImage(sess, f) for f in self._filenames]\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testAgainstMatlab(self):\n    \"\"\"Tests against values produced by Matlab.\"\"\"\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3)]\n\n    def ssim_func(x):\n      return image_ops.ssim(\n          *x, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    with self.cached_session():\n      scores = [\n          self.evaluate(ssim_func(t))\n          for t in itertools.combinations_with_replacement(img, 2)\n      ]\n\n    self.assertAllClose(expected, np.squeeze(scores), atol=1e-4)\n\n  def testBatch(self):\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    ssim = image_ops.ssim(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testBatchNumpyInputs(self):\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    with self.cached_session():\n      img1 = self.evaluate(constant_op.constant(img1))\n      img2 = self.evaluate(constant_op.constant(img2))\n\n    ssim = image_ops.ssim(\n        img1,\n        img2,\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testBroadcast(self):\n    img = self._LoadTestImages()[:2]\n    expected = self._ssim[:2, :2]\n\n    img = constant_op.constant(np.concatenate(img))\n    img1 = array_ops.expand_dims(img, axis=0)  # batch dims: 1, 2.\n    img2 = array_ops.expand_dims(img, axis=1)  # batch dims: 2, 1.\n\n    ssim = image_ops.ssim(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testNegative(self):\n    \"\"\"Tests against negative SSIM index.\"\"\"\n    step = np.expand_dims(np.arange(0, 256, 16, dtype=np.uint8), axis=0)\n    img1 = np.tile(step, (16, 1))\n    img2 = np.fliplr(img1)\n\n    img1 = img1.reshape((1, 16, 16, 1))\n    img2 = img2.reshape((1, 16, 16, 1))\n\n    ssim = image_ops.ssim(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        255,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertLess(self.evaluate(ssim), 0)\n\n  def testInt(self):\n    img1 = self._RandomImage((1, 16, 16, 3), 255)\n    img2 = self._RandomImage((1, 16, 16, 3), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    ssim_uint8 = image_ops.ssim(\n        img1, img2, 255, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    ssim_float32 = image_ops.ssim(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(ssim_uint8), self.evaluate(ssim_float32), atol=0.001)\n\n\nclass MultiscaleSSIMTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for MS-SSIM.\"\"\"\n\n  _filenames = [\"checkerboard1.png\",\n                \"checkerboard2.png\",\n                \"checkerboard3.png\",]\n\n  _msssim = np.asarray([[1.000000, 0.091016, 0.091025],\n                        [0.091016, 1.000000, 0.999567],\n                        [0.091025, 0.999567, 1.000000]])\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/ssim/testdata\", filename))\n    im = image_ops.decode_png(content)\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      return [self._LoadTestImage(sess, f) for f in self._filenames]\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testAgainstMatlab(self):\n    \"\"\"Tests against MS-SSIM computed with Matlab implementation.\n\n    For color images, MS-SSIM scores are averaged over color channels.\n    \"\"\"\n    img = self._LoadTestImages()\n    expected = self._msssim[np.triu_indices(3)]\n\n    def ssim_func(x):\n      return image_ops.ssim_multiscale(\n          *x, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    with self.cached_session():\n      scores = [\n          self.evaluate(ssim_func(t))\n          for t in itertools.combinations_with_replacement(img, 2)\n      ]\n\n    self.assertAllClose(expected, np.squeeze(scores), atol=1e-4)\n\n  def testUnweightedIsDifferentiable(self):\n    img = self._LoadTestImages()\n\n    @def_function.function\n    def msssim_func(x1, x2, scalar):\n      return image_ops.ssim_multiscale(\n          x1 * scalar,\n          x2 * scalar,\n          max_val=1.0,\n          power_factors=(1, 1, 1, 1, 1),\n          filter_size=11,\n          filter_sigma=1.5,\n          k1=0.01,\n          k2=0.03)\n\n    scalar = constant_op.constant(1.0, dtype=dtypes.float32)\n\n    with backprop.GradientTape() as tape:\n      tape.watch(scalar)\n      y = msssim_func(img[0], img[1], scalar)\n\n    grad = tape.gradient(y, scalar)\n    np_grads = self.evaluate(grad)\n    self.assertTrue(np.isfinite(np_grads).all())\n\n  def testUnweightedIsDifferentiableEager(self):\n    if not context.executing_eagerly():\n      self.skipTest(\"Eager mode only\")\n\n    img = self._LoadTestImages()\n\n    def msssim_func(x1, x2, scalar):\n      return image_ops.ssim_multiscale(\n          x1 * scalar,\n          x2 * scalar,\n          max_val=1.0,\n          power_factors=(1, 1, 1, 1, 1),\n          filter_size=11,\n          filter_sigma=1.5,\n          k1=0.01,\n          k2=0.03)\n\n    scalar = constant_op.constant(1.0, dtype=dtypes.float32)\n\n    with backprop.GradientTape() as tape:\n      tape.watch(scalar)\n      y = msssim_func(img[0], img[1], scalar)\n\n    grad = tape.gradient(y, scalar)\n    np_grads = self.evaluate(grad)\n    self.assertTrue(np.isfinite(np_grads).all())\n\n  def testBatch(self):\n    \"\"\"Tests MS-SSIM computed in batch.\"\"\"\n    img = self._LoadTestImages()\n    expected = self._msssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    msssim = image_ops.ssim_multiscale(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(msssim), 1e-4)\n\n  def testBroadcast(self):\n    \"\"\"Tests MS-SSIM broadcasting.\"\"\"\n    img = self._LoadTestImages()[:2]\n    expected = self._msssim[:2, :2]\n\n    img = constant_op.constant(np.concatenate(img))\n    img1 = array_ops.expand_dims(img, axis=0)  # batch dims: 1, 2.\n    img2 = array_ops.expand_dims(img, axis=1)  # batch dims: 2, 1.\n\n    score_tensor = image_ops.ssim_multiscale(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(score_tensor), 1e-4)\n\n  def testRange(self):\n    \"\"\"Tests against low MS-SSIM score.\n\n    MS-SSIM is a geometric mean of SSIM and CS scores of various scales.\n    If any of the value is negative so that the geometric mean is not\n    well-defined, then treat the MS-SSIM score as zero.\n    \"\"\"\n    with self.cached_session() as sess:\n      img1 = self._LoadTestImage(sess, \"checkerboard1.png\")\n      img2 = self._LoadTestImage(sess, \"checkerboard3.png\")\n      images = [img1, img2, np.zeros_like(img1),\n                np.full_like(img1, fill_value=255)]\n\n      images = [ops.convert_to_tensor(x, dtype=dtypes.float32) for x in images]\n      msssim_ops = [\n          image_ops.ssim_multiscale(\n              x, y, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n          for x, y in itertools.combinations(images, 2)\n      ]\n      msssim = self.evaluate(msssim_ops)\n      msssim = np.squeeze(msssim)\n\n    self.assertTrue(np.all(msssim >= 0.0))\n    self.assertTrue(np.all(msssim <= 1.0))\n\n  def testInt(self):\n    img1 = self._RandomImage((1, 180, 240, 3), 255)\n    img2 = self._RandomImage((1, 180, 240, 3), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    ssim_uint8 = image_ops.ssim_multiscale(\n        img1, img2, 255, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    ssim_float32 = image_ops.ssim_multiscale(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(ssim_uint8), self.evaluate(ssim_float32), atol=0.001)\n\n  def testNumpyInput(self):\n    \"\"\"Test case for GitHub issue 28241.\"\"\"\n    image = np.random.random([512, 512, 1])\n    score_tensor = image_ops.ssim_multiscale(image, image, max_val=1.0)\n    with self.cached_session():\n      _ = self.evaluate(score_tensor)\n\n\nclass ImageGradientsTest(test_util.TensorFlowTestCase):\n\n  def testImageGradients(self):\n    shape = [1, 2, 4, 1]\n    img = constant_op.constant([[1, 3, 4, 2], [8, 7, 5, 6]])\n    img = array_ops.reshape(img, shape)\n\n    expected_dy = np.reshape([[7, 4, 1, 4], [0, 0, 0, 0]], shape)\n    expected_dx = np.reshape([[2, 1, -2, 0], [-1, -2, 1, 0]], shape)\n\n    dy, dx = image_ops.image_gradients(img)\n    with self.cached_session():\n      actual_dy = self.evaluate(dy)\n      actual_dx = self.evaluate(dx)\n      self.assertAllClose(expected_dy, actual_dy)\n      self.assertAllClose(expected_dx, actual_dx)\n\n  def testImageGradientsMultiChannelBatch(self):\n    batch = [[[[1, 2], [2, 5], [3, 3]],\n              [[8, 4], [5, 1], [9, 8]]],\n             [[[5, 3], [7, 9], [1, 6]],\n              [[1, 2], [6, 3], [6, 3]]]]\n\n    expected_dy = [[[[7, 2], [3, -4], [6, 5]],\n                    [[0, 0], [0, 0], [0, 0]]],\n                   [[[-4, -1], [-1, -6], [5, -3]],\n                    [[0, 0], [0, 0], [0, 0]]]]\n\n    expected_dx = [[[[1, 3], [1, -2], [0, 0]],\n                    [[-3, -3], [4, 7], [0, 0]]],\n                   [[[2, 6], [-6, -3], [0, 0]],\n                    [[5, 1], [0, 0], [0, 0]]]]\n\n    batch = constant_op.constant(batch)\n    assert batch.get_shape().as_list() == [2, 2, 3, 2]\n    dy, dx = image_ops.image_gradients(batch)\n    with self.cached_session():\n      actual_dy = self.evaluate(dy)\n      actual_dx = self.evaluate(dx)\n      self.assertAllClose(expected_dy, actual_dy)\n      self.assertAllClose(expected_dx, actual_dx)\n\n  def testImageGradientsBadShape(self):\n    # [2 x 4] image but missing batch and depth dimensions.\n    img = constant_op.constant([[1, 3, 4, 2], [8, 7, 5, 6]])\n    with self.assertRaises(ValueError):\n      image_ops.image_gradients(img)\n\n\nclass SobelEdgesTest(test_util.TensorFlowTestCase):\n\n  def disabled_testSobelEdges1x2x3x1(self):\n    img = constant_op.constant([[1, 3, 6], [4, 1, 5]],\n                               dtype=dtypes.float32, shape=[1, 2, 3, 1])\n    expected = np.reshape([[[0, 0], [0, 12], [0, 0]],\n                           [[0, 0], [0, 12], [0, 0]]], [1, 2, 3, 1, 2])\n    sobel = image_ops.sobel_edges(img)\n    with self.cached_session():\n      actual_sobel = self.evaluate(sobel)\n      self.assertAllClose(expected, actual_sobel)\n\n  def testSobelEdges5x3x4x2(self):\n    batch_size = 5\n    plane = np.reshape([[1, 3, 6, 2], [4, 1, 5, 7], [2, 5, 1, 4]],\n                       [1, 3, 4, 1])\n    two_channel = np.concatenate([plane, plane], axis=3)\n    batch = np.concatenate([two_channel] * batch_size, axis=0)\n    img = constant_op.constant(batch, dtype=dtypes.float32,\n                               shape=[batch_size, 3, 4, 2])\n\n    expected_plane = np.reshape([[[0, 0], [0, 12], [0, 10], [0, 0]],\n                                 [[6, 0], [0, 6], [-6, 10], [-6, 0]],\n                                 [[0, 0], [0, 0], [0, 10], [0, 0]]],\n                                [1, 3, 4, 1, 2])\n    expected_two_channel = np.concatenate(\n        [expected_plane, expected_plane], axis=3)\n    expected_batch = np.concatenate([expected_two_channel] * batch_size, axis=0)\n\n    sobel = image_ops.sobel_edges(img)\n    with self.cached_session():\n      actual_sobel = self.evaluate(sobel)\n      self.assertAllClose(expected_batch, actual_sobel)\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass DecodeImageTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  _FORWARD_COMPATIBILITY_HORIZONS = [\n      (2020, 1, 1),\n      (2020, 7, 14),\n      (2525, 1, 1),  # future behavior\n  ]\n\n  def testBmpChannels(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with test_util.use_gpu():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          # `rgba_transparent.bmp` has 4 channels with transparent pixels.\n          # Test consistency between `decode_image` and `decode_bmp` functions.\n          bmp0 = io_ops.read_file(os.path.join(base, \"rgba_small.bmp\"))\n          image0 = image_ops.decode_image(bmp0, channels=4)\n          image1 = image_ops.decode_bmp(bmp0, channels=4)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n          # Test that 3 channels is returned with user request of `channels=3`\n          # even though image has 4 channels.\n          # Note that this operation simply drops 4th channel information. This\n          # is the same behavior as `decode_png`.\n          # e.g. pixel values [25, 25, 25, 100] becomes [25, 25, 25].\n          bmp1 = io_ops.read_file(os.path.join(base, \"rgb_small.bmp\"))\n          image2 = image_ops.decode_bmp(bmp0, channels=3)\n          image3 = image_ops.decode_bmp(bmp1)\n          image2, image3 = self.evaluate([image2, image3])\n          self.assertAllEqual(image2, image3)\n\n          # Test that 4 channels is returned with user request of `channels=4`\n          # even though image has 3 channels. Alpha channel should be set to\n          # UINT8_MAX.\n          bmp3 = io_ops.read_file(os.path.join(base, \"rgb_small_255.bmp\"))\n          bmp4 = io_ops.read_file(os.path.join(base, \"rgba_small_255.bmp\"))\n          image4 = image_ops.decode_bmp(bmp3, channels=4)\n          image5 = image_ops.decode_bmp(bmp4)\n          image4, image5 = self.evaluate([image4, image5])\n          self.assertAllEqual(image4, image5)\n\n          # Test that 3 channels is returned with user request of `channels=3`\n          # even though image has 1 channel (grayscale).\n          bmp6 = io_ops.read_file(os.path.join(base, \"grayscale_small.bmp\"))\n          bmp7 = io_ops.read_file(\n              os.path.join(base, \"grayscale_small_3channels.bmp\"))\n          image6 = image_ops.decode_bmp(bmp6, channels=3)\n          image7 = image_ops.decode_bmp(bmp7)\n          image6, image7 = self.evaluate([image6, image7])\n          self.assertAllEqual(image6, image7)\n\n          # Test that 4 channels is returned with user request of `channels=4`\n          # even though image has 1 channel (grayscale). Alpha channel should be\n          # set to UINT8_MAX.\n          bmp9 = io_ops.read_file(\n              os.path.join(base, \"grayscale_small_4channels.bmp\"))\n          image8 = image_ops.decode_bmp(bmp6, channels=4)\n          image9 = image_ops.decode_bmp(bmp9)\n          image8, image9 = self.evaluate([image8, image9])\n          self.assertAllEqual(image8, image9)\n\n  def testJpegUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/jpeg/testdata\"\n          jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n          image0 = image_ops.decode_image(jpeg0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_jpeg(jpeg0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testPngUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/png/testdata\"\n          png0 = io_ops.read_file(os.path.join(base, \"lena_rgba.png\"))\n          image0 = image_ops.decode_image(png0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(\n              image_ops.decode_png(png0, dtype=dtypes.uint16), dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n          # NumPy conversions should happen before\n          x = np.random.randint(256, size=(4, 4, 3), dtype=np.uint16)\n          x_str = image_ops_impl.encode_png(x)\n          x_dec = image_ops_impl.decode_image(\n              x_str, channels=3, dtype=dtypes.uint16)\n          self.assertAllEqual(x, x_dec)\n\n  def testGifUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n          image0 = image_ops.decode_image(gif0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_gif(gif0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testBmpUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          bmp0 = io_ops.read_file(os.path.join(base, \"lena.bmp\"))\n          image0 = image_ops.decode_image(bmp0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_bmp(bmp0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testJpegFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/jpeg/testdata\"\n          jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n          image0 = image_ops.decode_image(jpeg0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_jpeg(jpeg0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testPngFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/png/testdata\"\n          png0 = io_ops.read_file(os.path.join(base, \"lena_rgba.png\"))\n          image0 = image_ops.decode_image(png0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(\n              image_ops.decode_png(png0, dtype=dtypes.uint16), dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testGifFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n          image0 = image_ops.decode_image(gif0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_gif(gif0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testBmpFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          bmp0 = io_ops.read_file(os.path.join(base, \"lena.bmp\"))\n          image0 = image_ops.decode_image(bmp0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_bmp(bmp0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testExpandAnimations(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n\n          # Test `expand_animations=False` case.\n          image0 = image_ops.decode_image(\n              gif0, dtype=dtypes.float32, expand_animations=False)\n          # image_ops.decode_png() handles GIFs and returns 3D tensors\n          animation = image_ops.decode_gif(gif0)\n          first_frame = array_ops.gather(animation, 0)\n          image1 = image_ops.convert_image_dtype(first_frame, dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertLen(image0.shape, 3)\n          self.assertAllEqual(list(image0.shape), [40, 20, 3])\n          self.assertAllEqual(image0, image1)\n\n          # Test `expand_animations=True` case.\n          image2 = image_ops.decode_image(gif0, dtype=dtypes.float32)\n          image3 = image_ops.convert_image_dtype(animation, dtypes.float32)\n          image2, image3 = self.evaluate([image2, image3])\n          self.assertLen(image2.shape, 4)\n          self.assertAllEqual(list(image2.shape), [12, 40, 20, 3])\n          self.assertAllEqual(image2, image3)\n\n  def testImageCropAndResize(self):\n    if test_util.is_gpu_available():\n      op = image_ops_impl.crop_and_resize_v2(\n          image=array_ops.zeros((2, 1, 1, 1)),\n          boxes=[[1.0e+40, 0, 0, 0]],\n          box_indices=[1],\n          crop_size=[1, 1])\n      self.evaluate(op)\n    else:\n      message = \"Boxes contains at least one element that is not finite\"\n      with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                  message):\n        op = image_ops_impl.crop_and_resize_v2(\n            image=array_ops.zeros((2, 1, 1, 1)),\n            boxes=[[1.0e+40, 0, 0, 0]],\n            box_indices=[1],\n            crop_size=[1, 1])\n        self.evaluate(op)\n\n  @parameterized.named_parameters(\n      (\"_jpeg\", \"JPEG\", \"jpeg_merge_test1.jpg\"),\n      (\"_png\", \"PNG\", \"lena_rgba.png\"),\n      (\"_gif\", \"GIF\", \"scan.gif\"),\n  )\n  def testWrongOpBmp(self, img_format, filename):\n    base_folder = \"tensorflow/core/lib\"\n    base_path = os.path.join(base_folder, img_format.lower(), \"testdata\")\n    err_msg = \"Trying to decode \" + img_format + \" format using DecodeBmp op\"\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img_bytes = io_ops.read_file(os.path.join(base_path, filename))\n      img = image_ops.decode_bmp(img_bytes)\n      self.evaluate(img)\n\n  @parameterized.named_parameters(\n      (\"_jpeg\", image_ops.decode_jpeg, \"DecodeJpeg\"),\n      (\"_png\", image_ops.decode_png, \"DecodePng\"),\n      (\"_gif\", image_ops.decode_gif, \"DecodeGif\"),\n  )\n  def testWrongOp(self, decode_op, op_used):\n    base = \"tensorflow/core/lib/bmp/testdata\"\n    bmp0 = io_ops.read_file(os.path.join(base, \"rgba_small.bmp\"))\n    err_msg = (\"Trying to decode BMP format using a wrong op. Use `decode_bmp` \"\n               \"or `decode_image` instead. Op used: \") + op_used\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img = decode_op(bmp0)\n      self.evaluate(img)\n\n  @parameterized.named_parameters(\n      (\"_png\", \"PNG\", \"lena_rgba.png\"),\n      (\"_gif\", \"GIF\", \"scan.gif\"),\n      (\"_bmp\", \"BMP\", \"rgba_small.bmp\"),\n  )\n  def testWrongOpJpeg(self, img_format, filename):\n    base_folder = \"tensorflow/core/lib\"\n    base_path = os.path.join(base_folder, img_format.lower(), \"testdata\")\n    err_msg = (\"DecodeAndCropJpeg operation can run on JPEG only, but \"\n               \"detected \") + img_format\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img_bytes = io_ops.read_file(os.path.join(base_path, filename))\n      img = image_ops.decode_and_crop_jpeg(img_bytes, [1, 1, 2, 2])\n      self.evaluate(img)\n\n  def testGifFramesWithDiffSize(self):\n    \"\"\"Test decoding an animated GIF.\n\n    This test verifies that `decode_image` op can decode animated GIFs whose\n    first frame does not fill the canvas. The unoccupied areas should be filled\n    with zeros (black).\n\n    `squares.gif` is animated with two images of different sizes. It\n    alternates between a smaller image of size 10 x 10 and a larger image of\n    size 16 x 16. Because it starts animating with the smaller image, the first\n    frame does not fill the canvas. (Canvas size is equal to max frame width x\n    max frame height.)\n\n    `red_black.gif` has just a single image in a GIF format. It is the same\n    image as the smaller image (size 10 x 10) of the two images in\n    `squares.gif`. The only difference is that its background (canvas - smaller\n    image) is pre-filled with zeros (black); it is the groundtruth.\n    \"\"\"\n    base = \"tensorflow/core/lib/gif/testdata\"\n    gif_bytes0 = io_ops.read_file(os.path.join(base, \"squares.gif\"))\n    image0 = image_ops.decode_image(gif_bytes0, dtype=dtypes.float32,\n                                    expand_animations=False)\n    gif_bytes1 = io_ops.read_file(os.path.join(base, \"red_black.gif\"))\n    image1 = image_ops.decode_image(gif_bytes1, dtype=dtypes.float32)\n    image1_0 = array_ops.gather(image1, 0)\n    image0, image1_0 = self.evaluate([image0, image1_0])\n    self.assertAllEqual(image0, image1_0)\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/image_ops.cc\n\n#define EIGEN_USE_THREADS\n\n#include \"tensorflow/core/kernels/image/crop_and_resize_op.h\"\n\n#include <functional>\n#include <string>\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_reference.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/determinism.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/common_runtime/gpu/gpu_event_mgr.h\"\n#include \"tensorflow/core/platform/stream_executor.h\"\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#if GOOGLE_CUDA\n#include \"tensorflow/stream_executor/cuda/cuda_activation.h\"\nusing stream_executor::cuda::ScopedActivateExecutorContext;\n#elif TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/platform/rocm.h\"\nusing stream_executor::rocm::ScopedActivateExecutorContext;\n#endif\n\nnamespace tensorflow {\nnamespace {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\nusing Callback = std::function<void()>;\n\nstatic inline Status ParseAndCheckBoxSizes(const Tensor& boxes,\n                                           const Tensor& box_index,\n                                           int* num_boxes) {\n  if (boxes.NumElements() == 0 && box_index.NumElements() == 0) {\n    *num_boxes = 0;\n    return Status::OK();\n  }\n  // The shape of 'boxes' is [num_boxes, 4].\n  if (boxes.dims() != 2) {\n    return errors::InvalidArgument(\"boxes must be 2-D\",\n                                   boxes.shape().DebugString());\n  }\n  *num_boxes = boxes.dim_size(0);\n  if (boxes.dim_size(1) != 4) {\n    return errors::InvalidArgument(\"boxes must have 4 columns\");\n  }\n  // The shape of 'box_index' is [num_boxes].\n  if (box_index.dims() != 1) {\n    return errors::InvalidArgument(\"box_index must be 1-D\",\n                                   box_index.shape().DebugString());\n  }\n  if (box_index.dim_size(0) != *num_boxes) {\n    return errors::InvalidArgument(\"box_index has incompatible shape\");\n  }\n  return Status::OK();\n}\n\n// Conditionally calls the compute callback if all values in box_index are in\n// [0, batch_size) then calls done.\ntemplate <typename Device>\ninline void RunIfBoxIndexIsValid(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done);\n\n// Specialization of CheckValidBoxIndex for a CPUDevice.\ntemplate <>\ninline void RunIfBoxIndexIsValid<CPUDevice>(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done) {\n  const int num_boxes = box_index.dimension(0);\n  for (int b = 0; b < num_boxes; ++b) {\n    OP_REQUIRES_ASYNC(\n        context, FastBoundsCheck(box_index(b), batch_size),\n        errors::OutOfRange(\"box_index has values outside [0, batch_size)\"),\n        done);\n  }\n  if (compute) {\n    compute();\n  }\n  if (done) {\n    done();\n  }\n}\n\n}  // namespace\n\ntemplate <typename Device, typename T>\nclass CropAndResizeOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method_));\n    OP_REQUIRES(context, method_ == \"bilinear\" || method_ == \"nearest\",\n                errors::InvalidArgument(\n                    \"method must be 'bilinear' or 'nearest'\", method_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"extrapolation_value\",\n                                             &extrapolation_value_));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'image' is [batch_size, image_height, image_width,\n    // channels].\n    const Tensor& image = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(1);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(2);\n    // The shape of 'crop_size' is [2].\n    const Tensor& crop_size = context->input(3);\n\n    // Validate inputs dimensions.\n    OP_REQUIRES_ASYNC(context, image.dims() == 4,\n                      errors::InvalidArgument(\"input image must be 4-D\",\n                                              image.shape().DebugString()),\n                      done);\n    const int batch_size = image.dim_size(0);\n    const int image_height = image.dim_size(1);\n    const int image_width = image.dim_size(2);\n    const int depth = image.dim_size(3);\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n\n    OP_REQUIRES_ASYNC(context, crop_size.dims() == 1,\n                      errors::InvalidArgument(\"crop_size must be 1-D\",\n                                              crop_size.shape().DebugString()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, crop_size.dim_size(0) == 2,\n        errors::InvalidArgument(\"crop_size must have two elements\",\n                                crop_size.shape().DebugString()),\n        done);\n\n    // Copy and validate crop sizes.\n    auto crop_size_vec = crop_size.vec<int32>();\n    const int crop_height = internal::SubtleMustCopy(crop_size_vec(0));\n    const int crop_width = internal::SubtleMustCopy(crop_size_vec(1));\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"crop dimensions must be positive\"), done);\n\n    TensorShape shape;\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(num_boxes), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(crop_height), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(crop_width), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(depth), done);\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, shape, &output),\n                         done);\n\n    auto compute_callback = [this, context, output]() {\n      const Tensor& image = context->input(0);\n      const Tensor& boxes = context->input(1);\n      const Tensor& box_index = context->input(2);\n      const bool status = functor::CropAndResize<Device, T>()(\n          context, image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), method_, extrapolation_value_,\n          output->tensor<float, 4>());\n\n      if (!status) {\n        context->SetStatus(\n            errors::Internal(\"Failed to launch CropAndResizeKernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n\n private:\n  float extrapolation_value_;\n  string method_;\n};\n\n// Partial specialization of CropAndResize functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResize<CPUDevice, T> {\n  bool operator()(OpKernelContext* context,\n                  typename TTypes<T, 4>::ConstTensor image,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  const string& method_name, float extrapolation_value,\n                  typename TTypes<float, 4>::Tensor crops) {\n    const int batch_size = image.dimension(0);\n    const int image_height = image.dimension(1);\n    const int image_width = image.dimension(2);\n\n    const int num_boxes = crops.dimension(0);\n    const int crop_height = crops.dimension(1);\n    const int crop_width = crops.dimension(2);\n    const int depth = crops.dimension(3);\n\n    // Since `functor::CropAndResize` operates on float, we first validate\n    // that we don't overflow (since overflow causes undefined behavior which\n    // could result in segfault in this scenario).\n    const Eigen::Tensor<bool, 0, Eigen::RowMajor> only_finite_elements =\n        boxes.isfinite().all();\n    if (!only_finite_elements()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Boxes contains at least one element that is not finite\"));\n      return false;\n    }\n\n    // Sharding across boxes.\n    auto CropAndResizePerBox = [&](int64_t start_box, int64_t limit_box) {\n      for (int b = start_box; b < limit_box; ++b) {\n        const float y1 = boxes(b, 0);\n        const float x1 = boxes(b, 1);\n        const float y2 = boxes(b, 2);\n        const float x2 = boxes(b, 3);\n\n        const int32_t b_in = box_index(b);\n        if (!FastBoundsCheck(b_in, batch_size)) {\n          continue;\n        }\n\n        const float height_scale =\n            (crop_height > 1)\n                ? (y2 - y1) * (image_height - 1) / (crop_height - 1)\n                : 0;\n        const float width_scale =\n            (crop_width > 1) ? (x2 - x1) * (image_width - 1) / (crop_width - 1)\n                             : 0;\n\n        for (int y = 0; y < crop_height; ++y) {\n          const float in_y = (crop_height > 1)\n                                 ? y1 * (image_height - 1) + y * height_scale\n                                 : 0.5 * (y1 + y2) * (image_height - 1);\n          if (in_y < 0 || in_y > image_height - 1) {\n            for (int x = 0; x < crop_width; ++x) {\n              for (int d = 0; d < depth; ++d) {\n                crops(b, y, x, d) = extrapolation_value;\n              }\n            }\n            continue;\n          }\n          if (method_name == \"bilinear\") {\n            const int top_y_index = floorf(in_y);\n            const int bottom_y_index = ceilf(in_y);\n            const float y_lerp = in_y - top_y_index;\n\n            for (int x = 0; x < crop_width; ++x) {\n              const float in_x = (crop_width > 1)\n                                     ? x1 * (image_width - 1) + x * width_scale\n                                     : 0.5 * (x1 + x2) * (image_width - 1);\n              if (in_x < 0 || in_x > image_width - 1) {\n                for (int d = 0; d < depth; ++d) {\n                  crops(b, y, x, d) = extrapolation_value;\n                }\n                continue;\n              }\n              const int left_x_index = floorf(in_x);\n              const int right_x_index = ceilf(in_x);\n              const float x_lerp = in_x - left_x_index;\n\n              for (int d = 0; d < depth; ++d) {\n                const float top_left(static_cast<float>(\n                    image(b_in, top_y_index, left_x_index, d)));\n                const float top_right(static_cast<float>(\n                    image(b_in, top_y_index, right_x_index, d)));\n                const float bottom_left(static_cast<float>(\n                    image(b_in, bottom_y_index, left_x_index, d)));\n                const float bottom_right(static_cast<float>(\n                    image(b_in, bottom_y_index, right_x_index, d)));\n                const float top = top_left + (top_right - top_left) * x_lerp;\n                const float bottom =\n                    bottom_left + (bottom_right - bottom_left) * x_lerp;\n                crops(b, y, x, d) = top + (bottom - top) * y_lerp;\n              }\n            }\n          } else {  // method == \"nearest\"\n            for (int x = 0; x < crop_width; ++x) {\n              const float in_x = (crop_width > 1)\n                                     ? x1 * (image_width - 1) + x * width_scale\n                                     : 0.5 * (x1 + x2) * (image_width - 1);\n              if (in_x < 0 || in_x > image_width - 1) {\n                for (int d = 0; d < depth; ++d) {\n                  crops(b, y, x, d) = extrapolation_value;\n                }\n                continue;\n              }\n              const int closest_x_index = roundf(in_x);\n              const int closest_y_index = roundf(in_y);\n              for (int d = 0; d < depth; ++d) {\n                crops(b, y, x, d) = static_cast<float>(\n                    image(b_in, closest_y_index, closest_x_index, d));\n              }\n            }\n          }\n        }\n      }\n    };\n\n    // A rough estimation of the cost for each cropped box.\n    double cost_per_pixel =\n        depth * (Eigen::TensorOpCost::AddCost<float>() * 6 +\n                 Eigen::TensorOpCost::MulCost<float>() * 3 +\n                 Eigen::TensorOpCost::CastCost<T, float>() * 4) +\n        (Eigen::TensorOpCost::AddCost<float>() * 2 +\n         Eigen::TensorOpCost::AddCost<float>() * 3);\n    if (method_name == \"nearest\") {\n      cost_per_pixel = depth * Eigen::TensorOpCost::CastCost<T, float>() +\n                       Eigen::TensorOpCost::AddCost<float>() * 4 +\n                       Eigen::TensorOpCost::MulCost<float>() * 4;\n    }\n    const double cost_per_box = crop_height * crop_width * cost_per_pixel;\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n    Shard(worker_threads.num_threads, worker_threads.workers, num_boxes,\n          cost_per_box, CropAndResizePerBox);\n\n    return true;\n  }\n};\n\n}  // namespace functor\n\ntemplate <typename Device, typename T>\nclass CropAndResizeGradImageOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeGradImageOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method_));\n    OP_REQUIRES(context, method_ == \"bilinear\" || method_ == \"nearest\",\n                errors::InvalidArgument(\n                    \"method must be 'bilinear' or 'nearest'\", method_));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'grads' is [num_boxes, crop_height, crop_width, depth].\n    const Tensor& grads = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(1);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(2);\n    // The shape of 'image_size' is [4].\n    const Tensor& image_size = context->input(3);\n\n    // Validate input shapes.\n    OP_REQUIRES_ASYNC(context, grads.dims() == 4,\n                      errors::InvalidArgument(\"grads image must be 4-D\",\n                                              grads.shape().DebugString()),\n                      done);\n    const int crop_height = grads.dim_size(1);\n    const int crop_width = grads.dim_size(2);\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"grads dimensions must be positive\"), done);\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(0) == num_boxes,\n        errors::InvalidArgument(\"boxes and grads have incompatible shape\"),\n        done);\n\n    OP_REQUIRES_ASYNC(context, image_size.dims() == 1,\n                      errors::InvalidArgument(\"image_size must be 1-D\",\n                                              image_size.shape().DebugString()),\n                      done);\n    OP_REQUIRES_ASYNC(context, image_size.dim_size(0) == 4,\n                      errors::InvalidArgument(\"image_size must have 4 elements\",\n                                              image_size.shape().DebugString()),\n                      done);\n    auto image_size_vec = image_size.vec<int32>();\n    const int batch_size = internal::SubtleMustCopy(image_size_vec(0));\n    const int image_height = internal::SubtleMustCopy(image_size_vec(1));\n    const int image_width = internal::SubtleMustCopy(image_size_vec(2));\n    const int depth = internal::SubtleMustCopy(image_size_vec(3));\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(3) == depth,\n        errors::InvalidArgument(\"image_size and grads are incompatible\"), done);\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES_ASYNC(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"Deterministic GPU implementation of CropAndResizeBackpropImage\"\n              \" not available.\"),\n          done);\n    }\n\n    TensorShape shape;\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(batch_size), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(image_height), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(image_width), done);\n    OP_REQUIRES_OK_ASYNC(context, shape.AddDimWithStatus(depth), done);\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, shape, &output),\n                         done);\n\n    auto compute_callback = [this, context, output]() {\n      const Tensor& grads = context->input(0);\n      const Tensor& boxes = context->input(1);\n      const Tensor& box_index = context->input(2);\n      const bool status = functor::CropAndResizeBackpropImage<Device, T>()(\n          context, grads.tensor<float, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), output->tensor<T, 4>(), method_);\n\n      if (!status) {\n        context->SetStatus(errors::Internal(\n            \"Failed to launch CropAndResizeBackpropImage kernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n\n private:\n  string method_;\n};\n\n// Partial specialization of CropAndResizeBackpropImage functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResizeBackpropImage<CPUDevice, T> {\n  bool operator()(const OpKernelContext* context,\n                  typename TTypes<float, 4>::ConstTensor grads,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  typename TTypes<T, 4>::Tensor grads_image,\n                  const string& method_name) {\n    const int batch_size = grads_image.dimension(0);\n    const int image_height = grads_image.dimension(1);\n    const int image_width = grads_image.dimension(2);\n\n    const int num_boxes = grads.dimension(0);\n    const int crop_height = grads.dimension(1);\n    const int crop_width = grads.dimension(2);\n    const int depth = grads.dimension(3);\n\n    grads_image.setZero();\n\n    auto CropAndResizeBackImgPerBox = [&](int64_t start_box,\n                                          int64_t limit_box) {\n      for (int b = start_box; b < limit_box; ++b) {\n        const float y1 = boxes(b, 0);\n        const float x1 = boxes(b, 1);\n        const float y2 = boxes(b, 2);\n        const float x2 = boxes(b, 3);\n\n        const int32_t b_in = box_index(b);\n        if (!FastBoundsCheck(b_in, batch_size)) {\n          continue;\n        }\n\n        const float height_scale =\n            (crop_height > 1)\n                ? (y2 - y1) * (image_height - 1) / (crop_height - 1)\n                : 0;\n        const float width_scale =\n            (crop_width > 1) ? (x2 - x1) * (image_width - 1) / (crop_width - 1)\n                             : 0;\n\n        for (int y = 0; y < crop_height; ++y) {\n          const float in_y = (crop_height > 1)\n                                 ? y1 * (image_height - 1) + y * height_scale\n                                 : 0.5 * (y1 + y2) * (image_height - 1);\n          if (in_y < 0 || in_y > image_height - 1) {\n            continue;\n          }\n          const int top_y_index = floorf(in_y);\n          const int bottom_y_index = ceilf(in_y);\n          const float y_lerp = in_y - top_y_index;\n\n          for (int x = 0; x < crop_width; ++x) {\n            const float in_x = (crop_width > 1)\n                                   ? x1 * (image_width - 1) + x * width_scale\n                                   : 0.5 * (x1 + x2) * (image_width - 1);\n            if (in_x < 0 || in_x > image_width - 1) {\n              continue;\n            }\n\n            if (method_name == \"bilinear\") {\n              const int left_x_index = floorf(in_x);\n              const int right_x_index = ceilf(in_x);\n              const float x_lerp = in_x - left_x_index;\n\n              for (int d = 0; d < depth; ++d) {\n                const float dtop = (1 - y_lerp) * grads(b, y, x, d);\n                grads_image(b_in, top_y_index, left_x_index, d) +=\n                    static_cast<T>((1 - x_lerp) * dtop);\n                grads_image(b_in, top_y_index, right_x_index, d) +=\n                    static_cast<T>(x_lerp * dtop);\n                const float dbottom = y_lerp * grads(b, y, x, d);\n                grads_image(b_in, bottom_y_index, left_x_index, d) +=\n                    static_cast<T>((1 - x_lerp) * dbottom);\n                grads_image(b_in, bottom_y_index, right_x_index, d) +=\n                    static_cast<T>(x_lerp * dbottom);\n              }\n            } else {  // method_name == \"nearest\"\n              for (int d = 0; d < depth; ++d) {\n                int closest_x_index = roundf(in_x);\n                int closest_y_index = roundf(in_y);\n                grads_image(b_in, closest_y_index, closest_x_index, d) +=\n                    static_cast<T>(grads(b, y, x, d));\n              }\n            }\n          }\n        }\n      }\n    };\n\n    // A rough estimation of the cost for each cropped box.\n    // Including calculation cost in the depth loop and pixel loop.\n    const double cost_per_pixel =\n        (method_name == \"bilinear\"\n             ? depth * (Eigen::TensorOpCost::AddCost<float>() * 7 +\n                        Eigen::TensorOpCost::MulCost<float>() * 6 +\n                        Eigen::TensorOpCost::CastCost<T, float>() * 4) +\n                   Eigen::TensorOpCost::AddCost<float>() * 4\n             : depth * (Eigen::TensorOpCost::AddCost<float>() +\n                        Eigen::TensorOpCost::CastCost<T, float>()) +\n                   Eigen::TensorOpCost::AddCost<float>() * 3);\n\n    const double cost_per_box = crop_height * crop_width * cost_per_pixel;\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Sharding introduces nondeterminism when the gradients associated with\n    // more than two crops backprop into the same element in the source image.\n    int max_threads = OpDeterminismRequired() ? 1 : worker_threads.num_threads;\n\n    Shard(max_threads, worker_threads.workers, num_boxes, cost_per_box,\n          CropAndResizeBackImgPerBox);\n\n    return true;\n  }\n};\n\n}  // namespace functor\n\ntemplate <typename Device, typename T>\nclass CropAndResizeGradBoxesOp : public AsyncOpKernel {\n public:\n  explicit CropAndResizeGradBoxesOp(OpKernelConstruction* context)\n      : AsyncOpKernel(context) {\n    string method;\n    OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method));\n    OP_REQUIRES(context, method == \"bilinear\",\n                errors::InvalidArgument(\"method must be 'bilinear'\", method));\n  }\n\n  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {\n    // The shape of 'grads' is [num_boxes, crop_height, crop_width, depth].\n    const Tensor& grads = context->input(0);\n    // The shape of 'boxes' is [num_boxes, 4].\n    const Tensor& boxes = context->input(2);\n    // The shape of 'box_index' is [num_boxes].\n    const Tensor& box_index = context->input(3);\n    // The shape of 'image' is [batch_size, image_height, image_width, depth].\n    const Tensor& image = context->input(1);\n\n    // Validate input shapes.\n    OP_REQUIRES_ASYNC(context, grads.dims() == 4,\n                      errors::InvalidArgument(\"grads image must be 4-D\",\n                                              grads.shape().DebugString()),\n                      done);\n    const int crop_height = grads.dim_size(1);\n    const int crop_width = grads.dim_size(2);\n    const int depth = grads.dim_size(3);\n    OP_REQUIRES_ASYNC(\n        context, crop_height > 0 && crop_width > 0,\n        errors::InvalidArgument(\"grads dimensions must be positive\"), done);\n\n    OP_REQUIRES_ASYNC(context, image.dims() == 4,\n                      errors::InvalidArgument(\"input image must be 4-D\",\n                                              image.shape().DebugString()),\n                      done);\n    const int batch_size = image.dim_size(0);\n    const int image_height = image.dim_size(1);\n    const int image_width = image.dim_size(2);\n    OP_REQUIRES_ASYNC(\n        context, image_height > 0 && image_width > 0,\n        errors::InvalidArgument(\"image dimensions must be positive\"), done);\n    OP_REQUIRES_ASYNC(context, image.dim_size(3) == depth,\n                      errors::InvalidArgument(\"image, grads depth differ\"),\n                      done);\n\n    int num_boxes = 0;\n    OP_REQUIRES_OK_ASYNC(\n        context, ParseAndCheckBoxSizes(boxes, box_index, &num_boxes), done);\n\n    OP_REQUIRES_ASYNC(\n        context, grads.dim_size(0) == num_boxes,\n        errors::InvalidArgument(\"boxes and grads have incompatible shape\"),\n        done);\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES_ASYNC(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"Deterministic GPU implementation of CropAndResizeBackpropBoxes\"\n              \" not available.\"),\n          done);\n    }\n\n    // Allocate output tensor.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->allocate_output(0, TensorShape({num_boxes, 4}), &output),\n        done);\n\n    auto compute_callback = [context, output]() {\n      const Tensor& grads = context->input(0);\n      const Tensor& image = context->input(1);\n      const Tensor& boxes = context->input(2);\n      const Tensor& box_index = context->input(3);\n      const bool status = functor::CropAndResizeBackpropBoxes<Device, T>()(\n          context->eigen_device<Device>(), grads.tensor<float, 4>(),\n          image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n          box_index.tensor<int32, 1>(), output->tensor<float, 2>());\n      if (!status) {\n        context->SetStatus(errors::Internal(\n            \"Failed to launch CropAndResizeBackpropBoxes kernel.\"));\n      }\n    };\n\n    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n                                 batch_size, std::move(compute_callback),\n                                 std::move(done));\n  }\n};\n\n// Partial specialization of CropAndResizeBackpropBoxes functor for a CPUDevice.\nnamespace functor {\ntemplate <typename T>\nstruct CropAndResizeBackpropBoxes<CPUDevice, T> {\n  bool operator()(const CPUDevice& d,\n                  typename TTypes<float, 4>::ConstTensor grads,\n                  typename TTypes<T, 4>::ConstTensor image,\n                  typename TTypes<float, 2>::ConstTensor boxes,\n                  typename TTypes<int32, 1>::ConstTensor box_index,\n                  typename TTypes<float, 2>::Tensor grads_boxes) {\n    const int batch_size = image.dimension(0);\n    const int image_height = image.dimension(1);\n    const int image_width = image.dimension(2);\n\n    const int num_boxes = grads.dimension(0);\n    const int crop_height = grads.dimension(1);\n    const int crop_width = grads.dimension(2);\n    const int depth = grads.dimension(3);\n\n    grads_boxes.setZero();\n\n    for (int b = 0; b < num_boxes; ++b) {\n      const float y1 = boxes(b, 0);\n      const float x1 = boxes(b, 1);\n      const float y2 = boxes(b, 2);\n      const float x2 = boxes(b, 3);\n\n      const int32_t b_in = box_index(b);\n      if (!FastBoundsCheck(b_in, batch_size)) {\n        continue;\n      }\n\n      const float height_ratio =\n          (crop_height > 1)\n              ? static_cast<float>(image_height - 1) / (crop_height - 1)\n              : 0;\n      const float width_ratio =\n          (crop_width > 1)\n              ? static_cast<float>(image_width - 1) / (crop_width - 1)\n              : 0;\n\n      const float height_scale =\n          (crop_height > 1) ? (y2 - y1) * height_ratio : 0;\n      const float width_scale = (crop_width > 1) ? (x2 - x1) * width_ratio : 0;\n\n      for (int y = 0; y < crop_height; ++y) {\n        const float in_y = (crop_height > 1)\n                               ? y1 * (image_height - 1) + y * height_scale\n                               : 0.5 * (y1 + y2) * (image_height - 1);\n        if (in_y < 0 || in_y > image_height - 1) {\n          continue;\n        }\n        const int top_y_index = floorf(in_y);\n        const int bottom_y_index = ceilf(in_y);\n        const float y_lerp = in_y - top_y_index;\n\n        for (int x = 0; x < crop_width; ++x) {\n          const float in_x = (crop_width > 1)\n                                 ? x1 * (image_width - 1) + x * width_scale\n                                 : 0.5 * (x1 + x2) * (image_width - 1);\n          if (in_x < 0 || in_x > image_width - 1) {\n            continue;\n          }\n          const int left_x_index = floorf(in_x);\n          const int right_x_index = ceilf(in_x);\n          const float x_lerp = in_x - left_x_index;\n\n          for (int d = 0; d < depth; ++d) {\n            const float top_left(\n                static_cast<float>(image(b_in, top_y_index, left_x_index, d)));\n            const float top_right(\n                static_cast<float>(image(b_in, top_y_index, right_x_index, d)));\n            const float bottom_left(static_cast<float>(\n                image(b_in, bottom_y_index, left_x_index, d)));\n            const float bottom_right(static_cast<float>(\n                image(b_in, bottom_y_index, right_x_index, d)));\n            // Compute the image gradient.\n            float image_grad_y = (1 - x_lerp) * (bottom_left - top_left) +\n                                 x_lerp * (bottom_right - top_right);\n            float image_grad_x = (1 - y_lerp) * (top_right - top_left) +\n                                 y_lerp * (bottom_right - bottom_left);\n            // Modulate the image gradient with the incoming gradient.\n            const float top_grad = grads(b, y, x, d);\n            image_grad_y *= top_grad;\n            image_grad_x *= top_grad;\n            // dy1, dy2\n            if (crop_height > 1) {\n              grads_boxes(b, 0) +=\n                  image_grad_y * (image_height - 1 - y * height_ratio);\n              grads_boxes(b, 2) += image_grad_y * (y * height_ratio);\n            } else {\n              grads_boxes(b, 0) += image_grad_y * 0.5 * (image_height - 1);\n              grads_boxes(b, 2) += image_grad_y * 0.5 * (image_height - 1);\n            }\n            // dx1, dx2\n            if (crop_width > 1) {\n              grads_boxes(b, 1) +=\n                  image_grad_x * (image_width - 1 - x * width_ratio);\n              grads_boxes(b, 3) += image_grad_x * (x * width_ratio);\n            } else {\n              grads_boxes(b, 1) += image_grad_x * 0.5 * (image_width - 1);\n              grads_boxes(b, 3) += image_grad_x * 0.5 * (image_width - 1);\n            }\n          }\n        }\n      }\n    }\n    return true;\n  }\n};\n\n}  // namespace functor\n\n#define REGISTER_KERNEL(T)                                \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResize\")           \\\n                              .Device(DEVICE_CPU)         \\\n                              .TypeConstraint<T>(\"T\")     \\\n                              .HostMemory(\"crop_size\"),   \\\n                          CropAndResizeOp<CPUDevice, T>); \\\n                                                          \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradBoxes\")  \\\n                              .Device(DEVICE_CPU)         \\\n                              .TypeConstraint<T>(\"T\"),    \\\n                          CropAndResizeGradBoxesOp<CPUDevice, T>);\n\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#define REGISTER_KERNEL(T)                               \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradImage\") \\\n                              .Device(DEVICE_CPU)        \\\n                              .TypeConstraint<T>(\"T\")    \\\n                              .HostMemory(\"image_size\"), \\\n                          CropAndResizeGradImageOp<CPUDevice, T>);\n\nTF_CALL_half(REGISTER_KERNEL);\nTF_CALL_float(REGISTER_KERNEL);\nTF_CALL_double(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n// Forward declaration of the CheckValidBoxIndexHelper specialization for GPU.\nnamespace functor {\ntemplate <>\nvoid CheckValidBoxIndexHelper<GPUDevice>::operator()(\n    const GPUDevice& d, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, typename TTypes<bool, 0>::Tensor isvalid);\nextern template struct CheckValidBoxIndexHelper<GPUDevice>;\n}  // namespace functor\n\nnamespace {\n\n// Specialization of CheckValidBoxIndex for a GPUDevice.\ntemplate <>\ninline void RunIfBoxIndexIsValid<GPUDevice>(\n    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n    int batch_size, const Callback& compute, const Callback& done) {\n  const int num_boxes = box_index.dimension(0);\n  if (num_boxes == 0) {\n    compute();\n    done();\n    return;\n  }\n\n  Tensor isvalid_dev_tensor;\n  OP_REQUIRES_OK_ASYNC(\n      context,\n      context->allocate_temp(DataTypeToEnum<bool>::value, TensorShape({}),\n                             &isvalid_dev_tensor),\n      done);\n  typename TTypes<bool, 0>::Tensor isvalid_dev =\n      isvalid_dev_tensor.tensor<bool, 0>();\n\n  // Run the actual box check on the device.\n  functor::CheckValidBoxIndexHelper<GPUDevice>()(\n      context->eigen_device<GPUDevice>(), box_index, batch_size, isvalid_dev);\n\n  // Copy the result back to the host.\n  auto* stream = context->op_device_context()->stream();\n  OP_REQUIRES_ASYNC(context, stream,\n                    errors::Internal(\"No GPU stream available.\"), done);\n  Tensor isvalid_host_tensor;\n  // Use pinned host memory on the host to avoid unnecessary\n  // synchronization.\n  AllocatorAttributes alloc_attr;\n  alloc_attr.set_on_host(true);\n  alloc_attr.set_gpu_compatible(true);\n  OP_REQUIRES_OK_ASYNC(\n      context,\n      context->allocate_temp(DataTypeToEnum<bool>::value, TensorShape({}),\n                             &isvalid_host_tensor, alloc_attr),\n      done);\n  se::DeviceMemoryBase wrapped(isvalid_dev.data(), sizeof(bool));\n  const bool status =\n      stream\n          ->ThenMemcpy(\n              isvalid_host_tensor.scalar<bool>().data() /* destination */,\n              wrapped /* source */, sizeof(bool))\n          .ok();\n  OP_REQUIRES_ASYNC(\n      context, status,\n      errors::Internal(\"Failed to launch copy of isvalid from device to host.\"),\n      done);\n\n  // We capture both temporary tensors to prevent them from being deallocated\n  // when ComputeAsync returns and before the closure runs.\n  TensorReference isvalid_dev_ref(isvalid_dev_tensor);\n  auto wrapped_callback = [context, isvalid_host_tensor, isvalid_dev_ref,\n                           compute, done]() {\n    auto stream = context->op_device_context()->stream();\n    ScopedActivateExecutorContext scoped_activation{stream->parent()};\n    const bool isvalid = isvalid_host_tensor.scalar<bool>()();\n    isvalid_dev_ref.Unref();\n    OP_REQUIRES_ASYNC(\n        context, isvalid,\n        errors::OutOfRange(\"box_index has values outside [0, batch_size)\"),\n        done);\n    compute();\n    done();\n  };\n\n  context->device()->tensorflow_gpu_device_info()->event_mgr->ThenExecute(\n      stream, wrapped_callback);\n}\n\n}  // namespace\n\n#define REGISTER_KERNEL(T)                                         \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResize\")                    \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\")              \\\n                              .HostMemory(\"crop_size\"),            \\\n                          CropAndResizeOp<GPUDevice, T>);          \\\n                                                                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradImage\")           \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\")              \\\n                              .HostMemory(\"image_size\"),           \\\n                          CropAndResizeGradImageOp<GPUDevice, T>); \\\n                                                                   \\\n  REGISTER_KERNEL_BUILDER(Name(\"CropAndResizeGradBoxes\")           \\\n                              .Device(DEVICE_GPU)                  \\\n                              .TypeConstraint<T>(\"T\"),             \\\n                          CropAndResizeGradBoxesOp<GPUDevice, T>);\n\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_KERNEL);\n\n#undef REGISTER_KERNEL\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for tensorflow.ops.image_ops.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport colorsys\nimport contextlib\nimport functools\nimport itertools\nimport math\nimport os\nimport time\n\nfrom absl.testing import parameterized\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.compat import compat\nfrom tensorflow.python.data.experimental.ops import get_single_element\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import config as tf_config\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import gen_image_ops\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import image_ops_impl\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import random_ops\nfrom tensorflow.python.ops import stateless_random_ops\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import googletest\nfrom tensorflow.python.platform import test\n\n\nclass RGBToHSVTest(test_util.TensorFlowTestCase):\n\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to HSV and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_hsv(batch0)\n        batch2 = image_ops.hsv_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_hsv, split0))\n        split2 = list(map(image_ops.hsv_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1)\n      self.assertAllClose(batch2, join2)\n      self.assertAllClose(batch2, inp)\n\n  def testRGBToHSVRoundTrip(self):\n    data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    for nptype in [np.float32, np.float64]:\n      rgb_np = np.array(data, dtype=nptype).reshape([2, 2, 3]) / 255.\n      with self.cached_session():\n        hsv = image_ops.rgb_to_hsv(rgb_np)\n        rgb = image_ops.hsv_to_rgb(hsv)\n        rgb_tf = self.evaluate(rgb)\n      self.assertAllClose(rgb_tf, rgb_np)\n\n\nclass RGBToYIQTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_without_tensor_float_32(\n      \"Calls rgb_to_yiq and yiq_to_rgb, which use matmul\")\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to YIQ and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_yiq(batch0)\n        batch2 = image_ops.yiq_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_yiq, split0))\n        split2 = list(map(image_ops.yiq_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, join2, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, inp, rtol=1e-4, atol=1e-4)\n\n\nclass RGBToYUVTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_without_tensor_float_32(\n      \"Calls rgb_to_yuv and yuv_to_rgb, which use matmul\")\n  def testBatch(self):\n    # Build an arbitrary RGB image\n    np.random.seed(7)\n    batch_size = 5\n    shape = (batch_size, 2, 7, 3)\n\n    for nptype in [np.float32, np.float64]:\n      inp = np.random.rand(*shape).astype(nptype)\n\n      # Convert to YUV and back, as a batch and individually\n      with self.cached_session():\n        batch0 = constant_op.constant(inp)\n        batch1 = image_ops.rgb_to_yuv(batch0)\n        batch2 = image_ops.yuv_to_rgb(batch1)\n        split0 = array_ops.unstack(batch0)\n        split1 = list(map(image_ops.rgb_to_yuv, split0))\n        split2 = list(map(image_ops.yuv_to_rgb, split1))\n        join1 = array_ops.stack(split1)\n        join2 = array_ops.stack(split2)\n        batch1, batch2, join1, join2 = self.evaluate(\n            [batch1, batch2, join1, join2])\n\n      # Verify that processing batch elements together is the same as separate\n      self.assertAllClose(batch1, join1, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, join2, rtol=1e-4, atol=1e-4)\n      self.assertAllClose(batch2, inp, rtol=1e-4, atol=1e-4)\n\n\nclass GrayscaleToRGBTest(test_util.TensorFlowTestCase):\n\n  def _RGBToGrayscale(self, images):\n    is_batch = True\n    if len(images.shape) == 3:\n      is_batch = False\n      images = np.expand_dims(images, axis=0)\n    out_shape = images.shape[0:3] + (1,)\n    out = np.zeros(shape=out_shape, dtype=np.uint8)\n    for batch in xrange(images.shape[0]):\n      for y in xrange(images.shape[1]):\n        for x in xrange(images.shape[2]):\n          red = images[batch, y, x, 0]\n          green = images[batch, y, x, 1]\n          blue = images[batch, y, x, 2]\n          gray = 0.2989 * red + 0.5870 * green + 0.1140 * blue\n          out[batch, y, x, 0] = int(gray)\n    if not is_batch:\n      out = np.squeeze(out, axis=0)\n    return out\n\n  def _TestRGBToGrayscale(self, x_np):\n    y_np = self._RGBToGrayscale(x_np)\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.rgb_to_grayscale(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBasicRGBToGrayscale(self):\n    # 4-D input with batch dimension.\n    x_np = np.array(\n        [[1, 2, 3], [4, 10, 1]], dtype=np.uint8).reshape([1, 1, 2, 3])\n    self._TestRGBToGrayscale(x_np)\n\n    # 3-D input with no batch dimension.\n    x_np = np.array([[1, 2, 3], [4, 10, 1]], dtype=np.uint8).reshape([1, 2, 3])\n    self._TestRGBToGrayscale(x_np)\n\n  def testBasicGrayscaleToRGB(self):\n    # 4-D input with batch dimension.\n    x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 1, 2, 1])\n    y_np = np.array(\n        [[1, 1, 1], [2, 2, 2]], dtype=np.uint8).reshape([1, 1, 2, 3])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.grayscale_to_rgb(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n    # 3-D input with no batch dimension.\n    x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 2, 1])\n    y_np = np.array([[1, 1, 1], [2, 2, 2]], dtype=np.uint8).reshape([1, 2, 3])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.grayscale_to_rgb(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testGrayscaleToRGBInputValidation(self):\n    # tests whether the grayscale_to_rgb function raises\n    # an exception if the input images' last dimension is\n    # not of size 1, i.e. the images have shape\n    # [batch size, height, width] or [height, width]\n\n    # tests if an exception is raised if a three dimensional\n    # input is used, i.e. the images have shape [batch size, height, width]\n    with self.cached_session():\n      # 3-D input with batch dimension.\n      x_np = np.array([[1, 2]], dtype=np.uint8).reshape([1, 1, 2])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # this is the error message we expect the function to raise\n      err_msg = \"Last dimension of a grayscale image should be size 1\"\n      with self.assertRaisesRegex(ValueError, err_msg):\n        image_ops.grayscale_to_rgb(x_tf)\n\n    # tests if an exception is raised if a two dimensional\n    # input is used, i.e. the images have shape [height, width]\n    with self.cached_session():\n      # 1-D input without batch dimension.\n      x_np = np.array([[1, 2]], dtype=np.uint8).reshape([2])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # this is the error message we expect the function to raise\n      err_msg = \"must be at least two-dimensional\"\n      with self.assertRaisesRegex(ValueError, err_msg):\n        image_ops.grayscale_to_rgb(x_tf)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Shape inference works and produces expected output where possible\n      rgb_shape = [7, None, 19, 3]\n      gray_shape = rgb_shape[:-1] + [1]\n      with self.cached_session():\n        rgb_tf = array_ops.placeholder(dtypes.uint8, shape=rgb_shape)\n        gray = image_ops.rgb_to_grayscale(rgb_tf)\n        self.assertEqual(gray_shape, gray.get_shape().as_list())\n\n      with self.cached_session():\n        gray_tf = array_ops.placeholder(dtypes.uint8, shape=gray_shape)\n        rgb = image_ops.grayscale_to_rgb(gray_tf)\n        self.assertEqual(rgb_shape, rgb.get_shape().as_list())\n\n      # Shape inference does not break for unknown shapes\n      with self.cached_session():\n        rgb_tf_unknown = array_ops.placeholder(dtypes.uint8)\n        gray_unknown = image_ops.rgb_to_grayscale(rgb_tf_unknown)\n        self.assertFalse(gray_unknown.get_shape())\n\n      with self.cached_session():\n        gray_tf_unknown = array_ops.placeholder(dtypes.uint8)\n        rgb_unknown = image_ops.grayscale_to_rgb(gray_tf_unknown)\n        self.assertFalse(rgb_unknown.get_shape())\n\n\nclass AdjustGamma(test_util.TensorFlowTestCase):\n\n  def test_adjust_gamma_less_zero_float32(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 1.0, (8, 8))\n      x_np = np.array(x_data, dtype=np.float32)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image_ops.adjust_gamma(x, gamma=-1)\n\n  def test_adjust_gamma_less_zero_uint8(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 255, (8, 8))\n      x_np = np.array(x_data, dtype=np.uint8)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image_ops.adjust_gamma(x, gamma=-1)\n\n  def test_adjust_gamma_less_zero_tensor(self):\n    \"\"\"White image should be returned for gamma equal to zero\"\"\"\n    with self.cached_session():\n      x_data = np.random.uniform(0, 1.0, (8, 8))\n      x_np = np.array(x_data, dtype=np.float32)\n\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = constant_op.constant(-1.0, dtype=dtypes.float32)\n\n      err_msg = \"Gamma should be a non-negative real number\"\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        image = image_ops.adjust_gamma(x, gamma=y)\n        self.evaluate(image)\n\n  def _test_adjust_gamma_uint8(self, gamma):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for uint8 images\n    \"\"\"\n    with self.cached_session():\n      x_np = np.random.uniform(0, 255, (8, 8)).astype(np.uint8)\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_gamma(x, gamma=gamma)\n      y_tf = np.trunc(self.evaluate(y))\n\n      # calculate gamma correction using numpy\n      # firstly, transform uint8 to float representation\n      # then perform correction\n      y_np = np.power(x_np / 255.0, gamma)\n      # convert correct numpy image back to uint8 type\n      y_np = np.trunc(np.clip(y_np * 255.5, 0, 255.0))\n\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def _test_adjust_gamma_float32(self, gamma):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for float32 images\n    \"\"\"\n    with self.cached_session():\n      x_np = np.random.uniform(0, 1.0, (8, 8))\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_gamma(x, gamma=gamma)\n      y_tf = self.evaluate(y)\n\n      y_np = np.clip(np.power(x_np, gamma), 0, 1.0)\n\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def test_adjust_gamma_one_float32(self):\n    \"\"\"Same image should be returned for gamma equal to one\"\"\"\n    self._test_adjust_gamma_float32(1.0)\n\n  def test_adjust_gamma_one_uint8(self):\n    self._test_adjust_gamma_uint8(1.0)\n\n  def test_adjust_gamma_zero_uint8(self):\n    \"\"\"White image should be returned for gamma equal\n\n    to zero for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=0.0)\n\n  def test_adjust_gamma_less_one_uint8(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to half for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=0.5)\n\n  def test_adjust_gamma_greater_one_uint8(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction for uint8 images\n    \"\"\"\n    self._test_adjust_gamma_uint8(gamma=1.0)\n\n  def test_adjust_gamma_less_one_float32(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to half for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(0.5)\n\n  def test_adjust_gamma_greater_one_float32(self):\n    \"\"\"Verifying the output with expected results for gamma\n\n    correction with gamma equal to two for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(1.0)\n\n  def test_adjust_gamma_zero_float32(self):\n    \"\"\"White image should be returned for gamma equal\n\n    to zero for float32 images\n    \"\"\"\n    self._test_adjust_gamma_float32(0.0)\n\n\nclass AdjustHueTest(test_util.TensorFlowTestCase):\n\n  def testAdjustNegativeHue(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = -0.25\n    y_data = [0, 13, 1, 54, 226, 59, 8, 234, 150, 255, 39, 1]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testAdjustPositiveHue(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = 0.25\n    y_data = [13, 0, 11, 226, 54, 221, 234, 8, 92, 1, 217, 255]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBatchAdjustHue(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    delta = 0.25\n    y_data = [13, 0, 11, 226, 54, 221, 234, 8, 92, 1, 217, 255]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_hue(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def _adjustHueNp(self, x_np, delta_h):\n    self.assertEqual(x_np.shape[-1], 3)\n    x_v = x_np.reshape([-1, 3])\n    y_v = np.ndarray(x_v.shape, dtype=x_v.dtype)\n    channel_count = x_v.shape[0]\n    for i in xrange(channel_count):\n      r = x_v[i][0]\n      g = x_v[i][1]\n      b = x_v[i][2]\n      h, s, v = colorsys.rgb_to_hsv(r, g, b)\n      h += delta_h\n      h = math.fmod(h + 10.0, 1.0)\n      r, g, b = colorsys.hsv_to_rgb(h, s, v)\n      y_v[i][0] = r\n      y_v[i][1] = g\n      y_v[i][2] = b\n    return y_v.reshape(x_np.shape)\n\n  def _adjustHueTf(self, x_np, delta_h):\n    with self.cached_session():\n      x = constant_op.constant(x_np)\n      y = image_ops.adjust_hue(x, delta_h)\n      y_tf = self.evaluate(y)\n    return y_tf\n\n  def testAdjustRandomHue(self):\n    x_shapes = [\n        [2, 2, 3],\n        [4, 2, 3],\n        [2, 4, 3],\n        [2, 5, 3],\n        [1000, 1, 3],\n    ]\n    test_styles = [\n        \"all_random\",\n        \"rg_same\",\n        \"rb_same\",\n        \"gb_same\",\n        \"rgb_same\",\n    ]\n    for x_shape in x_shapes:\n      for test_style in test_styles:\n        x_np = np.random.rand(*x_shape) * 255.\n        delta_h = np.random.rand() * 2.0 - 1.0\n        if test_style == \"all_random\":\n          pass\n        elif test_style == \"rg_same\":\n          x_np[..., 1] = x_np[..., 0]\n        elif test_style == \"rb_same\":\n          x_np[..., 2] = x_np[..., 0]\n        elif test_style == \"gb_same\":\n          x_np[..., 2] = x_np[..., 1]\n        elif test_style == \"rgb_same\":\n          x_np[..., 1] = x_np[..., 0]\n          x_np[..., 2] = x_np[..., 0]\n        else:\n          raise AssertionError(\"Invalid test style: %s\" % (test_style))\n        y_np = self._adjustHueNp(x_np, delta_h)\n        y_tf = self._adjustHueTf(x_np, delta_h)\n        self.assertAllClose(y_tf, y_np, rtol=2e-5, atol=1e-5)\n\n  def testInvalidShapes(self):\n    fused = False\n    if not fused:\n      # The tests are known to pass with the fused adjust_hue. We will enable\n      # them when the fused implementation is the default.\n      return\n    x_np = np.random.rand(2, 3) * 255.\n    delta_h = np.random.rand() * 2.0 - 1.0\n    fused = False\n    with self.assertRaisesRegex(ValueError, \"Shape must be at least rank 3\"):\n      self._adjustHueTf(x_np, delta_h)\n    x_np = np.random.rand(4, 2, 4) * 255.\n    delta_h = np.random.rand() * 2.0 - 1.0\n    with self.assertRaisesOpError(\"input must have 3 channels\"):\n      self._adjustHueTf(x_np, delta_h)\n\n\nclass FlipImageBenchmark(test.Benchmark):\n\n  def _benchmarkFlipLeftRight(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkFlipLeftRight_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkFlipLeftRight_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def _benchmarkRandomFlipLeftRight(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.random_flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkRandomFlipLeftRight_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkRandomFlipLeftRight_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def _benchmarkBatchedRandomFlipLeftRight(self, device, cpu_count):\n    image_shape = [16, 299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with session.Session(\"\", graph=ops.Graph(), config=config) as sess:\n      with ops.device(device):\n        inputs = variables.Variable(\n            random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n            trainable=False,\n            dtype=dtypes.float32)\n        run_op = image_ops.random_flip_left_right(inputs)\n        self.evaluate(variables.global_variables_initializer())\n        for i in xrange(warmup_rounds + benchmark_rounds):\n          if i == warmup_rounds:\n            start = time.time()\n          self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkBatchedRandomFlipLeftRight_16_299_299_3_%s step_time: \"\n          \"%.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkBatchedRandomFlipLeftRight_16_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkFlipLeftRightCpu1(self):\n    self._benchmarkFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkFlipLeftRightCpuAll(self):\n    self._benchmarkFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkFlipLeftRightGpu(self):\n    self._benchmarkFlipLeftRight(test.gpu_device_name(), None)\n\n  def benchmarkRandomFlipLeftRightCpu1(self):\n    self._benchmarkRandomFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkRandomFlipLeftRightCpuAll(self):\n    self._benchmarkRandomFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkRandomFlipLeftRightGpu(self):\n    self._benchmarkRandomFlipLeftRight(test.gpu_device_name(), None)\n\n  def benchmarkBatchedRandomFlipLeftRightCpu1(self):\n    self._benchmarkBatchedRandomFlipLeftRight(\"/cpu:0\", 1)\n\n  def benchmarkBatchedRandomFlipLeftRightCpuAll(self):\n    self._benchmarkBatchedRandomFlipLeftRight(\"/cpu:0\", None)\n\n  def benchmarkBatchedRandomFlipLeftRightGpu(self):\n    self._benchmarkBatchedRandomFlipLeftRight(test.gpu_device_name(), None)\n\n\nclass AdjustHueBenchmark(test.Benchmark):\n\n  def _benchmarkAdjustHue(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with self.benchmark_session(config=config, device=device) as sess:\n      inputs = variables.Variable(\n          random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n          trainable=False,\n          dtype=dtypes.float32)\n      delta = constant_op.constant(0.1, dtype=dtypes.float32)\n      outputs = image_ops.adjust_hue(inputs, delta)\n      run_op = control_flow_ops.group(outputs)\n      self.evaluate(variables.global_variables_initializer())\n      for i in xrange(warmup_rounds + benchmark_rounds):\n        if i == warmup_rounds:\n          start = time.time()\n        self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkAdjustHue_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkAdjustHue_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkAdjustHueCpu1(self):\n    self._benchmarkAdjustHue(\"/cpu:0\", 1)\n\n  def benchmarkAdjustHueCpuAll(self):\n    self._benchmarkAdjustHue(\"/cpu:0\", None)\n\n  def benchmarkAdjustHueGpu(self):\n    self._benchmarkAdjustHue(test.gpu_device_name(), None)\n\n\nclass AdjustSaturationBenchmark(test.Benchmark):\n\n  def _benchmarkAdjustSaturation(self, device, cpu_count):\n    image_shape = [299, 299, 3]\n    warmup_rounds = 100\n    benchmark_rounds = 1000\n    config = config_pb2.ConfigProto()\n    if cpu_count is not None:\n      config.inter_op_parallelism_threads = 1\n      config.intra_op_parallelism_threads = cpu_count\n    with self.benchmark_session(config=config, device=device) as sess:\n      inputs = variables.Variable(\n          random_ops.random_uniform(image_shape, dtype=dtypes.float32) * 255,\n          trainable=False,\n          dtype=dtypes.float32)\n      delta = constant_op.constant(0.1, dtype=dtypes.float32)\n      outputs = image_ops.adjust_saturation(inputs, delta)\n      run_op = control_flow_ops.group(outputs)\n      self.evaluate(variables.global_variables_initializer())\n      for _ in xrange(warmup_rounds):\n        self.evaluate(run_op)\n      start = time.time()\n      for _ in xrange(benchmark_rounds):\n        self.evaluate(run_op)\n    end = time.time()\n    step_time = (end - start) / benchmark_rounds\n    tag = device + \"_%s\" % (cpu_count if cpu_count is not None else \"_all\")\n    print(\"benchmarkAdjustSaturation_299_299_3_%s step_time: %.2f us\" %\n          (tag, step_time * 1e6))\n    self.report_benchmark(\n        name=\"benchmarkAdjustSaturation_299_299_3_%s\" % (tag),\n        iters=benchmark_rounds,\n        wall_time=step_time)\n\n  def benchmarkAdjustSaturationCpu1(self):\n    self._benchmarkAdjustSaturation(\"/cpu:0\", 1)\n\n  def benchmarkAdjustSaturationCpuAll(self):\n    self._benchmarkAdjustSaturation(\"/cpu:0\", None)\n\n  def benchmarkAdjustSaturationGpu(self):\n    self._benchmarkAdjustSaturation(test.gpu_device_name(), None)\n\n\nclass ResizeBilinearBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_bilinear(\n            img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          name=(\"resize_bilinear_%s_%s_%s\" % (image_size[0], image_size[1],\n                                              num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n\nclass ResizeBicubicBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_bicubic(\n            img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          min_iters=20,\n          name=(\"resize_bicubic_%s_%s_%s\" % (image_size[0], image_size[1],\n                                             num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n  def benchmarkSimilar4Channel(self):\n    self._benchmarkResize((183, 229), 4)\n\n  def benchmarkScaleUp4Channel(self):\n    self._benchmarkResize((141, 186), 4)\n\n  def benchmarkScaleDown4Channel(self):\n    self._benchmarkResize((749, 603), 4)\n\n\nclass ResizeAreaBenchmark(test.Benchmark):\n\n  def _benchmarkResize(self, image_size, num_channels):\n    batch_size = 1\n    num_ops = 1000\n    img = variables.Variable(\n        random_ops.random_normal(\n            [batch_size, image_size[0], image_size[1], num_channels]),\n        name=\"img\")\n\n    deps = []\n    for _ in xrange(num_ops):\n      with ops.control_dependencies(deps):\n        resize_op = image_ops.resize_area(img, [299, 299], align_corners=False)\n        deps = [resize_op]\n      benchmark_op = control_flow_ops.group(*deps)\n\n    with self.benchmark_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      results = self.run_op_benchmark(\n          sess,\n          benchmark_op,\n          name=(\"resize_area_%s_%s_%s\" % (image_size[0], image_size[1],\n                                          num_channels)))\n      print(\"%s   : %.2f ms/img\" %\n            (results[\"name\"],\n             1000 * results[\"wall_time\"] / (batch_size * num_ops)))\n\n  def benchmarkSimilar3Channel(self):\n    self._benchmarkResize((183, 229), 3)\n\n  def benchmarkScaleUp3Channel(self):\n    self._benchmarkResize((141, 186), 3)\n\n  def benchmarkScaleDown3Channel(self):\n    self._benchmarkResize((749, 603), 3)\n\n  def benchmarkSimilar1Channel(self):\n    self._benchmarkResize((183, 229), 1)\n\n  def benchmarkScaleUp1Channel(self):\n    self._benchmarkResize((141, 186), 1)\n\n  def benchmarkScaleDown1Channel(self):\n    self._benchmarkResize((749, 603), 1)\n\n\nclass AdjustSaturationTest(test_util.TensorFlowTestCase):\n\n  def testHalfSaturation(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 0.5\n    y_data = [6, 9, 13, 140, 180, 226, 135, 121, 234, 172, 255, 128]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testTwiceSaturation(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 2.0\n    y_data = [0, 5, 13, 0, 106, 226, 30, 0, 234, 89, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testBatchSaturation(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    saturation_factor = 0.5\n    y_data = [6, 9, 13, 140, 180, 226, 135, 121, 234, 172, 255, 128]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.adjust_saturation(x, saturation_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def _adjustSaturationNp(self, x_np, scale):\n    self.assertEqual(x_np.shape[-1], 3)\n    x_v = x_np.reshape([-1, 3])\n    y_v = np.ndarray(x_v.shape, dtype=x_v.dtype)\n    channel_count = x_v.shape[0]\n    for i in xrange(channel_count):\n      r = x_v[i][0]\n      g = x_v[i][1]\n      b = x_v[i][2]\n      h, s, v = colorsys.rgb_to_hsv(r, g, b)\n      s *= scale\n      s = min(1.0, max(0.0, s))\n      r, g, b = colorsys.hsv_to_rgb(h, s, v)\n      y_v[i][0] = r\n      y_v[i][1] = g\n      y_v[i][2] = b\n    return y_v.reshape(x_np.shape)\n\n  def testAdjustRandomSaturation(self):\n    x_shapes = [\n        [2, 2, 3],\n        [4, 2, 3],\n        [2, 4, 3],\n        [2, 5, 3],\n        [1000, 1, 3],\n    ]\n    test_styles = [\n        \"all_random\",\n        \"rg_same\",\n        \"rb_same\",\n        \"gb_same\",\n        \"rgb_same\",\n    ]\n    with self.cached_session():\n      for x_shape in x_shapes:\n        for test_style in test_styles:\n          x_np = np.random.rand(*x_shape) * 255.\n          scale = np.random.rand()\n          if test_style == \"all_random\":\n            pass\n          elif test_style == \"rg_same\":\n            x_np[..., 1] = x_np[..., 0]\n          elif test_style == \"rb_same\":\n            x_np[..., 2] = x_np[..., 0]\n          elif test_style == \"gb_same\":\n            x_np[..., 2] = x_np[..., 1]\n          elif test_style == \"rgb_same\":\n            x_np[..., 1] = x_np[..., 0]\n            x_np[..., 2] = x_np[..., 0]\n          else:\n            raise AssertionError(\"Invalid test style: %s\" % (test_style))\n          y_baseline = self._adjustSaturationNp(x_np, scale)\n          y_fused = self.evaluate(image_ops.adjust_saturation(x_np, scale))\n          self.assertAllClose(y_fused, y_baseline, rtol=2e-5, atol=1e-5)\n\n\nclass FlipTransposeRotateTest(test_util.TensorFlowTestCase,\n                              parameterized.TestCase):\n\n  def testInvolutionLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(image_ops.flip_left_right(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionLeftRightWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(image_ops.flip_left_right(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testLeftRightWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    y_np = np.array(\n        [[[3, 2, 1], [3, 2, 1]], [[3, 2, 1], [3, 2, 1]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_left_right(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testRandomFlipLeftRightStateful(self):\n    # Test random flip with single seed (stateful).\n    with ops.Graph().as_default():\n      x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n      seed = 42\n\n      with self.cached_session():\n        x_tf = constant_op.constant(x_np, shape=x_np.shape)\n        y = image_ops.random_flip_left_right(x_tf, seed=seed)\n        self.assertTrue(y.op.name.startswith(\"random_flip_left_right\"))\n\n        count_flipped = 0\n        count_unflipped = 0\n        for _ in range(100):\n          y_tf = self.evaluate(y)\n          if y_tf[0][0] == 1:\n            self.assertAllEqual(y_tf, x_np)\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf, y_np)\n            count_flipped += 1\n\n        # 100 trials\n        # Mean: 50\n        # Std Dev: ~5\n        # Six Sigma: 50 - (5 * 6) = 20\n        self.assertGreaterEqual(count_flipped, 20)\n        self.assertGreaterEqual(count_unflipped, 20)\n\n  def testRandomFlipLeftRight(self):\n    x_np = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[3, 2, 1], [3, 2, 1]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_left_right(x_tf, seed=seed))\n        if y_tf[0][0] == 1:\n          self.assertAllEqual(y_tf, x_np)\n          count_unflipped += 1\n        else:\n          self.assertAllEqual(y_tf, y_np)\n          count_flipped += 1\n\n      self.assertEqual(count_flipped, 45)\n      self.assertEqual(count_unflipped, 55)\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  @parameterized.named_parameters(\n      (\"_RandomFlipLeftRight\", image_ops.stateless_random_flip_left_right),\n      (\"_RandomFlipUpDown\", image_ops.stateless_random_flip_up_down),\n  )\n  def testRandomFlipStateless(self, func):\n    with test_util.use_gpu():\n      x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[3, 2, 1], [6, 5, 4]], dtype=np.uint8).reshape([2, 3, 1])\n      if \"RandomFlipUpDown\" in self.id():\n        y_np = np.array(\n            [[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      iterations = 2\n      flip_counts = [None for _ in range(iterations)]\n      flip_sequences = [\"\" for _ in range(iterations)]\n      test_seed = (1, 2)\n      split_seeds = stateless_random_ops.split(test_seed, 10)\n      seeds_list = self.evaluate(split_seeds)\n      for i in range(iterations):\n        count_flipped = 0\n        count_unflipped = 0\n        flip_seq = \"\"\n        for seed in seeds_list:\n          y_tf = func(x_tf, seed=seed)\n          y_tf_eval = self.evaluate(y_tf)\n          if y_tf_eval[0][0] == 1:\n            self.assertAllEqual(y_tf_eval, x_np)\n            count_unflipped += 1\n            flip_seq += \"U\"\n          else:\n            self.assertAllEqual(y_tf_eval, y_np)\n            count_flipped += 1\n            flip_seq += \"F\"\n\n        flip_counts[i] = (count_flipped, count_unflipped)\n        flip_sequences[i] = flip_seq\n\n      # Verify that results are deterministic.\n      for i in range(1, iterations):\n        self.assertAllEqual(flip_counts[0], flip_counts[i])\n        self.assertAllEqual(flip_sequences[0], flip_sequences[i])\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  @parameterized.named_parameters(\n      (\"_RandomFlipLeftRight\", image_ops.stateless_random_flip_left_right),\n      (\"_RandomFlipUpDown\", image_ops.stateless_random_flip_up_down)\n  )\n  def testRandomFlipStatelessWithBatch(self, func):\n    with test_util.use_gpu():\n      batch_size = 16\n\n      # create single item of test data\n      x_np_raw = np.array(\n          [[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([1, 2, 3, 1])\n      y_np_raw = np.array(\n          [[3, 2, 1], [6, 5, 4]], dtype=np.uint8).reshape([1, 2, 3, 1])\n      if \"RandomFlipUpDown\" in self.id():\n        y_np_raw = np.array(\n            [[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([1, 2, 3, 1])\n\n      # create batched test data\n      x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n      y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      iterations = 2\n      flip_counts = [None for _ in range(iterations)]\n      flip_sequences = [\"\" for _ in range(iterations)]\n      test_seed = (1, 2)\n      split_seeds = stateless_random_ops.split(test_seed, 10)\n      seeds_list = self.evaluate(split_seeds)\n      for i in range(iterations):\n        count_flipped = 0\n        count_unflipped = 0\n        flip_seq = \"\"\n        for seed in seeds_list:\n          y_tf = func(x_tf, seed=seed)\n          y_tf_eval = self.evaluate(y_tf)\n          for j in range(batch_size):\n            if y_tf_eval[j][0][0] == 1:\n              self.assertAllEqual(y_tf_eval[j], x_np[j])\n              count_unflipped += 1\n              flip_seq += \"U\"\n            else:\n              self.assertAllEqual(y_tf_eval[j], y_np[j])\n              count_flipped += 1\n              flip_seq += \"F\"\n\n        flip_counts[i] = (count_flipped, count_unflipped)\n        flip_sequences[i] = flip_seq\n\n      for i in range(1, iterations):\n        self.assertAllEqual(flip_counts[0], flip_counts[i])\n        self.assertAllEqual(flip_sequences[0], flip_sequences[i])\n\n  def testRandomFlipLeftRightWithBatch(self):\n    batch_size = 16\n    seed = 42\n\n    # create single item of test data\n    x_np_raw = np.array(\n        [[1, 2, 3], [1, 2, 3]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n    y_np_raw = np.array(\n        [[3, 2, 1], [3, 2, 1]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n\n    # create batched test data\n    x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n    y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_left_right(x_tf, seed=seed))\n\n        # check every element of the batch\n        for i in range(batch_size):\n          if y_tf[i][0][0] == 1:\n            self.assertAllEqual(y_tf[i], x_np[i])\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf[i], y_np[i])\n            count_flipped += 1\n\n      self.assertEqual(count_flipped, 772)\n      self.assertEqual(count_unflipped, 828)\n\n  def testInvolutionUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(image_ops.flip_up_down(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionUpDownWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(image_ops.flip_up_down(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testUpDownWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n    y_np = np.array(\n        [[[4, 5, 6], [1, 2, 3]], [[10, 11, 12], [7, 8, 9]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.flip_up_down(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testRandomFlipUpDownStateful(self):\n    # Test random flip with single seed (stateful).\n    with ops.Graph().as_default():\n      x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n      y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n      seed = 42\n\n      with self.cached_session():\n        x_tf = constant_op.constant(x_np, shape=x_np.shape)\n        y = image_ops.random_flip_up_down(x_tf, seed=seed)\n        self.assertTrue(y.op.name.startswith(\"random_flip_up_down\"))\n        count_flipped = 0\n        count_unflipped = 0\n        for _ in range(100):\n          y_tf = self.evaluate(y)\n          if y_tf[0][0] == 1:\n            self.assertAllEqual(y_tf, x_np)\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf, y_np)\n            count_flipped += 1\n\n        # 100 trials\n        # Mean: 50\n        # Std Dev: ~5\n        # Six Sigma: 50 - (5 * 6) = 20\n        self.assertGreaterEqual(count_flipped, 20)\n        self.assertGreaterEqual(count_unflipped, 20)\n\n  def testRandomFlipUpDown(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[4, 5, 6], [1, 2, 3]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_up_down(x_tf, seed=seed))\n        if y_tf[0][0] == 1:\n          self.assertAllEqual(y_tf, x_np)\n          count_unflipped += 1\n        else:\n          self.assertAllEqual(y_tf, y_np)\n          count_flipped += 1\n\n      self.assertEqual(count_flipped, 45)\n      self.assertEqual(count_unflipped, 55)\n\n  def testRandomFlipUpDownWithBatch(self):\n    batch_size = 16\n    seed = 42\n\n    # create single item of test data\n    x_np_raw = np.array(\n        [[1, 2, 3], [4, 5, 6]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n    y_np_raw = np.array(\n        [[4, 5, 6], [1, 2, 3]], dtype=np.uint8\n    ).reshape([1, 2, 3, 1])\n\n    # create batched test data\n    x_np = np.vstack([x_np_raw for _ in range(batch_size)])\n    y_np = np.vstack([y_np_raw for _ in range(batch_size)])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      count_flipped = 0\n      count_unflipped = 0\n      for seed in range(100):\n        y_tf = self.evaluate(image_ops.random_flip_up_down(x_tf, seed=seed))\n\n        # check every element of the batch\n        for i in range(batch_size):\n          if y_tf[i][0][0] == 1:\n            self.assertAllEqual(y_tf[i], x_np[i])\n            count_unflipped += 1\n          else:\n            self.assertAllEqual(y_tf[i], y_np[i])\n            count_flipped += 1\n\n      self.assertEqual(count_flipped, 772)\n      self.assertEqual(count_unflipped, 828)\n\n  def testInvolutionTranspose(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(image_ops.transpose(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testInvolutionTransposeWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(image_ops.transpose(x_tf))\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, x_np)\n\n  def testTranspose(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.uint8).reshape([2, 3, 1])\n    y_np = np.array([[1, 4], [2, 5], [3, 6]], dtype=np.uint8).reshape([3, 2, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testTransposeWithBatch(self):\n    x_np = np.array(\n        [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]],\n        dtype=np.uint8).reshape([2, 2, 3, 1])\n\n    y_np = np.array(\n        [[[1, 4], [2, 5], [3, 6]], [[7, 10], [8, 11], [9, 12]]],\n        dtype=np.uint8).reshape([2, 3, 2, 1])\n\n    with self.cached_session():\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.transpose(x_tf)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n\n  def testPartialShapes(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      p_unknown_rank = array_ops.placeholder(dtypes.uint8)\n      p_unknown_dims_3 = array_ops.placeholder(\n          dtypes.uint8, shape=[None, None, None])\n      p_unknown_dims_4 = array_ops.placeholder(\n          dtypes.uint8, shape=[None, None, None, None])\n      p_unknown_width = array_ops.placeholder(dtypes.uint8, shape=[64, None, 3])\n      p_unknown_batch = array_ops.placeholder(\n          dtypes.uint8, shape=[None, 64, 64, 3])\n      p_wrong_rank = array_ops.placeholder(dtypes.uint8, shape=[None, None])\n      p_zero_dim = array_ops.placeholder(dtypes.uint8, shape=[64, 0, 3])\n\n      #Ops that support 3D input\n      for op in [\n          image_ops.flip_left_right, image_ops.flip_up_down,\n          image_ops.random_flip_left_right, image_ops.random_flip_up_down,\n          image_ops.transpose, image_ops.rot90\n      ]:\n        transformed_unknown_rank = op(p_unknown_rank)\n        self.assertIsNone(transformed_unknown_rank.get_shape().ndims)\n        transformed_unknown_dims_3 = op(p_unknown_dims_3)\n        self.assertEqual(3, transformed_unknown_dims_3.get_shape().ndims)\n        transformed_unknown_width = op(p_unknown_width)\n        self.assertEqual(3, transformed_unknown_width.get_shape().ndims)\n\n        with self.assertRaisesRegex(ValueError, \"must be > 0\"):\n          op(p_zero_dim)\n\n      #Ops that support 4D input\n      for op in [\n          image_ops.flip_left_right, image_ops.flip_up_down,\n          image_ops.random_flip_left_right, image_ops.random_flip_up_down,\n          image_ops.transpose, image_ops.rot90\n      ]:\n        transformed_unknown_dims_4 = op(p_unknown_dims_4)\n        self.assertEqual(4, transformed_unknown_dims_4.get_shape().ndims)\n        transformed_unknown_batch = op(p_unknown_batch)\n        self.assertEqual(4, transformed_unknown_batch.get_shape().ndims)\n        with self.assertRaisesRegex(ValueError,\n                                    \"must be at least three-dimensional\"):\n          op(p_wrong_rank)\n\n  def testRot90GroupOrder(self):\n    image = np.arange(24, dtype=np.uint8).reshape([2, 4, 3])\n    with self.cached_session():\n      rotated = image\n      for _ in xrange(4):\n        rotated = image_ops.rot90(rotated)\n      self.assertAllEqual(image, self.evaluate(rotated))\n\n  def testRot90GroupOrderWithBatch(self):\n    image = np.arange(48, dtype=np.uint8).reshape([2, 2, 4, 3])\n    with self.cached_session():\n      rotated = image\n      for _ in xrange(4):\n        rotated = image_ops.rot90(rotated)\n      self.assertAllEqual(image, self.evaluate(rotated))\n\n  def testRot90NumpyEquivalence(self):\n    image = np.arange(24, dtype=np.uint8).reshape([2, 4, 3])\n    with self.cached_session():\n      for k in xrange(4):\n        y_np = np.rot90(image, k=k)\n        self.assertAllEqual(\n            y_np, self.evaluate(image_ops.rot90(image, k)))\n\n  def testRot90NumpyEquivalenceWithBatch(self):\n    image = np.arange(48, dtype=np.uint8).reshape([2, 2, 4, 3])\n    with self.cached_session():\n      for k in xrange(4):\n        y_np = np.rot90(image, k=k, axes=(1, 2))\n        self.assertAllEqual(\n            y_np, self.evaluate(image_ops.rot90(image, k)))\n\n  def testFlipImageUnknownShape(self):\n    expected_output = constant_op.constant([[[[3, 4, 5], [0, 1, 2]],\n                                             [[9, 10, 11], [6, 7, 8]]]])\n\n    def generator():\n      image_input = np.array(\n          [[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]], np.int32)\n      yield image_input\n\n    dataset = dataset_ops.Dataset.from_generator(\n        generator,\n        output_types=dtypes.int32,\n        output_shapes=tensor_shape.TensorShape([1, 2, 2, 3]))\n    dataset = dataset.map(image_ops.flip_left_right)\n\n    image_flipped_via_dataset_map = get_single_element.get_single_element(\n        dataset.take(1))\n    self.assertAllEqual(image_flipped_via_dataset_map, expected_output)\n\n\nclass AdjustContrastTest(test_util.TensorFlowTestCase):\n\n  def _testContrast(self, x_np, y_np, contrast_factor):\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_contrast(x, contrast_factor)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, 1e-6)\n\n  def testDoubleContrastUint8(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 0, 62, 169, 255, 28, 0, 255, 135, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def testDoubleContrastFloat(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float64).reshape(x_shape) / 255.\n\n    y_data = [\n        -45.25, -90.75, -92.5, 62.75, 169.25, 333.5, 28.75, -84.75, 349.5,\n        134.75, 409.25, -116.5\n    ]\n    y_np = np.array(y_data, dtype=np.float64).reshape(x_shape) / 255.\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def testHalfContrastUint8(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [22, 52, 65, 49, 118, 172, 41, 54, 176, 67, 178, 59]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=0.5)\n\n  def testBatchDoubleContrast(self):\n    x_shape = [2, 1, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 0, 81, 200, 255, 10, 0, 255, 116, 255, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testContrast(x_np, y_np, contrast_factor=2.0)\n\n  def _adjustContrastNp(self, x_np, contrast_factor):\n    mean = np.mean(x_np, (1, 2), keepdims=True)\n    y_np = mean + contrast_factor * (x_np - mean)\n    return y_np\n\n  def _adjustContrastTf(self, x_np, contrast_factor):\n    with self.cached_session():\n      x = constant_op.constant(x_np)\n      y = image_ops.adjust_contrast(x, contrast_factor)\n      y_tf = self.evaluate(y)\n    return y_tf\n\n  def testRandomContrast(self):\n    x_shapes = [\n        [1, 2, 2, 3],\n        [2, 1, 2, 3],\n        [1, 2, 2, 3],\n        [2, 5, 5, 3],\n        [2, 1, 1, 3],\n    ]\n    for x_shape in x_shapes:\n      x_np = np.random.rand(*x_shape) * 255.\n      contrast_factor = np.random.rand() * 2.0 + 0.1\n      y_np = self._adjustContrastNp(x_np, contrast_factor)\n      y_tf = self._adjustContrastTf(x_np, contrast_factor)\n      self.assertAllClose(y_tf, y_np, rtol=1e-5, atol=1e-5)\n\n  def testContrastFactorShape(self):\n    x_shape = [1, 2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"contrast_factor must be scalar|\"\n                                \"Shape must be rank 0 but is rank 1\"):\n      image_ops.adjust_contrast(x_np, [2.0])\n\n  @test_util.run_all_in_graph_and_eager_modes\n  def testDeterminismUnimplementedExceptionThrowing(self):\n    \"\"\"Test d9m-unimplemented exception-throwing when op-determinism is enabled.\n\n    This test depends upon other tests, tests which do not enable\n    op-determinism, to ensure that determinism-unimplemented exceptions are not\n    erroneously thrown when op-determinism is not enabled.\n    \"\"\"\n    if test_util.is_xla_enabled():\n      self.skipTest('XLA implementation does not raise exception')\n    with self.session(), test_util.deterministic_ops():\n      input_shape = (1, 2, 2, 1)\n      on_gpu = len(tf_config.list_physical_devices(\"GPU\"))\n      # AdjustContrast seems to now be inaccessible via the Python API.\n      # AdjustContrastv2 only supports float16 and float32 on GPU, and other\n      # types are converted to and from float32 at the Python level before\n      # AdjustContrastv2 is called.\n      dtypes_to_test = [\n          dtypes.uint8, dtypes.int8, dtypes.int16, dtypes.int32, dtypes.float32,\n          dtypes.float64\n      ]\n      if on_gpu:\n        dtypes_to_test.append(dtypes.float16)\n        ctx_mgr = self.assertRaisesRegex(\n            errors.UnimplementedError,\n            \"A deterministic GPU implementation of AdjustContrastv2 is not\" +\n            \" currently available.\")\n      else:\n        ctx_mgr = contextlib.suppress()\n      for dtype in dtypes_to_test:\n        input_images = array_ops.zeros(input_shape, dtype=dtype)\n        contrast_factor = 1.\n        with ctx_mgr:\n          output_images = image_ops.adjust_contrast(input_images,\n                                                    contrast_factor)\n          self.evaluate(output_images)\n\n\nclass AdjustBrightnessTest(test_util.TensorFlowTestCase):\n\n  def _testBrightness(self, x_np, y_np, delta, tol=1e-6):\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_np.shape)\n      y = image_ops.adjust_brightness(x, delta)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, tol)\n\n  def testPositiveDeltaUint8(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 255, 11]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testBrightness(x_np, y_np, delta=10. / 255.)\n\n  def testPositiveDeltaFloat32(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float32).reshape(x_shape) / 255.\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 265, 11]\n    y_np = np.array(y_data, dtype=np.float32).reshape(x_shape) / 255.\n\n    self._testBrightness(x_np, y_np, delta=10. / 255.)\n\n  def testPositiveDeltaFloat16(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.float16).reshape(x_shape) / 255.\n\n    y_data = [10, 15, 23, 64, 145, 236, 47, 18, 244, 100, 265, 11]\n    y_np = np.array(y_data, dtype=np.float16).reshape(x_shape) / 255.\n\n    self._testBrightness(x_np, y_np, delta=10. / 255., tol=1e-3)\n\n  def testNegativeDelta(self):\n    x_shape = [2, 2, 3]\n    x_data = [0, 5, 13, 54, 135, 226, 37, 8, 234, 90, 255, 1]\n    x_np = np.array(x_data, dtype=np.uint8).reshape(x_shape)\n\n    y_data = [0, 0, 3, 44, 125, 216, 27, 0, 224, 80, 245, 0]\n    y_np = np.array(y_data, dtype=np.uint8).reshape(x_shape)\n\n    self._testBrightness(x_np, y_np, delta=-10. / 255.)\n\n\nclass PerImageWhiteningTest(test_util.TensorFlowTestCase,\n                            parameterized.TestCase):\n\n  def _NumpyPerImageWhitening(self, x):\n    num_pixels = np.prod(x.shape)\n    mn = np.mean(x)\n    std = np.std(x)\n    stddev = max(std, 1.0 / math.sqrt(num_pixels))\n\n    y = x.astype(np.float32)\n    y -= mn\n    y /= stddev\n    return y\n\n  @parameterized.named_parameters([(\"_int8\", np.int8), (\"_int16\", np.int16),\n                                   (\"_int32\", np.int32), (\"_int64\", np.int64),\n                                   (\"_uint8\", np.uint8), (\"_uint16\", np.uint16),\n                                   (\"_uint32\", np.uint32),\n                                   (\"_uint64\", np.uint64),\n                                   (\"_float32\", np.float32)])\n  def testBasic(self, data_type):\n    x_shape = [13, 9, 3]\n    x_np = np.arange(0, np.prod(x_shape), dtype=data_type).reshape(x_shape)\n    y_np = self._NumpyPerImageWhitening(x_np)\n\n    with self.cached_session():\n      x = constant_op.constant(x_np, dtype=data_type, shape=x_shape)\n      y = image_ops.per_image_standardization(x)\n      y_tf = self.evaluate(y)\n      self.assertAllClose(y_tf, y_np, atol=1e-4)\n\n  def testUniformImage(self):\n    im_np = np.ones([19, 19, 3]).astype(np.float32) * 249\n    im = constant_op.constant(im_np)\n    whiten = image_ops.per_image_standardization(im)\n    with self.cached_session():\n      whiten_np = self.evaluate(whiten)\n      self.assertFalse(np.any(np.isnan(whiten_np)))\n\n  def testBatchWhitening(self):\n    imgs_np = np.random.uniform(0., 255., [4, 24, 24, 3])\n    whiten_np = [self._NumpyPerImageWhitening(img) for img in imgs_np]\n    with self.cached_session():\n      imgs = constant_op.constant(imgs_np)\n      whiten = image_ops.per_image_standardization(imgs)\n      whiten_tf = self.evaluate(whiten)\n      for w_tf, w_np in zip(whiten_tf, whiten_np):\n        self.assertAllClose(w_tf, w_np, atol=1e-4)\n\n\nclass CropToBoundingBoxTest(test_util.TensorFlowTestCase):\n\n  def _CropToBoundingBox(self, x, offset_height, offset_width, target_height,\n                         target_width, use_tensor_inputs):\n    if use_tensor_inputs:\n      offset_height = ops.convert_to_tensor(offset_height)\n      offset_width = ops.convert_to_tensor(offset_width)\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    y = image_ops.crop_to_bounding_box(x_tensor, offset_height, offset_width,\n                                       target_height, target_width)\n\n    with self.cached_session():\n      return self.evaluate(y)\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     offset_height,\n                     offset_width,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._CropToBoundingBox(x, offset_height, offset_width,\n                                     target_height, target_width,\n                                     use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    offset_height,\n                    offset_width,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._CropToBoundingBox(x, offset_height, offset_width, target_height,\n                                target_width, use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.crop_to_bounding_box(image, 0, 0, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n    self._assertReturns(x, x_shape, 0, 0, x, x_shape)\n\n  def testCrop(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    offset_height, offset_width = [1, 0]\n    y_shape = [2, 3, 1]\n    y = [4, 5, 6, 7, 8, 9]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 1]\n    y_shape = [3, 2, 1]\n    y = [2, 3, 5, 6, 8, 9]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y_shape = [2, 3, 1]\n    y = [1, 2, 3, 4, 5, 6]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y_shape = [3, 2, 1]\n    y = [1, 2, 4, 5, 7, 8]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    offset_height, offset_width = [0, 0]\n    target_height, target_width = [2, 2]\n\n    for x_shape in ([3, 5], [1, 3, 5, 1, 1]):\n      self._assertRaises(x, x_shape, offset_height, offset_width, target_height,\n                         target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    # Each line is a test configuration:\n    #   x_shape, target_height, target_width\n    test_config = (([0, 2, 2], 1, 1), ([2, 0, 2], 1, 1), ([2, 2, 0], 1, 1),\n                   ([0, 2, 2], 0, 1), ([2, 0, 2], 1, 0))\n    offset_height, offset_width = [0, 0]\n    x = []\n\n    for x_shape, target_height, target_width in test_config:\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n      # Multiple assertion could fail, but the evaluation order is arbitrary.\n      # Match gainst generic pattern.\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParams(self):\n    x_shape = [4, 4, 1]\n    x = np.zeros(x_shape)\n\n    # Each line is a test configuration:\n    #   (offset_height, offset_width, target_height, target_width), err_msg\n    test_config = (\n        ([-1, 0, 3, 3], \"offset_height must be >= 0\"),\n        ([0, -1, 3, 3], \"offset_width must be >= 0\"),\n        ([0, 0, 0, 3], \"target_height must be > 0\"),\n        ([0, 0, 3, 0], \"target_width must be > 0\"),\n        ([2, 0, 3, 3], r\"height must be >= target \\+ offset\"),\n        ([0, 2, 3, 3], r\"width must be >= target \\+ offset\"))\n\n    for params, err_msg in test_config:\n      self._assertRaises(x, x_shape, *params, err_msg=err_msg)\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[55, 66, 3])\n      y = image_ops.crop_to_bounding_box(image, 0, 0, 55, 66)\n      self.assertTrue(y.name.startswith(\"crop_to_bounding_box\"))\n\n\nclass CentralCropTest(test_util.TensorFlowTestCase):\n\n  def _assertShapeInference(self, pre_shape, fraction, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.central_crop(image, fraction)\n    if post_shape is None:\n      self.assertEqual(y.get_shape().dims, None)\n    else:\n      self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shapes = [[13, 9, 3], [5, 13, 9, 3]]\n    for x_shape in x_shapes:\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          x = constant_op.constant(x_np, shape=x_shape)\n          y = image_ops.central_crop(x, 1.0)\n          y_tf = self.evaluate(y)\n          self.assertAllEqual(y_tf, x_np)\n\n  def testCropping(self):\n    x_shape = [4, 8, 1]\n    x_np = np.array(\n        [[1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8]],\n        dtype=np.int32).reshape(x_shape)\n    y_np = np.array([[3, 4, 5, 6], [3, 4, 5, 6]]).reshape([2, 4, 1])\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        x = constant_op.constant(x_np, shape=x_shape)\n        y = image_ops.central_crop(x, 0.5)\n        y_tf = self.evaluate(y)\n        self.assertAllEqual(y_tf, y_np)\n        self.assertAllEqual(y_tf.shape, y_np.shape)\n\n    x_shape = [2, 4, 8, 1]\n    x_np = np.array(\n        [[1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8],\n         [8, 7, 6, 5, 4, 3, 2, 1], [8, 7, 6, 5, 4, 3, 2, 1],\n         [8, 7, 6, 5, 4, 3, 2, 1], [8, 7, 6, 5, 4, 3, 2, 1]],\n        dtype=np.int32).reshape(x_shape)\n    y_np = np.array([[[3, 4, 5, 6], [3, 4, 5, 6]],\n                     [[6, 5, 4, 3], [6, 5, 4, 3]]]).reshape([2, 2, 4, 1])\n    with self.cached_session():\n      x = constant_op.constant(x_np, shape=x_shape)\n      y = image_ops.central_crop(x, 0.5)\n      y_tf = self.evaluate(y)\n      self.assertAllEqual(y_tf, y_np)\n      self.assertAllEqual(y_tf.shape, y_np.shape)\n\n  def testCropping2(self):\n    # Test case for 10315\n    x_shapes = [[240, 320, 3], [5, 240, 320, 3]]\n    expected_y_shapes = [[80, 106, 3], [5, 80, 106, 3]]\n\n    for x_shape, y_shape in zip(x_shapes, expected_y_shapes):\n      x_np = np.zeros(x_shape, dtype=np.int32)\n      y_np = np.zeros(y_shape, dtype=np.int32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          y_tf = self.evaluate(image_ops.central_crop(x_np, 0.33))\n          self.assertAllEqual(y_tf, y_np)\n          self.assertAllEqual(y_tf.shape, y_np.shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test no-op fraction=1.0, with 3-D tensors.\n      self._assertShapeInference([50, 60, 3], 1.0, [50, 60, 3])\n      self._assertShapeInference([None, 60, 3], 1.0, [None, 60, 3])\n      self._assertShapeInference([50, None, 3], 1.0, [50, None, 3])\n      self._assertShapeInference([None, None, 3], 1.0, [None, None, 3])\n      self._assertShapeInference([50, 60, None], 1.0, [50, 60, None])\n      self._assertShapeInference([None, None, None], 1.0, [None, None, None])\n\n      # Test no-op fraction=0.5, with 3-D tensors.\n      self._assertShapeInference([50, 60, 3], 0.5, [26, 30, 3])\n      self._assertShapeInference([None, 60, 3], 0.5, [None, 30, 3])\n      self._assertShapeInference([50, None, 3], 0.5, [26, None, 3])\n      self._assertShapeInference([None, None, 3], 0.5, [None, None, 3])\n      self._assertShapeInference([50, 60, None], 0.5, [26, 30, None])\n      self._assertShapeInference([None, None, None], 0.5, [None, None, None])\n\n      # Test no-op fraction=1.0, with 4-D tensors.\n      self._assertShapeInference([5, 50, 60, 3], 1.0, [5, 50, 60, 3])\n      self._assertShapeInference([5, None, 60, 3], 1.0, [5, None, 60, 3])\n      self._assertShapeInference([5, 50, None, 3], 1.0, [5, 50, None, 3])\n      self._assertShapeInference([5, None, None, 3], 1.0, [5, None, None, 3])\n      self._assertShapeInference([5, 50, 60, None], 1.0, [5, 50, 60, None])\n      self._assertShapeInference([5, None, None, None], 1.0,\n                                 [5, None, None, None])\n      self._assertShapeInference([None, None, None, None], 1.0,\n                                 [None, None, None, None])\n\n      # Test no-op fraction=0.5, with 4-D tensors.\n      self._assertShapeInference([5, 50, 60, 3], 0.5, [5, 26, 30, 3])\n      self._assertShapeInference([5, None, 60, 3], 0.5, [5, None, 30, 3])\n      self._assertShapeInference([5, 50, None, 3], 0.5, [5, 26, None, 3])\n      self._assertShapeInference([5, None, None, 3], 0.5, [5, None, None, 3])\n      self._assertShapeInference([5, 50, 60, None], 0.5, [5, 26, 30, None])\n      self._assertShapeInference([5, None, None, None], 0.5,\n                                 [5, None, None, None])\n      self._assertShapeInference([None, None, None, None], 0.5,\n                                 [None, None, None, None])\n\n  def testErrorOnInvalidCentralCropFractionValues(self):\n    x_shape = [13, 9, 3]\n    x_np = np.ones(x_shape, dtype=np.float32)\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        x = constant_op.constant(x_np, shape=x_shape)\n        with self.assertRaises(ValueError):\n          _ = image_ops.central_crop(x, 0.0)\n        with self.assertRaises(ValueError):\n          _ = image_ops.central_crop(x, 1.01)\n\n  def testErrorOnInvalidShapes(self):\n    x_shapes = [None, [], [3], [3, 9], [3, 9, 3, 9, 3]]\n    for x_shape in x_shapes:\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          x = constant_op.constant(x_np, shape=x_shape)\n          with self.assertRaises(ValueError):\n            _ = image_ops.central_crop(x, 0.5)\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      x_shape = [13, 9, 3]\n      x_np = np.ones(x_shape, dtype=np.float32)\n      for use_gpu in [True, False]:\n        with self.cached_session(use_gpu=use_gpu):\n          y = image_ops.central_crop(x_np, 1.0)\n          self.assertTrue(y.op.name.startswith(\"central_crop\"))\n\n  def testCentralFractionTensor(self):\n    # Test case for GitHub issue 45324.\n    x_shape = [240, 320, 3]\n    y_shape = [80, 106, 3]\n\n    @def_function.function(autograph=False)\n    def f(x, central_fraction):\n      return image_ops.central_crop(x, central_fraction)\n\n    x_np = np.zeros(x_shape, dtype=np.int32)\n    y_np = np.zeros(y_shape, dtype=np.int32)\n    y_tf = self.evaluate(f(x_np, constant_op.constant(0.33)))\n    self.assertAllEqual(y_tf, y_np)\n    self.assertAllEqual(y_tf.shape, y_np.shape)\n\n\nclass PadToBoundingBoxTest(test_util.TensorFlowTestCase,\n                           parameterized.TestCase):\n\n  def _PadToBoundingBox(self, x, offset_height, offset_width, target_height,\n                        target_width, use_tensor_inputs):\n    if use_tensor_inputs:\n      offset_height = ops.convert_to_tensor(offset_height)\n      offset_width = ops.convert_to_tensor(offset_width)\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    @def_function.function\n    def pad_bbox(*args):\n      return image_ops.pad_to_bounding_box(*args)\n\n    with self.cached_session():\n      return self.evaluate(pad_bbox(x_tensor, offset_height, offset_width,\n                                    target_height, target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     offset_height,\n                     offset_width,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._PadToBoundingBox(x, offset_height, offset_width,\n                                    target_height, target_width,\n                                    use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    offset_height,\n                    offset_width,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._PadToBoundingBox(x, offset_height, offset_width, target_height,\n                               target_width, use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.pad_to_bounding_box(image, 0, 0, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testInt64(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    y = [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y_shape = [4, 3, 1]\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    i = constant_op.constant([1, 0, 4, 3], dtype=dtypes.int64)\n    y_tf = image_ops.pad_to_bounding_box(x, i[0], i[1], i[2], i[3])\n    with self.cached_session():\n      self.assertAllClose(y, self.evaluate(y_tf))\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n    offset_height, offset_width = [0, 0]\n    self._assertReturns(x, x_shape, offset_height, offset_width, x, x_shape)\n\n  def testPadding(self):\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    x_shape = [3, 3, 1]\n\n    offset_height, offset_width = [1, 0]\n    y = [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    y_shape = [4, 3, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 1]\n    y = [0, 1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9]\n    y_shape = [3, 4, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0]\n    y_shape = [4, 3, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n    offset_height, offset_width = [0, 0]\n    y = [1, 2, 3, 0, 4, 5, 6, 0, 7, 8, 9, 0]\n    y_shape = [3, 4, 1]\n    self._assertReturns(x, x_shape, offset_height, offset_width, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    offset_height, offset_width = [0, 0]\n    target_height, target_width = [2, 2]\n\n    for x_shape in ([3, 5], [1, 3, 5, 1, 1]):\n      self._assertRaises(x, x_shape, offset_height, offset_width, target_height,\n                         target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    # Each line is a test configuration:\n    #   x_shape, target_height, target_width\n    test_config = (([0, 2, 2], 2, 2), ([2, 0, 2], 2, 2), ([2, 2, 0], 2, 2))\n    offset_height, offset_width = [0, 0]\n    x = []\n\n    for x_shape, target_height, target_width in test_config:\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n\n      # The original error message does not contain back slashes. However, they\n      # are added by either the assert op or the runtime. If this behavior\n      # changes in the future, the match string will also needs to be changed.\n      self._assertRaises(\n          x,\n          x_shape,\n          offset_height,\n          offset_width,\n          target_height,\n          target_width,\n          \"inner 3 dims of \\\\'image.shape\\\\' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParamsScalarInputs(self):\n    # In this test, inputs do not get converted to tensors before calling the\n    # tf.function. The error message here is raised in python\n    # since the python function has direct access to the scalars.\n    x_shape = [3, 3, 1]\n    x = np.zeros(x_shape)\n\n    # Each line is a test configuration:\n    #   offset_height, offset_width, target_height, target_width, err_msg\n    test_config = (\n        (-1, 0, 4, 4,\n         \"offset_height must be >= 0\"),\n        (0, -1, 4, 4,\n         \"offset_width must be >= 0\"),\n        (2, 0, 4, 4,\n         \"height must be <= target - offset\"),\n        (0, 2, 4, 4,\n         \"width must be <= target - offset\"))\n    for config_item in test_config:\n      self._assertRaises(\n          x, x_shape, *config_item, use_tensor_inputs_options=[False])\n\n  def testBadParamsTensorInputsEager(self):\n    # In this test inputs get converted to EagerTensors before calling the\n    # tf.function. The error message here is raised in python\n    # since the python function has direct access to the tensor's values.\n    with context.eager_mode():\n      x_shape = [3, 3, 1]\n      x = np.zeros(x_shape)\n\n      # Each line is a test configuration:\n      #   offset_height, offset_width, target_height, target_width, err_msg\n      test_config = (\n          (-1, 0, 4, 4,\n           \"offset_height must be >= 0\"),\n          (0, -1, 4, 4,\n           \"offset_width must be >= 0\"),\n          (2, 0, 4, 4,\n           \"height must be <= target - offset\"),\n          (0, 2, 4, 4,\n           \"width must be <= target - offset\"))\n      for config_item in test_config:\n        self._assertRaises(\n            x, x_shape, *config_item, use_tensor_inputs_options=[True])\n\n  @parameterized.named_parameters([(\"OffsetHeight\", (-1, 0, 4, 4)),\n                                   (\"OffsetWidth\", (0, -1, 4, 4)),\n                                   (\"Height\", (2, 0, 4, 4)),\n                                   (\"Width\", (0, 2, 4, 4))])\n  def testBadParamsTensorInputsGraph(self, config):\n    # In this test inputs get converted to tensors before calling the\n    # tf.function. The error message here is raised during shape inference.\n    with context.graph_mode():\n      x_shape = [3, 3, 1]\n      x = np.zeros(x_shape)\n      self._assertRaises(\n          x,\n          x_shape,\n          *config,\n          \"Paddings must be non-negative\",\n          use_tensor_inputs_options=[True])\n\n  def testNameScope(self):\n    # Testing name scope requires a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[55, 66, 3])\n      y = image_ops.pad_to_bounding_box(image, 0, 0, 55, 66)\n      self.assertTrue(y.op.name.startswith(\"pad_to_bounding_box\"))\n\n\nclass SelectDistortedCropBoxTest(test_util.TensorFlowTestCase):\n\n  def _testSampleDistortedBoundingBox(self, image, bounding_box,\n                                      min_object_covered, aspect_ratio_range,\n                                      area_range):\n    original_area = float(np.prod(image.shape))\n    bounding_box_area = float((bounding_box[3] - bounding_box[1]) *\n                              (bounding_box[2] - bounding_box[0]))\n\n    image_size_np = np.array(image.shape, dtype=np.int32)\n    bounding_box_np = (\n        np.array(bounding_box, dtype=np.float32).reshape([1, 1, 4]))\n\n    aspect_ratios = []\n    area_ratios = []\n\n    fraction_object_covered = []\n\n    num_iter = 1000\n    with self.cached_session():\n      image_tf = constant_op.constant(image, shape=image.shape)\n      image_size_tf = constant_op.constant(\n          image_size_np, shape=image_size_np.shape)\n      bounding_box_tf = constant_op.constant(\n          bounding_box_np, dtype=dtypes.float32, shape=bounding_box_np.shape)\n\n      begin, size, _ = image_ops.sample_distorted_bounding_box(\n          image_size=image_size_tf,\n          bounding_boxes=bounding_box_tf,\n          min_object_covered=min_object_covered,\n          aspect_ratio_range=aspect_ratio_range,\n          area_range=area_range)\n      y = array_ops.strided_slice(image_tf, begin, begin + size)\n\n      for _ in xrange(num_iter):\n        y_tf = self.evaluate(y)\n        crop_height = y_tf.shape[0]\n        crop_width = y_tf.shape[1]\n        aspect_ratio = float(crop_width) / float(crop_height)\n        area = float(crop_width * crop_height)\n\n        aspect_ratios.append(aspect_ratio)\n        area_ratios.append(area / original_area)\n        fraction_object_covered.append(float(np.sum(y_tf)) / bounding_box_area)\n\n      # min_object_covered as tensor\n      min_object_covered_t = ops.convert_to_tensor(min_object_covered)\n      begin, size, _ = image_ops.sample_distorted_bounding_box(\n          image_size=image_size_tf,\n          bounding_boxes=bounding_box_tf,\n          min_object_covered=min_object_covered_t,\n          aspect_ratio_range=aspect_ratio_range,\n          area_range=area_range)\n      y = array_ops.strided_slice(image_tf, begin, begin + size)\n\n      for _ in xrange(num_iter):\n        y_tf = self.evaluate(y)\n        crop_height = y_tf.shape[0]\n        crop_width = y_tf.shape[1]\n        aspect_ratio = float(crop_width) / float(crop_height)\n        area = float(crop_width * crop_height)\n\n        aspect_ratios.append(aspect_ratio)\n        area_ratios.append(area / original_area)\n        fraction_object_covered.append(float(np.sum(y_tf)) / bounding_box_area)\n\n    # Ensure that each entry is observed within 3 standard deviations.\n    # num_bins = 10\n    # aspect_ratio_hist, _ = np.histogram(aspect_ratios,\n    #                                     bins=num_bins,\n    #                                     range=aspect_ratio_range)\n    # mean = np.mean(aspect_ratio_hist)\n    # stddev = np.sqrt(mean)\n    # TODO(wicke, shlens, dga): Restore this test so that it is no longer flaky.\n    # TODO(irving): Since the rejection probability is not independent of the\n    # aspect ratio, the aspect_ratio random value is not exactly uniformly\n    # distributed in [min_aspect_ratio, max_aspect_ratio).  This test should be\n    # fixed to reflect the true statistical property, then tightened to enforce\n    # a stricter bound.  Or, ideally, the sample_distorted_bounding_box Op\n    # be fixed to not use rejection sampling and generate correctly uniform\n    # aspect ratios.\n    # self.assertAllClose(aspect_ratio_hist,\n    #                     [mean] * num_bins, atol=3.6 * stddev)\n\n    # The resulting crop will not be uniformly distributed in area. In practice,\n    # we find that the area skews towards the small sizes. Instead, we perform\n    # a weaker test to ensure that the area ratios are merely within the\n    # specified bounds.\n    self.assertLessEqual(max(area_ratios), area_range[1])\n    self.assertGreaterEqual(min(area_ratios), area_range[0])\n\n    # For reference, here is what the distribution of area ratios look like.\n    area_ratio_hist, _ = np.histogram(area_ratios, bins=10, range=area_range)\n    print(\"area_ratio_hist \", area_ratio_hist)\n\n    # Ensure that fraction_object_covered is satisfied.\n    # TODO(wicke, shlens, dga): Restore this test so that it is no longer flaky.\n    # self.assertGreaterEqual(min(fraction_object_covered), min_object_covered)\n\n  def testWholeImageBoundingBox(self):\n    height = 40\n    width = 50\n    image_size = [height, width, 1]\n    bounding_box = [0.0, 0.0, 1.0, 1.0]\n    image = np.arange(\n        0, np.prod(image_size), dtype=np.int32).reshape(image_size)\n    self._testSampleDistortedBoundingBox(\n        image,\n        bounding_box,\n        min_object_covered=0.1,\n        aspect_ratio_range=(0.75, 1.33),\n        area_range=(0.05, 1.0))\n\n  def testWithBoundingBox(self):\n    height = 40\n    width = 50\n    x_shape = [height, width, 1]\n    image = np.zeros(x_shape, dtype=np.int32)\n\n    # Create an object with 1's in a region with area A and require that\n    # the total pixel values >= 0.1 * A.\n    min_object_covered = 0.1\n\n    xmin = 2\n    ymin = 3\n    xmax = 12\n    ymax = 13\n    for x in np.arange(xmin, xmax + 1, 1):\n      for y in np.arange(ymin, ymax + 1, 1):\n        image[x, y] = 1\n\n    # Bounding box is specified as (ymin, xmin, ymax, xmax) in\n    # relative coordinates.\n    bounding_box = (float(ymin) / height, float(xmin) / width,\n                    float(ymax) / height, float(xmax) / width)\n\n    self._testSampleDistortedBoundingBox(\n        image,\n        bounding_box=bounding_box,\n        min_object_covered=min_object_covered,\n        aspect_ratio_range=(0.75, 1.33),\n        area_range=(0.05, 1.0))\n\n  def testSampleDistortedBoundingBoxShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        image_size = constant_op.constant(\n            [40, 50, 1], shape=[3], dtype=dtypes.int32)\n        bounding_box = constant_op.constant(\n            [[[0.0, 0.0, 1.0, 1.0]]],\n            shape=[1, 1, 4],\n            dtype=dtypes.float32,\n        )\n        begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n            image_size=image_size,\n            bounding_boxes=bounding_box,\n            min_object_covered=0.1,\n            aspect_ratio_range=(0.75, 1.33),\n            area_range=(0.05, 1.0))\n\n        # Test that the shapes are correct.\n        self.assertAllEqual([3], begin.get_shape().as_list())\n        self.assertAllEqual([3], end.get_shape().as_list())\n        self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n        # Actual run to make sure shape is correct inside Compute().\n        begin = self.evaluate(begin)\n        end = self.evaluate(end)\n        bbox_for_drawing = self.evaluate(bbox_for_drawing)\n\n        begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n            image_size=image_size,\n            bounding_boxes=bounding_box,\n            min_object_covered=array_ops.placeholder(dtypes.float32),\n            aspect_ratio_range=(0.75, 1.33),\n            area_range=(0.05, 1.0))\n\n        # Test that the shapes are correct.\n        self.assertAllEqual([3], begin.get_shape().as_list())\n        self.assertAllEqual([3], end.get_shape().as_list())\n        self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n\n  def testDefaultMinObjectCovered(self):\n    # By default min_object_covered=0.1 if not provided\n    with self.cached_session():\n      image_size = constant_op.constant(\n          [40, 50, 1], shape=[3], dtype=dtypes.int32)\n      bounding_box = constant_op.constant(\n          [[[0.0, 0.0, 1.0, 1.0]]],\n          shape=[1, 1, 4],\n          dtype=dtypes.float32,\n      )\n      begin, end, bbox_for_drawing = image_ops.sample_distorted_bounding_box(\n          image_size=image_size,\n          bounding_boxes=bounding_box,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n      self.assertAllEqual([3], begin.get_shape().as_list())\n      self.assertAllEqual([3], end.get_shape().as_list())\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n      # Actual run to make sure shape is correct inside Compute().\n      begin = self.evaluate(begin)\n      end = self.evaluate(end)\n      bbox_for_drawing = self.evaluate(bbox_for_drawing)\n\n  def _testStatelessSampleDistortedBoundingBox(self, image, bounding_box,\n                                               min_object_covered,\n                                               aspect_ratio_range, area_range):\n    with test_util.use_gpu():\n      original_area = float(np.prod(image.shape))\n      bounding_box_area = float((bounding_box[3] - bounding_box[1]) *\n                                (bounding_box[2] - bounding_box[0]))\n\n      image_size_np = np.array(image.shape, dtype=np.int32)\n      bounding_box_np = (\n          np.array(bounding_box, dtype=np.float32).reshape([1, 1, 4]))\n\n      iterations = 2\n      test_seeds = [(1, 2), (3, 4), (5, 6)]\n\n      for seed in test_seeds:\n        aspect_ratios = []\n        area_ratios = []\n        fraction_object_covered = []\n        for _ in range(iterations):\n          image_tf = constant_op.constant(image, shape=image.shape)\n          image_size_tf = constant_op.constant(\n              image_size_np, shape=image_size_np.shape)\n          bounding_box_tf = constant_op.constant(bounding_box_np,\n                                                 dtype=dtypes.float32,\n                                                 shape=bounding_box_np.shape)\n          begin, size, _ = image_ops.stateless_sample_distorted_bounding_box(\n              image_size=image_size_tf,\n              bounding_boxes=bounding_box_tf,\n              seed=seed,\n              min_object_covered=min_object_covered,\n              aspect_ratio_range=aspect_ratio_range,\n              area_range=area_range)\n          y = array_ops.strided_slice(image_tf, begin, begin + size)\n          y_tf = self.evaluate(y)\n          crop_height = y_tf.shape[0]\n          crop_width = y_tf.shape[1]\n          aspect_ratio = float(crop_width) / float(crop_height)\n          area = float(crop_width * crop_height)\n          aspect_ratios.append(aspect_ratio)\n          area_ratio = area / original_area\n          area_ratios.append(area_ratio)\n          fraction_object_covered.append(\n              float(np.sum(y_tf)) / bounding_box_area)\n\n        # Check that `area_ratio` is within valid range.\n        self.assertLessEqual(area_ratio, area_range[1])\n        self.assertGreaterEqual(area_ratio, area_range[0])\n\n        # Each array should consist of one value just repeated `iteration` times\n        # because the same seed is used.\n        self.assertEqual(len(set(aspect_ratios)), 1)\n        self.assertEqual(len(set(area_ratios)), 1)\n        self.assertEqual(len(set(fraction_object_covered)), 1)\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testWholeImageBoundingBoxStateless(self):\n    height = 40\n    width = 50\n    image_size = [height, width, 1]\n    bounding_box = [0.0, 0.0, 1.0, 1.0]\n    image = np.arange(\n        0, np.prod(image_size), dtype=np.int32).reshape(image_size)\n    for min_obj_covered in [0.1, constant_op.constant(0.1)]:\n      self._testStatelessSampleDistortedBoundingBox(\n          image,\n          bounding_box,\n          min_object_covered=min_obj_covered,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testWithBoundingBoxStateless(self):\n    height = 40\n    width = 50\n    x_shape = [height, width, 1]\n    image = np.zeros(x_shape, dtype=np.int32)\n\n    xmin = 2\n    ymin = 3\n    xmax = 12\n    ymax = 13\n    for x in np.arange(xmin, xmax + 1, 1):\n      for y in np.arange(ymin, ymax + 1, 1):\n        image[x, y] = 1\n\n    # Bounding box is specified as (ymin, xmin, ymax, xmax) in\n    # relative coordinates.\n    bounding_box = (float(ymin) / height, float(xmin) / width,\n                    float(ymax) / height, float(xmax) / width)\n\n    # Test both scalar and tensor input for `min_object_covered`.\n    for min_obj_covered in [0.1, constant_op.constant(0.1)]:\n      self._testStatelessSampleDistortedBoundingBox(\n          image,\n          bounding_box=bounding_box,\n          min_object_covered=min_obj_covered,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n  def testSampleDistortedBoundingBoxShapeStateless(self):\n    with test_util.use_gpu():\n      image_size = constant_op.constant(\n          [40, 50, 1], shape=[3], dtype=dtypes.int32)\n      bounding_box = constant_op.constant(\n          [[[0.0, 0.0, 1.0, 1.0]]],\n          shape=[1, 1, 4],\n          dtype=dtypes.float32,\n      )\n\n      bbox_func = functools.partial(\n          image_ops.stateless_sample_distorted_bounding_box,\n          image_size=image_size,\n          bounding_boxes=bounding_box,\n          min_object_covered=0.1,\n          aspect_ratio_range=(0.75, 1.33),\n          area_range=(0.05, 1.0))\n\n      # Check error is raised with wrong seed shapes.\n      for seed in [1, (1, 2, 3)]:\n        with self.assertRaises((ValueError, errors.InvalidArgumentError)):\n          begin, end, bbox_for_drawing = bbox_func(seed=seed)\n\n      test_seed = (1, 2)\n      begin, end, bbox_for_drawing = bbox_func(seed=test_seed)\n\n      # Test that the shapes are correct.\n      self.assertAllEqual([3], begin.get_shape().as_list())\n      self.assertAllEqual([3], end.get_shape().as_list())\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.get_shape().as_list())\n\n      # Actual run to make sure shape is correct inside Compute().\n      begin = self.evaluate(begin)\n      end = self.evaluate(end)\n      bbox_for_drawing = self.evaluate(bbox_for_drawing)\n      self.assertAllEqual([3], begin.shape)\n      self.assertAllEqual([3], end.shape)\n      self.assertAllEqual([1, 1, 4], bbox_for_drawing.shape)\n\n\nclass ResizeImagesV2Test(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  METHODS = [\n      image_ops.ResizeMethod.BILINEAR, image_ops.ResizeMethod.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethod.BICUBIC, image_ops.ResizeMethod.AREA,\n      image_ops.ResizeMethod.LANCZOS3, image_ops.ResizeMethod.LANCZOS5,\n      image_ops.ResizeMethod.GAUSSIAN, image_ops.ResizeMethod.MITCHELLCUBIC\n  ]\n\n  # Some resize methods, such as Gaussian, are non-interpolating in that they\n  # change the image even if there is no scale change, for some test, we only\n  # check the value on the value preserving methods.\n  INTERPOLATING_METHODS = [\n      image_ops.ResizeMethod.BILINEAR, image_ops.ResizeMethod.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethod.BICUBIC, image_ops.ResizeMethod.AREA,\n      image_ops.ResizeMethod.LANCZOS3, image_ops.ResizeMethod.LANCZOS5\n  ]\n\n  TYPES = [\n      np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.float16,\n      np.float32, np.float64\n  ]\n\n  def _assertShapeInference(self, pre_shape, size, post_shape):\n    # Try single image resize\n    single_image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_images_v2(single_image, size)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n    # Try batch images resize with known batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[99] + pre_shape)\n    y = image_ops.resize_images_v2(images, size)\n    self.assertEqual(y.get_shape().as_list(), [99] + post_shape)\n    # Try batch images resize with unknown batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[None] + pre_shape)\n    y = image_ops.resize_images_v2(images, size)\n    self.assertEqual(y.get_shape().as_list(), [None] + post_shape)\n\n  def shouldRunOnGPU(self, method, nptype):\n    if (method == image_ops.ResizeMethod.NEAREST_NEIGHBOR and\n        nptype in [np.float32, np.float64]):\n      return True\n    else:\n      return False\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testNoOp(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    target_height = 6\n    target_width = 4\n\n    for nptype in self.TYPES:\n      img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n      for method in self.METHODS:\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                         method)\n          yshape = array_ops.shape(y)\n          resized, newshape = self.evaluate([y, yshape])\n          self.assertAllEqual(img_shape, newshape)\n          if method in self.INTERPOLATING_METHODS:\n            self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                       self.METHODS[0])\n        yshape = array_ops.shape(y)\n        newshape = self.evaluate(yshape)\n        self.assertAllEqual(single_shape, newshape)\n\n  # half_pixel_centers unsupported in ResizeBilinear\n  @test_util.disable_xla(\"b/127616992\")\n  def testTensorArguments(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    def resize_func(t, new_size, method):\n      return image_ops.resize_images_v2(t, new_size, method)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = resize_func(image, [6, 4], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = resize_func(image, [6, 4], self.METHODS[0])\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(single_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_single, atol=1e-5)\n\n    # Incorrect shape.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant(4)\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([1, 2, 3])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n\n    # Incorrect dtypes.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([6.0, 4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, 4.0], image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [None, 4], image_ops.ResizeMethod.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, None], image_ops.ResizeMethod.BILINEAR)\n\n  def testReturnDtypeV1(self):\n    # Shape inference in V1.\n    with ops.Graph().as_default():\n      target_shapes = [[6, 4], [3, 2],\n                       [\n                           array_ops.placeholder(dtypes.int32),\n                           array_ops.placeholder(dtypes.int32)\n                       ]]\n      for nptype in self.TYPES:\n        image = array_ops.placeholder(nptype, shape=[1, 6, 4, 1])\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            y = image_ops.resize_images_v2(image, target_shape, method)\n            if method == image_ops.ResizeMethod.NEAREST_NEIGHBOR:\n              expected_dtype = image.dtype\n            else:\n              expected_dtype = dtypes.float32\n            self.assertEqual(y.dtype, expected_dtype)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  def testReturnDtypeV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def test_dtype(image, target_shape, target_method):\n        y = image_ops.resize_images_v2(image, target_shape, target_method)\n        if method == image_ops.ResizeMethod.NEAREST_NEIGHBOR:\n          expected_dtype = image.dtype\n        else:\n          expected_dtype = dtypes.float32\n\n        self.assertEqual(y.dtype, expected_dtype)\n\n      target_shapes = [[6, 4],\n                       [3, 2],\n                       [tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32),\n                        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)]]\n\n      for nptype in self.TYPES:\n        image = tensor_spec.TensorSpec(shape=[1, 6, 4, 1], dtype=nptype)\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            with test_util.run_functions_eagerly(run_func_eagerly):\n              test_dtype.get_concrete_function(image, target_shape, method)\n\n  # half_pixel_centers not supported by XLA\n  @test_util.disable_xla(\"b/127616992\")\n  def testSumTensor(self):\n    img_shape = [1, 6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    # Test size where width is specified as a tensor which is a sum\n    # of two tensors.\n    width_1 = constant_op.constant(1)\n    width_2 = constant_op.constant(3)\n    width = math_ops.add(width_1, width_2)\n    height = constant_op.constant(6)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = image_ops.resize_images_v2(image, [height, width], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        if method in self.INTERPOLATING_METHODS:\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeDown(self):\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    expected_data = [127, 64, 64, 127, 50, 100]\n    target_height = 3\n    target_width = 2\n\n    # Test out 3-D and 4-D image shapes.\n    img_shapes = [[1, 6, 4, 1], [6, 4, 1]]\n    target_shapes = [[1, target_height, target_width, 1],\n                     [target_height, target_width, 1]]\n\n    for target_shape, img_shape in zip(target_shapes, img_shapes):\n\n      for nptype in self.TYPES:\n        img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n        for method in self.METHODS:\n          if test.is_gpu_available() and self.shouldRunOnGPU(method, nptype):\n            with self.cached_session():\n              image = constant_op.constant(img_np, shape=img_shape)\n              y = image_ops.resize_images_v2(\n                  image, [target_height, target_width], method)\n              expected = np.array(expected_data).reshape(target_shape)\n              resized = self.evaluate(y)\n              self.assertAllClose(resized, expected, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeUp(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethod.BILINEAR] = [\n        64.0, 56.0, 40.0, 32.0, 56.0, 52.0, 44.0, 40.0, 40.0, 44.0, 52.0, 56.0,\n        36.5, 45.625, 63.875, 73.0, 45.5, 56.875, 79.625, 91.0, 50.0, 62.5,\n        87.5, 100.0\n    ]\n    expected_data[image_ops.ResizeMethod.NEAREST_NEIGHBOR] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethod.AREA] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethod.LANCZOS3] = [\n        75.8294, 59.6281, 38.4313, 22.23, 60.6851, 52.0037, 40.6454, 31.964,\n        35.8344, 41.0779, 47.9383, 53.1818, 24.6968, 43.0769, 67.1244, 85.5045,\n        35.7939, 56.4713, 83.5243, 104.2017, 44.8138, 65.1949, 91.8603, 112.2413\n    ]\n    expected_data[image_ops.ResizeMethod.LANCZOS5] = [\n        77.5699, 60.0223, 40.6694, 23.1219, 61.8253, 51.2369, 39.5593, 28.9709,\n        35.7438, 40.8875, 46.5604, 51.7041, 21.5942, 43.5299, 67.7223, 89.658,\n        32.1213, 56.784, 83.984, 108.6467, 44.5802, 66.183, 90.0082, 111.6109\n    ]\n    expected_data[image_ops.ResizeMethod.GAUSSIAN] = [\n        61.1087, 54.6926, 41.3074, 34.8913, 54.6926, 51.4168, 44.5832, 41.3074,\n        41.696, 45.2456, 52.6508, 56.2004, 39.4273, 47.0526, 62.9602, 70.5855,\n        47.3008, 57.3042, 78.173, 88.1764, 51.4771, 62.3638, 85.0752, 95.9619\n    ]\n    expected_data[image_ops.ResizeMethod.BICUBIC] = [\n        70.1453, 59.0252, 36.9748, 25.8547, 59.3195, 53.3386, 41.4789, 35.4981,\n        36.383, 41.285, 51.0051, 55.9071, 30.2232, 42.151, 65.8032, 77.731,\n        41.6492, 55.823, 83.9288, 98.1026, 47.0363, 62.2744, 92.4903, 107.7284\n    ]\n    expected_data[image_ops.ResizeMethod.MITCHELLCUBIC] = [\n        66.0382, 56.6079, 39.3921, 29.9618, 56.7255, 51.9603, 43.2611, 38.4959,\n        39.1828, 43.4664, 51.2864, 55.57, 34.6287, 45.1812, 64.4458, 74.9983,\n        43.8523, 56.8078, 80.4594, 93.4149, 48.9943, 63.026, 88.6422, 102.6739\n    ]\n    for nptype in self.TYPES:\n      for method in expected_data:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                         method)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-04)\n\n  # XLA doesn't implement half_pixel_centers\n  @test_util.disable_xla(\"b/127616992\")\n  def testLegacyBicubicMethodsMatchNewMethods(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    methods_to_test = ((gen_image_ops.resize_bilinear, \"triangle\"),\n                       (gen_image_ops.resize_bicubic, \"keyscubic\"))\n    for legacy_method, new_method in methods_to_test:\n      with self.cached_session():\n        img_np = np.array(data, dtype=np.float32).reshape(img_shape)\n        image = constant_op.constant(img_np, shape=img_shape)\n        legacy_result = legacy_method(\n            image,\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.int32),\n            half_pixel_centers=True)\n        scale = (\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.float32) /\n            math_ops.cast(array_ops.shape(image)[1:3], dtype=dtypes.float32))\n        new_result = gen_image_ops.scale_and_translate(\n            image,\n            constant_op.constant([target_height, target_width],\n                                 dtype=dtypes.int32),\n            scale,\n            array_ops.zeros([2]),\n            kernel_type=new_method,\n            antialias=False)\n        self.assertAllClose(\n            self.evaluate(legacy_result), self.evaluate(new_result), atol=1e-04)\n\n  def testResizeDownArea(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 64, 32, 16, 8, 4, 4, 8, 16, 32, 64, 128, 128, 64, 32, 16, 8, 4, 5,\n        10, 15, 20, 25, 30, 30, 25, 20, 15, 10, 5, 5, 10, 15, 20, 25, 30\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 4\n    target_width = 4\n    expected_data = [\n        73, 33, 23, 39, 73, 33, 23, 39, 14, 16, 19, 21, 14, 16, 19, 21\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images_v2(image, [target_height, target_width],\n                                     image_ops.ResizeMethod.AREA)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      resized = self.evaluate(y)\n      self.assertAllClose(resized, expected, atol=1)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testCompareNearestNeighbor(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        img_np = np.arange(\n            0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=input_shape)\n          new_size = constant_op.constant([target_height, target_width])\n          out_op = image_ops.resize_images_v2(\n              image, new_size, image_ops.ResizeMethod.NEAREST_NEIGHBOR)\n          gpu_val = self.evaluate(out_op)\n        with self.cached_session(use_gpu=False):\n          image = constant_op.constant(img_np, shape=input_shape)\n          new_size = constant_op.constant([target_height, target_width])\n          out_op = image_ops.resize_images_v2(\n              image, new_size, image_ops.ResizeMethod.NEAREST_NEIGHBOR)\n          cpu_val = self.evaluate(out_op)\n        self.assertAllClose(cpu_val, gpu_val, rtol=1e-5, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testBfloat16MultipleOps(self):\n    target_height = 8\n    target_width = 12\n    img = np.random.uniform(0, 100, size=(30, 10, 2)).astype(np.float32)\n    img_bf16 = ops.convert_to_tensor(img, dtype=\"bfloat16\")\n    new_size = constant_op.constant([target_height, target_width])\n    img_methods = [\n        image_ops.ResizeMethod.BILINEAR,\n        image_ops.ResizeMethod.NEAREST_NEIGHBOR, image_ops.ResizeMethod.BICUBIC,\n        image_ops.ResizeMethod.AREA\n    ]\n    for method in img_methods:\n      out_op_bf16 = image_ops.resize_images_v2(img_bf16, new_size, method)\n      out_op_f32 = image_ops.resize_images_v2(img, new_size, method)\n      bf16_val = self.evaluate(out_op_bf16)\n      f32_val = self.evaluate(out_op_f32)\n      self.assertAllClose(bf16_val, f32_val, rtol=1e-2, atol=1e-2)\n\n  def testCompareBilinear(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        img_np = np.arange(\n            0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n        value = {}\n        for use_gpu in [True, False]:\n          with self.cached_session(use_gpu=use_gpu):\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(image, new_size,\n                                             image_ops.ResizeMethod.BILINEAR)\n            value[use_gpu] = self.evaluate(out_op)\n        self.assertAllClose(value[True], value[False], rtol=1e-5, atol=1e-5)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([55, 66, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([50, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([None, None, None], [55, 66], [55, 66, None])\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        single_image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n        y = image_ops.resize_images(single_image, [55, 66])\n        self.assertTrue(y.op.name.startswith(\"resize\"))\n\n  def _ResizeImageCall(self, x, max_h, max_w, preserve_aspect_ratio,\n                       use_tensor_inputs):\n    if use_tensor_inputs:\n      target_max = ops.convert_to_tensor([max_h, max_w])\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      target_max = (max_h, max_w)\n      x_tensor = x\n\n    def resize_func(t,\n                    target_max=target_max,\n                    preserve_aspect_ratio=preserve_aspect_ratio):\n      return image_ops.resize_images(\n          t, ops.convert_to_tensor(target_max),\n          preserve_aspect_ratio=preserve_aspect_ratio)\n\n    with self.cached_session():\n      return self.evaluate(resize_func(x_tensor))\n\n  def _assertResizeEqual(self,\n                         x,\n                         x_shape,\n                         y,\n                         y_shape,\n                         preserve_aspect_ratio=True,\n                         use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertResizeCheckShape(self,\n                              x,\n                              x_shape,\n                              target_shape,\n                              y_shape,\n                              preserve_aspect_ratio=True,\n                              use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width = target_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.zeros(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertShapeEqual(y, ops.convert_to_tensor(y_tf))\n\n  def testPreserveAspectRatioMultipleImages(self):\n    x_shape = [10, 100, 80, 10]\n    x = np.random.uniform(size=x_shape)\n    for preserve_aspect_ratio in [True, False]:\n      with self.subTest(preserve_aspect_ratio=preserve_aspect_ratio):\n        expect_shape = [10, 250, 200, 10] if preserve_aspect_ratio \\\n            else [10, 250, 250, 10]\n        self._assertResizeCheckShape(\n            x,\n            x_shape, [250, 250],\n            expect_shape,\n            preserve_aspect_ratio=preserve_aspect_ratio)\n\n  def testPreserveAspectRatioNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeEqual(x, x_shape, x, x_shape)\n\n  def testPreserveAspectRatioSmaller(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [50, 50, 10])\n\n  def testPreserveAspectRatioSmallerMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [10, 50, 50, 10])\n\n  def testPreserveAspectRatioLarger(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [150, 200], [150, 150, 10])\n\n  def testPreserveAspectRatioSameRatio(self):\n    x_shape = [1920, 1080, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [3840, 2160], [3840, 2160, 3])\n\n  def testPreserveAspectRatioSquare(self):\n    x_shape = [299, 299, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [320, 320], [320, 320, 3])\n\n  def testLargeDim(self):\n    with self.session():\n      with self.assertRaises(errors.InternalError):\n        x = np.ones((5, 1, 1, 2))\n        v = image_ops.resize_images_v2(x, [1610637938, 1610637938],\n                                       image_ops.ResizeMethod.BILINEAR)\n        _ = self.evaluate(v)\n\n\nclass ResizeImagesTest(test_util.TensorFlowTestCase,\n                       parameterized.TestCase):\n\n  METHODS = [\n      image_ops.ResizeMethodV1.BILINEAR,\n      image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n      image_ops.ResizeMethodV1.BICUBIC, image_ops.ResizeMethodV1.AREA\n  ]\n\n  TYPES = [\n      np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.float16,\n      np.float32, np.float64\n  ]\n\n  def _assertShapeInference(self, pre_shape, size, post_shape):\n    # Try single image resize\n    single_image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_images(single_image, size)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n    # Try batch images resize with known batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[99] + pre_shape)\n    y = image_ops.resize_images(images, size)\n    self.assertEqual(y.get_shape().as_list(), [99] + post_shape)\n    # Try batch images resize with unknown batch size\n    images = array_ops.placeholder(dtypes.float32, shape=[None] + pre_shape)\n    y = image_ops.resize_images(images, size)\n    self.assertEqual(y.get_shape().as_list(), [None] + post_shape)\n\n  def shouldRunOnGPU(self, method, nptype):\n    if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR and\n        nptype in [np.float32, np.float64]):\n      return True\n    else:\n      return False\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testNoOp(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    target_height = 6\n    target_width = 4\n\n    for nptype in self.TYPES:\n      img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n      for method in self.METHODS:\n        with self.cached_session():\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(image, [target_height, target_width],\n                                      method)\n          yshape = array_ops.shape(y)\n          resized, newshape = self.evaluate([y, yshape])\n          self.assertAllEqual(img_shape, newshape)\n          self.assertAllClose(resized, img_np, atol=1e-5)\n\n      # Resizing with a single image must leave the shape unchanged also.\n      with self.cached_session():\n        img_single = img_np.reshape(single_shape)\n        image = constant_op.constant(img_single, shape=single_shape)\n        y = image_ops.resize_images(image, [target_height, target_width],\n                                    self.METHODS[0])\n        yshape = array_ops.shape(y)\n        newshape = self.evaluate(yshape)\n        self.assertAllEqual(single_shape, newshape)\n\n  def testTensorArguments(self):\n    img_shape = [1, 6, 4, 1]\n    single_shape = [6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n\n    def resize_func(t, new_size, method):\n      return image_ops.resize_images(t, new_size, method)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session():\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = resize_func(image, [6, 4], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        self.assertAllClose(resized, img_np, atol=1e-5)\n\n    # Resizing with a single image must leave the shape unchanged also.\n    with self.cached_session():\n      img_single = img_np.reshape(single_shape)\n      image = constant_op.constant(img_single, shape=single_shape)\n      y = resize_func(image, [6, 4], self.METHODS[0])\n      yshape = array_ops.shape(y)\n      resized, newshape = self.evaluate([y, yshape])\n      self.assertAllEqual(single_shape, newshape)\n      self.assertAllClose(resized, img_single, atol=1e-5)\n\n    # Incorrect shape.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant(4)\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([1, 2, 3])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n\n    # Incorrect dtypes.\n    with self.assertRaises(ValueError):\n      new_size = constant_op.constant([6.0, 4])\n      _ = resize_func(image, new_size, image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, 4.0], image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [None, 4], image_ops.ResizeMethodV1.BILINEAR)\n    with self.assertRaises(ValueError):\n      _ = resize_func(image, [6, None], image_ops.ResizeMethodV1.BILINEAR)\n\n  def testReturnDtypeV1(self):\n    # Shape inference in V1.\n    with ops.Graph().as_default():\n      target_shapes = [[6, 4], [3, 2], [\n          array_ops.placeholder(dtypes.int32),\n          array_ops.placeholder(dtypes.int32)\n      ]]\n      for nptype in self.TYPES:\n        image = array_ops.placeholder(nptype, shape=[1, 6, 4, 1])\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            y = image_ops.resize_images(image, target_shape, method)\n            if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR or\n                target_shape == image.shape[1:3]):\n              expected_dtype = image.dtype\n            else:\n              expected_dtype = dtypes.float32\n            self.assertEqual(y.dtype, expected_dtype)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  def testReturnDtypeV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def test_dtype(image, target_shape, target_method):\n        y = image_ops.resize_images(image, target_shape, target_method)\n        if (method == image_ops.ResizeMethodV1.NEAREST_NEIGHBOR or\n            target_shape == image.shape[1:3]):\n          expected_dtype = image.dtype\n        else:\n          expected_dtype = dtypes.float32\n\n        self.assertEqual(y.dtype, expected_dtype)\n\n      target_shapes = [[6, 4],\n                       [3, 2],\n                       [tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32),\n                        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)]]\n\n      for nptype in self.TYPES:\n        image = tensor_spec.TensorSpec(shape=[1, 6, 4, 1], dtype=nptype)\n        for method in self.METHODS:\n          for target_shape in target_shapes:\n            with test_util.run_functions_eagerly(run_func_eagerly):\n              test_dtype.get_concrete_function(image, target_shape, method)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testSumTensor(self):\n    img_shape = [1, 6, 4, 1]\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    # Test size where width is specified as a tensor which is a sum\n    # of two tensors.\n    width_1 = constant_op.constant(1)\n    width_2 = constant_op.constant(3)\n    width = math_ops.add(width_1, width_2)\n    height = constant_op.constant(6)\n\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    for method in self.METHODS:\n      with self.cached_session() as sess:\n        image = constant_op.constant(img_np, shape=img_shape)\n        y = image_ops.resize_images(image, [height, width], method)\n        yshape = array_ops.shape(y)\n        resized, newshape = self.evaluate([y, yshape])\n        self.assertAllEqual(img_shape, newshape)\n        self.assertAllClose(resized, img_np, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeDown(self):\n    # This test is also conducted with int8, so 127 is the maximum\n    # value that can be used.\n    data = [\n        127, 127, 64, 64, 127, 127, 64, 64, 64, 64, 127, 127, 64, 64, 127, 127,\n        50, 50, 100, 100, 50, 50, 100, 100\n    ]\n    expected_data = [127, 64, 64, 127, 50, 100]\n    target_height = 3\n    target_width = 2\n\n    # Test out 3-D and 4-D image shapes.\n    img_shapes = [[1, 6, 4, 1], [6, 4, 1]]\n    target_shapes = [[1, target_height, target_width, 1],\n                     [target_height, target_width, 1]]\n\n    for target_shape, img_shape in zip(target_shapes, img_shapes):\n\n      for nptype in self.TYPES:\n        img_np = np.array(data, dtype=nptype).reshape(img_shape)\n\n        for method in self.METHODS:\n          if test.is_gpu_available() and self.shouldRunOnGPU(method, nptype):\n            with self.cached_session():\n              image = constant_op.constant(img_np, shape=img_shape)\n              y = image_ops.resize_images(image, [target_height, target_width],\n                                          method)\n              expected = np.array(expected_data).reshape(target_shape)\n              resized = self.evaluate(y)\n              self.assertAllClose(resized, expected, atol=1e-5)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testResizeUpAlignCornersFalse(self):\n    img_shape = [1, 3, 2, 1]\n    data = [64, 32, 32, 64, 50, 100]\n    target_height = 6\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethodV1.BILINEAR] = [\n        64.0, 48.0, 32.0, 32.0, 48.0, 48.0, 48.0, 48.0, 32.0, 48.0, 64.0, 64.0,\n        41.0, 61.5, 82.0, 82.0, 50.0, 75.0, 100.0, 100.0, 50.0, 75.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.NEAREST_NEIGHBOR] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.AREA] = [\n        64.0, 64.0, 32.0, 32.0, 64.0, 64.0, 32.0, 32.0, 32.0, 32.0, 64.0, 64.0,\n        32.0, 32.0, 64.0, 64.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0, 100.0,\n        100.0\n    ]\n\n    for nptype in self.TYPES:\n      for method in [\n          image_ops.ResizeMethodV1.BILINEAR,\n          image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n          image_ops.ResizeMethodV1.AREA\n      ]:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(\n              image, [target_height, target_width], method, align_corners=False)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-05)\n\n  def testResizeUpAlignCornersTrue(self):\n    img_shape = [1, 3, 2, 1]\n    data = [6, 3, 3, 6, 6, 9]\n    target_height = 5\n    target_width = 4\n    expected_data = {}\n    expected_data[image_ops.ResizeMethodV1.BILINEAR] = [\n        6.0, 5.0, 4.0, 3.0, 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 5.0, 6.0, 4.5, 5.5,\n        6.5, 7.5, 6.0, 7.0, 8.0, 9.0\n    ]\n    expected_data[image_ops.ResizeMethodV1.NEAREST_NEIGHBOR] = [\n        6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0,\n        9.0, 9.0, 6.0, 6.0, 9.0, 9.0\n    ]\n    # TODO(b/37749740): Improve alignment of ResizeMethodV1.AREA when\n    # align_corners=True.\n    expected_data[image_ops.ResizeMethodV1.AREA] = [\n        6.0, 6.0, 6.0, 3.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 6.0, 3.0, 3.0,\n        3.0, 6.0, 6.0, 6.0, 6.0, 9.0\n    ]\n\n    for nptype in self.TYPES:\n      for method in [\n          image_ops.ResizeMethodV1.BILINEAR,\n          image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n          image_ops.ResizeMethodV1.AREA\n      ]:\n        with self.cached_session():\n          img_np = np.array(data, dtype=nptype).reshape(img_shape)\n          image = constant_op.constant(img_np, shape=img_shape)\n          y = image_ops.resize_images(\n              image, [target_height, target_width], method, align_corners=True)\n          resized = self.evaluate(y)\n          expected = np.array(expected_data[method]).reshape(\n              [1, target_height, target_width, 1])\n          self.assertAllClose(resized, expected, atol=1e-05)\n\n  def testResizeUpBicubic(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 128, 64, 64, 128, 128, 64, 64, 64, 64, 128, 128, 64, 64, 128, 128,\n        50, 50, 100, 100, 50, 50, 100, 100, 50, 50, 100, 100, 50, 50, 100, 100,\n        50, 50, 100, 100\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 8\n    target_width = 8\n    expected_data = [\n        128, 135, 96, 55, 64, 114, 134, 128, 78, 81, 68, 52, 57, 118, 144, 136,\n        55, 49, 79, 109, 103, 89, 83, 84, 74, 70, 95, 122, 115, 69, 49, 55, 100,\n        105, 75, 43, 50, 89, 105, 100, 57, 54, 74, 96, 91, 65, 55, 58, 70, 69,\n        75, 81, 80, 72, 69, 70, 105, 112, 75, 36, 45, 92, 111, 105\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images(image, [target_height, target_width],\n                                  image_ops.ResizeMethodV1.BICUBIC)\n      resized = self.evaluate(y)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      self.assertAllClose(resized, expected, atol=1)\n\n  def testResizeDownArea(self):\n    img_shape = [1, 6, 6, 1]\n    data = [\n        128, 64, 32, 16, 8, 4, 4, 8, 16, 32, 64, 128, 128, 64, 32, 16, 8, 4, 5,\n        10, 15, 20, 25, 30, 30, 25, 20, 15, 10, 5, 5, 10, 15, 20, 25, 30\n    ]\n    img_np = np.array(data, dtype=np.uint8).reshape(img_shape)\n\n    target_height = 4\n    target_width = 4\n    expected_data = [\n        73, 33, 23, 39, 73, 33, 23, 39, 14, 16, 19, 21, 14, 16, 19, 21\n    ]\n\n    with self.cached_session():\n      image = constant_op.constant(img_np, shape=img_shape)\n      y = image_ops.resize_images(image, [target_height, target_width],\n                                  image_ops.ResizeMethodV1.AREA)\n      expected = np.array(expected_data).reshape(\n          [1, target_height, target_width, 1])\n      resized = self.evaluate(y)\n      self.assertAllClose(resized, expected, atol=1)\n\n  @test_util.disable_xla(\"align_corners=False not supported by XLA\")\n  def testCompareNearestNeighbor(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        for align_corners in [True, False]:\n          img_np = np.arange(\n              0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n          with self.cached_session():\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(\n                image,\n                new_size,\n                image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n                align_corners=align_corners)\n            gpu_val = self.evaluate(out_op)\n          with self.cached_session(use_gpu=False):\n            image = constant_op.constant(img_np, shape=input_shape)\n            new_size = constant_op.constant([target_height, target_width])\n            out_op = image_ops.resize_images(\n                image,\n                new_size,\n                image_ops.ResizeMethodV1.NEAREST_NEIGHBOR,\n                align_corners=align_corners)\n            cpu_val = self.evaluate(out_op)\n          self.assertAllClose(cpu_val, gpu_val, rtol=1e-5, atol=1e-5)\n\n  def testCompareBilinear(self):\n    if test.is_gpu_available():\n      input_shape = [1, 5, 6, 3]\n      target_height = 8\n      target_width = 12\n      for nptype in [np.float32, np.float64]:\n        for align_corners in [True, False]:\n          img_np = np.arange(\n              0, np.prod(input_shape), dtype=nptype).reshape(input_shape)\n          value = {}\n          for use_gpu in [True, False]:\n            with self.cached_session(use_gpu=use_gpu):\n              image = constant_op.constant(img_np, shape=input_shape)\n              new_size = constant_op.constant([target_height, target_width])\n              out_op = image_ops.resize_images(\n                  image,\n                  new_size,\n                  image_ops.ResizeMethodV1.BILINEAR,\n                  align_corners=align_corners)\n              value[use_gpu] = self.evaluate(out_op)\n          self.assertAllClose(value[True], value[False], rtol=1e-5, atol=1e-5)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([55, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([59, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([None, None, 3], [55, 66], [55, 66, 3])\n      self._assertShapeInference([50, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([55, 66, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([50, 69, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([59, 60, None], [55, 66], [55, 66, None])\n      self._assertShapeInference([None, None, None], [55, 66], [55, 66, None])\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img_shape = [1, 3, 2, 1]\n      with self.cached_session():\n        single_image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n        y = image_ops.resize_images(single_image, [55, 66])\n        self.assertTrue(y.op.name.startswith(\"resize\"))\n\n  def _ResizeImageCall(self, x, max_h, max_w, preserve_aspect_ratio,\n                       use_tensor_inputs):\n    if use_tensor_inputs:\n      target_max = ops.convert_to_tensor([max_h, max_w])\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      target_max = [max_h, max_w]\n      x_tensor = x\n\n    y = image_ops.resize_images(\n        x_tensor, target_max, preserve_aspect_ratio=preserve_aspect_ratio)\n\n    with self.cached_session():\n      return self.evaluate(y)\n\n  def _assertResizeEqual(self, x, x_shape, y, y_shape,\n                         preserve_aspect_ratio=True,\n                         use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertResizeCheckShape(self, x, x_shape, target_shape,\n                              y_shape, preserve_aspect_ratio=True,\n                              use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width = target_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.zeros(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageCall(x, target_height, target_width,\n                                   preserve_aspect_ratio, use_tensor_inputs)\n      self.assertShapeEqual(y, ops.convert_to_tensor(y_tf))\n\n  def testPreserveAspectRatioMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [250, 250], [10, 250, 250, 10],\n                                 preserve_aspect_ratio=False)\n\n  def testPreserveAspectRatioNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeEqual(x, x_shape, x, x_shape)\n\n  def testPreserveAspectRatioSmaller(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [50, 50, 10])\n\n  def testPreserveAspectRatioSmallerMultipleImages(self):\n    x_shape = [10, 100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [75, 50], [10, 50, 50, 10])\n\n  def testPreserveAspectRatioLarger(self):\n    x_shape = [100, 100, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [150, 200], [150, 150, 10])\n\n  def testPreserveAspectRatioSameRatio(self):\n    x_shape = [1920, 1080, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [3840, 2160], [3840, 2160, 3])\n\n  def testPreserveAspectRatioSquare(self):\n    x_shape = [299, 299, 3]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertResizeCheckShape(x, x_shape, [320, 320], [320, 320, 3])\n\n\nclass ResizeImageWithPadV1Test(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithPad(self, x, target_height, target_width,\n                          use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    with self.cached_session():\n      return self.evaluate(\n          image_ops.resize_image_with_pad_v1(x_tensor, target_height,\n                                             target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithPad(x, target_height, target_width,\n                                      use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithPad(x, target_height, target_width,\n                                 use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_pad_v1(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test with 3-D tensors.\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n      # Test with 4-D tensors.\n      self._assertShapeInference([5, 55, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, 66, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, 50, 60, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, None, None, None], 55, 66,\n                                 [5, 55, 66, None])\n      self._assertShapeInference([None, None, None, None], 55, 66,\n                                 [None, 55, 66, None])\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Reduce vertical dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 3, 0]\n    y_shape = [1, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Reduce horizontal dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [1, 3, 0, 0]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [1, 3]\n    y_shape = [1, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n\n# half_pixel_centers not supported by XLA\n@test_util.for_all_test_methods(test_util.disable_xla, \"b/127616992\")\nclass ResizeImageWithPadV2Test(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithPad(self, x, target_height, target_width,\n                          use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    with self.cached_session():\n      return self.evaluate(\n          image_ops.resize_image_with_pad_v2(x_tensor, target_height,\n                                             target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithPad(x, target_height, target_width,\n                                      use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithPad(x, target_height, target_width,\n                                 use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_pad_v1(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      # Test with 3-D tensors.\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n      # Test with 4-D tensors.\n      self._assertShapeInference([5, 55, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 66, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, 60, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 50, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, None, None, 3], 55, 66, [5, 55, 66, 3])\n      self._assertShapeInference([5, 55, 66, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, 50, 60, None], 55, 66, [5, 55, 66, None])\n      self._assertShapeInference([5, None, None, None], 55, 66,\n                                 [5, 55, 66, None])\n      self._assertShapeInference([None, None, None, None], 55, 66,\n                                 [None, 55, 66, None])\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Reduce vertical dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 3.5, 5.5, 0]\n    y_shape = [1, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Reduce horizontal dimension\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [3.5, 5.5, 0, 0]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [3.5, 5.5]\n    y_shape = [1, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n\nclass ResizeImageWithCropOrPadTest(test_util.TensorFlowTestCase):\n\n  def _ResizeImageWithCropOrPad(self, x, target_height, target_width,\n                                use_tensor_inputs):\n    if use_tensor_inputs:\n      target_height = ops.convert_to_tensor(target_height)\n      target_width = ops.convert_to_tensor(target_width)\n      x_tensor = ops.convert_to_tensor(x)\n    else:\n      x_tensor = x\n\n    @def_function.function\n    def resize_crop_or_pad(*args):\n      return image_ops.resize_image_with_crop_or_pad(*args)\n\n    with self.cached_session():\n      return self.evaluate(\n          resize_crop_or_pad(x_tensor, target_height, target_width))\n\n  def _assertReturns(self,\n                     x,\n                     x_shape,\n                     y,\n                     y_shape,\n                     use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    target_height, target_width, _ = y_shape\n    x = np.array(x).reshape(x_shape)\n    y = np.array(y).reshape(y_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      y_tf = self._ResizeImageWithCropOrPad(x, target_height, target_width,\n                                            use_tensor_inputs)\n      self.assertAllClose(y, y_tf)\n\n  def _assertRaises(self,\n                    x,\n                    x_shape,\n                    target_height,\n                    target_width,\n                    err_msg,\n                    use_tensor_inputs_options=None):\n    use_tensor_inputs_options = use_tensor_inputs_options or [False, True]\n    x = np.array(x).reshape(x_shape)\n\n    for use_tensor_inputs in use_tensor_inputs_options:\n      with self.assertRaisesRegex(\n          (ValueError, errors.InvalidArgumentError), err_msg):\n        self._ResizeImageWithCropOrPad(x, target_height, target_width,\n                                       use_tensor_inputs)\n\n  def _assertShapeInference(self, pre_shape, height, width, post_shape):\n    image = array_ops.placeholder(dtypes.float32, shape=pre_shape)\n    y = image_ops.resize_image_with_crop_or_pad(image, height, width)\n    self.assertEqual(y.get_shape().as_list(), post_shape)\n\n  def testNoOp(self):\n    x_shape = [10, 10, 10]\n    x = np.random.uniform(size=x_shape)\n\n    self._assertReturns(x, x_shape, x, x_shape)\n\n  def testPad(self):\n    # Pad even along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 2, 3, 4, 0, 0, 5, 6, 7, 8, 0]\n    y_shape = [2, 6, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad odd along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 1, 2, 3, 4, 0, 0, 0, 5, 6, 7, 8, 0, 0]\n    y_shape = [2, 7, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad even along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0]\n    y_shape = [4, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Pad odd along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0]\n    y_shape = [5, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testCrop(self):\n    # Crop even along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [2, 3, 6, 7]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop odd along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    x_shape = [2, 6, 1]\n\n    y = [2, 3, 4, 8, 9, 10]\n    y_shape = [2, 3, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop even along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [4, 2, 1]\n\n    y = [3, 4, 5, 6]\n    y_shape = [2, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop odd along row.\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n    x_shape = [8, 2, 1]\n\n    y = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    y_shape = [5, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testCropAndPad(self):\n    # Pad along row but crop along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [2, 4, 1]\n\n    y = [0, 0, 2, 3, 6, 7, 0, 0]\n    y_shape = [4, 2, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n    # Crop along row but pad along col.\n    x = [1, 2, 3, 4, 5, 6, 7, 8]\n    x_shape = [4, 2, 1]\n\n    y = [0, 3, 4, 0, 0, 5, 6, 0]\n    y_shape = [2, 4, 1]\n\n    self._assertReturns(x, x_shape, y, y_shape)\n\n  def testShapeInference(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      self._assertShapeInference([50, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 60, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 66, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, 69, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([55, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([59, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([None, None, 3], 55, 66, [55, 66, 3])\n      self._assertShapeInference([50, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([55, 66, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([50, 69, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([59, 60, None], 55, 66, [55, 66, None])\n      self._assertShapeInference([None, None, None], 55, 66, [55, 66, None])\n      self._assertShapeInference(None, 55, 66, [55, 66, None])\n\n  def testNon3DInput(self):\n    # Input image is not 3D\n    x = [0] * 15\n    target_height, target_width = [4, 4]\n\n    for x_shape in ([3, 5],):\n      self._assertRaises(x, x_shape, target_height, target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n    for x_shape in ([1, 3, 5, 1, 1],):\n      self._assertRaises(x, x_shape, target_height, target_width,\n                         \"must have either 3 or 4 dimensions.\")\n\n  def testZeroLengthInput(self):\n    # Input image has 0-length dimension(s).\n    target_height, target_width = [1, 1]\n    x = []\n\n    for x_shape in ([0, 2, 2], [2, 0, 2], [2, 2, 0]):\n      self._assertRaises(\n          x,\n          x_shape,\n          target_height,\n          target_width,\n          \"inner 3 dims of 'image.shape' must be > 0\",\n          use_tensor_inputs_options=[False])\n\n      # The original error message does not contain back slashes. However, they\n      # are added by either the assert op or the runtime. If this behavior\n      # changes in the future, the match string will also needs to be changed.\n      self._assertRaises(\n          x,\n          x_shape,\n          target_height,\n          target_width,\n          \"inner 3 dims of \\\\'image.shape\\\\' must be > 0\",\n          use_tensor_inputs_options=[True])\n\n  def testBadParams(self):\n    x_shape = [4, 4, 1]\n    x = np.zeros(x_shape)\n\n    # target_height <= 0\n    target_height, target_width = [0, 5]\n    self._assertRaises(x, x_shape, target_height, target_width,\n                       \"target_height must be > 0\")\n\n    # target_width <= 0\n    target_height, target_width = [5, 0]\n    self._assertRaises(x, x_shape, target_height, target_width,\n                       \"target_width must be > 0\")\n\n  def testNameScope(self):\n    # Testing name scope requires placeholders and a graph.\n    with ops.Graph().as_default():\n      image = array_ops.placeholder(dtypes.float32, shape=[50, 60, 3])\n      y = image_ops.resize_image_with_crop_or_pad(image, 55, 66)\n      self.assertTrue(y.op.name.startswith(\"resize_image_with_crop_or_pad\"))\n\n\ndef simple_color_ramp():\n  \"\"\"Build a simple color ramp RGB image.\"\"\"\n  w, h = 256, 200\n  i = np.arange(h)[:, None]\n  j = np.arange(w)\n  image = np.empty((h, w, 3), dtype=np.uint8)\n  image[:, :, 0] = i\n  image[:, :, 1] = j\n  image[:, :, 2] = (i + j) >> 1\n  return image\n\n\nclass JpegTest(test_util.TensorFlowTestCase):\n\n  # TODO(irving): Add self.assertAverageLess or similar to test_util\n  def averageError(self, image0, image1):\n    self.assertEqual(image0.shape, image1.shape)\n    image0 = image0.astype(int)  # Avoid overflow\n    return np.abs(image0 - image1).sum() / np.prod(image0.shape)\n\n  def testExisting(self):\n    # Read a real jpeg and verify shape\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1.jpg\")\n    with self.cached_session():\n      jpeg0 = io_ops.read_file(path)\n      image0 = image_ops.decode_jpeg(jpeg0)\n      image1 = image_ops.decode_jpeg(image_ops.encode_jpeg(image0))\n      jpeg0, image0, image1 = self.evaluate([jpeg0, image0, image1])\n      self.assertEqual(len(jpeg0), 3771)\n      self.assertEqual(image0.shape, (256, 128, 3))\n      self.assertLess(self.averageError(image0, image1), 1.4)\n\n  def testCmyk(self):\n    # Confirm that CMYK reads in as RGB\n    base = \"tensorflow/core/lib/jpeg/testdata\"\n    rgb_path = os.path.join(base, \"jpeg_merge_test1.jpg\")\n    cmyk_path = os.path.join(base, \"jpeg_merge_test1_cmyk.jpg\")\n    shape = 256, 128, 3\n    for channels in 3, 0:\n      with self.cached_session():\n        rgb = image_ops.decode_jpeg(\n            io_ops.read_file(rgb_path), channels=channels)\n        cmyk = image_ops.decode_jpeg(\n            io_ops.read_file(cmyk_path), channels=channels)\n        rgb, cmyk = self.evaluate([rgb, cmyk])\n        self.assertEqual(rgb.shape, shape)\n        self.assertEqual(cmyk.shape, shape)\n        error = self.averageError(rgb, cmyk)\n        self.assertLess(error, 4)\n\n  def testCropAndDecodeJpeg(self):\n    with self.cached_session() as sess:\n      # Encode it, then decode it, then encode it\n      base = \"tensorflow/core/lib/jpeg/testdata\"\n      jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n\n      h, w, _ = 256, 128, 3\n      crop_windows = [[0, 0, 5, 5], [0, 0, 5, w], [0, 0, h, 5],\n                      [h - 6, w - 5, 6, 5], [6, 5, 15, 10], [0, 0, h, w]]\n      for crop_window in crop_windows:\n        # Explicit two stages: decode + crop.\n        image1 = image_ops.decode_jpeg(jpeg0)\n        y, x, h, w = crop_window\n        image1_crop = image_ops.crop_to_bounding_box(image1, y, x, h, w)\n\n        # Combined decode+crop.\n        image2 = image_ops.decode_and_crop_jpeg(jpeg0, crop_window, channels=3)\n\n        # Combined decode+crop should have the same shape inference on image\n        # sizes.\n        image1_shape = image1_crop.get_shape().as_list()\n        image2_shape = image2.get_shape().as_list()\n        self.assertAllEqual(image1_shape, image2_shape)\n\n        # CropAndDecode should be equal to DecodeJpeg+Crop.\n        image1_crop, image2 = self.evaluate([image1_crop, image2])\n        self.assertAllEqual(image1_crop, image2)\n\n  def testCropAndDecodeJpegWithInvalidCropWindow(self):\n    with self.cached_session() as sess:\n      # Encode it, then decode it, then encode it\n      base = \"tensorflow/core/lib/jpeg/testdata\"\n      jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n\n      h, w, _ = 256, 128, 3\n      # Invalid crop windows.\n      crop_windows = [[-1, 11, 11, 11], [11, -1, 11, 11], [11, 11, -1, 11],\n                      [11, 11, 11, -1], [11, 11, 0, 11], [11, 11, 11, 0],\n                      [0, 0, h + 1, w], [0, 0, h, w + 1]]\n      for crop_window in crop_windows:\n        with self.assertRaisesRegex(\n            (ValueError, errors.InvalidArgumentError),\n            \"Invalid JPEG data or crop window\"):\n          result = image_ops.decode_and_crop_jpeg(jpeg0, crop_window)\n          self.evaluate(result)\n\n  def testSynthetic(self):\n    with self.cached_session():\n      # Encode it, then decode it, then encode it\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_ACCURATE\")\n      image2 = image_ops.decode_jpeg(\n          image_ops.encode_jpeg(image1), dct_method=\"INTEGER_ACCURATE\")\n      jpeg0, image0, image1, image2 = self.evaluate(\n          [jpeg0, image0, image1, image2])\n\n      # The decoded-encoded image should be similar to the input\n      self.assertLess(self.averageError(image0, image1), 0.6)\n\n      # We should be very close to a fixpoint\n      self.assertLess(self.averageError(image1, image2), 0.02)\n\n      # Smooth ramps compress well (input size is 153600)\n      self.assertGreaterEqual(len(jpeg0), 5000)\n      self.assertLessEqual(len(jpeg0), 6000)\n\n  def testSyntheticFasterAlgorithm(self):\n    with self.cached_session():\n      # Encode it, then decode it, then encode it\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_FAST\")\n      image2 = image_ops.decode_jpeg(\n          image_ops.encode_jpeg(image1), dct_method=\"INTEGER_FAST\")\n      jpeg0, image0, image1, image2 = self.evaluate(\n          [jpeg0, image0, image1, image2])\n\n      # The decoded-encoded image should be similar to the input, but\n      # note this is worse than the slower algorithm because it is\n      # less accurate.\n      self.assertLess(self.averageError(image0, image1), 0.95)\n\n      # Repeated compression / decompression will have a higher error\n      # with a lossier algorithm.\n      self.assertLess(self.averageError(image1, image2), 1.05)\n\n      # Smooth ramps compress well (input size is 153600)\n      self.assertGreaterEqual(len(jpeg0), 5000)\n      self.assertLessEqual(len(jpeg0), 6000)\n\n  def testDefaultDCTMethodIsIntegerFast(self):\n    with self.cached_session():\n      # Compare decoding with both dct_option=INTEGER_FAST and\n      # default.  They should be the same.\n      image0 = constant_op.constant(simple_color_ramp())\n      jpeg0 = image_ops.encode_jpeg(image0)\n      image1 = image_ops.decode_jpeg(jpeg0, dct_method=\"INTEGER_FAST\")\n      image2 = image_ops.decode_jpeg(jpeg0)\n      image1, image2 = self.evaluate([image1, image2])\n\n      # The images should be the same.\n      self.assertAllClose(image1, image2)\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        jpeg = constant_op.constant(\"nonsense\")\n        for channels in 0, 1, 3:\n          image = image_ops.decode_jpeg(jpeg, channels=channels)\n          self.assertEqual(image.get_shape().as_list(),\n                           [None, None, channels or None])\n\n  def testExtractJpegShape(self):\n    # Read a real jpeg and verify shape.\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1.jpg\")\n    with self.cached_session():\n      jpeg = io_ops.read_file(path)\n      # Extract shape without decoding.\n      image_shape = self.evaluate(image_ops.extract_jpeg_shape(jpeg))\n      self.assertAllEqual(image_shape, [256, 128, 3])\n\n  def testExtractJpegShapeforCmyk(self):\n    # Read a cmyk jpeg image, and verify its shape.\n    path = (\"tensorflow/core/lib/jpeg/testdata/\"\n            \"jpeg_merge_test1_cmyk.jpg\")\n    with self.cached_session():\n      jpeg = io_ops.read_file(path)\n      image_shape = self.evaluate(image_ops.extract_jpeg_shape(jpeg))\n      # Cmyk jpeg image has 4 channels.\n      self.assertAllEqual(image_shape, [256, 128, 4])\n\n  def testRandomJpegQuality(self):\n    # Previous implementation of random_jpeg_quality had a bug.\n    # This unit test tests the fixed version, but due to forward compatibility\n    # this test can only be done when fixed version is used.\n    # Test jpeg quality dynamic randomization.\n    with ops.Graph().as_default(), self.test_session():\n      np.random.seed(7)\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      random_jpeg_image = image_ops.random_jpeg_quality(image, 40, 100)\n      with self.cached_session() as sess:\n        # Test randomization.\n        random_jpeg_images = [sess.run(random_jpeg_image) for _ in range(5)]\n        are_images_equal = []\n        for i in range(1, len(random_jpeg_images)):\n          # Most of them should be different if randomization is occurring\n          # correctly.\n          are_images_equal.append(\n              np.array_equal(random_jpeg_images[0], random_jpeg_images[i]))\n        self.assertFalse(all(are_images_equal))\n\n  # TODO(b/162345082): stateless random op generates different random number\n  # with xla_gpu. Update tests such that there is a single ground truth result\n  # to test against.\n  def testStatelessRandomJpegQuality(self):\n    # Test deterministic randomness in jpeg quality by checking that the same\n    # sequence of jpeg quality adjustments are returned each round given the\n    # same seed.\n    with test_util.use_gpu():\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      jpeg_quality = (40, 100)\n      seeds_list = [(1, 2), (3, 4)]\n\n      iterations = 2\n      random_jpeg_images_all = [[] for _ in range(iterations)]\n      for random_jpeg_images in random_jpeg_images_all:\n        for seed in seeds_list:\n          distorted_jpeg = image_ops.stateless_random_jpeg_quality(\n              image, jpeg_quality[0], jpeg_quality[1], seed=seed)\n          # Verify that the random jpeg image is different from the original\n          # jpeg image.\n          self.assertNotAllEqual(image, distorted_jpeg)\n          random_jpeg_images.append(self.evaluate(distorted_jpeg))\n\n      # Verify that the results are identical given the same seed.\n      for i in range(1, iterations):\n        self.assertAllEqual(random_jpeg_images_all[0],\n                            random_jpeg_images_all[i])\n\n  def testAdjustJpegQuality(self):\n    # Test if image_ops.adjust_jpeg_quality works when jpeq quality\n    # is an int (not tensor) for backward compatibility.\n    with ops.Graph().as_default(), self.test_session():\n      np.random.seed(7)\n      jpeg_quality = np.random.randint(40, 100)\n      path = (\"tensorflow/core/lib/jpeg/testdata/medium.jpg\")\n      jpeg = io_ops.read_file(path)\n      image = image_ops.decode_jpeg(jpeg)\n      adjust_jpeg_quality_image = image_ops.adjust_jpeg_quality(\n          image, jpeg_quality)\n      with self.cached_session() as sess:\n        sess.run(adjust_jpeg_quality_image)\n\n  def testAdjustJpegQualityShape(self):\n    with self.cached_session():\n      image = constant_op.constant(\n          np.arange(24, dtype=np.uint8).reshape([2, 4, 3]))\n      adjusted_image = image_ops.adjust_jpeg_quality(image, 80)\n      adjusted_image.shape.assert_is_compatible_with([None, None, 3])\n\n\nclass PngTest(test_util.TensorFlowTestCase):\n\n  def testExisting(self):\n    # Read some real PNGs, converting to different channel numbers\n    prefix = \"tensorflow/core/lib/png/testdata/\"\n    inputs = ((1, \"lena_gray.png\"), (4, \"lena_rgba.png\"),\n              (3, \"lena_palette.png\"), (4, \"lena_palette_trns.png\"))\n    for channels_in, filename in inputs:\n      for channels in 0, 1, 3, 4:\n        with self.cached_session():\n          png0 = io_ops.read_file(prefix + filename)\n          image0 = image_ops.decode_png(png0, channels=channels)\n          png0, image0 = self.evaluate([png0, image0])\n          self.assertEqual(image0.shape, (26, 51, channels or channels_in))\n          if channels == channels_in:\n            image1 = image_ops.decode_png(image_ops.encode_png(image0))\n            self.assertAllEqual(image0, self.evaluate(image1))\n\n  def testSynthetic(self):\n    with self.cached_session():\n      # Encode it, then decode it\n      image0 = constant_op.constant(simple_color_ramp())\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n\n      # PNG is lossless\n      self.assertAllEqual(image0, image1)\n\n      # Smooth ramps compress well, but not too well\n      self.assertGreaterEqual(len(png0), 400)\n      self.assertLessEqual(len(png0), 750)\n\n  def testSyntheticUint16(self):\n    with self.cached_session():\n      # Encode it, then decode it\n      image0 = constant_op.constant(simple_color_ramp(), dtype=dtypes.uint16)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0, dtype=dtypes.uint16)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n\n      # PNG is lossless\n      self.assertAllEqual(image0, image1)\n\n      # Smooth ramps compress well, but not too well\n      self.assertGreaterEqual(len(png0), 800)\n      self.assertLessEqual(len(png0), 1500)\n\n  def testSyntheticTwoChannel(self):\n    with self.cached_session():\n      # Strip the b channel from an rgb image to get a two-channel image.\n      gray_alpha = simple_color_ramp()[:, :, 0:2]\n      image0 = constant_op.constant(gray_alpha)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n      self.assertEqual(2, image0.shape[-1])\n      self.assertAllEqual(image0, image1)\n\n  def testSyntheticTwoChannelUint16(self):\n    with self.cached_session():\n      # Strip the b channel from an rgb image to get a two-channel image.\n      gray_alpha = simple_color_ramp()[:, :, 0:2]\n      image0 = constant_op.constant(gray_alpha, dtype=dtypes.uint16)\n      png0 = image_ops.encode_png(image0, compression=7)\n      image1 = image_ops.decode_png(png0, dtype=dtypes.uint16)\n      png0, image0, image1 = self.evaluate([png0, image0, image1])\n      self.assertEqual(2, image0.shape[-1])\n      self.assertAllEqual(image0, image1)\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        png = constant_op.constant(\"nonsense\")\n        for channels in 0, 1, 3:\n          image = image_ops.decode_png(png, channels=channels)\n          self.assertEqual(image.get_shape().as_list(),\n                           [None, None, channels or None])\n\n\nclass GifTest(test_util.TensorFlowTestCase):\n\n  def _testValid(self, filename):\n    # Read some real GIFs\n    prefix = \"tensorflow/core/lib/gif/testdata/\"\n    WIDTH = 20\n    HEIGHT = 40\n    STRIDE = 5\n    shape = (12, HEIGHT, WIDTH, 3)\n\n    with self.cached_session():\n      gif0 = io_ops.read_file(prefix + filename)\n      image0 = image_ops.decode_gif(gif0)\n      gif0, image0 = self.evaluate([gif0, image0])\n\n      self.assertEqual(image0.shape, shape)\n\n      for frame_idx, frame in enumerate(image0):\n        gt = np.zeros(shape[1:], dtype=np.uint8)\n        start = frame_idx * STRIDE\n        end = (frame_idx + 1) * STRIDE\n        print(frame_idx)\n        if end <= WIDTH:\n          gt[:, start:end, :] = 255\n        else:\n          start -= WIDTH\n          end -= WIDTH\n          gt[start:end, :, :] = 255\n\n        self.assertAllClose(frame, gt)\n\n  def testValid(self):\n    self._testValid(\"scan.gif\")\n    self._testValid(\"optimized.gif\")\n\n  def testShape(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      with self.cached_session():\n        gif = constant_op.constant(\"nonsense\")\n        image = image_ops.decode_gif(gif)\n        self.assertEqual(image.get_shape().as_list(), [None, None, None, 3])\n\n  def testAnimatedGif(self):\n    # Test if all frames in the animated GIF file is properly decoded.\n    with self.cached_session():\n      base = \"tensorflow/core/lib/gif/testdata\"\n      gif = io_ops.read_file(os.path.join(base, \"pendulum_sm.gif\"))\n      gt_frame0 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame0.png\"))\n      gt_frame1 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame1.png\"))\n      gt_frame2 = io_ops.read_file(os.path.join(base, \"pendulum_sm_frame2.png\"))\n\n      image = image_ops.decode_gif(gif)\n      frame0 = image_ops.decode_png(gt_frame0)\n      frame1 = image_ops.decode_png(gt_frame1)\n      frame2 = image_ops.decode_png(gt_frame2)\n      image, frame0, frame1, frame2 = self.evaluate([image, frame0, frame1,\n                                                     frame2])\n      # Compare decoded gif frames with ground-truth data.\n      self.assertAllEqual(image[0], frame0)\n      self.assertAllEqual(image[1], frame1)\n      self.assertAllEqual(image[2], frame2)\n\n\nclass ConvertImageTest(test_util.TensorFlowTestCase):\n\n  def _convert(self, original, original_dtype, output_dtype, expected):\n    x_np = np.array(original, dtype=original_dtype.as_numpy_dtype())\n    y_np = np.array(expected, dtype=output_dtype.as_numpy_dtype())\n\n    with self.cached_session():\n      image = constant_op.constant(x_np)\n      y = image_ops.convert_image_dtype(image, output_dtype)\n      self.assertTrue(y.dtype == output_dtype)\n      self.assertAllClose(y, y_np, atol=1e-5)\n      if output_dtype in [\n          dtypes.float32, dtypes.float64, dtypes.int32, dtypes.int64\n      ]:\n        y_saturate = image_ops.convert_image_dtype(\n            image, output_dtype, saturate=True)\n        self.assertTrue(y_saturate.dtype == output_dtype)\n        self.assertAllClose(y_saturate, y_np, atol=1e-5)\n\n  def testNoConvert(self):\n    # Tests with Tensor.op requires a graph.\n    with ops.Graph().as_default():\n      # Make sure converting to the same data type creates only an identity op\n      with self.cached_session():\n        image = constant_op.constant([1], dtype=dtypes.uint8)\n        image_ops.convert_image_dtype(image, dtypes.uint8)\n        y = image_ops.convert_image_dtype(image, dtypes.uint8)\n        self.assertEqual(y.op.type, \"Identity\")\n        self.assertEqual(y.op.inputs[0], image)\n\n  def testConvertBetweenInteger(self):\n    # Make sure converting to between integer types scales appropriately\n    with self.cached_session():\n      self._convert([0, 255], dtypes.uint8, dtypes.int16, [0, 255 * 128])\n      self._convert([0, 32767], dtypes.int16, dtypes.uint8, [0, 255])\n      self._convert([0, 2**32], dtypes.int64, dtypes.int32, [0, 1])\n      self._convert([0, 1], dtypes.int32, dtypes.int64, [0, 2**32])\n\n  def testConvertBetweenFloat(self):\n    # Make sure converting to between float types does nothing interesting\n    with self.cached_session():\n      self._convert([-1.0, 0, 1.0, 200000], dtypes.float32, dtypes.float64,\n                    [-1.0, 0, 1.0, 200000])\n      self._convert([-1.0, 0, 1.0, 200000], dtypes.float64, dtypes.float32,\n                    [-1.0, 0, 1.0, 200000])\n\n  def testConvertBetweenIntegerAndFloat(self):\n    # Make sure converting from and to a float type scales appropriately\n    with self.cached_session():\n      self._convert([0, 1, 255], dtypes.uint8, dtypes.float32,\n                    [0, 1.0 / 255.0, 1])\n      self._convert([0, 1.1 / 255.0, 1], dtypes.float32, dtypes.uint8,\n                    [0, 1, 255])\n\n  def testConvertBetweenInt16AndInt8(self):\n    with self.cached_session():\n      # uint8, uint16\n      self._convert([0, 255 * 256], dtypes.uint16, dtypes.uint8, [0, 255])\n      self._convert([0, 255], dtypes.uint8, dtypes.uint16, [0, 255 * 256])\n      # int8, uint16\n      self._convert([0, 127 * 2 * 256], dtypes.uint16, dtypes.int8, [0, 127])\n      self._convert([0, 127], dtypes.int8, dtypes.uint16, [0, 127 * 2 * 256])\n      # int16, uint16\n      self._convert([0, 255 * 256], dtypes.uint16, dtypes.int16, [0, 255 * 128])\n      self._convert([0, 255 * 128], dtypes.int16, dtypes.uint16, [0, 255 * 256])\n\n\nclass TotalVariationTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests the function total_variation() in image_ops.\n\n  We test a few small handmade examples, as well as\n  some larger examples using an equivalent numpy\n  implementation of the total_variation() function.\n\n  We do NOT test for overflows and invalid / edge-case arguments.\n  \"\"\"\n\n  def _test(self, x_np, y_np):\n    \"\"\"Test that the TensorFlow implementation of\n    total_variation(x_np) calculates the values in y_np.\n\n    Note that these may be float-numbers so we only test\n    for approximate equality within some narrow error-bound.\n    \"\"\"\n\n    # Create a TensorFlow session.\n    with self.cached_session():\n      # Add a constant to the TensorFlow graph that holds the input.\n      x_tf = constant_op.constant(x_np, shape=x_np.shape)\n\n      # Add ops for calculating the total variation using TensorFlow.\n      y = image_ops.total_variation(images=x_tf)\n\n      # Run the TensorFlow session to calculate the result.\n      y_tf = self.evaluate(y)\n\n      # Assert that the results are as expected within\n      # some small error-bound in case they are float-values.\n      self.assertAllClose(y_tf, y_np)\n\n  def _total_variation_np(self, x_np):\n    \"\"\"Calculate the total variation of x_np using numpy.\n    This implements the same function as TensorFlow but\n    using numpy instead.\n\n    Args:\n        x_np: Numpy array with 3 or 4 dimensions.\n    \"\"\"\n\n    dim = len(x_np.shape)\n\n    if dim == 3:\n      # Calculate differences for neighboring pixel-values using slices.\n      dif1 = x_np[1:, :, :] - x_np[:-1, :, :]\n      dif2 = x_np[:, 1:, :] - x_np[:, :-1, :]\n\n      # Sum for all axis.\n      sum_axis = None\n    elif dim == 4:\n      # Calculate differences for neighboring pixel-values using slices.\n      dif1 = x_np[:, 1:, :, :] - x_np[:, :-1, :, :]\n      dif2 = x_np[:, :, 1:, :] - x_np[:, :, :-1, :]\n\n      # Only sum for the last 3 axis.\n      sum_axis = (1, 2, 3)\n    else:\n      # This should not occur in this test-code.\n      pass\n\n    tot_var = np.sum(np.abs(dif1), axis=sum_axis) + \\\n              np.sum(np.abs(dif2), axis=sum_axis)\n\n    return tot_var\n\n  def _test_tensorflow_vs_numpy(self, x_np):\n    \"\"\"Test the TensorFlow implementation against a numpy implementation.\n\n    Args:\n        x_np: Numpy array with 3 or 4 dimensions.\n    \"\"\"\n\n    # Calculate the y-values using the numpy implementation.\n    y_np = self._total_variation_np(x_np)\n\n    self._test(x_np, y_np)\n\n  def _generateArray(self, shape):\n    \"\"\"Generate an array of the given shape for use in testing.\n    The numbers are calculated as the cumulative sum, which\n    causes the difference between neighboring numbers to vary.\"\"\"\n\n    # Flattened length of the array.\n    flat_len = np.prod(shape)\n\n    a = np.array(range(flat_len), dtype=int)\n    a = np.cumsum(a)\n    a = a.reshape(shape)\n\n    return a\n\n  # TODO(b/133851381): re-enable this test.\n  def disabledtestTotalVariationNumpy(self):\n    \"\"\"Test the TensorFlow implementation against a numpy implementation.\n    The two implementations are very similar so it is possible that both\n    have the same bug, which would not be detected by this test. It is\n    therefore necessary to test with manually crafted data as well.\"\"\"\n\n    # Generate a test-array.\n    # This is an 'image' with 100x80 pixels and 3 color channels.\n    a = self._generateArray(shape=(100, 80, 3))\n\n    # Test the TensorFlow implementation vs. numpy implementation.\n    # We use a numpy implementation to check the results that are\n    # calculated using TensorFlow are correct.\n    self._test_tensorflow_vs_numpy(a)\n    self._test_tensorflow_vs_numpy(a + 1)\n    self._test_tensorflow_vs_numpy(-a)\n    self._test_tensorflow_vs_numpy(1.1 * a)\n\n    # Expand to a 4-dim array.\n    b = a[np.newaxis, :]\n\n    # Combine several variations of the image into a single 4-dim array.\n    multi = np.vstack((b, b + 1, -b, 1.1 * b))\n\n    # Test that the TensorFlow function can also handle 4-dim arrays.\n    self._test_tensorflow_vs_numpy(multi)\n\n  def testTotalVariationHandmade(self):\n    \"\"\"Test the total variation for a few handmade examples.\"\"\"\n\n    # We create an image that is 2x2 pixels with 3 color channels.\n    # The image is very small so we can check the result by hand.\n\n    # Red color channel.\n    # The following are the sum of absolute differences between the pixels.\n    # sum row dif = (4-1) + (7-2) = 3 + 5 = 8\n    # sum col dif = (2-1) + (7-4) = 1 + 3 = 4\n    r = [[1, 2], [4, 7]]\n\n    # Blue color channel.\n    # sum row dif = 18 + 29 = 47\n    # sum col dif = 7 + 18 = 25\n    g = [[11, 18], [29, 47]]\n\n    # Green color channel.\n    # sum row dif = 120 + 193 = 313\n    # sum col dif = 47 + 120 = 167\n    b = [[73, 120], [193, 313]]\n\n    # Combine the 3 color channels into a single 3-dim array.\n    # The shape is (2, 2, 3) corresponding to (height, width and color).\n    a = np.dstack((r, g, b))\n\n    # Total variation for this image.\n    # Sum of all pixel differences = 8 + 4 + 47 + 25 + 313 + 167 = 564\n    tot_var = 564\n\n    # Calculate the total variation using TensorFlow and assert it is correct.\n    self._test(a, tot_var)\n\n    # If we add 1 to all pixel-values then the total variation is unchanged.\n    self._test(a + 1, tot_var)\n\n    # If we negate all pixel-values then the total variation is unchanged.\n    self._test(-a, tot_var)  # pylint: disable=invalid-unary-operand-type\n\n    # Scale the pixel-values by a float. This scales the total variation as\n    # well.\n    b = 1.1 * a\n    self._test(b, 1.1 * tot_var)\n\n    # Scale by another float.\n    c = 1.2 * a\n    self._test(c, 1.2 * tot_var)\n\n    # Combine these 3 images into a single array of shape (3, 2, 2, 3)\n    # where the first dimension is for the image-number.\n    multi = np.vstack((a[np.newaxis, :], b[np.newaxis, :], c[np.newaxis, :]))\n\n    # Check that TensorFlow correctly calculates the total variation\n    # for each image individually and returns the correct array.\n    self._test(multi, tot_var * np.array([1.0, 1.1, 1.2]))\n\n\nclass FormatTest(test_util.TensorFlowTestCase):\n\n  def testFormats(self):\n    prefix = \"tensorflow/core/lib\"\n    paths = (\"png/testdata/lena_gray.png\", \"jpeg/testdata/jpeg_merge_test1.jpg\",\n             \"gif/testdata/lena.gif\")\n    decoders = {\n        \"jpeg\": functools.partial(image_ops.decode_jpeg, channels=3),\n        \"png\": functools.partial(image_ops.decode_png, channels=3),\n        \"gif\": lambda s: array_ops.squeeze(image_ops.decode_gif(s), axis=0),\n    }\n    with self.cached_session():\n      for path in paths:\n        contents = self.evaluate(io_ops.read_file(os.path.join(prefix, path)))\n        images = {}\n        for name, decode in decoders.items():\n          image = self.evaluate(decode(contents))\n          self.assertEqual(image.ndim, 3)\n          for prev_name, prev in images.items():\n            print(\"path %s, names %s %s, shapes %s %s\" %\n                  (path, name, prev_name, image.shape, prev.shape))\n            self.assertAllEqual(image, prev)\n          images[name] = image\n\n  def testError(self):\n    path = \"tensorflow/core/lib/gif/testdata/scan.gif\"\n    with self.cached_session():\n      for decode in image_ops.decode_jpeg, image_ops.decode_png:\n        with self.assertRaisesOpError(r\"Got 12 frames\"):\n          decode(io_ops.read_file(path)).eval()\n\n\nclass CombinedNonMaxSuppressionTest(test_util.TensorFlowTestCase):\n\n  # NOTE(b/142795960): parameterized tests do not work well with tf.tensor\n  # inputs. Due to failures, creating another test `testInvalidTensorInput`\n  # which is identical to this one except that the input here is a scalar as\n  # opposed to a tensor.\n  def testInvalidPyInput(self):\n    boxes_np = [[[[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]]]\n    scores_np = [[[0.9, 0.75, 0.6, 0.95, 0.5, 0.3]]]\n    max_output_size_per_class = 5\n    max_total_size = 2**31\n    with self.assertRaisesRegex(\n        (TypeError, ValueError),\n        \"type int64 that does not match expected type of int32|\"\n        \"Tensor conversion requested dtype int32 for Tensor with dtype int64\"):\n      image_ops.combined_non_max_suppression(\n          boxes=boxes_np,\n          scores=scores_np,\n          max_output_size_per_class=max_output_size_per_class,\n          max_total_size=max_total_size)\n\n  # NOTE(b/142795960): parameterized tests do not work well with tf.tensor\n  # inputs. Due to failures, creating another this test which is identical to\n  # `testInvalidPyInput` except that the input is a tensor here as opposed\n  # to a scalar.\n  def testInvalidTensorInput(self):\n    boxes_np = [[[[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]]]\n    scores_np = [[[0.9, 0.75, 0.6, 0.95, 0.5, 0.3]]]\n    max_output_size_per_class = 5\n    max_total_size = ops.convert_to_tensor(2**31)\n    with self.assertRaisesRegex(\n        (TypeError, ValueError),\n        \"type int64 that does not match expected type of int32|\"\n        \"Tensor conversion requested dtype int32 for Tensor with dtype int64\"):\n      image_ops.combined_non_max_suppression(\n          boxes=boxes_np,\n          scores=scores_np,\n          max_output_size_per_class=max_output_size_per_class,\n          max_total_size=max_total_size)\n\n\nclass NonMaxSuppressionTest(test_util.TensorFlowTestCase):\n\n  def testNonMaxSuppression(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 3\n    iou_threshold_np = 0.5\n    with self.cached_session():\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices = image_ops.non_max_suppression(\n          boxes, scores, max_output_size, iou_threshold)\n      self.assertAllClose(selected_indices, [3, 0, 5])\n\n  def testInvalidShape(self):\n\n    def nms_func(box, score, iou_thres, score_thres):\n      return image_ops.non_max_suppression(box, score, iou_thres, score_thres)\n\n    iou_thres = 3\n    score_thres = 0.5\n\n    # The boxes should be 2D of shape [num_boxes, 4].\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 2 but is rank 1\"):\n      boxes = constant_op.constant([0.0, 0.0, 1.0, 1.0])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Dimension must be 4 but is 3\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The boxes is of shape [num_boxes, 4], and the scores is\n    # of shape [num_boxes]. So an error will be thrown.\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Dimensions must be equal, but are 1 and 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9, 0.75])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The scores should be 1D of shape [num_boxes].\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 1 but is rank 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([[0.9]])\n      nms_func(boxes, scores, iou_thres, score_thres)\n\n    # The max_output_size should be a scalar (0-D).\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 0 but is rank 1\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, [iou_thres], score_thres)\n\n    # The iou_threshold should be a scalar (0-D).\n    with self.assertRaisesRegex((ValueError, errors_impl.InvalidArgumentError),\n                                \"Shape must be rank 0 but is rank 2\"):\n      boxes = constant_op.constant([[0.0, 0.0, 1.0, 1.0]])\n      scores = constant_op.constant([0.9])\n      nms_func(boxes, scores, iou_thres, [[score_thres]])\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testTensors(self):\n    with context.eager_mode():\n      boxes_tensor = constant_op.constant([[6.625, 6.688, 272., 158.5],\n                                           [6.625, 6.75, 270.5, 158.4],\n                                           [5.375, 5., 272., 157.5]])\n      scores_tensor = constant_op.constant([0.84, 0.7944, 0.7715])\n      max_output_size = 100\n      iou_threshold = 0.5\n      score_threshold = 0.3\n      soft_nms_sigma = 0.25\n      pad_to_max_output_size = False\n\n      # gen_image_ops.non_max_suppression_v5.\n      for dtype in [np.float16, np.float32]:\n        boxes = math_ops.cast(boxes_tensor, dtype=dtype)\n        scores = math_ops.cast(scores_tensor, dtype=dtype)\n        _, _, num_selected = gen_image_ops.non_max_suppression_v5(\n            boxes, scores, max_output_size, iou_threshold, score_threshold,\n            soft_nms_sigma, pad_to_max_output_size)\n        self.assertEqual(num_selected.numpy(), 1)\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testDataTypes(self):\n    # Test case for GitHub issue 20199.\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 3\n    iou_threshold_np = 0.5\n    score_threshold_np = float(\"-inf\")\n    # Note: There are multiple versions of non_max_suppression v2, v3, v4.\n    # gen_image_ops.non_max_suppression_v2:\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        selected_indices = gen_image_ops.non_max_suppression_v2(\n            boxes, scores, max_output_size, iou_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v3\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        selected_indices = gen_image_ops.non_max_suppression_v3(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v4.\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        selected_indices, _ = gen_image_ops.non_max_suppression_v4(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n    # gen_image_ops.non_max_suppression_v5.\n    soft_nms_sigma_np = float(0.0)\n    for dtype in [np.float16, np.float32]:\n      with self.cached_session():\n        boxes = constant_op.constant(boxes_np, dtype=dtype)\n        scores = constant_op.constant(scores_np, dtype=dtype)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np, dtype=dtype)\n        score_threshold = constant_op.constant(score_threshold_np, dtype=dtype)\n        soft_nms_sigma = constant_op.constant(soft_nms_sigma_np, dtype=dtype)\n        selected_indices, _, _ = gen_image_ops.non_max_suppression_v5(\n            boxes, scores, max_output_size, iou_threshold, score_threshold,\n            soft_nms_sigma)\n        selected_indices = self.evaluate(selected_indices)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n\n  def testZeroIOUThreshold(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [1., 1., 1., 1., 1., 1.]\n    max_output_size_np = 3\n    iou_threshold_np = 0.0\n    with self.cached_session():\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices = image_ops.non_max_suppression(\n          boxes, scores, max_output_size, iou_threshold)\n      self.assertAllClose(selected_indices, [0, 3, 5])\n\n\nclass NonMaxSuppressionWithScoresTest(test_util.TensorFlowTestCase):\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersWithSoftNMS(self):\n    boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n    scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n    max_output_size_np = 6\n    iou_threshold_np = 0.5\n    score_threshold_np = 0.0\n    soft_nms_sigma_np = 0.5\n    boxes = constant_op.constant(boxes_np)\n    scores = constant_op.constant(scores_np)\n    max_output_size = constant_op.constant(max_output_size_np)\n    iou_threshold = constant_op.constant(iou_threshold_np)\n    score_threshold = constant_op.constant(score_threshold_np)\n    soft_nms_sigma = constant_op.constant(soft_nms_sigma_np)\n    selected_indices, selected_scores = \\\n        image_ops.non_max_suppression_with_scores(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            score_threshold,\n            soft_nms_sigma)\n    selected_indices, selected_scores = self.evaluate(\n        [selected_indices, selected_scores])\n    self.assertAllClose(selected_indices, [3, 0, 1, 5, 4, 2])\n    self.assertAllClose(selected_scores,\n                        [0.95, 0.9, 0.384, 0.3, 0.256, 0.197],\n                        rtol=1e-2, atol=1e-2)\n\n\nclass NonMaxSuppressionPaddedTest(test_util.TensorFlowTestCase,\n                                  parameterized.TestCase):\n\n  @test_util.disable_xla(\n      \"b/141236442: \"\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersV1(self):\n    with ops.Graph().as_default():\n      boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n      scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n      max_output_size_np = 5\n      iou_threshold_np = 0.5\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      selected_indices_padded, num_valid_padded = \\\n          image_ops.non_max_suppression_padded(\n              boxes,\n              scores,\n              max_output_size,\n              iou_threshold,\n              pad_to_max_output_size=True)\n      selected_indices, num_valid = image_ops.non_max_suppression_padded(\n          boxes,\n          scores,\n          max_output_size,\n          iou_threshold,\n          pad_to_max_output_size=False)\n      # The output shape of the padded operation must be fully defined.\n      self.assertEqual(selected_indices_padded.shape.is_fully_defined(), True)\n      self.assertEqual(selected_indices.shape.is_fully_defined(), False)\n      with self.cached_session():\n        self.assertAllClose(selected_indices_padded, [3, 0, 5, 0, 0])\n        self.assertEqual(num_valid_padded.eval(), 3)\n        self.assertAllClose(selected_indices, [3, 0, 5])\n        self.assertEqual(num_valid.eval(), 3)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  @test_util.disable_xla(\n      \"b/141236442: \"\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromThreeClustersV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def func(boxes, scores, max_output_size, iou_threshold):\n        boxes = constant_op.constant(boxes_np)\n        scores = constant_op.constant(scores_np)\n        max_output_size = constant_op.constant(max_output_size_np)\n        iou_threshold = constant_op.constant(iou_threshold_np)\n\n        yp, nvp = image_ops.non_max_suppression_padded(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            pad_to_max_output_size=True)\n\n        y, n = image_ops.non_max_suppression_padded(\n            boxes,\n            scores,\n            max_output_size,\n            iou_threshold,\n            pad_to_max_output_size=False)\n\n        # The output shape of the padded operation must be fully defined.\n        self.assertEqual(yp.shape.is_fully_defined(), True)\n        self.assertEqual(y.shape.is_fully_defined(), False)\n\n        return yp, nvp, y, n\n\n      boxes_np = [[0, 0, 1, 1], [0, 0.1, 1, 1.1], [0, -0.1, 1, 0.9],\n                  [0, 10, 1, 11], [0, 10.1, 1, 11.1], [0, 100, 1, 101]]\n      scores_np = [0.9, 0.75, 0.6, 0.95, 0.5, 0.3]\n      max_output_size_np = 5\n      iou_threshold_np = 0.5\n\n      selected_indices_padded, num_valid_padded, selected_indices, num_valid = \\\n          func(boxes_np, scores_np, max_output_size_np, iou_threshold_np)\n\n      with self.cached_session():\n        with test_util.run_functions_eagerly(run_func_eagerly):\n          self.assertAllClose(selected_indices_padded, [3, 0, 5, 0, 0])\n          self.assertEqual(self.evaluate(num_valid_padded), 3)\n          self.assertAllClose(selected_indices, [3, 0, 5])\n          self.assertEqual(self.evaluate(num_valid), 3)\n\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromContinuousOverLapV1(self):\n    with ops.Graph().as_default():\n      boxes_np = [[0, 0, 1, 1], [0, 0.2, 1, 1.2], [0, 0.4, 1, 1.4],\n                  [0, 0.6, 1, 1.6], [0, 0.8, 1, 1.8], [0, 2, 1, 2]]\n      scores_np = [0.9, 0.75, 0.6, 0.5, 0.4, 0.3]\n      max_output_size_np = 3\n      iou_threshold_np = 0.5\n      score_threshold_np = 0.1\n      boxes = constant_op.constant(boxes_np)\n      scores = constant_op.constant(scores_np)\n      max_output_size = constant_op.constant(max_output_size_np)\n      iou_threshold = constant_op.constant(iou_threshold_np)\n      score_threshold = constant_op.constant(score_threshold_np)\n      selected_indices, num_valid = image_ops.non_max_suppression_padded(\n          boxes,\n          scores,\n          max_output_size,\n          iou_threshold,\n          score_threshold)\n      # The output shape of the padded operation must be fully defined.\n      self.assertEqual(selected_indices.shape.is_fully_defined(), False)\n      with self.cached_session():\n        self.assertAllClose(selected_indices, [0, 2, 4])\n        self.assertEqual(num_valid.eval(), 3)\n\n  @parameterized.named_parameters([(\"_RunEagerly\", True), (\"_RunGraph\", False)])\n  @test_util.xla_allow_fallback(\n      \"non_max_suppression with dynamic output shape unsupported.\")\n  def testSelectFromContinuousOverLapV2(self, run_func_eagerly):\n    if not context.executing_eagerly() and run_func_eagerly:\n      # Skip running tf.function eagerly in V1 mode.\n      self.skipTest(\"Skip test that runs tf.function eagerly in V1 mode.\")\n    else:\n\n      @def_function.function\n      def func(boxes, scores, max_output_size, iou_threshold, score_threshold):\n        boxes = constant_op.constant(boxes)\n        scores = constant_op.constant(scores)\n        max_output_size = constant_op.constant(max_output_size)\n        iou_threshold = constant_op.constant(iou_threshold)\n        score_threshold = constant_op.constant(score_threshold)\n\n        y, nv = image_ops.non_max_suppression_padded(\n            boxes, scores, max_output_size, iou_threshold, score_threshold)\n\n        # The output shape of the padded operation must be fully defined.\n        self.assertEqual(y.shape.is_fully_defined(), False)\n\n        return y, nv\n\n      boxes_np = [[0, 0, 1, 1], [0, 0.2, 1, 1.2], [0, 0.4, 1, 1.4],\n                  [0, 0.6, 1, 1.6], [0, 0.8, 1, 1.8], [0, 2, 1, 2]]\n      scores_np = [0.9, 0.75, 0.6, 0.5, 0.4, 0.3]\n      max_output_size_np = 3\n      iou_threshold_np = 0.5\n      score_threshold_np = 0.1\n      selected_indices, num_valid = func(boxes_np, scores_np,\n                                         max_output_size_np, iou_threshold_np,\n                                         score_threshold_np)\n      with self.cached_session():\n        with test_util.run_functions_eagerly(run_func_eagerly):\n          self.assertAllClose(selected_indices, [0, 2, 4])\n          self.assertEqual(self.evaluate(num_valid), 3)\n\n  def testInvalidDtype(self):\n    boxes_np = [[4.0, 6.0, 3.0, 6.0],\n                [2.0, 1.0, 5.0, 4.0],\n                [9.0, 0.0, 9.0, 9.0]]\n    scores = [5.0, 6.0, 5.0]\n    max_output_size = 2**31\n    with self.assertRaisesRegex(\n        (TypeError, ValueError), \"type int64 that does not match type int32\"):\n      boxes = constant_op.constant(boxes_np)\n      image_ops.non_max_suppression_padded(boxes, scores, max_output_size)\n\n\nclass NonMaxSuppressionWithOverlapsTest(test_util.TensorFlowTestCase):\n\n  def testSelectOneFromThree(self):\n    overlaps_np = [\n        [1.0, 0.7, 0.2],\n        [0.7, 1.0, 0.0],\n        [0.2, 0.0, 1.0],\n    ]\n    scores_np = [0.7, 0.9, 0.1]\n    max_output_size_np = 3\n\n    overlaps = constant_op.constant(overlaps_np)\n    scores = constant_op.constant(scores_np)\n    max_output_size = constant_op.constant(max_output_size_np)\n    overlap_threshold = 0.6\n    score_threshold = 0.4\n\n    selected_indices = image_ops.non_max_suppression_with_overlaps(\n        overlaps, scores, max_output_size, overlap_threshold, score_threshold)\n\n    with self.cached_session():\n      self.assertAllClose(selected_indices, [1])\n\n\nclass VerifyCompatibleImageShapesTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests utility function used by ssim() and psnr().\"\"\"\n\n  def testWrongDims(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img = array_ops.placeholder(dtype=dtypes.float32)\n      img_np = np.array((2, 2))\n\n      with self.cached_session() as sess:\n        _, _, checks = image_ops_impl._verify_compatible_image_shapes(img, img)\n        with self.assertRaises(errors.InvalidArgumentError):\n          sess.run(checks, {img: img_np})\n\n  def testShapeMismatch(self):\n    # Shape function requires placeholders and a graph.\n    with ops.Graph().as_default():\n      img1 = array_ops.placeholder(dtype=dtypes.float32)\n      img2 = array_ops.placeholder(dtype=dtypes.float32)\n\n      img1_np = np.array([1, 2, 2, 1])\n      img2_np = np.array([1, 3, 3, 1])\n\n      with self.cached_session() as sess:\n        _, _, checks = image_ops_impl._verify_compatible_image_shapes(\n            img1, img2)\n        with self.assertRaises(errors.InvalidArgumentError):\n          sess.run(checks, {img1: img1_np, img2: img2_np})\n\n\nclass PSNRTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for PSNR.\"\"\"\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/psnr/testdata\", filename))\n    im = image_ops.decode_jpeg(content, dct_method=\"INTEGER_ACCURATE\")\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      q20 = self._LoadTestImage(sess, \"cat_q20.jpg\")\n      q72 = self._LoadTestImage(sess, \"cat_q72.jpg\")\n      q95 = self._LoadTestImage(sess, \"cat_q95.jpg\")\n      return q20, q72, q95\n\n  def _PSNR_NumPy(self, orig, target, max_value):\n    \"\"\"Numpy implementation of PSNR.\"\"\"\n    mse = ((orig - target) ** 2).mean(axis=(-3, -2, -1))\n    return 20 * np.log10(max_value) - 10 * np.log10(mse)\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testPSNRSingleImage(self):\n    image1 = self._RandomImage((8, 8, 1), 1)\n    image2 = self._RandomImage((8, 8, 1), 1)\n    psnr = self._PSNR_NumPy(image1, image2, 1)\n\n    with self.cached_session():\n      tf_image1 = constant_op.constant(image1, shape=image1.shape,\n                                       dtype=dtypes.float32)\n      tf_image2 = constant_op.constant(image2, shape=image2.shape,\n                                       dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_image1, tf_image2, 1.0, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testPSNRMultiImage(self):\n    image1 = self._RandomImage((10, 8, 8, 1), 1)\n    image2 = self._RandomImage((10, 8, 8, 1), 1)\n    psnr = self._PSNR_NumPy(image1, image2, 1)\n\n    with self.cached_session():\n      tf_image1 = constant_op.constant(image1, shape=image1.shape,\n                                       dtype=dtypes.float32)\n      tf_image2 = constant_op.constant(image2, shape=image2.shape,\n                                       dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_image1, tf_image2, 1, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testGoldenPSNR(self):\n    q20, q72, q95 = self._LoadTestImages()\n\n    # Verify NumPy implementation first.\n    # Golden values are generated using GNU Octave's psnr() function.\n    psnr1 = self._PSNR_NumPy(q20, q72, 1)\n    self.assertNear(30.321, psnr1, 0.001, msg=\"q20.dtype=\" + str(q20.dtype))\n    psnr2 = self._PSNR_NumPy(q20, q95, 1)\n    self.assertNear(29.994, psnr2, 0.001)\n    psnr3 = self._PSNR_NumPy(q72, q95, 1)\n    self.assertNear(35.302, psnr3, 0.001)\n\n    # Test TensorFlow implementation.\n    with self.cached_session():\n      tf_q20 = constant_op.constant(q20, shape=q20.shape, dtype=dtypes.float32)\n      tf_q72 = constant_op.constant(q72, shape=q72.shape, dtype=dtypes.float32)\n      tf_q95 = constant_op.constant(q95, shape=q95.shape, dtype=dtypes.float32)\n      tf_psnr1 = self.evaluate(image_ops.psnr(tf_q20, tf_q72, 1, \"psnr1\"))\n      tf_psnr2 = self.evaluate(image_ops.psnr(tf_q20, tf_q95, 1, \"psnr2\"))\n      tf_psnr3 = self.evaluate(image_ops.psnr(tf_q72, tf_q95, 1, \"psnr3\"))\n      self.assertAllClose(psnr1, tf_psnr1, atol=0.001)\n      self.assertAllClose(psnr2, tf_psnr2, atol=0.001)\n      self.assertAllClose(psnr3, tf_psnr3, atol=0.001)\n\n  def testInfinity(self):\n    q20, _, _ = self._LoadTestImages()\n    psnr = self._PSNR_NumPy(q20, q20, 1)\n    with self.cached_session():\n      tf_q20 = constant_op.constant(q20, shape=q20.shape, dtype=dtypes.float32)\n      tf_psnr = self.evaluate(image_ops.psnr(tf_q20, tf_q20, 1, \"psnr\"))\n      self.assertAllClose(psnr, tf_psnr, atol=0.001)\n\n  def testInt(self):\n    img1 = self._RandomImage((10, 8, 8, 1), 255)\n    img2 = self._RandomImage((10, 8, 8, 1), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    psnr_uint8 = image_ops.psnr(img1, img2, 255)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    psnr_float32 = image_ops.psnr(img1, img2, 1.0)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(psnr_uint8), self.evaluate(psnr_float32), atol=0.001)\n\n\nclass SSIMTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for SSIM.\"\"\"\n\n  _filenames = [\"checkerboard1.png\",\n                \"checkerboard2.png\",\n                \"checkerboard3.png\",]\n\n  _ssim = np.asarray([[1.000000, 0.230880, 0.231153],\n                      [0.230880, 1.000000, 0.996828],\n                      [0.231153, 0.996828, 1.000000]])\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/ssim/testdata\", filename))\n    im = image_ops.decode_png(content)\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      return [self._LoadTestImage(sess, f) for f in self._filenames]\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testAgainstMatlab(self):\n    \"\"\"Tests against values produced by Matlab.\"\"\"\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3)]\n\n    def ssim_func(x):\n      return image_ops.ssim(\n          *x, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    with self.cached_session():\n      scores = [\n          self.evaluate(ssim_func(t))\n          for t in itertools.combinations_with_replacement(img, 2)\n      ]\n\n    self.assertAllClose(expected, np.squeeze(scores), atol=1e-4)\n\n  def testBatch(self):\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    ssim = image_ops.ssim(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testBatchNumpyInputs(self):\n    img = self._LoadTestImages()\n    expected = self._ssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    with self.cached_session():\n      img1 = self.evaluate(constant_op.constant(img1))\n      img2 = self.evaluate(constant_op.constant(img2))\n\n    ssim = image_ops.ssim(\n        img1,\n        img2,\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testBroadcast(self):\n    img = self._LoadTestImages()[:2]\n    expected = self._ssim[:2, :2]\n\n    img = constant_op.constant(np.concatenate(img))\n    img1 = array_ops.expand_dims(img, axis=0)  # batch dims: 1, 2.\n    img2 = array_ops.expand_dims(img, axis=1)  # batch dims: 2, 1.\n\n    ssim = image_ops.ssim(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(ssim), atol=1e-4)\n\n  def testNegative(self):\n    \"\"\"Tests against negative SSIM index.\"\"\"\n    step = np.expand_dims(np.arange(0, 256, 16, dtype=np.uint8), axis=0)\n    img1 = np.tile(step, (16, 1))\n    img2 = np.fliplr(img1)\n\n    img1 = img1.reshape((1, 16, 16, 1))\n    img2 = img2.reshape((1, 16, 16, 1))\n\n    ssim = image_ops.ssim(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        255,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertLess(self.evaluate(ssim), 0)\n\n  def testInt(self):\n    img1 = self._RandomImage((1, 16, 16, 3), 255)\n    img2 = self._RandomImage((1, 16, 16, 3), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    ssim_uint8 = image_ops.ssim(\n        img1, img2, 255, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    ssim_float32 = image_ops.ssim(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(ssim_uint8), self.evaluate(ssim_float32), atol=0.001)\n\n\nclass MultiscaleSSIMTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests for MS-SSIM.\"\"\"\n\n  _filenames = [\"checkerboard1.png\",\n                \"checkerboard2.png\",\n                \"checkerboard3.png\",]\n\n  _msssim = np.asarray([[1.000000, 0.091016, 0.091025],\n                        [0.091016, 1.000000, 0.999567],\n                        [0.091025, 0.999567, 1.000000]])\n\n  def _LoadTestImage(self, sess, filename):\n    content = io_ops.read_file(os.path.join(\n        \"tensorflow/core/lib/ssim/testdata\", filename))\n    im = image_ops.decode_png(content)\n    im = image_ops.convert_image_dtype(im, dtypes.float32)\n    im, = self.evaluate([im])\n    return np.expand_dims(im, axis=0)\n\n  def _LoadTestImages(self):\n    with self.cached_session() as sess:\n      return [self._LoadTestImage(sess, f) for f in self._filenames]\n\n  def _RandomImage(self, shape, max_val):\n    \"\"\"Returns an image or image batch with given shape.\"\"\"\n    return np.random.rand(*shape).astype(np.float32) * max_val\n\n  def testAgainstMatlab(self):\n    \"\"\"Tests against MS-SSIM computed with Matlab implementation.\n\n    For color images, MS-SSIM scores are averaged over color channels.\n    \"\"\"\n    img = self._LoadTestImages()\n    expected = self._msssim[np.triu_indices(3)]\n\n    def ssim_func(x):\n      return image_ops.ssim_multiscale(\n          *x, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    with self.cached_session():\n      scores = [\n          self.evaluate(ssim_func(t))\n          for t in itertools.combinations_with_replacement(img, 2)\n      ]\n\n    self.assertAllClose(expected, np.squeeze(scores), atol=1e-4)\n\n  def testUnweightedIsDifferentiable(self):\n    img = self._LoadTestImages()\n\n    @def_function.function\n    def msssim_func(x1, x2, scalar):\n      return image_ops.ssim_multiscale(\n          x1 * scalar,\n          x2 * scalar,\n          max_val=1.0,\n          power_factors=(1, 1, 1, 1, 1),\n          filter_size=11,\n          filter_sigma=1.5,\n          k1=0.01,\n          k2=0.03)\n\n    scalar = constant_op.constant(1.0, dtype=dtypes.float32)\n\n    with backprop.GradientTape() as tape:\n      tape.watch(scalar)\n      y = msssim_func(img[0], img[1], scalar)\n\n    grad = tape.gradient(y, scalar)\n    np_grads = self.evaluate(grad)\n    self.assertTrue(np.isfinite(np_grads).all())\n\n  def testUnweightedIsDifferentiableEager(self):\n    if not context.executing_eagerly():\n      self.skipTest(\"Eager mode only\")\n\n    img = self._LoadTestImages()\n\n    def msssim_func(x1, x2, scalar):\n      return image_ops.ssim_multiscale(\n          x1 * scalar,\n          x2 * scalar,\n          max_val=1.0,\n          power_factors=(1, 1, 1, 1, 1),\n          filter_size=11,\n          filter_sigma=1.5,\n          k1=0.01,\n          k2=0.03)\n\n    scalar = constant_op.constant(1.0, dtype=dtypes.float32)\n\n    with backprop.GradientTape() as tape:\n      tape.watch(scalar)\n      y = msssim_func(img[0], img[1], scalar)\n\n    grad = tape.gradient(y, scalar)\n    np_grads = self.evaluate(grad)\n    self.assertTrue(np.isfinite(np_grads).all())\n\n  def testBatch(self):\n    \"\"\"Tests MS-SSIM computed in batch.\"\"\"\n    img = self._LoadTestImages()\n    expected = self._msssim[np.triu_indices(3, k=1)]\n\n    img1, img2 = zip(*itertools.combinations(img, 2))\n    img1 = np.concatenate(img1)\n    img2 = np.concatenate(img2)\n\n    msssim = image_ops.ssim_multiscale(\n        constant_op.constant(img1),\n        constant_op.constant(img2),\n        1.0,\n        filter_size=11,\n        filter_sigma=1.5,\n        k1=0.01,\n        k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(msssim), 1e-4)\n\n  def testBroadcast(self):\n    \"\"\"Tests MS-SSIM broadcasting.\"\"\"\n    img = self._LoadTestImages()[:2]\n    expected = self._msssim[:2, :2]\n\n    img = constant_op.constant(np.concatenate(img))\n    img1 = array_ops.expand_dims(img, axis=0)  # batch dims: 1, 2.\n    img2 = array_ops.expand_dims(img, axis=1)  # batch dims: 2, 1.\n\n    score_tensor = image_ops.ssim_multiscale(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(expected, self.evaluate(score_tensor), 1e-4)\n\n  def testRange(self):\n    \"\"\"Tests against low MS-SSIM score.\n\n    MS-SSIM is a geometric mean of SSIM and CS scores of various scales.\n    If any of the value is negative so that the geometric mean is not\n    well-defined, then treat the MS-SSIM score as zero.\n    \"\"\"\n    with self.cached_session() as sess:\n      img1 = self._LoadTestImage(sess, \"checkerboard1.png\")\n      img2 = self._LoadTestImage(sess, \"checkerboard3.png\")\n      images = [img1, img2, np.zeros_like(img1),\n                np.full_like(img1, fill_value=255)]\n\n      images = [ops.convert_to_tensor(x, dtype=dtypes.float32) for x in images]\n      msssim_ops = [\n          image_ops.ssim_multiscale(\n              x, y, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n          for x, y in itertools.combinations(images, 2)\n      ]\n      msssim = self.evaluate(msssim_ops)\n      msssim = np.squeeze(msssim)\n\n    self.assertTrue(np.all(msssim >= 0.0))\n    self.assertTrue(np.all(msssim <= 1.0))\n\n  def testInt(self):\n    img1 = self._RandomImage((1, 180, 240, 3), 255)\n    img2 = self._RandomImage((1, 180, 240, 3), 255)\n    img1 = constant_op.constant(img1, dtypes.uint8)\n    img2 = constant_op.constant(img2, dtypes.uint8)\n    ssim_uint8 = image_ops.ssim_multiscale(\n        img1, img2, 255, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    img1 = image_ops.convert_image_dtype(img1, dtypes.float32)\n    img2 = image_ops.convert_image_dtype(img2, dtypes.float32)\n    ssim_float32 = image_ops.ssim_multiscale(\n        img1, img2, 1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n    with self.cached_session():\n      self.assertAllClose(\n          self.evaluate(ssim_uint8), self.evaluate(ssim_float32), atol=0.001)\n\n  def testNumpyInput(self):\n    \"\"\"Test case for GitHub issue 28241.\"\"\"\n    image = np.random.random([512, 512, 1])\n    score_tensor = image_ops.ssim_multiscale(image, image, max_val=1.0)\n    with self.cached_session():\n      _ = self.evaluate(score_tensor)\n\n\nclass ImageGradientsTest(test_util.TensorFlowTestCase):\n\n  def testImageGradients(self):\n    shape = [1, 2, 4, 1]\n    img = constant_op.constant([[1, 3, 4, 2], [8, 7, 5, 6]])\n    img = array_ops.reshape(img, shape)\n\n    expected_dy = np.reshape([[7, 4, 1, 4], [0, 0, 0, 0]], shape)\n    expected_dx = np.reshape([[2, 1, -2, 0], [-1, -2, 1, 0]], shape)\n\n    dy, dx = image_ops.image_gradients(img)\n    with self.cached_session():\n      actual_dy = self.evaluate(dy)\n      actual_dx = self.evaluate(dx)\n      self.assertAllClose(expected_dy, actual_dy)\n      self.assertAllClose(expected_dx, actual_dx)\n\n  def testImageGradientsMultiChannelBatch(self):\n    batch = [[[[1, 2], [2, 5], [3, 3]],\n              [[8, 4], [5, 1], [9, 8]]],\n             [[[5, 3], [7, 9], [1, 6]],\n              [[1, 2], [6, 3], [6, 3]]]]\n\n    expected_dy = [[[[7, 2], [3, -4], [6, 5]],\n                    [[0, 0], [0, 0], [0, 0]]],\n                   [[[-4, -1], [-1, -6], [5, -3]],\n                    [[0, 0], [0, 0], [0, 0]]]]\n\n    expected_dx = [[[[1, 3], [1, -2], [0, 0]],\n                    [[-3, -3], [4, 7], [0, 0]]],\n                   [[[2, 6], [-6, -3], [0, 0]],\n                    [[5, 1], [0, 0], [0, 0]]]]\n\n    batch = constant_op.constant(batch)\n    assert batch.get_shape().as_list() == [2, 2, 3, 2]\n    dy, dx = image_ops.image_gradients(batch)\n    with self.cached_session():\n      actual_dy = self.evaluate(dy)\n      actual_dx = self.evaluate(dx)\n      self.assertAllClose(expected_dy, actual_dy)\n      self.assertAllClose(expected_dx, actual_dx)\n\n  def testImageGradientsBadShape(self):\n    # [2 x 4] image but missing batch and depth dimensions.\n    img = constant_op.constant([[1, 3, 4, 2], [8, 7, 5, 6]])\n    with self.assertRaises(ValueError):\n      image_ops.image_gradients(img)\n\n\nclass SobelEdgesTest(test_util.TensorFlowTestCase):\n\n  def disabled_testSobelEdges1x2x3x1(self):\n    img = constant_op.constant([[1, 3, 6], [4, 1, 5]],\n                               dtype=dtypes.float32, shape=[1, 2, 3, 1])\n    expected = np.reshape([[[0, 0], [0, 12], [0, 0]],\n                           [[0, 0], [0, 12], [0, 0]]], [1, 2, 3, 1, 2])\n    sobel = image_ops.sobel_edges(img)\n    with self.cached_session():\n      actual_sobel = self.evaluate(sobel)\n      self.assertAllClose(expected, actual_sobel)\n\n  def testSobelEdges5x3x4x2(self):\n    batch_size = 5\n    plane = np.reshape([[1, 3, 6, 2], [4, 1, 5, 7], [2, 5, 1, 4]],\n                       [1, 3, 4, 1])\n    two_channel = np.concatenate([plane, plane], axis=3)\n    batch = np.concatenate([two_channel] * batch_size, axis=0)\n    img = constant_op.constant(batch, dtype=dtypes.float32,\n                               shape=[batch_size, 3, 4, 2])\n\n    expected_plane = np.reshape([[[0, 0], [0, 12], [0, 10], [0, 0]],\n                                 [[6, 0], [0, 6], [-6, 10], [-6, 0]],\n                                 [[0, 0], [0, 0], [0, 10], [0, 0]]],\n                                [1, 3, 4, 1, 2])\n    expected_two_channel = np.concatenate(\n        [expected_plane, expected_plane], axis=3)\n    expected_batch = np.concatenate([expected_two_channel] * batch_size, axis=0)\n\n    sobel = image_ops.sobel_edges(img)\n    with self.cached_session():\n      actual_sobel = self.evaluate(sobel)\n      self.assertAllClose(expected_batch, actual_sobel)\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass DecodeImageTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  _FORWARD_COMPATIBILITY_HORIZONS = [\n      (2020, 1, 1),\n      (2020, 7, 14),\n      (2525, 1, 1),  # future behavior\n  ]\n\n  def testBmpChannels(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with test_util.use_gpu():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          # `rgba_transparent.bmp` has 4 channels with transparent pixels.\n          # Test consistency between `decode_image` and `decode_bmp` functions.\n          bmp0 = io_ops.read_file(os.path.join(base, \"rgba_small.bmp\"))\n          image0 = image_ops.decode_image(bmp0, channels=4)\n          image1 = image_ops.decode_bmp(bmp0, channels=4)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n          # Test that 3 channels is returned with user request of `channels=3`\n          # even though image has 4 channels.\n          # Note that this operation simply drops 4th channel information. This\n          # is the same behavior as `decode_png`.\n          # e.g. pixel values [25, 25, 25, 100] becomes [25, 25, 25].\n          bmp1 = io_ops.read_file(os.path.join(base, \"rgb_small.bmp\"))\n          image2 = image_ops.decode_bmp(bmp0, channels=3)\n          image3 = image_ops.decode_bmp(bmp1)\n          image2, image3 = self.evaluate([image2, image3])\n          self.assertAllEqual(image2, image3)\n\n          # Test that 4 channels is returned with user request of `channels=4`\n          # even though image has 3 channels. Alpha channel should be set to\n          # UINT8_MAX.\n          bmp3 = io_ops.read_file(os.path.join(base, \"rgb_small_255.bmp\"))\n          bmp4 = io_ops.read_file(os.path.join(base, \"rgba_small_255.bmp\"))\n          image4 = image_ops.decode_bmp(bmp3, channels=4)\n          image5 = image_ops.decode_bmp(bmp4)\n          image4, image5 = self.evaluate([image4, image5])\n          self.assertAllEqual(image4, image5)\n\n          # Test that 3 channels is returned with user request of `channels=3`\n          # even though image has 1 channel (grayscale).\n          bmp6 = io_ops.read_file(os.path.join(base, \"grayscale_small.bmp\"))\n          bmp7 = io_ops.read_file(\n              os.path.join(base, \"grayscale_small_3channels.bmp\"))\n          image6 = image_ops.decode_bmp(bmp6, channels=3)\n          image7 = image_ops.decode_bmp(bmp7)\n          image6, image7 = self.evaluate([image6, image7])\n          self.assertAllEqual(image6, image7)\n\n          # Test that 4 channels is returned with user request of `channels=4`\n          # even though image has 1 channel (grayscale). Alpha channel should be\n          # set to UINT8_MAX.\n          bmp9 = io_ops.read_file(\n              os.path.join(base, \"grayscale_small_4channels.bmp\"))\n          image8 = image_ops.decode_bmp(bmp6, channels=4)\n          image9 = image_ops.decode_bmp(bmp9)\n          image8, image9 = self.evaluate([image8, image9])\n          self.assertAllEqual(image8, image9)\n\n  def testJpegUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/jpeg/testdata\"\n          jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n          image0 = image_ops.decode_image(jpeg0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_jpeg(jpeg0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testPngUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/png/testdata\"\n          png0 = io_ops.read_file(os.path.join(base, \"lena_rgba.png\"))\n          image0 = image_ops.decode_image(png0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(\n              image_ops.decode_png(png0, dtype=dtypes.uint16), dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n          # NumPy conversions should happen before\n          x = np.random.randint(256, size=(4, 4, 3), dtype=np.uint16)\n          x_str = image_ops_impl.encode_png(x)\n          x_dec = image_ops_impl.decode_image(\n              x_str, channels=3, dtype=dtypes.uint16)\n          self.assertAllEqual(x, x_dec)\n\n  def testGifUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n          image0 = image_ops.decode_image(gif0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_gif(gif0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testBmpUint16(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          bmp0 = io_ops.read_file(os.path.join(base, \"lena.bmp\"))\n          image0 = image_ops.decode_image(bmp0, dtype=dtypes.uint16)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_bmp(bmp0),\n                                                 dtypes.uint16)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testJpegFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/jpeg/testdata\"\n          jpeg0 = io_ops.read_file(os.path.join(base, \"jpeg_merge_test1.jpg\"))\n          image0 = image_ops.decode_image(jpeg0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_jpeg(jpeg0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testPngFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/png/testdata\"\n          png0 = io_ops.read_file(os.path.join(base, \"lena_rgba.png\"))\n          image0 = image_ops.decode_image(png0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(\n              image_ops.decode_png(png0, dtype=dtypes.uint16), dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testGifFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n          image0 = image_ops.decode_image(gif0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_gif(gif0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testBmpFloat32(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/bmp/testdata\"\n          bmp0 = io_ops.read_file(os.path.join(base, \"lena.bmp\"))\n          image0 = image_ops.decode_image(bmp0, dtype=dtypes.float32)\n          image1 = image_ops.convert_image_dtype(image_ops.decode_bmp(bmp0),\n                                                 dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertAllEqual(image0, image1)\n\n  def testExpandAnimations(self):\n    for horizon in self._FORWARD_COMPATIBILITY_HORIZONS:\n      with compat.forward_compatibility_horizon(*horizon):\n        with self.cached_session():\n          base = \"tensorflow/core/lib/gif/testdata\"\n          gif0 = io_ops.read_file(os.path.join(base, \"scan.gif\"))\n\n          # Test `expand_animations=False` case.\n          image0 = image_ops.decode_image(\n              gif0, dtype=dtypes.float32, expand_animations=False)\n          # image_ops.decode_png() handles GIFs and returns 3D tensors\n          animation = image_ops.decode_gif(gif0)\n          first_frame = array_ops.gather(animation, 0)\n          image1 = image_ops.convert_image_dtype(first_frame, dtypes.float32)\n          image0, image1 = self.evaluate([image0, image1])\n          self.assertLen(image0.shape, 3)\n          self.assertAllEqual(list(image0.shape), [40, 20, 3])\n          self.assertAllEqual(image0, image1)\n\n          # Test `expand_animations=True` case.\n          image2 = image_ops.decode_image(gif0, dtype=dtypes.float32)\n          image3 = image_ops.convert_image_dtype(animation, dtypes.float32)\n          image2, image3 = self.evaluate([image2, image3])\n          self.assertLen(image2.shape, 4)\n          self.assertAllEqual(list(image2.shape), [12, 40, 20, 3])\n          self.assertAllEqual(image2, image3)\n\n  def testImageCropAndResize(self):\n    if test_util.is_gpu_available():\n      op = image_ops_impl.crop_and_resize_v2(\n          image=array_ops.zeros((2, 1, 1, 1)),\n          boxes=[[1.0e+40, 0, 0, 0]],\n          box_indices=[1],\n          crop_size=[1, 1])\n      self.evaluate(op)\n    else:\n      message = \"Boxes contains at least one element that is not finite\"\n      with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                  message):\n        op = image_ops_impl.crop_and_resize_v2(\n            image=array_ops.zeros((2, 1, 1, 1)),\n            boxes=[[1.0e+40, 0, 0, 0]],\n            box_indices=[1],\n            crop_size=[1, 1])\n        self.evaluate(op)\n\n  def testImageCropAndResizeWithInvalidInput(self):\n    with self.session():\n      with self.assertRaises((errors.InternalError, ValueError)):\n        op = image_ops_impl.crop_and_resize_v2(\n            image=np.ones((1, 1, 1, 1)),\n            boxes=np.ones((11, 4)),\n            box_indices=np.ones((11)),\n            crop_size=[2065374891, 1145309325])\n        self.evaluate(op)\n\n  @parameterized.named_parameters(\n      (\"_jpeg\", \"JPEG\", \"jpeg_merge_test1.jpg\"),\n      (\"_png\", \"PNG\", \"lena_rgba.png\"),\n      (\"_gif\", \"GIF\", \"scan.gif\"),\n  )\n  def testWrongOpBmp(self, img_format, filename):\n    base_folder = \"tensorflow/core/lib\"\n    base_path = os.path.join(base_folder, img_format.lower(), \"testdata\")\n    err_msg = \"Trying to decode \" + img_format + \" format using DecodeBmp op\"\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img_bytes = io_ops.read_file(os.path.join(base_path, filename))\n      img = image_ops.decode_bmp(img_bytes)\n      self.evaluate(img)\n\n  @parameterized.named_parameters(\n      (\"_jpeg\", image_ops.decode_jpeg, \"DecodeJpeg\"),\n      (\"_png\", image_ops.decode_png, \"DecodePng\"),\n      (\"_gif\", image_ops.decode_gif, \"DecodeGif\"),\n  )\n  def testWrongOp(self, decode_op, op_used):\n    base = \"tensorflow/core/lib/bmp/testdata\"\n    bmp0 = io_ops.read_file(os.path.join(base, \"rgba_small.bmp\"))\n    err_msg = (\"Trying to decode BMP format using a wrong op. Use `decode_bmp` \"\n               \"or `decode_image` instead. Op used: \") + op_used\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img = decode_op(bmp0)\n      self.evaluate(img)\n\n  @parameterized.named_parameters(\n      (\"_png\", \"PNG\", \"lena_rgba.png\"),\n      (\"_gif\", \"GIF\", \"scan.gif\"),\n      (\"_bmp\", \"BMP\", \"rgba_small.bmp\"),\n  )\n  def testWrongOpJpeg(self, img_format, filename):\n    base_folder = \"tensorflow/core/lib\"\n    base_path = os.path.join(base_folder, img_format.lower(), \"testdata\")\n    err_msg = (\"DecodeAndCropJpeg operation can run on JPEG only, but \"\n               \"detected \") + img_format\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), err_msg):\n      img_bytes = io_ops.read_file(os.path.join(base_path, filename))\n      img = image_ops.decode_and_crop_jpeg(img_bytes, [1, 1, 2, 2])\n      self.evaluate(img)\n\n  def testGifFramesWithDiffSize(self):\n    \"\"\"Test decoding an animated GIF.\n\n    This test verifies that `decode_image` op can decode animated GIFs whose\n    first frame does not fill the canvas. The unoccupied areas should be filled\n    with zeros (black).\n\n    `squares.gif` is animated with two images of different sizes. It\n    alternates between a smaller image of size 10 x 10 and a larger image of\n    size 16 x 16. Because it starts animating with the smaller image, the first\n    frame does not fill the canvas. (Canvas size is equal to max frame width x\n    max frame height.)\n\n    `red_black.gif` has just a single image in a GIF format. It is the same\n    image as the smaller image (size 10 x 10) of the two images in\n    `squares.gif`. The only difference is that its background (canvas - smaller\n    image) is pre-filled with zeros (black); it is the groundtruth.\n    \"\"\"\n    base = \"tensorflow/core/lib/gif/testdata\"\n    gif_bytes0 = io_ops.read_file(os.path.join(base, \"squares.gif\"))\n    image0 = image_ops.decode_image(gif_bytes0, dtype=dtypes.float32,\n                                    expand_animations=False)\n    gif_bytes1 = io_ops.read_file(os.path.join(base, \"red_black.gif\"))\n    image1 = image_ops.decode_image(gif_bytes1, dtype=dtypes.float32)\n    image1_0 = array_ops.gather(image1, 0)\n    image0, image1_0 = self.evaluate([image0, image1_0])\n    self.assertAllEqual(image0, image1_0)\n\n\nif __name__ == \"__main__\":\n  googletest.main()\n"], "filenames": ["tensorflow/core/kernels/image/crop_and_resize_op.cc", "tensorflow/python/ops/image_ops_test.py"], "buggy_code_start_loc": [172, 6077], "buggy_code_end_loc": [428, 6077], "fixing_code_start_loc": [173, 6078], "fixing_code_end_loc": [430, 6088], "type": "CWE-190", "message": "TensorFlow is an open source platform for machine learning. In affected versions TensorFlow allows tensor to have a large number of dimensions and each dimension can be as large as desired. However, the total number of elements in a tensor must fit within an `int64_t`. If an overflow occurs, `MultiplyWithoutOverflow` would return a negative result. In the majority of TensorFlow codebase this then results in a `CHECK`-failure. Newer constructs exist which return a `Status` instead of crashing the binary. This is similar to CVE-2021-29584. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-41197", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T20:15:07.843", "lastModified": "2021-11-09T14:30:53.583", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions TensorFlow allows tensor to have a large number of dimensions and each dimension can be as large as desired. However, the total number of elements in a tensor must fit within an `int64_t`. If an overflow occurs, `MultiplyWithoutOverflow` would return a negative result. In the majority of TensorFlow codebase this then results in a `CHECK`-failure. Newer constructs exist which return a `Status` instead of crashing the binary. This is similar to CVE-2021-29584. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas TensorFlow permite que el tensor tenga un gran n\u00famero de dimensiones y cada dimensi\u00f3n puede ser tan grande como se desee. Sin embargo, el n\u00famero total de elementos en un tensor debe caber dentro de un \"int64_t\". Si se produce un desbordamiento, \"MultiplyWithoutOverflow\" devolver\u00e1 un resultado negativo. En la mayor\u00eda de los c\u00f3digos de TensorFlow esto resulta en un fallo de \"CHECK\". Se presentan nuevas construcciones que devuelven un \"Status\" en lugar de bloquear el binario. Esto es similar a CVE-2021-29584. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n ser\u00e1 incluida este commit en TensorFlow versi\u00f3n 2.6.1, TensorFlow versi\u00f3n 2.5.2, y TensorFlow versi\u00f3n 2.4.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.4.4", "matchCriteriaId": "455FB550-4C9C-4BD6-9F76-A627B62AB332"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.5.0", "versionEndExcluding": "2.5.2", "matchCriteriaId": "035CDF63-1548-4FB4-B8A9-B8D328FAF910"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "2.6.1", "matchCriteriaId": "5D68D8D1-DB27-4395-9D3D-2BED901B852C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/7c1692bd417eb4f9b33ead749a41166d6080af85", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/a871989d7b6c18cdebf2fb4f0e5c5b62fbc19edf", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/d81b1351da3e8c884ff836b64458d94e4a157c15", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/issues/46890", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/issues/51908", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-prcg-wp5q-rv7p", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/7c1692bd417eb4f9b33ead749a41166d6080af85"}}