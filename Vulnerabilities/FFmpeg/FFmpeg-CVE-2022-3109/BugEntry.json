{"buggy_code": ["/*\n * Copyright (C) 2003-2004 The FFmpeg project\n * Copyright (C) 2019 Peter Ross\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * On2 VP3/VP4 Video Decoder\n *\n * VP3 Video Decoder by Mike Melanson (mike at multimedia.cx)\n * For more information about the VP3 coding process, visit:\n *   http://wiki.multimedia.cx/index.php?title=On2_VP3\n *\n * Theora decoder by Alex Beregszaszi\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/mem_internal.h\"\n\n#include \"avcodec.h\"\n#include \"get_bits.h\"\n#include \"hpeldsp.h\"\n#include \"internal.h\"\n#include \"mathops.h\"\n#include \"thread.h\"\n#include \"threadframe.h\"\n#include \"videodsp.h\"\n#include \"vp3data.h\"\n#include \"vp4data.h\"\n#include \"vp3dsp.h\"\n#include \"xiph.h\"\n\n#define VP3_MV_VLC_BITS     6\n#define VP4_MV_VLC_BITS     6\n#define SUPERBLOCK_VLC_BITS 6\n\n#define FRAGMENT_PIXELS 8\n\n// FIXME split things out into their own arrays\ntypedef struct Vp3Fragment {\n    int16_t dc;\n    uint8_t coding_method;\n    uint8_t qpi;\n} Vp3Fragment;\n\n#define SB_NOT_CODED        0\n#define SB_PARTIALLY_CODED  1\n#define SB_FULLY_CODED      2\n\n// This is the maximum length of a single long bit run that can be encoded\n// for superblock coding or block qps. Theora special-cases this to read a\n// bit instead of flipping the current bit to allow for runs longer than 4129.\n#define MAXIMUM_LONG_BIT_RUN 4129\n\n#define MODE_INTER_NO_MV      0\n#define MODE_INTRA            1\n#define MODE_INTER_PLUS_MV    2\n#define MODE_INTER_LAST_MV    3\n#define MODE_INTER_PRIOR_LAST 4\n#define MODE_USING_GOLDEN     5\n#define MODE_GOLDEN_MV        6\n#define MODE_INTER_FOURMV     7\n#define CODING_MODE_COUNT     8\n\n/* special internal mode */\n#define MODE_COPY             8\n\nstatic int theora_decode_header(AVCodecContext *avctx, GetBitContext *gb);\nstatic int theora_decode_tables(AVCodecContext *avctx, GetBitContext *gb);\n\n\n/* There are 6 preset schemes, plus a free-form scheme */\nstatic const int ModeAlphabet[6][CODING_MODE_COUNT] = {\n    /* scheme 1: Last motion vector dominates */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_PLUS_MV,    MODE_INTER_NO_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 2 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_NO_MV,      MODE_INTER_PLUS_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 3 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PLUS_MV,\n      MODE_INTER_PRIOR_LAST, MODE_INTER_NO_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 4 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PLUS_MV,\n      MODE_INTER_NO_MV,      MODE_INTER_PRIOR_LAST,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 5: No motion vector dominates */\n    { MODE_INTER_NO_MV,      MODE_INTER_LAST_MV,\n      MODE_INTER_PRIOR_LAST, MODE_INTER_PLUS_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 6 */\n    { MODE_INTER_NO_MV,      MODE_USING_GOLDEN,\n      MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_PLUS_MV,    MODE_INTRA,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n};\n\nstatic const uint8_t hilbert_offset[16][2] = {\n    { 0, 0 }, { 1, 0 }, { 1, 1 }, { 0, 1 },\n    { 0, 2 }, { 0, 3 }, { 1, 3 }, { 1, 2 },\n    { 2, 2 }, { 2, 3 }, { 3, 3 }, { 3, 2 },\n    { 3, 1 }, { 2, 1 }, { 2, 0 }, { 3, 0 }\n};\n\nenum {\n    VP4_DC_INTRA  = 0,\n    VP4_DC_INTER  = 1,\n    VP4_DC_GOLDEN = 2,\n    NB_VP4_DC_TYPES,\n    VP4_DC_UNDEFINED = NB_VP4_DC_TYPES\n};\n\nstatic const uint8_t vp4_pred_block_type_map[8] = {\n    [MODE_INTER_NO_MV]      = VP4_DC_INTER,\n    [MODE_INTRA]            = VP4_DC_INTRA,\n    [MODE_INTER_PLUS_MV]    = VP4_DC_INTER,\n    [MODE_INTER_LAST_MV]    = VP4_DC_INTER,\n    [MODE_INTER_PRIOR_LAST] = VP4_DC_INTER,\n    [MODE_USING_GOLDEN]     = VP4_DC_GOLDEN,\n    [MODE_GOLDEN_MV]        = VP4_DC_GOLDEN,\n    [MODE_INTER_FOURMV]     = VP4_DC_INTER,\n};\n\ntypedef struct {\n    int dc;\n    int type;\n} VP4Predictor;\n\n#define MIN_DEQUANT_VAL 2\n\ntypedef struct HuffEntry {\n    uint8_t len, sym;\n} HuffEntry;\n\ntypedef struct HuffTable {\n    HuffEntry entries[32];\n    uint8_t   nb_entries;\n} HuffTable;\n\ntypedef struct Vp3DecodeContext {\n    AVCodecContext *avctx;\n    int theora, theora_tables, theora_header;\n    int version;\n    int width, height;\n    int chroma_x_shift, chroma_y_shift;\n    ThreadFrame golden_frame;\n    ThreadFrame last_frame;\n    ThreadFrame current_frame;\n    int keyframe;\n    uint8_t idct_permutation[64];\n    uint8_t idct_scantable[64];\n    HpelDSPContext hdsp;\n    VideoDSPContext vdsp;\n    VP3DSPContext vp3dsp;\n    DECLARE_ALIGNED(16, int16_t, block)[64];\n    int flipped_image;\n    int last_slice_end;\n    int skip_loop_filter;\n\n    int qps[3];\n    int nqps;\n    int last_qps[3];\n\n    int superblock_count;\n    int y_superblock_width;\n    int y_superblock_height;\n    int y_superblock_count;\n    int c_superblock_width;\n    int c_superblock_height;\n    int c_superblock_count;\n    int u_superblock_start;\n    int v_superblock_start;\n    unsigned char *superblock_coding;\n\n    int macroblock_count; /* y macroblock count */\n    int macroblock_width;\n    int macroblock_height;\n    int c_macroblock_count;\n    int c_macroblock_width;\n    int c_macroblock_height;\n    int yuv_macroblock_count; /* y+u+v macroblock count */\n\n    int fragment_count;\n    int fragment_width[2];\n    int fragment_height[2];\n\n    Vp3Fragment *all_fragments;\n    int fragment_start[3];\n    int data_offset[3];\n    uint8_t offset_x;\n    uint8_t offset_y;\n    int offset_x_warned;\n\n    int8_t (*motion_val[2])[2];\n\n    /* tables */\n    uint16_t coded_dc_scale_factor[2][64];\n    uint32_t coded_ac_scale_factor[64];\n    uint8_t base_matrix[384][64];\n    uint8_t qr_count[2][3];\n    uint8_t qr_size[2][3][64];\n    uint16_t qr_base[2][3][64];\n\n    /**\n     * This is a list of all tokens in bitstream order. Reordering takes place\n     * by pulling from each level during IDCT. As a consequence, IDCT must be\n     * in Hilbert order, making the minimum slice height 64 for 4:2:0 and 32\n     * otherwise. The 32 different tokens with up to 12 bits of extradata are\n     * collapsed into 3 types, packed as follows:\n     *   (from the low to high bits)\n     *\n     * 2 bits: type (0,1,2)\n     *   0: EOB run, 14 bits for run length (12 needed)\n     *   1: zero run, 7 bits for run length\n     *                7 bits for the next coefficient (3 needed)\n     *   2: coefficient, 14 bits (11 needed)\n     *\n     * Coefficients are signed, so are packed in the highest bits for automatic\n     * sign extension.\n     */\n    int16_t *dct_tokens[3][64];\n    int16_t *dct_tokens_base;\n#define TOKEN_EOB(eob_run)              ((eob_run) << 2)\n#define TOKEN_ZERO_RUN(coeff, zero_run) (((coeff) * 512) + ((zero_run) << 2) + 1)\n#define TOKEN_COEFF(coeff)              (((coeff) * 4) + 2)\n\n    /**\n     * number of blocks that contain DCT coefficients at\n     * the given level or higher\n     */\n    int num_coded_frags[3][64];\n    int total_num_coded_frags;\n\n    /* this is a list of indexes into the all_fragments array indicating\n     * which of the fragments are coded */\n    int *coded_fragment_list[3];\n\n    int *kf_coded_fragment_list;\n    int *nkf_coded_fragment_list;\n    int num_kf_coded_fragment[3];\n\n    /* The first 16 of the following VLCs are for the dc coefficients;\n       the others are four groups of 16 VLCs each for ac coefficients. */\n    VLC coeff_vlc[5 * 16];\n\n    VLC superblock_run_length_vlc; /* version < 2 */\n    VLC fragment_run_length_vlc; /* version < 2 */\n    VLC block_pattern_vlc[2]; /* version >= 2*/\n    VLC mode_code_vlc;\n    VLC motion_vector_vlc; /* version < 2 */\n    VLC vp4_mv_vlc[2][7]; /* version >=2 */\n\n    /* these arrays need to be on 16-byte boundaries since SSE2 operations\n     * index into them */\n    DECLARE_ALIGNED(16, int16_t, qmat)[3][2][3][64];     ///< qmat[qpi][is_inter][plane]\n\n    /* This table contains superblock_count * 16 entries. Each set of 16\n     * numbers corresponds to the fragment indexes 0..15 of the superblock.\n     * An entry will be -1 to indicate that no entry corresponds to that\n     * index. */\n    int *superblock_fragments;\n\n    /* This is an array that indicates how a particular macroblock\n     * is coded. */\n    unsigned char *macroblock_coding;\n\n    uint8_t *edge_emu_buffer;\n\n    /* Huffman decode */\n    HuffTable huffman_table[5 * 16];\n\n    uint8_t filter_limit_values[64];\n    DECLARE_ALIGNED(8, int, bounding_values_array)[256 + 2];\n\n    VP4Predictor * dc_pred_row; /* dc_pred_row[y_superblock_width * 4] */\n} Vp3DecodeContext;\n\n/************************************************************************\n * VP3 specific functions\n ************************************************************************/\n\nstatic av_cold void free_tables(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    av_freep(&s->superblock_coding);\n    av_freep(&s->all_fragments);\n    av_freep(&s->nkf_coded_fragment_list);\n    av_freep(&s->kf_coded_fragment_list);\n    av_freep(&s->dct_tokens_base);\n    av_freep(&s->superblock_fragments);\n    av_freep(&s->macroblock_coding);\n    av_freep(&s->dc_pred_row);\n    av_freep(&s->motion_val[0]);\n    av_freep(&s->motion_val[1]);\n}\n\nstatic void vp3_decode_flush(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    if (s->golden_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->golden_frame);\n    if (s->last_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->last_frame);\n    if (s->current_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->current_frame);\n}\n\nstatic av_cold int vp3_decode_end(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, j;\n\n    free_tables(avctx);\n    av_freep(&s->edge_emu_buffer);\n\n    s->theora_tables = 0;\n\n    /* release all frames */\n    vp3_decode_flush(avctx);\n    av_frame_free(&s->current_frame.f);\n    av_frame_free(&s->last_frame.f);\n    av_frame_free(&s->golden_frame.f);\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++)\n        ff_free_vlc(&s->coeff_vlc[i]);\n\n    ff_free_vlc(&s->superblock_run_length_vlc);\n    ff_free_vlc(&s->fragment_run_length_vlc);\n    ff_free_vlc(&s->mode_code_vlc);\n    ff_free_vlc(&s->motion_vector_vlc);\n\n    for (j = 0; j < 2; j++)\n        for (i = 0; i < 7; i++)\n            ff_free_vlc(&s->vp4_mv_vlc[j][i]);\n\n    for (i = 0; i < 2; i++)\n        ff_free_vlc(&s->block_pattern_vlc[i]);\n    return 0;\n}\n\n/**\n * This function sets up all of the various blocks mappings:\n * superblocks <-> fragments, macroblocks <-> fragments,\n * superblocks <-> macroblocks\n *\n * @return 0 is successful; returns 1 if *anything* went wrong.\n */\nstatic int init_block_mapping(Vp3DecodeContext *s)\n{\n    int sb_x, sb_y, plane;\n    int x, y, i, j = 0;\n\n    for (plane = 0; plane < 3; plane++) {\n        int sb_width    = plane ? s->c_superblock_width\n                                : s->y_superblock_width;\n        int sb_height   = plane ? s->c_superblock_height\n                                : s->y_superblock_height;\n        int frag_width  = s->fragment_width[!!plane];\n        int frag_height = s->fragment_height[!!plane];\n\n        for (sb_y = 0; sb_y < sb_height; sb_y++)\n            for (sb_x = 0; sb_x < sb_width; sb_x++)\n                for (i = 0; i < 16; i++) {\n                    x = 4 * sb_x + hilbert_offset[i][0];\n                    y = 4 * sb_y + hilbert_offset[i][1];\n\n                    if (x < frag_width && y < frag_height)\n                        s->superblock_fragments[j++] = s->fragment_start[plane] +\n                                                       y * frag_width + x;\n                    else\n                        s->superblock_fragments[j++] = -1;\n                }\n    }\n\n    return 0;  /* successful path out */\n}\n\n/*\n * This function sets up the dequantization tables used for a particular\n * frame.\n */\nstatic void init_dequantizer(Vp3DecodeContext *s, int qpi)\n{\n    int ac_scale_factor = s->coded_ac_scale_factor[s->qps[qpi]];\n    int i, plane, inter, qri, bmi, bmj, qistart;\n\n    for (inter = 0; inter < 2; inter++) {\n        for (plane = 0; plane < 3; plane++) {\n            int dc_scale_factor = s->coded_dc_scale_factor[!!plane][s->qps[qpi]];\n            int sum = 0;\n            for (qri = 0; qri < s->qr_count[inter][plane]; qri++) {\n                sum += s->qr_size[inter][plane][qri];\n                if (s->qps[qpi] <= sum)\n                    break;\n            }\n            qistart = sum - s->qr_size[inter][plane][qri];\n            bmi     = s->qr_base[inter][plane][qri];\n            bmj     = s->qr_base[inter][plane][qri + 1];\n            for (i = 0; i < 64; i++) {\n                int coeff = (2 * (sum     - s->qps[qpi]) * s->base_matrix[bmi][i] -\n                             2 * (qistart - s->qps[qpi]) * s->base_matrix[bmj][i] +\n                             s->qr_size[inter][plane][qri]) /\n                            (2 * s->qr_size[inter][plane][qri]);\n\n                int qmin   = 8 << (inter + !i);\n                int qscale = i ? ac_scale_factor : dc_scale_factor;\n                int qbias = (1 + inter) * 3;\n                s->qmat[qpi][inter][plane][s->idct_permutation[i]] =\n                    (i == 0 || s->version < 2) ? av_clip((qscale * coeff) / 100 * 4, qmin, 4096)\n                                               : (qscale * (coeff - qbias) / 100 + qbias) * 4;\n            }\n            /* all DC coefficients use the same quant so as not to interfere\n             * with DC prediction */\n            s->qmat[qpi][inter][plane][0] = s->qmat[0][inter][plane][0];\n        }\n    }\n}\n\n/*\n * This function initializes the loop filter boundary limits if the frame's\n * quality index is different from the previous frame's.\n *\n * The filter_limit_values may not be larger than 127.\n */\nstatic void init_loop_filter(Vp3DecodeContext *s)\n{\n    ff_vp3dsp_set_bounding_values(s->bounding_values_array, s->filter_limit_values[s->qps[0]]);\n}\n\n/*\n * This function unpacks all of the superblock/macroblock/fragment coding\n * information from the bitstream.\n */\nstatic int unpack_superblocks(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int superblock_starts[3] = {\n        0, s->u_superblock_start, s->v_superblock_start\n    };\n    int bit = 0;\n    int current_superblock = 0;\n    int current_run = 0;\n    int num_partial_superblocks = 0;\n\n    int i, j;\n    int current_fragment;\n    int plane;\n    int plane0_num_coded_frags = 0;\n\n    if (s->keyframe) {\n        memset(s->superblock_coding, SB_FULLY_CODED, s->superblock_count);\n    } else {\n        /* unpack the list of partially-coded superblocks */\n        bit         = get_bits1(gb) ^ 1;\n        current_run = 0;\n\n        while (current_superblock < s->superblock_count && get_bits_left(gb) > 0) {\n            if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n                bit = get_bits1(gb);\n            else\n                bit ^= 1;\n\n            current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                   SUPERBLOCK_VLC_BITS, 2);\n            if (current_run == 34)\n                current_run += get_bits(gb, 12);\n\n            if (current_run > s->superblock_count - current_superblock) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Invalid partially coded superblock run length\\n\");\n                return -1;\n            }\n\n            memset(s->superblock_coding + current_superblock, bit, current_run);\n\n            current_superblock += current_run;\n            if (bit)\n                num_partial_superblocks += current_run;\n        }\n\n        /* unpack the list of fully coded superblocks if any of the blocks were\n         * not marked as partially coded in the previous step */\n        if (num_partial_superblocks < s->superblock_count) {\n            int superblocks_decoded = 0;\n\n            current_superblock = 0;\n            bit                = get_bits1(gb) ^ 1;\n            current_run        = 0;\n\n            while (superblocks_decoded < s->superblock_count - num_partial_superblocks &&\n                   get_bits_left(gb) > 0) {\n                if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n                    bit = get_bits1(gb);\n                else\n                    bit ^= 1;\n\n                current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                       SUPERBLOCK_VLC_BITS, 2);\n                if (current_run == 34)\n                    current_run += get_bits(gb, 12);\n\n                for (j = 0; j < current_run; current_superblock++) {\n                    if (current_superblock >= s->superblock_count) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                               \"Invalid fully coded superblock run length\\n\");\n                        return -1;\n                    }\n\n                    /* skip any superblocks already marked as partially coded */\n                    if (s->superblock_coding[current_superblock] == SB_NOT_CODED) {\n                        s->superblock_coding[current_superblock] = 2 * bit;\n                        j++;\n                    }\n                }\n                superblocks_decoded += current_run;\n            }\n        }\n\n        /* if there were partial blocks, initialize bitstream for\n         * unpacking fragment codings */\n        if (num_partial_superblocks) {\n            current_run = 0;\n            bit         = get_bits1(gb);\n            /* toggle the bit because as soon as the first run length is\n             * fetched the bit will be toggled again */\n            bit ^= 1;\n        }\n    }\n\n    /* figure out which fragments are coded; iterate through each\n     * superblock (all planes) */\n    s->total_num_coded_frags = 0;\n    memset(s->macroblock_coding, MODE_COPY, s->macroblock_count);\n\n    s->coded_fragment_list[0] = s->keyframe ? s->kf_coded_fragment_list\n                                            : s->nkf_coded_fragment_list;\n\n    for (plane = 0; plane < 3; plane++) {\n        int sb_start = superblock_starts[plane];\n        int sb_end   = sb_start + (plane ? s->c_superblock_count\n                                         : s->y_superblock_count);\n        int num_coded_frags = 0;\n\n        if (s->keyframe) {\n            if (s->num_kf_coded_fragment[plane] == -1) {\n                for (i = sb_start; i < sb_end; i++) {\n                    /* iterate through all 16 fragments in a superblock */\n                    for (j = 0; j < 16; j++) {\n                        /* if the fragment is in bounds, check its coding status */\n                        current_fragment = s->superblock_fragments[i * 16 + j];\n                        if (current_fragment != -1) {\n                            s->coded_fragment_list[plane][num_coded_frags++] =\n                                current_fragment;\n                        }\n                    }\n                }\n                s->num_kf_coded_fragment[plane] = num_coded_frags;\n            } else\n                num_coded_frags = s->num_kf_coded_fragment[plane];\n        } else {\n            for (i = sb_start; i < sb_end && get_bits_left(gb) > 0; i++) {\n                if (get_bits_left(gb) < plane0_num_coded_frags >> 2) {\n                    return AVERROR_INVALIDDATA;\n                }\n                /* iterate through all 16 fragments in a superblock */\n                for (j = 0; j < 16; j++) {\n                    /* if the fragment is in bounds, check its coding status */\n                    current_fragment = s->superblock_fragments[i * 16 + j];\n                    if (current_fragment != -1) {\n                        int coded = s->superblock_coding[i];\n\n                        if (coded == SB_PARTIALLY_CODED) {\n                            /* fragment may or may not be coded; this is the case\n                             * that cares about the fragment coding runs */\n                            if (current_run-- == 0) {\n                                bit        ^= 1;\n                                current_run = get_vlc2(gb, s->fragment_run_length_vlc.table, 5, 2);\n                            }\n                            coded = bit;\n                        }\n\n                        if (coded) {\n                            /* default mode; actual mode will be decoded in\n                             * the next phase */\n                            s->all_fragments[current_fragment].coding_method =\n                                MODE_INTER_NO_MV;\n                            s->coded_fragment_list[plane][num_coded_frags++] =\n                                current_fragment;\n                        } else {\n                            /* not coded; copy this fragment from the prior frame */\n                            s->all_fragments[current_fragment].coding_method =\n                                MODE_COPY;\n                        }\n                    }\n                }\n            }\n        }\n        if (!plane)\n            plane0_num_coded_frags = num_coded_frags;\n        s->total_num_coded_frags += num_coded_frags;\n        for (i = 0; i < 64; i++)\n            s->num_coded_frags[plane][i] = num_coded_frags;\n        if (plane < 2)\n            s->coded_fragment_list[plane + 1] = s->coded_fragment_list[plane] +\n                                                num_coded_frags;\n    }\n    return 0;\n}\n\n#define BLOCK_X (2 * mb_x + (k & 1))\n#define BLOCK_Y (2 * mb_y + (k >> 1))\n\n#if CONFIG_VP4_DECODER\n/**\n * @return number of blocks, or > yuv_macroblock_count on error.\n *         return value is always >= 1.\n */\nstatic int vp4_get_mb_count(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int v = 1;\n    int bits;\n    while ((bits = show_bits(gb, 9)) == 0x1ff) {\n        skip_bits(gb, 9);\n        v += 256;\n        if (v > s->yuv_macroblock_count) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid run length\\n\");\n            return v;\n        }\n    }\n#define body(n) { \\\n    skip_bits(gb, 2 + n); \\\n    v += (1 << n) + get_bits(gb, n); }\n#define thresh(n) (0x200 - (0x80 >> n))\n#define else_if(n) else if (bits < thresh(n)) body(n)\n    if (bits < 0x100) {\n        skip_bits(gb, 1);\n    } else if (bits < thresh(0)) {\n        skip_bits(gb, 2);\n        v += 1;\n    }\n    else_if(1)\n    else_if(2)\n    else_if(3)\n    else_if(4)\n    else_if(5)\n    else_if(6)\n    else body(7)\n#undef body\n#undef thresh\n#undef else_if\n    return v;\n}\n\nstatic int vp4_get_block_pattern(Vp3DecodeContext *s, GetBitContext *gb, int *next_block_pattern_table)\n{\n    int v = get_vlc2(gb, s->block_pattern_vlc[*next_block_pattern_table].table, 3, 2);\n    *next_block_pattern_table = vp4_block_pattern_table_selector[v];\n    return v + 1;\n}\n\nstatic int vp4_unpack_macroblocks(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int plane, i, j, k, fragment;\n    int next_block_pattern_table;\n    int bit, current_run, has_partial;\n\n    memset(s->macroblock_coding, MODE_COPY, s->macroblock_count);\n\n    if (s->keyframe)\n        return 0;\n\n    has_partial = 0;\n    bit         = get_bits1(gb);\n    for (i = 0; i < s->yuv_macroblock_count; i += current_run) {\n        if (get_bits_left(gb) <= 0)\n            return AVERROR_INVALIDDATA;\n        current_run = vp4_get_mb_count(s, gb);\n        if (current_run > s->yuv_macroblock_count - i)\n            return -1;\n        memset(s->superblock_coding + i, 2 * bit, current_run);\n        bit ^= 1;\n        has_partial |= bit;\n    }\n\n    if (has_partial) {\n        if (get_bits_left(gb) <= 0)\n            return AVERROR_INVALIDDATA;\n        bit  = get_bits1(gb);\n        current_run = vp4_get_mb_count(s, gb);\n        for (i = 0; i < s->yuv_macroblock_count; i++) {\n            if (!s->superblock_coding[i]) {\n                if (!current_run) {\n                    bit ^= 1;\n                    current_run = vp4_get_mb_count(s, gb);\n                }\n                s->superblock_coding[i] = bit;\n                current_run--;\n            }\n        }\n        if (current_run) /* handle situation when vp4_get_mb_count() fails */\n            return -1;\n    }\n\n    next_block_pattern_table = 0;\n    i = 0;\n    for (plane = 0; plane < 3; plane++) {\n        int sb_x, sb_y;\n        int sb_width = plane ? s->c_superblock_width : s->y_superblock_width;\n        int sb_height = plane ? s->c_superblock_height : s->y_superblock_height;\n        int mb_width = plane ? s->c_macroblock_width : s->macroblock_width;\n        int mb_height = plane ? s->c_macroblock_height : s->macroblock_height;\n        int fragment_width = s->fragment_width[!!plane];\n        int fragment_height = s->fragment_height[!!plane];\n\n        for (sb_y = 0; sb_y < sb_height; sb_y++) {\n            for (sb_x = 0; sb_x < sb_width; sb_x++) {\n                for (j = 0; j < 4; j++) {\n                    int mb_x = 2 * sb_x + (j >> 1);\n                    int mb_y = 2 * sb_y + (j >> 1) ^ (j & 1);\n                    int mb_coded, pattern, coded;\n\n                    if (mb_x >= mb_width || mb_y >= mb_height)\n                        continue;\n\n                    mb_coded = s->superblock_coding[i++];\n\n                    if (mb_coded == SB_FULLY_CODED)\n                        pattern = 0xF;\n                    else if (mb_coded == SB_PARTIALLY_CODED)\n                        pattern = vp4_get_block_pattern(s, gb, &next_block_pattern_table);\n                    else\n                        pattern = 0;\n\n                    for (k = 0; k < 4; k++) {\n                        if (BLOCK_X >= fragment_width || BLOCK_Y >= fragment_height)\n                            continue;\n                        fragment = s->fragment_start[plane] + BLOCK_Y * fragment_width + BLOCK_X;\n                        coded = pattern & (8 >> k);\n                        /* MODE_INTER_NO_MV is the default for coded fragments.\n                           the actual method is decoded in the next phase. */\n                        s->all_fragments[fragment].coding_method = coded ? MODE_INTER_NO_MV : MODE_COPY;\n                    }\n                }\n            }\n        }\n    }\n    return 0;\n}\n#endif\n\n/*\n * This function unpacks all the coding mode data for individual macroblocks\n * from the bitstream.\n */\nstatic int unpack_modes(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i, j, k, sb_x, sb_y;\n    int scheme;\n    int current_macroblock;\n    int current_fragment;\n    int coding_mode;\n    int custom_mode_alphabet[CODING_MODE_COUNT];\n    const int *alphabet;\n    Vp3Fragment *frag;\n\n    if (s->keyframe) {\n        for (i = 0; i < s->fragment_count; i++)\n            s->all_fragments[i].coding_method = MODE_INTRA;\n    } else {\n        /* fetch the mode coding scheme for this frame */\n        scheme = get_bits(gb, 3);\n\n        /* is it a custom coding scheme? */\n        if (scheme == 0) {\n            for (i = 0; i < 8; i++)\n                custom_mode_alphabet[i] = MODE_INTER_NO_MV;\n            for (i = 0; i < 8; i++)\n                custom_mode_alphabet[get_bits(gb, 3)] = i;\n            alphabet = custom_mode_alphabet;\n        } else\n            alphabet = ModeAlphabet[scheme - 1];\n\n        /* iterate through all of the macroblocks that contain 1 or more\n         * coded fragments */\n        for (sb_y = 0; sb_y < s->y_superblock_height; sb_y++) {\n            for (sb_x = 0; sb_x < s->y_superblock_width; sb_x++) {\n                if (get_bits_left(gb) <= 0)\n                    return -1;\n\n                for (j = 0; j < 4; j++) {\n                    int mb_x = 2 * sb_x + (j >> 1);\n                    int mb_y = 2 * sb_y + (((j >> 1) + j) & 1);\n                    current_macroblock = mb_y * s->macroblock_width + mb_x;\n\n                    if (mb_x >= s->macroblock_width ||\n                        mb_y >= s->macroblock_height)\n                        continue;\n\n                    /* coding modes are only stored if the macroblock has\n                     * at least one luma block coded, otherwise it must be\n                     * INTER_NO_MV */\n                    for (k = 0; k < 4; k++) {\n                        current_fragment = BLOCK_Y *\n                                           s->fragment_width[0] + BLOCK_X;\n                        if (s->all_fragments[current_fragment].coding_method != MODE_COPY)\n                            break;\n                    }\n                    if (k == 4) {\n                        s->macroblock_coding[current_macroblock] = MODE_INTER_NO_MV;\n                        continue;\n                    }\n\n                    /* mode 7 means get 3 bits for each coding mode */\n                    if (scheme == 7)\n                        coding_mode = get_bits(gb, 3);\n                    else\n                        coding_mode = alphabet[get_vlc2(gb, s->mode_code_vlc.table, 3, 3)];\n\n                    s->macroblock_coding[current_macroblock] = coding_mode;\n                    for (k = 0; k < 4; k++) {\n                        frag = s->all_fragments + BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                        if (frag->coding_method != MODE_COPY)\n                            frag->coding_method = coding_mode;\n                    }\n\n#define SET_CHROMA_MODES                                                      \\\n    if (frag[s->fragment_start[1]].coding_method != MODE_COPY)                \\\n        frag[s->fragment_start[1]].coding_method = coding_mode;               \\\n    if (frag[s->fragment_start[2]].coding_method != MODE_COPY)                \\\n        frag[s->fragment_start[2]].coding_method = coding_mode;\n\n                    if (s->chroma_y_shift) {\n                        frag = s->all_fragments + mb_y *\n                               s->fragment_width[1] + mb_x;\n                        SET_CHROMA_MODES\n                    } else if (s->chroma_x_shift) {\n                        frag = s->all_fragments +\n                               2 * mb_y * s->fragment_width[1] + mb_x;\n                        for (k = 0; k < 2; k++) {\n                            SET_CHROMA_MODES\n                            frag += s->fragment_width[1];\n                        }\n                    } else {\n                        for (k = 0; k < 4; k++) {\n                            frag = s->all_fragments +\n                                   BLOCK_Y * s->fragment_width[1] + BLOCK_X;\n                            SET_CHROMA_MODES\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic int vp4_get_mv(Vp3DecodeContext *s, GetBitContext *gb, int axis, int last_motion)\n{\n    int v = get_vlc2(gb, s->vp4_mv_vlc[axis][vp4_mv_table_selector[FFABS(last_motion)]].table,\n                     VP4_MV_VLC_BITS, 2);\n    return last_motion < 0 ? -v : v;\n}\n\n/*\n * This function unpacks all the motion vectors for the individual\n * macroblocks from the bitstream.\n */\nstatic int unpack_vectors(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int j, k, sb_x, sb_y;\n    int coding_mode;\n    int motion_x[4];\n    int motion_y[4];\n    int last_motion_x = 0;\n    int last_motion_y = 0;\n    int prior_last_motion_x = 0;\n    int prior_last_motion_y = 0;\n    int last_gold_motion_x = 0;\n    int last_gold_motion_y = 0;\n    int current_macroblock;\n    int current_fragment;\n    int frag;\n\n    if (s->keyframe)\n        return 0;\n\n    /* coding mode 0 is the VLC scheme; 1 is the fixed code scheme; 2 is VP4 code scheme */\n    coding_mode = s->version < 2 ? get_bits1(gb) : 2;\n\n    /* iterate through all of the macroblocks that contain 1 or more\n     * coded fragments */\n    for (sb_y = 0; sb_y < s->y_superblock_height; sb_y++) {\n        for (sb_x = 0; sb_x < s->y_superblock_width; sb_x++) {\n            if (get_bits_left(gb) <= 0)\n                return -1;\n\n            for (j = 0; j < 4; j++) {\n                int mb_x = 2 * sb_x + (j >> 1);\n                int mb_y = 2 * sb_y + (((j >> 1) + j) & 1);\n                current_macroblock = mb_y * s->macroblock_width + mb_x;\n\n                if (mb_x >= s->macroblock_width  ||\n                    mb_y >= s->macroblock_height ||\n                    s->macroblock_coding[current_macroblock] == MODE_COPY)\n                    continue;\n\n                switch (s->macroblock_coding[current_macroblock]) {\n                case MODE_GOLDEN_MV:\n                    if (coding_mode == 2) { /* VP4 */\n                        last_gold_motion_x = motion_x[0] = vp4_get_mv(s, gb, 0, last_gold_motion_x);\n                        last_gold_motion_y = motion_y[0] = vp4_get_mv(s, gb, 1, last_gold_motion_y);\n                        break;\n                    } /* otherwise fall through */\n                case MODE_INTER_PLUS_MV:\n                    /* all 6 fragments use the same motion vector */\n                    if (coding_mode == 0) {\n                        motion_x[0] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                               VP3_MV_VLC_BITS, 2);\n                        motion_y[0] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                               VP3_MV_VLC_BITS, 2);\n                    } else if (coding_mode == 1) {\n                        motion_x[0] = fixed_motion_vector_table[get_bits(gb, 6)];\n                        motion_y[0] = fixed_motion_vector_table[get_bits(gb, 6)];\n                    } else { /* VP4 */\n                        motion_x[0] = vp4_get_mv(s, gb, 0, last_motion_x);\n                        motion_y[0] = vp4_get_mv(s, gb, 1, last_motion_y);\n                    }\n\n                    /* vector maintenance, only on MODE_INTER_PLUS_MV */\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_PLUS_MV) {\n                        prior_last_motion_x = last_motion_x;\n                        prior_last_motion_y = last_motion_y;\n                        last_motion_x       = motion_x[0];\n                        last_motion_y       = motion_y[0];\n                    }\n                    break;\n\n                case MODE_INTER_FOURMV:\n                    /* vector maintenance */\n                    prior_last_motion_x = last_motion_x;\n                    prior_last_motion_y = last_motion_y;\n\n                    /* fetch 4 vectors from the bitstream, one for each\n                     * Y fragment, then average for the C fragment vectors */\n                    for (k = 0; k < 4; k++) {\n                        current_fragment = BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                        if (s->all_fragments[current_fragment].coding_method != MODE_COPY) {\n                            if (coding_mode == 0) {\n                                motion_x[k] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                                       VP3_MV_VLC_BITS, 2);\n                                motion_y[k] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                                       VP3_MV_VLC_BITS, 2);\n                            } else if (coding_mode == 1) {\n                                motion_x[k] = fixed_motion_vector_table[get_bits(gb, 6)];\n                                motion_y[k] = fixed_motion_vector_table[get_bits(gb, 6)];\n                            } else { /* VP4 */\n                                motion_x[k] = vp4_get_mv(s, gb, 0, prior_last_motion_x);\n                                motion_y[k] = vp4_get_mv(s, gb, 1, prior_last_motion_y);\n                            }\n                            last_motion_x = motion_x[k];\n                            last_motion_y = motion_y[k];\n                        } else {\n                            motion_x[k] = 0;\n                            motion_y[k] = 0;\n                        }\n                    }\n                    break;\n\n                case MODE_INTER_LAST_MV:\n                    /* all 6 fragments use the last motion vector */\n                    motion_x[0] = last_motion_x;\n                    motion_y[0] = last_motion_y;\n\n                    /* no vector maintenance (last vector remains the\n                     * last vector) */\n                    break;\n\n                case MODE_INTER_PRIOR_LAST:\n                    /* all 6 fragments use the motion vector prior to the\n                     * last motion vector */\n                    motion_x[0] = prior_last_motion_x;\n                    motion_y[0] = prior_last_motion_y;\n\n                    /* vector maintenance */\n                    prior_last_motion_x = last_motion_x;\n                    prior_last_motion_y = last_motion_y;\n                    last_motion_x       = motion_x[0];\n                    last_motion_y       = motion_y[0];\n                    break;\n\n                default:\n                    /* covers intra, inter without MV, golden without MV */\n                    motion_x[0] = 0;\n                    motion_y[0] = 0;\n\n                    /* no vector maintenance */\n                    break;\n                }\n\n                /* assign the motion vectors to the correct fragments */\n                for (k = 0; k < 4; k++) {\n                    current_fragment =\n                        BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        s->motion_val[0][current_fragment][0] = motion_x[k];\n                        s->motion_val[0][current_fragment][1] = motion_y[k];\n                    } else {\n                        s->motion_val[0][current_fragment][0] = motion_x[0];\n                        s->motion_val[0][current_fragment][1] = motion_y[0];\n                    }\n                }\n\n                if (s->chroma_y_shift) {\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        motion_x[0] = RSHIFT(motion_x[0] + motion_x[1] +\n                                             motion_x[2] + motion_x[3], 2);\n                        motion_y[0] = RSHIFT(motion_y[0] + motion_y[1] +\n                                             motion_y[2] + motion_y[3], 2);\n                    }\n                    if (s->version <= 2) {\n                        motion_x[0] = (motion_x[0] >> 1) | (motion_x[0] & 1);\n                        motion_y[0] = (motion_y[0] >> 1) | (motion_y[0] & 1);\n                    }\n                    frag = mb_y * s->fragment_width[1] + mb_x;\n                    s->motion_val[1][frag][0] = motion_x[0];\n                    s->motion_val[1][frag][1] = motion_y[0];\n                } else if (s->chroma_x_shift) {\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        motion_x[0] = RSHIFT(motion_x[0] + motion_x[1], 1);\n                        motion_y[0] = RSHIFT(motion_y[0] + motion_y[1], 1);\n                        motion_x[1] = RSHIFT(motion_x[2] + motion_x[3], 1);\n                        motion_y[1] = RSHIFT(motion_y[2] + motion_y[3], 1);\n                    } else {\n                        motion_x[1] = motion_x[0];\n                        motion_y[1] = motion_y[0];\n                    }\n                    if (s->version <= 2) {\n                        motion_x[0] = (motion_x[0] >> 1) | (motion_x[0] & 1);\n                        motion_x[1] = (motion_x[1] >> 1) | (motion_x[1] & 1);\n                    }\n                    frag = 2 * mb_y * s->fragment_width[1] + mb_x;\n                    for (k = 0; k < 2; k++) {\n                        s->motion_val[1][frag][0] = motion_x[k];\n                        s->motion_val[1][frag][1] = motion_y[k];\n                        frag += s->fragment_width[1];\n                    }\n                } else {\n                    for (k = 0; k < 4; k++) {\n                        frag = BLOCK_Y * s->fragment_width[1] + BLOCK_X;\n                        if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                            s->motion_val[1][frag][0] = motion_x[k];\n                            s->motion_val[1][frag][1] = motion_y[k];\n                        } else {\n                            s->motion_val[1][frag][0] = motion_x[0];\n                            s->motion_val[1][frag][1] = motion_y[0];\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic int unpack_block_qpis(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int qpi, i, j, bit, run_length, blocks_decoded, num_blocks_at_qpi;\n    int num_blocks = s->total_num_coded_frags;\n\n    for (qpi = 0; qpi < s->nqps - 1 && num_blocks > 0; qpi++) {\n        i = blocks_decoded = num_blocks_at_qpi = 0;\n\n        bit        = get_bits1(gb) ^ 1;\n        run_length = 0;\n\n        do {\n            if (run_length == MAXIMUM_LONG_BIT_RUN)\n                bit = get_bits1(gb);\n            else\n                bit ^= 1;\n\n            run_length = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                  SUPERBLOCK_VLC_BITS, 2);\n            if (run_length == 34)\n                run_length += get_bits(gb, 12);\n            blocks_decoded += run_length;\n\n            if (!bit)\n                num_blocks_at_qpi += run_length;\n\n            for (j = 0; j < run_length; i++) {\n                if (i >= s->total_num_coded_frags)\n                    return -1;\n\n                if (s->all_fragments[s->coded_fragment_list[0][i]].qpi == qpi) {\n                    s->all_fragments[s->coded_fragment_list[0][i]].qpi += bit;\n                    j++;\n                }\n            }\n        } while (blocks_decoded < num_blocks && get_bits_left(gb) > 0);\n\n        num_blocks -= num_blocks_at_qpi;\n    }\n\n    return 0;\n}\n\nstatic inline int get_eob_run(GetBitContext *gb, int token)\n{\n    int v = eob_run_table[token].base;\n    if (eob_run_table[token].bits)\n        v += get_bits(gb, eob_run_table[token].bits);\n    return v;\n}\n\nstatic inline int get_coeff(GetBitContext *gb, int token, int16_t *coeff)\n{\n    int bits_to_get, zero_run;\n\n    bits_to_get = coeff_get_bits[token];\n    if (bits_to_get)\n        bits_to_get = get_bits(gb, bits_to_get);\n    *coeff = coeff_tables[token][bits_to_get];\n\n    zero_run = zero_run_base[token];\n    if (zero_run_get_bits[token])\n        zero_run += get_bits(gb, zero_run_get_bits[token]);\n\n    return zero_run;\n}\n\n/*\n * This function is called by unpack_dct_coeffs() to extract the VLCs from\n * the bitstream. The VLCs encode tokens which are used to unpack DCT\n * data. This function unpacks all the VLCs for either the Y plane or both\n * C planes, and is called for DC coefficients or different AC coefficient\n * levels (since different coefficient types require different VLC tables.\n *\n * This function returns a residual eob run. E.g, if a particular token gave\n * instructions to EOB the next 5 fragments and there were only 2 fragments\n * left in the current fragment range, 3 would be returned so that it could\n * be passed into the next call to this same function.\n */\nstatic int unpack_vlcs(Vp3DecodeContext *s, GetBitContext *gb,\n                       VLC *table, int coeff_index,\n                       int plane,\n                       int eob_run)\n{\n    int i, j = 0;\n    int token;\n    int zero_run  = 0;\n    int16_t coeff = 0;\n    int blocks_ended;\n    int coeff_i = 0;\n    int num_coeffs      = s->num_coded_frags[plane][coeff_index];\n    int16_t *dct_tokens = s->dct_tokens[plane][coeff_index];\n\n    /* local references to structure members to avoid repeated dereferences */\n    int *coded_fragment_list   = s->coded_fragment_list[plane];\n    Vp3Fragment *all_fragments = s->all_fragments;\n    VLC_TYPE(*vlc_table)[2] = table->table;\n\n    if (num_coeffs < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Invalid number of coefficients at level %d\\n\", coeff_index);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (eob_run > num_coeffs) {\n        coeff_i      =\n        blocks_ended = num_coeffs;\n        eob_run     -= num_coeffs;\n    } else {\n        coeff_i      =\n        blocks_ended = eob_run;\n        eob_run      = 0;\n    }\n\n    // insert fake EOB token to cover the split between planes or zzi\n    if (blocks_ended)\n        dct_tokens[j++] = blocks_ended << 2;\n\n    while (coeff_i < num_coeffs && get_bits_left(gb) > 0) {\n        /* decode a VLC into a token */\n        token = get_vlc2(gb, vlc_table, 11, 3);\n        /* use the token to get a zero run, a coefficient, and an eob run */\n        if ((unsigned) token <= 6U) {\n            eob_run = get_eob_run(gb, token);\n            if (!eob_run)\n                eob_run = INT_MAX;\n\n            // record only the number of blocks ended in this plane,\n            // any spill will be recorded in the next plane.\n            if (eob_run > num_coeffs - coeff_i) {\n                dct_tokens[j++] = TOKEN_EOB(num_coeffs - coeff_i);\n                blocks_ended   += num_coeffs - coeff_i;\n                eob_run        -= num_coeffs - coeff_i;\n                coeff_i         = num_coeffs;\n            } else {\n                dct_tokens[j++] = TOKEN_EOB(eob_run);\n                blocks_ended   += eob_run;\n                coeff_i        += eob_run;\n                eob_run         = 0;\n            }\n        } else if (token >= 0) {\n            zero_run = get_coeff(gb, token, &coeff);\n\n            if (zero_run) {\n                dct_tokens[j++] = TOKEN_ZERO_RUN(coeff, zero_run);\n            } else {\n                // Save DC into the fragment structure. DC prediction is\n                // done in raster order, so the actual DC can't be in with\n                // other tokens. We still need the token in dct_tokens[]\n                // however, or else the structure collapses on itself.\n                if (!coeff_index)\n                    all_fragments[coded_fragment_list[coeff_i]].dc = coeff;\n\n                dct_tokens[j++] = TOKEN_COEFF(coeff);\n            }\n\n            if (coeff_index + zero_run > 64) {\n                av_log(s->avctx, AV_LOG_DEBUG,\n                       \"Invalid zero run of %d with %d coeffs left\\n\",\n                       zero_run, 64 - coeff_index);\n                zero_run = 64 - coeff_index;\n            }\n\n            // zero runs code multiple coefficients,\n            // so don't try to decode coeffs for those higher levels\n            for (i = coeff_index + 1; i <= coeff_index + zero_run; i++)\n                s->num_coded_frags[plane][i]--;\n            coeff_i++;\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid token %d\\n\", token);\n            return -1;\n        }\n    }\n\n    if (blocks_ended > s->num_coded_frags[plane][coeff_index])\n        av_log(s->avctx, AV_LOG_ERROR, \"More blocks ended than coded!\\n\");\n\n    // decrement the number of blocks that have higher coefficients for each\n    // EOB run at this level\n    if (blocks_ended)\n        for (i = coeff_index + 1; i < 64; i++)\n            s->num_coded_frags[plane][i] -= blocks_ended;\n\n    // setup the next buffer\n    if (plane < 2)\n        s->dct_tokens[plane + 1][coeff_index] = dct_tokens + j;\n    else if (coeff_index < 63)\n        s->dct_tokens[0][coeff_index + 1] = dct_tokens + j;\n\n    return eob_run;\n}\n\nstatic void reverse_dc_prediction(Vp3DecodeContext *s,\n                                  int first_fragment,\n                                  int fragment_width,\n                                  int fragment_height);\n/*\n * This function unpacks all of the DCT coefficient data from the\n * bitstream.\n */\nstatic int unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i;\n    int dc_y_table;\n    int dc_c_table;\n    int ac_y_table;\n    int ac_c_table;\n    int residual_eob_run = 0;\n    VLC *y_tables[64];\n    VLC *c_tables[64];\n\n    s->dct_tokens[0][0] = s->dct_tokens_base;\n\n    if (get_bits_left(gb) < 16)\n        return AVERROR_INVALIDDATA;\n\n    /* fetch the DC table indexes */\n    dc_y_table = get_bits(gb, 4);\n    dc_c_table = get_bits(gb, 4);\n\n    /* unpack the Y plane DC coefficients */\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_y_table], 0,\n                                   0, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n    if (get_bits_left(gb) < 8)\n        return AVERROR_INVALIDDATA;\n\n    /* reverse prediction of the Y-plane DC coefficients */\n    reverse_dc_prediction(s, 0, s->fragment_width[0], s->fragment_height[0]);\n\n    /* unpack the C plane DC coefficients */\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_c_table], 0,\n                                   1, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_c_table], 0,\n                                   2, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n\n    /* reverse prediction of the C-plane DC coefficients */\n    if (!(s->avctx->flags & AV_CODEC_FLAG_GRAY)) {\n        reverse_dc_prediction(s, s->fragment_start[1],\n                              s->fragment_width[1], s->fragment_height[1]);\n        reverse_dc_prediction(s, s->fragment_start[2],\n                              s->fragment_width[1], s->fragment_height[1]);\n    }\n\n    if (get_bits_left(gb) < 8)\n        return AVERROR_INVALIDDATA;\n    /* fetch the AC table indexes */\n    ac_y_table = get_bits(gb, 4);\n    ac_c_table = get_bits(gb, 4);\n\n    /* build tables of AC VLC tables */\n    for (i = 1; i <= 5; i++) {\n        /* AC VLC table group 1 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 16];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 16];\n    }\n    for (i = 6; i <= 14; i++) {\n        /* AC VLC table group 2 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 32];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 32];\n    }\n    for (i = 15; i <= 27; i++) {\n        /* AC VLC table group 3 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 48];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 48];\n    }\n    for (i = 28; i <= 63; i++) {\n        /* AC VLC table group 4 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 64];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 64];\n    }\n\n    /* decode all AC coefficients */\n    for (i = 1; i <= 63; i++) {\n        residual_eob_run = unpack_vlcs(s, gb, y_tables[i], i,\n                                       0, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n\n        residual_eob_run = unpack_vlcs(s, gb, c_tables[i], i,\n                                       1, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n        residual_eob_run = unpack_vlcs(s, gb, c_tables[i], i,\n                                       2, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n    }\n\n    return 0;\n}\n\n#if CONFIG_VP4_DECODER\n/**\n * eob_tracker[] is instead of TOKEN_EOB(value)\n * a dummy TOKEN_EOB(0) value is used to make vp3_dequant work\n *\n * @return < 0 on error\n */\nstatic int vp4_unpack_vlcs(Vp3DecodeContext *s, GetBitContext *gb,\n                       VLC *vlc_tables[64],\n                       int plane, int eob_tracker[64], int fragment)\n{\n    int token;\n    int zero_run  = 0;\n    int16_t coeff = 0;\n    int coeff_i = 0;\n    int eob_run;\n\n    while (!eob_tracker[coeff_i]) {\n        if (get_bits_left(gb) < 1)\n            return AVERROR_INVALIDDATA;\n\n        token = get_vlc2(gb, vlc_tables[coeff_i]->table, 11, 3);\n\n        /* use the token to get a zero run, a coefficient, and an eob run */\n        if ((unsigned) token <= 6U) {\n            eob_run = get_eob_run(gb, token);\n            *s->dct_tokens[plane][coeff_i]++ = TOKEN_EOB(0);\n            eob_tracker[coeff_i] = eob_run - 1;\n            return 0;\n        } else if (token >= 0) {\n            zero_run = get_coeff(gb, token, &coeff);\n\n            if (zero_run) {\n                if (coeff_i + zero_run > 64) {\n                    av_log(s->avctx, AV_LOG_DEBUG,\n                        \"Invalid zero run of %d with %d coeffs left\\n\",\n                        zero_run, 64 - coeff_i);\n                    zero_run = 64 - coeff_i;\n                }\n                *s->dct_tokens[plane][coeff_i]++ = TOKEN_ZERO_RUN(coeff, zero_run);\n                coeff_i += zero_run;\n            } else {\n                if (!coeff_i)\n                    s->all_fragments[fragment].dc = coeff;\n\n                *s->dct_tokens[plane][coeff_i]++ = TOKEN_COEFF(coeff);\n            }\n            coeff_i++;\n            if (coeff_i >= 64) /* > 64 occurs when there is a zero_run overflow */\n                return 0; /* stop */\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid token %d\\n\", token);\n            return -1;\n        }\n    }\n    *s->dct_tokens[plane][coeff_i]++ = TOKEN_EOB(0);\n    eob_tracker[coeff_i]--;\n    return 0;\n}\n\nstatic void vp4_dc_predictor_reset(VP4Predictor *p)\n{\n    p->dc = 0;\n    p->type = VP4_DC_UNDEFINED;\n}\n\nstatic void vp4_dc_pred_before(const Vp3DecodeContext *s, VP4Predictor dc_pred[6][6], int sb_x)\n{\n    int i, j;\n\n    for (i = 0; i < 4; i++)\n        dc_pred[0][i + 1] = s->dc_pred_row[sb_x * 4 + i];\n\n    for (j = 1; j < 5; j++)\n        for (i = 0; i < 4; i++)\n            vp4_dc_predictor_reset(&dc_pred[j][i + 1]);\n}\n\nstatic void vp4_dc_pred_after(Vp3DecodeContext *s, VP4Predictor dc_pred[6][6], int sb_x)\n{\n    int i;\n\n    for (i = 0; i < 4; i++)\n        s->dc_pred_row[sb_x * 4 + i] = dc_pred[4][i + 1];\n\n    for (i = 1; i < 5; i++)\n        dc_pred[i][0] = dc_pred[i][4];\n}\n\n/* note: dc_pred points to the current block */\nstatic int vp4_dc_pred(const Vp3DecodeContext *s, const VP4Predictor * dc_pred, const int * last_dc, int type, int plane)\n{\n    int count = 0;\n    int dc = 0;\n\n    if (dc_pred[-6].type == type) {\n        dc += dc_pred[-6].dc;\n        count++;\n    }\n\n    if (dc_pred[6].type == type) {\n        dc += dc_pred[6].dc;\n        count++;\n    }\n\n    if (count != 2 && dc_pred[-1].type == type) {\n        dc += dc_pred[-1].dc;\n        count++;\n    }\n\n    if (count != 2 && dc_pred[1].type == type) {\n        dc += dc_pred[1].dc;\n        count++;\n    }\n\n    /* using division instead of shift to correctly handle negative values */\n    return count == 2 ? dc / 2 : last_dc[type];\n}\n\nstatic void vp4_set_tokens_base(Vp3DecodeContext *s)\n{\n    int plane, i;\n    int16_t *base = s->dct_tokens_base;\n    for (plane = 0; plane < 3; plane++) {\n        for (i = 0; i < 64; i++) {\n            s->dct_tokens[plane][i] = base;\n            base += s->fragment_width[!!plane] * s->fragment_height[!!plane];\n        }\n    }\n}\n\nstatic int vp4_unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i, j;\n    int dc_y_table;\n    int dc_c_table;\n    int ac_y_table;\n    int ac_c_table;\n    VLC *tables[2][64];\n    int plane, sb_y, sb_x;\n    int eob_tracker[64];\n    VP4Predictor dc_pred[6][6];\n    int last_dc[NB_VP4_DC_TYPES];\n\n    if (get_bits_left(gb) < 16)\n        return AVERROR_INVALIDDATA;\n\n    /* fetch the DC table indexes */\n    dc_y_table = get_bits(gb, 4);\n    dc_c_table = get_bits(gb, 4);\n\n    ac_y_table = get_bits(gb, 4);\n    ac_c_table = get_bits(gb, 4);\n\n    /* build tables of DC/AC VLC tables */\n\n    /* DC table group */\n    tables[0][0] = &s->coeff_vlc[dc_y_table];\n    tables[1][0] = &s->coeff_vlc[dc_c_table];\n    for (i = 1; i <= 5; i++) {\n        /* AC VLC table group 1 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 16];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 16];\n    }\n    for (i = 6; i <= 14; i++) {\n        /* AC VLC table group 2 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 32];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 32];\n    }\n    for (i = 15; i <= 27; i++) {\n        /* AC VLC table group 3 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 48];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 48];\n    }\n    for (i = 28; i <= 63; i++) {\n        /* AC VLC table group 4 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 64];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 64];\n    }\n\n    vp4_set_tokens_base(s);\n\n    memset(last_dc, 0, sizeof(last_dc));\n\n    for (plane = 0; plane < ((s->avctx->flags & AV_CODEC_FLAG_GRAY) ? 1 : 3); plane++) {\n        memset(eob_tracker, 0, sizeof(eob_tracker));\n\n        /* initialise dc prediction */\n        for (i = 0; i < s->fragment_width[!!plane]; i++)\n            vp4_dc_predictor_reset(&s->dc_pred_row[i]);\n\n        for (j = 0; j < 6; j++)\n            for (i = 0; i < 6; i++)\n                vp4_dc_predictor_reset(&dc_pred[j][i]);\n\n        for (sb_y = 0; sb_y * 4 < s->fragment_height[!!plane]; sb_y++) {\n            for (sb_x = 0; sb_x *4 < s->fragment_width[!!plane]; sb_x++) {\n                vp4_dc_pred_before(s, dc_pred, sb_x);\n                for (j = 0; j < 16; j++) {\n                        int hx = hilbert_offset[j][0];\n                        int hy = hilbert_offset[j][1];\n                        int x  = 4 * sb_x + hx;\n                        int y  = 4 * sb_y + hy;\n                        VP4Predictor *this_dc_pred = &dc_pred[hy + 1][hx + 1];\n                        int fragment, dc_block_type;\n\n                        if (x >= s->fragment_width[!!plane] || y >= s->fragment_height[!!plane])\n                            continue;\n\n                        fragment = s->fragment_start[plane] + y * s->fragment_width[!!plane] + x;\n\n                        if (s->all_fragments[fragment].coding_method == MODE_COPY)\n                            continue;\n\n                        if (vp4_unpack_vlcs(s, gb, tables[!!plane], plane, eob_tracker, fragment) < 0)\n                            return -1;\n\n                        dc_block_type = vp4_pred_block_type_map[s->all_fragments[fragment].coding_method];\n\n                        s->all_fragments[fragment].dc +=\n                            vp4_dc_pred(s, this_dc_pred, last_dc, dc_block_type, plane);\n\n                        this_dc_pred->type = dc_block_type,\n                        this_dc_pred->dc   = last_dc[dc_block_type] = s->all_fragments[fragment].dc;\n                }\n                vp4_dc_pred_after(s, dc_pred, sb_x);\n            }\n        }\n    }\n\n    vp4_set_tokens_base(s);\n\n    return 0;\n}\n#endif\n\n/*\n * This function reverses the DC prediction for each coded fragment in\n * the frame. Much of this function is adapted directly from the original\n * VP3 source code.\n */\n#define COMPATIBLE_FRAME(x)                                                   \\\n    (compatible_frame[s->all_fragments[x].coding_method] == current_frame_type)\n#define DC_COEFF(u) s->all_fragments[u].dc\n\nstatic void reverse_dc_prediction(Vp3DecodeContext *s,\n                                  int first_fragment,\n                                  int fragment_width,\n                                  int fragment_height)\n{\n#define PUL 8\n#define PU 4\n#define PUR 2\n#define PL 1\n\n    int x, y;\n    int i = first_fragment;\n\n    int predicted_dc;\n\n    /* DC values for the left, up-left, up, and up-right fragments */\n    int vl, vul, vu, vur;\n\n    /* indexes for the left, up-left, up, and up-right fragments */\n    int l, ul, u, ur;\n\n    /*\n     * The 6 fields mean:\n     *   0: up-left multiplier\n     *   1: up multiplier\n     *   2: up-right multiplier\n     *   3: left multiplier\n     */\n    static const int predictor_transform[16][4] = {\n        {    0,   0,   0,   0 },\n        {    0,   0,   0, 128 }, // PL\n        {    0,   0, 128,   0 }, // PUR\n        {    0,   0,  53,  75 }, // PUR|PL\n        {    0, 128,   0,   0 }, // PU\n        {    0,  64,   0,  64 }, // PU |PL\n        {    0, 128,   0,   0 }, // PU |PUR\n        {    0,   0,  53,  75 }, // PU |PUR|PL\n        {  128,   0,   0,   0 }, // PUL\n        {    0,   0,   0, 128 }, // PUL|PL\n        {   64,   0,  64,   0 }, // PUL|PUR\n        {    0,   0,  53,  75 }, // PUL|PUR|PL\n        {    0, 128,   0,   0 }, // PUL|PU\n        { -104, 116,   0, 116 }, // PUL|PU |PL\n        {   24,  80,  24,   0 }, // PUL|PU |PUR\n        { -104, 116,   0, 116 }  // PUL|PU |PUR|PL\n    };\n\n    /* This table shows which types of blocks can use other blocks for\n     * prediction. For example, INTRA is the only mode in this table to\n     * have a frame number of 0. That means INTRA blocks can only predict\n     * from other INTRA blocks. There are 2 golden frame coding types;\n     * blocks encoding in these modes can only predict from other blocks\n     * that were encoded with these 1 of these 2 modes. */\n    static const unsigned char compatible_frame[9] = {\n        1,    /* MODE_INTER_NO_MV */\n        0,    /* MODE_INTRA */\n        1,    /* MODE_INTER_PLUS_MV */\n        1,    /* MODE_INTER_LAST_MV */\n        1,    /* MODE_INTER_PRIOR_MV */\n        2,    /* MODE_USING_GOLDEN */\n        2,    /* MODE_GOLDEN_MV */\n        1,    /* MODE_INTER_FOUR_MV */\n        3     /* MODE_COPY */\n    };\n    int current_frame_type;\n\n    /* there is a last DC predictor for each of the 3 frame types */\n    short last_dc[3];\n\n    int transform = 0;\n\n    vul =\n    vu  =\n    vur =\n    vl  = 0;\n    last_dc[0] =\n    last_dc[1] =\n    last_dc[2] = 0;\n\n    /* for each fragment row... */\n    for (y = 0; y < fragment_height; y++) {\n        /* for each fragment in a row... */\n        for (x = 0; x < fragment_width; x++, i++) {\n\n            /* reverse prediction if this block was coded */\n            if (s->all_fragments[i].coding_method != MODE_COPY) {\n                current_frame_type =\n                    compatible_frame[s->all_fragments[i].coding_method];\n\n                transform = 0;\n                if (x) {\n                    l  = i - 1;\n                    vl = DC_COEFF(l);\n                    if (COMPATIBLE_FRAME(l))\n                        transform |= PL;\n                }\n                if (y) {\n                    u  = i - fragment_width;\n                    vu = DC_COEFF(u);\n                    if (COMPATIBLE_FRAME(u))\n                        transform |= PU;\n                    if (x) {\n                        ul  = i - fragment_width - 1;\n                        vul = DC_COEFF(ul);\n                        if (COMPATIBLE_FRAME(ul))\n                            transform |= PUL;\n                    }\n                    if (x + 1 < fragment_width) {\n                        ur  = i - fragment_width + 1;\n                        vur = DC_COEFF(ur);\n                        if (COMPATIBLE_FRAME(ur))\n                            transform |= PUR;\n                    }\n                }\n\n                if (transform == 0) {\n                    /* if there were no fragments to predict from, use last\n                     * DC saved */\n                    predicted_dc = last_dc[current_frame_type];\n                } else {\n                    /* apply the appropriate predictor transform */\n                    predicted_dc =\n                        (predictor_transform[transform][0] * vul) +\n                        (predictor_transform[transform][1] * vu) +\n                        (predictor_transform[transform][2] * vur) +\n                        (predictor_transform[transform][3] * vl);\n\n                    predicted_dc /= 128;\n\n                    /* check for outranging on the [ul u l] and\n                     * [ul u ur l] predictors */\n                    if ((transform == 15) || (transform == 13)) {\n                        if (FFABS(predicted_dc - vu) > 128)\n                            predicted_dc = vu;\n                        else if (FFABS(predicted_dc - vl) > 128)\n                            predicted_dc = vl;\n                        else if (FFABS(predicted_dc - vul) > 128)\n                            predicted_dc = vul;\n                    }\n                }\n\n                /* at long last, apply the predictor */\n                DC_COEFF(i) += predicted_dc;\n                /* save the DC */\n                last_dc[current_frame_type] = DC_COEFF(i);\n            }\n        }\n    }\n}\n\nstatic void apply_loop_filter(Vp3DecodeContext *s, int plane,\n                              int ystart, int yend)\n{\n    int x, y;\n    int *bounding_values = s->bounding_values_array + 127;\n\n    int width           = s->fragment_width[!!plane];\n    int height          = s->fragment_height[!!plane];\n    int fragment        = s->fragment_start[plane] + ystart * width;\n    ptrdiff_t stride    = s->current_frame.f->linesize[plane];\n    uint8_t *plane_data = s->current_frame.f->data[plane];\n    if (!s->flipped_image)\n        stride = -stride;\n    plane_data += s->data_offset[plane] + 8 * ystart * stride;\n\n    for (y = ystart; y < yend; y++) {\n        for (x = 0; x < width; x++) {\n            /* This code basically just deblocks on the edges of coded blocks.\n             * However, it has to be much more complicated because of the\n             * brain damaged deblock ordering used in VP3/Theora. Order matters\n             * because some pixels get filtered twice. */\n            if (s->all_fragments[fragment].coding_method != MODE_COPY) {\n                /* do not perform left edge filter for left columns frags */\n                if (x > 0) {\n                    s->vp3dsp.h_loop_filter(\n                        plane_data + 8 * x,\n                        stride, bounding_values);\n                }\n\n                /* do not perform top edge filter for top row fragments */\n                if (y > 0) {\n                    s->vp3dsp.v_loop_filter(\n                        plane_data + 8 * x,\n                        stride, bounding_values);\n                }\n\n                /* do not perform right edge filter for right column\n                 * fragments or if right fragment neighbor is also coded\n                 * in this frame (it will be filtered in next iteration) */\n                if ((x < width - 1) &&\n                    (s->all_fragments[fragment + 1].coding_method == MODE_COPY)) {\n                    s->vp3dsp.h_loop_filter(\n                        plane_data + 8 * x + 8,\n                        stride, bounding_values);\n                }\n\n                /* do not perform bottom edge filter for bottom row\n                 * fragments or if bottom fragment neighbor is also coded\n                 * in this frame (it will be filtered in the next row) */\n                if ((y < height - 1) &&\n                    (s->all_fragments[fragment + width].coding_method == MODE_COPY)) {\n                    s->vp3dsp.v_loop_filter(\n                        plane_data + 8 * x + 8 * stride,\n                        stride, bounding_values);\n                }\n            }\n\n            fragment++;\n        }\n        plane_data += 8 * stride;\n    }\n}\n\n/**\n * Pull DCT tokens from the 64 levels to decode and dequant the coefficients\n * for the next block in coding order\n */\nstatic inline int vp3_dequant(Vp3DecodeContext *s, Vp3Fragment *frag,\n                              int plane, int inter, int16_t block[64])\n{\n    int16_t *dequantizer = s->qmat[frag->qpi][inter][plane];\n    uint8_t *perm = s->idct_scantable;\n    int i = 0;\n\n    do {\n        int token = *s->dct_tokens[plane][i];\n        switch (token & 3) {\n        case 0: // EOB\n            if (--token < 4) // 0-3 are token types so the EOB run must now be 0\n                s->dct_tokens[plane][i]++;\n            else\n                *s->dct_tokens[plane][i] = token & ~3;\n            goto end;\n        case 1: // zero run\n            s->dct_tokens[plane][i]++;\n            i += (token >> 2) & 0x7f;\n            if (i > 63) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Coefficient index overflow\\n\");\n                return i;\n            }\n            block[perm[i]] = (token >> 9) * dequantizer[perm[i]];\n            i++;\n            break;\n        case 2: // coeff\n            block[perm[i]] = (token >> 2) * dequantizer[perm[i]];\n            s->dct_tokens[plane][i++]++;\n            break;\n        default: // shouldn't happen\n            return i;\n        }\n    } while (i < 64);\n    // return value is expected to be a valid level\n    i--;\nend:\n    // the actual DC+prediction is in the fragment structure\n    block[0] = frag->dc * s->qmat[0][inter][plane][0];\n    return i;\n}\n\n/**\n * called when all pixels up to row y are complete\n */\nstatic void vp3_draw_horiz_band(Vp3DecodeContext *s, int y)\n{\n    int h, cy, i;\n    int offset[AV_NUM_DATA_POINTERS];\n\n    if (HAVE_THREADS && s->avctx->active_thread_type & FF_THREAD_FRAME) {\n        int y_flipped = s->flipped_image ? s->height - y : y;\n\n        /* At the end of the frame, report INT_MAX instead of the height of\n         * the frame. This makes the other threads' ff_thread_await_progress()\n         * calls cheaper, because they don't have to clip their values. */\n        ff_thread_report_progress(&s->current_frame,\n                                  y_flipped == s->height ? INT_MAX\n                                                         : y_flipped - 1,\n                                  0);\n    }\n\n    if (!s->avctx->draw_horiz_band)\n        return;\n\n    h = y - s->last_slice_end;\n    s->last_slice_end = y;\n    y -= h;\n\n    if (!s->flipped_image)\n        y = s->height - y - h;\n\n    cy        = y >> s->chroma_y_shift;\n    offset[0] = s->current_frame.f->linesize[0] * y;\n    offset[1] = s->current_frame.f->linesize[1] * cy;\n    offset[2] = s->current_frame.f->linesize[2] * cy;\n    for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n        offset[i] = 0;\n\n    emms_c();\n    s->avctx->draw_horiz_band(s->avctx, s->current_frame.f, offset, y, 3, h);\n}\n\n/**\n * Wait for the reference frame of the current fragment.\n * The progress value is in luma pixel rows.\n */\nstatic void await_reference_row(Vp3DecodeContext *s, Vp3Fragment *fragment,\n                                int motion_y, int y)\n{\n    ThreadFrame *ref_frame;\n    int ref_row;\n    int border = motion_y & 1;\n\n    if (fragment->coding_method == MODE_USING_GOLDEN ||\n        fragment->coding_method == MODE_GOLDEN_MV)\n        ref_frame = &s->golden_frame;\n    else\n        ref_frame = &s->last_frame;\n\n    ref_row = y + (motion_y >> 1);\n    ref_row = FFMAX(FFABS(ref_row), ref_row + 8 + border);\n\n    ff_thread_await_progress(ref_frame, ref_row, 0);\n}\n\n#if CONFIG_VP4_DECODER\n/**\n * @return non-zero if temp (edge_emu_buffer) was populated\n */\nstatic int vp4_mc_loop_filter(Vp3DecodeContext *s, int plane, int motion_x, int motion_y, int bx, int by,\n       uint8_t * motion_source, int stride, int src_x, int src_y, uint8_t *temp)\n{\n    int motion_shift = plane ? 4 : 2;\n    int subpel_mask = plane ? 3 : 1;\n    int *bounding_values = s->bounding_values_array + 127;\n\n    int i;\n    int x, y;\n    int x2, y2;\n    int x_subpel, y_subpel;\n    int x_offset, y_offset;\n\n    int block_width = plane ? 8 : 16;\n    int plane_width  = s->width  >> (plane && s->chroma_x_shift);\n    int plane_height = s->height >> (plane && s->chroma_y_shift);\n\n#define loop_stride 12\n    uint8_t loop[12 * loop_stride];\n\n    /* using division instead of shift to correctly handle negative values */\n    x = 8 * bx + motion_x / motion_shift;\n    y = 8 * by + motion_y / motion_shift;\n\n    x_subpel = motion_x & subpel_mask;\n    y_subpel = motion_y & subpel_mask;\n\n    if (x_subpel || y_subpel) {\n        x--;\n        y--;\n\n        if (x_subpel)\n            x = FFMIN(x, x + FFSIGN(motion_x));\n\n        if (y_subpel)\n            y = FFMIN(y, y + FFSIGN(motion_y));\n\n        x2 = x + block_width;\n        y2 = y + block_width;\n\n        if (x2 < 0 || x2 >= plane_width || y2 < 0 || y2 >= plane_height)\n            return 0;\n\n        x_offset = (-(x + 2) & 7) + 2;\n        y_offset = (-(y + 2) & 7) + 2;\n\n        if (x_offset > 8 + x_subpel && y_offset > 8 + y_subpel)\n            return 0;\n\n        s->vdsp.emulated_edge_mc(loop, motion_source - stride - 1,\n             loop_stride, stride,\n             12, 12, src_x - 1, src_y - 1,\n             plane_width,\n             plane_height);\n\n        if (x_offset <= 8 + x_subpel)\n            ff_vp3dsp_h_loop_filter_12(loop + x_offset, loop_stride, bounding_values);\n\n        if (y_offset <= 8 + y_subpel)\n            ff_vp3dsp_v_loop_filter_12(loop + y_offset*loop_stride, loop_stride, bounding_values);\n\n    } else {\n\n        x_offset = -x & 7;\n        y_offset = -y & 7;\n\n        if (!x_offset && !y_offset)\n            return 0;\n\n        s->vdsp.emulated_edge_mc(loop, motion_source - stride - 1,\n             loop_stride, stride,\n             12, 12, src_x - 1, src_y - 1,\n             plane_width,\n             plane_height);\n\n#define safe_loop_filter(name, ptr, stride, bounding_values) \\\n    if ((uintptr_t)(ptr) & 7) \\\n        s->vp3dsp.name##_unaligned(ptr, stride, bounding_values); \\\n    else \\\n        s->vp3dsp.name(ptr, stride, bounding_values);\n\n        if (x_offset)\n            safe_loop_filter(h_loop_filter, loop + loop_stride + x_offset + 1, loop_stride, bounding_values);\n\n        if (y_offset)\n            safe_loop_filter(v_loop_filter, loop + (y_offset + 1)*loop_stride + 1, loop_stride, bounding_values);\n    }\n\n    for (i = 0; i < 9; i++)\n        memcpy(temp + i*stride, loop + (i + 1) * loop_stride + 1, 9);\n\n    return 1;\n}\n#endif\n\n/*\n * Perform the final rendering for a particular slice of data.\n * The slice number ranges from 0..(c_superblock_height - 1).\n */\nstatic void render_slice(Vp3DecodeContext *s, int slice)\n{\n    int x, y, i, j, fragment;\n    int16_t *block = s->block;\n    int motion_x = 0xdeadbeef, motion_y = 0xdeadbeef;\n    int motion_halfpel_index;\n    uint8_t *motion_source;\n    int plane, first_pixel;\n\n    if (slice >= s->c_superblock_height)\n        return;\n\n    for (plane = 0; plane < 3; plane++) {\n        uint8_t *output_plane = s->current_frame.f->data[plane] +\n                                s->data_offset[plane];\n        uint8_t *last_plane = s->last_frame.f->data[plane] +\n                              s->data_offset[plane];\n        uint8_t *golden_plane = s->golden_frame.f->data[plane] +\n                                s->data_offset[plane];\n        ptrdiff_t stride = s->current_frame.f->linesize[plane];\n        int plane_width  = s->width  >> (plane && s->chroma_x_shift);\n        int plane_height = s->height >> (plane && s->chroma_y_shift);\n        int8_t(*motion_val)[2] = s->motion_val[!!plane];\n\n        int sb_x, sb_y = slice << (!plane && s->chroma_y_shift);\n        int slice_height = sb_y + 1 + (!plane && s->chroma_y_shift);\n        int slice_width  = plane ? s->c_superblock_width\n                                 : s->y_superblock_width;\n\n        int fragment_width  = s->fragment_width[!!plane];\n        int fragment_height = s->fragment_height[!!plane];\n        int fragment_start  = s->fragment_start[plane];\n\n        int do_await = !plane && HAVE_THREADS &&\n                       (s->avctx->active_thread_type & FF_THREAD_FRAME);\n\n        if (!s->flipped_image)\n            stride = -stride;\n        if (CONFIG_GRAY && plane && (s->avctx->flags & AV_CODEC_FLAG_GRAY))\n            continue;\n\n        /* for each superblock row in the slice (both of them)... */\n        for (; sb_y < slice_height; sb_y++) {\n            /* for each superblock in a row... */\n            for (sb_x = 0; sb_x < slice_width; sb_x++) {\n                /* for each block in a superblock... */\n                for (j = 0; j < 16; j++) {\n                    x        = 4 * sb_x + hilbert_offset[j][0];\n                    y        = 4 * sb_y + hilbert_offset[j][1];\n                    fragment = y * fragment_width + x;\n\n                    i = fragment_start + fragment;\n\n                    // bounds check\n                    if (x >= fragment_width || y >= fragment_height)\n                        continue;\n\n                    first_pixel = 8 * y * stride + 8 * x;\n\n                    if (do_await &&\n                        s->all_fragments[i].coding_method != MODE_INTRA)\n                        await_reference_row(s, &s->all_fragments[i],\n                                            motion_val[fragment][1],\n                                            (16 * y) >> s->chroma_y_shift);\n\n                    /* transform if this block was coded */\n                    if (s->all_fragments[i].coding_method != MODE_COPY) {\n                        if ((s->all_fragments[i].coding_method == MODE_USING_GOLDEN) ||\n                            (s->all_fragments[i].coding_method == MODE_GOLDEN_MV))\n                            motion_source = golden_plane;\n                        else\n                            motion_source = last_plane;\n\n                        motion_source       += first_pixel;\n                        motion_halfpel_index = 0;\n\n                        /* sort out the motion vector if this fragment is coded\n                         * using a motion vector method */\n                        if ((s->all_fragments[i].coding_method > MODE_INTRA) &&\n                            (s->all_fragments[i].coding_method != MODE_USING_GOLDEN)) {\n                            int src_x, src_y;\n                            int standard_mc = 1;\n                            motion_x = motion_val[fragment][0];\n                            motion_y = motion_val[fragment][1];\n#if CONFIG_VP4_DECODER\n                            if (plane && s->version >= 2) {\n                                motion_x = (motion_x >> 1) | (motion_x & 1);\n                                motion_y = (motion_y >> 1) | (motion_y & 1);\n                            }\n#endif\n\n                            src_x = (motion_x >> 1) + 8 * x;\n                            src_y = (motion_y >> 1) + 8 * y;\n\n                            motion_halfpel_index = motion_x & 0x01;\n                            motion_source       += (motion_x >> 1);\n\n                            motion_halfpel_index |= (motion_y & 0x01) << 1;\n                            motion_source        += ((motion_y >> 1) * stride);\n\n#if CONFIG_VP4_DECODER\n                            if (s->version >= 2) {\n                                uint8_t *temp = s->edge_emu_buffer;\n                                if (stride < 0)\n                                    temp -= 8 * stride;\n                                if (vp4_mc_loop_filter(s, plane, motion_val[fragment][0], motion_val[fragment][1], x, y, motion_source, stride, src_x, src_y, temp)) {\n                                    motion_source = temp;\n                                    standard_mc = 0;\n                                }\n                            }\n#endif\n\n                            if (standard_mc && (\n                                src_x < 0 || src_y < 0 ||\n                                src_x + 9 >= plane_width ||\n                                src_y + 9 >= plane_height)) {\n                                uint8_t *temp = s->edge_emu_buffer;\n                                if (stride < 0)\n                                    temp -= 8 * stride;\n\n                                s->vdsp.emulated_edge_mc(temp, motion_source,\n                                                         stride, stride,\n                                                         9, 9, src_x, src_y,\n                                                         plane_width,\n                                                         plane_height);\n                                motion_source = temp;\n                            }\n                        }\n\n                        /* first, take care of copying a block from either the\n                         * previous or the golden frame */\n                        if (s->all_fragments[i].coding_method != MODE_INTRA) {\n                            /* Note, it is possible to implement all MC cases\n                             * with put_no_rnd_pixels_l2 which would look more\n                             * like the VP3 source but this would be slower as\n                             * put_no_rnd_pixels_tab is better optimized */\n                            if (motion_halfpel_index != 3) {\n                                s->hdsp.put_no_rnd_pixels_tab[1][motion_halfpel_index](\n                                    output_plane + first_pixel,\n                                    motion_source, stride, 8);\n                            } else {\n                                /* d is 0 if motion_x and _y have the same sign,\n                                 * else -1 */\n                                int d = (motion_x ^ motion_y) >> 31;\n                                s->vp3dsp.put_no_rnd_pixels_l2(output_plane + first_pixel,\n                                                               motion_source - d,\n                                                               motion_source + stride + 1 + d,\n                                                               stride, 8);\n                            }\n                        }\n\n                        /* invert DCT and place (or add) in final output */\n\n                        if (s->all_fragments[i].coding_method == MODE_INTRA) {\n                            vp3_dequant(s, s->all_fragments + i,\n                                        plane, 0, block);\n                            s->vp3dsp.idct_put(output_plane + first_pixel,\n                                               stride,\n                                               block);\n                        } else {\n                            if (vp3_dequant(s, s->all_fragments + i,\n                                            plane, 1, block)) {\n                                s->vp3dsp.idct_add(output_plane + first_pixel,\n                                                   stride,\n                                                   block);\n                            } else {\n                                s->vp3dsp.idct_dc_add(output_plane + first_pixel,\n                                                      stride, block);\n                            }\n                        }\n                    } else {\n                        /* copy directly from the previous frame */\n                        s->hdsp.put_pixels_tab[1][0](\n                            output_plane + first_pixel,\n                            last_plane + first_pixel,\n                            stride, 8);\n                    }\n                }\n            }\n\n            // Filter up to the last row in the superblock row\n            if (s->version < 2 && !s->skip_loop_filter)\n                apply_loop_filter(s, plane, 4 * sb_y - !!sb_y,\n                                  FFMIN(4 * sb_y + 3, fragment_height - 1));\n        }\n    }\n\n    /* this looks like a good place for slice dispatch... */\n    /* algorithm:\n     *   if (slice == s->macroblock_height - 1)\n     *     dispatch (both last slice & 2nd-to-last slice);\n     *   else if (slice > 0)\n     *     dispatch (slice - 1);\n     */\n\n    vp3_draw_horiz_band(s, FFMIN((32 << s->chroma_y_shift) * (slice + 1) - 16,\n                                 s->height - 16));\n}\n\n/// Allocate tables for per-frame data in Vp3DecodeContext\nstatic av_cold int allocate_tables(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int y_fragment_count, c_fragment_count;\n\n    free_tables(avctx);\n\n    y_fragment_count = s->fragment_width[0] * s->fragment_height[0];\n    c_fragment_count = s->fragment_width[1] * s->fragment_height[1];\n\n    /* superblock_coding is used by unpack_superblocks (VP3/Theora) and vp4_unpack_macroblocks (VP4) */\n    s->superblock_coding = av_mallocz(FFMAX(s->superblock_count, s->yuv_macroblock_count));\n    s->all_fragments     = av_calloc(s->fragment_count, sizeof(*s->all_fragments));\n\n    s-> kf_coded_fragment_list = av_calloc(s->fragment_count, sizeof(int));\n    s->nkf_coded_fragment_list = av_calloc(s->fragment_count, sizeof(int));\n    memset(s-> num_kf_coded_fragment, -1, sizeof(s-> num_kf_coded_fragment));\n\n    s->dct_tokens_base = av_calloc(s->fragment_count,\n                                   64 * sizeof(*s->dct_tokens_base));\n    s->motion_val[0] = av_calloc(y_fragment_count, sizeof(*s->motion_val[0]));\n    s->motion_val[1] = av_calloc(c_fragment_count, sizeof(*s->motion_val[1]));\n\n    /* work out the block mapping tables */\n    s->superblock_fragments = av_calloc(s->superblock_count, 16 * sizeof(int));\n    s->macroblock_coding    = av_mallocz(s->macroblock_count + 1);\n\n    s->dc_pred_row = av_malloc_array(s->y_superblock_width * 4, sizeof(*s->dc_pred_row));\n\n    if (!s->superblock_coding    || !s->all_fragments          ||\n        !s->dct_tokens_base      || !s->kf_coded_fragment_list ||\n        !s->nkf_coded_fragment_list ||\n        !s->superblock_fragments || !s->macroblock_coding      ||\n        !s->dc_pred_row ||\n        !s->motion_val[0]        || !s->motion_val[1]) {\n        return -1;\n    }\n\n    init_block_mapping(s);\n\n    return 0;\n}\n\nstatic av_cold int init_frames(Vp3DecodeContext *s)\n{\n    s->current_frame.f = av_frame_alloc();\n    s->last_frame.f    = av_frame_alloc();\n    s->golden_frame.f  = av_frame_alloc();\n\n    if (!s->current_frame.f || !s->last_frame.f || !s->golden_frame.f)\n        return AVERROR(ENOMEM);\n\n    return 0;\n}\n\nstatic av_cold int vp3_decode_init(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, inter, plane, ret;\n    int c_width;\n    int c_height;\n    int y_fragment_count, c_fragment_count;\n#if CONFIG_VP4_DECODER\n    int j;\n#endif\n\n    ret = init_frames(s);\n    if (ret < 0)\n        return ret;\n\n    if (avctx->codec_tag == MKTAG('V', 'P', '4', '0')) {\n        s->version = 3;\n#if !CONFIG_VP4_DECODER\n        av_log(avctx, AV_LOG_ERROR, \"This build does not support decoding VP4.\\n\");\n        return AVERROR_DECODER_NOT_FOUND;\n#endif\n    } else if (avctx->codec_tag == MKTAG('V', 'P', '3', '0'))\n        s->version = 0;\n    else\n        s->version = 1;\n\n    s->avctx  = avctx;\n    s->width  = FFALIGN(avctx->coded_width, 16);\n    s->height = FFALIGN(avctx->coded_height, 16);\n    if (avctx->codec_id != AV_CODEC_ID_THEORA)\n        avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n    avctx->chroma_sample_location = AVCHROMA_LOC_CENTER;\n    ff_hpeldsp_init(&s->hdsp, avctx->flags | AV_CODEC_FLAG_BITEXACT);\n    ff_videodsp_init(&s->vdsp, 8);\n    ff_vp3dsp_init(&s->vp3dsp, avctx->flags);\n\n    for (i = 0; i < 64; i++) {\n#define TRANSPOSE(x) (((x) >> 3) | (((x) & 7) << 3))\n        s->idct_permutation[i] = TRANSPOSE(i);\n        s->idct_scantable[i]   = TRANSPOSE(ff_zigzag_direct[i]);\n#undef TRANSPOSE\n    }\n\n    /* initialize to an impossible value which will force a recalculation\n     * in the first frame decode */\n    for (i = 0; i < 3; i++)\n        s->qps[i] = -1;\n\n    ret = av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n    if (ret)\n        return ret;\n\n    s->y_superblock_width  = (s->width  + 31) / 32;\n    s->y_superblock_height = (s->height + 31) / 32;\n    s->y_superblock_count  = s->y_superblock_width * s->y_superblock_height;\n\n    /* work out the dimensions for the C planes */\n    c_width                = s->width >> s->chroma_x_shift;\n    c_height               = s->height >> s->chroma_y_shift;\n    s->c_superblock_width  = (c_width  + 31) / 32;\n    s->c_superblock_height = (c_height + 31) / 32;\n    s->c_superblock_count  = s->c_superblock_width * s->c_superblock_height;\n\n    s->superblock_count   = s->y_superblock_count + (s->c_superblock_count * 2);\n    s->u_superblock_start = s->y_superblock_count;\n    s->v_superblock_start = s->u_superblock_start + s->c_superblock_count;\n\n    s->macroblock_width  = (s->width  + 15) / 16;\n    s->macroblock_height = (s->height + 15) / 16;\n    s->macroblock_count  = s->macroblock_width * s->macroblock_height;\n    s->c_macroblock_width  = (c_width  + 15) / 16;\n    s->c_macroblock_height = (c_height + 15) / 16;\n    s->c_macroblock_count  = s->c_macroblock_width * s->c_macroblock_height;\n    s->yuv_macroblock_count = s->macroblock_count + 2 * s->c_macroblock_count;\n\n    s->fragment_width[0]  = s->width / FRAGMENT_PIXELS;\n    s->fragment_height[0] = s->height / FRAGMENT_PIXELS;\n    s->fragment_width[1]  = s->fragment_width[0] >> s->chroma_x_shift;\n    s->fragment_height[1] = s->fragment_height[0] >> s->chroma_y_shift;\n\n    /* fragment count covers all 8x8 blocks for all 3 planes */\n    y_fragment_count     = s->fragment_width[0] * s->fragment_height[0];\n    c_fragment_count     = s->fragment_width[1] * s->fragment_height[1];\n    s->fragment_count    = y_fragment_count + 2 * c_fragment_count;\n    s->fragment_start[1] = y_fragment_count;\n    s->fragment_start[2] = y_fragment_count + c_fragment_count;\n\n    if (!s->theora_tables) {\n        const uint8_t (*bias_tabs)[32][2];\n\n        for (i = 0; i < 64; i++) {\n            s->coded_dc_scale_factor[0][i] = s->version < 2 ? vp31_dc_scale_factor[i] : vp4_y_dc_scale_factor[i];\n            s->coded_dc_scale_factor[1][i] = s->version < 2 ? vp31_dc_scale_factor[i] : vp4_uv_dc_scale_factor[i];\n            s->coded_ac_scale_factor[i] = s->version < 2 ? vp31_ac_scale_factor[i] : vp4_ac_scale_factor[i];\n            s->base_matrix[0][i]        = s->version < 2 ? vp31_intra_y_dequant[i] : vp4_generic_dequant[i];\n            s->base_matrix[1][i]        = s->version < 2 ? vp31_intra_c_dequant[i] : vp4_generic_dequant[i];\n            s->base_matrix[2][i]        = s->version < 2 ? vp31_inter_dequant[i]   : vp4_generic_dequant[i];\n            s->filter_limit_values[i]   = s->version < 2 ? vp31_filter_limit_values[i] : vp4_filter_limit_values[i];\n        }\n\n        for (inter = 0; inter < 2; inter++) {\n            for (plane = 0; plane < 3; plane++) {\n                s->qr_count[inter][plane]   = 1;\n                s->qr_size[inter][plane][0] = 63;\n                s->qr_base[inter][plane][0] =\n                s->qr_base[inter][plane][1] = 2 * inter + (!!plane) * !inter;\n            }\n        }\n\n        /* init VLC tables */\n        bias_tabs = CONFIG_VP4_DECODER && s->version >= 2 ? vp4_bias : vp3_bias;\n        for (int i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++) {\n            ret = ff_init_vlc_from_lengths(&s->coeff_vlc[i], 11, 32,\n                                           &bias_tabs[i][0][1], 2,\n                                           &bias_tabs[i][0][0], 2, 1,\n                                           0, 0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n    } else {\n        for (i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++) {\n            const HuffTable *tab = &s->huffman_table[i];\n\n            ret = ff_init_vlc_from_lengths(&s->coeff_vlc[i], 11, tab->nb_entries,\n                                           &tab->entries[0].len, sizeof(*tab->entries),\n                                           &tab->entries[0].sym, sizeof(*tab->entries), 1,\n                                           0, 0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    ret = ff_init_vlc_from_lengths(&s->superblock_run_length_vlc, SUPERBLOCK_VLC_BITS, 34,\n                                   superblock_run_length_vlc_lens, 1,\n                                   NULL, 0, 0, 1, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->fragment_run_length_vlc, 5, 30,\n                                   fragment_run_length_vlc_len, 1,\n                                   NULL, 0, 0, 0, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->mode_code_vlc, 3, 8,\n                                   mode_code_vlc_len, 1,\n                                   NULL, 0, 0, 0, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->motion_vector_vlc, VP3_MV_VLC_BITS, 63,\n                                   &motion_vector_vlc_table[0][1], 2,\n                                   &motion_vector_vlc_table[0][0], 2, 1,\n                                   -31, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n#if CONFIG_VP4_DECODER\n    for (j = 0; j < 2; j++)\n        for (i = 0; i < 7; i++) {\n            ret = ff_init_vlc_from_lengths(&s->vp4_mv_vlc[j][i], VP4_MV_VLC_BITS, 63,\n                                           &vp4_mv_vlc[j][i][0][1], 2,\n                                           &vp4_mv_vlc[j][i][0][0], 2, 1, -31,\n                                           0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n\n    /* version >= 2 */\n    for (i = 0; i < 2; i++)\n        if ((ret = init_vlc(&s->block_pattern_vlc[i], 3, 14,\n                            &vp4_block_pattern_vlc[i][0][1], 2, 1,\n                            &vp4_block_pattern_vlc[i][0][0], 2, 1, 0)) < 0)\n            return ret;\n#endif\n\n    return allocate_tables(avctx);\n}\n\n/// Release and shuffle frames after decode finishes\nstatic int update_frames(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int ret = 0;\n\n    /* shuffle frames (last = current) */\n    ff_thread_release_ext_buffer(avctx, &s->last_frame);\n    ret = ff_thread_ref_frame(&s->last_frame, &s->current_frame);\n    if (ret < 0)\n        goto fail;\n\n    if (s->keyframe) {\n        ff_thread_release_ext_buffer(avctx, &s->golden_frame);\n        ret = ff_thread_ref_frame(&s->golden_frame, &s->current_frame);\n    }\n\nfail:\n    ff_thread_release_ext_buffer(avctx, &s->current_frame);\n    return ret;\n}\n\n#if HAVE_THREADS\nstatic int ref_frame(Vp3DecodeContext *s, ThreadFrame *dst, ThreadFrame *src)\n{\n    ff_thread_release_ext_buffer(s->avctx, dst);\n    if (src->f->data[0])\n        return ff_thread_ref_frame(dst, src);\n    return 0;\n}\n\nstatic int ref_frames(Vp3DecodeContext *dst, Vp3DecodeContext *src)\n{\n    int ret;\n    if ((ret = ref_frame(dst, &dst->current_frame, &src->current_frame)) < 0 ||\n        (ret = ref_frame(dst, &dst->golden_frame,  &src->golden_frame)) < 0  ||\n        (ret = ref_frame(dst, &dst->last_frame,    &src->last_frame)) < 0)\n        return ret;\n    return 0;\n}\n\nstatic int vp3_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    Vp3DecodeContext *s = dst->priv_data, *s1 = src->priv_data;\n    int qps_changed = 0, i, err;\n\n    if (!s1->current_frame.f->data[0] ||\n        s->width != s1->width || s->height != s1->height) {\n        if (s != s1)\n            ref_frames(s, s1);\n        return -1;\n    }\n\n    if (s != s1) {\n        // copy previous frame data\n        if ((err = ref_frames(s, s1)) < 0)\n            return err;\n\n        s->keyframe = s1->keyframe;\n\n        // copy qscale data if necessary\n        for (i = 0; i < 3; i++) {\n            if (s->qps[i] != s1->qps[1]) {\n                qps_changed = 1;\n                memcpy(&s->qmat[i], &s1->qmat[i], sizeof(s->qmat[i]));\n            }\n        }\n\n        if (s->qps[0] != s1->qps[0])\n            memcpy(&s->bounding_values_array, &s1->bounding_values_array,\n                   sizeof(s->bounding_values_array));\n\n        if (qps_changed) {\n            memcpy(s->qps,      s1->qps,      sizeof(s->qps));\n            memcpy(s->last_qps, s1->last_qps, sizeof(s->last_qps));\n            s->nqps = s1->nqps;\n        }\n    }\n\n    return update_frames(dst);\n}\n#endif\n\nstatic int vp3_decode_frame(AVCodecContext *avctx,\n                            void *data, int *got_frame,\n                            AVPacket *avpkt)\n{\n    AVFrame     *frame  = data;\n    const uint8_t *buf  = avpkt->data;\n    int buf_size        = avpkt->size;\n    Vp3DecodeContext *s = avctx->priv_data;\n    GetBitContext gb;\n    int i, ret;\n\n    if ((ret = init_get_bits8(&gb, buf, buf_size)) < 0)\n        return ret;\n\n#if CONFIG_THEORA_DECODER\n    if (s->theora && get_bits1(&gb)) {\n        int type = get_bits(&gb, 7);\n        skip_bits_long(&gb, 6*8); /* \"theora\" */\n\n        if (s->avctx->active_thread_type&FF_THREAD_FRAME) {\n            av_log(avctx, AV_LOG_ERROR, \"midstream reconfiguration with multithreading is unsupported, try -threads 1\\n\");\n            return AVERROR_PATCHWELCOME;\n        }\n        if (type == 0) {\n            vp3_decode_end(avctx);\n            ret = theora_decode_header(avctx, &gb);\n\n            if (ret >= 0)\n                ret = vp3_decode_init(avctx);\n            if (ret < 0) {\n                vp3_decode_end(avctx);\n                return ret;\n            }\n            return buf_size;\n        } else if (type == 2) {\n            vp3_decode_end(avctx);\n            ret = theora_decode_tables(avctx, &gb);\n            if (ret >= 0)\n                ret = vp3_decode_init(avctx);\n            if (ret < 0) {\n                vp3_decode_end(avctx);\n                return ret;\n            }\n            return buf_size;\n        }\n\n        av_log(avctx, AV_LOG_ERROR,\n               \"Header packet passed to frame decoder, skipping\\n\");\n        return -1;\n    }\n#endif\n\n    s->keyframe = !get_bits1(&gb);\n    if (!s->all_fragments) {\n        av_log(avctx, AV_LOG_ERROR, \"Data packet without prior valid headers\\n\");\n        return -1;\n    }\n    if (!s->theora)\n        skip_bits(&gb, 1);\n    for (i = 0; i < 3; i++)\n        s->last_qps[i] = s->qps[i];\n\n    s->nqps = 0;\n    do {\n        s->qps[s->nqps++] = get_bits(&gb, 6);\n    } while (s->theora >= 0x030200 && s->nqps < 3 && get_bits1(&gb));\n    for (i = s->nqps; i < 3; i++)\n        s->qps[i] = -1;\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(s->avctx, AV_LOG_INFO, \" VP3 %sframe #%d: Q index = %d\\n\",\n               s->keyframe ? \"key\" : \"\", avctx->frame_number + 1, s->qps[0]);\n\n    s->skip_loop_filter = !s->filter_limit_values[s->qps[0]] ||\n                          avctx->skip_loop_filter >= (s->keyframe ? AVDISCARD_ALL\n                                                                  : AVDISCARD_NONKEY);\n\n    if (s->qps[0] != s->last_qps[0])\n        init_loop_filter(s);\n\n    for (i = 0; i < s->nqps; i++)\n        // reinit all dequantizers if the first one changed, because\n        // the DC of the first quantizer must be used for all matrices\n        if (s->qps[i] != s->last_qps[i] || s->qps[0] != s->last_qps[0])\n            init_dequantizer(s, i);\n\n    if (avctx->skip_frame >= AVDISCARD_NONKEY && !s->keyframe)\n        return buf_size;\n\n    s->current_frame.f->pict_type = s->keyframe ? AV_PICTURE_TYPE_I\n                                                : AV_PICTURE_TYPE_P;\n    s->current_frame.f->key_frame = s->keyframe;\n    if ((ret = ff_thread_get_ext_buffer(avctx, &s->current_frame,\n                                        AV_GET_BUFFER_FLAG_REF)) < 0)\n        goto error;\n\n    if (!s->edge_emu_buffer)\n        s->edge_emu_buffer = av_malloc(9 * FFABS(s->current_frame.f->linesize[0]));\n\n    if (s->keyframe) {\n        if (!s->theora) {\n            skip_bits(&gb, 4); /* width code */\n            skip_bits(&gb, 4); /* height code */\n            if (s->version) {\n                int version = get_bits(&gb, 5);\n#if !CONFIG_VP4_DECODER\n                if (version >= 2) {\n                    av_log(avctx, AV_LOG_ERROR, \"This build does not support decoding VP4.\\n\");\n                    return AVERROR_DECODER_NOT_FOUND;\n                }\n#endif\n                s->version = version;\n                if (avctx->frame_number == 0)\n                    av_log(s->avctx, AV_LOG_DEBUG,\n                           \"VP version: %d\\n\", s->version);\n            }\n        }\n        if (s->version || s->theora) {\n            if (get_bits1(&gb))\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Warning, unsupported keyframe coding type?!\\n\");\n            skip_bits(&gb, 2); /* reserved? */\n\n#if CONFIG_VP4_DECODER\n            if (s->version >= 2) {\n                int mb_height, mb_width;\n                int mb_width_mul, mb_width_div, mb_height_mul, mb_height_div;\n\n                mb_height = get_bits(&gb, 8);\n                mb_width  = get_bits(&gb, 8);\n                if (mb_height != s->macroblock_height ||\n                    mb_width != s->macroblock_width)\n                    avpriv_request_sample(s->avctx, \"macroblock dimension mismatch\");\n\n                mb_width_mul = get_bits(&gb, 5);\n                mb_width_div = get_bits(&gb, 3);\n                mb_height_mul = get_bits(&gb, 5);\n                mb_height_div = get_bits(&gb, 3);\n                if (mb_width_mul != 1 || mb_width_div != 1 || mb_height_mul != 1 || mb_height_div != 1)\n                    avpriv_request_sample(s->avctx, \"unexpected macroblock dimension multipler/divider\");\n\n                if (get_bits(&gb, 2))\n                    avpriv_request_sample(s->avctx, \"unknown bits\");\n            }\n#endif\n        }\n    } else {\n        if (!s->golden_frame.f->data[0]) {\n            av_log(s->avctx, AV_LOG_WARNING,\n                   \"vp3: first frame not a keyframe\\n\");\n\n            s->golden_frame.f->pict_type = AV_PICTURE_TYPE_I;\n            if ((ret = ff_thread_get_ext_buffer(avctx, &s->golden_frame,\n                                                AV_GET_BUFFER_FLAG_REF)) < 0)\n                goto error;\n            ff_thread_release_ext_buffer(avctx, &s->last_frame);\n            if ((ret = ff_thread_ref_frame(&s->last_frame,\n                                           &s->golden_frame)) < 0)\n                goto error;\n            ff_thread_report_progress(&s->last_frame, INT_MAX, 0);\n        }\n    }\n\n    memset(s->all_fragments, 0, s->fragment_count * sizeof(Vp3Fragment));\n    ff_thread_finish_setup(avctx);\n\n    if (s->version < 2) {\n        if ((ret = unpack_superblocks(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_superblocks\\n\");\n            goto error;\n        }\n#if CONFIG_VP4_DECODER\n    } else {\n        if ((ret = vp4_unpack_macroblocks(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in vp4_unpack_macroblocks\\n\");\n            goto error;\n    }\n#endif\n    }\n    if ((ret = unpack_modes(s, &gb)) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_modes\\n\");\n        goto error;\n    }\n    if (ret = unpack_vectors(s, &gb)) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_vectors\\n\");\n        goto error;\n    }\n    if ((ret = unpack_block_qpis(s, &gb)) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_block_qpis\\n\");\n        goto error;\n    }\n\n    if (s->version < 2) {\n        if ((ret = unpack_dct_coeffs(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_dct_coeffs\\n\");\n            goto error;\n        }\n#if CONFIG_VP4_DECODER\n    } else {\n        if ((ret = vp4_unpack_dct_coeffs(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in vp4_unpack_dct_coeffs\\n\");\n            goto error;\n        }\n#endif\n    }\n\n    for (i = 0; i < 3; i++) {\n        int height = s->height >> (i && s->chroma_y_shift);\n        if (s->flipped_image)\n            s->data_offset[i] = 0;\n        else\n            s->data_offset[i] = (height - 1) * s->current_frame.f->linesize[i];\n    }\n\n    s->last_slice_end = 0;\n    for (i = 0; i < s->c_superblock_height; i++)\n        render_slice(s, i);\n\n    // filter the last row\n    if (s->version < 2)\n        for (i = 0; i < 3; i++) {\n            int row = (s->height >> (3 + (i && s->chroma_y_shift))) - 1;\n            apply_loop_filter(s, i, row, row + 1);\n        }\n    vp3_draw_horiz_band(s, s->height);\n\n    /* output frame, offset as needed */\n    if ((ret = av_frame_ref(data, s->current_frame.f)) < 0)\n        return ret;\n\n    frame->crop_left   = s->offset_x;\n    frame->crop_right  = avctx->coded_width - avctx->width - s->offset_x;\n    frame->crop_top    = s->offset_y;\n    frame->crop_bottom = avctx->coded_height - avctx->height - s->offset_y;\n\n    *got_frame = 1;\n\n    if (!HAVE_THREADS || !(s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n        ret = update_frames(avctx);\n        if (ret < 0)\n            return ret;\n    }\n\n    return buf_size;\n\nerror:\n    ff_thread_report_progress(&s->current_frame, INT_MAX, 0);\n\n    if (!HAVE_THREADS || !(s->avctx->active_thread_type & FF_THREAD_FRAME))\n        av_frame_unref(s->current_frame.f);\n\n    return ret;\n}\n\nstatic int read_huffman_tree(HuffTable *huff, GetBitContext *gb, int length,\n                             AVCodecContext *avctx)\n{\n    if (get_bits1(gb)) {\n        int token;\n        if (huff->nb_entries >= 32) { /* overflow */\n            av_log(avctx, AV_LOG_ERROR, \"huffman tree overflow\\n\");\n            return -1;\n        }\n        token = get_bits(gb, 5);\n        ff_dlog(avctx, \"code length %d, curr entry %d, token %d\\n\",\n                length, huff->nb_entries, token);\n        huff->entries[huff->nb_entries++] = (HuffEntry){ length, token };\n    } else {\n        /* The following bound follows from the fact that nb_entries <= 32. */\n        if (length >= 31) { /* overflow */\n            av_log(avctx, AV_LOG_ERROR, \"huffman tree overflow\\n\");\n            return -1;\n        }\n        length++;\n        if (read_huffman_tree(huff, gb, length, avctx))\n            return -1;\n        if (read_huffman_tree(huff, gb, length, avctx))\n            return -1;\n    }\n    return 0;\n}\n\n#if CONFIG_THEORA_DECODER\nstatic const enum AVPixelFormat theora_pix_fmts[4] = {\n    AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE, AV_PIX_FMT_YUV422P, AV_PIX_FMT_YUV444P\n};\n\nstatic int theora_decode_header(AVCodecContext *avctx, GetBitContext *gb)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int visible_width, visible_height, colorspace;\n    uint8_t offset_x = 0, offset_y = 0;\n    int ret;\n    AVRational fps, aspect;\n\n    if (get_bits_left(gb) < 206)\n        return AVERROR_INVALIDDATA;\n\n    s->theora_header = 0;\n    s->theora = get_bits(gb, 24);\n    av_log(avctx, AV_LOG_DEBUG, \"Theora bitstream version %X\\n\", s->theora);\n    if (!s->theora) {\n        s->theora = 1;\n        avpriv_request_sample(s->avctx, \"theora 0\");\n    }\n\n    /* 3.2.0 aka alpha3 has the same frame orientation as original vp3\n     * but previous versions have the image flipped relative to vp3 */\n    if (s->theora < 0x030200) {\n        s->flipped_image = 1;\n        av_log(avctx, AV_LOG_DEBUG,\n               \"Old (<alpha3) Theora bitstream, flipped image\\n\");\n    }\n\n    visible_width  =\n    s->width       = get_bits(gb, 16) << 4;\n    visible_height =\n    s->height      = get_bits(gb, 16) << 4;\n\n    if (s->theora >= 0x030200) {\n        visible_width  = get_bits(gb, 24);\n        visible_height = get_bits(gb, 24);\n\n        offset_x = get_bits(gb, 8); /* offset x */\n        offset_y = get_bits(gb, 8); /* offset y, from bottom */\n    }\n\n    /* sanity check */\n    if (av_image_check_size(visible_width, visible_height, 0, avctx) < 0 ||\n        visible_width  + offset_x > s->width ||\n        visible_height + offset_y > s->height) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Invalid frame dimensions - w:%d h:%d x:%d y:%d (%dx%d).\\n\",\n               visible_width, visible_height, offset_x, offset_y,\n               s->width, s->height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    fps.num = get_bits_long(gb, 32);\n    fps.den = get_bits_long(gb, 32);\n    if (fps.num && fps.den) {\n        if (fps.num < 0 || fps.den < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid framerate\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        av_reduce(&avctx->framerate.den, &avctx->framerate.num,\n                  fps.den, fps.num, 1 << 30);\n    }\n\n    aspect.num = get_bits(gb, 24);\n    aspect.den = get_bits(gb, 24);\n    if (aspect.num && aspect.den) {\n        av_reduce(&avctx->sample_aspect_ratio.num,\n                  &avctx->sample_aspect_ratio.den,\n                  aspect.num, aspect.den, 1 << 30);\n        ff_set_sar(avctx, avctx->sample_aspect_ratio);\n    }\n\n    if (s->theora < 0x030200)\n        skip_bits(gb, 5); /* keyframe frequency force */\n    colorspace = get_bits(gb, 8);\n    skip_bits(gb, 24); /* bitrate */\n\n    skip_bits(gb, 6); /* quality hint */\n\n    if (s->theora >= 0x030200) {\n        skip_bits(gb, 5); /* keyframe frequency force */\n        avctx->pix_fmt = theora_pix_fmts[get_bits(gb, 2)];\n        if (avctx->pix_fmt == AV_PIX_FMT_NONE) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid pixel format\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        skip_bits(gb, 3); /* reserved */\n    } else\n        avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    ret = ff_set_dimensions(avctx, s->width, s->height);\n    if (ret < 0)\n        return ret;\n    if (!(avctx->flags2 & AV_CODEC_FLAG2_IGNORE_CROP)) {\n        avctx->width  = visible_width;\n        avctx->height = visible_height;\n        // translate offsets from theora axis ([0,0] lower left)\n        // to normal axis ([0,0] upper left)\n        s->offset_x = offset_x;\n        s->offset_y = s->height - visible_height - offset_y;\n    }\n\n    if (colorspace == 1)\n        avctx->color_primaries = AVCOL_PRI_BT470M;\n    else if (colorspace == 2)\n        avctx->color_primaries = AVCOL_PRI_BT470BG;\n\n    if (colorspace == 1 || colorspace == 2) {\n        avctx->colorspace = AVCOL_SPC_BT470BG;\n        avctx->color_trc  = AVCOL_TRC_BT709;\n    }\n\n    s->theora_header = 1;\n    return 0;\n}\n\nstatic int theora_decode_tables(AVCodecContext *avctx, GetBitContext *gb)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, n, matrices, inter, plane, ret;\n\n    if (!s->theora_header)\n        return AVERROR_INVALIDDATA;\n\n    if (s->theora >= 0x030200) {\n        n = get_bits(gb, 3);\n        /* loop filter limit values table */\n        if (n)\n            for (i = 0; i < 64; i++)\n                s->filter_limit_values[i] = get_bits(gb, n);\n    }\n\n    if (s->theora >= 0x030200)\n        n = get_bits(gb, 4) + 1;\n    else\n        n = 16;\n    /* quality threshold table */\n    for (i = 0; i < 64; i++)\n        s->coded_ac_scale_factor[i] = get_bits(gb, n);\n\n    if (s->theora >= 0x030200)\n        n = get_bits(gb, 4) + 1;\n    else\n        n = 16;\n    /* dc scale factor table */\n    for (i = 0; i < 64; i++)\n        s->coded_dc_scale_factor[0][i] =\n        s->coded_dc_scale_factor[1][i] = get_bits(gb, n);\n\n    if (s->theora >= 0x030200)\n        matrices = get_bits(gb, 9) + 1;\n    else\n        matrices = 3;\n\n    if (matrices > 384) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of base matrixes\\n\");\n        return -1;\n    }\n\n    for (n = 0; n < matrices; n++)\n        for (i = 0; i < 64; i++)\n            s->base_matrix[n][i] = get_bits(gb, 8);\n\n    for (inter = 0; inter <= 1; inter++) {\n        for (plane = 0; plane <= 2; plane++) {\n            int newqr = 1;\n            if (inter || plane > 0)\n                newqr = get_bits1(gb);\n            if (!newqr) {\n                int qtj, plj;\n                if (inter && get_bits1(gb)) {\n                    qtj = 0;\n                    plj = plane;\n                } else {\n                    qtj = (3 * inter + plane - 1) / 3;\n                    plj = (plane + 2) % 3;\n                }\n                s->qr_count[inter][plane] = s->qr_count[qtj][plj];\n                memcpy(s->qr_size[inter][plane], s->qr_size[qtj][plj],\n                       sizeof(s->qr_size[0][0]));\n                memcpy(s->qr_base[inter][plane], s->qr_base[qtj][plj],\n                       sizeof(s->qr_base[0][0]));\n            } else {\n                int qri = 0;\n                int qi  = 0;\n\n                for (;;) {\n                    i = get_bits(gb, av_log2(matrices - 1) + 1);\n                    if (i >= matrices) {\n                        av_log(avctx, AV_LOG_ERROR,\n                               \"invalid base matrix index\\n\");\n                        return -1;\n                    }\n                    s->qr_base[inter][plane][qri] = i;\n                    if (qi >= 63)\n                        break;\n                    i = get_bits(gb, av_log2(63 - qi) + 1) + 1;\n                    s->qr_size[inter][plane][qri++] = i;\n                    qi += i;\n                }\n\n                if (qi > 63) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid qi %d > 63\\n\", qi);\n                    return -1;\n                }\n                s->qr_count[inter][plane] = qri;\n            }\n        }\n    }\n\n    /* Huffman tables */\n    for (int i = 0; i < FF_ARRAY_ELEMS(s->huffman_table); i++) {\n        s->huffman_table[i].nb_entries = 0;\n        if ((ret = read_huffman_tree(&s->huffman_table[i], gb, 0, avctx)) < 0)\n            return ret;\n    }\n\n    s->theora_tables = 1;\n\n    return 0;\n}\n\nstatic av_cold int theora_decode_init(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    GetBitContext gb;\n    int ptype;\n    const uint8_t *header_start[3];\n    int header_len[3];\n    int i;\n    int ret;\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    s->theora = 1;\n\n    if (!avctx->extradata_size) {\n        av_log(avctx, AV_LOG_ERROR, \"Missing extradata!\\n\");\n        return -1;\n    }\n\n    if (avpriv_split_xiph_headers(avctx->extradata, avctx->extradata_size,\n                                  42, header_start, header_len) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Corrupt extradata\\n\");\n        return -1;\n    }\n\n    for (i = 0; i < 3; i++) {\n        if (header_len[i] <= 0)\n            continue;\n        ret = init_get_bits8(&gb, header_start[i], header_len[i]);\n        if (ret < 0)\n            return ret;\n\n        ptype = get_bits(&gb, 8);\n\n        if (!(ptype & 0x80)) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid extradata!\\n\");\n//          return -1;\n        }\n\n        // FIXME: Check for this as well.\n        skip_bits_long(&gb, 6 * 8); /* \"theora\" */\n\n        switch (ptype) {\n        case 0x80:\n            if (theora_decode_header(avctx, &gb) < 0)\n                return -1;\n            break;\n        case 0x81:\n// FIXME: is this needed? it breaks sometimes\n//            theora_decode_comments(avctx, gb);\n            break;\n        case 0x82:\n            if (theora_decode_tables(avctx, &gb))\n                return -1;\n            break;\n        default:\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Unknown Theora config packet: %d\\n\", ptype & ~0x80);\n            break;\n        }\n        if (ptype != 0x81 && get_bits_left(&gb) >= 8U)\n            av_log(avctx, AV_LOG_WARNING,\n                   \"%d bits left in packet %X\\n\",\n                   get_bits_left(&gb), ptype);\n        if (s->theora < 0x030200)\n            break;\n    }\n\n    return vp3_decode_init(avctx);\n}\n\nconst AVCodec ff_theora_decoder = {\n    .name                  = \"theora\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"Theora\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_THEORA,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = theora_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_EXPORTS_CROPPING | FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n#endif\n\nconst AVCodec ff_vp3_decoder = {\n    .name                  = \"vp3\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP3\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP3,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = vp3_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n\n#if CONFIG_VP4_DECODER\nconst AVCodec ff_vp4_decoder = {\n    .name                  = \"vp4\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP4\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP4,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = vp3_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n#endif\n"], "fixing_code": ["/*\n * Copyright (C) 2003-2004 The FFmpeg project\n * Copyright (C) 2019 Peter Ross\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * On2 VP3/VP4 Video Decoder\n *\n * VP3 Video Decoder by Mike Melanson (mike at multimedia.cx)\n * For more information about the VP3 coding process, visit:\n *   http://wiki.multimedia.cx/index.php?title=On2_VP3\n *\n * Theora decoder by Alex Beregszaszi\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/mem_internal.h\"\n\n#include \"avcodec.h\"\n#include \"get_bits.h\"\n#include \"hpeldsp.h\"\n#include \"internal.h\"\n#include \"mathops.h\"\n#include \"thread.h\"\n#include \"threadframe.h\"\n#include \"videodsp.h\"\n#include \"vp3data.h\"\n#include \"vp4data.h\"\n#include \"vp3dsp.h\"\n#include \"xiph.h\"\n\n#define VP3_MV_VLC_BITS     6\n#define VP4_MV_VLC_BITS     6\n#define SUPERBLOCK_VLC_BITS 6\n\n#define FRAGMENT_PIXELS 8\n\n// FIXME split things out into their own arrays\ntypedef struct Vp3Fragment {\n    int16_t dc;\n    uint8_t coding_method;\n    uint8_t qpi;\n} Vp3Fragment;\n\n#define SB_NOT_CODED        0\n#define SB_PARTIALLY_CODED  1\n#define SB_FULLY_CODED      2\n\n// This is the maximum length of a single long bit run that can be encoded\n// for superblock coding or block qps. Theora special-cases this to read a\n// bit instead of flipping the current bit to allow for runs longer than 4129.\n#define MAXIMUM_LONG_BIT_RUN 4129\n\n#define MODE_INTER_NO_MV      0\n#define MODE_INTRA            1\n#define MODE_INTER_PLUS_MV    2\n#define MODE_INTER_LAST_MV    3\n#define MODE_INTER_PRIOR_LAST 4\n#define MODE_USING_GOLDEN     5\n#define MODE_GOLDEN_MV        6\n#define MODE_INTER_FOURMV     7\n#define CODING_MODE_COUNT     8\n\n/* special internal mode */\n#define MODE_COPY             8\n\nstatic int theora_decode_header(AVCodecContext *avctx, GetBitContext *gb);\nstatic int theora_decode_tables(AVCodecContext *avctx, GetBitContext *gb);\n\n\n/* There are 6 preset schemes, plus a free-form scheme */\nstatic const int ModeAlphabet[6][CODING_MODE_COUNT] = {\n    /* scheme 1: Last motion vector dominates */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_PLUS_MV,    MODE_INTER_NO_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 2 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_NO_MV,      MODE_INTER_PLUS_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 3 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PLUS_MV,\n      MODE_INTER_PRIOR_LAST, MODE_INTER_NO_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 4 */\n    { MODE_INTER_LAST_MV,    MODE_INTER_PLUS_MV,\n      MODE_INTER_NO_MV,      MODE_INTER_PRIOR_LAST,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 5: No motion vector dominates */\n    { MODE_INTER_NO_MV,      MODE_INTER_LAST_MV,\n      MODE_INTER_PRIOR_LAST, MODE_INTER_PLUS_MV,\n      MODE_INTRA,            MODE_USING_GOLDEN,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n\n    /* scheme 6 */\n    { MODE_INTER_NO_MV,      MODE_USING_GOLDEN,\n      MODE_INTER_LAST_MV,    MODE_INTER_PRIOR_LAST,\n      MODE_INTER_PLUS_MV,    MODE_INTRA,\n      MODE_GOLDEN_MV,        MODE_INTER_FOURMV },\n};\n\nstatic const uint8_t hilbert_offset[16][2] = {\n    { 0, 0 }, { 1, 0 }, { 1, 1 }, { 0, 1 },\n    { 0, 2 }, { 0, 3 }, { 1, 3 }, { 1, 2 },\n    { 2, 2 }, { 2, 3 }, { 3, 3 }, { 3, 2 },\n    { 3, 1 }, { 2, 1 }, { 2, 0 }, { 3, 0 }\n};\n\nenum {\n    VP4_DC_INTRA  = 0,\n    VP4_DC_INTER  = 1,\n    VP4_DC_GOLDEN = 2,\n    NB_VP4_DC_TYPES,\n    VP4_DC_UNDEFINED = NB_VP4_DC_TYPES\n};\n\nstatic const uint8_t vp4_pred_block_type_map[8] = {\n    [MODE_INTER_NO_MV]      = VP4_DC_INTER,\n    [MODE_INTRA]            = VP4_DC_INTRA,\n    [MODE_INTER_PLUS_MV]    = VP4_DC_INTER,\n    [MODE_INTER_LAST_MV]    = VP4_DC_INTER,\n    [MODE_INTER_PRIOR_LAST] = VP4_DC_INTER,\n    [MODE_USING_GOLDEN]     = VP4_DC_GOLDEN,\n    [MODE_GOLDEN_MV]        = VP4_DC_GOLDEN,\n    [MODE_INTER_FOURMV]     = VP4_DC_INTER,\n};\n\ntypedef struct {\n    int dc;\n    int type;\n} VP4Predictor;\n\n#define MIN_DEQUANT_VAL 2\n\ntypedef struct HuffEntry {\n    uint8_t len, sym;\n} HuffEntry;\n\ntypedef struct HuffTable {\n    HuffEntry entries[32];\n    uint8_t   nb_entries;\n} HuffTable;\n\ntypedef struct Vp3DecodeContext {\n    AVCodecContext *avctx;\n    int theora, theora_tables, theora_header;\n    int version;\n    int width, height;\n    int chroma_x_shift, chroma_y_shift;\n    ThreadFrame golden_frame;\n    ThreadFrame last_frame;\n    ThreadFrame current_frame;\n    int keyframe;\n    uint8_t idct_permutation[64];\n    uint8_t idct_scantable[64];\n    HpelDSPContext hdsp;\n    VideoDSPContext vdsp;\n    VP3DSPContext vp3dsp;\n    DECLARE_ALIGNED(16, int16_t, block)[64];\n    int flipped_image;\n    int last_slice_end;\n    int skip_loop_filter;\n\n    int qps[3];\n    int nqps;\n    int last_qps[3];\n\n    int superblock_count;\n    int y_superblock_width;\n    int y_superblock_height;\n    int y_superblock_count;\n    int c_superblock_width;\n    int c_superblock_height;\n    int c_superblock_count;\n    int u_superblock_start;\n    int v_superblock_start;\n    unsigned char *superblock_coding;\n\n    int macroblock_count; /* y macroblock count */\n    int macroblock_width;\n    int macroblock_height;\n    int c_macroblock_count;\n    int c_macroblock_width;\n    int c_macroblock_height;\n    int yuv_macroblock_count; /* y+u+v macroblock count */\n\n    int fragment_count;\n    int fragment_width[2];\n    int fragment_height[2];\n\n    Vp3Fragment *all_fragments;\n    int fragment_start[3];\n    int data_offset[3];\n    uint8_t offset_x;\n    uint8_t offset_y;\n    int offset_x_warned;\n\n    int8_t (*motion_val[2])[2];\n\n    /* tables */\n    uint16_t coded_dc_scale_factor[2][64];\n    uint32_t coded_ac_scale_factor[64];\n    uint8_t base_matrix[384][64];\n    uint8_t qr_count[2][3];\n    uint8_t qr_size[2][3][64];\n    uint16_t qr_base[2][3][64];\n\n    /**\n     * This is a list of all tokens in bitstream order. Reordering takes place\n     * by pulling from each level during IDCT. As a consequence, IDCT must be\n     * in Hilbert order, making the minimum slice height 64 for 4:2:0 and 32\n     * otherwise. The 32 different tokens with up to 12 bits of extradata are\n     * collapsed into 3 types, packed as follows:\n     *   (from the low to high bits)\n     *\n     * 2 bits: type (0,1,2)\n     *   0: EOB run, 14 bits for run length (12 needed)\n     *   1: zero run, 7 bits for run length\n     *                7 bits for the next coefficient (3 needed)\n     *   2: coefficient, 14 bits (11 needed)\n     *\n     * Coefficients are signed, so are packed in the highest bits for automatic\n     * sign extension.\n     */\n    int16_t *dct_tokens[3][64];\n    int16_t *dct_tokens_base;\n#define TOKEN_EOB(eob_run)              ((eob_run) << 2)\n#define TOKEN_ZERO_RUN(coeff, zero_run) (((coeff) * 512) + ((zero_run) << 2) + 1)\n#define TOKEN_COEFF(coeff)              (((coeff) * 4) + 2)\n\n    /**\n     * number of blocks that contain DCT coefficients at\n     * the given level or higher\n     */\n    int num_coded_frags[3][64];\n    int total_num_coded_frags;\n\n    /* this is a list of indexes into the all_fragments array indicating\n     * which of the fragments are coded */\n    int *coded_fragment_list[3];\n\n    int *kf_coded_fragment_list;\n    int *nkf_coded_fragment_list;\n    int num_kf_coded_fragment[3];\n\n    /* The first 16 of the following VLCs are for the dc coefficients;\n       the others are four groups of 16 VLCs each for ac coefficients. */\n    VLC coeff_vlc[5 * 16];\n\n    VLC superblock_run_length_vlc; /* version < 2 */\n    VLC fragment_run_length_vlc; /* version < 2 */\n    VLC block_pattern_vlc[2]; /* version >= 2*/\n    VLC mode_code_vlc;\n    VLC motion_vector_vlc; /* version < 2 */\n    VLC vp4_mv_vlc[2][7]; /* version >=2 */\n\n    /* these arrays need to be on 16-byte boundaries since SSE2 operations\n     * index into them */\n    DECLARE_ALIGNED(16, int16_t, qmat)[3][2][3][64];     ///< qmat[qpi][is_inter][plane]\n\n    /* This table contains superblock_count * 16 entries. Each set of 16\n     * numbers corresponds to the fragment indexes 0..15 of the superblock.\n     * An entry will be -1 to indicate that no entry corresponds to that\n     * index. */\n    int *superblock_fragments;\n\n    /* This is an array that indicates how a particular macroblock\n     * is coded. */\n    unsigned char *macroblock_coding;\n\n    uint8_t *edge_emu_buffer;\n\n    /* Huffman decode */\n    HuffTable huffman_table[5 * 16];\n\n    uint8_t filter_limit_values[64];\n    DECLARE_ALIGNED(8, int, bounding_values_array)[256 + 2];\n\n    VP4Predictor * dc_pred_row; /* dc_pred_row[y_superblock_width * 4] */\n} Vp3DecodeContext;\n\n/************************************************************************\n * VP3 specific functions\n ************************************************************************/\n\nstatic av_cold void free_tables(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    av_freep(&s->superblock_coding);\n    av_freep(&s->all_fragments);\n    av_freep(&s->nkf_coded_fragment_list);\n    av_freep(&s->kf_coded_fragment_list);\n    av_freep(&s->dct_tokens_base);\n    av_freep(&s->superblock_fragments);\n    av_freep(&s->macroblock_coding);\n    av_freep(&s->dc_pred_row);\n    av_freep(&s->motion_val[0]);\n    av_freep(&s->motion_val[1]);\n}\n\nstatic void vp3_decode_flush(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    if (s->golden_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->golden_frame);\n    if (s->last_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->last_frame);\n    if (s->current_frame.f)\n        ff_thread_release_ext_buffer(avctx, &s->current_frame);\n}\n\nstatic av_cold int vp3_decode_end(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, j;\n\n    free_tables(avctx);\n    av_freep(&s->edge_emu_buffer);\n\n    s->theora_tables = 0;\n\n    /* release all frames */\n    vp3_decode_flush(avctx);\n    av_frame_free(&s->current_frame.f);\n    av_frame_free(&s->last_frame.f);\n    av_frame_free(&s->golden_frame.f);\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++)\n        ff_free_vlc(&s->coeff_vlc[i]);\n\n    ff_free_vlc(&s->superblock_run_length_vlc);\n    ff_free_vlc(&s->fragment_run_length_vlc);\n    ff_free_vlc(&s->mode_code_vlc);\n    ff_free_vlc(&s->motion_vector_vlc);\n\n    for (j = 0; j < 2; j++)\n        for (i = 0; i < 7; i++)\n            ff_free_vlc(&s->vp4_mv_vlc[j][i]);\n\n    for (i = 0; i < 2; i++)\n        ff_free_vlc(&s->block_pattern_vlc[i]);\n    return 0;\n}\n\n/**\n * This function sets up all of the various blocks mappings:\n * superblocks <-> fragments, macroblocks <-> fragments,\n * superblocks <-> macroblocks\n *\n * @return 0 is successful; returns 1 if *anything* went wrong.\n */\nstatic int init_block_mapping(Vp3DecodeContext *s)\n{\n    int sb_x, sb_y, plane;\n    int x, y, i, j = 0;\n\n    for (plane = 0; plane < 3; plane++) {\n        int sb_width    = plane ? s->c_superblock_width\n                                : s->y_superblock_width;\n        int sb_height   = plane ? s->c_superblock_height\n                                : s->y_superblock_height;\n        int frag_width  = s->fragment_width[!!plane];\n        int frag_height = s->fragment_height[!!plane];\n\n        for (sb_y = 0; sb_y < sb_height; sb_y++)\n            for (sb_x = 0; sb_x < sb_width; sb_x++)\n                for (i = 0; i < 16; i++) {\n                    x = 4 * sb_x + hilbert_offset[i][0];\n                    y = 4 * sb_y + hilbert_offset[i][1];\n\n                    if (x < frag_width && y < frag_height)\n                        s->superblock_fragments[j++] = s->fragment_start[plane] +\n                                                       y * frag_width + x;\n                    else\n                        s->superblock_fragments[j++] = -1;\n                }\n    }\n\n    return 0;  /* successful path out */\n}\n\n/*\n * This function sets up the dequantization tables used for a particular\n * frame.\n */\nstatic void init_dequantizer(Vp3DecodeContext *s, int qpi)\n{\n    int ac_scale_factor = s->coded_ac_scale_factor[s->qps[qpi]];\n    int i, plane, inter, qri, bmi, bmj, qistart;\n\n    for (inter = 0; inter < 2; inter++) {\n        for (plane = 0; plane < 3; plane++) {\n            int dc_scale_factor = s->coded_dc_scale_factor[!!plane][s->qps[qpi]];\n            int sum = 0;\n            for (qri = 0; qri < s->qr_count[inter][plane]; qri++) {\n                sum += s->qr_size[inter][plane][qri];\n                if (s->qps[qpi] <= sum)\n                    break;\n            }\n            qistart = sum - s->qr_size[inter][plane][qri];\n            bmi     = s->qr_base[inter][plane][qri];\n            bmj     = s->qr_base[inter][plane][qri + 1];\n            for (i = 0; i < 64; i++) {\n                int coeff = (2 * (sum     - s->qps[qpi]) * s->base_matrix[bmi][i] -\n                             2 * (qistart - s->qps[qpi]) * s->base_matrix[bmj][i] +\n                             s->qr_size[inter][plane][qri]) /\n                            (2 * s->qr_size[inter][plane][qri]);\n\n                int qmin   = 8 << (inter + !i);\n                int qscale = i ? ac_scale_factor : dc_scale_factor;\n                int qbias = (1 + inter) * 3;\n                s->qmat[qpi][inter][plane][s->idct_permutation[i]] =\n                    (i == 0 || s->version < 2) ? av_clip((qscale * coeff) / 100 * 4, qmin, 4096)\n                                               : (qscale * (coeff - qbias) / 100 + qbias) * 4;\n            }\n            /* all DC coefficients use the same quant so as not to interfere\n             * with DC prediction */\n            s->qmat[qpi][inter][plane][0] = s->qmat[0][inter][plane][0];\n        }\n    }\n}\n\n/*\n * This function initializes the loop filter boundary limits if the frame's\n * quality index is different from the previous frame's.\n *\n * The filter_limit_values may not be larger than 127.\n */\nstatic void init_loop_filter(Vp3DecodeContext *s)\n{\n    ff_vp3dsp_set_bounding_values(s->bounding_values_array, s->filter_limit_values[s->qps[0]]);\n}\n\n/*\n * This function unpacks all of the superblock/macroblock/fragment coding\n * information from the bitstream.\n */\nstatic int unpack_superblocks(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int superblock_starts[3] = {\n        0, s->u_superblock_start, s->v_superblock_start\n    };\n    int bit = 0;\n    int current_superblock = 0;\n    int current_run = 0;\n    int num_partial_superblocks = 0;\n\n    int i, j;\n    int current_fragment;\n    int plane;\n    int plane0_num_coded_frags = 0;\n\n    if (s->keyframe) {\n        memset(s->superblock_coding, SB_FULLY_CODED, s->superblock_count);\n    } else {\n        /* unpack the list of partially-coded superblocks */\n        bit         = get_bits1(gb) ^ 1;\n        current_run = 0;\n\n        while (current_superblock < s->superblock_count && get_bits_left(gb) > 0) {\n            if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n                bit = get_bits1(gb);\n            else\n                bit ^= 1;\n\n            current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                   SUPERBLOCK_VLC_BITS, 2);\n            if (current_run == 34)\n                current_run += get_bits(gb, 12);\n\n            if (current_run > s->superblock_count - current_superblock) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Invalid partially coded superblock run length\\n\");\n                return -1;\n            }\n\n            memset(s->superblock_coding + current_superblock, bit, current_run);\n\n            current_superblock += current_run;\n            if (bit)\n                num_partial_superblocks += current_run;\n        }\n\n        /* unpack the list of fully coded superblocks if any of the blocks were\n         * not marked as partially coded in the previous step */\n        if (num_partial_superblocks < s->superblock_count) {\n            int superblocks_decoded = 0;\n\n            current_superblock = 0;\n            bit                = get_bits1(gb) ^ 1;\n            current_run        = 0;\n\n            while (superblocks_decoded < s->superblock_count - num_partial_superblocks &&\n                   get_bits_left(gb) > 0) {\n                if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n                    bit = get_bits1(gb);\n                else\n                    bit ^= 1;\n\n                current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                       SUPERBLOCK_VLC_BITS, 2);\n                if (current_run == 34)\n                    current_run += get_bits(gb, 12);\n\n                for (j = 0; j < current_run; current_superblock++) {\n                    if (current_superblock >= s->superblock_count) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                               \"Invalid fully coded superblock run length\\n\");\n                        return -1;\n                    }\n\n                    /* skip any superblocks already marked as partially coded */\n                    if (s->superblock_coding[current_superblock] == SB_NOT_CODED) {\n                        s->superblock_coding[current_superblock] = 2 * bit;\n                        j++;\n                    }\n                }\n                superblocks_decoded += current_run;\n            }\n        }\n\n        /* if there were partial blocks, initialize bitstream for\n         * unpacking fragment codings */\n        if (num_partial_superblocks) {\n            current_run = 0;\n            bit         = get_bits1(gb);\n            /* toggle the bit because as soon as the first run length is\n             * fetched the bit will be toggled again */\n            bit ^= 1;\n        }\n    }\n\n    /* figure out which fragments are coded; iterate through each\n     * superblock (all planes) */\n    s->total_num_coded_frags = 0;\n    memset(s->macroblock_coding, MODE_COPY, s->macroblock_count);\n\n    s->coded_fragment_list[0] = s->keyframe ? s->kf_coded_fragment_list\n                                            : s->nkf_coded_fragment_list;\n\n    for (plane = 0; plane < 3; plane++) {\n        int sb_start = superblock_starts[plane];\n        int sb_end   = sb_start + (plane ? s->c_superblock_count\n                                         : s->y_superblock_count);\n        int num_coded_frags = 0;\n\n        if (s->keyframe) {\n            if (s->num_kf_coded_fragment[plane] == -1) {\n                for (i = sb_start; i < sb_end; i++) {\n                    /* iterate through all 16 fragments in a superblock */\n                    for (j = 0; j < 16; j++) {\n                        /* if the fragment is in bounds, check its coding status */\n                        current_fragment = s->superblock_fragments[i * 16 + j];\n                        if (current_fragment != -1) {\n                            s->coded_fragment_list[plane][num_coded_frags++] =\n                                current_fragment;\n                        }\n                    }\n                }\n                s->num_kf_coded_fragment[plane] = num_coded_frags;\n            } else\n                num_coded_frags = s->num_kf_coded_fragment[plane];\n        } else {\n            for (i = sb_start; i < sb_end && get_bits_left(gb) > 0; i++) {\n                if (get_bits_left(gb) < plane0_num_coded_frags >> 2) {\n                    return AVERROR_INVALIDDATA;\n                }\n                /* iterate through all 16 fragments in a superblock */\n                for (j = 0; j < 16; j++) {\n                    /* if the fragment is in bounds, check its coding status */\n                    current_fragment = s->superblock_fragments[i * 16 + j];\n                    if (current_fragment != -1) {\n                        int coded = s->superblock_coding[i];\n\n                        if (coded == SB_PARTIALLY_CODED) {\n                            /* fragment may or may not be coded; this is the case\n                             * that cares about the fragment coding runs */\n                            if (current_run-- == 0) {\n                                bit        ^= 1;\n                                current_run = get_vlc2(gb, s->fragment_run_length_vlc.table, 5, 2);\n                            }\n                            coded = bit;\n                        }\n\n                        if (coded) {\n                            /* default mode; actual mode will be decoded in\n                             * the next phase */\n                            s->all_fragments[current_fragment].coding_method =\n                                MODE_INTER_NO_MV;\n                            s->coded_fragment_list[plane][num_coded_frags++] =\n                                current_fragment;\n                        } else {\n                            /* not coded; copy this fragment from the prior frame */\n                            s->all_fragments[current_fragment].coding_method =\n                                MODE_COPY;\n                        }\n                    }\n                }\n            }\n        }\n        if (!plane)\n            plane0_num_coded_frags = num_coded_frags;\n        s->total_num_coded_frags += num_coded_frags;\n        for (i = 0; i < 64; i++)\n            s->num_coded_frags[plane][i] = num_coded_frags;\n        if (plane < 2)\n            s->coded_fragment_list[plane + 1] = s->coded_fragment_list[plane] +\n                                                num_coded_frags;\n    }\n    return 0;\n}\n\n#define BLOCK_X (2 * mb_x + (k & 1))\n#define BLOCK_Y (2 * mb_y + (k >> 1))\n\n#if CONFIG_VP4_DECODER\n/**\n * @return number of blocks, or > yuv_macroblock_count on error.\n *         return value is always >= 1.\n */\nstatic int vp4_get_mb_count(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int v = 1;\n    int bits;\n    while ((bits = show_bits(gb, 9)) == 0x1ff) {\n        skip_bits(gb, 9);\n        v += 256;\n        if (v > s->yuv_macroblock_count) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid run length\\n\");\n            return v;\n        }\n    }\n#define body(n) { \\\n    skip_bits(gb, 2 + n); \\\n    v += (1 << n) + get_bits(gb, n); }\n#define thresh(n) (0x200 - (0x80 >> n))\n#define else_if(n) else if (bits < thresh(n)) body(n)\n    if (bits < 0x100) {\n        skip_bits(gb, 1);\n    } else if (bits < thresh(0)) {\n        skip_bits(gb, 2);\n        v += 1;\n    }\n    else_if(1)\n    else_if(2)\n    else_if(3)\n    else_if(4)\n    else_if(5)\n    else_if(6)\n    else body(7)\n#undef body\n#undef thresh\n#undef else_if\n    return v;\n}\n\nstatic int vp4_get_block_pattern(Vp3DecodeContext *s, GetBitContext *gb, int *next_block_pattern_table)\n{\n    int v = get_vlc2(gb, s->block_pattern_vlc[*next_block_pattern_table].table, 3, 2);\n    *next_block_pattern_table = vp4_block_pattern_table_selector[v];\n    return v + 1;\n}\n\nstatic int vp4_unpack_macroblocks(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int plane, i, j, k, fragment;\n    int next_block_pattern_table;\n    int bit, current_run, has_partial;\n\n    memset(s->macroblock_coding, MODE_COPY, s->macroblock_count);\n\n    if (s->keyframe)\n        return 0;\n\n    has_partial = 0;\n    bit         = get_bits1(gb);\n    for (i = 0; i < s->yuv_macroblock_count; i += current_run) {\n        if (get_bits_left(gb) <= 0)\n            return AVERROR_INVALIDDATA;\n        current_run = vp4_get_mb_count(s, gb);\n        if (current_run > s->yuv_macroblock_count - i)\n            return -1;\n        memset(s->superblock_coding + i, 2 * bit, current_run);\n        bit ^= 1;\n        has_partial |= bit;\n    }\n\n    if (has_partial) {\n        if (get_bits_left(gb) <= 0)\n            return AVERROR_INVALIDDATA;\n        bit  = get_bits1(gb);\n        current_run = vp4_get_mb_count(s, gb);\n        for (i = 0; i < s->yuv_macroblock_count; i++) {\n            if (!s->superblock_coding[i]) {\n                if (!current_run) {\n                    bit ^= 1;\n                    current_run = vp4_get_mb_count(s, gb);\n                }\n                s->superblock_coding[i] = bit;\n                current_run--;\n            }\n        }\n        if (current_run) /* handle situation when vp4_get_mb_count() fails */\n            return -1;\n    }\n\n    next_block_pattern_table = 0;\n    i = 0;\n    for (plane = 0; plane < 3; plane++) {\n        int sb_x, sb_y;\n        int sb_width = plane ? s->c_superblock_width : s->y_superblock_width;\n        int sb_height = plane ? s->c_superblock_height : s->y_superblock_height;\n        int mb_width = plane ? s->c_macroblock_width : s->macroblock_width;\n        int mb_height = plane ? s->c_macroblock_height : s->macroblock_height;\n        int fragment_width = s->fragment_width[!!plane];\n        int fragment_height = s->fragment_height[!!plane];\n\n        for (sb_y = 0; sb_y < sb_height; sb_y++) {\n            for (sb_x = 0; sb_x < sb_width; sb_x++) {\n                for (j = 0; j < 4; j++) {\n                    int mb_x = 2 * sb_x + (j >> 1);\n                    int mb_y = 2 * sb_y + (j >> 1) ^ (j & 1);\n                    int mb_coded, pattern, coded;\n\n                    if (mb_x >= mb_width || mb_y >= mb_height)\n                        continue;\n\n                    mb_coded = s->superblock_coding[i++];\n\n                    if (mb_coded == SB_FULLY_CODED)\n                        pattern = 0xF;\n                    else if (mb_coded == SB_PARTIALLY_CODED)\n                        pattern = vp4_get_block_pattern(s, gb, &next_block_pattern_table);\n                    else\n                        pattern = 0;\n\n                    for (k = 0; k < 4; k++) {\n                        if (BLOCK_X >= fragment_width || BLOCK_Y >= fragment_height)\n                            continue;\n                        fragment = s->fragment_start[plane] + BLOCK_Y * fragment_width + BLOCK_X;\n                        coded = pattern & (8 >> k);\n                        /* MODE_INTER_NO_MV is the default for coded fragments.\n                           the actual method is decoded in the next phase. */\n                        s->all_fragments[fragment].coding_method = coded ? MODE_INTER_NO_MV : MODE_COPY;\n                    }\n                }\n            }\n        }\n    }\n    return 0;\n}\n#endif\n\n/*\n * This function unpacks all the coding mode data for individual macroblocks\n * from the bitstream.\n */\nstatic int unpack_modes(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i, j, k, sb_x, sb_y;\n    int scheme;\n    int current_macroblock;\n    int current_fragment;\n    int coding_mode;\n    int custom_mode_alphabet[CODING_MODE_COUNT];\n    const int *alphabet;\n    Vp3Fragment *frag;\n\n    if (s->keyframe) {\n        for (i = 0; i < s->fragment_count; i++)\n            s->all_fragments[i].coding_method = MODE_INTRA;\n    } else {\n        /* fetch the mode coding scheme for this frame */\n        scheme = get_bits(gb, 3);\n\n        /* is it a custom coding scheme? */\n        if (scheme == 0) {\n            for (i = 0; i < 8; i++)\n                custom_mode_alphabet[i] = MODE_INTER_NO_MV;\n            for (i = 0; i < 8; i++)\n                custom_mode_alphabet[get_bits(gb, 3)] = i;\n            alphabet = custom_mode_alphabet;\n        } else\n            alphabet = ModeAlphabet[scheme - 1];\n\n        /* iterate through all of the macroblocks that contain 1 or more\n         * coded fragments */\n        for (sb_y = 0; sb_y < s->y_superblock_height; sb_y++) {\n            for (sb_x = 0; sb_x < s->y_superblock_width; sb_x++) {\n                if (get_bits_left(gb) <= 0)\n                    return -1;\n\n                for (j = 0; j < 4; j++) {\n                    int mb_x = 2 * sb_x + (j >> 1);\n                    int mb_y = 2 * sb_y + (((j >> 1) + j) & 1);\n                    current_macroblock = mb_y * s->macroblock_width + mb_x;\n\n                    if (mb_x >= s->macroblock_width ||\n                        mb_y >= s->macroblock_height)\n                        continue;\n\n                    /* coding modes are only stored if the macroblock has\n                     * at least one luma block coded, otherwise it must be\n                     * INTER_NO_MV */\n                    for (k = 0; k < 4; k++) {\n                        current_fragment = BLOCK_Y *\n                                           s->fragment_width[0] + BLOCK_X;\n                        if (s->all_fragments[current_fragment].coding_method != MODE_COPY)\n                            break;\n                    }\n                    if (k == 4) {\n                        s->macroblock_coding[current_macroblock] = MODE_INTER_NO_MV;\n                        continue;\n                    }\n\n                    /* mode 7 means get 3 bits for each coding mode */\n                    if (scheme == 7)\n                        coding_mode = get_bits(gb, 3);\n                    else\n                        coding_mode = alphabet[get_vlc2(gb, s->mode_code_vlc.table, 3, 3)];\n\n                    s->macroblock_coding[current_macroblock] = coding_mode;\n                    for (k = 0; k < 4; k++) {\n                        frag = s->all_fragments + BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                        if (frag->coding_method != MODE_COPY)\n                            frag->coding_method = coding_mode;\n                    }\n\n#define SET_CHROMA_MODES                                                      \\\n    if (frag[s->fragment_start[1]].coding_method != MODE_COPY)                \\\n        frag[s->fragment_start[1]].coding_method = coding_mode;               \\\n    if (frag[s->fragment_start[2]].coding_method != MODE_COPY)                \\\n        frag[s->fragment_start[2]].coding_method = coding_mode;\n\n                    if (s->chroma_y_shift) {\n                        frag = s->all_fragments + mb_y *\n                               s->fragment_width[1] + mb_x;\n                        SET_CHROMA_MODES\n                    } else if (s->chroma_x_shift) {\n                        frag = s->all_fragments +\n                               2 * mb_y * s->fragment_width[1] + mb_x;\n                        for (k = 0; k < 2; k++) {\n                            SET_CHROMA_MODES\n                            frag += s->fragment_width[1];\n                        }\n                    } else {\n                        for (k = 0; k < 4; k++) {\n                            frag = s->all_fragments +\n                                   BLOCK_Y * s->fragment_width[1] + BLOCK_X;\n                            SET_CHROMA_MODES\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic int vp4_get_mv(Vp3DecodeContext *s, GetBitContext *gb, int axis, int last_motion)\n{\n    int v = get_vlc2(gb, s->vp4_mv_vlc[axis][vp4_mv_table_selector[FFABS(last_motion)]].table,\n                     VP4_MV_VLC_BITS, 2);\n    return last_motion < 0 ? -v : v;\n}\n\n/*\n * This function unpacks all the motion vectors for the individual\n * macroblocks from the bitstream.\n */\nstatic int unpack_vectors(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int j, k, sb_x, sb_y;\n    int coding_mode;\n    int motion_x[4];\n    int motion_y[4];\n    int last_motion_x = 0;\n    int last_motion_y = 0;\n    int prior_last_motion_x = 0;\n    int prior_last_motion_y = 0;\n    int last_gold_motion_x = 0;\n    int last_gold_motion_y = 0;\n    int current_macroblock;\n    int current_fragment;\n    int frag;\n\n    if (s->keyframe)\n        return 0;\n\n    /* coding mode 0 is the VLC scheme; 1 is the fixed code scheme; 2 is VP4 code scheme */\n    coding_mode = s->version < 2 ? get_bits1(gb) : 2;\n\n    /* iterate through all of the macroblocks that contain 1 or more\n     * coded fragments */\n    for (sb_y = 0; sb_y < s->y_superblock_height; sb_y++) {\n        for (sb_x = 0; sb_x < s->y_superblock_width; sb_x++) {\n            if (get_bits_left(gb) <= 0)\n                return -1;\n\n            for (j = 0; j < 4; j++) {\n                int mb_x = 2 * sb_x + (j >> 1);\n                int mb_y = 2 * sb_y + (((j >> 1) + j) & 1);\n                current_macroblock = mb_y * s->macroblock_width + mb_x;\n\n                if (mb_x >= s->macroblock_width  ||\n                    mb_y >= s->macroblock_height ||\n                    s->macroblock_coding[current_macroblock] == MODE_COPY)\n                    continue;\n\n                switch (s->macroblock_coding[current_macroblock]) {\n                case MODE_GOLDEN_MV:\n                    if (coding_mode == 2) { /* VP4 */\n                        last_gold_motion_x = motion_x[0] = vp4_get_mv(s, gb, 0, last_gold_motion_x);\n                        last_gold_motion_y = motion_y[0] = vp4_get_mv(s, gb, 1, last_gold_motion_y);\n                        break;\n                    } /* otherwise fall through */\n                case MODE_INTER_PLUS_MV:\n                    /* all 6 fragments use the same motion vector */\n                    if (coding_mode == 0) {\n                        motion_x[0] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                               VP3_MV_VLC_BITS, 2);\n                        motion_y[0] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                               VP3_MV_VLC_BITS, 2);\n                    } else if (coding_mode == 1) {\n                        motion_x[0] = fixed_motion_vector_table[get_bits(gb, 6)];\n                        motion_y[0] = fixed_motion_vector_table[get_bits(gb, 6)];\n                    } else { /* VP4 */\n                        motion_x[0] = vp4_get_mv(s, gb, 0, last_motion_x);\n                        motion_y[0] = vp4_get_mv(s, gb, 1, last_motion_y);\n                    }\n\n                    /* vector maintenance, only on MODE_INTER_PLUS_MV */\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_PLUS_MV) {\n                        prior_last_motion_x = last_motion_x;\n                        prior_last_motion_y = last_motion_y;\n                        last_motion_x       = motion_x[0];\n                        last_motion_y       = motion_y[0];\n                    }\n                    break;\n\n                case MODE_INTER_FOURMV:\n                    /* vector maintenance */\n                    prior_last_motion_x = last_motion_x;\n                    prior_last_motion_y = last_motion_y;\n\n                    /* fetch 4 vectors from the bitstream, one for each\n                     * Y fragment, then average for the C fragment vectors */\n                    for (k = 0; k < 4; k++) {\n                        current_fragment = BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                        if (s->all_fragments[current_fragment].coding_method != MODE_COPY) {\n                            if (coding_mode == 0) {\n                                motion_x[k] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                                       VP3_MV_VLC_BITS, 2);\n                                motion_y[k] = get_vlc2(gb, s->motion_vector_vlc.table,\n                                                       VP3_MV_VLC_BITS, 2);\n                            } else if (coding_mode == 1) {\n                                motion_x[k] = fixed_motion_vector_table[get_bits(gb, 6)];\n                                motion_y[k] = fixed_motion_vector_table[get_bits(gb, 6)];\n                            } else { /* VP4 */\n                                motion_x[k] = vp4_get_mv(s, gb, 0, prior_last_motion_x);\n                                motion_y[k] = vp4_get_mv(s, gb, 1, prior_last_motion_y);\n                            }\n                            last_motion_x = motion_x[k];\n                            last_motion_y = motion_y[k];\n                        } else {\n                            motion_x[k] = 0;\n                            motion_y[k] = 0;\n                        }\n                    }\n                    break;\n\n                case MODE_INTER_LAST_MV:\n                    /* all 6 fragments use the last motion vector */\n                    motion_x[0] = last_motion_x;\n                    motion_y[0] = last_motion_y;\n\n                    /* no vector maintenance (last vector remains the\n                     * last vector) */\n                    break;\n\n                case MODE_INTER_PRIOR_LAST:\n                    /* all 6 fragments use the motion vector prior to the\n                     * last motion vector */\n                    motion_x[0] = prior_last_motion_x;\n                    motion_y[0] = prior_last_motion_y;\n\n                    /* vector maintenance */\n                    prior_last_motion_x = last_motion_x;\n                    prior_last_motion_y = last_motion_y;\n                    last_motion_x       = motion_x[0];\n                    last_motion_y       = motion_y[0];\n                    break;\n\n                default:\n                    /* covers intra, inter without MV, golden without MV */\n                    motion_x[0] = 0;\n                    motion_y[0] = 0;\n\n                    /* no vector maintenance */\n                    break;\n                }\n\n                /* assign the motion vectors to the correct fragments */\n                for (k = 0; k < 4; k++) {\n                    current_fragment =\n                        BLOCK_Y * s->fragment_width[0] + BLOCK_X;\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        s->motion_val[0][current_fragment][0] = motion_x[k];\n                        s->motion_val[0][current_fragment][1] = motion_y[k];\n                    } else {\n                        s->motion_val[0][current_fragment][0] = motion_x[0];\n                        s->motion_val[0][current_fragment][1] = motion_y[0];\n                    }\n                }\n\n                if (s->chroma_y_shift) {\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        motion_x[0] = RSHIFT(motion_x[0] + motion_x[1] +\n                                             motion_x[2] + motion_x[3], 2);\n                        motion_y[0] = RSHIFT(motion_y[0] + motion_y[1] +\n                                             motion_y[2] + motion_y[3], 2);\n                    }\n                    if (s->version <= 2) {\n                        motion_x[0] = (motion_x[0] >> 1) | (motion_x[0] & 1);\n                        motion_y[0] = (motion_y[0] >> 1) | (motion_y[0] & 1);\n                    }\n                    frag = mb_y * s->fragment_width[1] + mb_x;\n                    s->motion_val[1][frag][0] = motion_x[0];\n                    s->motion_val[1][frag][1] = motion_y[0];\n                } else if (s->chroma_x_shift) {\n                    if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                        motion_x[0] = RSHIFT(motion_x[0] + motion_x[1], 1);\n                        motion_y[0] = RSHIFT(motion_y[0] + motion_y[1], 1);\n                        motion_x[1] = RSHIFT(motion_x[2] + motion_x[3], 1);\n                        motion_y[1] = RSHIFT(motion_y[2] + motion_y[3], 1);\n                    } else {\n                        motion_x[1] = motion_x[0];\n                        motion_y[1] = motion_y[0];\n                    }\n                    if (s->version <= 2) {\n                        motion_x[0] = (motion_x[0] >> 1) | (motion_x[0] & 1);\n                        motion_x[1] = (motion_x[1] >> 1) | (motion_x[1] & 1);\n                    }\n                    frag = 2 * mb_y * s->fragment_width[1] + mb_x;\n                    for (k = 0; k < 2; k++) {\n                        s->motion_val[1][frag][0] = motion_x[k];\n                        s->motion_val[1][frag][1] = motion_y[k];\n                        frag += s->fragment_width[1];\n                    }\n                } else {\n                    for (k = 0; k < 4; k++) {\n                        frag = BLOCK_Y * s->fragment_width[1] + BLOCK_X;\n                        if (s->macroblock_coding[current_macroblock] == MODE_INTER_FOURMV) {\n                            s->motion_val[1][frag][0] = motion_x[k];\n                            s->motion_val[1][frag][1] = motion_y[k];\n                        } else {\n                            s->motion_val[1][frag][0] = motion_x[0];\n                            s->motion_val[1][frag][1] = motion_y[0];\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic int unpack_block_qpis(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int qpi, i, j, bit, run_length, blocks_decoded, num_blocks_at_qpi;\n    int num_blocks = s->total_num_coded_frags;\n\n    for (qpi = 0; qpi < s->nqps - 1 && num_blocks > 0; qpi++) {\n        i = blocks_decoded = num_blocks_at_qpi = 0;\n\n        bit        = get_bits1(gb) ^ 1;\n        run_length = 0;\n\n        do {\n            if (run_length == MAXIMUM_LONG_BIT_RUN)\n                bit = get_bits1(gb);\n            else\n                bit ^= 1;\n\n            run_length = get_vlc2(gb, s->superblock_run_length_vlc.table,\n                                  SUPERBLOCK_VLC_BITS, 2);\n            if (run_length == 34)\n                run_length += get_bits(gb, 12);\n            blocks_decoded += run_length;\n\n            if (!bit)\n                num_blocks_at_qpi += run_length;\n\n            for (j = 0; j < run_length; i++) {\n                if (i >= s->total_num_coded_frags)\n                    return -1;\n\n                if (s->all_fragments[s->coded_fragment_list[0][i]].qpi == qpi) {\n                    s->all_fragments[s->coded_fragment_list[0][i]].qpi += bit;\n                    j++;\n                }\n            }\n        } while (blocks_decoded < num_blocks && get_bits_left(gb) > 0);\n\n        num_blocks -= num_blocks_at_qpi;\n    }\n\n    return 0;\n}\n\nstatic inline int get_eob_run(GetBitContext *gb, int token)\n{\n    int v = eob_run_table[token].base;\n    if (eob_run_table[token].bits)\n        v += get_bits(gb, eob_run_table[token].bits);\n    return v;\n}\n\nstatic inline int get_coeff(GetBitContext *gb, int token, int16_t *coeff)\n{\n    int bits_to_get, zero_run;\n\n    bits_to_get = coeff_get_bits[token];\n    if (bits_to_get)\n        bits_to_get = get_bits(gb, bits_to_get);\n    *coeff = coeff_tables[token][bits_to_get];\n\n    zero_run = zero_run_base[token];\n    if (zero_run_get_bits[token])\n        zero_run += get_bits(gb, zero_run_get_bits[token]);\n\n    return zero_run;\n}\n\n/*\n * This function is called by unpack_dct_coeffs() to extract the VLCs from\n * the bitstream. The VLCs encode tokens which are used to unpack DCT\n * data. This function unpacks all the VLCs for either the Y plane or both\n * C planes, and is called for DC coefficients or different AC coefficient\n * levels (since different coefficient types require different VLC tables.\n *\n * This function returns a residual eob run. E.g, if a particular token gave\n * instructions to EOB the next 5 fragments and there were only 2 fragments\n * left in the current fragment range, 3 would be returned so that it could\n * be passed into the next call to this same function.\n */\nstatic int unpack_vlcs(Vp3DecodeContext *s, GetBitContext *gb,\n                       VLC *table, int coeff_index,\n                       int plane,\n                       int eob_run)\n{\n    int i, j = 0;\n    int token;\n    int zero_run  = 0;\n    int16_t coeff = 0;\n    int blocks_ended;\n    int coeff_i = 0;\n    int num_coeffs      = s->num_coded_frags[plane][coeff_index];\n    int16_t *dct_tokens = s->dct_tokens[plane][coeff_index];\n\n    /* local references to structure members to avoid repeated dereferences */\n    int *coded_fragment_list   = s->coded_fragment_list[plane];\n    Vp3Fragment *all_fragments = s->all_fragments;\n    VLC_TYPE(*vlc_table)[2] = table->table;\n\n    if (num_coeffs < 0) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Invalid number of coefficients at level %d\\n\", coeff_index);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (eob_run > num_coeffs) {\n        coeff_i      =\n        blocks_ended = num_coeffs;\n        eob_run     -= num_coeffs;\n    } else {\n        coeff_i      =\n        blocks_ended = eob_run;\n        eob_run      = 0;\n    }\n\n    // insert fake EOB token to cover the split between planes or zzi\n    if (blocks_ended)\n        dct_tokens[j++] = blocks_ended << 2;\n\n    while (coeff_i < num_coeffs && get_bits_left(gb) > 0) {\n        /* decode a VLC into a token */\n        token = get_vlc2(gb, vlc_table, 11, 3);\n        /* use the token to get a zero run, a coefficient, and an eob run */\n        if ((unsigned) token <= 6U) {\n            eob_run = get_eob_run(gb, token);\n            if (!eob_run)\n                eob_run = INT_MAX;\n\n            // record only the number of blocks ended in this plane,\n            // any spill will be recorded in the next plane.\n            if (eob_run > num_coeffs - coeff_i) {\n                dct_tokens[j++] = TOKEN_EOB(num_coeffs - coeff_i);\n                blocks_ended   += num_coeffs - coeff_i;\n                eob_run        -= num_coeffs - coeff_i;\n                coeff_i         = num_coeffs;\n            } else {\n                dct_tokens[j++] = TOKEN_EOB(eob_run);\n                blocks_ended   += eob_run;\n                coeff_i        += eob_run;\n                eob_run         = 0;\n            }\n        } else if (token >= 0) {\n            zero_run = get_coeff(gb, token, &coeff);\n\n            if (zero_run) {\n                dct_tokens[j++] = TOKEN_ZERO_RUN(coeff, zero_run);\n            } else {\n                // Save DC into the fragment structure. DC prediction is\n                // done in raster order, so the actual DC can't be in with\n                // other tokens. We still need the token in dct_tokens[]\n                // however, or else the structure collapses on itself.\n                if (!coeff_index)\n                    all_fragments[coded_fragment_list[coeff_i]].dc = coeff;\n\n                dct_tokens[j++] = TOKEN_COEFF(coeff);\n            }\n\n            if (coeff_index + zero_run > 64) {\n                av_log(s->avctx, AV_LOG_DEBUG,\n                       \"Invalid zero run of %d with %d coeffs left\\n\",\n                       zero_run, 64 - coeff_index);\n                zero_run = 64 - coeff_index;\n            }\n\n            // zero runs code multiple coefficients,\n            // so don't try to decode coeffs for those higher levels\n            for (i = coeff_index + 1; i <= coeff_index + zero_run; i++)\n                s->num_coded_frags[plane][i]--;\n            coeff_i++;\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid token %d\\n\", token);\n            return -1;\n        }\n    }\n\n    if (blocks_ended > s->num_coded_frags[plane][coeff_index])\n        av_log(s->avctx, AV_LOG_ERROR, \"More blocks ended than coded!\\n\");\n\n    // decrement the number of blocks that have higher coefficients for each\n    // EOB run at this level\n    if (blocks_ended)\n        for (i = coeff_index + 1; i < 64; i++)\n            s->num_coded_frags[plane][i] -= blocks_ended;\n\n    // setup the next buffer\n    if (plane < 2)\n        s->dct_tokens[plane + 1][coeff_index] = dct_tokens + j;\n    else if (coeff_index < 63)\n        s->dct_tokens[0][coeff_index + 1] = dct_tokens + j;\n\n    return eob_run;\n}\n\nstatic void reverse_dc_prediction(Vp3DecodeContext *s,\n                                  int first_fragment,\n                                  int fragment_width,\n                                  int fragment_height);\n/*\n * This function unpacks all of the DCT coefficient data from the\n * bitstream.\n */\nstatic int unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i;\n    int dc_y_table;\n    int dc_c_table;\n    int ac_y_table;\n    int ac_c_table;\n    int residual_eob_run = 0;\n    VLC *y_tables[64];\n    VLC *c_tables[64];\n\n    s->dct_tokens[0][0] = s->dct_tokens_base;\n\n    if (get_bits_left(gb) < 16)\n        return AVERROR_INVALIDDATA;\n\n    /* fetch the DC table indexes */\n    dc_y_table = get_bits(gb, 4);\n    dc_c_table = get_bits(gb, 4);\n\n    /* unpack the Y plane DC coefficients */\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_y_table], 0,\n                                   0, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n    if (get_bits_left(gb) < 8)\n        return AVERROR_INVALIDDATA;\n\n    /* reverse prediction of the Y-plane DC coefficients */\n    reverse_dc_prediction(s, 0, s->fragment_width[0], s->fragment_height[0]);\n\n    /* unpack the C plane DC coefficients */\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_c_table], 0,\n                                   1, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n    residual_eob_run = unpack_vlcs(s, gb, &s->coeff_vlc[dc_c_table], 0,\n                                   2, residual_eob_run);\n    if (residual_eob_run < 0)\n        return residual_eob_run;\n\n    /* reverse prediction of the C-plane DC coefficients */\n    if (!(s->avctx->flags & AV_CODEC_FLAG_GRAY)) {\n        reverse_dc_prediction(s, s->fragment_start[1],\n                              s->fragment_width[1], s->fragment_height[1]);\n        reverse_dc_prediction(s, s->fragment_start[2],\n                              s->fragment_width[1], s->fragment_height[1]);\n    }\n\n    if (get_bits_left(gb) < 8)\n        return AVERROR_INVALIDDATA;\n    /* fetch the AC table indexes */\n    ac_y_table = get_bits(gb, 4);\n    ac_c_table = get_bits(gb, 4);\n\n    /* build tables of AC VLC tables */\n    for (i = 1; i <= 5; i++) {\n        /* AC VLC table group 1 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 16];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 16];\n    }\n    for (i = 6; i <= 14; i++) {\n        /* AC VLC table group 2 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 32];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 32];\n    }\n    for (i = 15; i <= 27; i++) {\n        /* AC VLC table group 3 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 48];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 48];\n    }\n    for (i = 28; i <= 63; i++) {\n        /* AC VLC table group 4 */\n        y_tables[i] = &s->coeff_vlc[ac_y_table + 64];\n        c_tables[i] = &s->coeff_vlc[ac_c_table + 64];\n    }\n\n    /* decode all AC coefficients */\n    for (i = 1; i <= 63; i++) {\n        residual_eob_run = unpack_vlcs(s, gb, y_tables[i], i,\n                                       0, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n\n        residual_eob_run = unpack_vlcs(s, gb, c_tables[i], i,\n                                       1, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n        residual_eob_run = unpack_vlcs(s, gb, c_tables[i], i,\n                                       2, residual_eob_run);\n        if (residual_eob_run < 0)\n            return residual_eob_run;\n    }\n\n    return 0;\n}\n\n#if CONFIG_VP4_DECODER\n/**\n * eob_tracker[] is instead of TOKEN_EOB(value)\n * a dummy TOKEN_EOB(0) value is used to make vp3_dequant work\n *\n * @return < 0 on error\n */\nstatic int vp4_unpack_vlcs(Vp3DecodeContext *s, GetBitContext *gb,\n                       VLC *vlc_tables[64],\n                       int plane, int eob_tracker[64], int fragment)\n{\n    int token;\n    int zero_run  = 0;\n    int16_t coeff = 0;\n    int coeff_i = 0;\n    int eob_run;\n\n    while (!eob_tracker[coeff_i]) {\n        if (get_bits_left(gb) < 1)\n            return AVERROR_INVALIDDATA;\n\n        token = get_vlc2(gb, vlc_tables[coeff_i]->table, 11, 3);\n\n        /* use the token to get a zero run, a coefficient, and an eob run */\n        if ((unsigned) token <= 6U) {\n            eob_run = get_eob_run(gb, token);\n            *s->dct_tokens[plane][coeff_i]++ = TOKEN_EOB(0);\n            eob_tracker[coeff_i] = eob_run - 1;\n            return 0;\n        } else if (token >= 0) {\n            zero_run = get_coeff(gb, token, &coeff);\n\n            if (zero_run) {\n                if (coeff_i + zero_run > 64) {\n                    av_log(s->avctx, AV_LOG_DEBUG,\n                        \"Invalid zero run of %d with %d coeffs left\\n\",\n                        zero_run, 64 - coeff_i);\n                    zero_run = 64 - coeff_i;\n                }\n                *s->dct_tokens[plane][coeff_i]++ = TOKEN_ZERO_RUN(coeff, zero_run);\n                coeff_i += zero_run;\n            } else {\n                if (!coeff_i)\n                    s->all_fragments[fragment].dc = coeff;\n\n                *s->dct_tokens[plane][coeff_i]++ = TOKEN_COEFF(coeff);\n            }\n            coeff_i++;\n            if (coeff_i >= 64) /* > 64 occurs when there is a zero_run overflow */\n                return 0; /* stop */\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid token %d\\n\", token);\n            return -1;\n        }\n    }\n    *s->dct_tokens[plane][coeff_i]++ = TOKEN_EOB(0);\n    eob_tracker[coeff_i]--;\n    return 0;\n}\n\nstatic void vp4_dc_predictor_reset(VP4Predictor *p)\n{\n    p->dc = 0;\n    p->type = VP4_DC_UNDEFINED;\n}\n\nstatic void vp4_dc_pred_before(const Vp3DecodeContext *s, VP4Predictor dc_pred[6][6], int sb_x)\n{\n    int i, j;\n\n    for (i = 0; i < 4; i++)\n        dc_pred[0][i + 1] = s->dc_pred_row[sb_x * 4 + i];\n\n    for (j = 1; j < 5; j++)\n        for (i = 0; i < 4; i++)\n            vp4_dc_predictor_reset(&dc_pred[j][i + 1]);\n}\n\nstatic void vp4_dc_pred_after(Vp3DecodeContext *s, VP4Predictor dc_pred[6][6], int sb_x)\n{\n    int i;\n\n    for (i = 0; i < 4; i++)\n        s->dc_pred_row[sb_x * 4 + i] = dc_pred[4][i + 1];\n\n    for (i = 1; i < 5; i++)\n        dc_pred[i][0] = dc_pred[i][4];\n}\n\n/* note: dc_pred points to the current block */\nstatic int vp4_dc_pred(const Vp3DecodeContext *s, const VP4Predictor * dc_pred, const int * last_dc, int type, int plane)\n{\n    int count = 0;\n    int dc = 0;\n\n    if (dc_pred[-6].type == type) {\n        dc += dc_pred[-6].dc;\n        count++;\n    }\n\n    if (dc_pred[6].type == type) {\n        dc += dc_pred[6].dc;\n        count++;\n    }\n\n    if (count != 2 && dc_pred[-1].type == type) {\n        dc += dc_pred[-1].dc;\n        count++;\n    }\n\n    if (count != 2 && dc_pred[1].type == type) {\n        dc += dc_pred[1].dc;\n        count++;\n    }\n\n    /* using division instead of shift to correctly handle negative values */\n    return count == 2 ? dc / 2 : last_dc[type];\n}\n\nstatic void vp4_set_tokens_base(Vp3DecodeContext *s)\n{\n    int plane, i;\n    int16_t *base = s->dct_tokens_base;\n    for (plane = 0; plane < 3; plane++) {\n        for (i = 0; i < 64; i++) {\n            s->dct_tokens[plane][i] = base;\n            base += s->fragment_width[!!plane] * s->fragment_height[!!plane];\n        }\n    }\n}\n\nstatic int vp4_unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n{\n    int i, j;\n    int dc_y_table;\n    int dc_c_table;\n    int ac_y_table;\n    int ac_c_table;\n    VLC *tables[2][64];\n    int plane, sb_y, sb_x;\n    int eob_tracker[64];\n    VP4Predictor dc_pred[6][6];\n    int last_dc[NB_VP4_DC_TYPES];\n\n    if (get_bits_left(gb) < 16)\n        return AVERROR_INVALIDDATA;\n\n    /* fetch the DC table indexes */\n    dc_y_table = get_bits(gb, 4);\n    dc_c_table = get_bits(gb, 4);\n\n    ac_y_table = get_bits(gb, 4);\n    ac_c_table = get_bits(gb, 4);\n\n    /* build tables of DC/AC VLC tables */\n\n    /* DC table group */\n    tables[0][0] = &s->coeff_vlc[dc_y_table];\n    tables[1][0] = &s->coeff_vlc[dc_c_table];\n    for (i = 1; i <= 5; i++) {\n        /* AC VLC table group 1 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 16];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 16];\n    }\n    for (i = 6; i <= 14; i++) {\n        /* AC VLC table group 2 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 32];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 32];\n    }\n    for (i = 15; i <= 27; i++) {\n        /* AC VLC table group 3 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 48];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 48];\n    }\n    for (i = 28; i <= 63; i++) {\n        /* AC VLC table group 4 */\n        tables[0][i] = &s->coeff_vlc[ac_y_table + 64];\n        tables[1][i] = &s->coeff_vlc[ac_c_table + 64];\n    }\n\n    vp4_set_tokens_base(s);\n\n    memset(last_dc, 0, sizeof(last_dc));\n\n    for (plane = 0; plane < ((s->avctx->flags & AV_CODEC_FLAG_GRAY) ? 1 : 3); plane++) {\n        memset(eob_tracker, 0, sizeof(eob_tracker));\n\n        /* initialise dc prediction */\n        for (i = 0; i < s->fragment_width[!!plane]; i++)\n            vp4_dc_predictor_reset(&s->dc_pred_row[i]);\n\n        for (j = 0; j < 6; j++)\n            for (i = 0; i < 6; i++)\n                vp4_dc_predictor_reset(&dc_pred[j][i]);\n\n        for (sb_y = 0; sb_y * 4 < s->fragment_height[!!plane]; sb_y++) {\n            for (sb_x = 0; sb_x *4 < s->fragment_width[!!plane]; sb_x++) {\n                vp4_dc_pred_before(s, dc_pred, sb_x);\n                for (j = 0; j < 16; j++) {\n                        int hx = hilbert_offset[j][0];\n                        int hy = hilbert_offset[j][1];\n                        int x  = 4 * sb_x + hx;\n                        int y  = 4 * sb_y + hy;\n                        VP4Predictor *this_dc_pred = &dc_pred[hy + 1][hx + 1];\n                        int fragment, dc_block_type;\n\n                        if (x >= s->fragment_width[!!plane] || y >= s->fragment_height[!!plane])\n                            continue;\n\n                        fragment = s->fragment_start[plane] + y * s->fragment_width[!!plane] + x;\n\n                        if (s->all_fragments[fragment].coding_method == MODE_COPY)\n                            continue;\n\n                        if (vp4_unpack_vlcs(s, gb, tables[!!plane], plane, eob_tracker, fragment) < 0)\n                            return -1;\n\n                        dc_block_type = vp4_pred_block_type_map[s->all_fragments[fragment].coding_method];\n\n                        s->all_fragments[fragment].dc +=\n                            vp4_dc_pred(s, this_dc_pred, last_dc, dc_block_type, plane);\n\n                        this_dc_pred->type = dc_block_type,\n                        this_dc_pred->dc   = last_dc[dc_block_type] = s->all_fragments[fragment].dc;\n                }\n                vp4_dc_pred_after(s, dc_pred, sb_x);\n            }\n        }\n    }\n\n    vp4_set_tokens_base(s);\n\n    return 0;\n}\n#endif\n\n/*\n * This function reverses the DC prediction for each coded fragment in\n * the frame. Much of this function is adapted directly from the original\n * VP3 source code.\n */\n#define COMPATIBLE_FRAME(x)                                                   \\\n    (compatible_frame[s->all_fragments[x].coding_method] == current_frame_type)\n#define DC_COEFF(u) s->all_fragments[u].dc\n\nstatic void reverse_dc_prediction(Vp3DecodeContext *s,\n                                  int first_fragment,\n                                  int fragment_width,\n                                  int fragment_height)\n{\n#define PUL 8\n#define PU 4\n#define PUR 2\n#define PL 1\n\n    int x, y;\n    int i = first_fragment;\n\n    int predicted_dc;\n\n    /* DC values for the left, up-left, up, and up-right fragments */\n    int vl, vul, vu, vur;\n\n    /* indexes for the left, up-left, up, and up-right fragments */\n    int l, ul, u, ur;\n\n    /*\n     * The 6 fields mean:\n     *   0: up-left multiplier\n     *   1: up multiplier\n     *   2: up-right multiplier\n     *   3: left multiplier\n     */\n    static const int predictor_transform[16][4] = {\n        {    0,   0,   0,   0 },\n        {    0,   0,   0, 128 }, // PL\n        {    0,   0, 128,   0 }, // PUR\n        {    0,   0,  53,  75 }, // PUR|PL\n        {    0, 128,   0,   0 }, // PU\n        {    0,  64,   0,  64 }, // PU |PL\n        {    0, 128,   0,   0 }, // PU |PUR\n        {    0,   0,  53,  75 }, // PU |PUR|PL\n        {  128,   0,   0,   0 }, // PUL\n        {    0,   0,   0, 128 }, // PUL|PL\n        {   64,   0,  64,   0 }, // PUL|PUR\n        {    0,   0,  53,  75 }, // PUL|PUR|PL\n        {    0, 128,   0,   0 }, // PUL|PU\n        { -104, 116,   0, 116 }, // PUL|PU |PL\n        {   24,  80,  24,   0 }, // PUL|PU |PUR\n        { -104, 116,   0, 116 }  // PUL|PU |PUR|PL\n    };\n\n    /* This table shows which types of blocks can use other blocks for\n     * prediction. For example, INTRA is the only mode in this table to\n     * have a frame number of 0. That means INTRA blocks can only predict\n     * from other INTRA blocks. There are 2 golden frame coding types;\n     * blocks encoding in these modes can only predict from other blocks\n     * that were encoded with these 1 of these 2 modes. */\n    static const unsigned char compatible_frame[9] = {\n        1,    /* MODE_INTER_NO_MV */\n        0,    /* MODE_INTRA */\n        1,    /* MODE_INTER_PLUS_MV */\n        1,    /* MODE_INTER_LAST_MV */\n        1,    /* MODE_INTER_PRIOR_MV */\n        2,    /* MODE_USING_GOLDEN */\n        2,    /* MODE_GOLDEN_MV */\n        1,    /* MODE_INTER_FOUR_MV */\n        3     /* MODE_COPY */\n    };\n    int current_frame_type;\n\n    /* there is a last DC predictor for each of the 3 frame types */\n    short last_dc[3];\n\n    int transform = 0;\n\n    vul =\n    vu  =\n    vur =\n    vl  = 0;\n    last_dc[0] =\n    last_dc[1] =\n    last_dc[2] = 0;\n\n    /* for each fragment row... */\n    for (y = 0; y < fragment_height; y++) {\n        /* for each fragment in a row... */\n        for (x = 0; x < fragment_width; x++, i++) {\n\n            /* reverse prediction if this block was coded */\n            if (s->all_fragments[i].coding_method != MODE_COPY) {\n                current_frame_type =\n                    compatible_frame[s->all_fragments[i].coding_method];\n\n                transform = 0;\n                if (x) {\n                    l  = i - 1;\n                    vl = DC_COEFF(l);\n                    if (COMPATIBLE_FRAME(l))\n                        transform |= PL;\n                }\n                if (y) {\n                    u  = i - fragment_width;\n                    vu = DC_COEFF(u);\n                    if (COMPATIBLE_FRAME(u))\n                        transform |= PU;\n                    if (x) {\n                        ul  = i - fragment_width - 1;\n                        vul = DC_COEFF(ul);\n                        if (COMPATIBLE_FRAME(ul))\n                            transform |= PUL;\n                    }\n                    if (x + 1 < fragment_width) {\n                        ur  = i - fragment_width + 1;\n                        vur = DC_COEFF(ur);\n                        if (COMPATIBLE_FRAME(ur))\n                            transform |= PUR;\n                    }\n                }\n\n                if (transform == 0) {\n                    /* if there were no fragments to predict from, use last\n                     * DC saved */\n                    predicted_dc = last_dc[current_frame_type];\n                } else {\n                    /* apply the appropriate predictor transform */\n                    predicted_dc =\n                        (predictor_transform[transform][0] * vul) +\n                        (predictor_transform[transform][1] * vu) +\n                        (predictor_transform[transform][2] * vur) +\n                        (predictor_transform[transform][3] * vl);\n\n                    predicted_dc /= 128;\n\n                    /* check for outranging on the [ul u l] and\n                     * [ul u ur l] predictors */\n                    if ((transform == 15) || (transform == 13)) {\n                        if (FFABS(predicted_dc - vu) > 128)\n                            predicted_dc = vu;\n                        else if (FFABS(predicted_dc - vl) > 128)\n                            predicted_dc = vl;\n                        else if (FFABS(predicted_dc - vul) > 128)\n                            predicted_dc = vul;\n                    }\n                }\n\n                /* at long last, apply the predictor */\n                DC_COEFF(i) += predicted_dc;\n                /* save the DC */\n                last_dc[current_frame_type] = DC_COEFF(i);\n            }\n        }\n    }\n}\n\nstatic void apply_loop_filter(Vp3DecodeContext *s, int plane,\n                              int ystart, int yend)\n{\n    int x, y;\n    int *bounding_values = s->bounding_values_array + 127;\n\n    int width           = s->fragment_width[!!plane];\n    int height          = s->fragment_height[!!plane];\n    int fragment        = s->fragment_start[plane] + ystart * width;\n    ptrdiff_t stride    = s->current_frame.f->linesize[plane];\n    uint8_t *plane_data = s->current_frame.f->data[plane];\n    if (!s->flipped_image)\n        stride = -stride;\n    plane_data += s->data_offset[plane] + 8 * ystart * stride;\n\n    for (y = ystart; y < yend; y++) {\n        for (x = 0; x < width; x++) {\n            /* This code basically just deblocks on the edges of coded blocks.\n             * However, it has to be much more complicated because of the\n             * brain damaged deblock ordering used in VP3/Theora. Order matters\n             * because some pixels get filtered twice. */\n            if (s->all_fragments[fragment].coding_method != MODE_COPY) {\n                /* do not perform left edge filter for left columns frags */\n                if (x > 0) {\n                    s->vp3dsp.h_loop_filter(\n                        plane_data + 8 * x,\n                        stride, bounding_values);\n                }\n\n                /* do not perform top edge filter for top row fragments */\n                if (y > 0) {\n                    s->vp3dsp.v_loop_filter(\n                        plane_data + 8 * x,\n                        stride, bounding_values);\n                }\n\n                /* do not perform right edge filter for right column\n                 * fragments or if right fragment neighbor is also coded\n                 * in this frame (it will be filtered in next iteration) */\n                if ((x < width - 1) &&\n                    (s->all_fragments[fragment + 1].coding_method == MODE_COPY)) {\n                    s->vp3dsp.h_loop_filter(\n                        plane_data + 8 * x + 8,\n                        stride, bounding_values);\n                }\n\n                /* do not perform bottom edge filter for bottom row\n                 * fragments or if bottom fragment neighbor is also coded\n                 * in this frame (it will be filtered in the next row) */\n                if ((y < height - 1) &&\n                    (s->all_fragments[fragment + width].coding_method == MODE_COPY)) {\n                    s->vp3dsp.v_loop_filter(\n                        plane_data + 8 * x + 8 * stride,\n                        stride, bounding_values);\n                }\n            }\n\n            fragment++;\n        }\n        plane_data += 8 * stride;\n    }\n}\n\n/**\n * Pull DCT tokens from the 64 levels to decode and dequant the coefficients\n * for the next block in coding order\n */\nstatic inline int vp3_dequant(Vp3DecodeContext *s, Vp3Fragment *frag,\n                              int plane, int inter, int16_t block[64])\n{\n    int16_t *dequantizer = s->qmat[frag->qpi][inter][plane];\n    uint8_t *perm = s->idct_scantable;\n    int i = 0;\n\n    do {\n        int token = *s->dct_tokens[plane][i];\n        switch (token & 3) {\n        case 0: // EOB\n            if (--token < 4) // 0-3 are token types so the EOB run must now be 0\n                s->dct_tokens[plane][i]++;\n            else\n                *s->dct_tokens[plane][i] = token & ~3;\n            goto end;\n        case 1: // zero run\n            s->dct_tokens[plane][i]++;\n            i += (token >> 2) & 0x7f;\n            if (i > 63) {\n                av_log(s->avctx, AV_LOG_ERROR, \"Coefficient index overflow\\n\");\n                return i;\n            }\n            block[perm[i]] = (token >> 9) * dequantizer[perm[i]];\n            i++;\n            break;\n        case 2: // coeff\n            block[perm[i]] = (token >> 2) * dequantizer[perm[i]];\n            s->dct_tokens[plane][i++]++;\n            break;\n        default: // shouldn't happen\n            return i;\n        }\n    } while (i < 64);\n    // return value is expected to be a valid level\n    i--;\nend:\n    // the actual DC+prediction is in the fragment structure\n    block[0] = frag->dc * s->qmat[0][inter][plane][0];\n    return i;\n}\n\n/**\n * called when all pixels up to row y are complete\n */\nstatic void vp3_draw_horiz_band(Vp3DecodeContext *s, int y)\n{\n    int h, cy, i;\n    int offset[AV_NUM_DATA_POINTERS];\n\n    if (HAVE_THREADS && s->avctx->active_thread_type & FF_THREAD_FRAME) {\n        int y_flipped = s->flipped_image ? s->height - y : y;\n\n        /* At the end of the frame, report INT_MAX instead of the height of\n         * the frame. This makes the other threads' ff_thread_await_progress()\n         * calls cheaper, because they don't have to clip their values. */\n        ff_thread_report_progress(&s->current_frame,\n                                  y_flipped == s->height ? INT_MAX\n                                                         : y_flipped - 1,\n                                  0);\n    }\n\n    if (!s->avctx->draw_horiz_band)\n        return;\n\n    h = y - s->last_slice_end;\n    s->last_slice_end = y;\n    y -= h;\n\n    if (!s->flipped_image)\n        y = s->height - y - h;\n\n    cy        = y >> s->chroma_y_shift;\n    offset[0] = s->current_frame.f->linesize[0] * y;\n    offset[1] = s->current_frame.f->linesize[1] * cy;\n    offset[2] = s->current_frame.f->linesize[2] * cy;\n    for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n        offset[i] = 0;\n\n    emms_c();\n    s->avctx->draw_horiz_band(s->avctx, s->current_frame.f, offset, y, 3, h);\n}\n\n/**\n * Wait for the reference frame of the current fragment.\n * The progress value is in luma pixel rows.\n */\nstatic void await_reference_row(Vp3DecodeContext *s, Vp3Fragment *fragment,\n                                int motion_y, int y)\n{\n    ThreadFrame *ref_frame;\n    int ref_row;\n    int border = motion_y & 1;\n\n    if (fragment->coding_method == MODE_USING_GOLDEN ||\n        fragment->coding_method == MODE_GOLDEN_MV)\n        ref_frame = &s->golden_frame;\n    else\n        ref_frame = &s->last_frame;\n\n    ref_row = y + (motion_y >> 1);\n    ref_row = FFMAX(FFABS(ref_row), ref_row + 8 + border);\n\n    ff_thread_await_progress(ref_frame, ref_row, 0);\n}\n\n#if CONFIG_VP4_DECODER\n/**\n * @return non-zero if temp (edge_emu_buffer) was populated\n */\nstatic int vp4_mc_loop_filter(Vp3DecodeContext *s, int plane, int motion_x, int motion_y, int bx, int by,\n       uint8_t * motion_source, int stride, int src_x, int src_y, uint8_t *temp)\n{\n    int motion_shift = plane ? 4 : 2;\n    int subpel_mask = plane ? 3 : 1;\n    int *bounding_values = s->bounding_values_array + 127;\n\n    int i;\n    int x, y;\n    int x2, y2;\n    int x_subpel, y_subpel;\n    int x_offset, y_offset;\n\n    int block_width = plane ? 8 : 16;\n    int plane_width  = s->width  >> (plane && s->chroma_x_shift);\n    int plane_height = s->height >> (plane && s->chroma_y_shift);\n\n#define loop_stride 12\n    uint8_t loop[12 * loop_stride];\n\n    /* using division instead of shift to correctly handle negative values */\n    x = 8 * bx + motion_x / motion_shift;\n    y = 8 * by + motion_y / motion_shift;\n\n    x_subpel = motion_x & subpel_mask;\n    y_subpel = motion_y & subpel_mask;\n\n    if (x_subpel || y_subpel) {\n        x--;\n        y--;\n\n        if (x_subpel)\n            x = FFMIN(x, x + FFSIGN(motion_x));\n\n        if (y_subpel)\n            y = FFMIN(y, y + FFSIGN(motion_y));\n\n        x2 = x + block_width;\n        y2 = y + block_width;\n\n        if (x2 < 0 || x2 >= plane_width || y2 < 0 || y2 >= plane_height)\n            return 0;\n\n        x_offset = (-(x + 2) & 7) + 2;\n        y_offset = (-(y + 2) & 7) + 2;\n\n        if (x_offset > 8 + x_subpel && y_offset > 8 + y_subpel)\n            return 0;\n\n        s->vdsp.emulated_edge_mc(loop, motion_source - stride - 1,\n             loop_stride, stride,\n             12, 12, src_x - 1, src_y - 1,\n             plane_width,\n             plane_height);\n\n        if (x_offset <= 8 + x_subpel)\n            ff_vp3dsp_h_loop_filter_12(loop + x_offset, loop_stride, bounding_values);\n\n        if (y_offset <= 8 + y_subpel)\n            ff_vp3dsp_v_loop_filter_12(loop + y_offset*loop_stride, loop_stride, bounding_values);\n\n    } else {\n\n        x_offset = -x & 7;\n        y_offset = -y & 7;\n\n        if (!x_offset && !y_offset)\n            return 0;\n\n        s->vdsp.emulated_edge_mc(loop, motion_source - stride - 1,\n             loop_stride, stride,\n             12, 12, src_x - 1, src_y - 1,\n             plane_width,\n             plane_height);\n\n#define safe_loop_filter(name, ptr, stride, bounding_values) \\\n    if ((uintptr_t)(ptr) & 7) \\\n        s->vp3dsp.name##_unaligned(ptr, stride, bounding_values); \\\n    else \\\n        s->vp3dsp.name(ptr, stride, bounding_values);\n\n        if (x_offset)\n            safe_loop_filter(h_loop_filter, loop + loop_stride + x_offset + 1, loop_stride, bounding_values);\n\n        if (y_offset)\n            safe_loop_filter(v_loop_filter, loop + (y_offset + 1)*loop_stride + 1, loop_stride, bounding_values);\n    }\n\n    for (i = 0; i < 9; i++)\n        memcpy(temp + i*stride, loop + (i + 1) * loop_stride + 1, 9);\n\n    return 1;\n}\n#endif\n\n/*\n * Perform the final rendering for a particular slice of data.\n * The slice number ranges from 0..(c_superblock_height - 1).\n */\nstatic void render_slice(Vp3DecodeContext *s, int slice)\n{\n    int x, y, i, j, fragment;\n    int16_t *block = s->block;\n    int motion_x = 0xdeadbeef, motion_y = 0xdeadbeef;\n    int motion_halfpel_index;\n    uint8_t *motion_source;\n    int plane, first_pixel;\n\n    if (slice >= s->c_superblock_height)\n        return;\n\n    for (plane = 0; plane < 3; plane++) {\n        uint8_t *output_plane = s->current_frame.f->data[plane] +\n                                s->data_offset[plane];\n        uint8_t *last_plane = s->last_frame.f->data[plane] +\n                              s->data_offset[plane];\n        uint8_t *golden_plane = s->golden_frame.f->data[plane] +\n                                s->data_offset[plane];\n        ptrdiff_t stride = s->current_frame.f->linesize[plane];\n        int plane_width  = s->width  >> (plane && s->chroma_x_shift);\n        int plane_height = s->height >> (plane && s->chroma_y_shift);\n        int8_t(*motion_val)[2] = s->motion_val[!!plane];\n\n        int sb_x, sb_y = slice << (!plane && s->chroma_y_shift);\n        int slice_height = sb_y + 1 + (!plane && s->chroma_y_shift);\n        int slice_width  = plane ? s->c_superblock_width\n                                 : s->y_superblock_width;\n\n        int fragment_width  = s->fragment_width[!!plane];\n        int fragment_height = s->fragment_height[!!plane];\n        int fragment_start  = s->fragment_start[plane];\n\n        int do_await = !plane && HAVE_THREADS &&\n                       (s->avctx->active_thread_type & FF_THREAD_FRAME);\n\n        if (!s->flipped_image)\n            stride = -stride;\n        if (CONFIG_GRAY && plane && (s->avctx->flags & AV_CODEC_FLAG_GRAY))\n            continue;\n\n        /* for each superblock row in the slice (both of them)... */\n        for (; sb_y < slice_height; sb_y++) {\n            /* for each superblock in a row... */\n            for (sb_x = 0; sb_x < slice_width; sb_x++) {\n                /* for each block in a superblock... */\n                for (j = 0; j < 16; j++) {\n                    x        = 4 * sb_x + hilbert_offset[j][0];\n                    y        = 4 * sb_y + hilbert_offset[j][1];\n                    fragment = y * fragment_width + x;\n\n                    i = fragment_start + fragment;\n\n                    // bounds check\n                    if (x >= fragment_width || y >= fragment_height)\n                        continue;\n\n                    first_pixel = 8 * y * stride + 8 * x;\n\n                    if (do_await &&\n                        s->all_fragments[i].coding_method != MODE_INTRA)\n                        await_reference_row(s, &s->all_fragments[i],\n                                            motion_val[fragment][1],\n                                            (16 * y) >> s->chroma_y_shift);\n\n                    /* transform if this block was coded */\n                    if (s->all_fragments[i].coding_method != MODE_COPY) {\n                        if ((s->all_fragments[i].coding_method == MODE_USING_GOLDEN) ||\n                            (s->all_fragments[i].coding_method == MODE_GOLDEN_MV))\n                            motion_source = golden_plane;\n                        else\n                            motion_source = last_plane;\n\n                        motion_source       += first_pixel;\n                        motion_halfpel_index = 0;\n\n                        /* sort out the motion vector if this fragment is coded\n                         * using a motion vector method */\n                        if ((s->all_fragments[i].coding_method > MODE_INTRA) &&\n                            (s->all_fragments[i].coding_method != MODE_USING_GOLDEN)) {\n                            int src_x, src_y;\n                            int standard_mc = 1;\n                            motion_x = motion_val[fragment][0];\n                            motion_y = motion_val[fragment][1];\n#if CONFIG_VP4_DECODER\n                            if (plane && s->version >= 2) {\n                                motion_x = (motion_x >> 1) | (motion_x & 1);\n                                motion_y = (motion_y >> 1) | (motion_y & 1);\n                            }\n#endif\n\n                            src_x = (motion_x >> 1) + 8 * x;\n                            src_y = (motion_y >> 1) + 8 * y;\n\n                            motion_halfpel_index = motion_x & 0x01;\n                            motion_source       += (motion_x >> 1);\n\n                            motion_halfpel_index |= (motion_y & 0x01) << 1;\n                            motion_source        += ((motion_y >> 1) * stride);\n\n#if CONFIG_VP4_DECODER\n                            if (s->version >= 2) {\n                                uint8_t *temp = s->edge_emu_buffer;\n                                if (stride < 0)\n                                    temp -= 8 * stride;\n                                if (vp4_mc_loop_filter(s, plane, motion_val[fragment][0], motion_val[fragment][1], x, y, motion_source, stride, src_x, src_y, temp)) {\n                                    motion_source = temp;\n                                    standard_mc = 0;\n                                }\n                            }\n#endif\n\n                            if (standard_mc && (\n                                src_x < 0 || src_y < 0 ||\n                                src_x + 9 >= plane_width ||\n                                src_y + 9 >= plane_height)) {\n                                uint8_t *temp = s->edge_emu_buffer;\n                                if (stride < 0)\n                                    temp -= 8 * stride;\n\n                                s->vdsp.emulated_edge_mc(temp, motion_source,\n                                                         stride, stride,\n                                                         9, 9, src_x, src_y,\n                                                         plane_width,\n                                                         plane_height);\n                                motion_source = temp;\n                            }\n                        }\n\n                        /* first, take care of copying a block from either the\n                         * previous or the golden frame */\n                        if (s->all_fragments[i].coding_method != MODE_INTRA) {\n                            /* Note, it is possible to implement all MC cases\n                             * with put_no_rnd_pixels_l2 which would look more\n                             * like the VP3 source but this would be slower as\n                             * put_no_rnd_pixels_tab is better optimized */\n                            if (motion_halfpel_index != 3) {\n                                s->hdsp.put_no_rnd_pixels_tab[1][motion_halfpel_index](\n                                    output_plane + first_pixel,\n                                    motion_source, stride, 8);\n                            } else {\n                                /* d is 0 if motion_x and _y have the same sign,\n                                 * else -1 */\n                                int d = (motion_x ^ motion_y) >> 31;\n                                s->vp3dsp.put_no_rnd_pixels_l2(output_plane + first_pixel,\n                                                               motion_source - d,\n                                                               motion_source + stride + 1 + d,\n                                                               stride, 8);\n                            }\n                        }\n\n                        /* invert DCT and place (or add) in final output */\n\n                        if (s->all_fragments[i].coding_method == MODE_INTRA) {\n                            vp3_dequant(s, s->all_fragments + i,\n                                        plane, 0, block);\n                            s->vp3dsp.idct_put(output_plane + first_pixel,\n                                               stride,\n                                               block);\n                        } else {\n                            if (vp3_dequant(s, s->all_fragments + i,\n                                            plane, 1, block)) {\n                                s->vp3dsp.idct_add(output_plane + first_pixel,\n                                                   stride,\n                                                   block);\n                            } else {\n                                s->vp3dsp.idct_dc_add(output_plane + first_pixel,\n                                                      stride, block);\n                            }\n                        }\n                    } else {\n                        /* copy directly from the previous frame */\n                        s->hdsp.put_pixels_tab[1][0](\n                            output_plane + first_pixel,\n                            last_plane + first_pixel,\n                            stride, 8);\n                    }\n                }\n            }\n\n            // Filter up to the last row in the superblock row\n            if (s->version < 2 && !s->skip_loop_filter)\n                apply_loop_filter(s, plane, 4 * sb_y - !!sb_y,\n                                  FFMIN(4 * sb_y + 3, fragment_height - 1));\n        }\n    }\n\n    /* this looks like a good place for slice dispatch... */\n    /* algorithm:\n     *   if (slice == s->macroblock_height - 1)\n     *     dispatch (both last slice & 2nd-to-last slice);\n     *   else if (slice > 0)\n     *     dispatch (slice - 1);\n     */\n\n    vp3_draw_horiz_band(s, FFMIN((32 << s->chroma_y_shift) * (slice + 1) - 16,\n                                 s->height - 16));\n}\n\n/// Allocate tables for per-frame data in Vp3DecodeContext\nstatic av_cold int allocate_tables(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int y_fragment_count, c_fragment_count;\n\n    free_tables(avctx);\n\n    y_fragment_count = s->fragment_width[0] * s->fragment_height[0];\n    c_fragment_count = s->fragment_width[1] * s->fragment_height[1];\n\n    /* superblock_coding is used by unpack_superblocks (VP3/Theora) and vp4_unpack_macroblocks (VP4) */\n    s->superblock_coding = av_mallocz(FFMAX(s->superblock_count, s->yuv_macroblock_count));\n    s->all_fragments     = av_calloc(s->fragment_count, sizeof(*s->all_fragments));\n\n    s-> kf_coded_fragment_list = av_calloc(s->fragment_count, sizeof(int));\n    s->nkf_coded_fragment_list = av_calloc(s->fragment_count, sizeof(int));\n    memset(s-> num_kf_coded_fragment, -1, sizeof(s-> num_kf_coded_fragment));\n\n    s->dct_tokens_base = av_calloc(s->fragment_count,\n                                   64 * sizeof(*s->dct_tokens_base));\n    s->motion_val[0] = av_calloc(y_fragment_count, sizeof(*s->motion_val[0]));\n    s->motion_val[1] = av_calloc(c_fragment_count, sizeof(*s->motion_val[1]));\n\n    /* work out the block mapping tables */\n    s->superblock_fragments = av_calloc(s->superblock_count, 16 * sizeof(int));\n    s->macroblock_coding    = av_mallocz(s->macroblock_count + 1);\n\n    s->dc_pred_row = av_malloc_array(s->y_superblock_width * 4, sizeof(*s->dc_pred_row));\n\n    if (!s->superblock_coding    || !s->all_fragments          ||\n        !s->dct_tokens_base      || !s->kf_coded_fragment_list ||\n        !s->nkf_coded_fragment_list ||\n        !s->superblock_fragments || !s->macroblock_coding      ||\n        !s->dc_pred_row ||\n        !s->motion_val[0]        || !s->motion_val[1]) {\n        return -1;\n    }\n\n    init_block_mapping(s);\n\n    return 0;\n}\n\nstatic av_cold int init_frames(Vp3DecodeContext *s)\n{\n    s->current_frame.f = av_frame_alloc();\n    s->last_frame.f    = av_frame_alloc();\n    s->golden_frame.f  = av_frame_alloc();\n\n    if (!s->current_frame.f || !s->last_frame.f || !s->golden_frame.f)\n        return AVERROR(ENOMEM);\n\n    return 0;\n}\n\nstatic av_cold int vp3_decode_init(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, inter, plane, ret;\n    int c_width;\n    int c_height;\n    int y_fragment_count, c_fragment_count;\n#if CONFIG_VP4_DECODER\n    int j;\n#endif\n\n    ret = init_frames(s);\n    if (ret < 0)\n        return ret;\n\n    if (avctx->codec_tag == MKTAG('V', 'P', '4', '0')) {\n        s->version = 3;\n#if !CONFIG_VP4_DECODER\n        av_log(avctx, AV_LOG_ERROR, \"This build does not support decoding VP4.\\n\");\n        return AVERROR_DECODER_NOT_FOUND;\n#endif\n    } else if (avctx->codec_tag == MKTAG('V', 'P', '3', '0'))\n        s->version = 0;\n    else\n        s->version = 1;\n\n    s->avctx  = avctx;\n    s->width  = FFALIGN(avctx->coded_width, 16);\n    s->height = FFALIGN(avctx->coded_height, 16);\n    if (avctx->codec_id != AV_CODEC_ID_THEORA)\n        avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n    avctx->chroma_sample_location = AVCHROMA_LOC_CENTER;\n    ff_hpeldsp_init(&s->hdsp, avctx->flags | AV_CODEC_FLAG_BITEXACT);\n    ff_videodsp_init(&s->vdsp, 8);\n    ff_vp3dsp_init(&s->vp3dsp, avctx->flags);\n\n    for (i = 0; i < 64; i++) {\n#define TRANSPOSE(x) (((x) >> 3) | (((x) & 7) << 3))\n        s->idct_permutation[i] = TRANSPOSE(i);\n        s->idct_scantable[i]   = TRANSPOSE(ff_zigzag_direct[i]);\n#undef TRANSPOSE\n    }\n\n    /* initialize to an impossible value which will force a recalculation\n     * in the first frame decode */\n    for (i = 0; i < 3; i++)\n        s->qps[i] = -1;\n\n    ret = av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n    if (ret)\n        return ret;\n\n    s->y_superblock_width  = (s->width  + 31) / 32;\n    s->y_superblock_height = (s->height + 31) / 32;\n    s->y_superblock_count  = s->y_superblock_width * s->y_superblock_height;\n\n    /* work out the dimensions for the C planes */\n    c_width                = s->width >> s->chroma_x_shift;\n    c_height               = s->height >> s->chroma_y_shift;\n    s->c_superblock_width  = (c_width  + 31) / 32;\n    s->c_superblock_height = (c_height + 31) / 32;\n    s->c_superblock_count  = s->c_superblock_width * s->c_superblock_height;\n\n    s->superblock_count   = s->y_superblock_count + (s->c_superblock_count * 2);\n    s->u_superblock_start = s->y_superblock_count;\n    s->v_superblock_start = s->u_superblock_start + s->c_superblock_count;\n\n    s->macroblock_width  = (s->width  + 15) / 16;\n    s->macroblock_height = (s->height + 15) / 16;\n    s->macroblock_count  = s->macroblock_width * s->macroblock_height;\n    s->c_macroblock_width  = (c_width  + 15) / 16;\n    s->c_macroblock_height = (c_height + 15) / 16;\n    s->c_macroblock_count  = s->c_macroblock_width * s->c_macroblock_height;\n    s->yuv_macroblock_count = s->macroblock_count + 2 * s->c_macroblock_count;\n\n    s->fragment_width[0]  = s->width / FRAGMENT_PIXELS;\n    s->fragment_height[0] = s->height / FRAGMENT_PIXELS;\n    s->fragment_width[1]  = s->fragment_width[0] >> s->chroma_x_shift;\n    s->fragment_height[1] = s->fragment_height[0] >> s->chroma_y_shift;\n\n    /* fragment count covers all 8x8 blocks for all 3 planes */\n    y_fragment_count     = s->fragment_width[0] * s->fragment_height[0];\n    c_fragment_count     = s->fragment_width[1] * s->fragment_height[1];\n    s->fragment_count    = y_fragment_count + 2 * c_fragment_count;\n    s->fragment_start[1] = y_fragment_count;\n    s->fragment_start[2] = y_fragment_count + c_fragment_count;\n\n    if (!s->theora_tables) {\n        const uint8_t (*bias_tabs)[32][2];\n\n        for (i = 0; i < 64; i++) {\n            s->coded_dc_scale_factor[0][i] = s->version < 2 ? vp31_dc_scale_factor[i] : vp4_y_dc_scale_factor[i];\n            s->coded_dc_scale_factor[1][i] = s->version < 2 ? vp31_dc_scale_factor[i] : vp4_uv_dc_scale_factor[i];\n            s->coded_ac_scale_factor[i] = s->version < 2 ? vp31_ac_scale_factor[i] : vp4_ac_scale_factor[i];\n            s->base_matrix[0][i]        = s->version < 2 ? vp31_intra_y_dequant[i] : vp4_generic_dequant[i];\n            s->base_matrix[1][i]        = s->version < 2 ? vp31_intra_c_dequant[i] : vp4_generic_dequant[i];\n            s->base_matrix[2][i]        = s->version < 2 ? vp31_inter_dequant[i]   : vp4_generic_dequant[i];\n            s->filter_limit_values[i]   = s->version < 2 ? vp31_filter_limit_values[i] : vp4_filter_limit_values[i];\n        }\n\n        for (inter = 0; inter < 2; inter++) {\n            for (plane = 0; plane < 3; plane++) {\n                s->qr_count[inter][plane]   = 1;\n                s->qr_size[inter][plane][0] = 63;\n                s->qr_base[inter][plane][0] =\n                s->qr_base[inter][plane][1] = 2 * inter + (!!plane) * !inter;\n            }\n        }\n\n        /* init VLC tables */\n        bias_tabs = CONFIG_VP4_DECODER && s->version >= 2 ? vp4_bias : vp3_bias;\n        for (int i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++) {\n            ret = ff_init_vlc_from_lengths(&s->coeff_vlc[i], 11, 32,\n                                           &bias_tabs[i][0][1], 2,\n                                           &bias_tabs[i][0][0], 2, 1,\n                                           0, 0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n    } else {\n        for (i = 0; i < FF_ARRAY_ELEMS(s->coeff_vlc); i++) {\n            const HuffTable *tab = &s->huffman_table[i];\n\n            ret = ff_init_vlc_from_lengths(&s->coeff_vlc[i], 11, tab->nb_entries,\n                                           &tab->entries[0].len, sizeof(*tab->entries),\n                                           &tab->entries[0].sym, sizeof(*tab->entries), 1,\n                                           0, 0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    ret = ff_init_vlc_from_lengths(&s->superblock_run_length_vlc, SUPERBLOCK_VLC_BITS, 34,\n                                   superblock_run_length_vlc_lens, 1,\n                                   NULL, 0, 0, 1, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->fragment_run_length_vlc, 5, 30,\n                                   fragment_run_length_vlc_len, 1,\n                                   NULL, 0, 0, 0, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->mode_code_vlc, 3, 8,\n                                   mode_code_vlc_len, 1,\n                                   NULL, 0, 0, 0, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n    ret = ff_init_vlc_from_lengths(&s->motion_vector_vlc, VP3_MV_VLC_BITS, 63,\n                                   &motion_vector_vlc_table[0][1], 2,\n                                   &motion_vector_vlc_table[0][0], 2, 1,\n                                   -31, 0, avctx);\n    if (ret < 0)\n        return ret;\n\n#if CONFIG_VP4_DECODER\n    for (j = 0; j < 2; j++)\n        for (i = 0; i < 7; i++) {\n            ret = ff_init_vlc_from_lengths(&s->vp4_mv_vlc[j][i], VP4_MV_VLC_BITS, 63,\n                                           &vp4_mv_vlc[j][i][0][1], 2,\n                                           &vp4_mv_vlc[j][i][0][0], 2, 1, -31,\n                                           0, avctx);\n            if (ret < 0)\n                return ret;\n        }\n\n    /* version >= 2 */\n    for (i = 0; i < 2; i++)\n        if ((ret = init_vlc(&s->block_pattern_vlc[i], 3, 14,\n                            &vp4_block_pattern_vlc[i][0][1], 2, 1,\n                            &vp4_block_pattern_vlc[i][0][0], 2, 1, 0)) < 0)\n            return ret;\n#endif\n\n    return allocate_tables(avctx);\n}\n\n/// Release and shuffle frames after decode finishes\nstatic int update_frames(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int ret = 0;\n\n    /* shuffle frames (last = current) */\n    ff_thread_release_ext_buffer(avctx, &s->last_frame);\n    ret = ff_thread_ref_frame(&s->last_frame, &s->current_frame);\n    if (ret < 0)\n        goto fail;\n\n    if (s->keyframe) {\n        ff_thread_release_ext_buffer(avctx, &s->golden_frame);\n        ret = ff_thread_ref_frame(&s->golden_frame, &s->current_frame);\n    }\n\nfail:\n    ff_thread_release_ext_buffer(avctx, &s->current_frame);\n    return ret;\n}\n\n#if HAVE_THREADS\nstatic int ref_frame(Vp3DecodeContext *s, ThreadFrame *dst, ThreadFrame *src)\n{\n    ff_thread_release_ext_buffer(s->avctx, dst);\n    if (src->f->data[0])\n        return ff_thread_ref_frame(dst, src);\n    return 0;\n}\n\nstatic int ref_frames(Vp3DecodeContext *dst, Vp3DecodeContext *src)\n{\n    int ret;\n    if ((ret = ref_frame(dst, &dst->current_frame, &src->current_frame)) < 0 ||\n        (ret = ref_frame(dst, &dst->golden_frame,  &src->golden_frame)) < 0  ||\n        (ret = ref_frame(dst, &dst->last_frame,    &src->last_frame)) < 0)\n        return ret;\n    return 0;\n}\n\nstatic int vp3_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    Vp3DecodeContext *s = dst->priv_data, *s1 = src->priv_data;\n    int qps_changed = 0, i, err;\n\n    if (!s1->current_frame.f->data[0] ||\n        s->width != s1->width || s->height != s1->height) {\n        if (s != s1)\n            ref_frames(s, s1);\n        return -1;\n    }\n\n    if (s != s1) {\n        // copy previous frame data\n        if ((err = ref_frames(s, s1)) < 0)\n            return err;\n\n        s->keyframe = s1->keyframe;\n\n        // copy qscale data if necessary\n        for (i = 0; i < 3; i++) {\n            if (s->qps[i] != s1->qps[1]) {\n                qps_changed = 1;\n                memcpy(&s->qmat[i], &s1->qmat[i], sizeof(s->qmat[i]));\n            }\n        }\n\n        if (s->qps[0] != s1->qps[0])\n            memcpy(&s->bounding_values_array, &s1->bounding_values_array,\n                   sizeof(s->bounding_values_array));\n\n        if (qps_changed) {\n            memcpy(s->qps,      s1->qps,      sizeof(s->qps));\n            memcpy(s->last_qps, s1->last_qps, sizeof(s->last_qps));\n            s->nqps = s1->nqps;\n        }\n    }\n\n    return update_frames(dst);\n}\n#endif\n\nstatic int vp3_decode_frame(AVCodecContext *avctx,\n                            void *data, int *got_frame,\n                            AVPacket *avpkt)\n{\n    AVFrame     *frame  = data;\n    const uint8_t *buf  = avpkt->data;\n    int buf_size        = avpkt->size;\n    Vp3DecodeContext *s = avctx->priv_data;\n    GetBitContext gb;\n    int i, ret;\n\n    if ((ret = init_get_bits8(&gb, buf, buf_size)) < 0)\n        return ret;\n\n#if CONFIG_THEORA_DECODER\n    if (s->theora && get_bits1(&gb)) {\n        int type = get_bits(&gb, 7);\n        skip_bits_long(&gb, 6*8); /* \"theora\" */\n\n        if (s->avctx->active_thread_type&FF_THREAD_FRAME) {\n            av_log(avctx, AV_LOG_ERROR, \"midstream reconfiguration with multithreading is unsupported, try -threads 1\\n\");\n            return AVERROR_PATCHWELCOME;\n        }\n        if (type == 0) {\n            vp3_decode_end(avctx);\n            ret = theora_decode_header(avctx, &gb);\n\n            if (ret >= 0)\n                ret = vp3_decode_init(avctx);\n            if (ret < 0) {\n                vp3_decode_end(avctx);\n                return ret;\n            }\n            return buf_size;\n        } else if (type == 2) {\n            vp3_decode_end(avctx);\n            ret = theora_decode_tables(avctx, &gb);\n            if (ret >= 0)\n                ret = vp3_decode_init(avctx);\n            if (ret < 0) {\n                vp3_decode_end(avctx);\n                return ret;\n            }\n            return buf_size;\n        }\n\n        av_log(avctx, AV_LOG_ERROR,\n               \"Header packet passed to frame decoder, skipping\\n\");\n        return -1;\n    }\n#endif\n\n    s->keyframe = !get_bits1(&gb);\n    if (!s->all_fragments) {\n        av_log(avctx, AV_LOG_ERROR, \"Data packet without prior valid headers\\n\");\n        return -1;\n    }\n    if (!s->theora)\n        skip_bits(&gb, 1);\n    for (i = 0; i < 3; i++)\n        s->last_qps[i] = s->qps[i];\n\n    s->nqps = 0;\n    do {\n        s->qps[s->nqps++] = get_bits(&gb, 6);\n    } while (s->theora >= 0x030200 && s->nqps < 3 && get_bits1(&gb));\n    for (i = s->nqps; i < 3; i++)\n        s->qps[i] = -1;\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(s->avctx, AV_LOG_INFO, \" VP3 %sframe #%d: Q index = %d\\n\",\n               s->keyframe ? \"key\" : \"\", avctx->frame_number + 1, s->qps[0]);\n\n    s->skip_loop_filter = !s->filter_limit_values[s->qps[0]] ||\n                          avctx->skip_loop_filter >= (s->keyframe ? AVDISCARD_ALL\n                                                                  : AVDISCARD_NONKEY);\n\n    if (s->qps[0] != s->last_qps[0])\n        init_loop_filter(s);\n\n    for (i = 0; i < s->nqps; i++)\n        // reinit all dequantizers if the first one changed, because\n        // the DC of the first quantizer must be used for all matrices\n        if (s->qps[i] != s->last_qps[i] || s->qps[0] != s->last_qps[0])\n            init_dequantizer(s, i);\n\n    if (avctx->skip_frame >= AVDISCARD_NONKEY && !s->keyframe)\n        return buf_size;\n\n    s->current_frame.f->pict_type = s->keyframe ? AV_PICTURE_TYPE_I\n                                                : AV_PICTURE_TYPE_P;\n    s->current_frame.f->key_frame = s->keyframe;\n    if ((ret = ff_thread_get_ext_buffer(avctx, &s->current_frame,\n                                        AV_GET_BUFFER_FLAG_REF)) < 0)\n        goto error;\n\n    if (!s->edge_emu_buffer) {\n        s->edge_emu_buffer = av_malloc(9 * FFABS(s->current_frame.f->linesize[0]));\n        if (!s->edge_emu_buffer) {\n            ret = AVERROR(ENOMEM);\n            goto error;\n        }\n    }\n\n    if (s->keyframe) {\n        if (!s->theora) {\n            skip_bits(&gb, 4); /* width code */\n            skip_bits(&gb, 4); /* height code */\n            if (s->version) {\n                int version = get_bits(&gb, 5);\n#if !CONFIG_VP4_DECODER\n                if (version >= 2) {\n                    av_log(avctx, AV_LOG_ERROR, \"This build does not support decoding VP4.\\n\");\n                    return AVERROR_DECODER_NOT_FOUND;\n                }\n#endif\n                s->version = version;\n                if (avctx->frame_number == 0)\n                    av_log(s->avctx, AV_LOG_DEBUG,\n                           \"VP version: %d\\n\", s->version);\n            }\n        }\n        if (s->version || s->theora) {\n            if (get_bits1(&gb))\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"Warning, unsupported keyframe coding type?!\\n\");\n            skip_bits(&gb, 2); /* reserved? */\n\n#if CONFIG_VP4_DECODER\n            if (s->version >= 2) {\n                int mb_height, mb_width;\n                int mb_width_mul, mb_width_div, mb_height_mul, mb_height_div;\n\n                mb_height = get_bits(&gb, 8);\n                mb_width  = get_bits(&gb, 8);\n                if (mb_height != s->macroblock_height ||\n                    mb_width != s->macroblock_width)\n                    avpriv_request_sample(s->avctx, \"macroblock dimension mismatch\");\n\n                mb_width_mul = get_bits(&gb, 5);\n                mb_width_div = get_bits(&gb, 3);\n                mb_height_mul = get_bits(&gb, 5);\n                mb_height_div = get_bits(&gb, 3);\n                if (mb_width_mul != 1 || mb_width_div != 1 || mb_height_mul != 1 || mb_height_div != 1)\n                    avpriv_request_sample(s->avctx, \"unexpected macroblock dimension multipler/divider\");\n\n                if (get_bits(&gb, 2))\n                    avpriv_request_sample(s->avctx, \"unknown bits\");\n            }\n#endif\n        }\n    } else {\n        if (!s->golden_frame.f->data[0]) {\n            av_log(s->avctx, AV_LOG_WARNING,\n                   \"vp3: first frame not a keyframe\\n\");\n\n            s->golden_frame.f->pict_type = AV_PICTURE_TYPE_I;\n            if ((ret = ff_thread_get_ext_buffer(avctx, &s->golden_frame,\n                                                AV_GET_BUFFER_FLAG_REF)) < 0)\n                goto error;\n            ff_thread_release_ext_buffer(avctx, &s->last_frame);\n            if ((ret = ff_thread_ref_frame(&s->last_frame,\n                                           &s->golden_frame)) < 0)\n                goto error;\n            ff_thread_report_progress(&s->last_frame, INT_MAX, 0);\n        }\n    }\n\n    memset(s->all_fragments, 0, s->fragment_count * sizeof(Vp3Fragment));\n    ff_thread_finish_setup(avctx);\n\n    if (s->version < 2) {\n        if ((ret = unpack_superblocks(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_superblocks\\n\");\n            goto error;\n        }\n#if CONFIG_VP4_DECODER\n    } else {\n        if ((ret = vp4_unpack_macroblocks(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in vp4_unpack_macroblocks\\n\");\n            goto error;\n    }\n#endif\n    }\n    if ((ret = unpack_modes(s, &gb)) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_modes\\n\");\n        goto error;\n    }\n    if (ret = unpack_vectors(s, &gb)) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_vectors\\n\");\n        goto error;\n    }\n    if ((ret = unpack_block_qpis(s, &gb)) < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_block_qpis\\n\");\n        goto error;\n    }\n\n    if (s->version < 2) {\n        if ((ret = unpack_dct_coeffs(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_dct_coeffs\\n\");\n            goto error;\n        }\n#if CONFIG_VP4_DECODER\n    } else {\n        if ((ret = vp4_unpack_dct_coeffs(s, &gb)) < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"error in vp4_unpack_dct_coeffs\\n\");\n            goto error;\n        }\n#endif\n    }\n\n    for (i = 0; i < 3; i++) {\n        int height = s->height >> (i && s->chroma_y_shift);\n        if (s->flipped_image)\n            s->data_offset[i] = 0;\n        else\n            s->data_offset[i] = (height - 1) * s->current_frame.f->linesize[i];\n    }\n\n    s->last_slice_end = 0;\n    for (i = 0; i < s->c_superblock_height; i++)\n        render_slice(s, i);\n\n    // filter the last row\n    if (s->version < 2)\n        for (i = 0; i < 3; i++) {\n            int row = (s->height >> (3 + (i && s->chroma_y_shift))) - 1;\n            apply_loop_filter(s, i, row, row + 1);\n        }\n    vp3_draw_horiz_band(s, s->height);\n\n    /* output frame, offset as needed */\n    if ((ret = av_frame_ref(data, s->current_frame.f)) < 0)\n        return ret;\n\n    frame->crop_left   = s->offset_x;\n    frame->crop_right  = avctx->coded_width - avctx->width - s->offset_x;\n    frame->crop_top    = s->offset_y;\n    frame->crop_bottom = avctx->coded_height - avctx->height - s->offset_y;\n\n    *got_frame = 1;\n\n    if (!HAVE_THREADS || !(s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n        ret = update_frames(avctx);\n        if (ret < 0)\n            return ret;\n    }\n\n    return buf_size;\n\nerror:\n    ff_thread_report_progress(&s->current_frame, INT_MAX, 0);\n\n    if (!HAVE_THREADS || !(s->avctx->active_thread_type & FF_THREAD_FRAME))\n        av_frame_unref(s->current_frame.f);\n\n    return ret;\n}\n\nstatic int read_huffman_tree(HuffTable *huff, GetBitContext *gb, int length,\n                             AVCodecContext *avctx)\n{\n    if (get_bits1(gb)) {\n        int token;\n        if (huff->nb_entries >= 32) { /* overflow */\n            av_log(avctx, AV_LOG_ERROR, \"huffman tree overflow\\n\");\n            return -1;\n        }\n        token = get_bits(gb, 5);\n        ff_dlog(avctx, \"code length %d, curr entry %d, token %d\\n\",\n                length, huff->nb_entries, token);\n        huff->entries[huff->nb_entries++] = (HuffEntry){ length, token };\n    } else {\n        /* The following bound follows from the fact that nb_entries <= 32. */\n        if (length >= 31) { /* overflow */\n            av_log(avctx, AV_LOG_ERROR, \"huffman tree overflow\\n\");\n            return -1;\n        }\n        length++;\n        if (read_huffman_tree(huff, gb, length, avctx))\n            return -1;\n        if (read_huffman_tree(huff, gb, length, avctx))\n            return -1;\n    }\n    return 0;\n}\n\n#if CONFIG_THEORA_DECODER\nstatic const enum AVPixelFormat theora_pix_fmts[4] = {\n    AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE, AV_PIX_FMT_YUV422P, AV_PIX_FMT_YUV444P\n};\n\nstatic int theora_decode_header(AVCodecContext *avctx, GetBitContext *gb)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int visible_width, visible_height, colorspace;\n    uint8_t offset_x = 0, offset_y = 0;\n    int ret;\n    AVRational fps, aspect;\n\n    if (get_bits_left(gb) < 206)\n        return AVERROR_INVALIDDATA;\n\n    s->theora_header = 0;\n    s->theora = get_bits(gb, 24);\n    av_log(avctx, AV_LOG_DEBUG, \"Theora bitstream version %X\\n\", s->theora);\n    if (!s->theora) {\n        s->theora = 1;\n        avpriv_request_sample(s->avctx, \"theora 0\");\n    }\n\n    /* 3.2.0 aka alpha3 has the same frame orientation as original vp3\n     * but previous versions have the image flipped relative to vp3 */\n    if (s->theora < 0x030200) {\n        s->flipped_image = 1;\n        av_log(avctx, AV_LOG_DEBUG,\n               \"Old (<alpha3) Theora bitstream, flipped image\\n\");\n    }\n\n    visible_width  =\n    s->width       = get_bits(gb, 16) << 4;\n    visible_height =\n    s->height      = get_bits(gb, 16) << 4;\n\n    if (s->theora >= 0x030200) {\n        visible_width  = get_bits(gb, 24);\n        visible_height = get_bits(gb, 24);\n\n        offset_x = get_bits(gb, 8); /* offset x */\n        offset_y = get_bits(gb, 8); /* offset y, from bottom */\n    }\n\n    /* sanity check */\n    if (av_image_check_size(visible_width, visible_height, 0, avctx) < 0 ||\n        visible_width  + offset_x > s->width ||\n        visible_height + offset_y > s->height) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Invalid frame dimensions - w:%d h:%d x:%d y:%d (%dx%d).\\n\",\n               visible_width, visible_height, offset_x, offset_y,\n               s->width, s->height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    fps.num = get_bits_long(gb, 32);\n    fps.den = get_bits_long(gb, 32);\n    if (fps.num && fps.den) {\n        if (fps.num < 0 || fps.den < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid framerate\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        av_reduce(&avctx->framerate.den, &avctx->framerate.num,\n                  fps.den, fps.num, 1 << 30);\n    }\n\n    aspect.num = get_bits(gb, 24);\n    aspect.den = get_bits(gb, 24);\n    if (aspect.num && aspect.den) {\n        av_reduce(&avctx->sample_aspect_ratio.num,\n                  &avctx->sample_aspect_ratio.den,\n                  aspect.num, aspect.den, 1 << 30);\n        ff_set_sar(avctx, avctx->sample_aspect_ratio);\n    }\n\n    if (s->theora < 0x030200)\n        skip_bits(gb, 5); /* keyframe frequency force */\n    colorspace = get_bits(gb, 8);\n    skip_bits(gb, 24); /* bitrate */\n\n    skip_bits(gb, 6); /* quality hint */\n\n    if (s->theora >= 0x030200) {\n        skip_bits(gb, 5); /* keyframe frequency force */\n        avctx->pix_fmt = theora_pix_fmts[get_bits(gb, 2)];\n        if (avctx->pix_fmt == AV_PIX_FMT_NONE) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid pixel format\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        skip_bits(gb, 3); /* reserved */\n    } else\n        avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    ret = ff_set_dimensions(avctx, s->width, s->height);\n    if (ret < 0)\n        return ret;\n    if (!(avctx->flags2 & AV_CODEC_FLAG2_IGNORE_CROP)) {\n        avctx->width  = visible_width;\n        avctx->height = visible_height;\n        // translate offsets from theora axis ([0,0] lower left)\n        // to normal axis ([0,0] upper left)\n        s->offset_x = offset_x;\n        s->offset_y = s->height - visible_height - offset_y;\n    }\n\n    if (colorspace == 1)\n        avctx->color_primaries = AVCOL_PRI_BT470M;\n    else if (colorspace == 2)\n        avctx->color_primaries = AVCOL_PRI_BT470BG;\n\n    if (colorspace == 1 || colorspace == 2) {\n        avctx->colorspace = AVCOL_SPC_BT470BG;\n        avctx->color_trc  = AVCOL_TRC_BT709;\n    }\n\n    s->theora_header = 1;\n    return 0;\n}\n\nstatic int theora_decode_tables(AVCodecContext *avctx, GetBitContext *gb)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    int i, n, matrices, inter, plane, ret;\n\n    if (!s->theora_header)\n        return AVERROR_INVALIDDATA;\n\n    if (s->theora >= 0x030200) {\n        n = get_bits(gb, 3);\n        /* loop filter limit values table */\n        if (n)\n            for (i = 0; i < 64; i++)\n                s->filter_limit_values[i] = get_bits(gb, n);\n    }\n\n    if (s->theora >= 0x030200)\n        n = get_bits(gb, 4) + 1;\n    else\n        n = 16;\n    /* quality threshold table */\n    for (i = 0; i < 64; i++)\n        s->coded_ac_scale_factor[i] = get_bits(gb, n);\n\n    if (s->theora >= 0x030200)\n        n = get_bits(gb, 4) + 1;\n    else\n        n = 16;\n    /* dc scale factor table */\n    for (i = 0; i < 64; i++)\n        s->coded_dc_scale_factor[0][i] =\n        s->coded_dc_scale_factor[1][i] = get_bits(gb, n);\n\n    if (s->theora >= 0x030200)\n        matrices = get_bits(gb, 9) + 1;\n    else\n        matrices = 3;\n\n    if (matrices > 384) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of base matrixes\\n\");\n        return -1;\n    }\n\n    for (n = 0; n < matrices; n++)\n        for (i = 0; i < 64; i++)\n            s->base_matrix[n][i] = get_bits(gb, 8);\n\n    for (inter = 0; inter <= 1; inter++) {\n        for (plane = 0; plane <= 2; plane++) {\n            int newqr = 1;\n            if (inter || plane > 0)\n                newqr = get_bits1(gb);\n            if (!newqr) {\n                int qtj, plj;\n                if (inter && get_bits1(gb)) {\n                    qtj = 0;\n                    plj = plane;\n                } else {\n                    qtj = (3 * inter + plane - 1) / 3;\n                    plj = (plane + 2) % 3;\n                }\n                s->qr_count[inter][plane] = s->qr_count[qtj][plj];\n                memcpy(s->qr_size[inter][plane], s->qr_size[qtj][plj],\n                       sizeof(s->qr_size[0][0]));\n                memcpy(s->qr_base[inter][plane], s->qr_base[qtj][plj],\n                       sizeof(s->qr_base[0][0]));\n            } else {\n                int qri = 0;\n                int qi  = 0;\n\n                for (;;) {\n                    i = get_bits(gb, av_log2(matrices - 1) + 1);\n                    if (i >= matrices) {\n                        av_log(avctx, AV_LOG_ERROR,\n                               \"invalid base matrix index\\n\");\n                        return -1;\n                    }\n                    s->qr_base[inter][plane][qri] = i;\n                    if (qi >= 63)\n                        break;\n                    i = get_bits(gb, av_log2(63 - qi) + 1) + 1;\n                    s->qr_size[inter][plane][qri++] = i;\n                    qi += i;\n                }\n\n                if (qi > 63) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid qi %d > 63\\n\", qi);\n                    return -1;\n                }\n                s->qr_count[inter][plane] = qri;\n            }\n        }\n    }\n\n    /* Huffman tables */\n    for (int i = 0; i < FF_ARRAY_ELEMS(s->huffman_table); i++) {\n        s->huffman_table[i].nb_entries = 0;\n        if ((ret = read_huffman_tree(&s->huffman_table[i], gb, 0, avctx)) < 0)\n            return ret;\n    }\n\n    s->theora_tables = 1;\n\n    return 0;\n}\n\nstatic av_cold int theora_decode_init(AVCodecContext *avctx)\n{\n    Vp3DecodeContext *s = avctx->priv_data;\n    GetBitContext gb;\n    int ptype;\n    const uint8_t *header_start[3];\n    int header_len[3];\n    int i;\n    int ret;\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    s->theora = 1;\n\n    if (!avctx->extradata_size) {\n        av_log(avctx, AV_LOG_ERROR, \"Missing extradata!\\n\");\n        return -1;\n    }\n\n    if (avpriv_split_xiph_headers(avctx->extradata, avctx->extradata_size,\n                                  42, header_start, header_len) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Corrupt extradata\\n\");\n        return -1;\n    }\n\n    for (i = 0; i < 3; i++) {\n        if (header_len[i] <= 0)\n            continue;\n        ret = init_get_bits8(&gb, header_start[i], header_len[i]);\n        if (ret < 0)\n            return ret;\n\n        ptype = get_bits(&gb, 8);\n\n        if (!(ptype & 0x80)) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid extradata!\\n\");\n//          return -1;\n        }\n\n        // FIXME: Check for this as well.\n        skip_bits_long(&gb, 6 * 8); /* \"theora\" */\n\n        switch (ptype) {\n        case 0x80:\n            if (theora_decode_header(avctx, &gb) < 0)\n                return -1;\n            break;\n        case 0x81:\n// FIXME: is this needed? it breaks sometimes\n//            theora_decode_comments(avctx, gb);\n            break;\n        case 0x82:\n            if (theora_decode_tables(avctx, &gb))\n                return -1;\n            break;\n        default:\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Unknown Theora config packet: %d\\n\", ptype & ~0x80);\n            break;\n        }\n        if (ptype != 0x81 && get_bits_left(&gb) >= 8U)\n            av_log(avctx, AV_LOG_WARNING,\n                   \"%d bits left in packet %X\\n\",\n                   get_bits_left(&gb), ptype);\n        if (s->theora < 0x030200)\n            break;\n    }\n\n    return vp3_decode_init(avctx);\n}\n\nconst AVCodec ff_theora_decoder = {\n    .name                  = \"theora\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"Theora\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_THEORA,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = theora_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_EXPORTS_CROPPING | FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n#endif\n\nconst AVCodec ff_vp3_decoder = {\n    .name                  = \"vp3\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP3\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP3,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = vp3_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n\n#if CONFIG_VP4_DECODER\nconst AVCodec ff_vp4_decoder = {\n    .name                  = \"vp4\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP4\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP4,\n    .priv_data_size        = sizeof(Vp3DecodeContext),\n    .init                  = vp3_decode_init,\n    .close                 = vp3_decode_end,\n    .decode                = vp3_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DRAW_HORIZ_BAND |\n                             AV_CODEC_CAP_FRAME_THREADS,\n    .flush                 = vp3_decode_flush,\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp3_update_thread_context),\n    .caps_internal         = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP |\n                             FF_CODEC_CAP_ALLOCATE_PROGRESS,\n};\n#endif\n"], "buggy_code_start_loc": [2682], "buggy_code_end_loc": [2683], "fixing_code_start_loc": [2682], "fixing_code_end_loc": [2689], "type": "CWE-476", "message": "An issue was discovered in the FFmpeg package, where vp3_decode_frame in libavcodec/vp3.c lacks check of the return value of av_malloc() and will cause a null pointer dereference, impacting availability.", "other": {"cve": {"id": "CVE-2022-3109", "sourceIdentifier": "secalert@redhat.com", "published": "2022-12-16T15:15:09.483", "lastModified": "2023-05-01T06:15:11.897", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "An issue was discovered in the FFmpeg package, where vp3_decode_frame in libavcodec/vp3.c lacks check of the return value of av_malloc() and will cause a null pointer dereference, impacting availability."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionEndExcluding": "5.1", "matchCriteriaId": "1729FAD7-CEEE-4DCC-9F09-E813995593C5"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=2153551", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/656cb0450aeb73b25d7d26980af342b37ac4c568", "source": "secalert@redhat.com", "tags": ["Patch"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/KOMB6WRUC55VWV25IKJTV22KARBUGWGQ/", "source": "secalert@redhat.com"}, {"url": "https://www.debian.org/security/2023/dsa-5394", "source": "secalert@redhat.com"}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/656cb0450aeb73b25d7d26980af342b37ac4c568"}}