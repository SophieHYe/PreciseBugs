{"buggy_code": ["/* cipher-gcm.c  - Generic Galois Counter Mode implementation\n * Copyright (C) 2013 Dmitry Eremin-Solenikov\n * Copyright (C) 2013, 2018-2019 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is part of Libgcrypt.\n *\n * Libgcrypt is free software; you can redistribute it and/or modify\n * it under the terms of the GNU Lesser general Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * Libgcrypt is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this program; if not, see <http://www.gnu.org/licenses/>.\n */\n\n#include <config.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n\n#include \"g10lib.h\"\n#include \"cipher.h\"\n#include \"bufhelp.h\"\n#include \"./cipher-internal.h\"\n\n\n#ifdef GCM_USE_INTEL_PCLMUL\nextern void _gcry_ghash_setup_intel_pclmul (gcry_cipher_hd_t c);\n\nextern unsigned int _gcry_ghash_intel_pclmul (gcry_cipher_hd_t c, byte *result,\n                                              const byte *buf, size_t nblocks);\n#endif\n\n#ifdef GCM_USE_ARM_PMULL\nextern void _gcry_ghash_setup_armv8_ce_pmull (void *gcm_key, void *gcm_table);\n\nextern unsigned int _gcry_ghash_armv8_ce_pmull (void *gcm_key, byte *result,\n                                                const byte *buf, size_t nblocks,\n                                                void *gcm_table);\n\nstatic void\nghash_setup_armv8_ce_pmull (gcry_cipher_hd_t c)\n{\n  _gcry_ghash_setup_armv8_ce_pmull(c->u_mode.gcm.u_ghash_key.key,\n                                   c->u_mode.gcm.gcm_table);\n}\n\nstatic unsigned int\nghash_armv8_ce_pmull (gcry_cipher_hd_t c, byte *result, const byte *buf,\n                      size_t nblocks)\n{\n  return _gcry_ghash_armv8_ce_pmull(c->u_mode.gcm.u_ghash_key.key, result, buf,\n                                    nblocks, c->u_mode.gcm.gcm_table);\n}\n#endif /* GCM_USE_ARM_PMULL */\n\n#ifdef GCM_USE_ARM_NEON\nextern void _gcry_ghash_setup_armv7_neon (void *gcm_key);\n\nextern unsigned int _gcry_ghash_armv7_neon (void *gcm_key, byte *result,\n\t\t\t\t\t    const byte *buf, size_t nblocks);\n\nstatic void\nghash_setup_armv7_neon (gcry_cipher_hd_t c)\n{\n  _gcry_ghash_setup_armv7_neon(c->u_mode.gcm.u_ghash_key.key);\n}\n\nstatic unsigned int\nghash_armv7_neon (gcry_cipher_hd_t c, byte *result, const byte *buf,\n\t\t  size_t nblocks)\n{\n  return _gcry_ghash_armv7_neon(c->u_mode.gcm.u_ghash_key.key, result, buf,\n\t\t\t\tnblocks);\n}\n#endif /* GCM_USE_ARM_NEON */\n\n\n#ifdef GCM_USE_TABLES\nstatic const u16 gcmR[256] = {\n  0x0000, 0x01c2, 0x0384, 0x0246, 0x0708, 0x06ca, 0x048c, 0x054e,\n  0x0e10, 0x0fd2, 0x0d94, 0x0c56, 0x0918, 0x08da, 0x0a9c, 0x0b5e,\n  0x1c20, 0x1de2, 0x1fa4, 0x1e66, 0x1b28, 0x1aea, 0x18ac, 0x196e,\n  0x1230, 0x13f2, 0x11b4, 0x1076, 0x1538, 0x14fa, 0x16bc, 0x177e,\n  0x3840, 0x3982, 0x3bc4, 0x3a06, 0x3f48, 0x3e8a, 0x3ccc, 0x3d0e,\n  0x3650, 0x3792, 0x35d4, 0x3416, 0x3158, 0x309a, 0x32dc, 0x331e,\n  0x2460, 0x25a2, 0x27e4, 0x2626, 0x2368, 0x22aa, 0x20ec, 0x212e,\n  0x2a70, 0x2bb2, 0x29f4, 0x2836, 0x2d78, 0x2cba, 0x2efc, 0x2f3e,\n  0x7080, 0x7142, 0x7304, 0x72c6, 0x7788, 0x764a, 0x740c, 0x75ce,\n  0x7e90, 0x7f52, 0x7d14, 0x7cd6, 0x7998, 0x785a, 0x7a1c, 0x7bde,\n  0x6ca0, 0x6d62, 0x6f24, 0x6ee6, 0x6ba8, 0x6a6a, 0x682c, 0x69ee,\n  0x62b0, 0x6372, 0x6134, 0x60f6, 0x65b8, 0x647a, 0x663c, 0x67fe,\n  0x48c0, 0x4902, 0x4b44, 0x4a86, 0x4fc8, 0x4e0a, 0x4c4c, 0x4d8e,\n  0x46d0, 0x4712, 0x4554, 0x4496, 0x41d8, 0x401a, 0x425c, 0x439e,\n  0x54e0, 0x5522, 0x5764, 0x56a6, 0x53e8, 0x522a, 0x506c, 0x51ae,\n  0x5af0, 0x5b32, 0x5974, 0x58b6, 0x5df8, 0x5c3a, 0x5e7c, 0x5fbe,\n  0xe100, 0xe0c2, 0xe284, 0xe346, 0xe608, 0xe7ca, 0xe58c, 0xe44e,\n  0xef10, 0xeed2, 0xec94, 0xed56, 0xe818, 0xe9da, 0xeb9c, 0xea5e,\n  0xfd20, 0xfce2, 0xfea4, 0xff66, 0xfa28, 0xfbea, 0xf9ac, 0xf86e,\n  0xf330, 0xf2f2, 0xf0b4, 0xf176, 0xf438, 0xf5fa, 0xf7bc, 0xf67e,\n  0xd940, 0xd882, 0xdac4, 0xdb06, 0xde48, 0xdf8a, 0xddcc, 0xdc0e,\n  0xd750, 0xd692, 0xd4d4, 0xd516, 0xd058, 0xd19a, 0xd3dc, 0xd21e,\n  0xc560, 0xc4a2, 0xc6e4, 0xc726, 0xc268, 0xc3aa, 0xc1ec, 0xc02e,\n  0xcb70, 0xcab2, 0xc8f4, 0xc936, 0xcc78, 0xcdba, 0xcffc, 0xce3e,\n  0x9180, 0x9042, 0x9204, 0x93c6, 0x9688, 0x974a, 0x950c, 0x94ce,\n  0x9f90, 0x9e52, 0x9c14, 0x9dd6, 0x9898, 0x995a, 0x9b1c, 0x9ade,\n  0x8da0, 0x8c62, 0x8e24, 0x8fe6, 0x8aa8, 0x8b6a, 0x892c, 0x88ee,\n  0x83b0, 0x8272, 0x8034, 0x81f6, 0x84b8, 0x857a, 0x873c, 0x86fe,\n  0xa9c0, 0xa802, 0xaa44, 0xab86, 0xaec8, 0xaf0a, 0xad4c, 0xac8e,\n  0xa7d0, 0xa612, 0xa454, 0xa596, 0xa0d8, 0xa11a, 0xa35c, 0xa29e,\n  0xb5e0, 0xb422, 0xb664, 0xb7a6, 0xb2e8, 0xb32a, 0xb16c, 0xb0ae,\n  0xbbf0, 0xba32, 0xb874, 0xb9b6, 0xbcf8, 0xbd3a, 0xbf7c, 0xbebe,\n};\n\nstatic inline\nvoid prefetch_table(const void *tab, size_t len)\n{\n  const volatile byte *vtab = tab;\n  size_t i;\n\n  for (i = 0; i < len; i += 8 * 32)\n    {\n      (void)vtab[i + 0 * 32];\n      (void)vtab[i + 1 * 32];\n      (void)vtab[i + 2 * 32];\n      (void)vtab[i + 3 * 32];\n      (void)vtab[i + 4 * 32];\n      (void)vtab[i + 5 * 32];\n      (void)vtab[i + 6 * 32];\n      (void)vtab[i + 7 * 32];\n    }\n\n  (void)vtab[len - 1];\n}\n\nstatic inline void\ndo_prefetch_tables (const void *gcmM, size_t gcmM_size)\n{\n  prefetch_table(gcmM, gcmM_size);\n  prefetch_table(gcmR, sizeof(gcmR));\n}\n\n#ifdef GCM_TABLES_USE_U64\nstatic void\nbshift (u64 * b0, u64 * b1)\n{\n  u64 t[2], mask;\n\n  t[0] = *b0;\n  t[1] = *b1;\n  mask = -(t[1] & 1) & 0xe1;\n  mask <<= 56;\n\n  *b1 = (t[1] >> 1) ^ (t[0] << 63);\n  *b0 = (t[0] >> 1) ^ mask;\n}\n\nstatic void\ndo_fillM (unsigned char *h, u64 *M)\n{\n  int i, j;\n\n  M[0 + 0] = 0;\n  M[0 + 16] = 0;\n\n  M[8 + 0] = buf_get_be64 (h + 0);\n  M[8 + 16] = buf_get_be64 (h + 8);\n\n  for (i = 4; i > 0; i /= 2)\n    {\n      M[i + 0] = M[2 * i + 0];\n      M[i + 16] = M[2 * i + 16];\n\n      bshift (&M[i], &M[i + 16]);\n    }\n\n  for (i = 2; i < 16; i *= 2)\n    for (j = 1; j < i; j++)\n      {\n        M[(i + j) + 0] = M[i + 0] ^ M[j + 0];\n        M[(i + j) + 16] = M[i + 16] ^ M[j + 16];\n      }\n\n  for (i = 0; i < 16; i++)\n    {\n      M[i + 32] = (M[i + 0] >> 4) ^ ((u64) gcmR[(M[i + 16] & 0xf) << 4] << 48);\n      M[i + 48] = (M[i + 16] >> 4) ^ (M[i + 0] << 60);\n    }\n}\n\nstatic inline unsigned int\ndo_ghash (unsigned char *result, const unsigned char *buf, const u64 *gcmM)\n{\n  u64 V[2];\n  u64 tmp[2];\n  const u64 *M;\n  u64 T;\n  u32 A;\n  int i;\n\n  cipher_block_xor (V, result, buf, 16);\n  V[0] = be_bswap64 (V[0]);\n  V[1] = be_bswap64 (V[1]);\n\n  /* First round can be manually tweaked based on fact that 'tmp' is zero. */\n  M = &gcmM[(V[1] & 0xf) + 32];\n  V[1] >>= 4;\n  tmp[0] = M[0];\n  tmp[1] = M[16];\n  tmp[0] ^= gcmM[(V[1] & 0xf) + 0];\n  tmp[1] ^= gcmM[(V[1] & 0xf) + 16];\n  V[1] >>= 4;\n\n  i = 6;\n  while (1)\n    {\n      M = &gcmM[(V[1] & 0xf) + 32];\n      V[1] >>= 4;\n\n      A = tmp[1] & 0xff;\n      T = tmp[0];\n      tmp[0] = (T >> 8) ^ ((u64) gcmR[A] << 48) ^ gcmM[(V[1] & 0xf) + 0];\n      tmp[1] = (T << 56) ^ (tmp[1] >> 8) ^ gcmM[(V[1] & 0xf) + 16];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[16];\n\n      if (i == 0)\n        break;\n\n      V[1] >>= 4;\n      --i;\n    }\n\n  i = 7;\n  while (1)\n    {\n      M = &gcmM[(V[0] & 0xf) + 32];\n      V[0] >>= 4;\n\n      A = tmp[1] & 0xff;\n      T = tmp[0];\n      tmp[0] = (T >> 8) ^ ((u64) gcmR[A] << 48) ^ gcmM[(V[0] & 0xf) + 0];\n      tmp[1] = (T << 56) ^ (tmp[1] >> 8) ^ gcmM[(V[0] & 0xf) + 16];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[16];\n\n      if (i == 0)\n        break;\n\n      V[0] >>= 4;\n      --i;\n    }\n\n  buf_put_be64 (result + 0, tmp[0]);\n  buf_put_be64 (result + 8, tmp[1]);\n\n  return (sizeof(V) + sizeof(T) + sizeof(tmp) +\n          sizeof(int)*2 + sizeof(void*)*5);\n}\n\n#else /*!GCM_TABLES_USE_U64*/\n\nstatic void\nbshift (u32 * M, int i)\n{\n  u32 t[4], mask;\n\n  t[0] = M[i * 4 + 0];\n  t[1] = M[i * 4 + 1];\n  t[2] = M[i * 4 + 2];\n  t[3] = M[i * 4 + 3];\n  mask = -(t[3] & 1) & 0xe1;\n\n  M[i * 4 + 3] = (t[3] >> 1) ^ (t[2] << 31);\n  M[i * 4 + 2] = (t[2] >> 1) ^ (t[1] << 31);\n  M[i * 4 + 1] = (t[1] >> 1) ^ (t[0] << 31);\n  M[i * 4 + 0] = (t[0] >> 1) ^ (mask << 24);\n}\n\nstatic void\ndo_fillM (unsigned char *h, u32 *M)\n{\n  int i, j;\n\n  M[0 * 4 + 0] = 0;\n  M[0 * 4 + 1] = 0;\n  M[0 * 4 + 2] = 0;\n  M[0 * 4 + 3] = 0;\n\n  M[8 * 4 + 0] = buf_get_be32 (h + 0);\n  M[8 * 4 + 1] = buf_get_be32 (h + 4);\n  M[8 * 4 + 2] = buf_get_be32 (h + 8);\n  M[8 * 4 + 3] = buf_get_be32 (h + 12);\n\n  for (i = 4; i > 0; i /= 2)\n    {\n      M[i * 4 + 0] = M[2 * i * 4 + 0];\n      M[i * 4 + 1] = M[2 * i * 4 + 1];\n      M[i * 4 + 2] = M[2 * i * 4 + 2];\n      M[i * 4 + 3] = M[2 * i * 4 + 3];\n\n      bshift (M, i);\n    }\n\n  for (i = 2; i < 16; i *= 2)\n    for (j = 1; j < i; j++)\n      {\n        M[(i + j) * 4 + 0] = M[i * 4 + 0] ^ M[j * 4 + 0];\n        M[(i + j) * 4 + 1] = M[i * 4 + 1] ^ M[j * 4 + 1];\n        M[(i + j) * 4 + 2] = M[i * 4 + 2] ^ M[j * 4 + 2];\n        M[(i + j) * 4 + 3] = M[i * 4 + 3] ^ M[j * 4 + 3];\n      }\n\n  for (i = 0; i < 4 * 16; i += 4)\n    {\n      M[i + 0 + 64] = (M[i + 0] >> 4)\n                      ^ ((u64) gcmR[(M[i + 3] << 4) & 0xf0] << 16);\n      M[i + 1 + 64] = (M[i + 1] >> 4) ^ (M[i + 0] << 28);\n      M[i + 2 + 64] = (M[i + 2] >> 4) ^ (M[i + 1] << 28);\n      M[i + 3 + 64] = (M[i + 3] >> 4) ^ (M[i + 2] << 28);\n    }\n}\n\nstatic inline unsigned int\ndo_ghash (unsigned char *result, const unsigned char *buf, const u32 *gcmM)\n{\n  byte V[16];\n  u32 tmp[4];\n  u32 v;\n  const u32 *M, *m;\n  u32 T[3];\n  int i;\n\n  cipher_block_xor (V, result, buf, 16); /* V is big-endian */\n\n  /* First round can be manually tweaked based on fact that 'tmp' is zero. */\n  i = 15;\n\n  v = V[i];\n  M = &gcmM[(v & 0xf) * 4 + 64];\n  v = (v & 0xf0) >> 4;\n  m = &gcmM[v * 4];\n  v = V[--i];\n\n  tmp[0] = M[0] ^ m[0];\n  tmp[1] = M[1] ^ m[1];\n  tmp[2] = M[2] ^ m[2];\n  tmp[3] = M[3] ^ m[3];\n\n  while (1)\n    {\n      M = &gcmM[(v & 0xf) * 4 + 64];\n      v = (v & 0xf0) >> 4;\n      m = &gcmM[v * 4];\n\n      T[0] = tmp[0];\n      T[1] = tmp[1];\n      T[2] = tmp[2];\n      tmp[0] = (T[0] >> 8) ^ ((u32) gcmR[tmp[3] & 0xff] << 16) ^ m[0];\n      tmp[1] = (T[0] << 24) ^ (tmp[1] >> 8) ^ m[1];\n      tmp[2] = (T[1] << 24) ^ (tmp[2] >> 8) ^ m[2];\n      tmp[3] = (T[2] << 24) ^ (tmp[3] >> 8) ^ m[3];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[1];\n      tmp[2] ^= M[2];\n      tmp[3] ^= M[3];\n\n      if (i == 0)\n        break;\n\n      v = V[--i];\n    }\n\n  buf_put_be32 (result + 0, tmp[0]);\n  buf_put_be32 (result + 4, tmp[1]);\n  buf_put_be32 (result + 8, tmp[2]);\n  buf_put_be32 (result + 12, tmp[3]);\n\n  return (sizeof(V) + sizeof(T) + sizeof(tmp) +\n          sizeof(int)*2 + sizeof(void*)*6);\n}\n#endif /*!GCM_TABLES_USE_U64*/\n\n#define fillM(c) \\\n  do_fillM (c->u_mode.gcm.u_ghash_key.key, c->u_mode.gcm.gcm_table)\n#define GHASH(c, result, buf) do_ghash (result, buf, c->u_mode.gcm.gcm_table)\n#define prefetch_tables(c) \\\n  do_prefetch_tables(c->u_mode.gcm.gcm_table, sizeof(c->u_mode.gcm.gcm_table))\n\n#else\n\nstatic unsigned long\nbshift (unsigned long *b)\n{\n  unsigned long c;\n  int i;\n  c = b[3] & 1;\n  for (i = 3; i > 0; i--)\n    {\n      b[i] = (b[i] >> 1) | (b[i - 1] << 31);\n    }\n  b[i] >>= 1;\n  return c;\n}\n\nstatic unsigned int\ndo_ghash (unsigned char *hsub, unsigned char *result, const unsigned char *buf)\n{\n  unsigned long V[4];\n  int i, j;\n  byte *p;\n\n#ifdef WORDS_BIGENDIAN\n  p = result;\n#else\n  unsigned long T[4];\n\n  cipher_block_xor (V, result, buf, 16);\n  for (i = 0; i < 4; i++)\n    {\n      V[i] = (V[i] & 0x00ff00ff) << 8 | (V[i] & 0xff00ff00) >> 8;\n      V[i] = (V[i] & 0x0000ffff) << 16 | (V[i] & 0xffff0000) >> 16;\n    }\n  p = (byte *) T;\n#endif\n\n  memset (p, 0, 16);\n\n  for (i = 0; i < 16; i++)\n    {\n      for (j = 0x80; j; j >>= 1)\n        {\n          if (hsub[i] & j)\n            cipher_block_xor (p, p, V, 16);\n          if (bshift (V))\n            V[0] ^= 0xe1000000;\n        }\n    }\n#ifndef WORDS_BIGENDIAN\n  for (i = 0, p = (byte *) T; i < 16; i += 4, p += 4)\n    {\n      result[i + 0] = p[3];\n      result[i + 1] = p[2];\n      result[i + 2] = p[1];\n      result[i + 3] = p[0];\n    }\n#endif\n\n  return (sizeof(V) + sizeof(T) + sizeof(int)*2 + sizeof(void*)*5);\n}\n\n#define fillM(c) do { } while (0)\n#define GHASH(c, result, buf) do_ghash (c->u_mode.gcm.u_ghash_key.key, result, buf)\n#define prefetch_tables(c) do {} while (0)\n\n#endif /* !GCM_USE_TABLES */\n\n\nstatic unsigned int\nghash_internal (gcry_cipher_hd_t c, byte *result, const byte *buf,\n                size_t nblocks)\n{\n  const unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  unsigned int burn = 0;\n\n  prefetch_tables (c);\n\n  while (nblocks)\n    {\n      burn = GHASH (c, result, buf);\n      buf += blocksize;\n      nblocks--;\n    }\n\n  return burn + (burn ? 5*sizeof(void*) : 0);\n}\n\n\nstatic void\nsetupM (gcry_cipher_hd_t c)\n{\n#if defined(GCM_USE_INTEL_PCLMUL) || defined(GCM_USE_ARM_PMULL)\n  unsigned int features = _gcry_get_hw_features ();\n#endif\n\n  if (0)\n    ;\n#ifdef GCM_USE_INTEL_PCLMUL\n  else if (features & HWF_INTEL_PCLMUL)\n    {\n      c->u_mode.gcm.ghash_fn = _gcry_ghash_intel_pclmul;\n      _gcry_ghash_setup_intel_pclmul (c);\n    }\n#endif\n#ifdef GCM_USE_ARM_PMULL\n  else if (features & HWF_ARM_PMULL)\n    {\n      c->u_mode.gcm.ghash_fn = ghash_armv8_ce_pmull;\n      ghash_setup_armv8_ce_pmull (c);\n    }\n#endif\n#ifdef GCM_USE_ARM_NEON\n  else if (features & HWF_ARM_NEON)\n    {\n      c->u_mode.gcm.ghash_fn = ghash_armv7_neon;\n      ghash_setup_armv7_neon (c);\n    }\n#endif\n  else\n    {\n      c->u_mode.gcm.ghash_fn = ghash_internal;\n      fillM (c);\n    }\n}\n\n\nstatic inline void\ngcm_bytecounter_add (u32 ctr[2], size_t add)\n{\n  if (sizeof(add) > sizeof(u32))\n    {\n      u32 high_add = ((add >> 31) >> 1) & 0xffffffff;\n      ctr[1] += high_add;\n    }\n\n  ctr[0] += add;\n  if (ctr[0] >= add)\n    return;\n  ++ctr[1];\n}\n\n\nstatic inline u32\ngcm_add32_be128 (byte *ctr, unsigned int add)\n{\n  /* 'ctr' must be aligned to four bytes. */\n  const unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  u32 *pval = (u32 *)(void *)(ctr + blocksize - sizeof(u32));\n  u32 val;\n\n  val = be_bswap32(*pval) + add;\n  *pval = be_bswap32(val);\n\n  return val; /* return result as host-endian value */\n}\n\n\nstatic inline int\ngcm_check_datalen (u32 ctr[2])\n{\n  /* len(plaintext) <= 2^39-256 bits == 2^36-32 bytes == 2^32-2 blocks */\n  if (ctr[1] > 0xfU)\n    return 0;\n  if (ctr[1] < 0xfU)\n    return 1;\n\n  if (ctr[0] <= 0xffffffe0U)\n    return 1;\n\n  return 0;\n}\n\n\nstatic inline int\ngcm_check_aadlen_or_ivlen (u32 ctr[2])\n{\n  /* len(aad/iv) <= 2^64-1 bits ~= 2^61-1 bytes */\n  if (ctr[1] > 0x1fffffffU)\n    return 0;\n  if (ctr[1] < 0x1fffffffU)\n    return 1;\n\n  if (ctr[0] <= 0xffffffffU)\n    return 1;\n\n  return 0;\n}\n\n\nstatic void\ndo_ghash_buf(gcry_cipher_hd_t c, byte *hash, const byte *buf,\n             size_t buflen, int do_padding)\n{\n  unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  unsigned int unused = c->u_mode.gcm.mac_unused;\n  ghash_fn_t ghash_fn = c->u_mode.gcm.ghash_fn;\n  size_t nblocks, n;\n  unsigned int burn = 0;\n\n  if (buflen == 0 && (unused == 0 || !do_padding))\n    return;\n\n  do\n    {\n      if (buflen > 0 && (buflen + unused < blocksize || unused > 0))\n        {\n          n = blocksize - unused;\n          n = n < buflen ? n : buflen;\n\n          buf_cpy (&c->u_mode.gcm.macbuf[unused], buf, n);\n\n          unused += n;\n          buf += n;\n          buflen -= n;\n        }\n      if (!buflen)\n        {\n          if (!do_padding)\n            break;\n\n\t  n = blocksize - unused;\n\t  if (n > 0)\n\t    {\n\t      memset (&c->u_mode.gcm.macbuf[unused], 0, n);\n\t      unused = blocksize;\n\t    }\n        }\n\n      if (unused > 0)\n        {\n          gcry_assert (unused == blocksize);\n\n          /* Process one block from macbuf.  */\n          burn = ghash_fn (c, hash, c->u_mode.gcm.macbuf, 1);\n          unused = 0;\n        }\n\n      nblocks = buflen / blocksize;\n\n      if (nblocks)\n        {\n          burn = ghash_fn (c, hash, buf, nblocks);\n          buf += blocksize * nblocks;\n          buflen -= blocksize * nblocks;\n        }\n    }\n  while (buflen > 0);\n\n  c->u_mode.gcm.mac_unused = unused;\n\n  if (burn)\n    _gcry_burn_stack (burn);\n}\n\n\nstatic gcry_err_code_t\ngcm_ctr_encrypt (gcry_cipher_hd_t c, byte *outbuf, size_t outbuflen,\n                 const byte *inbuf, size_t inbuflen)\n{\n  gcry_err_code_t err = 0;\n\n  while (inbuflen)\n    {\n      u32 nblocks_to_overflow;\n      u32 num_ctr_increments;\n      u32 curr_ctr_low;\n      size_t currlen = inbuflen;\n      byte ctr_copy[GCRY_GCM_BLOCK_LEN];\n      int fix_ctr = 0;\n\n      /* GCM CTR increments only least significant 32-bits, without carry\n       * to upper 96-bits of counter.  Using generic CTR implementation\n       * directly would carry 32-bit overflow to upper 96-bit.  Detect\n       * if input length is long enough to cause overflow, and limit\n       * input length so that CTR overflow happen but updated CTR value is\n       * not used to encrypt further input.  After overflow, upper 96 bits\n       * of CTR are restored to cancel out modification done by generic CTR\n       * encryption. */\n\n      if (inbuflen > c->unused)\n        {\n          curr_ctr_low = gcm_add32_be128 (c->u_ctr.ctr, 0);\n\n          /* Number of CTR increments this inbuflen would cause. */\n          num_ctr_increments = (inbuflen - c->unused) / GCRY_GCM_BLOCK_LEN +\n                               !!((inbuflen - c->unused) % GCRY_GCM_BLOCK_LEN);\n\n          if ((u32)(num_ctr_increments + curr_ctr_low) < curr_ctr_low)\n            {\n              nblocks_to_overflow = 0xffffffffU - curr_ctr_low + 1;\n              currlen = nblocks_to_overflow * GCRY_GCM_BLOCK_LEN + c->unused;\n              if (currlen > inbuflen)\n                {\n                  currlen = inbuflen;\n                }\n\n              fix_ctr = 1;\n              cipher_block_cpy(ctr_copy, c->u_ctr.ctr, GCRY_GCM_BLOCK_LEN);\n            }\n        }\n\n      err = _gcry_cipher_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err != 0)\n        return err;\n\n      if (fix_ctr)\n        {\n          /* Lower 32-bits of CTR should now be zero. */\n          gcry_assert(gcm_add32_be128 (c->u_ctr.ctr, 0) == 0);\n\n          /* Restore upper part of CTR. */\n          buf_cpy(c->u_ctr.ctr, ctr_copy, GCRY_GCM_BLOCK_LEN - sizeof(u32));\n\n          wipememory(ctr_copy, sizeof(ctr_copy));\n        }\n\n      inbuflen -= currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      outbuf += currlen;\n    }\n\n  return err;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_encrypt (gcry_cipher_hd_t c,\n                          byte *outbuf, size_t outbuflen,\n                          const byte *inbuf, size_t inbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n  gcry_err_code_t err;\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (outbuflen < inbuflen)\n    return GPG_ERR_BUFFER_TOO_SHORT;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  if (c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->u_mode.gcm.ghash_aad_finalized)\n    {\n      /* Start of encryption marks end of AAD stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n    }\n\n  gcm_bytecounter_add(c->u_mode.gcm.datalen, inbuflen);\n  if (!gcm_check_datalen(c->u_mode.gcm.datalen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  while (inbuflen)\n    {\n      size_t currlen = inbuflen;\n\n      /* Since checksumming is done after encryption, process input in 24KiB\n       * chunks to keep data loaded in L1 cache for checksumming. */\n      if (currlen > 24 * 1024)\n\tcurrlen = 24 * 1024;\n\n      err = gcm_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err != 0)\n\treturn err;\n\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, outbuf, currlen, 0);\n\n      outbuf += currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      inbuflen -= currlen;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_decrypt (gcry_cipher_hd_t c,\n                          byte *outbuf, size_t outbuflen,\n                          const byte *inbuf, size_t inbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n  gcry_err_code_t err;\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (outbuflen < inbuflen)\n    return GPG_ERR_BUFFER_TOO_SHORT;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  if (!c->u_mode.gcm.ghash_aad_finalized)\n    {\n      /* Start of decryption marks end of AAD stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n    }\n\n  gcm_bytecounter_add(c->u_mode.gcm.datalen, inbuflen);\n  if (!gcm_check_datalen(c->u_mode.gcm.datalen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  while (inbuflen)\n    {\n      size_t currlen = inbuflen;\n\n      /* Since checksumming is done before decryption, process input in\n       * 24KiB chunks to keep data loaded in L1 cache for decryption. */\n      if (currlen > 24 * 1024)\n\tcurrlen = 24 * 1024;\n\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, inbuf, currlen, 0);\n\n      err = gcm_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err)\n\treturn err;\n\n      outbuf += currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      inbuflen -= currlen;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_authenticate (gcry_cipher_hd_t c,\n                               const byte * aadbuf, size_t aadbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_aad_finalized\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  gcm_bytecounter_add(c->u_mode.gcm.aadlen, aadbuflen);\n  if (!gcm_check_aadlen_or_ivlen(c->u_mode.gcm.aadlen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, aadbuf, aadbuflen, 0);\n\n  return 0;\n}\n\n\nvoid\n_gcry_cipher_gcm_setkey (gcry_cipher_hd_t c)\n{\n  memset (c->u_mode.gcm.u_ghash_key.key, 0, GCRY_GCM_BLOCK_LEN);\n\n  c->spec->encrypt (&c->context.c, c->u_mode.gcm.u_ghash_key.key,\n                    c->u_mode.gcm.u_ghash_key.key);\n  setupM (c);\n}\n\n\nstatic gcry_err_code_t\n_gcry_cipher_gcm_initiv (gcry_cipher_hd_t c, const byte *iv, size_t ivlen)\n{\n  memset (c->u_mode.gcm.aadlen, 0, sizeof(c->u_mode.gcm.aadlen));\n  memset (c->u_mode.gcm.datalen, 0, sizeof(c->u_mode.gcm.datalen));\n  memset (c->u_mode.gcm.u_tag.tag, 0, GCRY_GCM_BLOCK_LEN);\n  c->u_mode.gcm.datalen_over_limits = 0;\n  c->u_mode.gcm.ghash_data_finalized = 0;\n  c->u_mode.gcm.ghash_aad_finalized = 0;\n\n  if (ivlen == 0)\n    return GPG_ERR_INV_LENGTH;\n\n  if (ivlen != GCRY_GCM_BLOCK_LEN - 4)\n    {\n      u32 iv_bytes[2] = {0, 0};\n      u32 bitlengths[2][2];\n\n      if (!c->u_mode.gcm.ghash_fn)\n        return GPG_ERR_INV_STATE;\n\n      memset(c->u_ctr.ctr, 0, GCRY_GCM_BLOCK_LEN);\n\n      gcm_bytecounter_add(iv_bytes, ivlen);\n      if (!gcm_check_aadlen_or_ivlen(iv_bytes))\n        {\n          c->u_mode.gcm.datalen_over_limits = 1;\n          return GPG_ERR_INV_LENGTH;\n        }\n\n      do_ghash_buf(c, c->u_ctr.ctr, iv, ivlen, 1);\n\n      /* iv length, 64-bit */\n      bitlengths[1][1] = be_bswap32(iv_bytes[0] << 3);\n      bitlengths[1][0] = be_bswap32((iv_bytes[0] >> 29) |\n                                    (iv_bytes[1] << 3));\n      /* zeros, 64-bit */\n      bitlengths[0][1] = 0;\n      bitlengths[0][0] = 0;\n\n      do_ghash_buf(c, c->u_ctr.ctr, (byte*)bitlengths, GCRY_GCM_BLOCK_LEN, 1);\n\n      wipememory (iv_bytes, sizeof iv_bytes);\n      wipememory (bitlengths, sizeof bitlengths);\n    }\n  else\n    {\n      /* 96-bit IV is handled differently. */\n      memcpy (c->u_ctr.ctr, iv, ivlen);\n      c->u_ctr.ctr[12] = c->u_ctr.ctr[13] = c->u_ctr.ctr[14] = 0;\n      c->u_ctr.ctr[15] = 1;\n    }\n\n  c->spec->encrypt (&c->context.c, c->u_mode.gcm.tagiv, c->u_ctr.ctr);\n\n  gcm_add32_be128 (c->u_ctr.ctr, 1);\n\n  c->unused = 0;\n  c->marks.iv = 1;\n  c->marks.tag = 0;\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_setiv (gcry_cipher_hd_t c, const byte *iv, size_t ivlen)\n{\n  c->marks.iv = 0;\n  c->marks.tag = 0;\n  c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 0;\n\n  if (fips_mode ())\n    {\n      /* Direct invocation of GCM setiv in FIPS mode disables encryption. */\n      c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 1;\n    }\n\n  return _gcry_cipher_gcm_initiv (c, iv, ivlen);\n}\n\n\n#if 0 && TODO\nvoid\n_gcry_cipher_gcm_geniv (gcry_cipher_hd_t c,\n                        byte *ivout, size_t ivoutlen, const byte *nonce,\n                        size_t noncelen)\n{\n  /* nonce:    user provided part (might be null) */\n  /* noncelen: check if proper length (if nonce not null) */\n  /* ivout:    iv used to initialize gcm, output to user */\n  /* ivoutlen: check correct size */\n  byte iv[IVLEN];\n\n  if (!ivout)\n    return GPG_ERR_INV_ARG;\n  if (ivoutlen != IVLEN)\n    return GPG_ERR_INV_LENGTH;\n  if (nonce != NULL && !is_nonce_ok_len(noncelen))\n    return GPG_ERR_INV_ARG;\n\n  gcm_generate_iv(iv, nonce, noncelen);\n\n  c->marks.iv = 0;\n  c->marks.tag = 0;\n  c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 0;\n\n  _gcry_cipher_gcm_initiv (c, iv, IVLEN);\n\n  buf_cpy(ivout, iv, IVLEN);\n  wipememory(iv, sizeof(iv));\n}\n#endif\n\n\nstatic int\nis_tag_length_valid(size_t taglen)\n{\n  switch (taglen)\n    {\n    /* Allowed tag lengths from NIST SP 800-38D.  */\n    case 128 / 8: /* GCRY_GCM_BLOCK_LEN */\n    case 120 / 8:\n    case 112 / 8:\n    case 104 / 8:\n    case 96 / 8:\n    case 64 / 8:\n    case 32 / 8:\n      return 1;\n\n    default:\n      return 0;\n    }\n}\n\nstatic gcry_err_code_t\n_gcry_cipher_gcm_tag (gcry_cipher_hd_t c,\n                      byte * outbuf, size_t outbuflen, int check)\n{\n  if (!(is_tag_length_valid (outbuflen) || outbuflen >= GCRY_GCM_BLOCK_LEN))\n    return GPG_ERR_INV_LENGTH;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n\n  if (!c->marks.tag)\n    {\n      u32 bitlengths[2][2];\n\n      if (!c->u_mode.gcm.ghash_fn)\n        return GPG_ERR_INV_STATE;\n\n      /* aad length */\n      bitlengths[0][1] = be_bswap32(c->u_mode.gcm.aadlen[0] << 3);\n      bitlengths[0][0] = be_bswap32((c->u_mode.gcm.aadlen[0] >> 29) |\n                                    (c->u_mode.gcm.aadlen[1] << 3));\n      /* data length */\n      bitlengths[1][1] = be_bswap32(c->u_mode.gcm.datalen[0] << 3);\n      bitlengths[1][0] = be_bswap32((c->u_mode.gcm.datalen[0] >> 29) |\n                                    (c->u_mode.gcm.datalen[1] << 3));\n\n      /* Finalize data-stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n      c->u_mode.gcm.ghash_data_finalized = 1;\n\n      /* Add bitlengths to tag. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, (byte*)bitlengths,\n                   GCRY_GCM_BLOCK_LEN, 1);\n      cipher_block_xor (c->u_mode.gcm.u_tag.tag, c->u_mode.gcm.tagiv,\n                        c->u_mode.gcm.u_tag.tag, GCRY_GCM_BLOCK_LEN);\n      c->marks.tag = 1;\n\n      wipememory (bitlengths, sizeof (bitlengths));\n      wipememory (c->u_mode.gcm.macbuf, GCRY_GCM_BLOCK_LEN);\n      wipememory (c->u_mode.gcm.tagiv, GCRY_GCM_BLOCK_LEN);\n      wipememory (c->u_mode.gcm.aadlen, sizeof (c->u_mode.gcm.aadlen));\n      wipememory (c->u_mode.gcm.datalen, sizeof (c->u_mode.gcm.datalen));\n    }\n\n  if (!check)\n    {\n      if (outbuflen > GCRY_GCM_BLOCK_LEN)\n        outbuflen = GCRY_GCM_BLOCK_LEN;\n\n      /* NB: We already checked that OUTBUF is large enough to hold\n       * the result or has valid truncated length.  */\n      memcpy (outbuf, c->u_mode.gcm.u_tag.tag, outbuflen);\n    }\n  else\n    {\n      /* OUTBUFLEN gives the length of the user supplied tag in OUTBUF\n       * and thus we need to compare its length first.  */\n      if (!is_tag_length_valid (outbuflen)\n          || !buf_eq_const (outbuf, c->u_mode.gcm.u_tag.tag, outbuflen))\n        return GPG_ERR_CHECKSUM;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_get_tag (gcry_cipher_hd_t c, unsigned char *outtag,\n                          size_t taglen)\n{\n  /* Outputting authentication tag is part of encryption. */\n  if (c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode)\n    return GPG_ERR_INV_STATE;\n\n  return _gcry_cipher_gcm_tag (c, outtag, taglen, 0);\n}\n\ngcry_err_code_t\n_gcry_cipher_gcm_check_tag (gcry_cipher_hd_t c, const unsigned char *intag,\n                            size_t taglen)\n{\n  return _gcry_cipher_gcm_tag (c, (unsigned char *) intag, taglen, 1);\n}\n"], "fixing_code": ["/* cipher-gcm.c  - Generic Galois Counter Mode implementation\n * Copyright (C) 2013 Dmitry Eremin-Solenikov\n * Copyright (C) 2013, 2018-2019 Jussi Kivilinna <jussi.kivilinna@iki.fi>\n *\n * This file is part of Libgcrypt.\n *\n * Libgcrypt is free software; you can redistribute it and/or modify\n * it under the terms of the GNU Lesser general Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * Libgcrypt is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this program; if not, see <http://www.gnu.org/licenses/>.\n */\n\n#include <config.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n\n#include \"g10lib.h\"\n#include \"cipher.h\"\n#include \"bufhelp.h\"\n#include \"./cipher-internal.h\"\n\n\n/* Helper macro to force alignment to 16 or 64 bytes.  */\n#ifdef HAVE_GCC_ATTRIBUTE_ALIGNED\n# define ATTR_ALIGNED_64  __attribute__ ((aligned (64)))\n#else\n# define ATTR_ALIGNED_64\n#endif\n\n\n#ifdef GCM_USE_INTEL_PCLMUL\nextern void _gcry_ghash_setup_intel_pclmul (gcry_cipher_hd_t c);\n\nextern unsigned int _gcry_ghash_intel_pclmul (gcry_cipher_hd_t c, byte *result,\n                                              const byte *buf, size_t nblocks);\n#endif\n\n#ifdef GCM_USE_ARM_PMULL\nextern void _gcry_ghash_setup_armv8_ce_pmull (void *gcm_key, void *gcm_table);\n\nextern unsigned int _gcry_ghash_armv8_ce_pmull (void *gcm_key, byte *result,\n                                                const byte *buf, size_t nblocks,\n                                                void *gcm_table);\n\nstatic void\nghash_setup_armv8_ce_pmull (gcry_cipher_hd_t c)\n{\n  _gcry_ghash_setup_armv8_ce_pmull(c->u_mode.gcm.u_ghash_key.key,\n                                   c->u_mode.gcm.gcm_table);\n}\n\nstatic unsigned int\nghash_armv8_ce_pmull (gcry_cipher_hd_t c, byte *result, const byte *buf,\n                      size_t nblocks)\n{\n  return _gcry_ghash_armv8_ce_pmull(c->u_mode.gcm.u_ghash_key.key, result, buf,\n                                    nblocks, c->u_mode.gcm.gcm_table);\n}\n#endif /* GCM_USE_ARM_PMULL */\n\n#ifdef GCM_USE_ARM_NEON\nextern void _gcry_ghash_setup_armv7_neon (void *gcm_key);\n\nextern unsigned int _gcry_ghash_armv7_neon (void *gcm_key, byte *result,\n\t\t\t\t\t    const byte *buf, size_t nblocks);\n\nstatic void\nghash_setup_armv7_neon (gcry_cipher_hd_t c)\n{\n  _gcry_ghash_setup_armv7_neon(c->u_mode.gcm.u_ghash_key.key);\n}\n\nstatic unsigned int\nghash_armv7_neon (gcry_cipher_hd_t c, byte *result, const byte *buf,\n\t\t  size_t nblocks)\n{\n  return _gcry_ghash_armv7_neon(c->u_mode.gcm.u_ghash_key.key, result, buf,\n\t\t\t\tnblocks);\n}\n#endif /* GCM_USE_ARM_NEON */\n\n\n#ifdef GCM_USE_TABLES\nstatic struct\n{\n  volatile u32 counter_head;\n  u32 cacheline_align[64 / 4 - 1];\n  u16 R[256];\n  volatile u32 counter_tail;\n} gcm_table ATTR_ALIGNED_64 =\n  {\n    0,\n    { 0, },\n    {\n      0x0000, 0x01c2, 0x0384, 0x0246, 0x0708, 0x06ca, 0x048c, 0x054e,\n      0x0e10, 0x0fd2, 0x0d94, 0x0c56, 0x0918, 0x08da, 0x0a9c, 0x0b5e,\n      0x1c20, 0x1de2, 0x1fa4, 0x1e66, 0x1b28, 0x1aea, 0x18ac, 0x196e,\n      0x1230, 0x13f2, 0x11b4, 0x1076, 0x1538, 0x14fa, 0x16bc, 0x177e,\n      0x3840, 0x3982, 0x3bc4, 0x3a06, 0x3f48, 0x3e8a, 0x3ccc, 0x3d0e,\n      0x3650, 0x3792, 0x35d4, 0x3416, 0x3158, 0x309a, 0x32dc, 0x331e,\n      0x2460, 0x25a2, 0x27e4, 0x2626, 0x2368, 0x22aa, 0x20ec, 0x212e,\n      0x2a70, 0x2bb2, 0x29f4, 0x2836, 0x2d78, 0x2cba, 0x2efc, 0x2f3e,\n      0x7080, 0x7142, 0x7304, 0x72c6, 0x7788, 0x764a, 0x740c, 0x75ce,\n      0x7e90, 0x7f52, 0x7d14, 0x7cd6, 0x7998, 0x785a, 0x7a1c, 0x7bde,\n      0x6ca0, 0x6d62, 0x6f24, 0x6ee6, 0x6ba8, 0x6a6a, 0x682c, 0x69ee,\n      0x62b0, 0x6372, 0x6134, 0x60f6, 0x65b8, 0x647a, 0x663c, 0x67fe,\n      0x48c0, 0x4902, 0x4b44, 0x4a86, 0x4fc8, 0x4e0a, 0x4c4c, 0x4d8e,\n      0x46d0, 0x4712, 0x4554, 0x4496, 0x41d8, 0x401a, 0x425c, 0x439e,\n      0x54e0, 0x5522, 0x5764, 0x56a6, 0x53e8, 0x522a, 0x506c, 0x51ae,\n      0x5af0, 0x5b32, 0x5974, 0x58b6, 0x5df8, 0x5c3a, 0x5e7c, 0x5fbe,\n      0xe100, 0xe0c2, 0xe284, 0xe346, 0xe608, 0xe7ca, 0xe58c, 0xe44e,\n      0xef10, 0xeed2, 0xec94, 0xed56, 0xe818, 0xe9da, 0xeb9c, 0xea5e,\n      0xfd20, 0xfce2, 0xfea4, 0xff66, 0xfa28, 0xfbea, 0xf9ac, 0xf86e,\n      0xf330, 0xf2f2, 0xf0b4, 0xf176, 0xf438, 0xf5fa, 0xf7bc, 0xf67e,\n      0xd940, 0xd882, 0xdac4, 0xdb06, 0xde48, 0xdf8a, 0xddcc, 0xdc0e,\n      0xd750, 0xd692, 0xd4d4, 0xd516, 0xd058, 0xd19a, 0xd3dc, 0xd21e,\n      0xc560, 0xc4a2, 0xc6e4, 0xc726, 0xc268, 0xc3aa, 0xc1ec, 0xc02e,\n      0xcb70, 0xcab2, 0xc8f4, 0xc936, 0xcc78, 0xcdba, 0xcffc, 0xce3e,\n      0x9180, 0x9042, 0x9204, 0x93c6, 0x9688, 0x974a, 0x950c, 0x94ce,\n      0x9f90, 0x9e52, 0x9c14, 0x9dd6, 0x9898, 0x995a, 0x9b1c, 0x9ade,\n      0x8da0, 0x8c62, 0x8e24, 0x8fe6, 0x8aa8, 0x8b6a, 0x892c, 0x88ee,\n      0x83b0, 0x8272, 0x8034, 0x81f6, 0x84b8, 0x857a, 0x873c, 0x86fe,\n      0xa9c0, 0xa802, 0xaa44, 0xab86, 0xaec8, 0xaf0a, 0xad4c, 0xac8e,\n      0xa7d0, 0xa612, 0xa454, 0xa596, 0xa0d8, 0xa11a, 0xa35c, 0xa29e,\n      0xb5e0, 0xb422, 0xb664, 0xb7a6, 0xb2e8, 0xb32a, 0xb16c, 0xb0ae,\n      0xbbf0, 0xba32, 0xb874, 0xb9b6, 0xbcf8, 0xbd3a, 0xbf7c, 0xbebe,\n    },\n    0\n  };\n\n#define gcmR gcm_table.R\n\nstatic inline\nvoid prefetch_table(const void *tab, size_t len)\n{\n  const volatile byte *vtab = tab;\n  size_t i;\n\n  for (i = 0; len - i >= 8 * 32; i += 8 * 32)\n    {\n      (void)vtab[i + 0 * 32];\n      (void)vtab[i + 1 * 32];\n      (void)vtab[i + 2 * 32];\n      (void)vtab[i + 3 * 32];\n      (void)vtab[i + 4 * 32];\n      (void)vtab[i + 5 * 32];\n      (void)vtab[i + 6 * 32];\n      (void)vtab[i + 7 * 32];\n    }\n  for (; i < len; i += 32)\n    {\n      (void)vtab[i];\n    }\n\n  (void)vtab[len - 1];\n}\n\nstatic inline void\ndo_prefetch_tables (const void *gcmM, size_t gcmM_size)\n{\n  /* Modify counters to trigger copy-on-write and unsharing if physical pages\n   * of look-up table are shared between processes.  Modifying counters also\n   * causes checksums for pages to change and hint same-page merging algorithm\n   * that these pages are frequently changing.  */\n  gcm_table.counter_head++;\n  gcm_table.counter_tail++;\n\n  /* Prefetch look-up tables to cache.  */\n  prefetch_table(gcmM, gcmM_size);\n  prefetch_table(&gcm_table, sizeof(gcm_table));\n}\n\n#ifdef GCM_TABLES_USE_U64\nstatic void\nbshift (u64 * b0, u64 * b1)\n{\n  u64 t[2], mask;\n\n  t[0] = *b0;\n  t[1] = *b1;\n  mask = -(t[1] & 1) & 0xe1;\n  mask <<= 56;\n\n  *b1 = (t[1] >> 1) ^ (t[0] << 63);\n  *b0 = (t[0] >> 1) ^ mask;\n}\n\nstatic void\ndo_fillM (unsigned char *h, u64 *M)\n{\n  int i, j;\n\n  M[0 + 0] = 0;\n  M[0 + 16] = 0;\n\n  M[8 + 0] = buf_get_be64 (h + 0);\n  M[8 + 16] = buf_get_be64 (h + 8);\n\n  for (i = 4; i > 0; i /= 2)\n    {\n      M[i + 0] = M[2 * i + 0];\n      M[i + 16] = M[2 * i + 16];\n\n      bshift (&M[i], &M[i + 16]);\n    }\n\n  for (i = 2; i < 16; i *= 2)\n    for (j = 1; j < i; j++)\n      {\n        M[(i + j) + 0] = M[i + 0] ^ M[j + 0];\n        M[(i + j) + 16] = M[i + 16] ^ M[j + 16];\n      }\n\n  for (i = 0; i < 16; i++)\n    {\n      M[i + 32] = (M[i + 0] >> 4) ^ ((u64) gcmR[(M[i + 16] & 0xf) << 4] << 48);\n      M[i + 48] = (M[i + 16] >> 4) ^ (M[i + 0] << 60);\n    }\n}\n\nstatic inline unsigned int\ndo_ghash (unsigned char *result, const unsigned char *buf, const u64 *gcmM)\n{\n  u64 V[2];\n  u64 tmp[2];\n  const u64 *M;\n  u64 T;\n  u32 A;\n  int i;\n\n  cipher_block_xor (V, result, buf, 16);\n  V[0] = be_bswap64 (V[0]);\n  V[1] = be_bswap64 (V[1]);\n\n  /* First round can be manually tweaked based on fact that 'tmp' is zero. */\n  M = &gcmM[(V[1] & 0xf) + 32];\n  V[1] >>= 4;\n  tmp[0] = M[0];\n  tmp[1] = M[16];\n  tmp[0] ^= gcmM[(V[1] & 0xf) + 0];\n  tmp[1] ^= gcmM[(V[1] & 0xf) + 16];\n  V[1] >>= 4;\n\n  i = 6;\n  while (1)\n    {\n      M = &gcmM[(V[1] & 0xf) + 32];\n      V[1] >>= 4;\n\n      A = tmp[1] & 0xff;\n      T = tmp[0];\n      tmp[0] = (T >> 8) ^ ((u64) gcmR[A] << 48) ^ gcmM[(V[1] & 0xf) + 0];\n      tmp[1] = (T << 56) ^ (tmp[1] >> 8) ^ gcmM[(V[1] & 0xf) + 16];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[16];\n\n      if (i == 0)\n        break;\n\n      V[1] >>= 4;\n      --i;\n    }\n\n  i = 7;\n  while (1)\n    {\n      M = &gcmM[(V[0] & 0xf) + 32];\n      V[0] >>= 4;\n\n      A = tmp[1] & 0xff;\n      T = tmp[0];\n      tmp[0] = (T >> 8) ^ ((u64) gcmR[A] << 48) ^ gcmM[(V[0] & 0xf) + 0];\n      tmp[1] = (T << 56) ^ (tmp[1] >> 8) ^ gcmM[(V[0] & 0xf) + 16];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[16];\n\n      if (i == 0)\n        break;\n\n      V[0] >>= 4;\n      --i;\n    }\n\n  buf_put_be64 (result + 0, tmp[0]);\n  buf_put_be64 (result + 8, tmp[1]);\n\n  return (sizeof(V) + sizeof(T) + sizeof(tmp) +\n          sizeof(int)*2 + sizeof(void*)*5);\n}\n\n#else /*!GCM_TABLES_USE_U64*/\n\nstatic void\nbshift (u32 * M, int i)\n{\n  u32 t[4], mask;\n\n  t[0] = M[i * 4 + 0];\n  t[1] = M[i * 4 + 1];\n  t[2] = M[i * 4 + 2];\n  t[3] = M[i * 4 + 3];\n  mask = -(t[3] & 1) & 0xe1;\n\n  M[i * 4 + 3] = (t[3] >> 1) ^ (t[2] << 31);\n  M[i * 4 + 2] = (t[2] >> 1) ^ (t[1] << 31);\n  M[i * 4 + 1] = (t[1] >> 1) ^ (t[0] << 31);\n  M[i * 4 + 0] = (t[0] >> 1) ^ (mask << 24);\n}\n\nstatic void\ndo_fillM (unsigned char *h, u32 *M)\n{\n  int i, j;\n\n  M[0 * 4 + 0] = 0;\n  M[0 * 4 + 1] = 0;\n  M[0 * 4 + 2] = 0;\n  M[0 * 4 + 3] = 0;\n\n  M[8 * 4 + 0] = buf_get_be32 (h + 0);\n  M[8 * 4 + 1] = buf_get_be32 (h + 4);\n  M[8 * 4 + 2] = buf_get_be32 (h + 8);\n  M[8 * 4 + 3] = buf_get_be32 (h + 12);\n\n  for (i = 4; i > 0; i /= 2)\n    {\n      M[i * 4 + 0] = M[2 * i * 4 + 0];\n      M[i * 4 + 1] = M[2 * i * 4 + 1];\n      M[i * 4 + 2] = M[2 * i * 4 + 2];\n      M[i * 4 + 3] = M[2 * i * 4 + 3];\n\n      bshift (M, i);\n    }\n\n  for (i = 2; i < 16; i *= 2)\n    for (j = 1; j < i; j++)\n      {\n        M[(i + j) * 4 + 0] = M[i * 4 + 0] ^ M[j * 4 + 0];\n        M[(i + j) * 4 + 1] = M[i * 4 + 1] ^ M[j * 4 + 1];\n        M[(i + j) * 4 + 2] = M[i * 4 + 2] ^ M[j * 4 + 2];\n        M[(i + j) * 4 + 3] = M[i * 4 + 3] ^ M[j * 4 + 3];\n      }\n\n  for (i = 0; i < 4 * 16; i += 4)\n    {\n      M[i + 0 + 64] = (M[i + 0] >> 4)\n                      ^ ((u64) gcmR[(M[i + 3] << 4) & 0xf0] << 16);\n      M[i + 1 + 64] = (M[i + 1] >> 4) ^ (M[i + 0] << 28);\n      M[i + 2 + 64] = (M[i + 2] >> 4) ^ (M[i + 1] << 28);\n      M[i + 3 + 64] = (M[i + 3] >> 4) ^ (M[i + 2] << 28);\n    }\n}\n\nstatic inline unsigned int\ndo_ghash (unsigned char *result, const unsigned char *buf, const u32 *gcmM)\n{\n  byte V[16];\n  u32 tmp[4];\n  u32 v;\n  const u32 *M, *m;\n  u32 T[3];\n  int i;\n\n  cipher_block_xor (V, result, buf, 16); /* V is big-endian */\n\n  /* First round can be manually tweaked based on fact that 'tmp' is zero. */\n  i = 15;\n\n  v = V[i];\n  M = &gcmM[(v & 0xf) * 4 + 64];\n  v = (v & 0xf0) >> 4;\n  m = &gcmM[v * 4];\n  v = V[--i];\n\n  tmp[0] = M[0] ^ m[0];\n  tmp[1] = M[1] ^ m[1];\n  tmp[2] = M[2] ^ m[2];\n  tmp[3] = M[3] ^ m[3];\n\n  while (1)\n    {\n      M = &gcmM[(v & 0xf) * 4 + 64];\n      v = (v & 0xf0) >> 4;\n      m = &gcmM[v * 4];\n\n      T[0] = tmp[0];\n      T[1] = tmp[1];\n      T[2] = tmp[2];\n      tmp[0] = (T[0] >> 8) ^ ((u32) gcmR[tmp[3] & 0xff] << 16) ^ m[0];\n      tmp[1] = (T[0] << 24) ^ (tmp[1] >> 8) ^ m[1];\n      tmp[2] = (T[1] << 24) ^ (tmp[2] >> 8) ^ m[2];\n      tmp[3] = (T[2] << 24) ^ (tmp[3] >> 8) ^ m[3];\n\n      tmp[0] ^= M[0];\n      tmp[1] ^= M[1];\n      tmp[2] ^= M[2];\n      tmp[3] ^= M[3];\n\n      if (i == 0)\n        break;\n\n      v = V[--i];\n    }\n\n  buf_put_be32 (result + 0, tmp[0]);\n  buf_put_be32 (result + 4, tmp[1]);\n  buf_put_be32 (result + 8, tmp[2]);\n  buf_put_be32 (result + 12, tmp[3]);\n\n  return (sizeof(V) + sizeof(T) + sizeof(tmp) +\n          sizeof(int)*2 + sizeof(void*)*6);\n}\n#endif /*!GCM_TABLES_USE_U64*/\n\n#define fillM(c) \\\n  do_fillM (c->u_mode.gcm.u_ghash_key.key, c->u_mode.gcm.gcm_table)\n#define GHASH(c, result, buf) do_ghash (result, buf, c->u_mode.gcm.gcm_table)\n#define prefetch_tables(c) \\\n  do_prefetch_tables(c->u_mode.gcm.gcm_table, sizeof(c->u_mode.gcm.gcm_table))\n\n#else\n\nstatic unsigned long\nbshift (unsigned long *b)\n{\n  unsigned long c;\n  int i;\n  c = b[3] & 1;\n  for (i = 3; i > 0; i--)\n    {\n      b[i] = (b[i] >> 1) | (b[i - 1] << 31);\n    }\n  b[i] >>= 1;\n  return c;\n}\n\nstatic unsigned int\ndo_ghash (unsigned char *hsub, unsigned char *result, const unsigned char *buf)\n{\n  unsigned long V[4];\n  int i, j;\n  byte *p;\n\n#ifdef WORDS_BIGENDIAN\n  p = result;\n#else\n  unsigned long T[4];\n\n  cipher_block_xor (V, result, buf, 16);\n  for (i = 0; i < 4; i++)\n    {\n      V[i] = (V[i] & 0x00ff00ff) << 8 | (V[i] & 0xff00ff00) >> 8;\n      V[i] = (V[i] & 0x0000ffff) << 16 | (V[i] & 0xffff0000) >> 16;\n    }\n  p = (byte *) T;\n#endif\n\n  memset (p, 0, 16);\n\n  for (i = 0; i < 16; i++)\n    {\n      for (j = 0x80; j; j >>= 1)\n        {\n          if (hsub[i] & j)\n            cipher_block_xor (p, p, V, 16);\n          if (bshift (V))\n            V[0] ^= 0xe1000000;\n        }\n    }\n#ifndef WORDS_BIGENDIAN\n  for (i = 0, p = (byte *) T; i < 16; i += 4, p += 4)\n    {\n      result[i + 0] = p[3];\n      result[i + 1] = p[2];\n      result[i + 2] = p[1];\n      result[i + 3] = p[0];\n    }\n#endif\n\n  return (sizeof(V) + sizeof(T) + sizeof(int)*2 + sizeof(void*)*5);\n}\n\n#define fillM(c) do { } while (0)\n#define GHASH(c, result, buf) do_ghash (c->u_mode.gcm.u_ghash_key.key, result, buf)\n#define prefetch_tables(c) do {} while (0)\n\n#endif /* !GCM_USE_TABLES */\n\n\nstatic unsigned int\nghash_internal (gcry_cipher_hd_t c, byte *result, const byte *buf,\n                size_t nblocks)\n{\n  const unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  unsigned int burn = 0;\n\n  prefetch_tables (c);\n\n  while (nblocks)\n    {\n      burn = GHASH (c, result, buf);\n      buf += blocksize;\n      nblocks--;\n    }\n\n  return burn + (burn ? 5*sizeof(void*) : 0);\n}\n\n\nstatic void\nsetupM (gcry_cipher_hd_t c)\n{\n#if defined(GCM_USE_INTEL_PCLMUL) || defined(GCM_USE_ARM_PMULL)\n  unsigned int features = _gcry_get_hw_features ();\n#endif\n\n  if (0)\n    ;\n#ifdef GCM_USE_INTEL_PCLMUL\n  else if (features & HWF_INTEL_PCLMUL)\n    {\n      c->u_mode.gcm.ghash_fn = _gcry_ghash_intel_pclmul;\n      _gcry_ghash_setup_intel_pclmul (c);\n    }\n#endif\n#ifdef GCM_USE_ARM_PMULL\n  else if (features & HWF_ARM_PMULL)\n    {\n      c->u_mode.gcm.ghash_fn = ghash_armv8_ce_pmull;\n      ghash_setup_armv8_ce_pmull (c);\n    }\n#endif\n#ifdef GCM_USE_ARM_NEON\n  else if (features & HWF_ARM_NEON)\n    {\n      c->u_mode.gcm.ghash_fn = ghash_armv7_neon;\n      ghash_setup_armv7_neon (c);\n    }\n#endif\n  else\n    {\n      c->u_mode.gcm.ghash_fn = ghash_internal;\n      fillM (c);\n    }\n}\n\n\nstatic inline void\ngcm_bytecounter_add (u32 ctr[2], size_t add)\n{\n  if (sizeof(add) > sizeof(u32))\n    {\n      u32 high_add = ((add >> 31) >> 1) & 0xffffffff;\n      ctr[1] += high_add;\n    }\n\n  ctr[0] += add;\n  if (ctr[0] >= add)\n    return;\n  ++ctr[1];\n}\n\n\nstatic inline u32\ngcm_add32_be128 (byte *ctr, unsigned int add)\n{\n  /* 'ctr' must be aligned to four bytes. */\n  const unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  u32 *pval = (u32 *)(void *)(ctr + blocksize - sizeof(u32));\n  u32 val;\n\n  val = be_bswap32(*pval) + add;\n  *pval = be_bswap32(val);\n\n  return val; /* return result as host-endian value */\n}\n\n\nstatic inline int\ngcm_check_datalen (u32 ctr[2])\n{\n  /* len(plaintext) <= 2^39-256 bits == 2^36-32 bytes == 2^32-2 blocks */\n  if (ctr[1] > 0xfU)\n    return 0;\n  if (ctr[1] < 0xfU)\n    return 1;\n\n  if (ctr[0] <= 0xffffffe0U)\n    return 1;\n\n  return 0;\n}\n\n\nstatic inline int\ngcm_check_aadlen_or_ivlen (u32 ctr[2])\n{\n  /* len(aad/iv) <= 2^64-1 bits ~= 2^61-1 bytes */\n  if (ctr[1] > 0x1fffffffU)\n    return 0;\n  if (ctr[1] < 0x1fffffffU)\n    return 1;\n\n  if (ctr[0] <= 0xffffffffU)\n    return 1;\n\n  return 0;\n}\n\n\nstatic void\ndo_ghash_buf(gcry_cipher_hd_t c, byte *hash, const byte *buf,\n             size_t buflen, int do_padding)\n{\n  unsigned int blocksize = GCRY_GCM_BLOCK_LEN;\n  unsigned int unused = c->u_mode.gcm.mac_unused;\n  ghash_fn_t ghash_fn = c->u_mode.gcm.ghash_fn;\n  size_t nblocks, n;\n  unsigned int burn = 0;\n\n  if (buflen == 0 && (unused == 0 || !do_padding))\n    return;\n\n  do\n    {\n      if (buflen > 0 && (buflen + unused < blocksize || unused > 0))\n        {\n          n = blocksize - unused;\n          n = n < buflen ? n : buflen;\n\n          buf_cpy (&c->u_mode.gcm.macbuf[unused], buf, n);\n\n          unused += n;\n          buf += n;\n          buflen -= n;\n        }\n      if (!buflen)\n        {\n          if (!do_padding)\n            break;\n\n\t  n = blocksize - unused;\n\t  if (n > 0)\n\t    {\n\t      memset (&c->u_mode.gcm.macbuf[unused], 0, n);\n\t      unused = blocksize;\n\t    }\n        }\n\n      if (unused > 0)\n        {\n          gcry_assert (unused == blocksize);\n\n          /* Process one block from macbuf.  */\n          burn = ghash_fn (c, hash, c->u_mode.gcm.macbuf, 1);\n          unused = 0;\n        }\n\n      nblocks = buflen / blocksize;\n\n      if (nblocks)\n        {\n          burn = ghash_fn (c, hash, buf, nblocks);\n          buf += blocksize * nblocks;\n          buflen -= blocksize * nblocks;\n        }\n    }\n  while (buflen > 0);\n\n  c->u_mode.gcm.mac_unused = unused;\n\n  if (burn)\n    _gcry_burn_stack (burn);\n}\n\n\nstatic gcry_err_code_t\ngcm_ctr_encrypt (gcry_cipher_hd_t c, byte *outbuf, size_t outbuflen,\n                 const byte *inbuf, size_t inbuflen)\n{\n  gcry_err_code_t err = 0;\n\n  while (inbuflen)\n    {\n      u32 nblocks_to_overflow;\n      u32 num_ctr_increments;\n      u32 curr_ctr_low;\n      size_t currlen = inbuflen;\n      byte ctr_copy[GCRY_GCM_BLOCK_LEN];\n      int fix_ctr = 0;\n\n      /* GCM CTR increments only least significant 32-bits, without carry\n       * to upper 96-bits of counter.  Using generic CTR implementation\n       * directly would carry 32-bit overflow to upper 96-bit.  Detect\n       * if input length is long enough to cause overflow, and limit\n       * input length so that CTR overflow happen but updated CTR value is\n       * not used to encrypt further input.  After overflow, upper 96 bits\n       * of CTR are restored to cancel out modification done by generic CTR\n       * encryption. */\n\n      if (inbuflen > c->unused)\n        {\n          curr_ctr_low = gcm_add32_be128 (c->u_ctr.ctr, 0);\n\n          /* Number of CTR increments this inbuflen would cause. */\n          num_ctr_increments = (inbuflen - c->unused) / GCRY_GCM_BLOCK_LEN +\n                               !!((inbuflen - c->unused) % GCRY_GCM_BLOCK_LEN);\n\n          if ((u32)(num_ctr_increments + curr_ctr_low) < curr_ctr_low)\n            {\n              nblocks_to_overflow = 0xffffffffU - curr_ctr_low + 1;\n              currlen = nblocks_to_overflow * GCRY_GCM_BLOCK_LEN + c->unused;\n              if (currlen > inbuflen)\n                {\n                  currlen = inbuflen;\n                }\n\n              fix_ctr = 1;\n              cipher_block_cpy(ctr_copy, c->u_ctr.ctr, GCRY_GCM_BLOCK_LEN);\n            }\n        }\n\n      err = _gcry_cipher_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err != 0)\n        return err;\n\n      if (fix_ctr)\n        {\n          /* Lower 32-bits of CTR should now be zero. */\n          gcry_assert(gcm_add32_be128 (c->u_ctr.ctr, 0) == 0);\n\n          /* Restore upper part of CTR. */\n          buf_cpy(c->u_ctr.ctr, ctr_copy, GCRY_GCM_BLOCK_LEN - sizeof(u32));\n\n          wipememory(ctr_copy, sizeof(ctr_copy));\n        }\n\n      inbuflen -= currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      outbuf += currlen;\n    }\n\n  return err;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_encrypt (gcry_cipher_hd_t c,\n                          byte *outbuf, size_t outbuflen,\n                          const byte *inbuf, size_t inbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n  gcry_err_code_t err;\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (outbuflen < inbuflen)\n    return GPG_ERR_BUFFER_TOO_SHORT;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  if (c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->u_mode.gcm.ghash_aad_finalized)\n    {\n      /* Start of encryption marks end of AAD stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n    }\n\n  gcm_bytecounter_add(c->u_mode.gcm.datalen, inbuflen);\n  if (!gcm_check_datalen(c->u_mode.gcm.datalen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  while (inbuflen)\n    {\n      size_t currlen = inbuflen;\n\n      /* Since checksumming is done after encryption, process input in 24KiB\n       * chunks to keep data loaded in L1 cache for checksumming. */\n      if (currlen > 24 * 1024)\n\tcurrlen = 24 * 1024;\n\n      err = gcm_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err != 0)\n\treturn err;\n\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, outbuf, currlen, 0);\n\n      outbuf += currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      inbuflen -= currlen;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_decrypt (gcry_cipher_hd_t c,\n                          byte *outbuf, size_t outbuflen,\n                          const byte *inbuf, size_t inbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n  gcry_err_code_t err;\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (outbuflen < inbuflen)\n    return GPG_ERR_BUFFER_TOO_SHORT;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  if (!c->u_mode.gcm.ghash_aad_finalized)\n    {\n      /* Start of decryption marks end of AAD stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n    }\n\n  gcm_bytecounter_add(c->u_mode.gcm.datalen, inbuflen);\n  if (!gcm_check_datalen(c->u_mode.gcm.datalen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  while (inbuflen)\n    {\n      size_t currlen = inbuflen;\n\n      /* Since checksumming is done before decryption, process input in\n       * 24KiB chunks to keep data loaded in L1 cache for decryption. */\n      if (currlen > 24 * 1024)\n\tcurrlen = 24 * 1024;\n\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, inbuf, currlen, 0);\n\n      err = gcm_ctr_encrypt(c, outbuf, outbuflen, inbuf, currlen);\n      if (err)\n\treturn err;\n\n      outbuf += currlen;\n      inbuf += currlen;\n      outbuflen -= currlen;\n      inbuflen -= currlen;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_authenticate (gcry_cipher_hd_t c,\n                               const byte * aadbuf, size_t aadbuflen)\n{\n  static const unsigned char zerobuf[MAX_BLOCKSIZE];\n\n  if (c->spec->blocksize != GCRY_GCM_BLOCK_LEN)\n    return GPG_ERR_CIPHER_ALGO;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n  if (c->marks.tag\n      || c->u_mode.gcm.ghash_aad_finalized\n      || c->u_mode.gcm.ghash_data_finalized\n      || !c->u_mode.gcm.ghash_fn)\n    return GPG_ERR_INV_STATE;\n\n  if (!c->marks.iv)\n    _gcry_cipher_gcm_setiv (c, zerobuf, GCRY_GCM_BLOCK_LEN);\n\n  gcm_bytecounter_add(c->u_mode.gcm.aadlen, aadbuflen);\n  if (!gcm_check_aadlen_or_ivlen(c->u_mode.gcm.aadlen))\n    {\n      c->u_mode.gcm.datalen_over_limits = 1;\n      return GPG_ERR_INV_LENGTH;\n    }\n\n  do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, aadbuf, aadbuflen, 0);\n\n  return 0;\n}\n\n\nvoid\n_gcry_cipher_gcm_setkey (gcry_cipher_hd_t c)\n{\n  memset (c->u_mode.gcm.u_ghash_key.key, 0, GCRY_GCM_BLOCK_LEN);\n\n  c->spec->encrypt (&c->context.c, c->u_mode.gcm.u_ghash_key.key,\n                    c->u_mode.gcm.u_ghash_key.key);\n  setupM (c);\n}\n\n\nstatic gcry_err_code_t\n_gcry_cipher_gcm_initiv (gcry_cipher_hd_t c, const byte *iv, size_t ivlen)\n{\n  memset (c->u_mode.gcm.aadlen, 0, sizeof(c->u_mode.gcm.aadlen));\n  memset (c->u_mode.gcm.datalen, 0, sizeof(c->u_mode.gcm.datalen));\n  memset (c->u_mode.gcm.u_tag.tag, 0, GCRY_GCM_BLOCK_LEN);\n  c->u_mode.gcm.datalen_over_limits = 0;\n  c->u_mode.gcm.ghash_data_finalized = 0;\n  c->u_mode.gcm.ghash_aad_finalized = 0;\n\n  if (ivlen == 0)\n    return GPG_ERR_INV_LENGTH;\n\n  if (ivlen != GCRY_GCM_BLOCK_LEN - 4)\n    {\n      u32 iv_bytes[2] = {0, 0};\n      u32 bitlengths[2][2];\n\n      if (!c->u_mode.gcm.ghash_fn)\n        return GPG_ERR_INV_STATE;\n\n      memset(c->u_ctr.ctr, 0, GCRY_GCM_BLOCK_LEN);\n\n      gcm_bytecounter_add(iv_bytes, ivlen);\n      if (!gcm_check_aadlen_or_ivlen(iv_bytes))\n        {\n          c->u_mode.gcm.datalen_over_limits = 1;\n          return GPG_ERR_INV_LENGTH;\n        }\n\n      do_ghash_buf(c, c->u_ctr.ctr, iv, ivlen, 1);\n\n      /* iv length, 64-bit */\n      bitlengths[1][1] = be_bswap32(iv_bytes[0] << 3);\n      bitlengths[1][0] = be_bswap32((iv_bytes[0] >> 29) |\n                                    (iv_bytes[1] << 3));\n      /* zeros, 64-bit */\n      bitlengths[0][1] = 0;\n      bitlengths[0][0] = 0;\n\n      do_ghash_buf(c, c->u_ctr.ctr, (byte*)bitlengths, GCRY_GCM_BLOCK_LEN, 1);\n\n      wipememory (iv_bytes, sizeof iv_bytes);\n      wipememory (bitlengths, sizeof bitlengths);\n    }\n  else\n    {\n      /* 96-bit IV is handled differently. */\n      memcpy (c->u_ctr.ctr, iv, ivlen);\n      c->u_ctr.ctr[12] = c->u_ctr.ctr[13] = c->u_ctr.ctr[14] = 0;\n      c->u_ctr.ctr[15] = 1;\n    }\n\n  c->spec->encrypt (&c->context.c, c->u_mode.gcm.tagiv, c->u_ctr.ctr);\n\n  gcm_add32_be128 (c->u_ctr.ctr, 1);\n\n  c->unused = 0;\n  c->marks.iv = 1;\n  c->marks.tag = 0;\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_setiv (gcry_cipher_hd_t c, const byte *iv, size_t ivlen)\n{\n  c->marks.iv = 0;\n  c->marks.tag = 0;\n  c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 0;\n\n  if (fips_mode ())\n    {\n      /* Direct invocation of GCM setiv in FIPS mode disables encryption. */\n      c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 1;\n    }\n\n  return _gcry_cipher_gcm_initiv (c, iv, ivlen);\n}\n\n\n#if 0 && TODO\nvoid\n_gcry_cipher_gcm_geniv (gcry_cipher_hd_t c,\n                        byte *ivout, size_t ivoutlen, const byte *nonce,\n                        size_t noncelen)\n{\n  /* nonce:    user provided part (might be null) */\n  /* noncelen: check if proper length (if nonce not null) */\n  /* ivout:    iv used to initialize gcm, output to user */\n  /* ivoutlen: check correct size */\n  byte iv[IVLEN];\n\n  if (!ivout)\n    return GPG_ERR_INV_ARG;\n  if (ivoutlen != IVLEN)\n    return GPG_ERR_INV_LENGTH;\n  if (nonce != NULL && !is_nonce_ok_len(noncelen))\n    return GPG_ERR_INV_ARG;\n\n  gcm_generate_iv(iv, nonce, noncelen);\n\n  c->marks.iv = 0;\n  c->marks.tag = 0;\n  c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode = 0;\n\n  _gcry_cipher_gcm_initiv (c, iv, IVLEN);\n\n  buf_cpy(ivout, iv, IVLEN);\n  wipememory(iv, sizeof(iv));\n}\n#endif\n\n\nstatic int\nis_tag_length_valid(size_t taglen)\n{\n  switch (taglen)\n    {\n    /* Allowed tag lengths from NIST SP 800-38D.  */\n    case 128 / 8: /* GCRY_GCM_BLOCK_LEN */\n    case 120 / 8:\n    case 112 / 8:\n    case 104 / 8:\n    case 96 / 8:\n    case 64 / 8:\n    case 32 / 8:\n      return 1;\n\n    default:\n      return 0;\n    }\n}\n\nstatic gcry_err_code_t\n_gcry_cipher_gcm_tag (gcry_cipher_hd_t c,\n                      byte * outbuf, size_t outbuflen, int check)\n{\n  if (!(is_tag_length_valid (outbuflen) || outbuflen >= GCRY_GCM_BLOCK_LEN))\n    return GPG_ERR_INV_LENGTH;\n  if (c->u_mode.gcm.datalen_over_limits)\n    return GPG_ERR_INV_LENGTH;\n\n  if (!c->marks.tag)\n    {\n      u32 bitlengths[2][2];\n\n      if (!c->u_mode.gcm.ghash_fn)\n        return GPG_ERR_INV_STATE;\n\n      /* aad length */\n      bitlengths[0][1] = be_bswap32(c->u_mode.gcm.aadlen[0] << 3);\n      bitlengths[0][0] = be_bswap32((c->u_mode.gcm.aadlen[0] >> 29) |\n                                    (c->u_mode.gcm.aadlen[1] << 3));\n      /* data length */\n      bitlengths[1][1] = be_bswap32(c->u_mode.gcm.datalen[0] << 3);\n      bitlengths[1][0] = be_bswap32((c->u_mode.gcm.datalen[0] >> 29) |\n                                    (c->u_mode.gcm.datalen[1] << 3));\n\n      /* Finalize data-stream. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, NULL, 0, 1);\n      c->u_mode.gcm.ghash_aad_finalized = 1;\n      c->u_mode.gcm.ghash_data_finalized = 1;\n\n      /* Add bitlengths to tag. */\n      do_ghash_buf(c, c->u_mode.gcm.u_tag.tag, (byte*)bitlengths,\n                   GCRY_GCM_BLOCK_LEN, 1);\n      cipher_block_xor (c->u_mode.gcm.u_tag.tag, c->u_mode.gcm.tagiv,\n                        c->u_mode.gcm.u_tag.tag, GCRY_GCM_BLOCK_LEN);\n      c->marks.tag = 1;\n\n      wipememory (bitlengths, sizeof (bitlengths));\n      wipememory (c->u_mode.gcm.macbuf, GCRY_GCM_BLOCK_LEN);\n      wipememory (c->u_mode.gcm.tagiv, GCRY_GCM_BLOCK_LEN);\n      wipememory (c->u_mode.gcm.aadlen, sizeof (c->u_mode.gcm.aadlen));\n      wipememory (c->u_mode.gcm.datalen, sizeof (c->u_mode.gcm.datalen));\n    }\n\n  if (!check)\n    {\n      if (outbuflen > GCRY_GCM_BLOCK_LEN)\n        outbuflen = GCRY_GCM_BLOCK_LEN;\n\n      /* NB: We already checked that OUTBUF is large enough to hold\n       * the result or has valid truncated length.  */\n      memcpy (outbuf, c->u_mode.gcm.u_tag.tag, outbuflen);\n    }\n  else\n    {\n      /* OUTBUFLEN gives the length of the user supplied tag in OUTBUF\n       * and thus we need to compare its length first.  */\n      if (!is_tag_length_valid (outbuflen)\n          || !buf_eq_const (outbuf, c->u_mode.gcm.u_tag.tag, outbuflen))\n        return GPG_ERR_CHECKSUM;\n    }\n\n  return 0;\n}\n\n\ngcry_err_code_t\n_gcry_cipher_gcm_get_tag (gcry_cipher_hd_t c, unsigned char *outtag,\n                          size_t taglen)\n{\n  /* Outputting authentication tag is part of encryption. */\n  if (c->u_mode.gcm.disallow_encryption_because_of_setiv_in_fips_mode)\n    return GPG_ERR_INV_STATE;\n\n  return _gcry_cipher_gcm_tag (c, outtag, taglen, 0);\n}\n\ngcry_err_code_t\n_gcry_cipher_gcm_check_tag (gcry_cipher_hd_t c, const unsigned char *intag,\n                            size_t taglen)\n{\n  return _gcry_cipher_gcm_tag (c, (unsigned char *) intag, taglen, 1);\n}\n"], "buggy_code_start_loc": [32], "buggy_code_end_loc": [147], "fixing_code_start_loc": [33], "fixing_code_end_loc": [181], "type": "CWE-668", "message": "** DISPUTED ** In Libgcrypt 1.8.4, the C implementation of AES is vulnerable to a flush-and-reload side-channel attack because physical addresses are available to other processes. (The C implementation is used on platforms where an assembly-language implementation is unavailable.) NOTE: the vendor's position is that the issue report cannot be validated because there is no description of an attack.", "other": {"cve": {"id": "CVE-2019-12904", "sourceIdentifier": "cve@mitre.org", "published": "2019-06-20T00:15:10.667", "lastModified": "2021-07-21T11:39:23.747", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "** DISPUTED ** In Libgcrypt 1.8.4, the C implementation of AES is vulnerable to a flush-and-reload side-channel attack because physical addresses are available to other processes. (The C implementation is used on platforms where an assembly-language implementation is unavailable.) NOTE: the vendor's position is that the issue report cannot be validated because there is no description of an attack."}, {"lang": "es", "value": "** EN DISPUTA ** En Libgcrypt versi\u00f3n 1.8.4, la implementaci\u00f3n en C de AES es vulnerable a un ataque de canal lateral de descarga y recarga porque las direcciones f\u00edsicas est\u00e1n disponibles para otros procesos. (La implementaci\u00f3n en C se usa en plataformas donde una implementaci\u00f3n en lenguaje ensamblador no est\u00e1 disponible). NOTA: la posici\u00f3n del vendedor es que el informe de emisi\u00f3n no puede ser validado porque no hay descripci\u00f3n de un ataque"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-668"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:gnupg:libgcrypt:1.8.4:*:*:*:*:*:*:*", "matchCriteriaId": "80BF5528-C785-4F9F-B6DE-2B017FAEFD03"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.0:*:*:*:*:*:*:*", "matchCriteriaId": "F1E78106-58E6-4D59-990F-75DA575BFAD9"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2019-07/msg00049.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://dev.gnupg.org/T4541", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/gpg/libgcrypt/commit/a4c561aab1014c3630bc88faf6f5246fee16b020", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/gpg/libgcrypt/commit/daedbbb5541cd8ecda1459d3b843ea4d92788762", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.apache.org/thread.html/rf9fa47ab66495c78bb4120b0754dd9531ca2ff0430f6685ac9b07772@%3Cdev.mina.apache.org%3E", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/gpg/libgcrypt/commit/a4c561aab1014c3630bc88faf6f5246fee16b020"}}