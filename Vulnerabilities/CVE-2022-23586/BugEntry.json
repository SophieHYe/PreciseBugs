{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/function.h\"\n\n#include <ctype.h>\n\n#include <map>\n#include <unordered_map>\n#include <utility>\n#include <vector>\n\n#include \"absl/container/flat_hash_set.h\"\n#include \"absl/strings/escaping.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/str_join.h\"\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/function.pb.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/graph/graph.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/lib/strings/proto_serialization.h\"\n#include \"tensorflow/core/platform/fingerprint.h\"\n#include \"tensorflow/core/util/device_name_utils.h\"\n#include \"tensorflow/core/util/equal_graph_def.h\"\n\nnamespace tensorflow {\n\n/* static */ constexpr const char* const FunctionLibraryDefinition::kArgOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kDeviceArgOp;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kRetOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kDeviceRetOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kIntsOnDeviceAttr;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kGradientOp;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kFuncAttr;\n\n// Extracts the actual type from \"attr_values\" based on its definition\n// \"arg_def\".\n//\n// If \"arg_def\" is a N*T type, *is_type_list is set to false, and\n// *dtypes is set to be a vector of size N and each element is T.\n//\n// If \"arg_def\" is a list(type), *is_type_list is set to true, and\n// *dtypes is set to be a vector of types specified in attrs for\n// arg_def.\n//\n// Otherwise (arg_def is a simple type T), *is_type_list is set to\n// false, and *dtypes is set to a single element vector, whose only\n// element is T.\nStatus ArgNumType(AttrSlice attrs, const OpDef::ArgDef& arg_def,\n                  bool* is_type_list, DataTypeVector* dtypes) {\n  dtypes->clear();\n  if (!arg_def.type_list_attr().empty()) {\n    const AttrValue* v = attrs.Find(arg_def.type_list_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \",\n                              arg_def.type_list_attr());\n    }\n    *is_type_list = true;\n    for (int i = 0; i < v->list().type_size(); ++i) {\n      dtypes->push_back(v->list().type(i));\n    }\n    return Status::OK();\n  }\n\n  *is_type_list = false;\n  int num = 1;\n  if (!arg_def.number_attr().empty()) {\n    const AttrValue* v = attrs.Find(arg_def.number_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \", arg_def.type_attr());\n    }\n    num = v->i();\n  }\n\n  DataType dtype;\n  if (arg_def.type() != DT_INVALID) {\n    dtype = arg_def.type();\n  } else if (arg_def.type_attr().empty()) {\n    dtype = DT_INVALID;\n  } else {\n    const AttrValue* v = attrs.Find(arg_def.type_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \", arg_def.type_attr());\n    }\n    dtype = v->type();\n  }\n  dtypes->resize(num, dtype);\n  return Status::OK();\n}\n\nnamespace {\n\ntemplate <typename T>\nvoid AddAttr(const string& name, const T& val, NodeDef* ndef) {\n  SetAttrValue(val, &((*ndef->mutable_attr())[name]));\n}\n\nStatus ValidateSignatureWithAttrs(const OpDef& sig, AttrSlice attr_values) {\n  // attr_values should specify all attrs defined in fdef, except for those\n  // which have a default value\n  for (const auto& attr : sig.attr()) {\n    const AttrValue* attr_value = attr_values.Find(attr.name());\n    if (attr_value) {\n      Status status = AttrValueHasType(*attr_value, attr.type());\n      if (!status.ok()) {\n        errors::AppendToMessage(&status, \"for attr '\", attr.name(), \"'\");\n        return status;\n      }\n    } else if (!attr.has_default_value()) {\n      return errors::NotFound(\"Attr \", attr.name(), \" is not found from \",\n                              SummarizeOpDef(sig));\n    }\n  }\n\n// TODO(josh11b): Enable this code once it works with function gradients.\n// Right now the C++ function gradient code assumes it can pass\n// all the attrs of the function to the gradient, and any attrs that\n// the gradient doesn't care about will be ignored.\n#if 0\n  if (attr_values.size() != sig.attr_size()) {\n    for (const auto& a : attr_values) {\n      // TODO(josh11b): Possibly should ignore attrs that start with \"_\" here?\n      bool found = false;\n      for (const auto& s : sig.attr()) {\n        if (a.first == s.name()) {\n          found = true;\n          break;\n        }\n      }\n      if (!found) {\n        return errors::NotFound(\"Attr \", a.first, \" is not found in \",\n                                SummarizeOpDef(sig));\n      }\n    }\n  }\n#endif\n\n  return Status::OK();\n}\n\n// A helper class for instantiating functions. This contains shared information\n// like the resulting graph and node name index.\nclass FunctionInstantiationHelper {\n public:\n  FunctionInstantiationHelper(GetFunctionSignature get_function,\n                              InstantiationResult* result)\n      : get_function_(std ::move(get_function)), result_(*result) {\n    result_.nodes.clear();\n  }\n\n  // Builds index for nodes that can be used as node's input arguments.\n  // `resource_arg_unique_id`: if non-negative, will be populated to the\n  // \"_resource_arg_unique_id\" attribute of the arg node.\n  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }\n\n  Status BuildNodeOutputIndex(const NodeDef& node, AttrSlice attrs,\n                              const int arg_index) {\n    const OpDef* node_sig = nullptr;\n    TF_RETURN_IF_ERROR(get_function_(node.op(), &node_sig));\n    if (node_sig->output_arg_size() == 0) {\n      return AddItem(node.name(), {false, arg_index, 0, false, {}});\n    }\n    const int num_retval = node_sig->output_arg_size();\n    int start = 0;\n    bool is_type_list;\n    DataTypeVector dtypes;\n    for (int i = 0; i < num_retval; ++i) {\n      TF_RETURN_IF_ERROR(\n          ArgNumType(attrs, node_sig->output_arg(i), &is_type_list, &dtypes));\n      // Note that we rely on the backwards-compatibility test enforcing\n      // that output_arg(*).name() doesn't change here.\n      const string base_name =\n          strings::StrCat(node.name(), \":\", node_sig->output_arg(i).name());\n      TF_RETURN_IF_ERROR(\n          AddItem(base_name, {false, arg_index, start, is_type_list, dtypes}));\n      for (int j = 0; j < static_cast<int>(dtypes.size()); ++j) {\n        TF_RETURN_IF_ERROR(\n            AddItem(strings::StrCat(base_name, \":\", j),\n                    {false, arg_index, start + j, false, {dtypes[j]}}));\n      }\n      start += dtypes.size();\n    }\n    return Status::OK();\n  }\n\n  Status InstantiateNode(const NodeDef& fnode, AttrSlice attrs) {\n    const OpDef* fnode_sig = nullptr;\n    TF_CHECK_OK(get_function_(fnode.op(), &fnode_sig));\n    NodeDef* gnode = AddNode(fnode.name());\n    gnode->set_op(fnode.op());\n    gnode->set_device(fnode.device());\n    int gnode_idx = nodes_.size() - 1;\n\n    // Input\n    const int num_args = fnode_sig->input_arg_size();\n    bool is_type_list;  // ignored\n    DataTypeVector dtypes;\n    int fnode_arg_index = 0;\n    for (int i = 0; i < num_args; ++i) {\n      TF_RETURN_IF_ERROR(\n          ArgNumType(attrs, fnode_sig->input_arg(i), &is_type_list, &dtypes));\n      // Consume inputs (indexed by fnode_arg_index) until we have\n      // matched each element of dtypes (indexed by j).\n      for (size_t j = 0; j < dtypes.size(); ++fnode_arg_index) {\n        if (fnode_arg_index >= fnode.input_size()) {\n          // Should never happen if we computed dtypes correctly.\n          return errors::InvalidArgument(\n              \"Attempt to access beyond input size: \", fnode_arg_index,\n              \" >= \", fnode.input_size());\n        }\n        // Look up the next input.\n        const string& input_name = fnode.input(fnode_arg_index);\n        const auto* item = GetItemOrNull(input_name);\n        if (item == nullptr) {\n          return errors::InvalidArgument(\n              \"input \", input_name,\n              \" is not found: \", FormatNodeDefForError(fnode));\n        }\n        if (item->dtypes.size() > dtypes.size() - j) {\n          return errors::InvalidArgument(\"Input \", input_name, \" too long for \",\n                                         fnode_sig->input_arg(i).name());\n        }\n        // Match up all the elements of this input (indexed by k) with\n        // elements of dtypes (advancing j).\n        for (int k = 0; k < item->dtypes.size(); ++k, ++j) {\n          if (item->dtypes[k] != dtypes[j]) {\n            return errors::InvalidArgument(\n                \"input \", fnode_sig->input_arg(i).name(), \"[\", j,\n                \"] expected type \", DataTypeString(dtypes[j]),\n                \" != \", DataTypeString(item->dtypes[k]), \", the type of \",\n                input_name, \"[\", k, \"]\");\n          }\n          if (item->is_func_arg) {\n            AddInput(gnode_idx, item->nid + k, 0);\n          } else {\n            AddInput(gnode_idx, item->nid, item->idx + k);\n          }\n        }\n      }\n    }\n\n    // Control deps.\n    for (int i = fnode_arg_index; i < fnode.input_size(); ++i) {\n      const string& input = fnode.input(i);\n      if (input.empty() || input[0] != '^') {\n        return errors::InvalidArgument(\"Expected input[\", i, \"] == '\", input,\n                                       \"' to be a control input.\");\n      }\n      int nid = -1;\n      const string node_name = input.substr(1);\n      const string node_colon = node_name + \":\";\n      const string node_colon_bound = node_name + \";\";\n      // index_ is a map sorted lexicographically, so the key we are looking for\n      // must lie in the range [node_name, node_colon_bound).\n      auto it = index_.lower_bound(node_name);\n      while (it != index_.end() && it->first <= node_colon_bound) {\n        if (it->first == node_name || absl::StartsWith(it->first, node_colon)) {\n          nid = it->second.nid;\n          break;\n        }\n        ++it;\n      }\n      if (nid == -1) {\n        return errors::InvalidArgument(\"input[\", i, \"] == '\", input,\n                                       \"', is not found.\");\n      }\n      AddDep(gnode_idx, nid);\n    }\n\n    // Attrs.\n    for (const auto& p : attrs) {\n      (*gnode->mutable_attr())[p.first] = p.second;\n    }\n\n    // Experimental_debug_info.\n    if (fnode.has_experimental_debug_info()) {\n      gnode->mutable_experimental_debug_info()->MergeFrom(\n          fnode.experimental_debug_info());\n    }\n\n    // Tye info.\n    // TODO(mdan): Might this need adjustment at instantiation?\n    if (fnode.has_experimental_type()) {\n      *gnode->mutable_experimental_type() = fnode.experimental_type();\n    }\n\n    return Status::OK();\n  }\n\n  Status AddReturnNode(\n      const OpDef::ArgDef& ret_def, AttrSlice attrs,\n      const ::tensorflow::protobuf::Map<string, string>& ret_map,\n      bool ints_on_device, int* ret_index) {\n    auto ret_iter = ret_map.find(ret_def.name());\n    if (ret_iter == ret_map.end()) {\n      return errors::InvalidArgument(\"Return \", ret_def.name(), \" missing.\");\n    }\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(ArgNumType(attrs, ret_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    const auto* item = GetItemOrNull(ret_iter->second);\n    if (item == nullptr) {\n      return errors::InvalidArgument(\"Return \", ret_def.name(), \" -> \",\n                                     ret_iter->second, \" is not found.\");\n    }\n    if (dtypes != item->dtypes) {\n      return errors::InvalidArgument(\"Invalid ret types \", ret_def.name(),\n                                     \" : \", DataTypeVectorString(dtypes),\n                                     \" vs. \",\n                                     DataTypeVectorString(item->dtypes));\n    }\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      string name = strings::StrCat(ret_def.name(), \"_RetVal\");\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceRetOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kRetOp);\n      }\n      AddInput(nodes_.size() - 1, item->nid, item->idx + i);\n      DataType dtype = ret_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", (*ret_index)++, gnode);\n      result_.ret_types.push_back(dtypes[i]);\n    }\n    return Status::OK();\n  }\n\n  // Adds the actual node inputs to the result graph by converting indexes to\n  // the node names.\n  void AddNodeInputs() {\n    for (int i = 0; i < result_.nodes.size(); i++) {\n      NodeInfo& node_info = nodes_[i];\n      for (const auto& p : node_info.data_inputs) {\n        result_.nodes[i].add_input(Name(p.first, p.second));\n      }\n      for (int index : node_info.control_inputs) {\n        result_.nodes[i].add_input(Dep(index));\n      }\n    }\n  }\n\n private:\n  // This is used to build a small index for all names that can be used as a\n  // node's input arguments.\n  //\n  // If is_func_arg is true, the name is a function's argument.  In\n  // this case, the produced graph def has node[nid:nid + dtype.size()].\n  //\n  // Otherwise, the name is a function body's node return value.  In\n  // this case, the produced graph def has one node node[nid] and\n  // the node's output index [idx ... idx + num) corresponds to the\n  // named outputs.\n  //\n  // In all cases, \"dtype\" specifies the data type.\n  struct NameInfoItem {\n    bool is_func_arg;\n    int nid;\n    int idx;\n    bool is_type_list;\n    DataTypeVector dtypes;\n  };\n\n  // Adds an item into the input name index.\n  Status AddItem(const string& name, const NameInfoItem& item) {\n    if (!index_.insert({name, item}).second) {\n      return errors::InvalidArgument(\n          strings::StrCat(\"Duplicated \", item.is_func_arg ? \"arg\" : \"ret\",\n                          \" name: \"),\n          name);\n    }\n    return Status::OK();\n  }\n\n  const NameInfoItem* GetItemOrNull(const string& name) const {\n    return gtl::FindOrNull(index_, name);\n  }\n\n  string Dep(int node_index) const {\n    return strings::StrCat(\"^\", Name(node_index));\n  }\n\n  string Name(int node_index) const {\n    CHECK_LT(node_index, nodes_.size());\n    return nodes_[node_index].name;\n  }\n\n  string Name(int node_index, int output_index) const {\n    if (output_index == 0) {\n      return Name(node_index);\n    } else {\n      return strings::StrCat(Name(node_index), \":\", output_index);\n    }\n  }\n\n  NodeDef* AddNode(const string& name) {\n    result_.nodes.emplace_back();\n    NodeDef* gnode = &result_.nodes.back();\n    gnode->set_name(name);\n    nodes_.push_back({name, {}, {}});\n    CHECK_EQ(result_.nodes.size(), nodes_.size());\n    return gnode;\n  }\n\n  void AddInput(int node_index, int output_node, int output_index) {\n    CHECK_LT(node_index, nodes_.size());\n    nodes_[node_index].data_inputs.push_back(\n        std::make_pair(output_node, output_index));\n  }\n\n  void AddDep(int node_index, int dep_index) {\n    CHECK_LT(node_index, nodes_.size());\n    nodes_[node_index].control_inputs.push_back(dep_index);\n  }\n\n  GetFunctionSignature get_function_;\n  InstantiationResult& result_;\n  // A small index for all names that can be used as a node's input arguments.\n  std::map<string, NameInfoItem> index_;\n  // This contains information about a node in the new graph including the node\n  // names and input nodes' indexes.\n  struct NodeInfo {\n    string name;\n    // Data inputs where <n, k> means arg k of node n.\n    std::vector<std::pair<int, int>> data_inputs;\n    // Control inputs (dependencies).\n    std::vector<int> control_inputs;\n  };\n  // nodes_[i] is the information about result_.nodes[i].\n  std::vector<NodeInfo> nodes_;\n};\n\n// Various helpers Print(proto) to print relevant protos to ascii.\nstring Print(const OpDef::ArgDef& arg) {\n  string out;\n  strings::StrAppend(&out, arg.name(), \":\");\n  if (arg.is_ref()) strings::StrAppend(&out, \"Ref(\");\n  if (!arg.number_attr().empty()) {\n    strings::StrAppend(&out, arg.number_attr(), \"*\");\n  }\n  if (arg.type() != DT_INVALID) {\n    strings::StrAppend(&out, DataTypeString(arg.type()));\n  } else {\n    strings::StrAppend(&out, arg.type_attr());\n  }\n  if (arg.is_ref()) strings::StrAppend(&out, \")\");\n  return out;\n}\n\n// TODO(josh11b): Merge this with SummarizeAttrValue().\n// When hash_string_attrs = true, string attributes are hashed instead of being\n// truncated with ellipses. This is done to reduce the chance of collisions when\n// looking up functions using the canonical representation.\nstring Print(const AttrValue& attr_value,\n             const bool hash_string_attrs = false) {\n  if (attr_value.value_case() == AttrValue::kType) {\n    return DataTypeString(attr_value.type());\n  } else if ((attr_value.value_case() == AttrValue::kList) &&\n             (attr_value.list().type_size() > 0)) {\n    string ret = \"{\";\n    for (int i = 0; i < attr_value.list().type_size(); ++i) {\n      if (i > 0) strings::StrAppend(&ret, \", \");\n      strings::StrAppend(&ret, DataTypeString(attr_value.list().type(i)));\n    }\n    strings::StrAppend(&ret, \"}\");\n    return ret;\n  } else if (attr_value.value_case() == AttrValue::kFunc) {\n    if (attr_value.func().attr_size() == 0) {\n      return attr_value.func().name();\n    }\n    std::vector<string> entries;\n    for (const auto& p : attr_value.func().attr()) {\n      entries.push_back(strings::StrCat(p.first, \"=\", Print(p.second)));\n    }\n    std::sort(entries.begin(), entries.end());\n    return strings::StrCat(attr_value.func().name(), \"[\",\n                           absl::StrJoin(entries, \", \"), \"]\");\n  } else if (attr_value.value_case() == AttrValue::kS && hash_string_attrs) {\n    return strings::StrCat(Fingerprint64(attr_value.s()));\n  }\n  return SummarizeAttrValue(attr_value);\n}\n\n// TODO(josh11b): Merge this with SummarizeNodeDef().\nstring Print(const NodeDef& n) {\n  string out;\n  strings::StrAppend(&out, n.name(), \" = \", n.op());\n  if (n.attr_size() > 0) {\n    std::vector<string> entries;\n    for (auto& a : n.attr()) {\n      entries.push_back(strings::StrCat(a.first, \"=\", Print(a.second)));\n    }\n    std::sort(entries.begin(), entries.end());\n    // Add a short device string at the end of all attributes.\n    if (!n.device().empty()) {\n      DeviceNameUtils::ParsedName parsed;\n      if (DeviceNameUtils::ParseFullName(n.device(), &parsed)) {\n        entries.push_back(\n            strings::StrCat(\"device=\", parsed.type, \":\", parsed.id));\n      } else {\n        entries.push_back(\"device=<FAILED_TO_PARSE>\");\n      }\n    }\n    strings::StrAppend(&out, \"[\", absl::StrJoin(entries, \", \"), \"]\");\n  }\n  strings::StrAppend(&out, \"(\");\n  std::vector<StringPiece> dat;\n  std::vector<string> dep;\n  for (StringPiece s : n.input()) {\n    if (absl::ConsumePrefix(&s, \"^\")) {\n      dep.emplace_back(s);\n    } else {\n      dat.push_back(s);\n    }\n  }\n  strings::StrAppend(&out, absl::StrJoin(dat, \", \"), \")\");\n  if (!dep.empty()) {\n    strings::StrAppend(&out, \" @ \", absl::StrJoin(dep, \", \"));\n  }\n  return out;\n}\n\nstring Print(const FunctionDef& fdef) {\n  string out;\n  const OpDef& sig = fdef.signature();\n  strings::StrAppend(&out, \"\\n\", sig.name());\n  if (sig.attr_size() > 0) {\n    strings::StrAppend(&out, \"[\");\n    for (int i = 0; i < sig.attr_size(); ++i) {\n      const auto& a = sig.attr(i);\n      if (i > 0) strings::StrAppend(&out, \", \");\n      if (a.type() == \"type\") {\n        strings::StrAppend(&out, a.name(), \":\", Print(a.allowed_values()));\n      } else {\n        strings::StrAppend(&out, a.name(), \":\", a.type());\n      }\n    }\n    strings::StrAppend(&out, \"]\");\n  }\n  strings::StrAppend(&out, \"(\");\n  for (int i = 0; i < sig.input_arg_size(); ++i) {\n    if (i > 0) strings::StrAppend(&out, \", \");\n    strings::StrAppend(&out, Print(sig.input_arg(i)));\n  }\n  strings::StrAppend(&out, \") -> (\");\n  for (int i = 0; i < sig.output_arg_size(); ++i) {\n    if (i > 0) strings::StrAppend(&out, \", \");\n    strings::StrAppend(&out, Print(sig.output_arg(i)));\n  }\n  strings::StrAppend(&out, \") {\\n\");\n  for (const auto& n : fdef.node_def()) {\n    strings::StrAppend(&out, \"  \", Print(n), \"\\n\");\n  }\n  for (const auto& cr : fdef.control_ret()) {\n    strings::StrAppend(&out, \"  @return \", cr.first, \" = \", cr.second, \"\\n\");\n  }\n  for (const auto& r : fdef.ret()) {\n    strings::StrAppend(&out, \"  return \", r.first, \" = \", r.second, \"\\n\");\n  }\n  strings::StrAppend(&out, \"}\\n\");\n  return out;\n}\n\nstring Print(gtl::ArraySlice<const NodeDef*> nodes) {\n  std::vector<const NodeDef*> arg;\n  std::vector<const NodeDef*> ret;\n  std::vector<const NodeDef*> body;\n  for (const NodeDef* n : nodes) {\n    if (n->op() == FunctionLibraryDefinition::kArgOp ||\n        n->op() == FunctionLibraryDefinition::kDeviceArgOp) {\n      arg.push_back(n);\n    } else if (n->op() == FunctionLibraryDefinition::kRetOp ||\n               n->op() == FunctionLibraryDefinition::kDeviceRetOp) {\n      ret.push_back(n);\n    } else {\n      body.push_back(n);\n    }\n  }\n  auto comp = [](const NodeDef* x, const NodeDef* y) {\n    int xi;\n    TF_CHECK_OK(GetNodeAttr(*x, \"index\", &xi));\n    int yi;\n    TF_CHECK_OK(GetNodeAttr(*y, \"index\", &yi));\n    return xi < yi;\n  };\n  std::sort(arg.begin(), arg.end(), comp);\n  std::sort(ret.begin(), ret.end(), comp);\n  string out;\n  strings::StrAppend(&out, \"\\n(\");\n  auto get_type_and_device = [](const NodeDef& n) {\n    DataType dt;\n    if (!TryGetNodeAttr(n, \"T\", &dt)) {\n      dt = DT_INVALID;\n    }\n    if (!n.device().empty()) {\n      DeviceNameUtils::ParsedName parsed;\n      if (DeviceNameUtils::ParseFullName(n.device(), &parsed)) {\n        return strings::StrCat(DataTypeString(dt), \"@\", parsed.type, \":\",\n                               parsed.id);\n      } else {\n        LOG(WARNING) << \"Failed to parse device \\\"\" << n.device() << \"\\\" in \"\n                     << n.op() << \":\" << n.name();\n        return strings::StrCat(DataTypeString(dt), \"@\",\n                               \"<FAILED_TO_PARSE_DEVICE>\");\n      }\n    }\n    return DataTypeString(dt);\n  };\n  for (size_t i = 0; i < arg.size(); ++i) {\n    const NodeDef* n = arg[i];\n    if (i > 0) strings::StrAppend(&out, \", \");\n    CHECK_GE(n->attr_size(), 2);\n    strings::StrAppend(&out, n->name(), \":\", get_type_and_device(*n));\n  }\n  strings::StrAppend(&out, \") -> (\");\n  for (size_t i = 0; i < ret.size(); ++i) {\n    const NodeDef* n = ret[i];\n    if (i > 0) strings::StrAppend(&out, \", \");\n    CHECK_LE(2, n->attr_size());\n\n    // The _RetVal op should have a unique non-control input. We assert that\n    // here and add it to the output.\n    bool found_non_control_input = false;\n    for (const string& input : n->input()) {\n      if (!input.empty() && input[0] != '^') {\n        DCHECK_EQ(found_non_control_input, false)\n            << \"RetVal node has more than one non-control input: \"\n            << absl::StrJoin(n->input(), \", \");\n        strings::StrAppend(&out, n->input(0), \":\", get_type_and_device(*n));\n        found_non_control_input = true;\n      }\n    }\n    DCHECK_EQ(found_non_control_input, true)\n        << \"RetVal did not have any non-control inputs: \"\n        << absl::StrJoin(n->input(), \", \");\n  }\n  strings::StrAppend(&out, \") {\\n\");\n  for (size_t i = 0; i < body.size(); ++i) {\n    strings::StrAppend(&out, \"  \", Print(*body[i]), \"\\n\");\n  }\n  strings::StrAppend(&out, \"}\\n\");\n  return out;\n}\n\nStatus AddDefaultAttrs(const string& op,\n                       const GetFunctionSignature& get_function,\n                       AttrValueMap* attrs) {\n  const OpDef* op_def = nullptr;\n  TF_RETURN_IF_ERROR(get_function(op, &op_def));\n  AttrSlice attr_slice(attrs);\n  for (const auto& attr_def : op_def->attr()) {\n    if (attr_def.has_default_value() && !attr_slice.Find(attr_def.name())) {\n      if (!attrs->insert({attr_def.name(), attr_def.default_value()}).second) {\n        return errors::Internal(\"Somehow duplicated: \", attr_def.name());\n      }\n    }\n  }\n  return Status::OK();\n}\n\n}  // end namespace\n\nStatus InstantiateFunction(const FunctionDef& fdef, AttrSlice attr_values,\n                           GetFunctionSignature get_function,\n                           InstantiationResult* result) {\n  if (VLOG_IS_ON(5)) {\n    const auto& signature = fdef.signature();\n    VLOG(5) << \"Instantiate function definition: name=\" << signature.name()\n            << \" #input_args=\" << signature.input_arg_size()\n            << \" #output_args=\" << signature.output_arg_size()\n            << \" #control_output=\" << signature.control_output_size();\n    for (const auto& line : str_util::Split(Print(fdef), '\\n')) {\n      VLOG(5) << \"|| \" << line;\n    }\n  }\n\n  const OpDef& sig = fdef.signature();\n  TF_RETURN_IF_ERROR(ValidateSignatureWithAttrs(sig, attr_values));\n\n  bool ints_on_device =\n      fdef.attr().count(FunctionLibraryDefinition::kIntsOnDeviceAttr) != 0 &&\n      fdef.attr().at(FunctionLibraryDefinition::kIntsOnDeviceAttr).b();\n\n  FunctionInstantiationHelper helper(get_function, result);\n  Status s;\n  for (int i = 0, e = sig.input_arg_size(); i < e; ++i) {\n    const OpDef::ArgDef& arg_def = sig.input_arg(i);\n    auto it = fdef.arg_attr().find(i);\n    const FunctionDef::ArgAttrs* arg_attrs =\n        it != fdef.arg_attr().end() ? &it->second : nullptr;\n    auto resource_id_it = fdef.resource_arg_unique_id().find(i);\n    int64_t resource_arg_unique_id =\n        resource_id_it != fdef.resource_arg_unique_id().end()\n            ? resource_id_it->second\n            : -1LL;\n    s = helper.BuildInputArgIndex(arg_def, attr_values, arg_attrs,\n                                  ints_on_device, resource_arg_unique_id);\n\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \", Print(arg_def));\n      return s;\n    }\n  }\n\n  auto substitute = [attr_values, &sig](StringPiece name, AttrValue* val) {\n    // Look for a specified value...\n    if (const AttrValue* v = attr_values.Find(name)) {\n      *val = *v;\n      return true;\n    }\n    // .. and if not, then check for a default value.\n    if (const OpDef::AttrDef* attr = FindAttr(name, sig)) {\n      if (attr->has_default_value()) {\n        *val = attr->default_value();\n        return true;\n      }\n    }\n    // No luck finding a substitution.\n    return false;\n  };\n\n  // Makes a copy of all attrs in fdef and substitutes placeholders.\n  // After this step, every attr is bound to a concrete value.\n  std::vector<AttrValueMap> node_attrs;\n  node_attrs.resize(fdef.node_def_size());\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    for (auto attr : fdef.node_def(i).attr()) {\n      if (!SubstitutePlaceholders(substitute, &attr.second)) {\n        return errors::InvalidArgument(\"Failed to bind all placeholders in \",\n                                       SummarizeAttrValue(attr.second));\n      }\n      if (!node_attrs[i].insert(attr).second) {\n        return errors::Internal(\"Somehow duplicated: \", attr.first);\n      }\n    }\n    TF_RETURN_IF_ERROR(\n        AddDefaultAttrs(fdef.node_def(i).op(), get_function, &node_attrs[i]));\n  }\n\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    s = helper.BuildNodeOutputIndex(fdef.node_def(i), AttrSlice(&node_attrs[i]),\n                                    result->nodes.size() + i);\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \",\n                              FormatNodeDefForError(fdef.node_def(i)));\n      return s;\n    }\n  }\n  // Emits one node for each fdef.node_def.\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    s = helper.InstantiateNode(fdef.node_def(i), AttrSlice(&node_attrs[i]));\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \",\n                              FormatNodeDefForError(fdef.node_def(i)));\n      return s;\n    }\n  }\n\n  // Emits nodes for the function's return values.\n  int ret_index = 0;\n  for (const OpDef::ArgDef& ret_def : sig.output_arg()) {\n    s = helper.AddReturnNode(ret_def, attr_values, fdef.ret(), ints_on_device,\n                             &ret_index);\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In function output \", Print(ret_def));\n      return s;\n    }\n  }\n\n  // Adds the actual node inputs using the input indexes.\n  helper.AddNodeInputs();\n\n  return Status::OK();\n}\n\nstring DebugString(const FunctionDef& func_def) { return Print(func_def); }\n\nstring DebugString(const GraphDef& instantiated_func_def) {\n  std::vector<const NodeDef*> ptrs;\n  for (const NodeDef& n : instantiated_func_def.node()) {\n    ptrs.push_back(&n);\n  }\n  return Print(ptrs);\n}\n\nstring DebugString(gtl::ArraySlice<NodeDef> instantiated_func_nodes) {\n  std::vector<const NodeDef*> ptrs;\n  for (const NodeDef& n : instantiated_func_nodes) {\n    ptrs.push_back(&n);\n  }\n  return Print(ptrs);\n}\n\nstring DebugStringWhole(const GraphDef& gdef) {\n  string ret;\n  for (const auto& fdef : gdef.library().function()) {\n    strings::StrAppend(&ret, Print(fdef));\n  }\n  strings::StrAppend(&ret, \"\\n\");\n  for (const auto& ndef : gdef.node()) {\n    strings::StrAppend(&ret, Print(ndef), \"\\n\");\n  }\n  return ret;\n}\n\nnamespace {\n\n// Returns the name -> attr mapping of fdef's attrs that have a value set. In\n// Python, it's possible to access unset attrs, which returns a default value\n// and adds an unset attr to the map.\nstd::map<string, AttrValue> GetSetAttrs(const FunctionDef& fdef) {\n  std::map<string, AttrValue> set_attrs;\n  for (const auto& pair : fdef.attr()) {\n    if (pair.second.value_case() != AttrValue::VALUE_NOT_SET) {\n      set_attrs[pair.first] = pair.second;\n    }\n  }\n  return set_attrs;\n}\n\n}  // end namespace\n\nbool FunctionDefsEqual(const FunctionDef& f1, const FunctionDef& f2) {\n  if (!OpDefEqual(f1.signature(), f2.signature())) return false;\n\n  std::map<string, AttrValue> f1_attrs = GetSetAttrs(f1);\n  std::map<string, AttrValue> f2_attrs = GetSetAttrs(f2);\n  if (f1_attrs.size() != f2_attrs.size()) return false;\n  for (const auto& iter1 : f1_attrs) {\n    auto iter2 = f2_attrs.find(iter1.first);\n    if (iter2 == f2_attrs.end()) return false;\n    if (!AreAttrValuesEqual(iter1.second, iter2->second)) return false;\n  }\n\n  if (!EqualRepeatedNodeDef(f1.node_def(), f2.node_def(), nullptr)) {\n    return false;\n  }\n\n  std::map<string, string> ret1(f1.ret().begin(), f1.ret().end());\n  std::map<string, string> ret2(f2.ret().begin(), f2.ret().end());\n  if (ret1 != ret2) return false;\n\n  std::map<string, string> control_ret1(f1.control_ret().begin(),\n                                        f1.control_ret().end());\n  std::map<string, string> control_ret2(f2.control_ret().begin(),\n                                        f2.control_ret().end());\n  if (control_ret1 != control_ret2) return false;\n\n  return true;\n}\n\nuint64 FunctionDefHash(const FunctionDef& fdef) {\n  // signature\n  uint64 h = OpDefHash(fdef.signature());\n\n  // attrs\n  std::map<string, AttrValue> attrs = GetSetAttrs(fdef);\n  for (const auto& p : attrs) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64Combine(AttrValueHash(p.second), h);\n  }\n\n  // node defs\n  h = Hash64Combine(RepeatedNodeDefHash(fdef.node_def()), h);\n\n  // output names\n  std::map<string, string> ret(fdef.ret().begin(), fdef.ret().end());\n  for (const auto& p : ret) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64(p.second.data(), p.second.size(), h);\n  }\n\n  // control output names\n  std::map<string, string> control_ret(fdef.control_ret().begin(),\n                                       fdef.control_ret().end());\n  for (const auto& p : control_ret) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64(p.second.data(), p.second.size(), h);\n  }\n\n  return h;\n}\n\nstatic constexpr const char* const kExecutorAttr = \"_executor\";\n\n/* static */\nstring FunctionLibraryRuntime::ExecutorType(const InstantiateOptions& options,\n                                            AttrSlice attrs) {\n  if (!options.executor_type.empty()) {\n    return options.executor_type;\n  } else if (const AttrValue* executor_attr = attrs.Find(kExecutorAttr)) {\n    return executor_attr->s();\n  } else {\n    return string();\n  }\n}\n\nnamespace {\nclass AttrKeyAndValue {\n public:\n  enum ValueRepresentationOp {\n    kRaw,\n    kCEscape,\n  };\n  AttrKeyAndValue(absl::string_view key_name, int key_suffix, string value,\n                  ValueRepresentationOp value_op = kRaw)\n      : key_name_(key_name),\n        key_suffix_(key_suffix),\n        value_op_(value_op),\n        value_(std::move(value)) {}\n\n  bool operator<(const AttrKeyAndValue& b) const {\n    if (key_name_ != b.key_name_) {\n      return key_name_ < b.key_name_;\n    } else if (key_suffix_ != b.key_suffix_) {\n      return key_suffix_ < b.key_suffix_;\n    } else {\n      return value_ < b.value_;\n    }\n  }\n\n  void AppendTo(bool first, string* s) const {\n    absl::string_view v;\n    bool add_escaped = false;\n    if ((value_op_ == kCEscape) && NeedsEscaping(value_)) {\n      // Use CEscape call below\n      add_escaped = true;\n    } else {\n      // Add raw value contents directly\n      v = value_;\n    }\n    if (key_suffix_ >= 0) {\n      strings::StrAppend(s, first ? \"\" : \",\", key_name_, key_suffix_, \"=\", v);\n    } else {\n      strings::StrAppend(s, first ? \"\" : \",\", key_name_, \"=\", v);\n    }\n    if (add_escaped) {\n      strings::StrAppend(s, absl::CEscape(value_));\n    }\n  }\n\n private:\n  static bool NeedsEscaping(const string& s) {\n    for (auto c : s) {\n      if (!isalnum(c) && (c != ' ')) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  absl::string_view key_name_;\n  int key_suffix_;  // -1 if missing\n  ValueRepresentationOp value_op_;\n  string value_;\n};\n}  // namespace\n\nstring GetFunctionResourceInputDevice(\n    const Tensor& input, const int arg_index, const FunctionDef& function_def,\n    absl::flat_hash_map<string, std::vector<string>>* composite_devices) {\n  const auto& handles = input.flat<ResourceHandle>();\n  const ResourceHandle& handle0 = handles(0);\n  string composite_device;\n  auto iter = function_def.arg_attr().find(arg_index);\n  if (iter != function_def.arg_attr().end()) {\n    auto arg_attr = iter->second.attr().find(\"_composite_device\");\n    if (arg_attr != iter->second.attr().end()) {\n      composite_device = arg_attr->second.s();\n    }\n  }\n  if (!composite_device.empty()) {\n    if (composite_devices->find(composite_device) == composite_devices->end()) {\n      for (int i = 0; i < handles.size(); ++i) {\n        (*composite_devices)[composite_device].push_back(handles(i).device());\n      }\n    }\n    return composite_device;\n  } else {\n    return handle0.device();\n  }\n}\n\nstring Canonicalize(const string& funcname, AttrSlice attrs,\n                    const FunctionLibraryRuntime::InstantiateOptions& options) {\n  absl::InlinedVector<AttrKeyAndValue, 8> entries;\n  entries.reserve(attrs.size() + static_cast<int>(!options.target.empty()) +\n                  options.input_devices.size());\n  for (const auto& p : attrs) {\n    if (p.first != kExecutorAttr) {\n      entries.push_back(AttrKeyAndValue(\n          p.first, -1, Print(p.second, /*hash_string_attrs=*/true)));\n    }\n  }\n  if (!options.target.empty()) {\n    entries.push_back(AttrKeyAndValue(\"_target\", -1, options.target,\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (int i = 0; i < options.input_devices.size(); ++i) {\n    entries.push_back(AttrKeyAndValue(\"_input_dev\", i, options.input_devices[i],\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (int i = 0; i < options.output_devices.size(); ++i) {\n    entries.push_back(AttrKeyAndValue(\"_output_dev\", i,\n                                      options.output_devices[i],\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (const auto& iter : options.input_resource_dtypes_and_shapes) {\n    entries.push_back(AttrKeyAndValue(\"_input_resource_dtype\", iter.first,\n                                      DataTypeString(iter.second.dtype)));\n    entries.push_back(AttrKeyAndValue(\"_input_resource_shape\", iter.first,\n                                      iter.second.shape.DebugString(),\n                                      AttrKeyAndValue::kCEscape));\n  }\n  if (options.lib_def) {\n    entries.push_back(AttrKeyAndValue(\n        \"_lib_def\", -1,\n        absl::StrCat(\"\", reinterpret_cast<uintptr_t>(options.lib_def))));\n  }\n  if (!options.state_handle.empty()) {\n    entries.push_back(\n        AttrKeyAndValue(\"_state_handle\", -1, options.state_handle));\n  }\n  string executor_type = FunctionLibraryRuntime::ExecutorType(options, attrs);\n  if (!executor_type.empty()) {\n    entries.push_back(AttrKeyAndValue(kExecutorAttr, -1, executor_type));\n  }\n  if (options.config_proto.ByteSize() > 0) {\n    string config_proto_serialized;\n    SerializeToStringDeterministic(options.config_proto,\n                                   &config_proto_serialized);\n    entries.push_back(AttrKeyAndValue(\"_config_proto\", -1,\n                                      config_proto_serialized,\n                                      AttrKeyAndValue::kCEscape));\n  }\n  std::sort(entries.begin(), entries.end());\n  string result = strings::StrCat(funcname, \"[\");\n  bool first = true;\n  for (const auto& entry : entries) {\n    entry.AppendTo(first, &result);\n    first = false;\n  }\n  result += \"]\";\n  return result;\n}\n\nstring Canonicalize(const string& funcname, AttrSlice attrs) {\n  static const FunctionLibraryRuntime::InstantiateOptions* kEmptyOptions =\n      new FunctionLibraryRuntime::InstantiateOptions;\n  return Canonicalize(funcname, attrs, *kEmptyOptions);\n}\n\nFunctionCallFrame::FunctionCallFrame(DataTypeSlice arg_types,\n                                     DataTypeSlice ret_types)\n    : arg_types_(arg_types.begin(), arg_types.end()),\n      ret_types_(ret_types.begin(), ret_types.end()) {\n  args_.resize(arg_types_.size());\n  rets_.resize(ret_types_.size());\n}\n\nFunctionCallFrame::~FunctionCallFrame() {}\n\nStatus FunctionCallFrame::SetArgs(gtl::ArraySlice<Tensor> args) {\n  // Input type checks.\n  if (args.size() != arg_types_.size()) {\n    return errors::InvalidArgument(\"Expects \", arg_types_.size(),\n                                   \" arguments, but \", args.size(),\n                                   \" is provided\");\n  }\n  for (size_t i = 0; i < args.size(); ++i) {\n    if (arg_types_[i] != args[i].dtype()) {\n      return errors::InvalidArgument(\n          \"Expects arg[\", i, \"] to be \", DataTypeString(arg_types_[i]), \" but \",\n          DataTypeString(args[i].dtype()), \" is provided\");\n    }\n    args_[i] = args[i];\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::GetRetvals(std::vector<Tensor>* rets) const {\n  rets->clear();\n  rets->reserve(rets_.size());\n  for (size_t i = 0; i < rets_.size(); ++i) {\n    const auto& item = rets_[i];\n    if (item.has_val) {\n      rets->push_back(item.val);\n    } else {\n      return errors::Internal(\"Retval[\", i, \"] does not have value\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::ConsumeRetvals(std::vector<Tensor>* rets,\n                                         bool allow_dead_tensors) {\n  rets->clear();\n  rets->reserve(rets_.size());\n  for (size_t i = 0; i < rets_.size(); ++i) {\n    if (rets_[i].has_val) {\n      rets->emplace_back(std::move(rets_[i].val));\n    } else if (allow_dead_tensors) {\n      rets->emplace_back();\n    } else {\n      return errors::Internal(\"Retval[\", i, \"] does not have value\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::GetArg(int index, const Tensor** val) {\n  if (index < 0 || static_cast<size_t>(index) >= args_.size()) {\n    return errors::InvalidArgument(\"GetArg \", index, \" is not within [0, \",\n                                   args_.size(), \")\");\n  }\n  *val = &args_[index];\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::SetRetval(int index, const Tensor& val) {\n  if (index < 0 || static_cast<size_t>(index) >= rets_.size()) {\n    return errors::InvalidArgument(\"SetRetval \", index, \" is not within [0, \",\n                                   rets_.size(), \")\");\n  }\n  if (val.dtype() != ret_types_[index]) {\n    return errors::InvalidArgument(\n        \"Expects ret[\", index, \"] to be \", DataTypeString(ret_types_[index]),\n        \", but \", DataTypeString(val.dtype()), \" is provided.\");\n  }\n  Retval* item = &rets_[index];\n  if (!item->has_val) {\n    item->has_val = true;\n    item->val = val;\n  } else {\n    return errors::Internal(\"Retval[\", index, \"] has already been set.\");\n  }\n  return Status::OK();\n}\n\nFunctionLibraryDefinition::FunctionDefAndOpRegistration::\n    FunctionDefAndOpRegistration(const FunctionDef& fdef_in,\n                                 const StackTracesMap& stack_traces)\n    : fdef(fdef_in),\n      // Exact shape inference for functions is handled by ShapeRefiner.\n      // Here we pass a dummy shape inference function for legacy code paths.\n      op_registration_data(fdef.signature(), shape_inference::UnknownShape,\n                           true /* is_function */),\n      stack_traces(stack_traces) {}\n\nFunctionLibraryDefinition::FunctionLibraryDefinition(\n    const FunctionLibraryDefinition& other)\n    : default_registry_(other.default_registry_) {\n  tf_shared_lock l(other.mu_);\n  function_defs_ = other.function_defs_;\n  func_grad_ = other.func_grad_;\n}\n\nFunctionLibraryDefinition::FunctionLibraryDefinition(\n    const OpRegistryInterface* default_registry,\n    const FunctionDefLibrary& def_lib)\n    : default_registry_(default_registry),\n      function_defs_(def_lib.function_size()) {\n  for (const auto& fdef : def_lib.function()) {\n    // The latter function definition wins.\n    auto& ptr = function_defs_[fdef.signature().name()];\n    ptr.reset(new FunctionDefAndOpRegistration(fdef));\n  }\n  for (const auto& grad : def_lib.gradient()) {\n    func_grad_[grad.function_name()] = grad.gradient_func();\n  }\n}\n\nFunctionLibraryDefinition::~FunctionLibraryDefinition() {}\n\nbool FunctionLibraryDefinition::Contains(const string& func) const {\n  tf_shared_lock l(mu_);\n  return function_defs_.find(func) != function_defs_.end();\n}\n\nconst FunctionDef* FunctionLibraryDefinition::Find(const string& func) const {\n  tf_shared_lock l(mu_);\n  auto result = FindHelper(func);\n  if (result) {\n    return &result->fdef;\n  } else {\n    return nullptr;\n  }\n}\n\nstd::shared_ptr<FunctionLibraryDefinition::FunctionDefAndOpRegistration>\nFunctionLibraryDefinition::FindHelper(const string& func) const {\n  auto iter = function_defs_.find(func);\n  if (iter == function_defs_.end()) {\n    return nullptr;\n  } else {\n    return iter->second;\n  }\n}\n\nStatus FunctionLibraryDefinition::AddFunctionDef(\n    const FunctionDef& fdef, const StackTracesMap& stack_traces) {\n  mutex_lock l(mu_);\n  bool added;\n  return AddFunctionDefHelper(fdef, stack_traces, &added);\n}\n\nStatus FunctionLibraryDefinition::AddFunctionDefHelper(\n    const FunctionDef& fdef, const StackTracesMap& stack_traces, bool* added) {\n  *added = false;\n  std::shared_ptr<FunctionDefAndOpRegistration>& entry =\n      function_defs_[fdef.signature().name()];\n  if (entry) {\n    if (!FunctionDefsEqual(entry->fdef, fdef)) {\n      return errors::InvalidArgument(\n          \"Cannot add function '\", fdef.signature().name(),\n          \"' because a different function with the same name already \"\n          \"exists.\");\n    }\n    // Ignore duplicate FunctionDefs.\n    return Status::OK();\n  }\n  const OpDef* op_def;\n  if (default_registry_->LookUpOpDef(fdef.signature().name(), &op_def).ok()) {\n    return errors::InvalidArgument(\n        \"Cannot add function '\", fdef.signature().name(),\n        \"' because an op with the same name already exists.\");\n  }\n  entry = std::make_shared<FunctionDefAndOpRegistration>(fdef, stack_traces);\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddHelper(\n    std::shared_ptr<FunctionDefAndOpRegistration> registration, bool* added) {\n  *added = false;\n  std::shared_ptr<FunctionDefAndOpRegistration>& entry =\n      function_defs_[registration->fdef.signature().name()];\n  if (entry) {\n    if (!FunctionDefsEqual(entry->fdef, registration->fdef)) {\n      return errors::InvalidArgument(\n          \"Cannot add function '\", registration->fdef.signature().name(),\n          \"' because a different function with the same name already \"\n          \"exists.\");\n    }\n    // Ignore duplicate FunctionDefs.\n    return Status::OK();\n  }\n  const OpDef* op_def;\n  if (default_registry_\n          ->LookUpOpDef(registration->fdef.signature().name(), &op_def)\n          .ok()) {\n    return errors::InvalidArgument(\n        \"Cannot add function '\", registration->fdef.signature().name(),\n        \"' because an op with the same name already exists.\");\n  }\n  entry = std::move(registration);\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::CopyFunctionDefFrom(\n    const string& func, const FunctionLibraryDefinition& other) {\n  if (default_registry_ != other.default_registry_) {\n    return errors::InvalidArgument(\n        \"Cannot copy function '\", func,\n        \"' because CopyFunctionDefFrom() requires that both libraries have the \"\n        \"same default registry.\");\n  }\n  std::shared_ptr<FunctionDefAndOpRegistration> function_def;\n  {\n    tf_shared_lock l(other.mu_);\n    function_def = other.FindHelper(func);\n  }\n  if (!function_def) {\n    return errors::InvalidArgument(\n        \"Cannot copy function '\", func,\n        \"' because no function with that name exists in the other library.\");\n  }\n  {\n    mutex_lock l(mu_);\n    std::shared_ptr<FunctionDefAndOpRegistration>& entry = function_defs_[func];\n    if (entry) {\n      if (!FunctionDefsEqual(entry->fdef, function_def->fdef)) {\n        return errors::InvalidArgument(\n            \"Cannot copy function '\", func,\n            \"' because a different function with the same name already \"\n            \"exists.\");\n      }\n    } else {\n      entry = std::move(function_def);\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddGradientDef(const GradientDef& grad) {\n  mutex_lock l(mu_);\n  bool added;\n  return AddGradientDefHelper(grad, &added);\n}\n\nStatus FunctionLibraryDefinition::AddGradientDefHelper(const GradientDef& grad,\n                                                       bool* added) {\n  *added = false;\n  string* entry = &func_grad_[grad.function_name()];\n  if (!entry->empty()) {\n    if (*entry != grad.gradient_func()) {\n      return errors::InvalidArgument(\n          \"Cannot assign gradient function '\", grad.gradient_func(), \"' to '\",\n          grad.function_name(), \"' because it already has gradient function \",\n          \"'\", *entry, \"'\");\n    }\n    // Ignore duplicate GradientDefs\n    return Status::OK();\n  }\n  *entry = grad.gradient_func();\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddLibrary(\n    const FunctionLibraryDefinition& other) {\n  // Clone `other` to ensure thread-safety (grabbing `other`'s lock for\n  // the duration of the function could lead to deadlock).\n  FunctionLibraryDefinition clone(other);\n  mutex_lock l(mu_);\n  mutex_lock l2(clone.mu_);\n  // Remember the funcs and grads that we added successfully so that\n  // we can roll them back on error.\n  std::vector<string> funcs;\n  std::vector<string> funcs_with_grads;\n  Status s;\n  bool added;\n  for (auto iter : clone.function_defs_) {\n    s = AddHelper(iter.second, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs.push_back(iter.second->fdef.signature().name());\n    }\n  }\n  for (auto iter : clone.func_grad_) {\n    GradientDef grad;\n    grad.set_function_name(iter.first);\n    grad.set_gradient_func(iter.second);\n    s = AddGradientDefHelper(grad, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs_with_grads.push_back(grad.function_name());\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddLibrary(\n    const FunctionDefLibrary& lib_def) {\n  // Remember the funcs and grads that we added successfully so that\n  // we can roll them back on error.\n  mutex_lock l(mu_);\n  std::vector<string> funcs;\n  std::vector<string> funcs_with_grads;\n  Status s;\n  bool added;\n  for (const FunctionDef& fdef : lib_def.function()) {\n    s = AddFunctionDefHelper(fdef, /*stack_traces=*/{}, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs.push_back(fdef.signature().name());\n    }\n  }\n  for (const GradientDef& grad : lib_def.gradient()) {\n    s = AddGradientDefHelper(grad, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs_with_grads.push_back(grad.function_name());\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::ReplaceFunction(\n    const string& func, const FunctionDef& fdef,\n    const StackTracesMap& stack_traces) {\n  mutex_lock l(mu_);\n  bool added;\n  TF_RETURN_IF_ERROR(RemoveFunctionHelper(func));\n  TF_RETURN_IF_ERROR(AddFunctionDefHelper(fdef, stack_traces, &added));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::ReplaceGradient(const GradientDef& grad) {\n  mutex_lock l(mu_);\n  bool added;\n  TF_RETURN_IF_ERROR(RemoveGradient(grad.function_name()));\n  TF_RETURN_IF_ERROR(AddGradientDefHelper(grad, &added));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::RemoveFunction(const string& func) {\n  mutex_lock l(mu_);\n  TF_RETURN_IF_ERROR(RemoveFunctionHelper(func));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::RemoveFunctionHelper(const string& func) {\n  const auto& i = function_defs_.find(func);\n  if (i == function_defs_.end()) {\n    return errors::InvalidArgument(\"Tried to remove non-existent function '\",\n                                   func, \"'.\");\n  }\n  function_defs_.erase(i);\n  return Status::OK();\n}\n\nvoid FunctionLibraryDefinition::Clear() {\n  mutex_lock l(mu_);\n  function_defs_.clear();\n  func_grad_.clear();\n}\n\nStatus FunctionLibraryDefinition::RemoveGradient(const string& func) {\n  const auto& i = func_grad_.find(func);\n  if (i == func_grad_.end()) {\n    return errors::InvalidArgument(\"Tried to remove non-existent gradient '\",\n                                   func, \"'.\");\n  }\n  func_grad_.erase(i);\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::Remove(\n    const std::vector<string>& funcs,\n    const std::vector<string>& funcs_with_grads) {\n  Status s;\n  for (const string& f : funcs) {\n    s = RemoveFunctionHelper(f);\n    if (!s.ok()) {\n      return s;\n    }\n  }\n  for (const string& f : funcs_with_grads) {\n    s = RemoveGradient(f);\n    if (!s.ok()) {\n      return s;\n    }\n  }\n  return Status::OK();\n}\n\nstring FunctionLibraryDefinition::FindGradient(const string& func) const {\n  tf_shared_lock l(mu_);\n  return gtl::FindWithDefault(func_grad_, func, \"\");\n}\n\nstring FunctionLibraryDefinition::FindGradientHelper(const string& func) const {\n  return gtl::FindWithDefault(func_grad_, func, \"\");\n}\n\nStatus FunctionLibraryDefinition::LookUp(\n    const string& op, const OpRegistrationData** op_reg_data) const {\n  tf_shared_lock l(mu_);\n  auto iter = function_defs_.find(op);\n  if (iter != function_defs_.end()) {\n    *op_reg_data = &iter->second->op_registration_data;\n    return Status::OK();\n  }\n  return default_registry_->LookUp(op, op_reg_data);\n}\n\nstring FunctionLibraryDefinition::UniqueFunctionName(StringPiece prefix) const {\n  tf_shared_lock l(mu_);\n  int index = 0;\n  string name = strings::StrCat(prefix, index);\n  while (function_defs_.find(name) != function_defs_.end()) {\n    ++index;\n    name = strings::StrCat(prefix, index);\n  }\n  return name;\n}\n\nconst FunctionDef* FunctionLibraryDefinition::GetAttrImpl(\n    const NodeDef& ndef) const {\n  if (ndef.op() != kGradientOp) {\n    // If 'ndef' calls a function and the function's def has the attr,\n    // returns it.\n    return Find(ndef.op());\n  }\n\n  // If ndef is SymbolicGradient[f=Foo], we use Foo's gradient or\n  // Foo's attributes.\n  const NameAttrList* forward_func_attrs;\n  if (!TryGetNodeAttr(ndef, kFuncAttr, &forward_func_attrs)) {\n    return nullptr;\n  }\n  const string& func_name = forward_func_attrs->name();\n  {\n    tf_shared_lock l(mu_);\n    const string& grad_name = FindGradientHelper(func_name);\n    // If 'func' has a user-defined gradient function, uses the grad\n    // function's attrs to see if noinline is specified. Otherwise,\n    // uses func's attrs.\n    if (!grad_name.empty()) {\n      if (const auto helper = FindHelper(grad_name)) {\n        return &(helper->fdef);\n      } else {\n        return nullptr;\n      }\n    }\n    if (const auto helper = FindHelper(func_name)) {\n      return &(helper->fdef);\n    } else {\n      return nullptr;\n    }\n  }\n}\n\nstd::vector<string> FunctionLibraryDefinition::ListFunctionNames() const {\n  std::vector<string> function_names;\n  tf_shared_lock l(mu_);\n  function_names.reserve(function_defs_.size());\n  for (const auto& it : function_defs_) {\n    function_names.emplace_back(it.first);\n  }\n  return function_names;\n}\n\nFunctionDefLibrary FunctionLibraryDefinition::ToProto() const {\n  FunctionDefLibrary lib;\n  tf_shared_lock l(mu_);\n  for (const auto& f : function_defs_) {\n    *lib.add_function() = f.second->fdef;\n  }\n  for (const auto& g : func_grad_) {\n    GradientDef* gd = lib.add_gradient();\n    gd->set_function_name(g.first);\n    gd->set_gradient_func(g.second);\n  }\n  return lib;\n}\n\ntemplate <typename T>\nStatus FunctionLibraryDefinition::GetAttr(const NodeDef& ndef,\n                                          const string& attr, T* value) const {\n  const FunctionDef* fdef = GetAttrImpl(ndef);\n  if (fdef && TryGetNodeAttr(AttrSlice(&fdef->attr()), attr, value)) {\n    return Status::OK();\n  }\n  return errors::InvalidArgument(\"Attr \", attr, \" is not defined.\");\n}\n\ntemplate <typename T>\nStatus FunctionLibraryDefinition::GetAttr(const Node& node, const string& attr,\n                                          T* value) const {\n  return GetAttr(node.def(), attr, value);\n}\n\n#define GET_ATTR(T)                                                            \\\n  template Status FunctionLibraryDefinition::GetAttr(const Node&,              \\\n                                                     const string&, T*) const; \\\n  template Status FunctionLibraryDefinition::GetAttr(const NodeDef&,           \\\n                                                     const string&, T*) const;\nGET_ATTR(string)\nGET_ATTR(bool)\n#undef GET_ATTR\n\nnamespace {\n\nconstexpr char kApiImplements[] = \"api_implements\";\n\nstd::set<string> ReachableFunctions(\n    const FunctionLibraryDefinition& flib,\n    const protobuf::RepeatedPtrField<NodeDef>& nodes) {\n  // Functions that are reachable from the graph.\n  std::set<string> reachable_funcs;\n\n  // For any functions, if it has attribute \"api_implements\" =\n  // \"some_interface\" and it is reachable, then it means any other\n  // function with same attribute name and value could also be potentially\n  // reachable, eg via implementation_selector swapping the nodedef.\n  absl::flat_hash_set<string> reachable_api_interface;\n\n  // Functions might be reachable from the nested function calls, so we keep a\n  // queue of functions that we have to check.\n  gtl::InlinedVector<const FunctionDef*, 4> func_queue;\n\n  // Add reachable and not already processed functions to the functions queue.\n  const auto add_to_func_queue = [&](const string& func_name) {\n    const FunctionDef* func = flib.Find(func_name);\n    if (func && reachable_funcs.find(func_name) == reachable_funcs.end()) {\n      func_queue.push_back(func);\n    }\n  };\n\n  // If any function with certain API name is reachable, all the other functions\n  // with same API name should also be checked.\n  const auto add_function_with_api_interface = [&](const string& api_name) {\n    if (!reachable_api_interface.contains(api_name)) {\n      reachable_api_interface.insert(api_name);\n      for (const auto& func_name : flib.ListFunctionNames()) {\n        const auto& func_def = flib.Find(func_name);\n        const auto attr_it = func_def->attr().find(kApiImplements);\n        if (attr_it != func_def->attr().end() &&\n            attr_it->second.s() == api_name) {\n          add_to_func_queue(func_name);\n        }\n      }\n    }\n  };\n\n  // Add all the functions that are reachable from the given node to the queue.\n  const auto process_node = [&](const NodeDef& node) {\n    // Node itself can be a call to the function.\n    add_to_func_queue(node.op());\n\n    // Or node can have an attribute referencing a function.\n    for (const auto& attr : node.attr()) {\n      const auto& attr_value = attr.second;\n\n      // 1. AttrValue.func\n      if (attr_value.has_func()) {\n        add_to_func_queue(attr_value.func().name());\n      }\n\n      // 2. AttrValue.ListValue.func\n      if (attr_value.has_list()) {\n        for (const auto& func : attr_value.list().func()) {\n          add_to_func_queue(func.name());\n        }\n      }\n    }\n  };\n\n  // Add all functions that are directly called from the optimized graph.\n  std::for_each(nodes.begin(), nodes.end(), process_node);\n\n  // Process all reachable functions.\n  while (!func_queue.empty()) {\n    const FunctionDef* func = func_queue.back();\n    func_queue.pop_back();\n\n    const string& func_name = func->signature().name();\n    reachable_funcs.insert(func_name);\n\n    const auto attr_it = func->attr().find(kApiImplements);\n    if (attr_it != func->attr().end()) {\n      add_function_with_api_interface(attr_it->second.s());\n    }\n\n    // Find all the functions called from the function body.\n    const auto& func_body = func->node_def();\n    std::for_each(func_body.begin(), func_body.end(), process_node);\n\n    // Check if the function has a registered gradient.\n    const string grad_func_name = flib.FindGradient(func_name);\n    if (!grad_func_name.empty()) add_to_func_queue(grad_func_name);\n  }\n\n  return reachable_funcs;\n}\n\nFunctionLibraryDefinition ReachableFunctionLibraryDefinition(\n    const FunctionLibraryDefinition& flib,\n    const protobuf::RepeatedPtrField<NodeDef>& nodes) {\n  std::set<string> reachable_funcs = ReachableFunctions(flib, nodes);\n\n  FunctionLibraryDefinition reachable_flib(flib.default_registry(),\n                                           FunctionDefLibrary());\n\n  for (const string& func_name : reachable_funcs) {\n    // This should never fail, because we copy functions from a valid flib and\n    // use the same default registry.\n    Status added = reachable_flib.CopyFunctionDefFrom(func_name, flib);\n    TF_DCHECK_OK(added);\n\n    const string grad_func_name = flib.FindGradient(func_name);\n    if (!grad_func_name.empty()) {\n      GradientDef grad;\n      grad.set_function_name(func_name);\n      grad.set_gradient_func(grad_func_name);\n      // It can only fail if function already has a gradient function.\n      const Status added_grad = reachable_flib.AddGradientDef(grad);\n      TF_DCHECK_OK(added_grad);\n    }\n  }\n\n  return reachable_flib;\n}\n\nstring AllocatorAttributesToString(\n    const std::vector<AllocatorAttributes>& attrs) {\n  string result(\"[\");\n  // AllocatorAttribute::DebugString produces around 85 bytes now.\n  result.reserve(100 * attrs.size());\n  for (const AllocatorAttributes& attr : attrs) {\n    result.append(attr.DebugString());\n    result.append(\", \");\n  }\n  if (!attrs.empty()) {\n    result.resize(result.size() - 2);\n  }\n  result.append(\"]\");\n  return result;\n}\n\nconst char* IsSet(void* ptr) { return ptr == nullptr ? \"unset\" : \"set\"; }\n\n}  // namespace\n\nFunctionLibraryDefinition FunctionLibraryDefinition::ReachableDefinitions(\n    const GraphDef& graph) const {\n  return ReachableFunctionLibraryDefinition(*this, graph.node());\n}\n\nFunctionLibraryDefinition FunctionLibraryDefinition::ReachableDefinitions(\n    const FunctionDef& func) const {\n  return ReachableFunctionLibraryDefinition(*this, func.node_def());\n}\n\nstring FunctionLibraryRuntime::Options::DebugString() const {\n  return absl::StrCat(\n      \"FLR::Options(step_id=\", step_id, \" rendezvous=\", IsSet(rendezvous),\n      \" cancellation_manager=\", IsSet(cancellation_manager),\n      \" collective_executor=\", IsSet(collective_executor),\n      \" step_container=\", IsSet(step_container),\n      \" stats_collector=\", IsSet(stats_collector), \" runner=\", IsSet(runner),\n      \" remote_execution=\", remote_execution, \" source_device=\", source_device,\n      \" create_rendezvous=\", create_rendezvous,\n      \" allow_dead_tensors=\", allow_dead_tensors,\n      \" args_alloc_attrs=\", AllocatorAttributesToString(args_alloc_attrs),\n      \" rets_alloc_attrs=\", AllocatorAttributesToString(rets_alloc_attrs), \")\");\n}\n\nvoid FunctionDefHelper::AttrValueWrapper::InitFromString(StringPiece val) {\n  if (val.size() >= 2 && val[0] == '$') {\n    proto.set_placeholder(val.data() + 1, val.size() - 1);\n  } else {\n    SetAttrValue(val, &proto);\n  }\n}\n\nFunctionDefHelper::AttrValueWrapper FunctionDefHelper::FunctionRef(\n    const string& name,\n    gtl::ArraySlice<std::pair<string, AttrValueWrapper>> attrs) {\n  AttrValueWrapper ret;\n  ret.proto.mutable_func()->set_name(name);\n  for (const auto& a : attrs) {\n    ret.proto.mutable_func()->mutable_attr()->insert({a.first, a.second.proto});\n  }\n  return ret;\n}\n\nNodeDef FunctionDefHelper::Node::ToNodeDef() const {\n  NodeDef n;\n  n.set_op(this->op);\n  n.set_name(GetName());\n  for (const auto& a : this->attr) {\n    n.mutable_attr()->insert({a.first, a.second.proto});\n  }\n  for (const string& a : this->arg) {\n    n.add_input(a);\n  }\n  for (const string& d : this->dep) {\n    n.add_input(strings::StrCat(\"^\", d));\n  }\n  if (!this->device.empty()) {\n    n.set_device(this->device);\n  }\n  if (!this->original_node_names.empty()) {\n    *n.mutable_experimental_debug_info()->mutable_original_node_names() = {\n        this->original_node_names.begin(), this->original_node_names.end()};\n  }\n  if (!this->original_func_names.empty()) {\n    *n.mutable_experimental_debug_info()->mutable_original_func_names() = {\n        this->original_func_names.begin(), this->original_func_names.end()};\n  }\n  return n;\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Create(\n    const string& function_name, gtl::ArraySlice<string> in_def,\n    gtl::ArraySlice<string> out_def, gtl::ArraySlice<string> attr_def,\n    gtl::ArraySlice<Node> node_def,\n    gtl::ArraySlice<std::pair<string, string>> ret_def,\n    gtl::ArraySlice<std::pair<string, string>> control_ret_def) {\n  FunctionDef fdef;\n\n  // Signature\n  OpDefBuilder b(function_name);\n  for (const auto& i : in_def) b.Input(i);\n  for (const auto& o : out_def) b.Output(o);\n  for (const auto& a : attr_def) b.Attr(a);\n  for (const auto& c : control_ret_def) b.ControlOutput(c.first);\n\n  OpRegistrationData op_reg_data;\n  TF_CHECK_OK(b.Finalize(&op_reg_data));\n  fdef.mutable_signature()->Swap(&op_reg_data.op_def);\n\n  // Function body\n  for (const auto& n : node_def) {\n    *(fdef.add_node_def()) = n.ToNodeDef();\n  }\n\n  // Returns\n  for (const auto& r : ret_def) {\n    fdef.mutable_ret()->insert({r.first, r.second});\n  }\n\n  // Control returns\n  for (const auto& cr : control_ret_def) {\n    fdef.mutable_control_ret()->insert({cr.first, cr.second});\n  }\n\n  auto* op_def_registry = OpRegistry::Global();\n  // Check if any op is stateful.\n  for (const auto& n : node_def) {\n    const OpDef* op_def = nullptr;\n    auto status = op_def_registry->LookUpOpDef(n.op, &op_def);\n    // Lookup can fail if e.g. we are calling a function that was not yet\n    // defined.  If it happens, conservatively assume the op is stateful.\n    if (!status.ok() || op_def->is_stateful()) {\n      fdef.mutable_signature()->set_is_stateful(true);\n    }\n  }\n\n  return fdef;\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Create(\n    const string& function_name, gtl::ArraySlice<string> in_def,\n    gtl::ArraySlice<string> out_def, gtl::ArraySlice<string> attr_def,\n    gtl::ArraySlice<Node> node_def,\n    gtl::ArraySlice<std::pair<string, string>> ret_def) {\n  return Create(function_name, in_def, out_def, attr_def, node_def, ret_def,\n                /*control_ret_def=*/{});\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Define(const string& name,\n                                      gtl::ArraySlice<string> arg_def,\n                                      gtl::ArraySlice<string> ret_def,\n                                      gtl::ArraySlice<string> attr_def,\n                                      gtl::ArraySlice<Node> node_def) {\n  FunctionDef fdef;\n  OpDefBuilder b(name);\n  for (const auto& a : arg_def) b.Input(a);\n  for (const auto& r : ret_def) b.Output(r);\n  for (const auto& a : attr_def) b.Attr(a);\n\n  OpRegistrationData op_reg_data;\n  TF_CHECK_OK(b.Finalize(&op_reg_data));\n  fdef.mutable_signature()->Swap(&op_reg_data.op_def);\n\n  // Mapping from legacy output names to NodeDef outputs.\n  std::unordered_map<string, string> ret_index;\n  for (const auto& a : fdef.signature().input_arg()) {\n    ret_index[a.name()] = a.name();\n  }\n\n  // For looking up OpDefs\n  auto* op_def_registry = OpRegistry::Global();\n\n  // Function body\n  for (const auto& src : node_def) {\n    NodeDef* n = fdef.add_node_def();\n    n->set_op(src.op);\n    n->set_name(src.GetName());\n    for (const auto& a : src.attr) {\n      n->mutable_attr()->insert({a.first, a.second.proto});\n    }\n    for (const string& a : src.arg) {\n      const auto iter = ret_index.find(a);\n      CHECK(iter != ret_index.end())\n          << \"Node input '\" << a << \"' in '\" << n->name() << \"' of \" << name;\n      n->add_input(iter->second);\n    }\n    for (const string& d : src.dep) {\n      n->add_input(strings::StrCat(\"^\", d));\n    }\n\n    // Add the outputs of this node to ret_index.\n    const OpDef* op_def = nullptr;\n    TF_CHECK_OK(op_def_registry->LookUpOpDef(n->op(), &op_def)) << n->op();\n    CHECK(op_def != nullptr) << n->op();\n    NameRangeMap output_names;\n    TF_CHECK_OK(NameRangesForNode(*n, *op_def, nullptr, &output_names));\n    for (const auto& o : output_names) {\n      CHECK_LE(o.second.second, src.ret.size())\n          << \"Missing ret for output '\" << o.first << \"' in '\" << n->name()\n          << \"' of \" << name;\n      for (int i = o.second.first; i < o.second.second; ++i) {\n        ret_index[src.ret[i]] =\n            strings::StrCat(n->name(), \":\", o.first, \":\", i - o.second.first);\n      }\n    }\n    if (op_def->is_stateful()) fdef.mutable_signature()->set_is_stateful(true);\n  }\n\n  // Returns\n  for (const auto& r : fdef.signature().output_arg()) {\n    const auto iter = ret_index.find(r.name());\n    CHECK(iter != ret_index.end()) << \"Return '\" << r.name() << \"' in \" << name;\n    fdef.mutable_ret()->insert({r.name(), iter->second});\n  }\n  return fdef;\n}\n\nFunctionDef FunctionDefHelper::Define(gtl::ArraySlice<string> arg_def,\n                                      gtl::ArraySlice<string> ret_def,\n                                      gtl::ArraySlice<string> attr_def,\n                                      gtl::ArraySlice<Node> node_def) {\n  return Define(\"_\", arg_def, ret_def, attr_def, node_def);\n}\n\nnamespace gradient {\n\ntypedef std::unordered_map<string, Creator> OpGradFactory;\n\nOpGradFactory* GetOpGradFactory() {\n  static OpGradFactory* factory = new OpGradFactory;\n  return factory;\n}\n\nbool RegisterOp(const string& op, Creator func) {\n  CHECK(GetOpGradFactory()->insert({op, func}).second)\n      << \"Duplicated gradient for \" << op;\n  return true;\n}\n\nStatus GetOpGradientCreator(const string& op, Creator* creator) {\n  auto fac = GetOpGradFactory();\n  auto iter = fac->find(op);\n  if (iter == fac->end()) {\n    return errors::NotFound(\"No gradient defined for op: \", op);\n  }\n  *creator = iter->second;\n  return Status::OK();\n}\n\n}  // end namespace gradient\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/function.h\"\n\n#include <ctype.h>\n\n#include <map>\n#include <unordered_map>\n#include <utility>\n#include <vector>\n\n#include \"absl/container/flat_hash_set.h\"\n#include \"absl/strings/escaping.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/str_join.h\"\n#include \"tensorflow/core/framework/allocator.h\"\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/function.pb.h\"\n#include \"tensorflow/core/framework/graph.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/graph/graph.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/lib/strings/proto_serialization.h\"\n#include \"tensorflow/core/platform/fingerprint.h\"\n#include \"tensorflow/core/util/device_name_utils.h\"\n#include \"tensorflow/core/util/equal_graph_def.h\"\n\nnamespace tensorflow {\n\n/* static */ constexpr const char* const FunctionLibraryDefinition::kArgOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kDeviceArgOp;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kRetOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kDeviceRetOp;\n/* static */ constexpr const char* const\n    FunctionLibraryDefinition::kIntsOnDeviceAttr;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kGradientOp;\n/* static */ constexpr const char* const FunctionLibraryDefinition::kFuncAttr;\n\n// Extracts the actual type from \"attr_values\" based on its definition\n// \"arg_def\".\n//\n// If \"arg_def\" is a N*T type, *is_type_list is set to false, and\n// *dtypes is set to be a vector of size N and each element is T.\n//\n// If \"arg_def\" is a list(type), *is_type_list is set to true, and\n// *dtypes is set to be a vector of types specified in attrs for\n// arg_def.\n//\n// Otherwise (arg_def is a simple type T), *is_type_list is set to\n// false, and *dtypes is set to a single element vector, whose only\n// element is T.\nStatus ArgNumType(AttrSlice attrs, const OpDef::ArgDef& arg_def,\n                  bool* is_type_list, DataTypeVector* dtypes) {\n  dtypes->clear();\n  if (!arg_def.type_list_attr().empty()) {\n    const AttrValue* v = attrs.Find(arg_def.type_list_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \",\n                              arg_def.type_list_attr());\n    }\n    *is_type_list = true;\n    for (int i = 0; i < v->list().type_size(); ++i) {\n      dtypes->push_back(v->list().type(i));\n    }\n    return Status::OK();\n  }\n\n  *is_type_list = false;\n  int num = 1;\n  if (!arg_def.number_attr().empty()) {\n    const AttrValue* v = attrs.Find(arg_def.number_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \", arg_def.type_attr());\n    }\n    num = v->i();\n  }\n\n  DataType dtype;\n  if (arg_def.type() != DT_INVALID) {\n    dtype = arg_def.type();\n  } else if (arg_def.type_attr().empty()) {\n    dtype = DT_INVALID;\n  } else {\n    const AttrValue* v = attrs.Find(arg_def.type_attr());\n    if (v == nullptr) {\n      return errors::NotFound(\"type attr not found: \", arg_def.type_attr());\n    }\n    dtype = v->type();\n  }\n  dtypes->resize(num, dtype);\n  return Status::OK();\n}\n\nnamespace {\n\ntemplate <typename T>\nvoid AddAttr(const string& name, const T& val, NodeDef* ndef) {\n  SetAttrValue(val, &((*ndef->mutable_attr())[name]));\n}\n\nStatus ValidateSignatureWithAttrs(const OpDef& sig, AttrSlice attr_values) {\n  // attr_values should specify all attrs defined in fdef, except for those\n  // which have a default value\n  for (const auto& attr : sig.attr()) {\n    const AttrValue* attr_value = attr_values.Find(attr.name());\n    if (attr_value) {\n      Status status = AttrValueHasType(*attr_value, attr.type());\n      if (!status.ok()) {\n        errors::AppendToMessage(&status, \"for attr '\", attr.name(), \"'\");\n        return status;\n      }\n    } else if (!attr.has_default_value()) {\n      return errors::NotFound(\"Attr \", attr.name(), \" is not found from \",\n                              SummarizeOpDef(sig));\n    }\n  }\n\n// TODO(josh11b): Enable this code once it works with function gradients.\n// Right now the C++ function gradient code assumes it can pass\n// all the attrs of the function to the gradient, and any attrs that\n// the gradient doesn't care about will be ignored.\n#if 0\n  if (attr_values.size() != sig.attr_size()) {\n    for (const auto& a : attr_values) {\n      // TODO(josh11b): Possibly should ignore attrs that start with \"_\" here?\n      bool found = false;\n      for (const auto& s : sig.attr()) {\n        if (a.first == s.name()) {\n          found = true;\n          break;\n        }\n      }\n      if (!found) {\n        return errors::NotFound(\"Attr \", a.first, \" is not found in \",\n                                SummarizeOpDef(sig));\n      }\n    }\n  }\n#endif\n\n  return Status::OK();\n}\n\n// A helper class for instantiating functions. This contains shared information\n// like the resulting graph and node name index.\nclass FunctionInstantiationHelper {\n public:\n  FunctionInstantiationHelper(GetFunctionSignature get_function,\n                              InstantiationResult* result)\n      : get_function_(std ::move(get_function)), result_(*result) {\n    result_.nodes.clear();\n  }\n\n  // Builds index for nodes that can be used as node's input arguments.\n  // `resource_arg_unique_id`: if non-negative, will be populated to the\n  // \"_resource_arg_unique_id\" attribute of the arg node.\n  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }\n\n  Status BuildNodeOutputIndex(const NodeDef& node, AttrSlice attrs,\n                              const int arg_index) {\n    const OpDef* node_sig = nullptr;\n    TF_RETURN_IF_ERROR(get_function_(node.op(), &node_sig));\n    if (node_sig->output_arg_size() == 0) {\n      return AddItem(node.name(), {false, arg_index, 0, false, {}});\n    }\n    const int num_retval = node_sig->output_arg_size();\n    int start = 0;\n    bool is_type_list;\n    DataTypeVector dtypes;\n    for (int i = 0; i < num_retval; ++i) {\n      TF_RETURN_IF_ERROR(\n          ArgNumType(attrs, node_sig->output_arg(i), &is_type_list, &dtypes));\n      // Note that we rely on the backwards-compatibility test enforcing\n      // that output_arg(*).name() doesn't change here.\n      const string base_name =\n          strings::StrCat(node.name(), \":\", node_sig->output_arg(i).name());\n      TF_RETURN_IF_ERROR(\n          AddItem(base_name, {false, arg_index, start, is_type_list, dtypes}));\n      for (int j = 0; j < static_cast<int>(dtypes.size()); ++j) {\n        TF_RETURN_IF_ERROR(\n            AddItem(strings::StrCat(base_name, \":\", j),\n                    {false, arg_index, start + j, false, {dtypes[j]}}));\n      }\n      start += dtypes.size();\n    }\n    return Status::OK();\n  }\n\n  Status InstantiateNode(const NodeDef& fnode, AttrSlice attrs) {\n    const OpDef* fnode_sig = nullptr;\n    TF_CHECK_OK(get_function_(fnode.op(), &fnode_sig));\n    NodeDef* gnode = AddNode(fnode.name());\n    gnode->set_op(fnode.op());\n    gnode->set_device(fnode.device());\n    int gnode_idx = nodes_.size() - 1;\n\n    // Input\n    const int num_args = fnode_sig->input_arg_size();\n    bool is_type_list;  // ignored\n    DataTypeVector dtypes;\n    int fnode_arg_index = 0;\n    for (int i = 0; i < num_args; ++i) {\n      TF_RETURN_IF_ERROR(\n          ArgNumType(attrs, fnode_sig->input_arg(i), &is_type_list, &dtypes));\n      // Consume inputs (indexed by fnode_arg_index) until we have\n      // matched each element of dtypes (indexed by j).\n      for (size_t j = 0; j < dtypes.size(); ++fnode_arg_index) {\n        if (fnode_arg_index >= fnode.input_size()) {\n          // Should never happen if we computed dtypes correctly.\n          return errors::InvalidArgument(\n              \"Attempt to access beyond input size: \", fnode_arg_index,\n              \" >= \", fnode.input_size());\n        }\n        // Look up the next input.\n        const string& input_name = fnode.input(fnode_arg_index);\n        const auto* item = GetItemOrNull(input_name);\n        if (item == nullptr) {\n          return errors::InvalidArgument(\n              \"input \", input_name,\n              \" is not found: \", FormatNodeDefForError(fnode));\n        }\n        if (item->dtypes.size() > dtypes.size() - j) {\n          return errors::InvalidArgument(\"Input \", input_name, \" too long for \",\n                                         fnode_sig->input_arg(i).name());\n        }\n        // Match up all the elements of this input (indexed by k) with\n        // elements of dtypes (advancing j).\n        for (int k = 0; k < item->dtypes.size(); ++k, ++j) {\n          if (item->dtypes[k] != dtypes[j]) {\n            return errors::InvalidArgument(\n                \"input \", fnode_sig->input_arg(i).name(), \"[\", j,\n                \"] expected type \", DataTypeString(dtypes[j]),\n                \" != \", DataTypeString(item->dtypes[k]), \", the type of \",\n                input_name, \"[\", k, \"]\");\n          }\n          if (item->is_func_arg) {\n            AddInput(gnode_idx, item->nid + k, 0);\n          } else {\n            AddInput(gnode_idx, item->nid, item->idx + k);\n          }\n        }\n      }\n    }\n\n    // Control deps.\n    for (int i = fnode_arg_index; i < fnode.input_size(); ++i) {\n      const string& input = fnode.input(i);\n      if (input.empty() || input[0] != '^') {\n        return errors::InvalidArgument(\"Expected input[\", i, \"] == '\", input,\n                                       \"' to be a control input.\");\n      }\n      int nid = -1;\n      const string node_name = input.substr(1);\n      const string node_colon = node_name + \":\";\n      const string node_colon_bound = node_name + \";\";\n      // index_ is a map sorted lexicographically, so the key we are looking for\n      // must lie in the range [node_name, node_colon_bound).\n      auto it = index_.lower_bound(node_name);\n      while (it != index_.end() && it->first <= node_colon_bound) {\n        if (it->first == node_name || absl::StartsWith(it->first, node_colon)) {\n          nid = it->second.nid;\n          break;\n        }\n        ++it;\n      }\n      if (nid == -1) {\n        return errors::InvalidArgument(\"input[\", i, \"] == '\", input,\n                                       \"', is not found.\");\n      }\n      AddDep(gnode_idx, nid);\n    }\n\n    // Attrs.\n    for (const auto& p : attrs) {\n      (*gnode->mutable_attr())[p.first] = p.second;\n    }\n\n    // Experimental_debug_info.\n    if (fnode.has_experimental_debug_info()) {\n      gnode->mutable_experimental_debug_info()->MergeFrom(\n          fnode.experimental_debug_info());\n    }\n\n    // Tye info.\n    // TODO(mdan): Might this need adjustment at instantiation?\n    if (fnode.has_experimental_type()) {\n      *gnode->mutable_experimental_type() = fnode.experimental_type();\n    }\n\n    return Status::OK();\n  }\n\n  Status AddReturnNode(\n      const OpDef::ArgDef& ret_def, AttrSlice attrs,\n      const ::tensorflow::protobuf::Map<string, string>& ret_map,\n      bool ints_on_device, int* ret_index) {\n    auto ret_iter = ret_map.find(ret_def.name());\n    if (ret_iter == ret_map.end()) {\n      return errors::InvalidArgument(\"Return \", ret_def.name(), \" missing.\");\n    }\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(ArgNumType(attrs, ret_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    const auto* item = GetItemOrNull(ret_iter->second);\n    if (item == nullptr) {\n      return errors::InvalidArgument(\"Return \", ret_def.name(), \" -> \",\n                                     ret_iter->second, \" is not found.\");\n    }\n    if (dtypes != item->dtypes) {\n      return errors::InvalidArgument(\"Invalid ret types \", ret_def.name(),\n                                     \" : \", DataTypeVectorString(dtypes),\n                                     \" vs. \",\n                                     DataTypeVectorString(item->dtypes));\n    }\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      string name = strings::StrCat(ret_def.name(), \"_RetVal\");\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceRetOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kRetOp);\n      }\n      AddInput(nodes_.size() - 1, item->nid, item->idx + i);\n      DataType dtype = ret_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", (*ret_index)++, gnode);\n      result_.ret_types.push_back(dtypes[i]);\n    }\n    return Status::OK();\n  }\n\n  // Adds the actual node inputs to the result graph by converting indexes to\n  // the node names.\n  void AddNodeInputs() {\n    for (int i = 0; i < result_.nodes.size(); i++) {\n      NodeInfo& node_info = nodes_[i];\n      for (const auto& p : node_info.data_inputs) {\n        result_.nodes[i].add_input(Name(p.first, p.second));\n      }\n      for (int index : node_info.control_inputs) {\n        result_.nodes[i].add_input(Dep(index));\n      }\n    }\n  }\n\n private:\n  // This is used to build a small index for all names that can be used as a\n  // node's input arguments.\n  //\n  // If is_func_arg is true, the name is a function's argument.  In\n  // this case, the produced graph def has node[nid:nid + dtype.size()].\n  //\n  // Otherwise, the name is a function body's node return value.  In\n  // this case, the produced graph def has one node node[nid] and\n  // the node's output index [idx ... idx + num) corresponds to the\n  // named outputs.\n  //\n  // In all cases, \"dtype\" specifies the data type.\n  struct NameInfoItem {\n    bool is_func_arg;\n    int nid;\n    int idx;\n    bool is_type_list;\n    DataTypeVector dtypes;\n  };\n\n  // Adds an item into the input name index.\n  Status AddItem(const string& name, const NameInfoItem& item) {\n    if (!index_.insert({name, item}).second) {\n      return errors::InvalidArgument(\n          strings::StrCat(\"Duplicated \", item.is_func_arg ? \"arg\" : \"ret\",\n                          \" name: \"),\n          name);\n    }\n    return Status::OK();\n  }\n\n  const NameInfoItem* GetItemOrNull(const string& name) const {\n    return gtl::FindOrNull(index_, name);\n  }\n\n  string Dep(int node_index) const {\n    return strings::StrCat(\"^\", Name(node_index));\n  }\n\n  string Name(int node_index) const {\n    CHECK_LT(node_index, nodes_.size());\n    return nodes_[node_index].name;\n  }\n\n  string Name(int node_index, int output_index) const {\n    if (output_index == 0) {\n      return Name(node_index);\n    } else {\n      return strings::StrCat(Name(node_index), \":\", output_index);\n    }\n  }\n\n  NodeDef* AddNode(const string& name) {\n    result_.nodes.emplace_back();\n    NodeDef* gnode = &result_.nodes.back();\n    gnode->set_name(name);\n    nodes_.push_back({name, {}, {}});\n    CHECK_EQ(result_.nodes.size(), nodes_.size());\n    return gnode;\n  }\n\n  void AddInput(int node_index, int output_node, int output_index) {\n    CHECK_LT(node_index, nodes_.size());\n    nodes_[node_index].data_inputs.push_back(\n        std::make_pair(output_node, output_index));\n  }\n\n  void AddDep(int node_index, int dep_index) {\n    CHECK_LT(node_index, nodes_.size());\n    nodes_[node_index].control_inputs.push_back(dep_index);\n  }\n\n  GetFunctionSignature get_function_;\n  InstantiationResult& result_;\n  // A small index for all names that can be used as a node's input arguments.\n  std::map<string, NameInfoItem> index_;\n  // This contains information about a node in the new graph including the node\n  // names and input nodes' indexes.\n  struct NodeInfo {\n    string name;\n    // Data inputs where <n, k> means arg k of node n.\n    std::vector<std::pair<int, int>> data_inputs;\n    // Control inputs (dependencies).\n    std::vector<int> control_inputs;\n  };\n  // nodes_[i] is the information about result_.nodes[i].\n  std::vector<NodeInfo> nodes_;\n};\n\n// Various helpers Print(proto) to print relevant protos to ascii.\nstring Print(const OpDef::ArgDef& arg) {\n  string out;\n  strings::StrAppend(&out, arg.name(), \":\");\n  if (arg.is_ref()) strings::StrAppend(&out, \"Ref(\");\n  if (!arg.number_attr().empty()) {\n    strings::StrAppend(&out, arg.number_attr(), \"*\");\n  }\n  if (arg.type() != DT_INVALID) {\n    strings::StrAppend(&out, DataTypeString(arg.type()));\n  } else {\n    strings::StrAppend(&out, arg.type_attr());\n  }\n  if (arg.is_ref()) strings::StrAppend(&out, \")\");\n  return out;\n}\n\n// TODO(josh11b): Merge this with SummarizeAttrValue().\n// When hash_string_attrs = true, string attributes are hashed instead of being\n// truncated with ellipses. This is done to reduce the chance of collisions when\n// looking up functions using the canonical representation.\nstring Print(const AttrValue& attr_value,\n             const bool hash_string_attrs = false) {\n  if (attr_value.value_case() == AttrValue::kType) {\n    return DataTypeString(attr_value.type());\n  } else if ((attr_value.value_case() == AttrValue::kList) &&\n             (attr_value.list().type_size() > 0)) {\n    string ret = \"{\";\n    for (int i = 0; i < attr_value.list().type_size(); ++i) {\n      if (i > 0) strings::StrAppend(&ret, \", \");\n      strings::StrAppend(&ret, DataTypeString(attr_value.list().type(i)));\n    }\n    strings::StrAppend(&ret, \"}\");\n    return ret;\n  } else if (attr_value.value_case() == AttrValue::kFunc) {\n    if (attr_value.func().attr_size() == 0) {\n      return attr_value.func().name();\n    }\n    std::vector<string> entries;\n    for (const auto& p : attr_value.func().attr()) {\n      entries.push_back(strings::StrCat(p.first, \"=\", Print(p.second)));\n    }\n    std::sort(entries.begin(), entries.end());\n    return strings::StrCat(attr_value.func().name(), \"[\",\n                           absl::StrJoin(entries, \", \"), \"]\");\n  } else if (attr_value.value_case() == AttrValue::kS && hash_string_attrs) {\n    return strings::StrCat(Fingerprint64(attr_value.s()));\n  }\n  return SummarizeAttrValue(attr_value);\n}\n\n// TODO(josh11b): Merge this with SummarizeNodeDef().\nstring Print(const NodeDef& n) {\n  string out;\n  strings::StrAppend(&out, n.name(), \" = \", n.op());\n  if (n.attr_size() > 0) {\n    std::vector<string> entries;\n    for (auto& a : n.attr()) {\n      entries.push_back(strings::StrCat(a.first, \"=\", Print(a.second)));\n    }\n    std::sort(entries.begin(), entries.end());\n    // Add a short device string at the end of all attributes.\n    if (!n.device().empty()) {\n      DeviceNameUtils::ParsedName parsed;\n      if (DeviceNameUtils::ParseFullName(n.device(), &parsed)) {\n        entries.push_back(\n            strings::StrCat(\"device=\", parsed.type, \":\", parsed.id));\n      } else {\n        entries.push_back(\"device=<FAILED_TO_PARSE>\");\n      }\n    }\n    strings::StrAppend(&out, \"[\", absl::StrJoin(entries, \", \"), \"]\");\n  }\n  strings::StrAppend(&out, \"(\");\n  std::vector<StringPiece> dat;\n  std::vector<string> dep;\n  for (StringPiece s : n.input()) {\n    if (absl::ConsumePrefix(&s, \"^\")) {\n      dep.emplace_back(s);\n    } else {\n      dat.push_back(s);\n    }\n  }\n  strings::StrAppend(&out, absl::StrJoin(dat, \", \"), \")\");\n  if (!dep.empty()) {\n    strings::StrAppend(&out, \" @ \", absl::StrJoin(dep, \", \"));\n  }\n  return out;\n}\n\nstring Print(const FunctionDef& fdef) {\n  string out;\n  const OpDef& sig = fdef.signature();\n  strings::StrAppend(&out, \"\\n\", sig.name());\n  if (sig.attr_size() > 0) {\n    strings::StrAppend(&out, \"[\");\n    for (int i = 0; i < sig.attr_size(); ++i) {\n      const auto& a = sig.attr(i);\n      if (i > 0) strings::StrAppend(&out, \", \");\n      if (a.type() == \"type\") {\n        strings::StrAppend(&out, a.name(), \":\", Print(a.allowed_values()));\n      } else {\n        strings::StrAppend(&out, a.name(), \":\", a.type());\n      }\n    }\n    strings::StrAppend(&out, \"]\");\n  }\n  strings::StrAppend(&out, \"(\");\n  for (int i = 0; i < sig.input_arg_size(); ++i) {\n    if (i > 0) strings::StrAppend(&out, \", \");\n    strings::StrAppend(&out, Print(sig.input_arg(i)));\n  }\n  strings::StrAppend(&out, \") -> (\");\n  for (int i = 0; i < sig.output_arg_size(); ++i) {\n    if (i > 0) strings::StrAppend(&out, \", \");\n    strings::StrAppend(&out, Print(sig.output_arg(i)));\n  }\n  strings::StrAppend(&out, \") {\\n\");\n  for (const auto& n : fdef.node_def()) {\n    strings::StrAppend(&out, \"  \", Print(n), \"\\n\");\n  }\n  for (const auto& cr : fdef.control_ret()) {\n    strings::StrAppend(&out, \"  @return \", cr.first, \" = \", cr.second, \"\\n\");\n  }\n  for (const auto& r : fdef.ret()) {\n    strings::StrAppend(&out, \"  return \", r.first, \" = \", r.second, \"\\n\");\n  }\n  strings::StrAppend(&out, \"}\\n\");\n  return out;\n}\n\nstring Print(gtl::ArraySlice<const NodeDef*> nodes) {\n  std::vector<const NodeDef*> arg;\n  std::vector<const NodeDef*> ret;\n  std::vector<const NodeDef*> body;\n  for (const NodeDef* n : nodes) {\n    if (n->op() == FunctionLibraryDefinition::kArgOp ||\n        n->op() == FunctionLibraryDefinition::kDeviceArgOp) {\n      arg.push_back(n);\n    } else if (n->op() == FunctionLibraryDefinition::kRetOp ||\n               n->op() == FunctionLibraryDefinition::kDeviceRetOp) {\n      ret.push_back(n);\n    } else {\n      body.push_back(n);\n    }\n  }\n  auto comp = [](const NodeDef* x, const NodeDef* y) {\n    int xi;\n    TF_CHECK_OK(GetNodeAttr(*x, \"index\", &xi));\n    int yi;\n    TF_CHECK_OK(GetNodeAttr(*y, \"index\", &yi));\n    return xi < yi;\n  };\n  std::sort(arg.begin(), arg.end(), comp);\n  std::sort(ret.begin(), ret.end(), comp);\n  string out;\n  strings::StrAppend(&out, \"\\n(\");\n  auto get_type_and_device = [](const NodeDef& n) {\n    DataType dt;\n    if (!TryGetNodeAttr(n, \"T\", &dt)) {\n      dt = DT_INVALID;\n    }\n    if (!n.device().empty()) {\n      DeviceNameUtils::ParsedName parsed;\n      if (DeviceNameUtils::ParseFullName(n.device(), &parsed)) {\n        return strings::StrCat(DataTypeString(dt), \"@\", parsed.type, \":\",\n                               parsed.id);\n      } else {\n        LOG(WARNING) << \"Failed to parse device \\\"\" << n.device() << \"\\\" in \"\n                     << n.op() << \":\" << n.name();\n        return strings::StrCat(DataTypeString(dt), \"@\",\n                               \"<FAILED_TO_PARSE_DEVICE>\");\n      }\n    }\n    return DataTypeString(dt);\n  };\n  for (size_t i = 0; i < arg.size(); ++i) {\n    const NodeDef* n = arg[i];\n    if (i > 0) strings::StrAppend(&out, \", \");\n    CHECK_GE(n->attr_size(), 2);\n    strings::StrAppend(&out, n->name(), \":\", get_type_and_device(*n));\n  }\n  strings::StrAppend(&out, \") -> (\");\n  for (size_t i = 0; i < ret.size(); ++i) {\n    const NodeDef* n = ret[i];\n    if (i > 0) strings::StrAppend(&out, \", \");\n    CHECK_LE(2, n->attr_size());\n\n    // The _RetVal op should have a unique non-control input. We assert that\n    // here and add it to the output.\n    bool found_non_control_input = false;\n    for (const string& input : n->input()) {\n      if (!input.empty() && input[0] != '^') {\n        DCHECK_EQ(found_non_control_input, false)\n            << \"RetVal node has more than one non-control input: \"\n            << absl::StrJoin(n->input(), \", \");\n        strings::StrAppend(&out, n->input(0), \":\", get_type_and_device(*n));\n        found_non_control_input = true;\n      }\n    }\n    DCHECK_EQ(found_non_control_input, true)\n        << \"RetVal did not have any non-control inputs: \"\n        << absl::StrJoin(n->input(), \", \");\n  }\n  strings::StrAppend(&out, \") {\\n\");\n  for (size_t i = 0; i < body.size(); ++i) {\n    strings::StrAppend(&out, \"  \", Print(*body[i]), \"\\n\");\n  }\n  strings::StrAppend(&out, \"}\\n\");\n  return out;\n}\n\nStatus AddDefaultAttrs(const string& op,\n                       const GetFunctionSignature& get_function,\n                       AttrValueMap* attrs) {\n  const OpDef* op_def = nullptr;\n  TF_RETURN_IF_ERROR(get_function(op, &op_def));\n  AttrSlice attr_slice(attrs);\n  for (const auto& attr_def : op_def->attr()) {\n    if (attr_def.has_default_value() && !attr_slice.Find(attr_def.name())) {\n      if (!attrs->insert({attr_def.name(), attr_def.default_value()}).second) {\n        return errors::Internal(\"Somehow duplicated: \", attr_def.name());\n      }\n    }\n  }\n  return Status::OK();\n}\n\n}  // end namespace\n\nStatus InstantiateFunction(const FunctionDef& fdef, AttrSlice attr_values,\n                           GetFunctionSignature get_function,\n                           InstantiationResult* result) {\n  if (VLOG_IS_ON(5)) {\n    const auto& signature = fdef.signature();\n    VLOG(5) << \"Instantiate function definition: name=\" << signature.name()\n            << \" #input_args=\" << signature.input_arg_size()\n            << \" #output_args=\" << signature.output_arg_size()\n            << \" #control_output=\" << signature.control_output_size();\n    for (const auto& line : str_util::Split(Print(fdef), '\\n')) {\n      VLOG(5) << \"|| \" << line;\n    }\n  }\n\n  const OpDef& sig = fdef.signature();\n  TF_RETURN_IF_ERROR(ValidateSignatureWithAttrs(sig, attr_values));\n\n  bool ints_on_device =\n      fdef.attr().count(FunctionLibraryDefinition::kIntsOnDeviceAttr) != 0 &&\n      fdef.attr().at(FunctionLibraryDefinition::kIntsOnDeviceAttr).b();\n\n  FunctionInstantiationHelper helper(get_function, result);\n  Status s;\n  for (int i = 0, e = sig.input_arg_size(); i < e; ++i) {\n    const OpDef::ArgDef& arg_def = sig.input_arg(i);\n    auto it = fdef.arg_attr().find(i);\n    const FunctionDef::ArgAttrs* arg_attrs =\n        it != fdef.arg_attr().end() ? &it->second : nullptr;\n    auto resource_id_it = fdef.resource_arg_unique_id().find(i);\n    int64_t resource_arg_unique_id =\n        resource_id_it != fdef.resource_arg_unique_id().end()\n            ? resource_id_it->second\n            : -1LL;\n    s = helper.BuildInputArgIndex(arg_def, attr_values, arg_attrs,\n                                  ints_on_device, resource_arg_unique_id);\n\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \", Print(arg_def));\n      return s;\n    }\n  }\n\n  auto substitute = [attr_values, &sig](StringPiece name, AttrValue* val) {\n    // Look for a specified value...\n    if (const AttrValue* v = attr_values.Find(name)) {\n      *val = *v;\n      return true;\n    }\n    // .. and if not, then check for a default value.\n    if (const OpDef::AttrDef* attr = FindAttr(name, sig)) {\n      if (attr->has_default_value()) {\n        *val = attr->default_value();\n        return true;\n      }\n    }\n    // No luck finding a substitution.\n    return false;\n  };\n\n  // Makes a copy of all attrs in fdef and substitutes placeholders.\n  // After this step, every attr is bound to a concrete value.\n  std::vector<AttrValueMap> node_attrs;\n  node_attrs.resize(fdef.node_def_size());\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    for (auto attr : fdef.node_def(i).attr()) {\n      if (!SubstitutePlaceholders(substitute, &attr.second)) {\n        return errors::InvalidArgument(\"Failed to bind all placeholders in \",\n                                       SummarizeAttrValue(attr.second));\n      }\n      if (!node_attrs[i].insert(attr).second) {\n        return errors::Internal(\"Somehow duplicated: \", attr.first);\n      }\n    }\n    TF_RETURN_IF_ERROR(\n        AddDefaultAttrs(fdef.node_def(i).op(), get_function, &node_attrs[i]));\n  }\n\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    s = helper.BuildNodeOutputIndex(fdef.node_def(i), AttrSlice(&node_attrs[i]),\n                                    result->nodes.size() + i);\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \",\n                              FormatNodeDefForError(fdef.node_def(i)));\n      return s;\n    }\n  }\n  // Emits one node for each fdef.node_def.\n  for (int i = 0; i < fdef.node_def_size(); ++i) {\n    s = helper.InstantiateNode(fdef.node_def(i), AttrSlice(&node_attrs[i]));\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In \",\n                              FormatNodeDefForError(fdef.node_def(i)));\n      return s;\n    }\n  }\n\n  // Emits nodes for the function's return values.\n  int ret_index = 0;\n  for (const OpDef::ArgDef& ret_def : sig.output_arg()) {\n    s = helper.AddReturnNode(ret_def, attr_values, fdef.ret(), ints_on_device,\n                             &ret_index);\n    if (!s.ok()) {\n      errors::AppendToMessage(&s, \"In function output \", Print(ret_def));\n      return s;\n    }\n  }\n\n  // Adds the actual node inputs using the input indexes.\n  helper.AddNodeInputs();\n\n  return Status::OK();\n}\n\nstring DebugString(const FunctionDef& func_def) { return Print(func_def); }\n\nstring DebugString(const GraphDef& instantiated_func_def) {\n  std::vector<const NodeDef*> ptrs;\n  for (const NodeDef& n : instantiated_func_def.node()) {\n    ptrs.push_back(&n);\n  }\n  return Print(ptrs);\n}\n\nstring DebugString(gtl::ArraySlice<NodeDef> instantiated_func_nodes) {\n  std::vector<const NodeDef*> ptrs;\n  for (const NodeDef& n : instantiated_func_nodes) {\n    ptrs.push_back(&n);\n  }\n  return Print(ptrs);\n}\n\nstring DebugStringWhole(const GraphDef& gdef) {\n  string ret;\n  for (const auto& fdef : gdef.library().function()) {\n    strings::StrAppend(&ret, Print(fdef));\n  }\n  strings::StrAppend(&ret, \"\\n\");\n  for (const auto& ndef : gdef.node()) {\n    strings::StrAppend(&ret, Print(ndef), \"\\n\");\n  }\n  return ret;\n}\n\nnamespace {\n\n// Returns the name -> attr mapping of fdef's attrs that have a value set. In\n// Python, it's possible to access unset attrs, which returns a default value\n// and adds an unset attr to the map.\nstd::map<string, AttrValue> GetSetAttrs(const FunctionDef& fdef) {\n  std::map<string, AttrValue> set_attrs;\n  for (const auto& pair : fdef.attr()) {\n    if (pair.second.value_case() != AttrValue::VALUE_NOT_SET) {\n      set_attrs[pair.first] = pair.second;\n    }\n  }\n  return set_attrs;\n}\n\n}  // end namespace\n\nbool FunctionDefsEqual(const FunctionDef& f1, const FunctionDef& f2) {\n  if (!OpDefEqual(f1.signature(), f2.signature())) return false;\n\n  std::map<string, AttrValue> f1_attrs = GetSetAttrs(f1);\n  std::map<string, AttrValue> f2_attrs = GetSetAttrs(f2);\n  if (f1_attrs.size() != f2_attrs.size()) return false;\n  for (const auto& iter1 : f1_attrs) {\n    auto iter2 = f2_attrs.find(iter1.first);\n    if (iter2 == f2_attrs.end()) return false;\n    if (!AreAttrValuesEqual(iter1.second, iter2->second)) return false;\n  }\n\n  if (!EqualRepeatedNodeDef(f1.node_def(), f2.node_def(), nullptr)) {\n    return false;\n  }\n\n  std::map<string, string> ret1(f1.ret().begin(), f1.ret().end());\n  std::map<string, string> ret2(f2.ret().begin(), f2.ret().end());\n  if (ret1 != ret2) return false;\n\n  std::map<string, string> control_ret1(f1.control_ret().begin(),\n                                        f1.control_ret().end());\n  std::map<string, string> control_ret2(f2.control_ret().begin(),\n                                        f2.control_ret().end());\n  if (control_ret1 != control_ret2) return false;\n\n  return true;\n}\n\nuint64 FunctionDefHash(const FunctionDef& fdef) {\n  // signature\n  uint64 h = OpDefHash(fdef.signature());\n\n  // attrs\n  std::map<string, AttrValue> attrs = GetSetAttrs(fdef);\n  for (const auto& p : attrs) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64Combine(AttrValueHash(p.second), h);\n  }\n\n  // node defs\n  h = Hash64Combine(RepeatedNodeDefHash(fdef.node_def()), h);\n\n  // output names\n  std::map<string, string> ret(fdef.ret().begin(), fdef.ret().end());\n  for (const auto& p : ret) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64(p.second.data(), p.second.size(), h);\n  }\n\n  // control output names\n  std::map<string, string> control_ret(fdef.control_ret().begin(),\n                                       fdef.control_ret().end());\n  for (const auto& p : control_ret) {\n    h = Hash64(p.first.data(), p.first.size(), h);\n    h = Hash64(p.second.data(), p.second.size(), h);\n  }\n\n  return h;\n}\n\nstatic constexpr const char* const kExecutorAttr = \"_executor\";\n\n/* static */\nstring FunctionLibraryRuntime::ExecutorType(const InstantiateOptions& options,\n                                            AttrSlice attrs) {\n  if (!options.executor_type.empty()) {\n    return options.executor_type;\n  } else if (const AttrValue* executor_attr = attrs.Find(kExecutorAttr)) {\n    return executor_attr->s();\n  } else {\n    return string();\n  }\n}\n\nnamespace {\nclass AttrKeyAndValue {\n public:\n  enum ValueRepresentationOp {\n    kRaw,\n    kCEscape,\n  };\n  AttrKeyAndValue(absl::string_view key_name, int key_suffix, string value,\n                  ValueRepresentationOp value_op = kRaw)\n      : key_name_(key_name),\n        key_suffix_(key_suffix),\n        value_op_(value_op),\n        value_(std::move(value)) {}\n\n  bool operator<(const AttrKeyAndValue& b) const {\n    if (key_name_ != b.key_name_) {\n      return key_name_ < b.key_name_;\n    } else if (key_suffix_ != b.key_suffix_) {\n      return key_suffix_ < b.key_suffix_;\n    } else {\n      return value_ < b.value_;\n    }\n  }\n\n  void AppendTo(bool first, string* s) const {\n    absl::string_view v;\n    bool add_escaped = false;\n    if ((value_op_ == kCEscape) && NeedsEscaping(value_)) {\n      // Use CEscape call below\n      add_escaped = true;\n    } else {\n      // Add raw value contents directly\n      v = value_;\n    }\n    if (key_suffix_ >= 0) {\n      strings::StrAppend(s, first ? \"\" : \",\", key_name_, key_suffix_, \"=\", v);\n    } else {\n      strings::StrAppend(s, first ? \"\" : \",\", key_name_, \"=\", v);\n    }\n    if (add_escaped) {\n      strings::StrAppend(s, absl::CEscape(value_));\n    }\n  }\n\n private:\n  static bool NeedsEscaping(const string& s) {\n    for (auto c : s) {\n      if (!isalnum(c) && (c != ' ')) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  absl::string_view key_name_;\n  int key_suffix_;  // -1 if missing\n  ValueRepresentationOp value_op_;\n  string value_;\n};\n}  // namespace\n\nstring GetFunctionResourceInputDevice(\n    const Tensor& input, const int arg_index, const FunctionDef& function_def,\n    absl::flat_hash_map<string, std::vector<string>>* composite_devices) {\n  const auto& handles = input.flat<ResourceHandle>();\n  const ResourceHandle& handle0 = handles(0);\n  string composite_device;\n  auto iter = function_def.arg_attr().find(arg_index);\n  if (iter != function_def.arg_attr().end()) {\n    auto arg_attr = iter->second.attr().find(\"_composite_device\");\n    if (arg_attr != iter->second.attr().end()) {\n      composite_device = arg_attr->second.s();\n    }\n  }\n  if (!composite_device.empty()) {\n    if (composite_devices->find(composite_device) == composite_devices->end()) {\n      for (int i = 0; i < handles.size(); ++i) {\n        (*composite_devices)[composite_device].push_back(handles(i).device());\n      }\n    }\n    return composite_device;\n  } else {\n    return handle0.device();\n  }\n}\n\nstring Canonicalize(const string& funcname, AttrSlice attrs,\n                    const FunctionLibraryRuntime::InstantiateOptions& options) {\n  absl::InlinedVector<AttrKeyAndValue, 8> entries;\n  entries.reserve(attrs.size() + static_cast<int>(!options.target.empty()) +\n                  options.input_devices.size());\n  for (const auto& p : attrs) {\n    if (p.first != kExecutorAttr) {\n      entries.push_back(AttrKeyAndValue(\n          p.first, -1, Print(p.second, /*hash_string_attrs=*/true)));\n    }\n  }\n  if (!options.target.empty()) {\n    entries.push_back(AttrKeyAndValue(\"_target\", -1, options.target,\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (int i = 0; i < options.input_devices.size(); ++i) {\n    entries.push_back(AttrKeyAndValue(\"_input_dev\", i, options.input_devices[i],\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (int i = 0; i < options.output_devices.size(); ++i) {\n    entries.push_back(AttrKeyAndValue(\"_output_dev\", i,\n                                      options.output_devices[i],\n                                      AttrKeyAndValue::kCEscape));\n  }\n  for (const auto& iter : options.input_resource_dtypes_and_shapes) {\n    entries.push_back(AttrKeyAndValue(\"_input_resource_dtype\", iter.first,\n                                      DataTypeString(iter.second.dtype)));\n    entries.push_back(AttrKeyAndValue(\"_input_resource_shape\", iter.first,\n                                      iter.second.shape.DebugString(),\n                                      AttrKeyAndValue::kCEscape));\n  }\n  if (options.lib_def) {\n    entries.push_back(AttrKeyAndValue(\n        \"_lib_def\", -1,\n        absl::StrCat(\"\", reinterpret_cast<uintptr_t>(options.lib_def))));\n  }\n  if (!options.state_handle.empty()) {\n    entries.push_back(\n        AttrKeyAndValue(\"_state_handle\", -1, options.state_handle));\n  }\n  string executor_type = FunctionLibraryRuntime::ExecutorType(options, attrs);\n  if (!executor_type.empty()) {\n    entries.push_back(AttrKeyAndValue(kExecutorAttr, -1, executor_type));\n  }\n  if (options.config_proto.ByteSize() > 0) {\n    string config_proto_serialized;\n    SerializeToStringDeterministic(options.config_proto,\n                                   &config_proto_serialized);\n    entries.push_back(AttrKeyAndValue(\"_config_proto\", -1,\n                                      config_proto_serialized,\n                                      AttrKeyAndValue::kCEscape));\n  }\n  std::sort(entries.begin(), entries.end());\n  string result = strings::StrCat(funcname, \"[\");\n  bool first = true;\n  for (const auto& entry : entries) {\n    entry.AppendTo(first, &result);\n    first = false;\n  }\n  result += \"]\";\n  return result;\n}\n\nstring Canonicalize(const string& funcname, AttrSlice attrs) {\n  static const FunctionLibraryRuntime::InstantiateOptions* kEmptyOptions =\n      new FunctionLibraryRuntime::InstantiateOptions;\n  return Canonicalize(funcname, attrs, *kEmptyOptions);\n}\n\nFunctionCallFrame::FunctionCallFrame(DataTypeSlice arg_types,\n                                     DataTypeSlice ret_types)\n    : arg_types_(arg_types.begin(), arg_types.end()),\n      ret_types_(ret_types.begin(), ret_types.end()) {\n  args_.resize(arg_types_.size());\n  rets_.resize(ret_types_.size());\n}\n\nFunctionCallFrame::~FunctionCallFrame() {}\n\nStatus FunctionCallFrame::SetArgs(gtl::ArraySlice<Tensor> args) {\n  // Input type checks.\n  if (args.size() != arg_types_.size()) {\n    return errors::InvalidArgument(\"Expects \", arg_types_.size(),\n                                   \" arguments, but \", args.size(),\n                                   \" is provided\");\n  }\n  for (size_t i = 0; i < args.size(); ++i) {\n    if (arg_types_[i] != args[i].dtype()) {\n      return errors::InvalidArgument(\n          \"Expects arg[\", i, \"] to be \", DataTypeString(arg_types_[i]), \" but \",\n          DataTypeString(args[i].dtype()), \" is provided\");\n    }\n    args_[i] = args[i];\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::GetRetvals(std::vector<Tensor>* rets) const {\n  rets->clear();\n  rets->reserve(rets_.size());\n  for (size_t i = 0; i < rets_.size(); ++i) {\n    const auto& item = rets_[i];\n    if (item.has_val) {\n      rets->push_back(item.val);\n    } else {\n      return errors::Internal(\"Retval[\", i, \"] does not have value\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::ConsumeRetvals(std::vector<Tensor>* rets,\n                                         bool allow_dead_tensors) {\n  rets->clear();\n  rets->reserve(rets_.size());\n  for (size_t i = 0; i < rets_.size(); ++i) {\n    if (rets_[i].has_val) {\n      rets->emplace_back(std::move(rets_[i].val));\n    } else if (allow_dead_tensors) {\n      rets->emplace_back();\n    } else {\n      return errors::Internal(\"Retval[\", i, \"] does not have value\");\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::GetArg(int index, const Tensor** val) {\n  if (index < 0 || static_cast<size_t>(index) >= args_.size()) {\n    return errors::InvalidArgument(\"GetArg \", index, \" is not within [0, \",\n                                   args_.size(), \")\");\n  }\n  *val = &args_[index];\n  return Status::OK();\n}\n\nStatus FunctionCallFrame::SetRetval(int index, const Tensor& val) {\n  if (index < 0 || static_cast<size_t>(index) >= rets_.size()) {\n    return errors::InvalidArgument(\"SetRetval \", index, \" is not within [0, \",\n                                   rets_.size(), \")\");\n  }\n  if (val.dtype() != ret_types_[index]) {\n    return errors::InvalidArgument(\n        \"Expects ret[\", index, \"] to be \", DataTypeString(ret_types_[index]),\n        \", but \", DataTypeString(val.dtype()), \" is provided.\");\n  }\n  Retval* item = &rets_[index];\n  if (!item->has_val) {\n    item->has_val = true;\n    item->val = val;\n  } else {\n    return errors::Internal(\"Retval[\", index, \"] has already been set.\");\n  }\n  return Status::OK();\n}\n\nFunctionLibraryDefinition::FunctionDefAndOpRegistration::\n    FunctionDefAndOpRegistration(const FunctionDef& fdef_in,\n                                 const StackTracesMap& stack_traces)\n    : fdef(fdef_in),\n      // Exact shape inference for functions is handled by ShapeRefiner.\n      // Here we pass a dummy shape inference function for legacy code paths.\n      op_registration_data(fdef.signature(), shape_inference::UnknownShape,\n                           true /* is_function */),\n      stack_traces(stack_traces) {}\n\nFunctionLibraryDefinition::FunctionLibraryDefinition(\n    const FunctionLibraryDefinition& other)\n    : default_registry_(other.default_registry_) {\n  tf_shared_lock l(other.mu_);\n  function_defs_ = other.function_defs_;\n  func_grad_ = other.func_grad_;\n}\n\nFunctionLibraryDefinition::FunctionLibraryDefinition(\n    const OpRegistryInterface* default_registry,\n    const FunctionDefLibrary& def_lib)\n    : default_registry_(default_registry),\n      function_defs_(def_lib.function_size()) {\n  for (const auto& fdef : def_lib.function()) {\n    // The latter function definition wins.\n    auto& ptr = function_defs_[fdef.signature().name()];\n    ptr.reset(new FunctionDefAndOpRegistration(fdef));\n  }\n  for (const auto& grad : def_lib.gradient()) {\n    func_grad_[grad.function_name()] = grad.gradient_func();\n  }\n}\n\nFunctionLibraryDefinition::~FunctionLibraryDefinition() {}\n\nbool FunctionLibraryDefinition::Contains(const string& func) const {\n  tf_shared_lock l(mu_);\n  return function_defs_.find(func) != function_defs_.end();\n}\n\nconst FunctionDef* FunctionLibraryDefinition::Find(const string& func) const {\n  tf_shared_lock l(mu_);\n  auto result = FindHelper(func);\n  if (result) {\n    return &result->fdef;\n  } else {\n    return nullptr;\n  }\n}\n\nstd::shared_ptr<FunctionLibraryDefinition::FunctionDefAndOpRegistration>\nFunctionLibraryDefinition::FindHelper(const string& func) const {\n  auto iter = function_defs_.find(func);\n  if (iter == function_defs_.end()) {\n    return nullptr;\n  } else {\n    return iter->second;\n  }\n}\n\nStatus FunctionLibraryDefinition::AddFunctionDef(\n    const FunctionDef& fdef, const StackTracesMap& stack_traces) {\n  mutex_lock l(mu_);\n  bool added;\n  return AddFunctionDefHelper(fdef, stack_traces, &added);\n}\n\nStatus FunctionLibraryDefinition::AddFunctionDefHelper(\n    const FunctionDef& fdef, const StackTracesMap& stack_traces, bool* added) {\n  *added = false;\n  std::shared_ptr<FunctionDefAndOpRegistration>& entry =\n      function_defs_[fdef.signature().name()];\n  if (entry) {\n    if (!FunctionDefsEqual(entry->fdef, fdef)) {\n      return errors::InvalidArgument(\n          \"Cannot add function '\", fdef.signature().name(),\n          \"' because a different function with the same name already \"\n          \"exists.\");\n    }\n    // Ignore duplicate FunctionDefs.\n    return Status::OK();\n  }\n  const OpDef* op_def;\n  if (default_registry_->LookUpOpDef(fdef.signature().name(), &op_def).ok()) {\n    return errors::InvalidArgument(\n        \"Cannot add function '\", fdef.signature().name(),\n        \"' because an op with the same name already exists.\");\n  }\n  entry = std::make_shared<FunctionDefAndOpRegistration>(fdef, stack_traces);\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddHelper(\n    std::shared_ptr<FunctionDefAndOpRegistration> registration, bool* added) {\n  *added = false;\n  std::shared_ptr<FunctionDefAndOpRegistration>& entry =\n      function_defs_[registration->fdef.signature().name()];\n  if (entry) {\n    if (!FunctionDefsEqual(entry->fdef, registration->fdef)) {\n      return errors::InvalidArgument(\n          \"Cannot add function '\", registration->fdef.signature().name(),\n          \"' because a different function with the same name already \"\n          \"exists.\");\n    }\n    // Ignore duplicate FunctionDefs.\n    return Status::OK();\n  }\n  const OpDef* op_def;\n  if (default_registry_\n          ->LookUpOpDef(registration->fdef.signature().name(), &op_def)\n          .ok()) {\n    return errors::InvalidArgument(\n        \"Cannot add function '\", registration->fdef.signature().name(),\n        \"' because an op with the same name already exists.\");\n  }\n  entry = std::move(registration);\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::CopyFunctionDefFrom(\n    const string& func, const FunctionLibraryDefinition& other) {\n  if (default_registry_ != other.default_registry_) {\n    return errors::InvalidArgument(\n        \"Cannot copy function '\", func,\n        \"' because CopyFunctionDefFrom() requires that both libraries have the \"\n        \"same default registry.\");\n  }\n  std::shared_ptr<FunctionDefAndOpRegistration> function_def;\n  {\n    tf_shared_lock l(other.mu_);\n    function_def = other.FindHelper(func);\n  }\n  if (!function_def) {\n    return errors::InvalidArgument(\n        \"Cannot copy function '\", func,\n        \"' because no function with that name exists in the other library.\");\n  }\n  {\n    mutex_lock l(mu_);\n    std::shared_ptr<FunctionDefAndOpRegistration>& entry = function_defs_[func];\n    if (entry) {\n      if (!FunctionDefsEqual(entry->fdef, function_def->fdef)) {\n        return errors::InvalidArgument(\n            \"Cannot copy function '\", func,\n            \"' because a different function with the same name already \"\n            \"exists.\");\n      }\n    } else {\n      entry = std::move(function_def);\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddGradientDef(const GradientDef& grad) {\n  mutex_lock l(mu_);\n  bool added;\n  return AddGradientDefHelper(grad, &added);\n}\n\nStatus FunctionLibraryDefinition::AddGradientDefHelper(const GradientDef& grad,\n                                                       bool* added) {\n  *added = false;\n  string* entry = &func_grad_[grad.function_name()];\n  if (!entry->empty()) {\n    if (*entry != grad.gradient_func()) {\n      return errors::InvalidArgument(\n          \"Cannot assign gradient function '\", grad.gradient_func(), \"' to '\",\n          grad.function_name(), \"' because it already has gradient function \",\n          \"'\", *entry, \"'\");\n    }\n    // Ignore duplicate GradientDefs\n    return Status::OK();\n  }\n  *entry = grad.gradient_func();\n  *added = true;\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddLibrary(\n    const FunctionLibraryDefinition& other) {\n  // Clone `other` to ensure thread-safety (grabbing `other`'s lock for\n  // the duration of the function could lead to deadlock).\n  FunctionLibraryDefinition clone(other);\n  mutex_lock l(mu_);\n  mutex_lock l2(clone.mu_);\n  // Remember the funcs and grads that we added successfully so that\n  // we can roll them back on error.\n  std::vector<string> funcs;\n  std::vector<string> funcs_with_grads;\n  Status s;\n  bool added;\n  for (auto iter : clone.function_defs_) {\n    s = AddHelper(iter.second, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs.push_back(iter.second->fdef.signature().name());\n    }\n  }\n  for (auto iter : clone.func_grad_) {\n    GradientDef grad;\n    grad.set_function_name(iter.first);\n    grad.set_gradient_func(iter.second);\n    s = AddGradientDefHelper(grad, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs_with_grads.push_back(grad.function_name());\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::AddLibrary(\n    const FunctionDefLibrary& lib_def) {\n  // Remember the funcs and grads that we added successfully so that\n  // we can roll them back on error.\n  mutex_lock l(mu_);\n  std::vector<string> funcs;\n  std::vector<string> funcs_with_grads;\n  Status s;\n  bool added;\n  for (const FunctionDef& fdef : lib_def.function()) {\n    s = AddFunctionDefHelper(fdef, /*stack_traces=*/{}, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs.push_back(fdef.signature().name());\n    }\n  }\n  for (const GradientDef& grad : lib_def.gradient()) {\n    s = AddGradientDefHelper(grad, &added);\n    if (!s.ok()) {\n      Status remove_status = Remove(funcs, funcs_with_grads);\n      if (!remove_status.ok()) {\n        return remove_status;\n      }\n      return s;\n    }\n    if (added) {\n      funcs_with_grads.push_back(grad.function_name());\n    }\n  }\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::ReplaceFunction(\n    const string& func, const FunctionDef& fdef,\n    const StackTracesMap& stack_traces) {\n  mutex_lock l(mu_);\n  bool added;\n  TF_RETURN_IF_ERROR(RemoveFunctionHelper(func));\n  TF_RETURN_IF_ERROR(AddFunctionDefHelper(fdef, stack_traces, &added));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::ReplaceGradient(const GradientDef& grad) {\n  mutex_lock l(mu_);\n  bool added;\n  TF_RETURN_IF_ERROR(RemoveGradient(grad.function_name()));\n  TF_RETURN_IF_ERROR(AddGradientDefHelper(grad, &added));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::RemoveFunction(const string& func) {\n  mutex_lock l(mu_);\n  TF_RETURN_IF_ERROR(RemoveFunctionHelper(func));\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::RemoveFunctionHelper(const string& func) {\n  const auto& i = function_defs_.find(func);\n  if (i == function_defs_.end()) {\n    return errors::InvalidArgument(\"Tried to remove non-existent function '\",\n                                   func, \"'.\");\n  }\n  function_defs_.erase(i);\n  return Status::OK();\n}\n\nvoid FunctionLibraryDefinition::Clear() {\n  mutex_lock l(mu_);\n  function_defs_.clear();\n  func_grad_.clear();\n}\n\nStatus FunctionLibraryDefinition::RemoveGradient(const string& func) {\n  const auto& i = func_grad_.find(func);\n  if (i == func_grad_.end()) {\n    return errors::InvalidArgument(\"Tried to remove non-existent gradient '\",\n                                   func, \"'.\");\n  }\n  func_grad_.erase(i);\n  return Status::OK();\n}\n\nStatus FunctionLibraryDefinition::Remove(\n    const std::vector<string>& funcs,\n    const std::vector<string>& funcs_with_grads) {\n  Status s;\n  for (const string& f : funcs) {\n    s = RemoveFunctionHelper(f);\n    if (!s.ok()) {\n      return s;\n    }\n  }\n  for (const string& f : funcs_with_grads) {\n    s = RemoveGradient(f);\n    if (!s.ok()) {\n      return s;\n    }\n  }\n  return Status::OK();\n}\n\nstring FunctionLibraryDefinition::FindGradient(const string& func) const {\n  tf_shared_lock l(mu_);\n  return gtl::FindWithDefault(func_grad_, func, \"\");\n}\n\nstring FunctionLibraryDefinition::FindGradientHelper(const string& func) const {\n  return gtl::FindWithDefault(func_grad_, func, \"\");\n}\n\nStatus FunctionLibraryDefinition::LookUp(\n    const string& op, const OpRegistrationData** op_reg_data) const {\n  tf_shared_lock l(mu_);\n  auto iter = function_defs_.find(op);\n  if (iter != function_defs_.end()) {\n    *op_reg_data = &iter->second->op_registration_data;\n    return Status::OK();\n  }\n  return default_registry_->LookUp(op, op_reg_data);\n}\n\nstring FunctionLibraryDefinition::UniqueFunctionName(StringPiece prefix) const {\n  tf_shared_lock l(mu_);\n  int index = 0;\n  string name = strings::StrCat(prefix, index);\n  while (function_defs_.find(name) != function_defs_.end()) {\n    ++index;\n    name = strings::StrCat(prefix, index);\n  }\n  return name;\n}\n\nconst FunctionDef* FunctionLibraryDefinition::GetAttrImpl(\n    const NodeDef& ndef) const {\n  if (ndef.op() != kGradientOp) {\n    // If 'ndef' calls a function and the function's def has the attr,\n    // returns it.\n    return Find(ndef.op());\n  }\n\n  // If ndef is SymbolicGradient[f=Foo], we use Foo's gradient or\n  // Foo's attributes.\n  const NameAttrList* forward_func_attrs;\n  if (!TryGetNodeAttr(ndef, kFuncAttr, &forward_func_attrs)) {\n    return nullptr;\n  }\n  const string& func_name = forward_func_attrs->name();\n  {\n    tf_shared_lock l(mu_);\n    const string& grad_name = FindGradientHelper(func_name);\n    // If 'func' has a user-defined gradient function, uses the grad\n    // function's attrs to see if noinline is specified. Otherwise,\n    // uses func's attrs.\n    if (!grad_name.empty()) {\n      if (const auto helper = FindHelper(grad_name)) {\n        return &(helper->fdef);\n      } else {\n        return nullptr;\n      }\n    }\n    if (const auto helper = FindHelper(func_name)) {\n      return &(helper->fdef);\n    } else {\n      return nullptr;\n    }\n  }\n}\n\nstd::vector<string> FunctionLibraryDefinition::ListFunctionNames() const {\n  std::vector<string> function_names;\n  tf_shared_lock l(mu_);\n  function_names.reserve(function_defs_.size());\n  for (const auto& it : function_defs_) {\n    function_names.emplace_back(it.first);\n  }\n  return function_names;\n}\n\nFunctionDefLibrary FunctionLibraryDefinition::ToProto() const {\n  FunctionDefLibrary lib;\n  tf_shared_lock l(mu_);\n  for (const auto& f : function_defs_) {\n    *lib.add_function() = f.second->fdef;\n  }\n  for (const auto& g : func_grad_) {\n    GradientDef* gd = lib.add_gradient();\n    gd->set_function_name(g.first);\n    gd->set_gradient_func(g.second);\n  }\n  return lib;\n}\n\ntemplate <typename T>\nStatus FunctionLibraryDefinition::GetAttr(const NodeDef& ndef,\n                                          const string& attr, T* value) const {\n  const FunctionDef* fdef = GetAttrImpl(ndef);\n  if (fdef && TryGetNodeAttr(AttrSlice(&fdef->attr()), attr, value)) {\n    return Status::OK();\n  }\n  return errors::InvalidArgument(\"Attr \", attr, \" is not defined.\");\n}\n\ntemplate <typename T>\nStatus FunctionLibraryDefinition::GetAttr(const Node& node, const string& attr,\n                                          T* value) const {\n  return GetAttr(node.def(), attr, value);\n}\n\n#define GET_ATTR(T)                                                            \\\n  template Status FunctionLibraryDefinition::GetAttr(const Node&,              \\\n                                                     const string&, T*) const; \\\n  template Status FunctionLibraryDefinition::GetAttr(const NodeDef&,           \\\n                                                     const string&, T*) const;\nGET_ATTR(string)\nGET_ATTR(bool)\n#undef GET_ATTR\n\nnamespace {\n\nconstexpr char kApiImplements[] = \"api_implements\";\n\nstd::set<string> ReachableFunctions(\n    const FunctionLibraryDefinition& flib,\n    const protobuf::RepeatedPtrField<NodeDef>& nodes) {\n  // Functions that are reachable from the graph.\n  std::set<string> reachable_funcs;\n\n  // For any functions, if it has attribute \"api_implements\" =\n  // \"some_interface\" and it is reachable, then it means any other\n  // function with same attribute name and value could also be potentially\n  // reachable, eg via implementation_selector swapping the nodedef.\n  absl::flat_hash_set<string> reachable_api_interface;\n\n  // Functions might be reachable from the nested function calls, so we keep a\n  // queue of functions that we have to check.\n  gtl::InlinedVector<const FunctionDef*, 4> func_queue;\n\n  // Add reachable and not already processed functions to the functions queue.\n  const auto add_to_func_queue = [&](const string& func_name) {\n    const FunctionDef* func = flib.Find(func_name);\n    if (func && reachable_funcs.find(func_name) == reachable_funcs.end()) {\n      func_queue.push_back(func);\n    }\n  };\n\n  // If any function with certain API name is reachable, all the other functions\n  // with same API name should also be checked.\n  const auto add_function_with_api_interface = [&](const string& api_name) {\n    if (!reachable_api_interface.contains(api_name)) {\n      reachable_api_interface.insert(api_name);\n      for (const auto& func_name : flib.ListFunctionNames()) {\n        const auto& func_def = flib.Find(func_name);\n        const auto attr_it = func_def->attr().find(kApiImplements);\n        if (attr_it != func_def->attr().end() &&\n            attr_it->second.s() == api_name) {\n          add_to_func_queue(func_name);\n        }\n      }\n    }\n  };\n\n  // Add all the functions that are reachable from the given node to the queue.\n  const auto process_node = [&](const NodeDef& node) {\n    // Node itself can be a call to the function.\n    add_to_func_queue(node.op());\n\n    // Or node can have an attribute referencing a function.\n    for (const auto& attr : node.attr()) {\n      const auto& attr_value = attr.second;\n\n      // 1. AttrValue.func\n      if (attr_value.has_func()) {\n        add_to_func_queue(attr_value.func().name());\n      }\n\n      // 2. AttrValue.ListValue.func\n      if (attr_value.has_list()) {\n        for (const auto& func : attr_value.list().func()) {\n          add_to_func_queue(func.name());\n        }\n      }\n    }\n  };\n\n  // Add all functions that are directly called from the optimized graph.\n  std::for_each(nodes.begin(), nodes.end(), process_node);\n\n  // Process all reachable functions.\n  while (!func_queue.empty()) {\n    const FunctionDef* func = func_queue.back();\n    func_queue.pop_back();\n\n    const string& func_name = func->signature().name();\n    reachable_funcs.insert(func_name);\n\n    const auto attr_it = func->attr().find(kApiImplements);\n    if (attr_it != func->attr().end()) {\n      add_function_with_api_interface(attr_it->second.s());\n    }\n\n    // Find all the functions called from the function body.\n    const auto& func_body = func->node_def();\n    std::for_each(func_body.begin(), func_body.end(), process_node);\n\n    // Check if the function has a registered gradient.\n    const string grad_func_name = flib.FindGradient(func_name);\n    if (!grad_func_name.empty()) add_to_func_queue(grad_func_name);\n  }\n\n  return reachable_funcs;\n}\n\nFunctionLibraryDefinition ReachableFunctionLibraryDefinition(\n    const FunctionLibraryDefinition& flib,\n    const protobuf::RepeatedPtrField<NodeDef>& nodes) {\n  std::set<string> reachable_funcs = ReachableFunctions(flib, nodes);\n\n  FunctionLibraryDefinition reachable_flib(flib.default_registry(),\n                                           FunctionDefLibrary());\n\n  for (const string& func_name : reachable_funcs) {\n    // This should never fail, because we copy functions from a valid flib and\n    // use the same default registry.\n    Status added = reachable_flib.CopyFunctionDefFrom(func_name, flib);\n    TF_DCHECK_OK(added);\n\n    const string grad_func_name = flib.FindGradient(func_name);\n    if (!grad_func_name.empty()) {\n      GradientDef grad;\n      grad.set_function_name(func_name);\n      grad.set_gradient_func(grad_func_name);\n      // It can only fail if function already has a gradient function.\n      const Status added_grad = reachable_flib.AddGradientDef(grad);\n      TF_DCHECK_OK(added_grad);\n    }\n  }\n\n  return reachable_flib;\n}\n\nstring AllocatorAttributesToString(\n    const std::vector<AllocatorAttributes>& attrs) {\n  string result(\"[\");\n  // AllocatorAttribute::DebugString produces around 85 bytes now.\n  result.reserve(100 * attrs.size());\n  for (const AllocatorAttributes& attr : attrs) {\n    result.append(attr.DebugString());\n    result.append(\", \");\n  }\n  if (!attrs.empty()) {\n    result.resize(result.size() - 2);\n  }\n  result.append(\"]\");\n  return result;\n}\n\nconst char* IsSet(void* ptr) { return ptr == nullptr ? \"unset\" : \"set\"; }\n\n}  // namespace\n\nFunctionLibraryDefinition FunctionLibraryDefinition::ReachableDefinitions(\n    const GraphDef& graph) const {\n  return ReachableFunctionLibraryDefinition(*this, graph.node());\n}\n\nFunctionLibraryDefinition FunctionLibraryDefinition::ReachableDefinitions(\n    const FunctionDef& func) const {\n  return ReachableFunctionLibraryDefinition(*this, func.node_def());\n}\n\nstring FunctionLibraryRuntime::Options::DebugString() const {\n  return absl::StrCat(\n      \"FLR::Options(step_id=\", step_id, \" rendezvous=\", IsSet(rendezvous),\n      \" cancellation_manager=\", IsSet(cancellation_manager),\n      \" collective_executor=\", IsSet(collective_executor),\n      \" step_container=\", IsSet(step_container),\n      \" stats_collector=\", IsSet(stats_collector), \" runner=\", IsSet(runner),\n      \" remote_execution=\", remote_execution, \" source_device=\", source_device,\n      \" create_rendezvous=\", create_rendezvous,\n      \" allow_dead_tensors=\", allow_dead_tensors,\n      \" args_alloc_attrs=\", AllocatorAttributesToString(args_alloc_attrs),\n      \" rets_alloc_attrs=\", AllocatorAttributesToString(rets_alloc_attrs), \")\");\n}\n\nvoid FunctionDefHelper::AttrValueWrapper::InitFromString(StringPiece val) {\n  if (val.size() >= 2 && val[0] == '$') {\n    proto.set_placeholder(val.data() + 1, val.size() - 1);\n  } else {\n    SetAttrValue(val, &proto);\n  }\n}\n\nFunctionDefHelper::AttrValueWrapper FunctionDefHelper::FunctionRef(\n    const string& name,\n    gtl::ArraySlice<std::pair<string, AttrValueWrapper>> attrs) {\n  AttrValueWrapper ret;\n  ret.proto.mutable_func()->set_name(name);\n  for (const auto& a : attrs) {\n    ret.proto.mutable_func()->mutable_attr()->insert({a.first, a.second.proto});\n  }\n  return ret;\n}\n\nNodeDef FunctionDefHelper::Node::ToNodeDef() const {\n  NodeDef n;\n  n.set_op(this->op);\n  n.set_name(GetName());\n  for (const auto& a : this->attr) {\n    n.mutable_attr()->insert({a.first, a.second.proto});\n  }\n  for (const string& a : this->arg) {\n    n.add_input(a);\n  }\n  for (const string& d : this->dep) {\n    n.add_input(strings::StrCat(\"^\", d));\n  }\n  if (!this->device.empty()) {\n    n.set_device(this->device);\n  }\n  if (!this->original_node_names.empty()) {\n    *n.mutable_experimental_debug_info()->mutable_original_node_names() = {\n        this->original_node_names.begin(), this->original_node_names.end()};\n  }\n  if (!this->original_func_names.empty()) {\n    *n.mutable_experimental_debug_info()->mutable_original_func_names() = {\n        this->original_func_names.begin(), this->original_func_names.end()};\n  }\n  return n;\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Create(\n    const string& function_name, gtl::ArraySlice<string> in_def,\n    gtl::ArraySlice<string> out_def, gtl::ArraySlice<string> attr_def,\n    gtl::ArraySlice<Node> node_def,\n    gtl::ArraySlice<std::pair<string, string>> ret_def,\n    gtl::ArraySlice<std::pair<string, string>> control_ret_def) {\n  FunctionDef fdef;\n\n  // Signature\n  OpDefBuilder b(function_name);\n  for (const auto& i : in_def) b.Input(i);\n  for (const auto& o : out_def) b.Output(o);\n  for (const auto& a : attr_def) b.Attr(a);\n  for (const auto& c : control_ret_def) b.ControlOutput(c.first);\n\n  OpRegistrationData op_reg_data;\n  TF_CHECK_OK(b.Finalize(&op_reg_data));\n  fdef.mutable_signature()->Swap(&op_reg_data.op_def);\n\n  // Function body\n  for (const auto& n : node_def) {\n    *(fdef.add_node_def()) = n.ToNodeDef();\n  }\n\n  // Returns\n  for (const auto& r : ret_def) {\n    fdef.mutable_ret()->insert({r.first, r.second});\n  }\n\n  // Control returns\n  for (const auto& cr : control_ret_def) {\n    fdef.mutable_control_ret()->insert({cr.first, cr.second});\n  }\n\n  auto* op_def_registry = OpRegistry::Global();\n  // Check if any op is stateful.\n  for (const auto& n : node_def) {\n    const OpDef* op_def = nullptr;\n    auto status = op_def_registry->LookUpOpDef(n.op, &op_def);\n    // Lookup can fail if e.g. we are calling a function that was not yet\n    // defined.  If it happens, conservatively assume the op is stateful.\n    if (!status.ok() || op_def->is_stateful()) {\n      fdef.mutable_signature()->set_is_stateful(true);\n    }\n  }\n\n  return fdef;\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Create(\n    const string& function_name, gtl::ArraySlice<string> in_def,\n    gtl::ArraySlice<string> out_def, gtl::ArraySlice<string> attr_def,\n    gtl::ArraySlice<Node> node_def,\n    gtl::ArraySlice<std::pair<string, string>> ret_def) {\n  return Create(function_name, in_def, out_def, attr_def, node_def, ret_def,\n                /*control_ret_def=*/{});\n}\n\n/* static */\nFunctionDef FunctionDefHelper::Define(const string& name,\n                                      gtl::ArraySlice<string> arg_def,\n                                      gtl::ArraySlice<string> ret_def,\n                                      gtl::ArraySlice<string> attr_def,\n                                      gtl::ArraySlice<Node> node_def) {\n  FunctionDef fdef;\n  OpDefBuilder b(name);\n  for (const auto& a : arg_def) b.Input(a);\n  for (const auto& r : ret_def) b.Output(r);\n  for (const auto& a : attr_def) b.Attr(a);\n\n  OpRegistrationData op_reg_data;\n  TF_CHECK_OK(b.Finalize(&op_reg_data));\n  fdef.mutable_signature()->Swap(&op_reg_data.op_def);\n\n  // Mapping from legacy output names to NodeDef outputs.\n  std::unordered_map<string, string> ret_index;\n  for (const auto& a : fdef.signature().input_arg()) {\n    ret_index[a.name()] = a.name();\n  }\n\n  // For looking up OpDefs\n  auto* op_def_registry = OpRegistry::Global();\n\n  // Function body\n  for (const auto& src : node_def) {\n    NodeDef* n = fdef.add_node_def();\n    n->set_op(src.op);\n    n->set_name(src.GetName());\n    for (const auto& a : src.attr) {\n      n->mutable_attr()->insert({a.first, a.second.proto});\n    }\n    for (const string& a : src.arg) {\n      const auto iter = ret_index.find(a);\n      CHECK(iter != ret_index.end())\n          << \"Node input '\" << a << \"' in '\" << n->name() << \"' of \" << name;\n      n->add_input(iter->second);\n    }\n    for (const string& d : src.dep) {\n      n->add_input(strings::StrCat(\"^\", d));\n    }\n\n    // Add the outputs of this node to ret_index.\n    const OpDef* op_def = nullptr;\n    TF_CHECK_OK(op_def_registry->LookUpOpDef(n->op(), &op_def)) << n->op();\n    CHECK(op_def != nullptr) << n->op();\n    NameRangeMap output_names;\n    TF_CHECK_OK(NameRangesForNode(*n, *op_def, nullptr, &output_names));\n    for (const auto& o : output_names) {\n      CHECK_LE(o.second.second, src.ret.size())\n          << \"Missing ret for output '\" << o.first << \"' in '\" << n->name()\n          << \"' of \" << name;\n      for (int i = o.second.first; i < o.second.second; ++i) {\n        ret_index[src.ret[i]] =\n            strings::StrCat(n->name(), \":\", o.first, \":\", i - o.second.first);\n      }\n    }\n    if (op_def->is_stateful()) fdef.mutable_signature()->set_is_stateful(true);\n  }\n\n  // Returns\n  for (const auto& r : fdef.signature().output_arg()) {\n    const auto iter = ret_index.find(r.name());\n    CHECK(iter != ret_index.end()) << \"Return '\" << r.name() << \"' in \" << name;\n    fdef.mutable_ret()->insert({r.name(), iter->second});\n  }\n  return fdef;\n}\n\nFunctionDef FunctionDefHelper::Define(gtl::ArraySlice<string> arg_def,\n                                      gtl::ArraySlice<string> ret_def,\n                                      gtl::ArraySlice<string> attr_def,\n                                      gtl::ArraySlice<Node> node_def) {\n  return Define(\"_\", arg_def, ret_def, attr_def, node_def);\n}\n\nnamespace gradient {\n\ntypedef std::unordered_map<string, Creator> OpGradFactory;\n\nOpGradFactory* GetOpGradFactory() {\n  static OpGradFactory* factory = new OpGradFactory;\n  return factory;\n}\n\nbool RegisterOp(const string& op, Creator func) {\n  CHECK(GetOpGradFactory()->insert({op, func}).second)\n      << \"Duplicated gradient for \" << op;\n  return true;\n}\n\nStatus GetOpGradientCreator(const string& op, Creator* creator) {\n  auto fac = GetOpGradFactory();\n  auto iter = fac->find(op);\n  if (iter == fac->end()) {\n    return errors::NotFound(\"No gradient defined for op: \", op);\n  }\n  *creator = iter->second;\n  return Status::OK();\n}\n\n}  // end namespace gradient\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/framework/function.cc"], "buggy_code_start_loc": [184], "buggy_code_end_loc": [185], "fixing_code_start_loc": [184], "fixing_code_end_loc": [187], "type": "CWE-617", "message": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2022-23586", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-04T23:15:14.977", "lastModified": "2022-02-10T17:33:30.730", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range."}, {"lang": "es", "value": "Tensorflow es un Marco de Aprendizaje Autom\u00e1tico de C\u00f3digo Abierto. Un usuario malicioso puede causar una denegaci\u00f3n de servicio alterando un \"SavedModel\" de tal manera que las aserciones en \"function.cc\" sean falsificadas y sea bloqueado el int\u00e9rprete de Python. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.8.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.7.1, TensorFlow versi\u00f3n 2.6.3, y TensorFlow versi\u00f3n 2.5.3, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.5.2", "matchCriteriaId": "688150BF-477C-48FC-9AEF-A79AC57A6DDC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndIncluding": "2.6.2", "matchCriteriaId": "C9E69B60-8C97-47E2-9027-9598B8392E5D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.7.0:*:*:*:*:*:*:*", "matchCriteriaId": "2EDFAAB8-799C-4259-9102-944D4760DA2C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/framework/function.cc", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/3d89911481ba6ebe8c88c1c0b595412121e6c645", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-43jf-985q-588j", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/3d89911481ba6ebe8c88c1c0b595412121e6c645"}}