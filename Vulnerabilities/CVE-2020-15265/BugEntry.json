{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#define EIGEN_USE_THREADS\n\n#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\n// Simulate quantization precision loss in a float tensor by:\n// 1. Quantize the tensor to fixed point numbers, which should match the target\n//    quantization method when it is used in inference.\n// 2. Dequantize it back to floating point numbers for the following ops, most\n//    likely matmul.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV2Op : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV2Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n\n    string round_mode_string;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n    OP_REQUIRES(\n        ctx,\n        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n        errors::InvalidArgument(\"Round mode string must be \"\n                                \"'HALF_UP' or \"\n                                \"'HALF_TO_EVEN', is '\" +\n                                round_mode_string + \"'\"));\n    if (round_mode_string == \"HALF_UP\") {\n      round_mode_ = ROUND_HALF_UP;\n    } else if (round_mode_string == \"HALF_TO_EVEN\") {\n      round_mode_ = ROUND_HALF_TO_EVEN;\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n\n private:\n  int num_bits_;\n  int axis_;\n  QuantizerRoundMode round_mode_;\n  bool signed_input_;\n  bool range_given_;\n  bool narrow_range_;\n};\n\n// Implementation of QuantizeAndDequantizeV4GradientOp.\n// When back-propagating the error through a quantized layer, the following\n// paper gives evidence that clipped-ReLU is better than non-clipped:\n// \"Deep Learning with Low Precision by Half-wave Gaussian Quantization\"\n// http://zpascal.net/cvpr2017/Cai_Deep_Learning_With_CVPR_2017_paper.pdf\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV4GradientOp : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV4GradientOp(OpKernelConstruction* ctx)\n      : OpKernel::OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    const Tensor& input_max_tensor = ctx->input(3);\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }\n\n private:\n  int axis_;\n};\n\n// Simulate quantization precision loss in a float tensor by:\n// 1. Quantize the tensor to fixed point numbers, which should match the target\n//    quantization method when it is used in inference.\n// 2. Dequantize it back to floating point numbers for the following ops, most\n//    likely matmul.\n// Almost identical to QuantizeAndDequantizeV2Op, except that num_bits is a\n// tensor.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV3Op : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV3Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    Tensor num_bits_tensor;\n    num_bits_tensor = ctx->input(3);\n    int num_bits_val = num_bits_tensor.scalar<int32>()();\n\n    OP_REQUIRES(\n        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n                                \" with signed_input_ \", signed_input_));\n\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_,\n        num_bits_val, range_given_, &input_min_tensor, &input_max_tensor,\n        ROUND_HALF_TO_EVEN, narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_val, range_given_, &input_min_tensor, &input_max_tensor,\n        ROUND_HALF_TO_EVEN, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n\n private:\n  int axis_;\n  bool signed_input_;\n  bool range_given_;\n  bool narrow_range_;\n};\n\n// DEPRECATED: Use QuantizeAndDequantizeV2Op.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeOp : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n    if (range_given_) {\n      OP_REQUIRES(\n          ctx, input_min_ <= input_max_,\n          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                  \" > input_max \", input_max_));\n    }\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    // One global scale.\n    Tensor input_min_tensor(DataTypeToEnum<T>::value, TensorShape());\n    Tensor input_max_tensor(DataTypeToEnum<T>::value, TensorShape());\n    // Initialize the tensors with the values in the Attrs.\n    input_min_tensor.template scalar<T>()() = static_cast<T>(input_min_);\n    input_max_tensor.template scalar<T>()() = static_cast<T>(input_max_);\n\n    functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> functor;\n    functor(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_,\n            num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n            ROUND_HALF_TO_EVEN, /*narrow_range=*/false, output->flat<T>());\n  }\n\n private:\n  bool signed_input_;\n  int num_bits_;\n  bool range_given_;\n  float input_min_;\n  float input_max_;\n};\n\n// Specializations for CPUDevice.\n\nnamespace functor {\ntemplate <typename T>\nstruct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,\n                  const bool signed_input, const int num_bits,\n                  const bool range_given, Tensor* input_min_tensor,\n                  Tensor* input_max_tensor, QuantizerRoundMode round_mode,\n                  bool narrow_range, typename TTypes<T>::Vec out) {\n    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(\n        d, input, signed_input, num_bits, range_given, input_min_tensor,\n        input_max_tensor, round_mode, narrow_range, out);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,\n                  bool signed_input, int num_bits, bool range_given,\n                  Tensor* input_min_tensor, Tensor* input_max_tensor,\n                  QuantizerRoundMode round_mode, bool narrow_range,\n                  typename TTypes<T, 3>::Tensor out) {\n    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(\n        d, input, signed_input, num_bits, range_given, input_min_tensor,\n        input_max_tensor, round_mode, narrow_range, out);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,\n                  typename TTypes<T>::ConstFlat input,\n                  typename TTypes<T>::ConstScalar input_min_tensor,\n                  typename TTypes<T>::ConstScalar input_max_tensor,\n                  typename TTypes<T>::Flat input_backprop,\n                  typename TTypes<T>::Scalar input_min_backprop,\n                  typename TTypes<T>::Scalar input_max_backprop) {\n    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(\n        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n        input_min_backprop, input_max_backprop);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d,\n                  typename TTypes<T, 3>::ConstTensor gradient,\n                  typename TTypes<T, 3>::ConstTensor input,\n                  const Tensor* input_min_tensor,\n                  const Tensor* input_max_tensor,\n                  typename TTypes<T, 3>::Tensor input_backprop,\n                  typename TTypes<T>::Flat input_min_backprop,\n                  typename TTypes<T>::Flat input_max_backprop) {\n    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(\n        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n        input_min_backprop, input_max_backprop);\n  }\n};\n\ntemplate struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,\n                                                                      float>;\ntemplate struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n    CPUDevice, double>;\n\n}  // namespace functor\n\n#define REGISTER_CPU_KERNEL(T)                                                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      QuantizeAndDequantizeOp<CPUDevice, T>);\nTF_CALL_float(REGISTER_CPU_KERNEL);\nTF_CALL_double(REGISTER_CPU_KERNEL);\n#undef REGISTER_CPU_KERNEL\n\n#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)\n#define REGISTER_GPU_KERNEL(T)                                                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .HostMemory(\"num_bits\")                          \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n      QuantizeAndDequantizeOp<GPUDevice, T>);\nTF_CALL_float(REGISTER_GPU_KERNEL);\nTF_CALL_double(REGISTER_GPU_KERNEL);\n#undef REGISTER_GPU_KERNEL\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for array_ops.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nimport time\nimport unittest\n\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import sparse_tensor\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import test_ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_array_ops\nfrom tensorflow.python.ops import gradient_checker_v2\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import map_fn\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import test as test_lib\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass BatchMatrixTransposeTest(test_util.TensorFlowTestCase):\n\n  def testNonBatchMatrix(self):\n    matrix = [[1, 2, 3], [4, 5, 6]]  # Shape (2, 3)\n    expected_transposed = [[1, 4], [2, 5], [3, 6]]  # Shape (3, 2)\n    transposed = array_ops.matrix_transpose(matrix)\n    self.assertEqual((3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testConjugate(self):\n    m = [[1 + 1j, 2 + 2j, 3 + 3j], [4 + 4j, 5 + 5j, 6 + 6j]]\n    expected_transposed = [[1 - 1j, 4 - 4j], [2 - 2j, 5 - 5j], [3 - 3j, 6 - 6j]]\n    matrix = ops.convert_to_tensor(m)\n    transposed = array_ops.matrix_transpose(matrix, conjugate=True)\n    self.assertEqual((3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testBatchMatrix(self):\n    matrix_0 = [[1, 2, 3], [4, 5, 6]]\n    matrix_0_t = [[1, 4], [2, 5], [3, 6]]\n    matrix_1 = [[11, 22, 33], [44, 55, 66]]\n    matrix_1_t = [[11, 44], [22, 55], [33, 66]]\n    batch_matrix = [matrix_0, matrix_1]  # Shape (2, 2, 3)\n    expected_transposed = [matrix_0_t, matrix_1_t]  # Shape (2, 3, 2)\n    transposed = array_ops.matrix_transpose(batch_matrix)\n    self.assertEqual((2, 3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testNonBatchMatrixDynamicallyDefined(self):\n    # needs explicit `constant` because lists are not automatically\n    # converted to sensors when applying `transpose` below\n    matrix = constant_op.constant([[1, 2, 3], [4, 5, 6]])  # Shape (2, 3)\n    expected_transposed = [[1, 4], [2, 5], [3, 6]]  # Shape (3, 2)\n\n    @def_function.function(input_signature=[\n        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n    ])\n    def transpose(matrix):\n      self.assertIs(matrix.shape.ndims, None)\n      return array_ops.matrix_transpose(matrix)\n\n    self.assertAllEqual(expected_transposed, transpose(matrix))\n\n  def testBatchMatrixDynamicallyDefined(self):\n    matrix_0 = [[1, 2, 3], [4, 5, 6]]\n    matrix_0_t = [[1, 4], [2, 5], [3, 6]]\n    matrix_1 = [[11, 22, 33], [44, 55, 66]]\n    matrix_1_t = [[11, 44], [22, 55], [33, 66]]\n    # needs explicit `constant` because lists are not automatically\n    # converted to sensors when applying `transpose` below\n    batch_matrix = constant_op.constant([matrix_0, matrix_1])  # Shape (2, 2, 3)\n    expected_transposed = [matrix_0_t, matrix_1_t]  # Shape (2, 3, 2)\n\n    @def_function.function(input_signature=[\n        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n    ])\n    def transpose(matrix):\n      self.assertIs(matrix.shape.ndims, None)\n      return array_ops.matrix_transpose(matrix)\n\n    self.assertAllEqual(expected_transposed, transpose(batch_matrix))\n\n  def testTensorWithStaticRankLessThanTwoRaisesBecauseNotAMatrix(self):\n    vector = [1, 2, 3]\n    with self.assertRaisesRegex(ValueError, \"should be a \"):\n      array_ops.matrix_transpose(vector)\n\n\nclass BooleanMaskTest(test_util.TensorFlowTestCase):\n\n  def setUp(self):\n    self.rng = np.random.RandomState(42)\n\n  def CheckVersusNumpy(self, ndims_mask, arr_shape, make_mask=None, axis=None):\n    \"\"\"Check equivalence between boolean_mask and numpy masking.\"\"\"\n    if make_mask is None:\n      make_mask = lambda shape: self.rng.randint(0, 2, size=shape).astype(bool)\n    arr = np.random.rand(*arr_shape)\n    mask = make_mask(arr_shape[:ndims_mask])\n    if axis is not None:\n      mask = make_mask(arr_shape[axis:ndims_mask + axis])\n    if axis is None or axis == 0:\n      masked_arr = arr[mask]\n    elif axis == 1:\n      masked_arr = arr[:, mask]\n    elif axis == 2:\n      masked_arr = arr[:, :, mask]\n    with self.cached_session():\n      masked_tensor = array_ops.boolean_mask(arr, mask, axis=axis)\n\n      # Leading dimension size of masked_tensor is always unknown until runtime\n      # since we don't how many elements will be kept.\n      leading = 1 if axis is None else axis + 1\n      self.assertAllEqual(masked_tensor.get_shape()[leading:],\n                          masked_arr.shape[leading:])\n\n      self.assertAllClose(masked_arr, masked_tensor)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim2Axis1(self):\n    ndims_mask = 1\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape, axis=1)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim2Axis1(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape, axis=1)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim1(self):\n    ndims_mask = 1\n    for arr_shape in [(1,), (2,), (3,), (10,)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim2(self):\n    ndims_mask = 1\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim2(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim3(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1, 1), (1, 2, 2), (2, 2, 1)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testEmptyInput2D(self):\n    mask = np.array([True, False])\n    arr = np.array([[], []]).astype(np.float32)\n    numpy_result = arr[mask]\n    tf_result = array_ops.boolean_mask(arr, mask)\n    self.assertAllEqual(numpy_result.shape[1:], tf_result.get_shape()[1:])\n    with self.cached_session():\n      self.assertAllClose(numpy_result, tf_result)\n\n  @test_util.run_deprecated_v1\n  def testEmptyInput1D(self):\n    mask = np.array([]).astype(bool)\n    arr = np.array([]).astype(np.float32)\n    numpy_result = arr[mask]\n    tf_result = array_ops.boolean_mask(arr, mask)\n    self.assertAllEqual(numpy_result.shape[1:], tf_result.get_shape()[1:])\n    with self.cached_session():\n      self.assertAllClose(numpy_result, tf_result)\n\n  @test_util.run_deprecated_v1\n  def testEmptyOutput(self):\n    make_mask = lambda shape: np.zeros(shape, dtype=bool)\n    for ndims_mask in range(1, 4):\n      for ndims_arr in range(ndims_mask, ndims_mask + 3):\n        for _ in range(3):\n          with self.subTest(ndims_mask=ndims_mask, ndims_arr=ndims_arr, _=_):\n            arr_shape = np.random.randint(1, 5, size=ndims_arr)\n            self.CheckVersusNumpy(ndims_mask, arr_shape, make_mask=make_mask)\n\n  @test_util.run_deprecated_v1\n  def testWorksWithDimensionsEqualToNoneDuringGraphBuild(self):\n    # The rank of the mask tensor must be specified. This is explained\n    # in the docstring as well.\n    with self.cached_session() as sess:\n      ph_tensor = array_ops.placeholder(dtypes.int32, shape=None)\n      ph_mask = array_ops.placeholder(dtypes.bool, shape=[None])\n\n      arr = np.array([[1, 2], [3, 4]])\n      mask = np.array([False, True])\n\n      masked_tensor = sess.run(\n          array_ops.boolean_mask(ph_tensor, ph_mask),\n          feed_dict={\n              ph_tensor: arr,\n              ph_mask: mask\n          })\n      np.testing.assert_allclose(masked_tensor, arr[mask])\n\n  @test_util.run_deprecated_v1\n  def testMaskDimensionsSetToNoneRaises(self):\n    # The rank of the mask tensor must be specified. This is explained\n    # in the docstring as well.\n    with self.cached_session():\n      tensor = array_ops.placeholder(dtypes.int32, shape=[None, 2])\n      mask = array_ops.placeholder(dtypes.bool, shape=None)\n      with self.assertRaisesRegex(ValueError, \"dimensions must be specified\"):\n        array_ops.boolean_mask(tensor, mask)\n\n  def testMaskHasMoreDimsThanTensorRaises(self):\n    mask = [[True, True], [False, False]]\n    tensor = [1, 2, 3, 4]\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"incompatible\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  def testMaskIsScalarRaises(self):\n    mask = True\n    tensor = 1\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"mask.*scalar\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  def testMaskShapeDifferentThanFirstPartOfTensorShapeRaises(self):\n    mask = [True, True, True]\n    tensor = [[1, 2], [3, 4]]\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"incompatible\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  @test_util.run_deprecated_v1\n  def testStringMask(self):\n    # Reproduces b/111171330, where the optimized boolean_mask graph would\n    # be incorrectly placed on GPU.\n    with ops.Graph().as_default():\n      tile_placeholder = array_ops.placeholder(dtypes.int32, [2])\n      string_tensor = array_ops.tile([[\"hello\"]], tile_placeholder)\n      bool_tensor = array_ops.tile([[True]], tile_placeholder)\n      masked_tensor = array_ops.boolean_mask(string_tensor, bool_tensor)\n      config = config_pb2.ConfigProto()\n      config.graph_options.rewrite_options.shape_optimization = 1\n      config.gpu_options.per_process_gpu_memory_fraction = 0.3\n      with session.Session(config=config) as sess:\n        result = sess.run(masked_tensor, feed_dict={tile_placeholder: [2, 2]})\n        self.assertAllEqual([b\"hello\", b\"hello\", b\"hello\", b\"hello\"], result)\n\n  def testMaskWithAxisTensor(self):\n\n    @def_function.function(autograph=False)\n    def f():\n      return array_ops.boolean_mask([1, 2, 3], [True, False, True],\n                                    axis=constant_op.constant(\n                                        0, dtype=dtypes.int32))\n\n    self.assertAllEqual(self.evaluate(f()), [1, 3])\n\n  def testMaskWithAxisNonConstTensor(self):\n\n    @def_function.function(\n        autograph=False,\n        input_signature=[\n            tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n        ])\n    def f(axis):\n      return array_ops.boolean_mask([1, 2, 3], [True, False, True], axis=axis)\n\n    self.assertAllEqual(\n        self.evaluate(f(constant_op.constant(0, dtype=dtypes.int32))), [1, 3])\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass OperatorShapeTest(test_util.TensorFlowTestCase):\n\n  def testExpandScalar(self):\n    scalar = \"hello\"\n    scalar_expanded = array_ops.expand_dims(scalar, [0])\n    self.assertEqual(scalar_expanded.get_shape(), (1,))\n\n  def testSqueezeScalar(self):\n    scalar = \"hello\"\n    scalar_squeezed = array_ops.squeeze(scalar, ())\n    self.assertEqual(scalar_squeezed.get_shape(), ())\n\n  def testSqueezeMatrix(self):\n    matrix = [[1, 2, 3]]\n    matrix_squeezed = array_ops.squeeze(matrix, [0])\n    self.assertEqual(matrix_squeezed.get_shape(), (3))\n\n    with self.assertRaisesRegex(\n        Exception, \"Can not squeeze dim.1., expected a dimension of 1, got 3\"):\n      matrix_squeezed = array_ops.squeeze(matrix, [1])\n\n  def testSqueezeScalarDim(self):\n    matrix = [[1, 2, 3]]\n    matrix_squeezed = array_ops.squeeze(matrix, 0)\n    self.assertEqual(matrix_squeezed.get_shape(), (3))\n\n  def testExpandDimsWithNonScalarDim(self):\n    with self.assertRaisesRegex(Exception,\n                                \"must be a tensor with a single value\"):\n      array_ops.expand_dims(1, axis=[0, 1])\n\n\nclass ReverseV2Test(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testReverse0DimAuto(self):\n    x_np = 4\n    for use_gpu in [False, True]:\n      with self.subTest(use_gpu=use_gpu):\n        with self.cached_session(use_gpu=use_gpu):\n          x_tf = array_ops.reverse_v2(x_np, []).eval()\n          self.assertAllEqual(x_tf, x_np)\n\n  def _reverse1DimAuto(self, np_dtype):\n    x_np = np.array([1, 200, 3, 40, 5], dtype=np_dtype)\n\n    for use_gpu in [False, True]:\n      for axis_dtype in [dtypes.int32, dtypes.int64]:\n        with self.subTest(use_gpu=use_gpu, axis_dtype=axis_dtype):\n          with self.cached_session(use_gpu=use_gpu):\n            x_tf = array_ops.reverse_v2(\n                x_np, constant_op.constant([0], dtype=axis_dtype)).eval()\n            self.assertAllEqual(x_tf, np.asarray(x_np)[::-1])\n\n  def _reverse2DimAuto(self, np_dtype):\n    x_np = np.array([[1, 200, 3], [4, 5, 60]], dtype=np_dtype)\n\n    for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n      for use_gpu in [False, True]:\n        for axis_dtype in [dtypes.int32, dtypes.int64]:\n          with self.subTest(\n              reverse_f=reverse_f, use_gpu=use_gpu, axis_dtype=axis_dtype):\n            with self.cached_session(use_gpu=use_gpu):\n              x_tf_1 = reverse_f(x_np,\n                                 constant_op.constant([0],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_2 = reverse_f(x_np,\n                                 constant_op.constant([-2],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_3 = reverse_f(x_np,\n                                 constant_op.constant([1],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_4 = reverse_f(x_np,\n                                 constant_op.constant([-1],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_5 = reverse_f(x_np,\n                                 constant_op.constant([1, 0],\n                                                      dtype=axis_dtype)).eval()\n              self.assertAllEqual(x_tf_1, np.asarray(x_np)[::-1, :])\n              self.assertAllEqual(x_tf_2, np.asarray(x_np)[::-1, :])\n              self.assertAllEqual(x_tf_3, np.asarray(x_np)[:, ::-1])\n              self.assertAllEqual(x_tf_4, np.asarray(x_np)[:, ::-1])\n              self.assertAllEqual(x_tf_5, np.asarray(x_np)[::-1, ::-1])\n\n  # This test covers the axis validation in the shape function\n  # (no eval())\n  @test_util.run_deprecated_v1\n  def testInvalidAxis(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n    with self.assertRaisesRegex(ValueError, \"is out of valid range\"):\n      array_ops.reverse_v2(x_np, [-30])\n    with self.assertRaisesRegex(ValueError, \"is out of valid range\"):\n      array_ops.reverse_v2(x_np, [2])\n    with self.assertRaisesRegex(ValueError, \"axis 0 specified more than once\"):\n      array_ops.reverse_v2(x_np, [0, -2])\n\n  # This is the version of reverse that uses axis indices rather than\n  # bool tensors\n  # TODO(b/32254538): Change this test to use array_ops.reverse\n  #\n  # Note: this test passes placeholder as constant axis is validated\n  # in shape function (see testInvalidAxis)\n  @test_util.run_deprecated_v1\n  def testInvalid(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n    axis = array_ops.placeholder(dtypes.int32)\n    with self.cached_session():\n      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                  \"is out of.*range\"):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [-30]})\n      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                  \"is out of.*range\"):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [2]})\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          \"(axis 0 specified more than once|canonicalized axis 0 was repeated.)\"\n      ):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [0, -2]})\n\n  @test_util.run_deprecated_v1\n  def testReverse1DimAuto(self):\n    for dtype in [\n        np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.bool,\n        np.float16, np.float32, np.float64, np.complex64, np.complex128,\n        np.array(b\"\").dtype.type\n    ]:\n      self._reverse1DimAuto(dtype)\n\n  @test_util.run_deprecated_v1\n  def testReverse2DimAuto(self):\n    for dtype in [\n        np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.bool,\n        np.float16, np.float32, np.float64, np.complex64, np.complex128,\n        np.array(b\"\").dtype.type\n    ]:\n      self._reverse2DimAuto(dtype)\n\n  @test_util.run_deprecated_v1\n  def testUnknownDims(self):\n    reverse_v2 = array_ops.reverse_v2\n    data_t = array_ops.placeholder(dtypes.float32)\n    axis_known_t = array_ops.placeholder(dtypes.int32, shape=[3])\n    reverse_known_t = reverse_v2(data_t, axis_known_t)\n    # Unlike V1 we cannot know this anymore\n    self.assertEqual(None, reverse_known_t.get_shape().ndims)\n\n    axis_unknown_t = array_ops.placeholder(dtypes.int32)\n    reverse_unknown_t = reverse_v2(data_t, axis_unknown_t)\n    self.assertIs(None, reverse_unknown_t.get_shape().ndims)\n\n    data_2d_t = array_ops.placeholder(dtypes.float32, shape=[None, None])\n    axis_2d_t = array_ops.placeholder(dtypes.int32, shape=[3])\n    reverse_2d_t = reverse_v2(data_2d_t, axis_2d_t)\n    self.assertEqual(2, reverse_2d_t.get_shape().ndims)\n\n  @test_util.run_deprecated_v1\n  def testReverseRowsOf3Channels(self):\n    \"\"\"Tests optimized code for reversing rows with last dim size = 3.\"\"\"\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in (1, 2):\n          for middle_size in list(range(50)) + [100000]:\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 3, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 3))\n              x_tf = reverse_f(x_np, [1]).eval()\n              np_answer = x_np[:, ::-1, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  @test_util.run_deprecated_v1\n  def testReverseRowsOf4Channels(self):\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in (1, 2):\n          for middle_size in list(range(50)) + [100000]:\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 4, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 4))\n              x_tf = reverse_f(x_np, [1]).eval()\n              np_answer = x_np[:, ::-1, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  @test_util.run_deprecated_v1\n  def testReverseColumnsOf3Channels(self):\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in list(range(50)) + [100000]:\n          for middle_size in (1, 2):\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 3, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 3))\n              x_tf = reverse_f(x_np, [0]).eval()\n              np_answer = x_np[::-1, :, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  def testReverseInvalidShape(self):\n    x = np.ndarray(shape=[0, 1, 1])\n    v = array_ops.reverse_v2(x, axis=[1])\n    self.assertAllEqual(self.evaluate(v), v)\n\n\nclass MeshgridTest(test_util.TensorFlowTestCase):\n\n  def _compareDiff(self, x, y, use_gpu):\n    for index in (\"ij\", \"xy\"):\n      numpy_out = np.meshgrid(x, y, indexing=index)\n      tf_out = array_ops.meshgrid(x, y, indexing=index)\n      with self.cached_session(use_gpu=use_gpu):\n        for xx, yy in zip(numpy_out, tf_out):\n          self.assertAllEqual(xx, yy)\n\n  def _compareDiffType(self, n, np_dtype, use_gpu):\n    inputs = []\n    for index in (\"ij\", \"xy\"):\n      for _ in range(n):\n        x = np.linspace(-10, 10, 5).astype(np_dtype)\n        if np_dtype in (np.complex64, np.complex128):\n          x += 1j\n        inputs.append(x)\n      numpy_out = np.meshgrid(*inputs, indexing=index)\n      with self.cached_session(use_gpu=use_gpu):\n        tf_out = array_ops.meshgrid(*inputs, indexing=index)\n        for x_np, x_tf in zip(numpy_out, tf_out):\n          self.assertAllEqual(x_np, x_tf)\n\n  @test_util.run_deprecated_v1\n  def testCompare(self):\n    for t in (np.float16, np.float32, np.float64, np.int32, np.int64,\n              np.complex64, np.complex128):\n      with self.subTest(t=t):\n        self._compareDiffType(2, t, False)\n        self._compareDiffType(3, t, False)\n\n        x = [1, 2, 3]\n        y = [4, 5]\n\n        a = [[1, 1], [1, 1]]\n\n        self._compareDiff(x, y, False)\n        self._compareDiff(x, a, False)\n\n\nclass StridedSliceChecker(object):\n  \"\"\"Check a given tensor against the numpy result.\"\"\"\n\n  REF_TENSOR = np.arange(1, 19, dtype=np.float32).reshape(3, 2, 3)\n  REF_TENSOR_ALIGNED = np.arange(1, 97, dtype=np.float32).reshape(3, 4, 8)\n\n  def __init__(self, test, x, tensor_type=dtypes.int32, check_type_infer=True):\n    self.x_np = np.array(x).astype(tensor_type.as_numpy_dtype)\n    if tensor_type.is_bool:\n      self.x_np = np.array(x % 3).astype(np.bool)\n    # Give the value a non-zero imaginary component for complex types.\n    if tensor_type.is_complex:\n      self.x_np -= 1j * self.x_np\n    self.test = test\n    self.x = constant_op.constant(self.x_np, dtype=tensor_type)\n    self.check_type_infer = check_type_infer\n\n  def __getitem__(self, spec):\n    op = self.x.__getitem__(spec)\n\n    def eval_if_tensor(x):\n      try:\n        return x.eval()\n      except AttributeError:\n        return x\n\n    if isinstance(spec, bool) or \\\n      (isinstance(spec, ops.Tensor) and spec.dtype == dtypes.bool) or \\\n      (isinstance(spec, np.ndarray) and spec.dtype == bool) or \\\n      (isinstance(spec, (list, tuple)) and np.asarray(spec).dtype == bool):\n      tensor = op.eval()\n      np_spec = eval_if_tensor(spec)\n      self.test.assertAllEqual(self.x_np[np_spec], tensor)\n      return tensor\n\n    if not isinstance(spec, (list, tuple)):\n      spec = [spec]\n\n    tensor = op.eval()\n\n    # Make a numpy spec that pre-evals the tensors\n    np_specs = []\n\n    for s in spec:\n      if isinstance(s, slice):\n        start = eval_if_tensor(s.start)\n        stop = eval_if_tensor(s.stop)\n        step = eval_if_tensor(s.step)\n        np_specs.append(slice(start, stop, step))\n      else:\n        np_specs.append(eval_if_tensor(s))\n\n    self.test.assertAllEqual(self.x_np[tuple(np_specs)], tensor)\n    if self.check_type_infer:\n      self.test.assertAllEqual(tensor.shape, op.get_shape())\n    return tensor\n\n\nSTRIDED_SLICE_TYPES = [\n    dtypes.int32, dtypes.int64, dtypes.int16, dtypes.int8, dtypes.float32,\n    dtypes.float64, dtypes.complex64, dtypes.complex128, dtypes.bool\n]\n\n\nclass StridedSliceTest(test_util.TensorFlowTestCase):\n  \"\"\"Test the strided slice operation with variants of slices.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def test_basic_slice(self):\n    for tensor_type in STRIDED_SLICE_TYPES:\n      with self.subTest(tensor_type=tensor_type):\n        with self.cached_session(use_gpu=True):\n          checker = StridedSliceChecker(\n              self, StridedSliceChecker.REF_TENSOR, tensor_type=tensor_type)\n          _ = checker[:, :, :]\n          # Various ways of representing identity slice\n          _ = checker[:, :, :]\n          _ = checker[::, ::, ::]\n          _ = checker[::1, ::1, ::1]\n          # Not zero slice\n          _ = checker[::1, ::5, ::2]\n          # Reverse in each dimension independently\n          _ = checker[::-1, :, :]\n          _ = checker[:, ::-1, :]\n          _ = checker[:, :, ::-1]\n          ## negative index tests i.e. n-2 in first component\n          _ = checker[-2::-1, :, ::1]\n          # negative index tests i.e. n-2 in first component, non-unit stride\n          _ = checker[-2::-1, :, ::2]\n\n          # Check rank-0 examples\n          checker2 = StridedSliceChecker(self, 5, tensor_type=tensor_type)\n          _ = checker2[None]\n          _ = checker2[...]\n          _ = checker2[tuple()]\n\n  def testInt64GPU(self):\n    if not test_util.is_gpu_available():\n      self.skipTest(\"No GPU available\")\n\n    with test_util.force_gpu():\n      x = constant_op.constant([1., 2., 3.])\n      begin = constant_op.constant([2], dtype=dtypes.int64)\n      end = constant_op.constant([3], dtype=dtypes.int64)\n      strides = constant_op.constant([1], dtype=dtypes.int64)\n      s = array_ops.strided_slice(x, begin, end, strides)\n      self.assertAllEqual([3.], self.evaluate(s))\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.assert_no_garbage_created\n  def testTensorSliceEagerMemory(self):\n    with context.eager_mode():\n      inputs = constant_op.constant([[[1], [2], [3], [4]]],\n                                    dtype=dtypes.float32)\n      # Tests that slicing an EagerTensor doesn't leak memory\n      inputs[0]  # pylint: disable=pointless-statement\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.assert_no_garbage_created\n  def testVariableSliceEagerMemory(self):\n    with context.eager_mode():\n      v = variables.Variable([1., 2.])\n      v[0]  # pylint: disable=pointless-statement\n\n  @test_util.run_deprecated_v1\n  def testDegenerateSlices(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      # degenerate by offering a forward interval with a negative stride\n      _ = checker[0:-1:-1, :, :]\n      # degenerate with a reverse interval with a positive stride\n      _ = checker[-1:0, :, :]\n      # empty interval in every dimension\n      _ = checker[-1:0, 2:2, 2:3:-1]\n      # empty first dimension only (used to break for aligned tensors).\n      checker = StridedSliceChecker(self,\n                                    StridedSliceChecker.REF_TENSOR_ALIGNED)\n      _ = checker[1:0]\n\n  @test_util.run_deprecated_v1\n  def testSliceWithUndefinedDimension(self):\n    t = constant_op.constant([1, 2, 3])\n    d = tensor_shape.Dimension(None)\n    self.assertAllEqual(t[d:d:d], t)\n\n  @test_util.run_deprecated_v1\n  def testEllipsis(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2], [3, 4], [5, 6]]], [[[7, 8], [9, 10], [11, 12]]]]]\n      checker = StridedSliceChecker(self, raw)\n\n      _ = checker[0:]\n      # implicit ellipsis\n      _ = checker[0:, ...]\n      # ellipsis alone\n      _ = checker[...]\n      # ellipsis at end\n      _ = checker[0:1, ...]\n      # ellipsis at begin\n      _ = checker[..., 0:1]\n      # ellipsis at middle\n      _ = checker[0:1, ..., 0:1]\n      # multiple ellipses not allowed\n      with self.assertRaisesRegex(ValueError, \"Multiple ellipses\"):\n        _ = checker[..., :, ...].eval()\n\n  @test_util.run_deprecated_v1\n  def testShrink(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw)\n      _ = checker[:, :, :, :, 3]\n      _ = checker[..., 3]\n      _ = checker[:, 0]\n      _ = checker[:, :, 0]\n\n  @test_util.run_deprecated_v1\n  def testBothNewAxisAndShrink(self):\n    with self.session(use_gpu=True):\n      ones = array_ops.placeholder(shape=[2, 2], dtype=dtypes.int16)\n      self.assertAllEqual(\n          ones[array_ops.newaxis, :,\n               0].eval(feed_dict={ones: [[1, 1], [1, 1]]}), [[1, 1]])\n\n  @test_util.run_deprecated_v1\n  def testTensorIndexing(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw, check_type_infer=False)\n      bar = constant_op.constant(2)\n      bar2 = constant_op.constant(3)\n      _ = checker[..., bar:bar2]\n      _ = checker[..., bar]\n      _ = checker[..., 3]\n      _ = checker[..., 2**64 // 2**63]  # Test longs in Python 2\n\n  def testTensorIndexingTypeError(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      expected = re.escape(array_ops._SLICE_TYPE_ERROR)\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[\"foo\"]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant(\"foo\")]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[0.0]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant(0.0)]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant([1, 2, 3])]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[[2.1, -0.7, 1.5]]\n\n  @test_util.run_deprecated_v1\n  def testExpand(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw)\n      # new axis (followed by implicit ellipsis)\n      _ = checker[np.newaxis]\n      # newaxis after ellipsis\n      _ = checker[..., np.newaxis]\n      # newaxis in between ellipsis and explicit range\n      _ = checker[..., np.newaxis, :]\n      _ = checker[:, ..., np.newaxis, :, :]\n      # Reverse final dimension with new axis\n      _ = checker[:, :, np.newaxis, :, 2::-1]\n      # Ellipsis in middle of two newaxis\n      _ = checker[np.newaxis, ..., np.newaxis]\n\n  @test_util.run_deprecated_v1\n  def testExpandVariable(self):\n    with self.session(use_gpu=True):\n      x = variables.Variable(7, dtype=dtypes.int32)\n      self.evaluate(x.initializer)\n      y = x[None].eval()\n      self.assertEqual(y.shape, (1,))\n      self.assertAllEqual(y, (7,))\n\n  @test_util.run_deprecated_v1\n  def testOptimizedCases(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self,\n                                    StridedSliceChecker.REF_TENSOR_ALIGNED)\n      # Identity\n      _ = checker[:]\n      # Identity\n      _ = checker[...]\n      # Identity\n      _ = checker[np.newaxis, ..., np.newaxis]\n      # First axis slice\n      _ = checker[1:]\n      # First axis slice\n      _ = checker[np.newaxis, 1:]\n\n  @test_util.run_v1_only(\"currently failing on v2\")\n  def testMasks(self):\n    with self.session(use_gpu=True):\n      scalar = np.array(0)\n      # Test tensor type mask\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      _ = checker[checker.x > 2]\n      _ = checker[checker.x <= 5]\n      _ = checker[ops.convert_to_tensor(scalar)]\n\n      # Test numpy array type mask\n      raw = np.array([[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n                       [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23,\n                                                              24]]]]])\n      checker1 = StridedSliceChecker(self, raw)\n      _ = checker1[raw >= 4]\n      _ = checker1[raw < 19]\n      _ = checker1[scalar]\n\n      # Test boolean and non boolean cases\n      mask = np.array([True, False, True])\n      raw1 = np.array([[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]])\n      checker2 = StridedSliceChecker(self, raw1)\n      _ = checker2[mask]\n      _ = checker2[ops.convert_to_tensor(mask)]\n\n\nclass StridedSliceShapeChecker(object):\n\n  def __init__(self, x):\n    self.x = x\n\n  def __getitem__(self, spec):\n    op = self.x.__getitem__(spec)\n    return op.get_shape()\n\n\nclass StridedSliceShapeTest(test_util.TensorFlowTestCase):\n  \"\"\"Test the shape inference of StridedSliceShapes.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def testUnknown(self):\n    with self.session(use_gpu=True):\n      uncertain_tensor = array_ops.placeholder(dtypes.float32)\n      a = StridedSliceShapeChecker(uncertain_tensor)\n      a_slice_shape = a[...]\n      self.assertAllEqual(a_slice_shape.ndims, None)\n\n  def tensorShapeEqual(self, x, y):\n    self.assertTrue(x is not None and y is not None or x is None and y is None)\n    self.assertEqual(x.as_list(), y.as_list())\n\n  @test_util.run_deprecated_v1\n  def testTensorShapeUncertain(self):\n    with self.session(use_gpu=True):\n      uncertain_tensor = array_ops.placeholder(\n          dtypes.float32, shape=(5, None, 7))\n      a = StridedSliceShapeChecker(uncertain_tensor)\n      self.tensorShapeEqual(a[3:5], tensor_shape.TensorShape([2, None, 7]))\n      self.tensorShapeEqual(a[3:5, :, 4], tensor_shape.TensorShape([2, None]))\n      self.tensorShapeEqual(a[3:5, 3:4, 4], tensor_shape.TensorShape([2, None]))\n      self.tensorShapeEqual(a[3:5, :, 5:10],\n                            tensor_shape.TensorShape([2, None, 2]))\n      self.tensorShapeEqual(a[3:5, :, 50:3],\n                            tensor_shape.TensorShape([2, None, 0]))\n      self.tensorShapeEqual(a[3:5, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[1:5:2, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[:5:3, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[:2:3, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([1, None, 1, 0]))\n      self.tensorShapeEqual(a[::-1, :, array_ops.newaxis, ::-2],\n                            tensor_shape.TensorShape([5, None, 1, 4]))\n\n  @test_util.run_deprecated_v1\n  def testTensorValuedIndexShape(self):\n    with self.session(use_gpu=True):\n      defined_shape_tensor = array_ops.placeholder(\n          dtypes.float32, shape=(5, 3, 7))\n      index_value = array_ops.placeholder(dtypes.int32, shape=())\n      a = StridedSliceShapeChecker(defined_shape_tensor)\n      self.tensorShapeEqual(a[index_value], tensor_shape.TensorShape([3, 7]))\n      self.tensorShapeEqual(a[index_value, ::-1],\n                            tensor_shape.TensorShape([3, 7]))\n      self.tensorShapeEqual(a[index_value, ::-2],\n                            tensor_shape.TensorShape([2, 7]))\n      other_scalar = array_ops.placeholder(dtypes.int32, shape=())\n      self.tensorShapeEqual(a[index_value, other_scalar:2],\n                            tensor_shape.TensorShape([None, 7]))\n\n\nclass GradSliceChecker(object):\n  \"\"\"Tests that we can compute a gradient for var^2.\"\"\"\n\n  def __init__(self, test, sess, var, varnp):\n    self.test = test\n    self.sess = sess\n    self.val = var * var\n    self.var = var\n    self.varnp = varnp\n\n  def __getitem__(self, spec):\n    slice_var = self.var[spec]\n    slice_val = self.val[spec]\n\n    # compute analytic 2nd derivative\n    analytic_grad2 = 2 * slice_val\n\n    dy = variables.Variable(\n        array_ops.ones_like(slice_var, dtype=dtypes.float32))\n    assign = dy.assign(slice_var)\n    slice_val_grad, = gradients_impl.gradients(slice_val, self.var, grad_ys=dy)\n    slice_val_grad2, = gradients_impl.gradients(\n        slice_val_grad, dy, grad_ys=self.var)\n    self.sess.run(assign)\n    slice_val_grad_evaled, slice_val_grad2_evaled = (\n        self.sess.run([slice_val_grad, slice_val_grad2]))\n    analytic_grad2_evaled = analytic_grad2.eval()\n    self.test.assertAllEqual(slice_val_grad2_evaled, analytic_grad2_evaled)\n\n    # compute analytic gradient for slice\n    np_val_grad = (2 * self.varnp * self.varnp)\n    np_sliceval_grad = np.zeros(self.var.get_shape())\n    if isinstance(spec, ops.Tensor):\n      spec = self.sess.run([spec])\n    np_sliceval_grad[spec] = np_val_grad[spec]\n    # verify gradient\n    self.test.assertAllEqual(slice_val_grad_evaled, np_sliceval_grad)\n\n\nclass StridedSliceGradTest(test_util.TensorFlowTestCase):\n  \"\"\"Test that strided slice's custom gradient produces correct gradients.\"\"\"\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testGradient(self):\n    with self.session(use_gpu=True) as sess:\n      var = variables.Variable(\n          array_ops.reshape(\n              math_ops.range(1, 97, 1, dtype=dtypes.float32), shape=(6, 4, 4)))\n      init = variables.global_variables_initializer()\n      sess.run(init)\n\n      raw = np.array(range(1, 97, 1)).reshape((6, 4, 4))\n      grad = GradSliceChecker(self, sess, var, raw)\n      _ = grad[2:6:2, 1:3, 1:3]\n      _ = grad[3:0:-2, 1:3, 1:3]\n      _ = grad[3:0:-2, array_ops.newaxis, 1:3, 2, array_ops.newaxis]\n      _ = grad[3:0:-2, 1:3, 2]\n      _ = grad[:, -1, :]\n      _ = grad[:, -2, :]\n      with self.assertRaisesRegex(ValueError, \"out of bounds\"):\n        _ = grad[:, -200, :]\n      with self.assertRaisesRegex(ValueError, \"out of bounds\"):\n        _ = grad[:, 200, :]\n\n      # Test numpy array type mask\n      _ = grad[raw > 51]\n      # Test tensor type mask\n      _ = grad[ops.convert_to_tensor(raw) <= 76]\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testGradientZero(self):\n    with self.session(use_gpu=True) as sess:\n      var = variables.Variable(8.)\n      init = variables.global_variables_initializer()\n      sess.run(init)\n      grad = GradSliceChecker(self, sess, var, np.array(8))\n      _ = grad[tuple()]\n\n  @test_util.run_deprecated_v1\n  def testInt64Indices(self):\n    with self.session(use_gpu=True) as sess:\n      a = math_ops.range(3, dtype=dtypes.float32)\n      index = constant_op.constant(1, dtype=dtypes.int64)\n      b = 2. * a[index]\n      grad, = gradients_impl.gradients(b, a)\n      self.assertAllEqual(self.evaluate(grad), [0., 2., 0.])\n\n\nclass StridedSliceGradTypeTest(test_util.TensorFlowTestCase):\n  \"\"\"Test varied index types and host located memory.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def testHostVsDevice(self):\n    with self.session(use_gpu=True) as sess:\n      var2 = variables.Variable(\n          array_ops.reshape(\n              math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n              shape=(4, 1, 1)))\n      varshape = variables.Variable([6, 4, 4], dtype=dtypes.int32)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0])\n      end = constant_op.constant([4, 1, 1])\n      strides = constant_op.constant([1, 1, 1])\n      foo = array_ops.strided_slice_grad(varshape, begin, end, strides, var2)\n      sess.run(foo)\n\n  @test_util.run_deprecated_v1\n  def testInt64Shape(self):\n    with self.session(use_gpu=True) as sess:\n      original_dy = array_ops.reshape(\n          math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n          shape=(4, 1, 1))\n      original_shape = constant_op.constant([6, 4, 4], dtype=dtypes.int64)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0], dtype=dtypes.int64)\n      end = constant_op.constant([4, 1, 1], dtype=dtypes.int64)\n      strides = constant_op.constant([1, 1, 1], dtype=dtypes.int64)\n      dx = array_ops.strided_slice_grad(original_shape, begin, end, strides,\n                                        original_dy)\n      sess.run(dx)\n\n  @test_util.run_deprecated_v1\n  def testMixedIndexTypes(self):\n    with self.session(use_gpu=True) as sess:\n      original_dy = array_ops.reshape(\n          math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n          shape=(4, 1, 1))\n      original_shape = constant_op.constant([6, 4, 4], dtype=dtypes.int64)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0], dtype=dtypes.int32)\n      end = constant_op.constant([4, 1, 1], dtype=dtypes.int64)\n      strides = constant_op.constant([1, 1, 1], dtype=dtypes.int64)\n      with self.assertRaisesRegex(\n          TypeError, \"Input 'begin' of 'StridedSliceGrad' Op has type int32\"\n          \" that does not match type int64 of argument 'shape'\"):\n        dx = array_ops.strided_slice_grad(original_shape, begin, end, strides,\n                                          original_dy)\n        sess.run(dx)\n\n\nclass BenchmarkSlice(object):\n\n  def __init__(self, tensor):\n    self.tensor = tensor\n\n  def __getitem__(self, x):\n    return self.tensor[x]\n\n\nclass StridedSliceBenchmark(test_lib.Benchmark):\n  \"\"\"Benchmark new strided slice operation on non-trivial case.\"\"\"\n\n  def run_and_time(self, slice_op):\n    self.evaluate(variables.global_variables_initializer())\n    for _ in range(10):\n      _ = self.evaluate(slice_op)\n    iters = 1000\n    t0 = time.time()\n    for _ in range(iters):\n      self.evaluate(slice_op)\n    t1 = time.time()\n    self.report_benchmark(iters=iters, wall_time=(t1 - t0) / 1000.0)\n\n  def make_variable(self):\n    n = 256\n    shape = (n, n, n)\n    items = n**3\n    var = variables.Variable(\n        array_ops.reshape(math_ops.linspace(1., float(items), items), shape),\n        dtype=dtypes.float32)\n    return var\n\n  def benchmark_strided_slice_skip(self):\n    with session.Session():\n      var = self.make_variable()\n      helper = BenchmarkSlice(var)\n      slice_op = helper[::2, ::1, ::2]\n      self.run_and_time(slice_op)\n\n  def benchmark_strided_slice_easy(self):\n    with session.Session():\n      var = self.make_variable()\n      helper = BenchmarkSlice(var)\n      slice_op = helper[3::1, 3::1, 3::1]\n      self.run_and_time(slice_op)\n\n  def benchmark_slice_easy(self):\n    with session.Session():\n      var = self.make_variable()\n      slice_op = var[3::1, 3::1, 3::1]\n      self.run_and_time(slice_op)\n\n\nclass StridedSliceAssignChecker(object):\n\n  def __init__(self, test, x, tensor_type=dtypes.float32, use_resource=False):\n    self.tensor_type = tensor_type\n    self.test = test\n    self._use_resource = use_resource\n\n    self.x_np = np.array(x).astype(tensor_type.as_numpy_dtype)\n    # Give the value a non-zero imaginary component for complex types.\n    if tensor_type.is_complex:\n      self.x_np -= 1j * self.x_np\n    self.x = constant_op.constant(self.x_np, dtype=tensor_type)\n\n  def __setitem__(self, index, value):\n    value = np.array(value).astype(self.tensor_type.as_numpy_dtype)\n    # Give the value a non-zero imaginary component for complex types.\n    if self.tensor_type.is_complex:\n      value -= 1j * value\n\n    with self.test.test_session(use_gpu=True) as sess:\n      if self._use_resource:\n        var = resource_variable_ops.ResourceVariable(self.x)\n      else:\n        var = variables.Variable(self.x)\n      sess.run(variables.variables_initializer([var]))\n      val = sess.run(var[index].assign(value))\n      # val_copy is used to check that tf.compat.v1.assign works equivalently\n      # to the assign method above.\n      val_copy = sess.run(state_ops.assign(var[index], value))\n      valnp = np.copy(self.x_np)\n      valnp[index] = np.array(value)\n      self.test.assertAllEqual(val, valnp)\n      self.test.assertAllEqual(val_copy, valnp)\n\n\nclass SliceAssignTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvalidSlice(self):\n    with self.cached_session() as sess:\n      foo = constant_op.constant([1, 2, 3])\n      with self.assertRaisesRegex(\n          ValueError, \"Sliced assignment\"\n          \" is only supported for variables\"):\n        bar = foo[:2].assign(constant_op.constant([1, 2]))\n        sess.run(bar)\n\n  def doTestSliceAssign(self, use_resource):\n    for dtype in STRIDED_SLICE_TYPES:\n      with self.subTest(dtype=dtype):\n        checker = StridedSliceAssignChecker(\n            self, [[1, 2, 3], [4, 5, 6]],\n            use_resource=use_resource,\n            tensor_type=dtype)\n        # Check if equal\n        checker[:] = [[10, 20, 30], [40, 50, 60]]\n        # Check trivial (1,1) shape tensor\n        checker[1:2, 1:2] = [[66]]\n        # shrinks shape changes\n        checker[1:2, 1] = [66]\n        checker[1, 1:2] = [66]\n        checker[1, 1] = 66\n        # newaxis shape changes\n        checker[:, None, :] = [[[10, 20, 30]], [[40, 50, 50]]]\n        # shrink and newaxis\n        checker[None, None, 0, 0:1] = [[[99]]]\n        # Non unit strides\n        checker[::1, ::-2] = [[3, 33], [4, 44]]\n        # degenerate interval\n        checker[8:10, 0] = []\n        checker[8:10, 8:10] = [[]]\n    # Assign vector to scalar (rank-0) using newaxis\n    checker2 = StridedSliceAssignChecker(self, 222)\n    checker2[()] = 6  # no indices\n    checker2[...] = 6  # ellipsis\n    checker2[None] = [6]  # new axis\n\n  @test_util.run_deprecated_v1\n  @test_util.disable_xla(\"b/123559667\")\n  def testSliceAssign(self):\n    self.doTestSliceAssign(use_resource=False)\n\n  @test_util.run_deprecated_v1\n  @test_util.disable_xla(\"b/123559667\")\n  def testSliceAssignResource(self):\n    self.doTestSliceAssign(use_resource=True)\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testUninitialized(self):\n    with self.assertRaisesRegex(\n        errors.FailedPreconditionError,\n        \"Attempting to use uninitialized value Variable\"):\n      with self.cached_session() as sess:\n        v = variables.VariableV1([1, 2])\n        sess.run(v[:].assign([1, 2]))\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testTypeError(self):\n    init_val = constant_op.constant([1, 2], dtype=dtypes.int32)\n    too_small_val = constant_op.constant([3, 4], dtype=dtypes.int8)\n    too_large_val = constant_op.constant([3, 4], dtype=dtypes.int64)\n    v = variables.VariableV1(init_val)\n    with self.assertRaises(TypeError):\n      v[:].assign(too_small_val)\n    with self.assertRaises(TypeError):\n      v[:].assign(too_large_val)\n\n  @test_util.run_deprecated_v1\n  def testTypeErrorResource(self):\n    init_val = constant_op.constant([1, 2], dtype=dtypes.int32)\n    too_small_val = constant_op.constant([3, 4], dtype=dtypes.int8)\n    too_large_val = constant_op.constant([3, 4], dtype=dtypes.int64)\n    v = resource_variable_ops.ResourceVariable(init_val)\n    with self.cached_session() as sess:\n      self.evaluate(v.initializer)\n      with self.assertRaises(ValueError):\n        sess.run(v[:].assign(too_large_val))\n      with self.assertRaises(ValueError):\n        sess.run(v[:].assign(too_small_val))\n\n  @test_util.disable_xla(\"b/123559667\")\n  @test_util.run_in_graph_and_eager_modes\n  def testTensorStridedSliceUpdateWithInputForward(self):\n    \"\"\"Tests tensor_strided_slice_update with input-forwarding taking effect.\"\"\"\n    @def_function.function\n    def assign(x):\n      y = x + 1\n      return gen_array_ops.tensor_strided_slice_update(y, [0], [1], [1], [0])\n    self.assertAllEqual([0, 1], self.evaluate(assign(array_ops.zeros([2]))))\n\n  @test_util.disable_xla(\"b/123559667\")\n  @test_util.run_in_graph_and_eager_modes\n  def testTensorStridedSliceUpdateNoInputForward(self):\n    \"\"\"Tests tensor_strided_slice_update with no input-forwarding.\"\"\"\n    x = constant_op.constant([0.2, 0.3])\n    y = x + 1\n    # y's buffer won't be forwarded to z because y and z will be alive at the\n    # same time later.\n    z = gen_array_ops.tensor_strided_slice_update(y, [0], [1], [1], [0.4])\n    ans = y + z\n    self.assertAllClose([1.6, 2.6], self.evaluate(ans))\n\n  @test_util.disable_xla(\"b/123559667\")\n  def testTensorStridedSliceUpdateGradSimple(self):\n    original = constant_op.constant([0.2, 0.3])\n    updates = constant_op.constant([0.4])\n    with backprop.GradientTape() as tape:\n      tape.watch([original, updates])\n      updated = gen_array_ops.tensor_strided_slice_update(\n          original, [0], [1], [1], updates)\n    d1, d2 = tape.gradient(updated, [original, updates],\n                           output_gradients=constant_op.constant([2.0, 3.0]))\n    self.assertAllClose([0.0, 3.0], d1)\n    self.assertAllClose([2.0], d2)\n\n  @parameterized.named_parameters(\n      (\"_%s\" % i, *args) for i, args in enumerate([  # pylint:disable=g-complex-comprehension\n          ([2, 5], [0, 1], [1, 0], [1, 2], [2], 0, 2, 0, 0, 1),\n          ([4], [5], [3], [1], [3], 1, 0, 0, 0, 0),\n          ([2, 2, 3, 2], [0, 0, 1], [1, 0, 2], [1, 0, 1], [2, 3], 0, 0, 2, 0, 5)\n      ]))\n  @test_util.disable_xla(\"b/123559667\")\n  def testTensorStridedSliceUpdateGrad(\n      self, shape, begin, end, strides, updates_shape, *args):\n    with self.cached_session():\n      def f(a, b):\n        return gen_array_ops.tensor_strided_slice_update(\n            a, begin, end, strides, b, *args)\n      theoretical, numerical = gradient_checker_v2.compute_gradient(\n          f, [array_ops.zeros(shape), array_ops.ones(updates_shape)], delta=1.0)\n      self.assertAllClose(theoretical, numerical)\n\n\nclass ShapeSizeRankTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def testDenseShape(self):\n    t_value = [[0, 42], [24, 0]]\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(t_value)))\n    self.assertEqual(4, self.evaluate(array_ops.size(t_value)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(t_value)))\n\n    t = constant_op.constant(t_value)\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(t)))\n    self.assertEqual(4, self.evaluate(array_ops.size(t)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(t)))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSparseShape(self):\n    sp_value = sparse_tensor.SparseTensorValue(\n        indices=((0, 1), (1, 0)), values=(42, 24), dense_shape=(2, 2))\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(sp_value)))\n    self.assertEqual(4, self.evaluate(array_ops.size(sp_value)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(sp_value)))\n\n    sp = sparse_tensor.SparseTensor.from_value(sp_value)\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(sp)))\n    self.assertEqual(4, self.evaluate(array_ops.size(sp)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(sp)))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSizeDtype(self):\n    tensor = [1]\n    self.assertEqual(dtypes.int32, self.evaluate(array_ops.size(tensor)).dtype)\n    self.assertEqual(\n        dtypes.int64,\n        self.evaluate(array_ops.size(tensor, out_type=dtypes.int64)).dtype)\n\n\nclass SequenceMaskTest(test_util.TensorFlowTestCase):\n\n  def testExceptions(self):\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"maxlen must be scalar\"):\n        array_ops.sequence_mask([10, 20], [10, 20])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalWithMaxlen(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([1, 3, 2]), 5)\n      self.assertAllEqual(res.get_shape(), [3, 5])\n      self.assertAllEqual(\n          res,\n          [[True, False, False, False, False], [True, True, True, False, False],\n           [True, True, False, False, False]])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalDtypeWithoutMaxlen(self):\n    with self.cached_session():\n      # test dtype and default maxlen:\n      res = array_ops.sequence_mask(\n          constant_op.constant([0, 1, 4]), dtype=dtypes.float32)\n      self.assertAllEqual(res.get_shape().as_list(), [3, 4])\n      self.assertAllEqual(\n          res,\n          [[0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0]])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalWithoutMaxlen(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([0, 1, 4]))\n      self.assertAllEqual(res.get_shape().as_list(), [3, 4])\n      self.assertAllEqual(\n          res, [[False, False, False, False], [True, False, False, False],\n                [True, True, True, True]])\n\n  @test_util.run_deprecated_v1\n  def testTwoDimensional(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([[1, 3, 2]]), 5)\n      self.assertAllEqual(res.get_shape(), [1, 3, 5])\n      self.assertAllEqual(res, [[[True, False, False, False, False],\n                                 [True, True, True, False, False],\n                                 [True, True, False, False, False]]])\n\n      # test dtype and default maxlen:\n      res = array_ops.sequence_mask(\n          constant_op.constant([[0, 1, 4], [1, 2, 3]]), dtype=dtypes.float32)\n      self.assertAllEqual(res.get_shape().as_list(), [2, 3, 4])\n      self.assertAllEqual(\n          res,\n          [[[0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0]],\n           [[1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0]]])\n\n  @test_util.run_deprecated_v1\n  def testUnknownShape(self):\n    lengths = array_ops.placeholder(dtype=dtypes.int32)\n    res = array_ops.sequence_mask(lengths)\n    self.assertEqual(res.shape, None)\n\n  @test_util.run_deprecated_v1\n  def testDtypes(self):\n\n    def check_dtypes(lengths_dtype, maxlen_dtype):\n      res = array_ops.sequence_mask(\n          constant_op.constant([1, 3, 2], dtype=lengths_dtype),\n          constant_op.constant(5, dtype=maxlen_dtype))\n      self.assertAllEqual(res.get_shape(), [3, 5])\n      self.assertAllEqual(\n          res,\n          [[True, False, False, False, False], [True, True, True, False, False],\n           [True, True, False, False, False]])\n\n    with self.cached_session():\n      check_dtypes(dtypes.int32, dtypes.int32)\n      check_dtypes(dtypes.int32, dtypes.int64)\n      check_dtypes(dtypes.int64, dtypes.int32)\n      check_dtypes(dtypes.int64, dtypes.int64)\n\n  def testOutputDtype(self):\n\n    def check_output_dtype(output_dtype):\n      res = self.evaluate(\n          array_ops.sequence_mask(\n              constant_op.constant([1, 3, 2], dtype=dtypes.int32),\n              constant_op.constant(5, dtype=dtypes.int32),\n              dtype=output_dtype))\n      self.assertAllEqual(\n          res,\n          self.evaluate(\n              math_ops.cast([[True, False, False, False, False],\n                             [True, True, True, False, False],\n                             [True, True, False, False, False]], output_dtype)))\n\n    check_output_dtype(dtypes.bool)\n    check_output_dtype(\"bool\")\n    check_output_dtype(np.bool)\n    check_output_dtype(dtypes.int32)\n    check_output_dtype(\"int32\")\n    check_output_dtype(np.int32)\n    check_output_dtype(dtypes.float32)\n    check_output_dtype(\"float32\")\n    check_output_dtype(np.float32)\n    check_output_dtype(dtypes.int64)\n    check_output_dtype(\"float64\")\n    check_output_dtype(np.float64)\n\n\nclass ConcatSliceResourceTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  @test_util.run_deprecated_v1\n  def testConcatSlice(self):\n    r1 = test_ops.stub_resource_handle_op(container=\"a\", shared_name=\"b\")\n    r2 = test_ops.stub_resource_handle_op(container=\"a\", shared_name=\"c\")\n    c = array_ops.stack([r1, r2])\n    s = array_ops.strided_slice(c, [1], [2])\n    self.evaluate(test_ops.resource_create_op(s))\n    with self.assertRaises(errors.AlreadyExistsError):\n      self.evaluate(test_ops.resource_create_op(r2))\n\n\nclass IdentityTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_gpu_only\n  def testEagerIdentity(self):\n    with context.eager_mode():\n\n      def _test(x, y, device):\n        self.assertAllEqual(x.numpy(), y.numpy())\n        self.assertTrue(device in y.device.lower())\n\n      with test_util.force_gpu():\n        a = constant_op.constant([[2], [3]], dtype=dtypes.float32)\n      with test_util.force_gpu():\n        b = array_ops.identity(a)\n        _test(a, b, \"gpu\")\n      with test_util.force_cpu():\n        c = array_ops.identity(b)\n        _test(b, c, \"cpu\")\n      with test_util.force_cpu():\n        d = array_ops.identity(c)\n        _test(c, d, \"cpu\")\n      with test_util.force_gpu():\n        e = array_ops.identity(d)\n        _test(d, e, \"gpu\")\n\n\nclass PadTest(test_util.TensorFlowTestCase):\n\n  def testEager(self):\n    with context.eager_mode():\n      t = constant_op.constant([[1, 2, 3], [4, 5, 6]])\n      paddings = constant_op.constant([[\n          1,\n          1,\n      ], [2, 2]])\n      padded = array_ops.pad(t, paddings, \"CONSTANT\")\n      self.assertAllEqual(padded.numpy(),\n                          [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0],\n                           [0, 0, 4, 5, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n\n\nclass InvertPermutationTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvertPermutation(self):\n    for dtype in [dtypes.int32, dtypes.int64]:\n      with self.subTest(dtype=dtype):\n        with self.cached_session(use_gpu=True):\n          x = constant_op.constant([3, 4, 0, 2, 1], dtype=dtype)\n          y = array_ops.invert_permutation(x)\n          self.assertAllEqual(y.get_shape(), [5])\n          self.assertAllEqual(y, [2, 4, 3, 0, 1])\n\n\nclass UnravelIndexTest(test_util.TensorFlowTestCase):\n\n  # TODO(b/73086570): Reenable test.\n  @unittest.skip(\"Test does not pass internally.\")\n  def testUnravelIndex(self):\n    with self.cached_session():\n      for dtype in [dtypes.int32, dtypes.int64]:\n        with self.subTest(dtype=dtype):\n          indices_1 = constant_op.constant(1621, dtype=dtype)\n          dims_1 = constant_op.constant([6, 7, 8, 9], dtype=dtype)\n          out_1 = array_ops.unravel_index(indices_1, dims_1)\n          self.assertAllEqual(out_1, [3, 1, 4, 1])\n\n          indices_2 = constant_op.constant([1621], dtype=dtype)\n          dims_2 = constant_op.constant([6, 7, 8, 9], dtype=dtype)\n          out_2 = array_ops.unravel_index(indices_2, dims_2)\n          self.assertAllEqual(out_2, [[3], [1], [4], [1]])\n\n          indices_3 = constant_op.constant([22, 41, 37], dtype=dtype)\n          dims_3 = constant_op.constant([7, 6], dtype=dtype)\n          out_3 = array_ops.unravel_index(indices_3, dims_3)\n          self.assertAllEqual(out_3, [[3, 6, 6], [4, 5, 1]])\n\n  # Test case for GitHub issue 40204.\n  def testUnravelIndexZeroDim(self):\n    with self.cached_session():\n      for dtype in [dtypes.int32, dtypes.int64]:\n        with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                    \"index is out of bound as with dims\"):\n          indices = constant_op.constant([2, 5, 7], dtype=dtype)\n          dims = constant_op.constant([3, 0], dtype=dtype)\n          self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n\n\nclass GuaranteeConstOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testSimple(self):\n    with self.cached_session():\n      a = array_ops.constant(10)\n      guarantee_a = array_ops.guarantee_const(a)\n      self.assertEqual(10, self.evaluate(guarantee_a))\n\n  @test_util.run_deprecated_v1\n  def testVariables(self):\n    with self.cached_session() as sess:\n      for use_resource in [False, True]:\n        with self.subTest(use_resource=use_resource):\n          a = variable_scope.get_variable(\n              \"var_{}\".format(use_resource), [],\n              initializer=init_ops.constant_initializer(10.0),\n              use_resource=use_resource)\n          guarantee_a = array_ops.guarantee_const(a)\n          self.evaluate(variables.global_variables_initializer())\n          self.assertEqual(10.0, self.evaluate(guarantee_a))\n\n  @test_util.run_deprecated_v1\n  def testResourceRejection(self):\n    with self.cached_session() as sess:\n      a = variable_scope.get_variable(\n          \"resource_var\", [],\n          initializer=init_ops.constant_initializer(10.0),\n          use_resource=True)\n      guarantee_a = array_ops.guarantee_const(a.handle)\n      self.evaluate(variables.global_variables_initializer())\n      with self.assertRaisesWithPredicateMatch(errors.InvalidArgumentError,\n                                               \"cannot be a resource variable\"):\n        self.evaluate(guarantee_a)\n\n\nclass SnapshotOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvertPermutation(self):\n    for dtype in [dtypes.int32, dtypes.int64, dtypes.float32, dtypes.float64]:\n      with self.subTest(dtype=dtype):\n        with self.cached_session(use_gpu=True):\n          x = constant_op.constant([0, 1, 2, 3], dtype=dtype)\n          y = gen_array_ops.snapshot(x)\n          self.assertAllEqual(y, [0, 1, 2, 3])\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass QuantizeAndDequantizeTest(test_util.TensorFlowTestCase):\n\n  # Generates a tensor of the specified `shape` using values from `values`\n  # scaled by (slice_idx + 1) along `axis` dimension.\n  def _scale_per_slice(self, shape, axis, values):\n    # Note: repeats the values if the shape is larger than values.\n    out = np.take(values, np.remainder(np.arange(np.prod(shape)),\n                                       len(values))).reshape(shape)\n    if axis is not None:\n      scale_shape = [1] * len(shape)\n      scale_shape[axis] = shape[axis]\n      out *= np.arange(1, shape[axis] + 1).reshape(scale_shape)\n    return out\n\n  def testAxis(self):\n    shape = np.array([2, 3, 4, 5])\n    values = np.array([-1, -0.5, 0, 0.3, 0.8, 0.555, 0.5], dtype=np.float32)\n    quant_values = np.array(\n        [-1, -0.5, 0, 38.0 / 128, 102.0 / 128, 71.0 / 128, 0.5],\n        dtype=np.float32)\n    for axis in [None, 0, 1, 2, 3]:\n      with self.subTest(axis=axis):\n        inputs = constant_op.constant(\n            self._scale_per_slice(shape, axis, values))\n        expected = self._scale_per_slice(shape, axis, quant_values)\n        unused_minmax_value = 0 if axis is None else [0] * shape[axis]\n        fake_quantized = self.evaluate(\n            array_ops.quantize_and_dequantize_v2(\n                inputs,\n                unused_minmax_value,\n                unused_minmax_value,\n                range_given=False,\n                round_mode=\"HALF_UP\",\n                axis=axis))\n        self.assertAllEqual(fake_quantized, expected)\n        if axis is not None:\n          fake_quantized = self.evaluate(\n              array_ops.quantize_and_dequantize_v2(\n                  inputs,\n                  unused_minmax_value,\n                  unused_minmax_value,\n                  range_given=False,\n                  axis=(axis - 4)))\n          self.assertAllClose(fake_quantized, expected)\n\n  def testQuantizeDequantizeGrad(self):\n    shape = (2, 2)\n    max_threshold = 0\n    min_threshold = -10\n    input_value = np.random.rand(2, 2) * 40.0 - 20.0\n    input_tensor = constant_op.constant(input_value, shape=shape,\n                                        name=\"input_tensor\")\n    with self.cached_session():\n      def f(a):\n        return array_ops.quantize_and_dequantize_v2(\n            a,\n            input_min=min_threshold,\n            input_max=max_threshold,\n            range_given=True)\n      output_grad = gradient_checker_v2.compute_gradient(f, [input_tensor])\n      self.assertAllClose(output_grad[0], np.zeros([1, 4, 4]))\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass SortedSearchTest(test_util.TensorFlowTestCase):\n\n  def testUpperBoundFloatHandCoded(self):\n    cdf = np.array([0, .2, .5, .6, .8, 1.], dtype=np.float32)\n    arr = np.array([.04, .99, .53, .58, .31, .01, .79, .8, .21],\n                   dtype=np.float32)\n    result = np.searchsorted(cdf, arr, side=\"right\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundFloatRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.uniform(size=shape).astype(np.float32), axis=(d - 1))\n      arr = np.random.uniform(size=shape).astype(np.float32) * dim_size\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundFloatUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.uniform(size=[batch_size, size_search_array]).astype(\n            np.float32),\n        axis=1)\n    arr = np.random.uniform(size=[batch_size, size_values]).astype(\n        np.float32) * size_search_array\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatHandCoded(self):\n    cdf = np.array([0, .2, .5, .6, .8, 1.], dtype=np.float32)\n    arr = np.array([.04, .99, .53, .58, .31, .01, .79, .8, .21],\n                   dtype=np.float32)\n    result = np.searchsorted(cdf, arr, side=\"left\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.uniform(size=shape).astype(np.float32), axis=(d - 1))\n      arr = np.random.uniform(size=shape).astype(np.float32) * dim_size\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.uniform(size=[batch_size, size_search_array]).astype(\n            np.float32),\n        axis=1)\n    arr = np.random.uniform(size=[batch_size, size_values]).astype(\n        np.float32) * size_search_array\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntHandCoded(self):\n    cdf = np.array([0, 20, 50, 60, 80, 100], dtype=np.int64)\n    arr = np.array([4, 99, 53, 58, 31, 1, 79, 8, 21], dtype=np.int64)\n    result = np.searchsorted(cdf, arr, side=\"right\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.randint(low=0, high=10, size=shape).astype(np.int64),\n          axis=(d - 1))\n      arr = np.random.randint(\n          low=0, high=10 * dim_size, size=shape).astype(np.int64)\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.randint(low=0, high=10,\n                          size=[batch_size,\n                                size_search_array]).astype(np.int64),\n        axis=1)\n    arr = np.random.randint(\n        low=0, high=10 * size_search_array, size=[batch_size,\n                                                  size_values]).astype(np.int64)\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntHandCoded(self):\n    cdf = np.array([0, 20, 50, 60, 80, 100], dtype=np.int64)\n    arr = np.array([4, 99, 53, 58, 31, 1, 79, 8, 21], dtype=np.int64)\n    result = np.searchsorted(cdf, arr, side=\"left\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.randint(low=0, high=10, size=shape).astype(np.int64),\n          axis=(d - 1))\n      arr = np.random.randint(\n          low=0, high=10 * dim_size, size=shape).astype(np.int64)\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.randint(low=0, high=10,\n                          size=[batch_size,\n                                size_search_array]).astype(np.int64),\n        axis=1)\n    arr = np.random.randint(\n        low=0, high=10 * size_search_array, size=[batch_size,\n                                                  size_values]).astype(np.int64)\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testZeroSequenceSize(self):\n    dtype = dtypes.int32\n    for side in (\"left\", \"right\"):\n      with self.subTest(side=side):\n        self.assertAllEqual(\n            array_ops.searchsorted(\n                array_ops.ones([2, 0]),\n                array_ops.ones([2, 3]),\n                side=side,\n                out_type=dtype), array_ops.zeros([2, 3], dtype))\n\n  def testZeroValueSize(self):\n    dtype = dtypes.int32\n    for side in (\"left\", \"right\"):\n      with self.subTest(side=side):\n        self.assertAllEqual(\n            array_ops.searchsorted(\n                array_ops.ones([2, 3]),\n                array_ops.ones([2, 0]),\n                side=side,\n                out_type=dtype), array_ops.zeros([2, 0], dtype))\n\n\nclass BatchGatherNdTest(test_util.TensorFlowTestCase):\n\n  def testShapesMatch(self):\n    \"\"\"Tests for various different shape combinations.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 2), (2, 3), 0),)\n    shapes.append(((2, 2, 2), (3,), 0),)\n    shapes.append(((2, 2, 2), (1,), 0),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(1.0, shape=(params_shape))\n        indices = constant_op.constant(\n            1, shape=(indices_shape), dtype=dtypes.int32)\n        out = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n        ndims_params = len(params_shape) - batch_dims\n        ndims_rows = ndims_params - indices_shape[-1]\n        expected_out_shape = indices_shape[:-1]\n        if ndims_rows > 0:\n          expected_out_shape += params_shape[-ndims_rows:]\n        self.assertSequenceEqual(out.shape, expected_out_shape)\n\n  def testReducesToGatherNDWhenBatchDimIsZero(self):\n    \"\"\"Confirms setting batch_dims to zero reduces to tf.gather_nd.\"\"\"\n    params = constant_op.constant(np.random.uniform(0.0, 1.0, size=(7, 8, 9)))\n    indices_shapes = []\n    indices_shapes.append((1,))\n    indices_shapes.append((3, 1))\n    indices_shapes.append((3, 3, 1))\n    indices_shapes.append((2,))\n    indices_shapes.append((3, 2))\n    indices_shapes.append((3, 3, 2))\n    indices_shapes.append((3,))\n    indices_shapes.append((3, 3))\n    indices_shapes.append((3, 3, 3))\n\n    for indices_shape in indices_shapes:\n      with self.subTest(indices_shape=indices_shape):\n        indices = np.random.randint(0, 7, size=indices_shape)\n        gather_nd_result = gen_array_ops.gather_nd(params, indices)\n        batch_gather_nd_result = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=0)\n        self.assertAllEqual(gather_nd_result, batch_gather_nd_result)\n\n  def testSameResultAsMapFn(self):\n    \"\"\"Compares results with gather_nd called on every element with map_fn.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(\n            np.random.uniform(0.0, 1.0, size=(params_shape)))\n        indices = np.random.randint(0, 2, size=indices_shape)\n        batch_gather_nd_result = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n\n        if batch_dims > 1:\n          params = array_ops.reshape(\n              params, shape=[-1] + list(params_shape[batch_dims:]))\n          indices = array_ops.reshape(\n              indices, shape=[-1] + list(indices_shape[batch_dims:]))\n\n        map_fn_gather_nd_result = map_fn.map_fn(\n            fn=self._map_fn_body, elems=(params, indices), dtype=dtypes.float64)\n\n        if batch_dims > 1:\n          out_shape = map_fn_gather_nd_result.shape.as_list()\n          out_shape = list(params_shape[:batch_dims]) + out_shape[1:]\n          map_fn_gather_nd_result = array_ops.reshape(\n              map_fn_gather_nd_result, shape=out_shape)\n\n        self.assertAllEqual(map_fn_gather_nd_result, batch_gather_nd_result)\n\n  def _map_fn_body(self, elems):\n    return gen_array_ops.gather_nd(elems[0], elems[1])\n\n  def testBatchDimsAsTensor(self):\n    \"\"\"Tests Tensor batch_dims as input works as intended.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 0),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(\n            np.random.uniform(0.0, 1.0, size=(params_shape)))\n        indices = np.random.randint(0, 2, size=indices_shape)\n        batch_gather_nd_result = array_ops.gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n        batch_dims_tensor = constant_op.constant([batch_dims])\n        batch_gather_nd_tensor_batch_dims_result = array_ops.gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims_tensor)\n\n        self.assertAllEqual(batch_gather_nd_tensor_batch_dims_result,\n                            batch_gather_nd_result)\n\n  def testInvalidBatchDimsRaisesException(self):\n    \"\"\"Tests whether invalid batch_dims raise expected exceptions.\"\"\"\n    params = constant_op.constant(\n        np.random.uniform(0.0, 1.0, size=(3, 2, 2, 3, 4)))\n    indices = np.random.randint(0, 2, size=(3, 2, 3))\n\n    with self.assertRaises(TypeError):\n      array_ops.batch_gather_nd(\n          params=params,\n          indices=indices,\n          batch_dims=constant_op.constant((0, 1)))\n\n    with self.assertRaises(ValueError):\n      array_ops.batch_gather_nd(params=params, indices=indices, batch_dims=-1)\n\n    with self.assertRaises(ValueError):\n      array_ops.batch_gather_nd(params=params, indices=indices, batch_dims=4)\n\n  @test_util.run_deprecated_v1\n  def testNoneBatchDimensions(self):\n    \"\"\"Tests gather_nd works with None dimensions.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      params_ph_shape = list(params_shape)\n      indices_ph_shape = list(indices_shape)\n      for i in range(batch_dims):\n        params_ph_shape[i] = None\n        indices_ph_shape[i] = None\n\n      params = array_ops.placeholder(dtypes.float32, shape=params_ph_shape)\n      indices = array_ops.placeholder(dtypes.int32, shape=indices_ph_shape)\n      out = array_ops.batch_gather_nd(\n          params=params, indices=indices, batch_dims=batch_dims)\n\n      with self.cached_session() as sess:\n        params_val = np.ones(dtype=np.float32, shape=params_shape)\n        indices_val = np.ones(dtype=np.int32, shape=indices_shape)\n        res = sess.run(\n            out, feed_dict={\n                params: params_val,\n                indices: indices_val\n            })\n      row_ndims = len(params_shape) - batch_dims - indices_shape[-1]\n      expected_out_shape = indices_shape[:-1]\n      if row_ndims > 0:\n        expected_out_shape += params_shape[-row_ndims:]\n\n      self.assertSequenceEqual(res.shape, expected_out_shape)\n\n  @test_util.run_deprecated_v1\n  def testUnknownIndices(self):\n    \"\"\"Tests whether indices with unknown rank works correctly.\"\"\"\n    params = constant_op.constant(((0, 1, 2),))\n    indices = array_ops.placeholder(dtypes.int32)\n    gather_nd_t = array_ops.gather_nd(params, indices, batch_dims=1)\n    shape = gather_nd_t.get_shape()\n    self.assertEqual(None, shape.ndims)\n    self.assertEqual(None, tensor_shape.dimension_value(shape[0]))\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass RepeatTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  @parameterized.parameters(\n      (3, 4, None),\n      ([[1, 2], [3, 4]], 2, None),\n      ([[1, 2], [3, 4]], [1, 2], 0),\n      ([[1, 2], [3, 4]], [1, 2], 1),\n      ([[1, 2], [3, 4]], 3, 1),\n      ([[1, 2], [3, 4]], [1, 2, 3, 4], None),\n      (np.ones([0, 4]), 0, 1),\n      (np.ones([1, 2]), [2], None),\n  )\n  def testRepeat(self, array, repeats, axis):\n    array = np.array(array)\n\n    @def_function.function(\n        input_signature=[tensor_spec.TensorSpec(None, dtypes.int32)] * 2)\n    def repeat_fn(array, repeats):\n      return array_ops.repeat(array, repeats, axis)\n\n    v_tf = array_ops.repeat(constant_op.constant(array), repeats, axis)\n    v_tf_fn = repeat_fn(\n        constant_op.constant(array, dtype=dtypes.int32), repeats)\n    v_np = np.repeat(array, repeats, axis)\n    self.assertAllEqual(v_tf, v_np)\n    self.assertAllEqual(v_tf_fn, v_np)\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass TileVariantTest(test_util.TensorFlowTestCase):\n\n  def test_tile_tensor_list(self):\n    t = constant_op.constant(np.random.uniform(size=[2, 3, 4]))\n    handle = list_ops.tensor_list_from_tensor(t, element_shape=None)\n    with ops.device(\"CPU:0\"):\n      tiled_handles = array_ops.tile(array_ops.reshape(handle, [1]), [2])\n    tiled_tensor_0 = list_ops.tensor_list_stack(tiled_handles[0], t.dtype, 2,\n                                                [3, 4])\n    tiled_tensor_1 = list_ops.tensor_list_stack(tiled_handles[1], t.dtype, 2,\n                                                [3, 4])\n    self.assertAllEqual(t, tiled_tensor_0)\n    self.assertAllEqual(t, tiled_tensor_1)\n    # Now mutate some of the lists and make sure the changes are not reflected\n    # in the tiled handles.\n    with ops.control_dependencies([\n        list_ops.tensor_list_scatter([t[0] + 1], [0], input_handle=handle),\n        list_ops.tensor_list_set_item(tiled_handles[0], 0, t[0] + 2)]):\n      tiled_tensor_0 = list_ops.tensor_list_stack(tiled_handles[0], t.dtype, 2,\n                                                  [3, 4])\n      tiled_tensor_1 = list_ops.tensor_list_stack(tiled_handles[1], t.dtype, 2,\n                                                  [3, 4])\n    self.assertAllEqual(t, tiled_tensor_0)\n    self.assertAllEqual(t, tiled_tensor_1)\n\n\nif __name__ == \"__main__\":\n  test_lib.main()\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#define EIGEN_USE_THREADS\n\n#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"\n\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\n// Simulate quantization precision loss in a float tensor by:\n// 1. Quantize the tensor to fixed point numbers, which should match the target\n//    quantization method when it is used in inference.\n// 2. Dequantize it back to floating point numbers for the following ops, most\n//    likely matmul.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV2Op : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV2Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n\n    string round_mode_string;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n    OP_REQUIRES(\n        ctx,\n        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n        errors::InvalidArgument(\"Round mode string must be \"\n                                \"'HALF_UP' or \"\n                                \"'HALF_TO_EVEN', is '\" +\n                                round_mode_string + \"'\"));\n    if (round_mode_string == \"HALF_UP\") {\n      round_mode_ = ROUND_HALF_UP;\n    } else if (round_mode_string == \"HALF_TO_EVEN\") {\n      round_mode_ = ROUND_HALF_TO_EVEN;\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    OP_REQUIRES(\n        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n                                \" but is rank \", input.shape().dims()));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n\n private:\n  int num_bits_;\n  int axis_;\n  QuantizerRoundMode round_mode_;\n  bool signed_input_;\n  bool range_given_;\n  bool narrow_range_;\n};\n\n// Implementation of QuantizeAndDequantizeV4GradientOp.\n// When back-propagating the error through a quantized layer, the following\n// paper gives evidence that clipped-ReLU is better than non-clipped:\n// \"Deep Learning with Low Precision by Half-wave Gaussian Quantization\"\n// http://zpascal.net/cvpr2017/Cai_Deep_Learning_With_CVPR_2017_paper.pdf\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV4GradientOp : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV4GradientOp(OpKernelConstruction* ctx)\n      : OpKernel::OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    const Tensor& input_max_tensor = ctx->input(3);\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }\n\n private:\n  int axis_;\n};\n\n// Simulate quantization precision loss in a float tensor by:\n// 1. Quantize the tensor to fixed point numbers, which should match the target\n//    quantization method when it is used in inference.\n// 2. Dequantize it back to floating point numbers for the following ops, most\n//    likely matmul.\n// Almost identical to QuantizeAndDequantizeV2Op, except that num_bits is a\n// tensor.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeV3Op : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeV3Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    Tensor num_bits_tensor;\n    num_bits_tensor = ctx->input(3);\n    int num_bits_val = num_bits_tensor.scalar<int32>()();\n\n    OP_REQUIRES(\n        ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n        errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,\n                                \" with signed_input_ \", signed_input_));\n\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_,\n        num_bits_val, range_given_, &input_min_tensor, &input_max_tensor,\n        ROUND_HALF_TO_EVEN, narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_val, range_given_, &input_min_tensor, &input_max_tensor,\n        ROUND_HALF_TO_EVEN, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n\n private:\n  int axis_;\n  bool signed_input_;\n  bool range_given_;\n  bool narrow_range_;\n};\n\n// DEPRECATED: Use QuantizeAndDequantizeV2Op.\ntemplate <typename Device, typename T>\nclass QuantizeAndDequantizeOp : public OpKernel {\n public:\n  explicit QuantizeAndDequantizeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n    if (range_given_) {\n      OP_REQUIRES(\n          ctx, input_min_ <= input_max_,\n          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                  \" > input_max \", input_max_));\n    }\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    // One global scale.\n    Tensor input_min_tensor(DataTypeToEnum<T>::value, TensorShape());\n    Tensor input_max_tensor(DataTypeToEnum<T>::value, TensorShape());\n    // Initialize the tensors with the values in the Attrs.\n    input_min_tensor.template scalar<T>()() = static_cast<T>(input_min_);\n    input_max_tensor.template scalar<T>()() = static_cast<T>(input_max_);\n\n    functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> functor;\n    functor(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_,\n            num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n            ROUND_HALF_TO_EVEN, /*narrow_range=*/false, output->flat<T>());\n  }\n\n private:\n  bool signed_input_;\n  int num_bits_;\n  bool range_given_;\n  float input_min_;\n  float input_max_;\n};\n\n// Specializations for CPUDevice.\n\nnamespace functor {\ntemplate <typename T>\nstruct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,\n                  const bool signed_input, const int num_bits,\n                  const bool range_given, Tensor* input_min_tensor,\n                  Tensor* input_max_tensor, QuantizerRoundMode round_mode,\n                  bool narrow_range, typename TTypes<T>::Vec out) {\n    QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(\n        d, input, signed_input, num_bits, range_given, input_min_tensor,\n        input_max_tensor, round_mode, narrow_range, out);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,\n                  bool signed_input, int num_bits, bool range_given,\n                  Tensor* input_min_tensor, Tensor* input_max_tensor,\n                  QuantizerRoundMode round_mode, bool narrow_range,\n                  typename TTypes<T, 3>::Tensor out) {\n    QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(\n        d, input, signed_input, num_bits, range_given, input_min_tensor,\n        input_max_tensor, round_mode, narrow_range, out);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,\n                  typename TTypes<T>::ConstFlat input,\n                  typename TTypes<T>::ConstScalar input_min_tensor,\n                  typename TTypes<T>::ConstScalar input_max_tensor,\n                  typename TTypes<T>::Flat input_backprop,\n                  typename TTypes<T>::Scalar input_min_backprop,\n                  typename TTypes<T>::Scalar input_max_backprop) {\n    QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(\n        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n        input_min_backprop, input_max_backprop);\n  }\n};\n\ntemplate <typename T>\nstruct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {\n  void operator()(const CPUDevice& d,\n                  typename TTypes<T, 3>::ConstTensor gradient,\n                  typename TTypes<T, 3>::ConstTensor input,\n                  const Tensor* input_min_tensor,\n                  const Tensor* input_max_tensor,\n                  typename TTypes<T, 3>::Tensor input_backprop,\n                  typename TTypes<T>::Flat input_min_backprop,\n                  typename TTypes<T>::Flat input_max_backprop) {\n    QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(\n        d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,\n        input_min_backprop, input_max_backprop);\n  }\n};\n\ntemplate struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,\n                                                                      float>;\ntemplate struct functor::QuantizeAndDequantizePerChannelGradientFunctor<\n    CPUDevice, double>;\n\n}  // namespace functor\n\n#define REGISTER_CPU_KERNEL(T)                                                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                              .Device(DEVICE_CPU)                              \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n      QuantizeAndDequantizeOp<CPUDevice, T>);\nTF_CALL_float(REGISTER_CPU_KERNEL);\nTF_CALL_double(REGISTER_CPU_KERNEL);\n#undef REGISTER_CPU_KERNEL\n\n#if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n    (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)\n#define REGISTER_GPU_KERNEL(T)                                                 \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .HostMemory(\"num_bits\")                          \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\\n  REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\\n                              .Device(DEVICE_GPU)                              \\\n                              .HostMemory(\"input_min\")                         \\\n                              .HostMemory(\"input_max\")                         \\\n                              .TypeConstraint<T>(\"T\"),                         \\\n                          QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\\n      QuantizeAndDequantizeOp<GPUDevice, T>);\nTF_CALL_float(REGISTER_GPU_KERNEL);\nTF_CALL_double(REGISTER_GPU_KERNEL);\n#undef REGISTER_GPU_KERNEL\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n}  // namespace tensorflow\n", "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for array_ops.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nimport time\nimport unittest\n\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.python.client import session\nfrom tensorflow.python.eager import backprop\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import sparse_tensor\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import test_ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_array_ops\nfrom tensorflow.python.ops import gradient_checker_v2\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import init_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import map_fn\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import state_ops\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import test as test_lib\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass BatchMatrixTransposeTest(test_util.TensorFlowTestCase):\n\n  def testNonBatchMatrix(self):\n    matrix = [[1, 2, 3], [4, 5, 6]]  # Shape (2, 3)\n    expected_transposed = [[1, 4], [2, 5], [3, 6]]  # Shape (3, 2)\n    transposed = array_ops.matrix_transpose(matrix)\n    self.assertEqual((3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testConjugate(self):\n    m = [[1 + 1j, 2 + 2j, 3 + 3j], [4 + 4j, 5 + 5j, 6 + 6j]]\n    expected_transposed = [[1 - 1j, 4 - 4j], [2 - 2j, 5 - 5j], [3 - 3j, 6 - 6j]]\n    matrix = ops.convert_to_tensor(m)\n    transposed = array_ops.matrix_transpose(matrix, conjugate=True)\n    self.assertEqual((3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testBatchMatrix(self):\n    matrix_0 = [[1, 2, 3], [4, 5, 6]]\n    matrix_0_t = [[1, 4], [2, 5], [3, 6]]\n    matrix_1 = [[11, 22, 33], [44, 55, 66]]\n    matrix_1_t = [[11, 44], [22, 55], [33, 66]]\n    batch_matrix = [matrix_0, matrix_1]  # Shape (2, 2, 3)\n    expected_transposed = [matrix_0_t, matrix_1_t]  # Shape (2, 3, 2)\n    transposed = array_ops.matrix_transpose(batch_matrix)\n    self.assertEqual((2, 3, 2), transposed.get_shape())\n    self.assertAllEqual(expected_transposed, transposed)\n\n  def testNonBatchMatrixDynamicallyDefined(self):\n    # needs explicit `constant` because lists are not automatically\n    # converted to sensors when applying `transpose` below\n    matrix = constant_op.constant([[1, 2, 3], [4, 5, 6]])  # Shape (2, 3)\n    expected_transposed = [[1, 4], [2, 5], [3, 6]]  # Shape (3, 2)\n\n    @def_function.function(input_signature=[\n        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n    ])\n    def transpose(matrix):\n      self.assertIs(matrix.shape.ndims, None)\n      return array_ops.matrix_transpose(matrix)\n\n    self.assertAllEqual(expected_transposed, transpose(matrix))\n\n  def testBatchMatrixDynamicallyDefined(self):\n    matrix_0 = [[1, 2, 3], [4, 5, 6]]\n    matrix_0_t = [[1, 4], [2, 5], [3, 6]]\n    matrix_1 = [[11, 22, 33], [44, 55, 66]]\n    matrix_1_t = [[11, 44], [22, 55], [33, 66]]\n    # needs explicit `constant` because lists are not automatically\n    # converted to sensors when applying `transpose` below\n    batch_matrix = constant_op.constant([matrix_0, matrix_1])  # Shape (2, 2, 3)\n    expected_transposed = [matrix_0_t, matrix_1_t]  # Shape (2, 3, 2)\n\n    @def_function.function(input_signature=[\n        tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n    ])\n    def transpose(matrix):\n      self.assertIs(matrix.shape.ndims, None)\n      return array_ops.matrix_transpose(matrix)\n\n    self.assertAllEqual(expected_transposed, transpose(batch_matrix))\n\n  def testTensorWithStaticRankLessThanTwoRaisesBecauseNotAMatrix(self):\n    vector = [1, 2, 3]\n    with self.assertRaisesRegex(ValueError, \"should be a \"):\n      array_ops.matrix_transpose(vector)\n\n\nclass BooleanMaskTest(test_util.TensorFlowTestCase):\n\n  def setUp(self):\n    self.rng = np.random.RandomState(42)\n\n  def CheckVersusNumpy(self, ndims_mask, arr_shape, make_mask=None, axis=None):\n    \"\"\"Check equivalence between boolean_mask and numpy masking.\"\"\"\n    if make_mask is None:\n      make_mask = lambda shape: self.rng.randint(0, 2, size=shape).astype(bool)\n    arr = np.random.rand(*arr_shape)\n    mask = make_mask(arr_shape[:ndims_mask])\n    if axis is not None:\n      mask = make_mask(arr_shape[axis:ndims_mask + axis])\n    if axis is None or axis == 0:\n      masked_arr = arr[mask]\n    elif axis == 1:\n      masked_arr = arr[:, mask]\n    elif axis == 2:\n      masked_arr = arr[:, :, mask]\n    with self.cached_session():\n      masked_tensor = array_ops.boolean_mask(arr, mask, axis=axis)\n\n      # Leading dimension size of masked_tensor is always unknown until runtime\n      # since we don't how many elements will be kept.\n      leading = 1 if axis is None else axis + 1\n      self.assertAllEqual(masked_tensor.get_shape()[leading:],\n                          masked_arr.shape[leading:])\n\n      self.assertAllClose(masked_arr, masked_tensor)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim2Axis1(self):\n    ndims_mask = 1\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape, axis=1)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim2Axis1(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape, axis=1)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim1(self):\n    ndims_mask = 1\n    for arr_shape in [(1,), (2,), (3,), (10,)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim1ArrDim2(self):\n    ndims_mask = 1\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim2(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1), (2, 2), (2, 5)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testMaskDim2ArrDim3(self):\n    ndims_mask = 2\n    for arr_shape in [(1, 1, 1), (1, 2, 2), (2, 2, 1)]:\n      with self.subTest(arr_shape=arr_shape):\n        self.CheckVersusNumpy(ndims_mask, arr_shape)\n\n  @test_util.run_deprecated_v1\n  def testEmptyInput2D(self):\n    mask = np.array([True, False])\n    arr = np.array([[], []]).astype(np.float32)\n    numpy_result = arr[mask]\n    tf_result = array_ops.boolean_mask(arr, mask)\n    self.assertAllEqual(numpy_result.shape[1:], tf_result.get_shape()[1:])\n    with self.cached_session():\n      self.assertAllClose(numpy_result, tf_result)\n\n  @test_util.run_deprecated_v1\n  def testEmptyInput1D(self):\n    mask = np.array([]).astype(bool)\n    arr = np.array([]).astype(np.float32)\n    numpy_result = arr[mask]\n    tf_result = array_ops.boolean_mask(arr, mask)\n    self.assertAllEqual(numpy_result.shape[1:], tf_result.get_shape()[1:])\n    with self.cached_session():\n      self.assertAllClose(numpy_result, tf_result)\n\n  @test_util.run_deprecated_v1\n  def testEmptyOutput(self):\n    make_mask = lambda shape: np.zeros(shape, dtype=bool)\n    for ndims_mask in range(1, 4):\n      for ndims_arr in range(ndims_mask, ndims_mask + 3):\n        for _ in range(3):\n          with self.subTest(ndims_mask=ndims_mask, ndims_arr=ndims_arr, _=_):\n            arr_shape = np.random.randint(1, 5, size=ndims_arr)\n            self.CheckVersusNumpy(ndims_mask, arr_shape, make_mask=make_mask)\n\n  @test_util.run_deprecated_v1\n  def testWorksWithDimensionsEqualToNoneDuringGraphBuild(self):\n    # The rank of the mask tensor must be specified. This is explained\n    # in the docstring as well.\n    with self.cached_session() as sess:\n      ph_tensor = array_ops.placeholder(dtypes.int32, shape=None)\n      ph_mask = array_ops.placeholder(dtypes.bool, shape=[None])\n\n      arr = np.array([[1, 2], [3, 4]])\n      mask = np.array([False, True])\n\n      masked_tensor = sess.run(\n          array_ops.boolean_mask(ph_tensor, ph_mask),\n          feed_dict={\n              ph_tensor: arr,\n              ph_mask: mask\n          })\n      np.testing.assert_allclose(masked_tensor, arr[mask])\n\n  @test_util.run_deprecated_v1\n  def testMaskDimensionsSetToNoneRaises(self):\n    # The rank of the mask tensor must be specified. This is explained\n    # in the docstring as well.\n    with self.cached_session():\n      tensor = array_ops.placeholder(dtypes.int32, shape=[None, 2])\n      mask = array_ops.placeholder(dtypes.bool, shape=None)\n      with self.assertRaisesRegex(ValueError, \"dimensions must be specified\"):\n        array_ops.boolean_mask(tensor, mask)\n\n  def testMaskHasMoreDimsThanTensorRaises(self):\n    mask = [[True, True], [False, False]]\n    tensor = [1, 2, 3, 4]\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"incompatible\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  def testMaskIsScalarRaises(self):\n    mask = True\n    tensor = 1\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"mask.*scalar\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  def testMaskShapeDifferentThanFirstPartOfTensorShapeRaises(self):\n    mask = [True, True, True]\n    tensor = [[1, 2], [3, 4]]\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"incompatible\"):\n        array_ops.boolean_mask(tensor, mask).eval()\n\n  @test_util.run_deprecated_v1\n  def testStringMask(self):\n    # Reproduces b/111171330, where the optimized boolean_mask graph would\n    # be incorrectly placed on GPU.\n    with ops.Graph().as_default():\n      tile_placeholder = array_ops.placeholder(dtypes.int32, [2])\n      string_tensor = array_ops.tile([[\"hello\"]], tile_placeholder)\n      bool_tensor = array_ops.tile([[True]], tile_placeholder)\n      masked_tensor = array_ops.boolean_mask(string_tensor, bool_tensor)\n      config = config_pb2.ConfigProto()\n      config.graph_options.rewrite_options.shape_optimization = 1\n      config.gpu_options.per_process_gpu_memory_fraction = 0.3\n      with session.Session(config=config) as sess:\n        result = sess.run(masked_tensor, feed_dict={tile_placeholder: [2, 2]})\n        self.assertAllEqual([b\"hello\", b\"hello\", b\"hello\", b\"hello\"], result)\n\n  def testMaskWithAxisTensor(self):\n\n    @def_function.function(autograph=False)\n    def f():\n      return array_ops.boolean_mask([1, 2, 3], [True, False, True],\n                                    axis=constant_op.constant(\n                                        0, dtype=dtypes.int32))\n\n    self.assertAllEqual(self.evaluate(f()), [1, 3])\n\n  def testMaskWithAxisNonConstTensor(self):\n\n    @def_function.function(\n        autograph=False,\n        input_signature=[\n            tensor_spec.TensorSpec(shape=None, dtype=dtypes.int32)\n        ])\n    def f(axis):\n      return array_ops.boolean_mask([1, 2, 3], [True, False, True], axis=axis)\n\n    self.assertAllEqual(\n        self.evaluate(f(constant_op.constant(0, dtype=dtypes.int32))), [1, 3])\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass OperatorShapeTest(test_util.TensorFlowTestCase):\n\n  def testExpandScalar(self):\n    scalar = \"hello\"\n    scalar_expanded = array_ops.expand_dims(scalar, [0])\n    self.assertEqual(scalar_expanded.get_shape(), (1,))\n\n  def testSqueezeScalar(self):\n    scalar = \"hello\"\n    scalar_squeezed = array_ops.squeeze(scalar, ())\n    self.assertEqual(scalar_squeezed.get_shape(), ())\n\n  def testSqueezeMatrix(self):\n    matrix = [[1, 2, 3]]\n    matrix_squeezed = array_ops.squeeze(matrix, [0])\n    self.assertEqual(matrix_squeezed.get_shape(), (3))\n\n    with self.assertRaisesRegex(\n        Exception, \"Can not squeeze dim.1., expected a dimension of 1, got 3\"):\n      matrix_squeezed = array_ops.squeeze(matrix, [1])\n\n  def testSqueezeScalarDim(self):\n    matrix = [[1, 2, 3]]\n    matrix_squeezed = array_ops.squeeze(matrix, 0)\n    self.assertEqual(matrix_squeezed.get_shape(), (3))\n\n  def testExpandDimsWithNonScalarDim(self):\n    with self.assertRaisesRegex(Exception,\n                                \"must be a tensor with a single value\"):\n      array_ops.expand_dims(1, axis=[0, 1])\n\n\nclass ReverseV2Test(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testReverse0DimAuto(self):\n    x_np = 4\n    for use_gpu in [False, True]:\n      with self.subTest(use_gpu=use_gpu):\n        with self.cached_session(use_gpu=use_gpu):\n          x_tf = array_ops.reverse_v2(x_np, []).eval()\n          self.assertAllEqual(x_tf, x_np)\n\n  def _reverse1DimAuto(self, np_dtype):\n    x_np = np.array([1, 200, 3, 40, 5], dtype=np_dtype)\n\n    for use_gpu in [False, True]:\n      for axis_dtype in [dtypes.int32, dtypes.int64]:\n        with self.subTest(use_gpu=use_gpu, axis_dtype=axis_dtype):\n          with self.cached_session(use_gpu=use_gpu):\n            x_tf = array_ops.reverse_v2(\n                x_np, constant_op.constant([0], dtype=axis_dtype)).eval()\n            self.assertAllEqual(x_tf, np.asarray(x_np)[::-1])\n\n  def _reverse2DimAuto(self, np_dtype):\n    x_np = np.array([[1, 200, 3], [4, 5, 60]], dtype=np_dtype)\n\n    for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n      for use_gpu in [False, True]:\n        for axis_dtype in [dtypes.int32, dtypes.int64]:\n          with self.subTest(\n              reverse_f=reverse_f, use_gpu=use_gpu, axis_dtype=axis_dtype):\n            with self.cached_session(use_gpu=use_gpu):\n              x_tf_1 = reverse_f(x_np,\n                                 constant_op.constant([0],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_2 = reverse_f(x_np,\n                                 constant_op.constant([-2],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_3 = reverse_f(x_np,\n                                 constant_op.constant([1],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_4 = reverse_f(x_np,\n                                 constant_op.constant([-1],\n                                                      dtype=axis_dtype)).eval()\n              x_tf_5 = reverse_f(x_np,\n                                 constant_op.constant([1, 0],\n                                                      dtype=axis_dtype)).eval()\n              self.assertAllEqual(x_tf_1, np.asarray(x_np)[::-1, :])\n              self.assertAllEqual(x_tf_2, np.asarray(x_np)[::-1, :])\n              self.assertAllEqual(x_tf_3, np.asarray(x_np)[:, ::-1])\n              self.assertAllEqual(x_tf_4, np.asarray(x_np)[:, ::-1])\n              self.assertAllEqual(x_tf_5, np.asarray(x_np)[::-1, ::-1])\n\n  # This test covers the axis validation in the shape function\n  # (no eval())\n  @test_util.run_deprecated_v1\n  def testInvalidAxis(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n    with self.assertRaisesRegex(ValueError, \"is out of valid range\"):\n      array_ops.reverse_v2(x_np, [-30])\n    with self.assertRaisesRegex(ValueError, \"is out of valid range\"):\n      array_ops.reverse_v2(x_np, [2])\n    with self.assertRaisesRegex(ValueError, \"axis 0 specified more than once\"):\n      array_ops.reverse_v2(x_np, [0, -2])\n\n  # This is the version of reverse that uses axis indices rather than\n  # bool tensors\n  # TODO(b/32254538): Change this test to use array_ops.reverse\n  #\n  # Note: this test passes placeholder as constant axis is validated\n  # in shape function (see testInvalidAxis)\n  @test_util.run_deprecated_v1\n  def testInvalid(self):\n    x_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n    axis = array_ops.placeholder(dtypes.int32)\n    with self.cached_session():\n      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                  \"is out of.*range\"):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [-30]})\n      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                  \"is out of.*range\"):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [2]})\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          \"(axis 0 specified more than once|canonicalized axis 0 was repeated.)\"\n      ):\n        array_ops.reverse_v2(x_np, axis).eval(feed_dict={axis: [0, -2]})\n\n  @test_util.run_deprecated_v1\n  def testReverse1DimAuto(self):\n    for dtype in [\n        np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.bool,\n        np.float16, np.float32, np.float64, np.complex64, np.complex128,\n        np.array(b\"\").dtype.type\n    ]:\n      self._reverse1DimAuto(dtype)\n\n  @test_util.run_deprecated_v1\n  def testReverse2DimAuto(self):\n    for dtype in [\n        np.uint8, np.int8, np.uint16, np.int16, np.int32, np.int64, np.bool,\n        np.float16, np.float32, np.float64, np.complex64, np.complex128,\n        np.array(b\"\").dtype.type\n    ]:\n      self._reverse2DimAuto(dtype)\n\n  @test_util.run_deprecated_v1\n  def testUnknownDims(self):\n    reverse_v2 = array_ops.reverse_v2\n    data_t = array_ops.placeholder(dtypes.float32)\n    axis_known_t = array_ops.placeholder(dtypes.int32, shape=[3])\n    reverse_known_t = reverse_v2(data_t, axis_known_t)\n    # Unlike V1 we cannot know this anymore\n    self.assertEqual(None, reverse_known_t.get_shape().ndims)\n\n    axis_unknown_t = array_ops.placeholder(dtypes.int32)\n    reverse_unknown_t = reverse_v2(data_t, axis_unknown_t)\n    self.assertIs(None, reverse_unknown_t.get_shape().ndims)\n\n    data_2d_t = array_ops.placeholder(dtypes.float32, shape=[None, None])\n    axis_2d_t = array_ops.placeholder(dtypes.int32, shape=[3])\n    reverse_2d_t = reverse_v2(data_2d_t, axis_2d_t)\n    self.assertEqual(2, reverse_2d_t.get_shape().ndims)\n\n  @test_util.run_deprecated_v1\n  def testReverseRowsOf3Channels(self):\n    \"\"\"Tests optimized code for reversing rows with last dim size = 3.\"\"\"\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in (1, 2):\n          for middle_size in list(range(50)) + [100000]:\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 3, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 3))\n              x_tf = reverse_f(x_np, [1]).eval()\n              np_answer = x_np[:, ::-1, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  @test_util.run_deprecated_v1\n  def testReverseRowsOf4Channels(self):\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in (1, 2):\n          for middle_size in list(range(50)) + [100000]:\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 4, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 4))\n              x_tf = reverse_f(x_np, [1]).eval()\n              np_answer = x_np[:, ::-1, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  @test_util.run_deprecated_v1\n  def testReverseColumnsOf3Channels(self):\n    with self.session(use_gpu=True):\n      for reverse_f in [array_ops.reverse_v2, array_ops.reverse]:\n        for outer_size in list(range(50)) + [100000]:\n          for middle_size in (1, 2):\n            with self.subTest(\n                reverse_f=reverse_f,\n                outer_size=outer_size,\n                middle_size=middle_size):\n              x_np = np.reshape(\n                  np.arange(outer_size * middle_size * 3, dtype=np.float32),\n                  newshape=(outer_size, middle_size, 3))\n              x_tf = reverse_f(x_np, [0]).eval()\n              np_answer = x_np[::-1, :, :]\n              self.assertAllEqual(x_tf, np_answer)\n\n  def testReverseInvalidShape(self):\n    x = np.ndarray(shape=[0, 1, 1])\n    v = array_ops.reverse_v2(x, axis=[1])\n    self.assertAllEqual(self.evaluate(v), v)\n\n\nclass MeshgridTest(test_util.TensorFlowTestCase):\n\n  def _compareDiff(self, x, y, use_gpu):\n    for index in (\"ij\", \"xy\"):\n      numpy_out = np.meshgrid(x, y, indexing=index)\n      tf_out = array_ops.meshgrid(x, y, indexing=index)\n      with self.cached_session(use_gpu=use_gpu):\n        for xx, yy in zip(numpy_out, tf_out):\n          self.assertAllEqual(xx, yy)\n\n  def _compareDiffType(self, n, np_dtype, use_gpu):\n    inputs = []\n    for index in (\"ij\", \"xy\"):\n      for _ in range(n):\n        x = np.linspace(-10, 10, 5).astype(np_dtype)\n        if np_dtype in (np.complex64, np.complex128):\n          x += 1j\n        inputs.append(x)\n      numpy_out = np.meshgrid(*inputs, indexing=index)\n      with self.cached_session(use_gpu=use_gpu):\n        tf_out = array_ops.meshgrid(*inputs, indexing=index)\n        for x_np, x_tf in zip(numpy_out, tf_out):\n          self.assertAllEqual(x_np, x_tf)\n\n  @test_util.run_deprecated_v1\n  def testCompare(self):\n    for t in (np.float16, np.float32, np.float64, np.int32, np.int64,\n              np.complex64, np.complex128):\n      with self.subTest(t=t):\n        self._compareDiffType(2, t, False)\n        self._compareDiffType(3, t, False)\n\n        x = [1, 2, 3]\n        y = [4, 5]\n\n        a = [[1, 1], [1, 1]]\n\n        self._compareDiff(x, y, False)\n        self._compareDiff(x, a, False)\n\n\nclass StridedSliceChecker(object):\n  \"\"\"Check a given tensor against the numpy result.\"\"\"\n\n  REF_TENSOR = np.arange(1, 19, dtype=np.float32).reshape(3, 2, 3)\n  REF_TENSOR_ALIGNED = np.arange(1, 97, dtype=np.float32).reshape(3, 4, 8)\n\n  def __init__(self, test, x, tensor_type=dtypes.int32, check_type_infer=True):\n    self.x_np = np.array(x).astype(tensor_type.as_numpy_dtype)\n    if tensor_type.is_bool:\n      self.x_np = np.array(x % 3).astype(np.bool)\n    # Give the value a non-zero imaginary component for complex types.\n    if tensor_type.is_complex:\n      self.x_np -= 1j * self.x_np\n    self.test = test\n    self.x = constant_op.constant(self.x_np, dtype=tensor_type)\n    self.check_type_infer = check_type_infer\n\n  def __getitem__(self, spec):\n    op = self.x.__getitem__(spec)\n\n    def eval_if_tensor(x):\n      try:\n        return x.eval()\n      except AttributeError:\n        return x\n\n    if isinstance(spec, bool) or \\\n      (isinstance(spec, ops.Tensor) and spec.dtype == dtypes.bool) or \\\n      (isinstance(spec, np.ndarray) and spec.dtype == bool) or \\\n      (isinstance(spec, (list, tuple)) and np.asarray(spec).dtype == bool):\n      tensor = op.eval()\n      np_spec = eval_if_tensor(spec)\n      self.test.assertAllEqual(self.x_np[np_spec], tensor)\n      return tensor\n\n    if not isinstance(spec, (list, tuple)):\n      spec = [spec]\n\n    tensor = op.eval()\n\n    # Make a numpy spec that pre-evals the tensors\n    np_specs = []\n\n    for s in spec:\n      if isinstance(s, slice):\n        start = eval_if_tensor(s.start)\n        stop = eval_if_tensor(s.stop)\n        step = eval_if_tensor(s.step)\n        np_specs.append(slice(start, stop, step))\n      else:\n        np_specs.append(eval_if_tensor(s))\n\n    self.test.assertAllEqual(self.x_np[tuple(np_specs)], tensor)\n    if self.check_type_infer:\n      self.test.assertAllEqual(tensor.shape, op.get_shape())\n    return tensor\n\n\nSTRIDED_SLICE_TYPES = [\n    dtypes.int32, dtypes.int64, dtypes.int16, dtypes.int8, dtypes.float32,\n    dtypes.float64, dtypes.complex64, dtypes.complex128, dtypes.bool\n]\n\n\nclass StridedSliceTest(test_util.TensorFlowTestCase):\n  \"\"\"Test the strided slice operation with variants of slices.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def test_basic_slice(self):\n    for tensor_type in STRIDED_SLICE_TYPES:\n      with self.subTest(tensor_type=tensor_type):\n        with self.cached_session(use_gpu=True):\n          checker = StridedSliceChecker(\n              self, StridedSliceChecker.REF_TENSOR, tensor_type=tensor_type)\n          _ = checker[:, :, :]\n          # Various ways of representing identity slice\n          _ = checker[:, :, :]\n          _ = checker[::, ::, ::]\n          _ = checker[::1, ::1, ::1]\n          # Not zero slice\n          _ = checker[::1, ::5, ::2]\n          # Reverse in each dimension independently\n          _ = checker[::-1, :, :]\n          _ = checker[:, ::-1, :]\n          _ = checker[:, :, ::-1]\n          ## negative index tests i.e. n-2 in first component\n          _ = checker[-2::-1, :, ::1]\n          # negative index tests i.e. n-2 in first component, non-unit stride\n          _ = checker[-2::-1, :, ::2]\n\n          # Check rank-0 examples\n          checker2 = StridedSliceChecker(self, 5, tensor_type=tensor_type)\n          _ = checker2[None]\n          _ = checker2[...]\n          _ = checker2[tuple()]\n\n  def testInt64GPU(self):\n    if not test_util.is_gpu_available():\n      self.skipTest(\"No GPU available\")\n\n    with test_util.force_gpu():\n      x = constant_op.constant([1., 2., 3.])\n      begin = constant_op.constant([2], dtype=dtypes.int64)\n      end = constant_op.constant([3], dtype=dtypes.int64)\n      strides = constant_op.constant([1], dtype=dtypes.int64)\n      s = array_ops.strided_slice(x, begin, end, strides)\n      self.assertAllEqual([3.], self.evaluate(s))\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.assert_no_garbage_created\n  def testTensorSliceEagerMemory(self):\n    with context.eager_mode():\n      inputs = constant_op.constant([[[1], [2], [3], [4]]],\n                                    dtype=dtypes.float32)\n      # Tests that slicing an EagerTensor doesn't leak memory\n      inputs[0]  # pylint: disable=pointless-statement\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.assert_no_garbage_created\n  def testVariableSliceEagerMemory(self):\n    with context.eager_mode():\n      v = variables.Variable([1., 2.])\n      v[0]  # pylint: disable=pointless-statement\n\n  @test_util.run_deprecated_v1\n  def testDegenerateSlices(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      # degenerate by offering a forward interval with a negative stride\n      _ = checker[0:-1:-1, :, :]\n      # degenerate with a reverse interval with a positive stride\n      _ = checker[-1:0, :, :]\n      # empty interval in every dimension\n      _ = checker[-1:0, 2:2, 2:3:-1]\n      # empty first dimension only (used to break for aligned tensors).\n      checker = StridedSliceChecker(self,\n                                    StridedSliceChecker.REF_TENSOR_ALIGNED)\n      _ = checker[1:0]\n\n  @test_util.run_deprecated_v1\n  def testSliceWithUndefinedDimension(self):\n    t = constant_op.constant([1, 2, 3])\n    d = tensor_shape.Dimension(None)\n    self.assertAllEqual(t[d:d:d], t)\n\n  @test_util.run_deprecated_v1\n  def testEllipsis(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2], [3, 4], [5, 6]]], [[[7, 8], [9, 10], [11, 12]]]]]\n      checker = StridedSliceChecker(self, raw)\n\n      _ = checker[0:]\n      # implicit ellipsis\n      _ = checker[0:, ...]\n      # ellipsis alone\n      _ = checker[...]\n      # ellipsis at end\n      _ = checker[0:1, ...]\n      # ellipsis at begin\n      _ = checker[..., 0:1]\n      # ellipsis at middle\n      _ = checker[0:1, ..., 0:1]\n      # multiple ellipses not allowed\n      with self.assertRaisesRegex(ValueError, \"Multiple ellipses\"):\n        _ = checker[..., :, ...].eval()\n\n  @test_util.run_deprecated_v1\n  def testShrink(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw)\n      _ = checker[:, :, :, :, 3]\n      _ = checker[..., 3]\n      _ = checker[:, 0]\n      _ = checker[:, :, 0]\n\n  @test_util.run_deprecated_v1\n  def testBothNewAxisAndShrink(self):\n    with self.session(use_gpu=True):\n      ones = array_ops.placeholder(shape=[2, 2], dtype=dtypes.int16)\n      self.assertAllEqual(\n          ones[array_ops.newaxis, :,\n               0].eval(feed_dict={ones: [[1, 1], [1, 1]]}), [[1, 1]])\n\n  @test_util.run_deprecated_v1\n  def testTensorIndexing(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw, check_type_infer=False)\n      bar = constant_op.constant(2)\n      bar2 = constant_op.constant(3)\n      _ = checker[..., bar:bar2]\n      _ = checker[..., bar]\n      _ = checker[..., 3]\n      _ = checker[..., 2**64 // 2**63]  # Test longs in Python 2\n\n  def testTensorIndexingTypeError(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      expected = re.escape(array_ops._SLICE_TYPE_ERROR)\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[\"foo\"]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant(\"foo\")]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[0.0]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant(0.0)]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[constant_op.constant([1, 2, 3])]\n      with self.assertRaisesRegex(TypeError, expected):\n        _ = checker[[2.1, -0.7, 1.5]]\n\n  @test_util.run_deprecated_v1\n  def testExpand(self):\n    with self.session(use_gpu=True):\n      raw = [[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n              [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]]]]]\n      checker = StridedSliceChecker(self, raw)\n      # new axis (followed by implicit ellipsis)\n      _ = checker[np.newaxis]\n      # newaxis after ellipsis\n      _ = checker[..., np.newaxis]\n      # newaxis in between ellipsis and explicit range\n      _ = checker[..., np.newaxis, :]\n      _ = checker[:, ..., np.newaxis, :, :]\n      # Reverse final dimension with new axis\n      _ = checker[:, :, np.newaxis, :, 2::-1]\n      # Ellipsis in middle of two newaxis\n      _ = checker[np.newaxis, ..., np.newaxis]\n\n  @test_util.run_deprecated_v1\n  def testExpandVariable(self):\n    with self.session(use_gpu=True):\n      x = variables.Variable(7, dtype=dtypes.int32)\n      self.evaluate(x.initializer)\n      y = x[None].eval()\n      self.assertEqual(y.shape, (1,))\n      self.assertAllEqual(y, (7,))\n\n  @test_util.run_deprecated_v1\n  def testOptimizedCases(self):\n    with self.session(use_gpu=True):\n      checker = StridedSliceChecker(self,\n                                    StridedSliceChecker.REF_TENSOR_ALIGNED)\n      # Identity\n      _ = checker[:]\n      # Identity\n      _ = checker[...]\n      # Identity\n      _ = checker[np.newaxis, ..., np.newaxis]\n      # First axis slice\n      _ = checker[1:]\n      # First axis slice\n      _ = checker[np.newaxis, 1:]\n\n  @test_util.run_v1_only(\"currently failing on v2\")\n  def testMasks(self):\n    with self.session(use_gpu=True):\n      scalar = np.array(0)\n      # Test tensor type mask\n      checker = StridedSliceChecker(self, StridedSliceChecker.REF_TENSOR)\n      _ = checker[checker.x > 2]\n      _ = checker[checker.x <= 5]\n      _ = checker[ops.convert_to_tensor(scalar)]\n\n      # Test numpy array type mask\n      raw = np.array([[[[[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]]],\n                       [[[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23,\n                                                              24]]]]])\n      checker1 = StridedSliceChecker(self, raw)\n      _ = checker1[raw >= 4]\n      _ = checker1[raw < 19]\n      _ = checker1[scalar]\n\n      # Test boolean and non boolean cases\n      mask = np.array([True, False, True])\n      raw1 = np.array([[1, 2, 4, 5], [5, 6, 7, 8], [9, 10, 11, 12]])\n      checker2 = StridedSliceChecker(self, raw1)\n      _ = checker2[mask]\n      _ = checker2[ops.convert_to_tensor(mask)]\n\n\nclass StridedSliceShapeChecker(object):\n\n  def __init__(self, x):\n    self.x = x\n\n  def __getitem__(self, spec):\n    op = self.x.__getitem__(spec)\n    return op.get_shape()\n\n\nclass StridedSliceShapeTest(test_util.TensorFlowTestCase):\n  \"\"\"Test the shape inference of StridedSliceShapes.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def testUnknown(self):\n    with self.session(use_gpu=True):\n      uncertain_tensor = array_ops.placeholder(dtypes.float32)\n      a = StridedSliceShapeChecker(uncertain_tensor)\n      a_slice_shape = a[...]\n      self.assertAllEqual(a_slice_shape.ndims, None)\n\n  def tensorShapeEqual(self, x, y):\n    self.assertTrue(x is not None and y is not None or x is None and y is None)\n    self.assertEqual(x.as_list(), y.as_list())\n\n  @test_util.run_deprecated_v1\n  def testTensorShapeUncertain(self):\n    with self.session(use_gpu=True):\n      uncertain_tensor = array_ops.placeholder(\n          dtypes.float32, shape=(5, None, 7))\n      a = StridedSliceShapeChecker(uncertain_tensor)\n      self.tensorShapeEqual(a[3:5], tensor_shape.TensorShape([2, None, 7]))\n      self.tensorShapeEqual(a[3:5, :, 4], tensor_shape.TensorShape([2, None]))\n      self.tensorShapeEqual(a[3:5, 3:4, 4], tensor_shape.TensorShape([2, None]))\n      self.tensorShapeEqual(a[3:5, :, 5:10],\n                            tensor_shape.TensorShape([2, None, 2]))\n      self.tensorShapeEqual(a[3:5, :, 50:3],\n                            tensor_shape.TensorShape([2, None, 0]))\n      self.tensorShapeEqual(a[3:5, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[1:5:2, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[:5:3, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([2, None, 1, 0]))\n      self.tensorShapeEqual(a[:2:3, :, array_ops.newaxis, 50:3,],\n                            tensor_shape.TensorShape([1, None, 1, 0]))\n      self.tensorShapeEqual(a[::-1, :, array_ops.newaxis, ::-2],\n                            tensor_shape.TensorShape([5, None, 1, 4]))\n\n  @test_util.run_deprecated_v1\n  def testTensorValuedIndexShape(self):\n    with self.session(use_gpu=True):\n      defined_shape_tensor = array_ops.placeholder(\n          dtypes.float32, shape=(5, 3, 7))\n      index_value = array_ops.placeholder(dtypes.int32, shape=())\n      a = StridedSliceShapeChecker(defined_shape_tensor)\n      self.tensorShapeEqual(a[index_value], tensor_shape.TensorShape([3, 7]))\n      self.tensorShapeEqual(a[index_value, ::-1],\n                            tensor_shape.TensorShape([3, 7]))\n      self.tensorShapeEqual(a[index_value, ::-2],\n                            tensor_shape.TensorShape([2, 7]))\n      other_scalar = array_ops.placeholder(dtypes.int32, shape=())\n      self.tensorShapeEqual(a[index_value, other_scalar:2],\n                            tensor_shape.TensorShape([None, 7]))\n\n\nclass GradSliceChecker(object):\n  \"\"\"Tests that we can compute a gradient for var^2.\"\"\"\n\n  def __init__(self, test, sess, var, varnp):\n    self.test = test\n    self.sess = sess\n    self.val = var * var\n    self.var = var\n    self.varnp = varnp\n\n  def __getitem__(self, spec):\n    slice_var = self.var[spec]\n    slice_val = self.val[spec]\n\n    # compute analytic 2nd derivative\n    analytic_grad2 = 2 * slice_val\n\n    dy = variables.Variable(\n        array_ops.ones_like(slice_var, dtype=dtypes.float32))\n    assign = dy.assign(slice_var)\n    slice_val_grad, = gradients_impl.gradients(slice_val, self.var, grad_ys=dy)\n    slice_val_grad2, = gradients_impl.gradients(\n        slice_val_grad, dy, grad_ys=self.var)\n    self.sess.run(assign)\n    slice_val_grad_evaled, slice_val_grad2_evaled = (\n        self.sess.run([slice_val_grad, slice_val_grad2]))\n    analytic_grad2_evaled = analytic_grad2.eval()\n    self.test.assertAllEqual(slice_val_grad2_evaled, analytic_grad2_evaled)\n\n    # compute analytic gradient for slice\n    np_val_grad = (2 * self.varnp * self.varnp)\n    np_sliceval_grad = np.zeros(self.var.get_shape())\n    if isinstance(spec, ops.Tensor):\n      spec = self.sess.run([spec])\n    np_sliceval_grad[spec] = np_val_grad[spec]\n    # verify gradient\n    self.test.assertAllEqual(slice_val_grad_evaled, np_sliceval_grad)\n\n\nclass StridedSliceGradTest(test_util.TensorFlowTestCase):\n  \"\"\"Test that strided slice's custom gradient produces correct gradients.\"\"\"\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testGradient(self):\n    with self.session(use_gpu=True) as sess:\n      var = variables.Variable(\n          array_ops.reshape(\n              math_ops.range(1, 97, 1, dtype=dtypes.float32), shape=(6, 4, 4)))\n      init = variables.global_variables_initializer()\n      sess.run(init)\n\n      raw = np.array(range(1, 97, 1)).reshape((6, 4, 4))\n      grad = GradSliceChecker(self, sess, var, raw)\n      _ = grad[2:6:2, 1:3, 1:3]\n      _ = grad[3:0:-2, 1:3, 1:3]\n      _ = grad[3:0:-2, array_ops.newaxis, 1:3, 2, array_ops.newaxis]\n      _ = grad[3:0:-2, 1:3, 2]\n      _ = grad[:, -1, :]\n      _ = grad[:, -2, :]\n      with self.assertRaisesRegex(ValueError, \"out of bounds\"):\n        _ = grad[:, -200, :]\n      with self.assertRaisesRegex(ValueError, \"out of bounds\"):\n        _ = grad[:, 200, :]\n\n      # Test numpy array type mask\n      _ = grad[raw > 51]\n      # Test tensor type mask\n      _ = grad[ops.convert_to_tensor(raw) <= 76]\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testGradientZero(self):\n    with self.session(use_gpu=True) as sess:\n      var = variables.Variable(8.)\n      init = variables.global_variables_initializer()\n      sess.run(init)\n      grad = GradSliceChecker(self, sess, var, np.array(8))\n      _ = grad[tuple()]\n\n  @test_util.run_deprecated_v1\n  def testInt64Indices(self):\n    with self.session(use_gpu=True) as sess:\n      a = math_ops.range(3, dtype=dtypes.float32)\n      index = constant_op.constant(1, dtype=dtypes.int64)\n      b = 2. * a[index]\n      grad, = gradients_impl.gradients(b, a)\n      self.assertAllEqual(self.evaluate(grad), [0., 2., 0.])\n\n\nclass StridedSliceGradTypeTest(test_util.TensorFlowTestCase):\n  \"\"\"Test varied index types and host located memory.\"\"\"\n\n  @test_util.run_deprecated_v1\n  def testHostVsDevice(self):\n    with self.session(use_gpu=True) as sess:\n      var2 = variables.Variable(\n          array_ops.reshape(\n              math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n              shape=(4, 1, 1)))\n      varshape = variables.Variable([6, 4, 4], dtype=dtypes.int32)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0])\n      end = constant_op.constant([4, 1, 1])\n      strides = constant_op.constant([1, 1, 1])\n      foo = array_ops.strided_slice_grad(varshape, begin, end, strides, var2)\n      sess.run(foo)\n\n  @test_util.run_deprecated_v1\n  def testInt64Shape(self):\n    with self.session(use_gpu=True) as sess:\n      original_dy = array_ops.reshape(\n          math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n          shape=(4, 1, 1))\n      original_shape = constant_op.constant([6, 4, 4], dtype=dtypes.int64)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0], dtype=dtypes.int64)\n      end = constant_op.constant([4, 1, 1], dtype=dtypes.int64)\n      strides = constant_op.constant([1, 1, 1], dtype=dtypes.int64)\n      dx = array_ops.strided_slice_grad(original_shape, begin, end, strides,\n                                        original_dy)\n      sess.run(dx)\n\n  @test_util.run_deprecated_v1\n  def testMixedIndexTypes(self):\n    with self.session(use_gpu=True) as sess:\n      original_dy = array_ops.reshape(\n          math_ops.cast(math_ops.range(1, 5, 1), dtypes.float32),\n          shape=(4, 1, 1))\n      original_shape = constant_op.constant([6, 4, 4], dtype=dtypes.int64)\n      self.evaluate(variables.global_variables_initializer())\n      begin = constant_op.constant([0, 0, 0], dtype=dtypes.int32)\n      end = constant_op.constant([4, 1, 1], dtype=dtypes.int64)\n      strides = constant_op.constant([1, 1, 1], dtype=dtypes.int64)\n      with self.assertRaisesRegex(\n          TypeError, \"Input 'begin' of 'StridedSliceGrad' Op has type int32\"\n          \" that does not match type int64 of argument 'shape'\"):\n        dx = array_ops.strided_slice_grad(original_shape, begin, end, strides,\n                                          original_dy)\n        sess.run(dx)\n\n\nclass BenchmarkSlice(object):\n\n  def __init__(self, tensor):\n    self.tensor = tensor\n\n  def __getitem__(self, x):\n    return self.tensor[x]\n\n\nclass StridedSliceBenchmark(test_lib.Benchmark):\n  \"\"\"Benchmark new strided slice operation on non-trivial case.\"\"\"\n\n  def run_and_time(self, slice_op):\n    self.evaluate(variables.global_variables_initializer())\n    for _ in range(10):\n      _ = self.evaluate(slice_op)\n    iters = 1000\n    t0 = time.time()\n    for _ in range(iters):\n      self.evaluate(slice_op)\n    t1 = time.time()\n    self.report_benchmark(iters=iters, wall_time=(t1 - t0) / 1000.0)\n\n  def make_variable(self):\n    n = 256\n    shape = (n, n, n)\n    items = n**3\n    var = variables.Variable(\n        array_ops.reshape(math_ops.linspace(1., float(items), items), shape),\n        dtype=dtypes.float32)\n    return var\n\n  def benchmark_strided_slice_skip(self):\n    with session.Session():\n      var = self.make_variable()\n      helper = BenchmarkSlice(var)\n      slice_op = helper[::2, ::1, ::2]\n      self.run_and_time(slice_op)\n\n  def benchmark_strided_slice_easy(self):\n    with session.Session():\n      var = self.make_variable()\n      helper = BenchmarkSlice(var)\n      slice_op = helper[3::1, 3::1, 3::1]\n      self.run_and_time(slice_op)\n\n  def benchmark_slice_easy(self):\n    with session.Session():\n      var = self.make_variable()\n      slice_op = var[3::1, 3::1, 3::1]\n      self.run_and_time(slice_op)\n\n\nclass StridedSliceAssignChecker(object):\n\n  def __init__(self, test, x, tensor_type=dtypes.float32, use_resource=False):\n    self.tensor_type = tensor_type\n    self.test = test\n    self._use_resource = use_resource\n\n    self.x_np = np.array(x).astype(tensor_type.as_numpy_dtype)\n    # Give the value a non-zero imaginary component for complex types.\n    if tensor_type.is_complex:\n      self.x_np -= 1j * self.x_np\n    self.x = constant_op.constant(self.x_np, dtype=tensor_type)\n\n  def __setitem__(self, index, value):\n    value = np.array(value).astype(self.tensor_type.as_numpy_dtype)\n    # Give the value a non-zero imaginary component for complex types.\n    if self.tensor_type.is_complex:\n      value -= 1j * value\n\n    with self.test.test_session(use_gpu=True) as sess:\n      if self._use_resource:\n        var = resource_variable_ops.ResourceVariable(self.x)\n      else:\n        var = variables.Variable(self.x)\n      sess.run(variables.variables_initializer([var]))\n      val = sess.run(var[index].assign(value))\n      # val_copy is used to check that tf.compat.v1.assign works equivalently\n      # to the assign method above.\n      val_copy = sess.run(state_ops.assign(var[index], value))\n      valnp = np.copy(self.x_np)\n      valnp[index] = np.array(value)\n      self.test.assertAllEqual(val, valnp)\n      self.test.assertAllEqual(val_copy, valnp)\n\n\nclass SliceAssignTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvalidSlice(self):\n    with self.cached_session() as sess:\n      foo = constant_op.constant([1, 2, 3])\n      with self.assertRaisesRegex(\n          ValueError, \"Sliced assignment\"\n          \" is only supported for variables\"):\n        bar = foo[:2].assign(constant_op.constant([1, 2]))\n        sess.run(bar)\n\n  def doTestSliceAssign(self, use_resource):\n    for dtype in STRIDED_SLICE_TYPES:\n      with self.subTest(dtype=dtype):\n        checker = StridedSliceAssignChecker(\n            self, [[1, 2, 3], [4, 5, 6]],\n            use_resource=use_resource,\n            tensor_type=dtype)\n        # Check if equal\n        checker[:] = [[10, 20, 30], [40, 50, 60]]\n        # Check trivial (1,1) shape tensor\n        checker[1:2, 1:2] = [[66]]\n        # shrinks shape changes\n        checker[1:2, 1] = [66]\n        checker[1, 1:2] = [66]\n        checker[1, 1] = 66\n        # newaxis shape changes\n        checker[:, None, :] = [[[10, 20, 30]], [[40, 50, 50]]]\n        # shrink and newaxis\n        checker[None, None, 0, 0:1] = [[[99]]]\n        # Non unit strides\n        checker[::1, ::-2] = [[3, 33], [4, 44]]\n        # degenerate interval\n        checker[8:10, 0] = []\n        checker[8:10, 8:10] = [[]]\n    # Assign vector to scalar (rank-0) using newaxis\n    checker2 = StridedSliceAssignChecker(self, 222)\n    checker2[()] = 6  # no indices\n    checker2[...] = 6  # ellipsis\n    checker2[None] = [6]  # new axis\n\n  @test_util.run_deprecated_v1\n  @test_util.disable_xla(\"b/123559667\")\n  def testSliceAssign(self):\n    self.doTestSliceAssign(use_resource=False)\n\n  @test_util.run_deprecated_v1\n  @test_util.disable_xla(\"b/123559667\")\n  def testSliceAssignResource(self):\n    self.doTestSliceAssign(use_resource=True)\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testUninitialized(self):\n    with self.assertRaisesRegex(\n        errors.FailedPreconditionError,\n        \"Attempting to use uninitialized value Variable\"):\n      with self.cached_session() as sess:\n        v = variables.VariableV1([1, 2])\n        sess.run(v[:].assign([1, 2]))\n\n  @test_util.run_v1_only(\"b/120545219\")\n  def testTypeError(self):\n    init_val = constant_op.constant([1, 2], dtype=dtypes.int32)\n    too_small_val = constant_op.constant([3, 4], dtype=dtypes.int8)\n    too_large_val = constant_op.constant([3, 4], dtype=dtypes.int64)\n    v = variables.VariableV1(init_val)\n    with self.assertRaises(TypeError):\n      v[:].assign(too_small_val)\n    with self.assertRaises(TypeError):\n      v[:].assign(too_large_val)\n\n  @test_util.run_deprecated_v1\n  def testTypeErrorResource(self):\n    init_val = constant_op.constant([1, 2], dtype=dtypes.int32)\n    too_small_val = constant_op.constant([3, 4], dtype=dtypes.int8)\n    too_large_val = constant_op.constant([3, 4], dtype=dtypes.int64)\n    v = resource_variable_ops.ResourceVariable(init_val)\n    with self.cached_session() as sess:\n      self.evaluate(v.initializer)\n      with self.assertRaises(ValueError):\n        sess.run(v[:].assign(too_large_val))\n      with self.assertRaises(ValueError):\n        sess.run(v[:].assign(too_small_val))\n\n  @test_util.disable_xla(\"b/123559667\")\n  @test_util.run_in_graph_and_eager_modes\n  def testTensorStridedSliceUpdateWithInputForward(self):\n    \"\"\"Tests tensor_strided_slice_update with input-forwarding taking effect.\"\"\"\n    @def_function.function\n    def assign(x):\n      y = x + 1\n      return gen_array_ops.tensor_strided_slice_update(y, [0], [1], [1], [0])\n    self.assertAllEqual([0, 1], self.evaluate(assign(array_ops.zeros([2]))))\n\n  @test_util.disable_xla(\"b/123559667\")\n  @test_util.run_in_graph_and_eager_modes\n  def testTensorStridedSliceUpdateNoInputForward(self):\n    \"\"\"Tests tensor_strided_slice_update with no input-forwarding.\"\"\"\n    x = constant_op.constant([0.2, 0.3])\n    y = x + 1\n    # y's buffer won't be forwarded to z because y and z will be alive at the\n    # same time later.\n    z = gen_array_ops.tensor_strided_slice_update(y, [0], [1], [1], [0.4])\n    ans = y + z\n    self.assertAllClose([1.6, 2.6], self.evaluate(ans))\n\n  @test_util.disable_xla(\"b/123559667\")\n  def testTensorStridedSliceUpdateGradSimple(self):\n    original = constant_op.constant([0.2, 0.3])\n    updates = constant_op.constant([0.4])\n    with backprop.GradientTape() as tape:\n      tape.watch([original, updates])\n      updated = gen_array_ops.tensor_strided_slice_update(\n          original, [0], [1], [1], updates)\n    d1, d2 = tape.gradient(updated, [original, updates],\n                           output_gradients=constant_op.constant([2.0, 3.0]))\n    self.assertAllClose([0.0, 3.0], d1)\n    self.assertAllClose([2.0], d2)\n\n  @parameterized.named_parameters(\n      (\"_%s\" % i, *args) for i, args in enumerate([  # pylint:disable=g-complex-comprehension\n          ([2, 5], [0, 1], [1, 0], [1, 2], [2], 0, 2, 0, 0, 1),\n          ([4], [5], [3], [1], [3], 1, 0, 0, 0, 0),\n          ([2, 2, 3, 2], [0, 0, 1], [1, 0, 2], [1, 0, 1], [2, 3], 0, 0, 2, 0, 5)\n      ]))\n  @test_util.disable_xla(\"b/123559667\")\n  def testTensorStridedSliceUpdateGrad(\n      self, shape, begin, end, strides, updates_shape, *args):\n    with self.cached_session():\n      def f(a, b):\n        return gen_array_ops.tensor_strided_slice_update(\n            a, begin, end, strides, b, *args)\n      theoretical, numerical = gradient_checker_v2.compute_gradient(\n          f, [array_ops.zeros(shape), array_ops.ones(updates_shape)], delta=1.0)\n      self.assertAllClose(theoretical, numerical)\n\n\nclass ShapeSizeRankTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def testDenseShape(self):\n    t_value = [[0, 42], [24, 0]]\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(t_value)))\n    self.assertEqual(4, self.evaluate(array_ops.size(t_value)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(t_value)))\n\n    t = constant_op.constant(t_value)\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(t)))\n    self.assertEqual(4, self.evaluate(array_ops.size(t)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(t)))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSparseShape(self):\n    sp_value = sparse_tensor.SparseTensorValue(\n        indices=((0, 1), (1, 0)), values=(42, 24), dense_shape=(2, 2))\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(sp_value)))\n    self.assertEqual(4, self.evaluate(array_ops.size(sp_value)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(sp_value)))\n\n    sp = sparse_tensor.SparseTensor.from_value(sp_value)\n    self.assertAllEqual((2, 2), self.evaluate(array_ops.shape(sp)))\n    self.assertEqual(4, self.evaluate(array_ops.size(sp)))\n    self.assertEqual(2, self.evaluate(array_ops.rank(sp)))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSizeDtype(self):\n    tensor = [1]\n    self.assertEqual(dtypes.int32, self.evaluate(array_ops.size(tensor)).dtype)\n    self.assertEqual(\n        dtypes.int64,\n        self.evaluate(array_ops.size(tensor, out_type=dtypes.int64)).dtype)\n\n\nclass SequenceMaskTest(test_util.TensorFlowTestCase):\n\n  def testExceptions(self):\n    with self.cached_session():\n      with self.assertRaisesRegex(ValueError, \"maxlen must be scalar\"):\n        array_ops.sequence_mask([10, 20], [10, 20])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalWithMaxlen(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([1, 3, 2]), 5)\n      self.assertAllEqual(res.get_shape(), [3, 5])\n      self.assertAllEqual(\n          res,\n          [[True, False, False, False, False], [True, True, True, False, False],\n           [True, True, False, False, False]])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalDtypeWithoutMaxlen(self):\n    with self.cached_session():\n      # test dtype and default maxlen:\n      res = array_ops.sequence_mask(\n          constant_op.constant([0, 1, 4]), dtype=dtypes.float32)\n      self.assertAllEqual(res.get_shape().as_list(), [3, 4])\n      self.assertAllEqual(\n          res,\n          [[0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0]])\n\n  @test_util.run_deprecated_v1\n  def testOneDimensionalWithoutMaxlen(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([0, 1, 4]))\n      self.assertAllEqual(res.get_shape().as_list(), [3, 4])\n      self.assertAllEqual(\n          res, [[False, False, False, False], [True, False, False, False],\n                [True, True, True, True]])\n\n  @test_util.run_deprecated_v1\n  def testTwoDimensional(self):\n    with self.cached_session():\n      res = array_ops.sequence_mask(constant_op.constant([[1, 3, 2]]), 5)\n      self.assertAllEqual(res.get_shape(), [1, 3, 5])\n      self.assertAllEqual(res, [[[True, False, False, False, False],\n                                 [True, True, True, False, False],\n                                 [True, True, False, False, False]]])\n\n      # test dtype and default maxlen:\n      res = array_ops.sequence_mask(\n          constant_op.constant([[0, 1, 4], [1, 2, 3]]), dtype=dtypes.float32)\n      self.assertAllEqual(res.get_shape().as_list(), [2, 3, 4])\n      self.assertAllEqual(\n          res,\n          [[[0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0]],\n           [[1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0]]])\n\n  @test_util.run_deprecated_v1\n  def testUnknownShape(self):\n    lengths = array_ops.placeholder(dtype=dtypes.int32)\n    res = array_ops.sequence_mask(lengths)\n    self.assertEqual(res.shape, None)\n\n  @test_util.run_deprecated_v1\n  def testDtypes(self):\n\n    def check_dtypes(lengths_dtype, maxlen_dtype):\n      res = array_ops.sequence_mask(\n          constant_op.constant([1, 3, 2], dtype=lengths_dtype),\n          constant_op.constant(5, dtype=maxlen_dtype))\n      self.assertAllEqual(res.get_shape(), [3, 5])\n      self.assertAllEqual(\n          res,\n          [[True, False, False, False, False], [True, True, True, False, False],\n           [True, True, False, False, False]])\n\n    with self.cached_session():\n      check_dtypes(dtypes.int32, dtypes.int32)\n      check_dtypes(dtypes.int32, dtypes.int64)\n      check_dtypes(dtypes.int64, dtypes.int32)\n      check_dtypes(dtypes.int64, dtypes.int64)\n\n  def testOutputDtype(self):\n\n    def check_output_dtype(output_dtype):\n      res = self.evaluate(\n          array_ops.sequence_mask(\n              constant_op.constant([1, 3, 2], dtype=dtypes.int32),\n              constant_op.constant(5, dtype=dtypes.int32),\n              dtype=output_dtype))\n      self.assertAllEqual(\n          res,\n          self.evaluate(\n              math_ops.cast([[True, False, False, False, False],\n                             [True, True, True, False, False],\n                             [True, True, False, False, False]], output_dtype)))\n\n    check_output_dtype(dtypes.bool)\n    check_output_dtype(\"bool\")\n    check_output_dtype(np.bool)\n    check_output_dtype(dtypes.int32)\n    check_output_dtype(\"int32\")\n    check_output_dtype(np.int32)\n    check_output_dtype(dtypes.float32)\n    check_output_dtype(\"float32\")\n    check_output_dtype(np.float32)\n    check_output_dtype(dtypes.int64)\n    check_output_dtype(\"float64\")\n    check_output_dtype(np.float64)\n\n\nclass ConcatSliceResourceTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  @test_util.run_deprecated_v1\n  def testConcatSlice(self):\n    r1 = test_ops.stub_resource_handle_op(container=\"a\", shared_name=\"b\")\n    r2 = test_ops.stub_resource_handle_op(container=\"a\", shared_name=\"c\")\n    c = array_ops.stack([r1, r2])\n    s = array_ops.strided_slice(c, [1], [2])\n    self.evaluate(test_ops.resource_create_op(s))\n    with self.assertRaises(errors.AlreadyExistsError):\n      self.evaluate(test_ops.resource_create_op(r2))\n\n\nclass IdentityTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_gpu_only\n  def testEagerIdentity(self):\n    with context.eager_mode():\n\n      def _test(x, y, device):\n        self.assertAllEqual(x.numpy(), y.numpy())\n        self.assertTrue(device in y.device.lower())\n\n      with test_util.force_gpu():\n        a = constant_op.constant([[2], [3]], dtype=dtypes.float32)\n      with test_util.force_gpu():\n        b = array_ops.identity(a)\n        _test(a, b, \"gpu\")\n      with test_util.force_cpu():\n        c = array_ops.identity(b)\n        _test(b, c, \"cpu\")\n      with test_util.force_cpu():\n        d = array_ops.identity(c)\n        _test(c, d, \"cpu\")\n      with test_util.force_gpu():\n        e = array_ops.identity(d)\n        _test(d, e, \"gpu\")\n\n\nclass PadTest(test_util.TensorFlowTestCase):\n\n  def testEager(self):\n    with context.eager_mode():\n      t = constant_op.constant([[1, 2, 3], [4, 5, 6]])\n      paddings = constant_op.constant([[\n          1,\n          1,\n      ], [2, 2]])\n      padded = array_ops.pad(t, paddings, \"CONSTANT\")\n      self.assertAllEqual(padded.numpy(),\n                          [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0],\n                           [0, 0, 4, 5, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n\n\nclass InvertPermutationTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvertPermutation(self):\n    for dtype in [dtypes.int32, dtypes.int64]:\n      with self.subTest(dtype=dtype):\n        with self.cached_session(use_gpu=True):\n          x = constant_op.constant([3, 4, 0, 2, 1], dtype=dtype)\n          y = array_ops.invert_permutation(x)\n          self.assertAllEqual(y.get_shape(), [5])\n          self.assertAllEqual(y, [2, 4, 3, 0, 1])\n\n\nclass UnravelIndexTest(test_util.TensorFlowTestCase):\n\n  # TODO(b/73086570): Reenable test.\n  @unittest.skip(\"Test does not pass internally.\")\n  def testUnravelIndex(self):\n    with self.cached_session():\n      for dtype in [dtypes.int32, dtypes.int64]:\n        with self.subTest(dtype=dtype):\n          indices_1 = constant_op.constant(1621, dtype=dtype)\n          dims_1 = constant_op.constant([6, 7, 8, 9], dtype=dtype)\n          out_1 = array_ops.unravel_index(indices_1, dims_1)\n          self.assertAllEqual(out_1, [3, 1, 4, 1])\n\n          indices_2 = constant_op.constant([1621], dtype=dtype)\n          dims_2 = constant_op.constant([6, 7, 8, 9], dtype=dtype)\n          out_2 = array_ops.unravel_index(indices_2, dims_2)\n          self.assertAllEqual(out_2, [[3], [1], [4], [1]])\n\n          indices_3 = constant_op.constant([22, 41, 37], dtype=dtype)\n          dims_3 = constant_op.constant([7, 6], dtype=dtype)\n          out_3 = array_ops.unravel_index(indices_3, dims_3)\n          self.assertAllEqual(out_3, [[3, 6, 6], [4, 5, 1]])\n\n  # Test case for GitHub issue 40204.\n  def testUnravelIndexZeroDim(self):\n    with self.cached_session():\n      for dtype in [dtypes.int32, dtypes.int64]:\n        with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                    \"index is out of bound as with dims\"):\n          indices = constant_op.constant([2, 5, 7], dtype=dtype)\n          dims = constant_op.constant([3, 0], dtype=dtype)\n          self.evaluate(array_ops.unravel_index(indices=indices, dims=dims))\n\n\nclass GuaranteeConstOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testSimple(self):\n    with self.cached_session():\n      a = array_ops.constant(10)\n      guarantee_a = array_ops.guarantee_const(a)\n      self.assertEqual(10, self.evaluate(guarantee_a))\n\n  @test_util.run_deprecated_v1\n  def testVariables(self):\n    with self.cached_session() as sess:\n      for use_resource in [False, True]:\n        with self.subTest(use_resource=use_resource):\n          a = variable_scope.get_variable(\n              \"var_{}\".format(use_resource), [],\n              initializer=init_ops.constant_initializer(10.0),\n              use_resource=use_resource)\n          guarantee_a = array_ops.guarantee_const(a)\n          self.evaluate(variables.global_variables_initializer())\n          self.assertEqual(10.0, self.evaluate(guarantee_a))\n\n  @test_util.run_deprecated_v1\n  def testResourceRejection(self):\n    with self.cached_session() as sess:\n      a = variable_scope.get_variable(\n          \"resource_var\", [],\n          initializer=init_ops.constant_initializer(10.0),\n          use_resource=True)\n      guarantee_a = array_ops.guarantee_const(a.handle)\n      self.evaluate(variables.global_variables_initializer())\n      with self.assertRaisesWithPredicateMatch(errors.InvalidArgumentError,\n                                               \"cannot be a resource variable\"):\n        self.evaluate(guarantee_a)\n\n\nclass SnapshotOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testInvertPermutation(self):\n    for dtype in [dtypes.int32, dtypes.int64, dtypes.float32, dtypes.float64]:\n      with self.subTest(dtype=dtype):\n        with self.cached_session(use_gpu=True):\n          x = constant_op.constant([0, 1, 2, 3], dtype=dtype)\n          y = gen_array_ops.snapshot(x)\n          self.assertAllEqual(y, [0, 1, 2, 3])\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass QuantizeAndDequantizeTest(test_util.TensorFlowTestCase):\n\n  # Generates a tensor of the specified `shape` using values from `values`\n  # scaled by (slice_idx + 1) along `axis` dimension.\n  def _scale_per_slice(self, shape, axis, values):\n    # Note: repeats the values if the shape is larger than values.\n    out = np.take(values, np.remainder(np.arange(np.prod(shape)),\n                                       len(values))).reshape(shape)\n    if axis is not None:\n      scale_shape = [1] * len(shape)\n      scale_shape[axis] = shape[axis]\n      out *= np.arange(1, shape[axis] + 1).reshape(scale_shape)\n    return out\n\n  def testAxis(self):\n    shape = np.array([2, 3, 4, 5])\n    values = np.array([-1, -0.5, 0, 0.3, 0.8, 0.555, 0.5], dtype=np.float32)\n    quant_values = np.array(\n        [-1, -0.5, 0, 38.0 / 128, 102.0 / 128, 71.0 / 128, 0.5],\n        dtype=np.float32)\n    for axis in [None, 0, 1, 2, 3]:\n      with self.subTest(axis=axis):\n        inputs = constant_op.constant(\n            self._scale_per_slice(shape, axis, values))\n        expected = self._scale_per_slice(shape, axis, quant_values)\n        unused_minmax_value = 0 if axis is None else [0] * shape[axis]\n        fake_quantized = self.evaluate(\n            array_ops.quantize_and_dequantize_v2(\n                inputs,\n                unused_minmax_value,\n                unused_minmax_value,\n                range_given=False,\n                round_mode=\"HALF_UP\",\n                axis=axis))\n        self.assertAllEqual(fake_quantized, expected)\n        if axis is not None:\n          fake_quantized = self.evaluate(\n              array_ops.quantize_and_dequantize_v2(\n                  inputs,\n                  unused_minmax_value,\n                  unused_minmax_value,\n                  range_given=False,\n                  axis=(axis - 4)))\n          self.assertAllClose(fake_quantized, expected)\n\n  def testBadAxis(self):\n    input_tensor = [2.5, 2.5]\n    input_min = [0, 0]\n    input_max = [1, 1]\n    error_message_pattern = \"Shape must be at least rank 11 but is rank 1\"\n    # TODO(b/171260356): Eager mode and graph mode throw different error types\n    error = errors.InvalidArgumentError if context.executing_eagerly(\n    ) else ValueError\n    with self.assertRaisesRegex(error, error_message_pattern):\n      self.evaluate(\n          array_ops.quantize_and_dequantize_v2(\n              input=input_tensor,\n              input_min=input_min,\n              input_max=input_max,\n              axis=10))\n\n  def testQuantizeDequantizeGrad(self):\n    shape = (2, 2)\n    max_threshold = 0\n    min_threshold = -10\n    input_value = np.random.rand(2, 2) * 40.0 - 20.0\n    input_tensor = constant_op.constant(input_value, shape=shape,\n                                        name=\"input_tensor\")\n    with self.cached_session():\n      def f(a):\n        return array_ops.quantize_and_dequantize_v2(\n            a,\n            input_min=min_threshold,\n            input_max=max_threshold,\n            range_given=True)\n      output_grad = gradient_checker_v2.compute_gradient(f, [input_tensor])\n      self.assertAllClose(output_grad[0], np.zeros([1, 4, 4]))\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass SortedSearchTest(test_util.TensorFlowTestCase):\n\n  def testUpperBoundFloatHandCoded(self):\n    cdf = np.array([0, .2, .5, .6, .8, 1.], dtype=np.float32)\n    arr = np.array([.04, .99, .53, .58, .31, .01, .79, .8, .21],\n                   dtype=np.float32)\n    result = np.searchsorted(cdf, arr, side=\"right\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundFloatRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.uniform(size=shape).astype(np.float32), axis=(d - 1))\n      arr = np.random.uniform(size=shape).astype(np.float32) * dim_size\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundFloatUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.uniform(size=[batch_size, size_search_array]).astype(\n            np.float32),\n        axis=1)\n    arr = np.random.uniform(size=[batch_size, size_values]).astype(\n        np.float32) * size_search_array\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatHandCoded(self):\n    cdf = np.array([0, .2, .5, .6, .8, 1.], dtype=np.float32)\n    arr = np.array([.04, .99, .53, .58, .31, .01, .79, .8, .21],\n                   dtype=np.float32)\n    result = np.searchsorted(cdf, arr, side=\"left\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.uniform(size=shape).astype(np.float32), axis=(d - 1))\n      arr = np.random.uniform(size=shape).astype(np.float32) * dim_size\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundFloatUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.uniform(size=[batch_size, size_search_array]).astype(\n            np.float32),\n        axis=1)\n    arr = np.random.uniform(size=[batch_size, size_values]).astype(\n        np.float32) * size_search_array\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntHandCoded(self):\n    cdf = np.array([0, 20, 50, 60, 80, 100], dtype=np.int64)\n    arr = np.array([4, 99, 53, 58, 31, 1, 79, 8, 21], dtype=np.int64)\n    result = np.searchsorted(cdf, arr, side=\"right\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.randint(low=0, high=10, size=shape).astype(np.int64),\n          axis=(d - 1))\n      arr = np.random.randint(\n          low=0, high=10 * dim_size, size=shape).astype(np.int64)\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testUpperBoundIntUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.randint(low=0, high=10,\n                          size=[batch_size,\n                                size_search_array]).astype(np.int64),\n        axis=1)\n    arr = np.random.randint(\n        low=0, high=10 * size_search_array, size=[batch_size,\n                                                  size_values]).astype(np.int64)\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"right\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"right\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntHandCoded(self):\n    cdf = np.array([0, 20, 50, 60, 80, 100], dtype=np.int64)\n    arr = np.array([4, 99, 53, 58, 31, 1, 79, 8, 21], dtype=np.int64)\n    result = np.searchsorted(cdf, arr, side=\"left\")\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n    self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntRandomNd(self):\n    dim_size = 7\n    for d in range(1, 5):\n      shape = [dim_size] * d\n      cdf = np.cumsum(\n          np.random.randint(low=0, high=10, size=shape).astype(np.int64),\n          axis=(d - 1))\n      arr = np.random.randint(\n          low=0, high=10 * dim_size, size=shape).astype(np.int64)\n\n      tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n      cdf = cdf.reshape([-1, dim_size])\n      arr = arr.reshape([-1, dim_size])\n      result = np.zeros(arr.shape, dtype=np.int32)\n      for i in range(dim_size**(d - 1)):\n        result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n      result = result.reshape(shape)\n\n      self.assertAllEqual(result, tf_result)\n\n  def testLowerBoundIntUneven(self):\n    batch_size = 7\n    size_search_array = 1000\n    size_values = 47\n    cdf = np.cumsum(\n        np.random.randint(low=0, high=10,\n                          size=[batch_size,\n                                size_search_array]).astype(np.int64),\n        axis=1)\n    arr = np.random.randint(\n        low=0, high=10 * size_search_array, size=[batch_size,\n                                                  size_values]).astype(np.int64)\n\n    tf_result = self.evaluate(array_ops.searchsorted(cdf, arr, side=\"left\"))\n\n    result = np.zeros(arr.shape, dtype=np.int32)\n    for i in range(batch_size):\n      result[i, :] = np.searchsorted(cdf[i, :], arr[i, :], side=\"left\")\n\n    self.assertAllEqual(result, tf_result)\n\n  def testZeroSequenceSize(self):\n    dtype = dtypes.int32\n    for side in (\"left\", \"right\"):\n      with self.subTest(side=side):\n        self.assertAllEqual(\n            array_ops.searchsorted(\n                array_ops.ones([2, 0]),\n                array_ops.ones([2, 3]),\n                side=side,\n                out_type=dtype), array_ops.zeros([2, 3], dtype))\n\n  def testZeroValueSize(self):\n    dtype = dtypes.int32\n    for side in (\"left\", \"right\"):\n      with self.subTest(side=side):\n        self.assertAllEqual(\n            array_ops.searchsorted(\n                array_ops.ones([2, 3]),\n                array_ops.ones([2, 0]),\n                side=side,\n                out_type=dtype), array_ops.zeros([2, 0], dtype))\n\n\nclass BatchGatherNdTest(test_util.TensorFlowTestCase):\n\n  def testShapesMatch(self):\n    \"\"\"Tests for various different shape combinations.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 2), (2, 3), 0),)\n    shapes.append(((2, 2, 2), (3,), 0),)\n    shapes.append(((2, 2, 2), (1,), 0),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(1.0, shape=(params_shape))\n        indices = constant_op.constant(\n            1, shape=(indices_shape), dtype=dtypes.int32)\n        out = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n        ndims_params = len(params_shape) - batch_dims\n        ndims_rows = ndims_params - indices_shape[-1]\n        expected_out_shape = indices_shape[:-1]\n        if ndims_rows > 0:\n          expected_out_shape += params_shape[-ndims_rows:]\n        self.assertSequenceEqual(out.shape, expected_out_shape)\n\n  def testReducesToGatherNDWhenBatchDimIsZero(self):\n    \"\"\"Confirms setting batch_dims to zero reduces to tf.gather_nd.\"\"\"\n    params = constant_op.constant(np.random.uniform(0.0, 1.0, size=(7, 8, 9)))\n    indices_shapes = []\n    indices_shapes.append((1,))\n    indices_shapes.append((3, 1))\n    indices_shapes.append((3, 3, 1))\n    indices_shapes.append((2,))\n    indices_shapes.append((3, 2))\n    indices_shapes.append((3, 3, 2))\n    indices_shapes.append((3,))\n    indices_shapes.append((3, 3))\n    indices_shapes.append((3, 3, 3))\n\n    for indices_shape in indices_shapes:\n      with self.subTest(indices_shape=indices_shape):\n        indices = np.random.randint(0, 7, size=indices_shape)\n        gather_nd_result = gen_array_ops.gather_nd(params, indices)\n        batch_gather_nd_result = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=0)\n        self.assertAllEqual(gather_nd_result, batch_gather_nd_result)\n\n  def testSameResultAsMapFn(self):\n    \"\"\"Compares results with gather_nd called on every element with map_fn.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(\n            np.random.uniform(0.0, 1.0, size=(params_shape)))\n        indices = np.random.randint(0, 2, size=indices_shape)\n        batch_gather_nd_result = array_ops.batch_gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n\n        if batch_dims > 1:\n          params = array_ops.reshape(\n              params, shape=[-1] + list(params_shape[batch_dims:]))\n          indices = array_ops.reshape(\n              indices, shape=[-1] + list(indices_shape[batch_dims:]))\n\n        map_fn_gather_nd_result = map_fn.map_fn(\n            fn=self._map_fn_body, elems=(params, indices), dtype=dtypes.float64)\n\n        if batch_dims > 1:\n          out_shape = map_fn_gather_nd_result.shape.as_list()\n          out_shape = list(params_shape[:batch_dims]) + out_shape[1:]\n          map_fn_gather_nd_result = array_ops.reshape(\n              map_fn_gather_nd_result, shape=out_shape)\n\n        self.assertAllEqual(map_fn_gather_nd_result, batch_gather_nd_result)\n\n  def _map_fn_body(self, elems):\n    return gen_array_ops.gather_nd(elems[0], elems[1])\n\n  def testBatchDimsAsTensor(self):\n    \"\"\"Tests Tensor batch_dims as input works as intended.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 0),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      with self.subTest(\n          params_shape=params_shape,\n          indices_shape=indices_shape,\n          batch_dims=batch_dims):\n        params = constant_op.constant(\n            np.random.uniform(0.0, 1.0, size=(params_shape)))\n        indices = np.random.randint(0, 2, size=indices_shape)\n        batch_gather_nd_result = array_ops.gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims)\n        batch_dims_tensor = constant_op.constant([batch_dims])\n        batch_gather_nd_tensor_batch_dims_result = array_ops.gather_nd(\n            params=params, indices=indices, batch_dims=batch_dims_tensor)\n\n        self.assertAllEqual(batch_gather_nd_tensor_batch_dims_result,\n                            batch_gather_nd_result)\n\n  def testInvalidBatchDimsRaisesException(self):\n    \"\"\"Tests whether invalid batch_dims raise expected exceptions.\"\"\"\n    params = constant_op.constant(\n        np.random.uniform(0.0, 1.0, size=(3, 2, 2, 3, 4)))\n    indices = np.random.randint(0, 2, size=(3, 2, 3))\n\n    with self.assertRaises(TypeError):\n      array_ops.batch_gather_nd(\n          params=params,\n          indices=indices,\n          batch_dims=constant_op.constant((0, 1)))\n\n    with self.assertRaises(ValueError):\n      array_ops.batch_gather_nd(params=params, indices=indices, batch_dims=-1)\n\n    with self.assertRaises(ValueError):\n      array_ops.batch_gather_nd(params=params, indices=indices, batch_dims=4)\n\n  @test_util.run_deprecated_v1\n  def testNoneBatchDimensions(self):\n    \"\"\"Tests gather_nd works with None dimensions.\"\"\"\n    shapes = []\n    # params_shape, indices_shape, batch_dims\n    shapes.append(((2, 2, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 1, 3), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 2, 2), 1),)\n    shapes.append(((2, 2, 3, 2), (2, 3, 1), 1),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 1, 3), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 2, 2), 2),)\n    shapes.append(((3, 2, 2, 3, 4), (3, 2, 3, 1), 2),)\n\n    for params_shape, indices_shape, batch_dims in shapes:\n      params_ph_shape = list(params_shape)\n      indices_ph_shape = list(indices_shape)\n      for i in range(batch_dims):\n        params_ph_shape[i] = None\n        indices_ph_shape[i] = None\n\n      params = array_ops.placeholder(dtypes.float32, shape=params_ph_shape)\n      indices = array_ops.placeholder(dtypes.int32, shape=indices_ph_shape)\n      out = array_ops.batch_gather_nd(\n          params=params, indices=indices, batch_dims=batch_dims)\n\n      with self.cached_session() as sess:\n        params_val = np.ones(dtype=np.float32, shape=params_shape)\n        indices_val = np.ones(dtype=np.int32, shape=indices_shape)\n        res = sess.run(\n            out, feed_dict={\n                params: params_val,\n                indices: indices_val\n            })\n      row_ndims = len(params_shape) - batch_dims - indices_shape[-1]\n      expected_out_shape = indices_shape[:-1]\n      if row_ndims > 0:\n        expected_out_shape += params_shape[-row_ndims:]\n\n      self.assertSequenceEqual(res.shape, expected_out_shape)\n\n  @test_util.run_deprecated_v1\n  def testUnknownIndices(self):\n    \"\"\"Tests whether indices with unknown rank works correctly.\"\"\"\n    params = constant_op.constant(((0, 1, 2),))\n    indices = array_ops.placeholder(dtypes.int32)\n    gather_nd_t = array_ops.gather_nd(params, indices, batch_dims=1)\n    shape = gather_nd_t.get_shape()\n    self.assertEqual(None, shape.ndims)\n    self.assertEqual(None, tensor_shape.dimension_value(shape[0]))\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass RepeatTest(test_util.TensorFlowTestCase, parameterized.TestCase):\n\n  @parameterized.parameters(\n      (3, 4, None),\n      ([[1, 2], [3, 4]], 2, None),\n      ([[1, 2], [3, 4]], [1, 2], 0),\n      ([[1, 2], [3, 4]], [1, 2], 1),\n      ([[1, 2], [3, 4]], 3, 1),\n      ([[1, 2], [3, 4]], [1, 2, 3, 4], None),\n      (np.ones([0, 4]), 0, 1),\n      (np.ones([1, 2]), [2], None),\n  )\n  def testRepeat(self, array, repeats, axis):\n    array = np.array(array)\n\n    @def_function.function(\n        input_signature=[tensor_spec.TensorSpec(None, dtypes.int32)] * 2)\n    def repeat_fn(array, repeats):\n      return array_ops.repeat(array, repeats, axis)\n\n    v_tf = array_ops.repeat(constant_op.constant(array), repeats, axis)\n    v_tf_fn = repeat_fn(\n        constant_op.constant(array, dtype=dtypes.int32), repeats)\n    v_np = np.repeat(array, repeats, axis)\n    self.assertAllEqual(v_tf, v_np)\n    self.assertAllEqual(v_tf_fn, v_np)\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass TileVariantTest(test_util.TensorFlowTestCase):\n\n  def test_tile_tensor_list(self):\n    t = constant_op.constant(np.random.uniform(size=[2, 3, 4]))\n    handle = list_ops.tensor_list_from_tensor(t, element_shape=None)\n    with ops.device(\"CPU:0\"):\n      tiled_handles = array_ops.tile(array_ops.reshape(handle, [1]), [2])\n    tiled_tensor_0 = list_ops.tensor_list_stack(tiled_handles[0], t.dtype, 2,\n                                                [3, 4])\n    tiled_tensor_1 = list_ops.tensor_list_stack(tiled_handles[1], t.dtype, 2,\n                                                [3, 4])\n    self.assertAllEqual(t, tiled_tensor_0)\n    self.assertAllEqual(t, tiled_tensor_1)\n    # Now mutate some of the lists and make sure the changes are not reflected\n    # in the tiled handles.\n    with ops.control_dependencies([\n        list_ops.tensor_list_scatter([t[0] + 1], [0], input_handle=handle),\n        list_ops.tensor_list_set_item(tiled_handles[0], 0, t[0] + 2)]):\n      tiled_tensor_0 = list_ops.tensor_list_stack(tiled_handles[0], t.dtype, 2,\n                                                  [3, 4])\n      tiled_tensor_1 = list_ops.tensor_list_stack(tiled_handles[1], t.dtype, 2,\n                                                  [3, 4])\n    self.assertAllEqual(t, tiled_tensor_0)\n    self.assertAllEqual(t, tiled_tensor_1)\n\n\nif __name__ == \"__main__\":\n  test_lib.main()\n"], "filenames": ["tensorflow/core/kernels/quantize_and_dequantize_op.cc", "tensorflow/python/kernel_tests/array_ops_test.py"], "buggy_code_start_loc": [73, 1630], "buggy_code_end_loc": [73, 1630], "fixing_code_start_loc": [74, 1631], "fixing_code_end_loc": [78, 1647], "type": "CWE-125", "message": "In Tensorflow before version 2.4.0, an attacker can pass an invalid `axis` value to `tf.quantization.quantize_and_dequantize`. This results in accessing a dimension outside the rank of the input tensor in the C++ kernel implementation. However, dim_size only does a DCHECK to validate the argument and then uses it to access the corresponding element of an array. Since in normal builds, `DCHECK`-like macros are no-ops, this results in segfault and access out of bounds of the array. The issue is patched in eccb7ec454e6617738554a255d77f08e60ee0808 and TensorFlow 2.4.0 will be released containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved.", "other": {"cve": {"id": "CVE-2020-15265", "sourceIdentifier": "security-advisories@github.com", "published": "2020-10-21T21:15:12.257", "lastModified": "2021-08-17T13:21:09.770", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Tensorflow before version 2.4.0, an attacker can pass an invalid `axis` value to `tf.quantization.quantize_and_dequantize`. This results in accessing a dimension outside the rank of the input tensor in the C++ kernel implementation. However, dim_size only does a DCHECK to validate the argument and then uses it to access the corresponding element of an array. Since in normal builds, `DCHECK`-like macros are no-ops, this results in segfault and access out of bounds of the array. The issue is patched in eccb7ec454e6617738554a255d77f08e60ee0808 and TensorFlow 2.4.0 will be released containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved."}, {"lang": "es", "value": "En Tensorflow versiones anteriores a  2.4.0, un atacante puede pasar un valor de \"axis\" no v\u00e1lido a la funci\u00f3n \"tf.quantization.quantize_and_dequantize\".&#xa0;Esto resulta en el acceso a una dimensi\u00f3n fuera del rango del tensor de entrada en la implementaci\u00f3n del kernel de C++.&#xa0;Sin embargo, dim_size solo hace un DCHECK para comprobar el argumento y luego lo usa para acceder al elemento correspondiente de una matriz.&#xa0;Dado que en las compilaciones normales, las macros similares a \"DCHECK\" no son operativas, esto resulta en un fallo de segmentaci\u00f3n y un acceso fuera de los l\u00edmites de la matriz.&#xa0;El problema est\u00e1 parcheado en eccb7ec454e6617738554a255d77f08e60ee0808 y TensorFlow versi\u00f3n 2.4.0 se publicar\u00e1 con el parche.&#xa0;Los paquetes nocturnos de TensorFlow despu\u00e9s de esta confirmaci\u00f3n tambi\u00e9n resolver\u00e1n el problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionEndExcluding": "2.4.0", "matchCriteriaId": "837BA051-B044-46A7-BCDF-81785C1E1FF9"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/eccb7ec454e6617738554a255d77f08e60ee0808", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/issues/42105", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-rrfp-j2mp-hq9c", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/eccb7ec454e6617738554a255d77f08e60ee0808"}}