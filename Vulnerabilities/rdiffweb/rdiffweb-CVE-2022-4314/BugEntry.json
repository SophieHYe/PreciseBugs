{"buggy_code": ["![Rdiffweb Banner](https://gitlab.com/ikus-soft/rdiffweb/-/raw/master/doc/_static/banner.png)\n\n<p align=\"center\">\n<strong>\n<a href=\"https://www.rdiffweb.org\">website</a>\n\u2022 <a href=\"https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/\">docs</a>\n\u2022 <a href=\"https://groups.google.com/d/forum/rdiffweb\">community</a>\n\u2022 <a href=\"https://rdiffweb-demo.ikus-soft.com/\">demo</a>\n</strong>\n</p>\n\n<p align=\"center\">\n<a href=\"LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/ikus060/rdiffweb\"></a>\n<a href=\"https://gitlab.com/ikus-soft/rdiffweb/pipelines\"><img alt=\"Build\" src=\"https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Quality Gate Minarca Client\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=alert_status\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Coverage\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=coverage\"></a>\n<a href=\"https://bestpractices.coreinfrastructure.org/projects/6583\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/6583/badge\"></a>\n</p>\n\n<h1 align=\"center\">\nWelcome to Rdiffweb\n</h1>\n\nRdiffweb is a web application that allows you to view repositories generated\nby [rdiff-backup](https://rdiff-backup.net/). The purpose of this\napplication is to ease the management of backups and quickly restore your data\nwith a rich and powerful web interface.\n\nRdiffweb is written in Python and is released as open source project under the \nGNU GENERAL PUBLIC LICENSE (GPL). All source code and documentation are\nCopyright Rdiffweb contributors.\n\nRdiffweb is actively developed by [IKUS Soft](https://www.ikus-soft.com/)\nsince November 2014.\n\nThe Rdiffweb source code is hosted on [Gitlab](https://gitlab.com/ikus-soft/rdiffweb)\nand mirrored to [Github](https://github.com/ikus060/rdiffweb).\n\nThe Rdiffweb website is https://rdiffweb.org/.\n\n## Features\n\nWith its rich web interface Rdiffweb provide a notable list of features:\n\n * Browse your backup\n * Restore single file or multiple files as an archived\n * Users authentication via local database and LDAP\n * Users authorization\n * Email notification when backup is not successful\n * Configurable repository encoding\n * Configurable retention period\n * Backup statistics visualization using graphs\n * SSH Keys management\n * Disk quota visualization\n * File and folder deletion\n\n## Demo\n\nIf you quickly want to check how Rdiffweb is behaving, you may try our demo server hosted on:\n\n[https://rdiffweb-demo.ikus-soft.com/](https://rdiffweb-demo.ikus-soft.com/)\n\nUse the following credential to login:\n\n * Username: admin\n * Password: admin123\n\n## Installation & Docker usage\n\nFor detailed installation steps, read the [Installation documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/installation.html).\n\n## Current Build Status\n\n[![Build Status](https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg)](https://gitlab.com/ikus-soft/rdiffweb/pipelines)\n\n## Download\n\nYou should read the [Documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/index.html) to properly install Rdiffweb in your environment.\n\n**Docker**\n\n    docker pull ikus060/rdiffweb\n    \n**Debian**\n\n    curl -L https://www.ikus-soft.com/archive/rdiffweb/public.key | apt-key add - \n    echo \"deb https://nexus.ikus-soft.com/repository/apt-release-bullseye/ bullseye main\" > /etc/apt/sources.list.d/rdiffweb.list\n    apt update\n    apt install rdiffweb\n\n**Pypi**\n\n    pip install rdiffweb\n\n## Support\n\n### Mailing list\n\nRdiffweb users should use the [Rdiffweb mailing list](https://groups.google.com/forum/#!forum/rdiffweb).\n\n### Bug Reports\n\nBug reports should be reported on the Rdiffweb Gitlab at https://gitlab.com/ikus-soft/rdiffweb/-/issues\n\n### Professional support\n\nProfessional support for Rdiffweb is available by contacting [IKUS Soft](https://www.ikus-soft.com/en/support/#form).\n\n# Changelog\n\n## Next Rlease - 2.5.1\n\n* Add support for Ubuntu Kinetic #240\n* Disable filesize for deleted files to improve page loading #241\n\n## 2.5.0 (2022-11-09)\n\nThis next release focus on two-factor-authentication as a measure to increase security of user's account.\n\n* Store User's session information into database\n* Update ldap plugin to load additional attributes from LDAP server\n* Improve `/status` page error handling when `session_statistics` cannot be read\n* Add support for Ubuntu Jammy\n* Upgrade from Bootstrap v3 to v4 #204\n* Replace Fontello by Font-Awesome v4\n* Use CSS variables `var()` to customize themes using `--branding-X` options #239\n* Remove usage of Jquery.validate\n* Replace custom timsort by jquery DataTables #205\n* Add Active Session managements #203\n  * Active session should be visible in user's profiles\n  * Active session may be revoked by user\n  * Active session should be visible in administration view\n  * Action session may be revoke by administrator\n  * Show number of active users within the last 24 hours in dashboard\n* Handle migration of older Rdiffweb database by adding the missing `repos.Encoding`, `repos.keepdays` and `users.role` columns #185\n* Replace deprecated references of `disutils.spawn.find_executable()` by `shutil.which()` #208\n* Add two-factor authentication with email verification #201\n* Generate a new session on login and 2FA #220\n* Enforce permission on /etc/rdiffweb configuration folder\n* Enforce validation on fullname, username and email\n* Limit incorrect attempts to change the user's password to prevent brute force attacks #225 [CVE-2022-3273](https://nvd.nist.gov/vuln/detail/CVE-2022-3273)\n* Enforce password policy new password cannot be set as new password [CVE-2022-3376](https://nvd.nist.gov/vuln/detail/CVE-2022-3376)\n* Enforce better rate limit on login, mfa, password change and API [CVE-2022-3439](https://nvd.nist.gov/vuln/detail/CVE-2022-3439) [CVE-2022-3456](https://nvd.nist.gov/vuln/detail/CVE-2022-3456)\n* Enforce 'Origin' validation [CVE-2022-3457](https://nvd.nist.gov/vuln/detail/CVE-2022-3457)\n* Define idle and absolute session timeout with agressive default to protect usage on public computer [CVE-2022-3327](https://nvd.nist.gov/vuln/detail/CVE-2022-3327)\n* Send email notification when enabling or disabling MFA [CVE-2022-3363](https://nvd.nist.gov/vuln/detail/CVE-2022-3363)\n* Use Argon2id to store password hash #231\n* Fixed plugin priorities to ensure that jobs are scheduled at each startup #232\n* Revoke previous user's sessions on password change [CVE-2022-3362](https://nvd.nist.gov/vuln/detail/CVE-2022-3362)\n\nBreaking changes:\n\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n* `session-dir` is deprecated and should be replace by `rate-limit-dir`. User's session are stored in database.\n* previous `.css` customization are not barkward compatible. Make usage of the `--branding-X` options.\n\n## 2.4.10 (2022-10-03)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate path traversal vulnerability [CVE-2022-3389](https://nvd.nist.gov/vuln/detail/CVE-2022-3389)\n\n## 2.4.9 (2022-09-28)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add `Cache-Control` and other security headers [CVE-2022-3292](https://nvd.nist.gov/vuln/detail/CVE-2022-3292)\n* Enforce password policy using `password-score` based on [zxcvbn](https://github.com/dropbox/zxcvbn) [CVE-2022-3326](https://nvd.nist.gov/vuln/detail/CVE-2022-3326)\n\n## 2.4.8 (2022-09-26)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Clean-up invalid path on error page\n* Limit username field length [CVE-2022-3290](https://nvd.nist.gov/vuln/detail/CVE-2022-3290)\n* Limit user's email field length [CVE-2022-3272](https://nvd.nist.gov/vuln/detail/CVE-2022-3272)\n* Limit user's root directory field length [CVE-2022-3295](https://nvd.nist.gov/vuln/detail/CVE-2022-3295)\n* Limit SSH Key title field length [CVE-2022-3298](https://nvd.nist.gov/vuln/detail/CVE-2022-3298)\n\n## 2.4.7 (2002-09-21)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Generate a new session on login and 2FA #220 [CVE-2022-3269](https://nvd.nist.gov/vuln/detail/CVE-2022-3269)\n* Mitigate CSRF on user's settings #221 [CVE-2022-3274](https://nvd.nist.gov/vuln/detail/CVE-2022-3274)\n\n## 2.4.6 (2022-09-20)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Support MarkupSafe<3 for Debian bookworm\n* Mitigate CSRF on user's notification settings #216 [CVE-2022-3233](https://nvd.nist.gov/vuln/detail/CVE-2022-3233)\n* Mitigate CSRF on repository settings #217 [CVE-2022-3267](https://nvd.nist.gov/vuln/detail/CVE-2022-3267)\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session on HTTP Error #218 [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174)\n\n## 2.4.5 (2002-09-16)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF on repository deletion and user deletion [CVE-2022-3232](https://nvd.nist.gov/vuln/detail/CVE-2022-3232) #214 #215\n\n## 2.4.4 (2002-09-15)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use `X-Real-IP` to identify client IP address to mitigate Brute-Force attack #213\n\n## 2.4.3 (2022-09-14)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF in profile's SSH Keys [CVE-2022-3221](https://nvd.nist.gov/vuln/detail/CVE-2022-3221) #212\n\n## 2.4.2 (2022-09-12)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session. [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174) #209\n* Avoid leakage of the stack trace in the default error page. [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3175) #210\n* Enforce minimum and maximum password length [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3179) #211\n\n## 2.4.1 (2022-09-08)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add Clickjacking Defense [CVE-2022-3167](https://nvd.nist.gov/vuln/detail/CVE-2022-3167)\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n\n## 2.4.0 (2022-06-21)\n\nThis new release brings a lot of improvement since the last version, multiple bug fixes\nto make the application stable. A couple of new features to improve the overall\nusability and a new security feature to block a brute force attack.\n\n* Add RateLimit to login page and API to mitigate robots attacks #167\n* Send email notification only if `email-sender` option is defined to avoid raising exception in logs #176\n* Support file restore cancellation without leaving `rdiffweb-restore` process in `<defunct>` state #174\n* Replace `python-ldap` by `ldap3` a pure python implementation to avoid dependencies on `sasl` and `ldap` binaries #186\n* Reffactor core module to allow better extendability and reusability #183\n* Add support for Debian Bookworm #180\n* Add support for Ubuntu Impish #175\n* Add rdiff-backup version to administration view\n* Run unit test during Debian build package\n* Refresh repository list automatically when required #188 #189\n* Fix error 500 displayed in status page #191\n* Improve repository browsing speed by minimizing the number of I/O call #192\n* Publish Docker image directly to DockerHub #144\n* Add REST API to manage sshkeys\n\nBreaking changes:\n\n* Ldap Password changes is not supported anymore.\n* Ldap Check Shadow expire config is not supported anymore. It should be replace by a custom filter.\n* Drop CentOS 7 and CentOS 8 support\n\n## 2.3.9 (2022-01-05)\n\nMaintenance release to fix minor issues\n\n* Improve date parsing for `backup.log` to avoid printing exception in logs #170\n* Return HTTP error 403 for invalid symlink to avoid returning a misleading HTTP 500 Server Error #168\n* Show a user friendly error message when trying to create a new user with an existing username #169\n* Handle repository without last-backup date during the notification process to ensure notifications are sent #171\n* Replace CherryPy `storage_type` by `storage_class` to avoid warning in logs\n* Update code to avoid deprecation warning where applicable\n* Add Flake8 validation to improve code quality\n* Remove Ubuntu Groovy support\n\n## 2.3.8 (2021-12-01)\n\n* Push all artefacts to nexus server including binaries and documentation\n* Fix `Chart.js` loading on Debian bullseye #164\n* Update installation steps documentation\n* Improve LDAP authentication to lookup entire directory\n* Fix usage of `--ldap-add-user-default-userroot` to avoid error related to wrong encoding\n* Improve authentication mechanics\n* Avoid raising an HTTP error 500 when login form receive invalid payload\n* Mitigate open redirect vulnerability in login form\n\n## 2.3.7 (2021-10-21)\n\n * To avoid backward compatibility issue, revert CSRF Token validation\n * Mitigate CSRF vulnerability using cookies with `SameSite=Lax`\n * Mitigate CSRF vulnerability by validating the `Origin` header when a form is submited\n * Improve usage of WTForm for all form validation\n * Update installation stepd for debian #162\n * Build Ubuntu packages and publish them to our APT repo\n\n## 2.3.6 (2021-10-20)\n\n * Broken build\n\n## 2.3.5 (2021-10-18)\n\n * Mitigate CSRF vulnerability to user, ssh and repo management with CSRF Token\n\n## 2.3.4 (2021-09-20)\n\n * Skip email notification if `email-host` configuration is not provided #157\n * Skip email notification when the new attribute value has the same value #159\n * USE LDAP `mail` attribute when creating new user from LDAP directory #156\n\n## 2.3.3 (2021-09-10)\n\n * Provide a new theme `blue` to match IKUS Soft colors #158\n\n## 2.3.2 (2021-09-07)\n\n * Automatically update user's repository list based on user's home directory\n\n## 2.3.1 (2021-07-14)\n\n * Update default `session-dir` location to `/var/lib/rdiffweb/session` to avoid using `/var/run` #148\n\n## 2.3.0 (2021-07-06)\n\n * Improve timezone handling to display date with local timezone using javascript #143\n * Improve charts by replacing d3js by chartkick #122\n * Replace the status view by something meaningful with chartkick #122\n * Provide Docker image with Rdiffweb `docker pull ikus060/rdiffweb` #55\n * Fix file and folder sorting #143\n\n## 2.2.0 (2021-05-11)\n \n * Debian package:\n   * Add rdiff-backup as dependencies to comply with Debian packaging rules\n   * Multiple other fixed to control files\n   * Use debhelper-compat (= 13)\n   * Use debhelper-compat (= 13)\n   * Run test during packaging\n   * Create default folder `/var/run/rdiffweb/sessions` to store user session\n * Use ConfigArgPare for configuration to support configuration file, environment variables and arguments to configure rdiffweb #114\n * Fix cache in localization module\n * Add `ldap-add-default-role` and `ldap-add-default-userroot` option to define default value for role and user root when creating user from LDAP #125\n * Support PostgreSQL database by replacing our storage layer by SQLAlchemy #126\n * Fix to retrieve user quota only for valid user_root #135\n * Add option `disable-ssh-keys` to disable SSH Key management\n * Use absolute URL everywhere\n * Add support for `X-Forwarded-For`, `X-Forwarded-proto` and other reverse proxy header when generating absolute URL\n * Drop Debian Stretch support\n * Implement a new background scheduler using apscheduler #82\n * Use background job to send email notification to avoid blocking web page loading #47\n * Use background job to delete repository to avoid blocking web page loading #48\n * Allow deleting a specific file or folder from the history using `rdiff-backup-delete` #128\n * Improve support for `session-dir` #131\n * Add option `admin-password` to define administrator password for better security\n * Improve performance of repository browsing \n * Add a new view to display logs of a specific repository\n * Allow downloading the log\n * Define a default limit to graph statistics to make it display faster\n * Fix `get-quota-cmd` option to properly return a value\n\n## 2.1.0 (2021-01-15)\n\n* Debian package: Remove dh-systemd from Debian build dependencies (https://bugs.debian.org/871312we)\n* Improve Quota management:\n  * `QuotaSetCmd`, `QuotaGetCmd` and `QuotaUsedCmd` options could be used to customize how to set the quota for your environment.\n  * Display user's quota in User View\n  * Display user's quota in Admin View\n  * Allow admin to update user quota from Admin View when `QuotaSetCmd` is defined.\n  * Allow admin to define user quota using human readable value (e.g.: GiB, TiB, etc.)\n  * Improve logging around quota management\n* Improve robustness when service is starting\n* Improve robustness when repository has wrong permission defined (e.g.: when some files not readable)\n* Add user id in Admin view\n* Replace `UserObject(1)` by the actual username in log file to improve debugging\n\n## 2.0.0 (2020-12-04)\n\n* Re-implement logic to update repositories views to remove duplicates and avoid nesting repo. #107\n* Handle elapsed time of days in the graph. Thanks [Nathaniel van Diepen](https://github.com/Eeems) contributions.\n* Rebrand all link to ikus-soft.com\n* Update documentation to install rdiffweb\n* Remove obsolete minify dependency\n* Drop support for python2\n* Provide null translation if translation catalogues are not found\n* Pass a LANG environment variable to rdiff-backup restore process to fix encoding issue #112\n* Remove obsolete python shebang\n* Remove execution bit (+x) on python modules\n* Provide `--help` and `--version` on `rdiffweb` executable\n* Improve cherrypy version detection\n* Do not update translation files (.mo) during build\n\n## 1.5.0 (2020-06-24)\n\nThis minor release introduce official support of rdiffweb on Debian Bullseye. It also includes some usability improvements.\n\n * Change formatting of Last Backup date for \"Updated 3 weeks ago\" to ease the readability\n * Add support for Debian Bullseye\n * Add support for Python 3.8 (#104)\n * Add warning in the users list view when a root directory is invalid (#30)\n * Add options to control search depthness (#1)\n * Print a warning in the log when the \"DefaultTheme\" value is not valid (#90)\n\n## 1.4.0 (2020-05-20)\n\nThanks to our sponsor, this release introduce a feature to have better control over the user's permission by defining 3 different levels of privilege: Admin, Maintainer and User. This addition allows you to have better control on what your users can or can't do.\n\n * Fix single repository discovery when a user's home is a rdiff-backup repository\n * [SPONSORED] Add a new setting at the user level to define the user's role. Admin,\n   Maintainer and User. Admin are allowed to do everything. Maintainer are\n   allow to browse and delete repo. Users are only allowed to browse. #94\n * Add \"Powered by\" in the web interface footer #91\n * Display a nice error message when trying to delete admin user #93\n * Introduce usage of wtforms and flash in admin users for better form validation. #96 #97\n * Update French translation\n\n## 1.3.2 (2020-04-23)\n\nThis minor releases fixed issues found while testing release 1.3.0.\n\n * Fix lookup of executable rdiff-backup and rdiffweb-restore to search in current virtualenv first\n * Fix repository view when multiple repo path are conflicting\n * Fix logging of rdiffweb-restore subprocess\n\n## 1.3.1 (2020-04-10)\n\nThis minor release enforces security of the password stored in rdiffweb database to make use of a better encryption using SSHA.\nOnly new passwords will make use of the SSHA scheme.\n\n * Enforce password encryption by using SSHA scheme #88\n\n## 1.3.0 (2020-04-07)\n\nThis release focuses on improving the restore of big archives. The download should be much faster to start. Major enhancement was made to offload the processing outside the web server. And all of this is still compatible with rdiff-backup v1.2.8 and the latest v2.0.0.\n\n * Restore file and folder in a subprocess to make the download start faster\n * Fix encoding of archive on Python3.6 (CentOS 7) by using PAX format\n * Add support to restore files and folders using rdiff-backup2\n * Remove obsolete dependencies `pysqlite2`\n * Fix issue creating duplicate entries of repository in the database\n\n## 1.2.2 (2020-03-05)\n\nThis release provides little improvement to the v1.2.x including official support of rdiff-backup v2.0.0.\n\n * Enhance the repository to invite users to refresh the repository when the view is empty.\n * Support rdiff-backup v2.0.0\n * Deprecate support for cherrypy 4, 5, 6 and 7\n * Improve loading of repository data (cache status and entries)\n * Restore compatibility with SQLite 3.7 (CentOS7)\n\nKnown issues:\n\n * Filename encoding in tar.gz and zip file might not be accurate if you are running Python 3.6 (CentOS7)\n\n\n## 1.2.1 (2020-02-08)\n\nLittle bug fix following the previous release\n\n * Fix 404 error when trying to access other users repo as admin\n * Fix logging format for cherrypy logs to matches rdiffweb format\n * Add log rotation by default\n\n## 1.2.0 (2020-01-30)\n\nThis release focus on improving the database layers for better extendability to add more type of data and to support more databases backend like postgresql in the near future.\n\n * Add explicit testing for Debian Stretch & Buster\n * Change the persistence layers\n   * Minimize number of SQL queries\n   * Add object lazy loading\n   * Add object data caching\n * Fix bugs with SQLite <= 3.16 (Debian Stretch)\n\n## 1.1.0 (2019-10-31)\n\nThis release focus on improving the admin area and building the fundation for repository access control list (ACL).\n\n * Update documentation from PDSL web site\n * Improve the navigation bar layout\n * Update the login page headline\n * Update jinja2 version to allow 2.10.x\n * Show server log in admin area\n * Reduce code smell\n * Add System information in admin area\n * Validate credential using local database before LDAP\n * Reffactoring templates macros\n * Enhance user's view search bar\n * Change repository URL to username/repopath\n * Add System information in admin area\n * Improve testcases\n * Clean-up obsolete code\n * Fix issue with captital case encoding name\n * Fix compilation of less files\n * Fix google font import\n\n## 1.0.3 (2019-10-04)\n * Removing the auto update repos\n\n## 1.0.2 (2019-10-01)\n * Create \"admin\" user if missing\n * Update french translation\n\n## 1.0.1 (2019-09-22)\n * Update installation documentation \n * Fix removal of SSH Key\n * Return meaningful error to the user trying to add an existing SSH key\n\n## 1.0.0 (2019-09-11)\n * Make repository removal more robust\n * Improve performance of librdiff\n * Add new RESTful api\n * Return the right HTTP 401 or 402 error code for authentication\n * Fix bug introduce by upgrade to Jinja2 + python3\n * Store ssh keys in database and disk\n * Add support for theme (default, orange)\n * Remove deprecated profiling code\n * Add disk usage support / quota\n * Add support of cherrypy v18\n * Drop support of cherrypy v3.2.2\n * Add wsgi entry point\n * Replace the plugins architecture to ease implementation\n * Numerous bug fixes\n\n## 0.10.9 (2019-05-22)\n * Better error handling when error.log file are not valid gzip file\n\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nfrom unittest.mock import ANY, MagicMock\n\nimport cherrypy\nfrom parameterized import parameterized\n\nimport rdiffweb.test\nfrom rdiffweb.core.model import UserObject\n\n\nclass AbstractAdminTest(rdiffweb.test.WebCase):\n\n    login = True\n\n    def setUp(self):\n        super().setUp()\n        self._quota = {}\n        self.listener = MagicMock()\n        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)\n        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)\n        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)\n        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)\n        self.listener.get_disk_quota.side_effect = self._load_quota\n        cherrypy.engine.subscribe('get_disk_quota', self.listener.get_disk_quota, priority=40)\n        self.listener.get_disk_usage.return_value = 0\n        cherrypy.engine.subscribe('get_disk_usage', self.listener.get_disk_usage, priority=40)\n        self.listener.set_disk_quota.side_effect = self._store_quota\n        cherrypy.engine.subscribe('set_disk_quota', self.listener.set_disk_quota, priority=40)\n\n    def tearDown(self):\n        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)\n        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)\n        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)\n        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)\n        cherrypy.engine.unsubscribe('get_disk_quota', self.listener.get_disk_quota)\n        cherrypy.engine.unsubscribe('get_disk_usage', self.listener.get_disk_usage)\n        cherrypy.engine.unsubscribe('set_disk_quota', self.listener.set_disk_quota)\n        return super().tearDown()\n\n    def _store_quota(self, userobj, value):\n        self._quota[userobj.username] = value\n\n    def _load_quota(self, userobj):\n        return self._quota.get(userobj.username, 0)\n\n    def _add_user(self, username=None, email=None, password=None, user_root=None, role=None, mfa=None, fullname=None):\n        b = {}\n        b['action'] = 'add'\n        if username is not None:\n            b['username'] = username\n        if email is not None:\n            b['email'] = email\n        if password is not None:\n            b['password'] = password\n        if user_root is not None:\n            b['user_root'] = user_root\n        if role is not None:\n            b['role'] = str(role)\n        if mfa is not None:\n            b['mfa'] = str(mfa)\n        if fullname is not None:\n            b['fullname'] = str(fullname)\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def _edit_user(\n        self, username=None, email=None, password=None, user_root=None, role=None, disk_quota=None, mfa=None\n    ):\n        b = {}\n        b['action'] = 'edit'\n        if username is not None:\n            b['username'] = username\n        if email is not None:\n            b['email'] = email\n        if password is not None:\n            b['password'] = password\n        if user_root is not None:\n            b['user_root'] = user_root\n        if role is not None:\n            b['role'] = str(role)\n        if disk_quota is not None:\n            b['disk_quota'] = disk_quota\n        if mfa is not None:\n            b['mfa'] = str(mfa)\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def _delete_user(self, username='test1'):\n        b = {'action': 'delete', 'username': username}\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def test_add_user_with_role_admin(self):\n        # When trying to create a new user with role admin\n        self._add_user(\"admin_role\", \"admin_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.ADMIN_ROLE)\n        # Then page return success\n        self.assertStatus(200)\n        # Then database is updated\n        userobj = UserObject.get_user('admin_role')\n        self.assertEqual(UserObject.ADMIN_ROLE, userobj.role)\n        # Then notification was raised\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_add_user_with_role_maintainer(self):\n        self._add_user(\"maintainer_role\", \"maintainer_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.MAINTAINER_ROLE)\n        self.assertStatus(200)\n        self.assertEqual(UserObject.MAINTAINER_ROLE, UserObject.get_user('maintainer_role').role)\n\n    def test_add_user_with_role_user(self):\n        self._add_user(\"user_role\", \"user_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        self.assertEqual(UserObject.USER_ROLE, UserObject.get_user('user_role').role)\n\n    def test_add_user_with_invalid_role(self):\n        # When trying to create a new user with an invalid role (admin instead of 0)\n        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", 'admin')\n        # Then an error message is displayed to the user\n        self.assertStatus(200)\n        self.assertInBody('Role: Invalid Choice: could not coerce')\n        # Then listener are not called\n        self.listener.user_added.assert_not_called()\n\n        # When trying to create a new user with an invalid role (-1)\n        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", -1)\n        # Then an error message is displayed to the user\n        self.assertStatus(200)\n        self.assertInBody('User Role: Not a valid choice')\n        # Then listener are not called\n        self.listener.user_added.assert_not_called()\n\n    def test_add_edit_delete(self):\n        #  Add user to be listed\n        self.listener.user_password_changed.reset_mock()\n        self._add_user(\n            \"test2\", \"test2@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE, mfa=UserObject.DISABLED_MFA\n        )\n        self.assertInBody(\"User added successfully.\")\n        self.assertInBody(\"test2\")\n        self.assertInBody(\"test2@test.com\")\n        self.listener.user_added.assert_called_once()\n        self.listener.user_password_changed.assert_called_once()\n        self.listener.user_password_changed.reset_mock()\n        #  Update user\n        self._edit_user(\n            \"test2\", \"chaned@test.com\", \"new-password\", \"/tmp/\", UserObject.ADMIN_ROLE, mfa=UserObject.ENABLED_MFA\n        )\n        self.listener.user_attr_changed.assert_called()\n        self.listener.user_password_changed.assert_called_once()\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertInBody(\"test2\")\n        self.assertInBody(\"chaned@test.com\")\n        self.assertNotInBody(\"/home/\")\n        self.assertInBody(\"/tmp/\")\n\n        self._delete_user(\"test2\")\n        self.listener.user_deleted.assert_called()\n        self.assertStatus(200)\n        self.assertInBody(\"User account removed.\")\n        self.assertNotInBody(\"test2\")\n\n    @parameterized.expand(\n        [\n            # Invalid\n            ('evil.com', False),\n            ('http://test', False),\n            ('email@test.test', False),\n            ('/test/', False),\n            # Valid\n            ('My fullname', True),\n            ('Test Test', True),\n            ('\u00c9ric Terrien-Pascal', True),\n            (\"Tel'c\", True),\n        ]\n    )\n    def test_edit_fullname_with_special_character(self, new_fullname, expected_valid):\n        # Given an existing user\n        # When updating the user's fullname\n        self.getPage(\n            \"/admin/users/\",\n            method='POST',\n            body={'action': 'edit', 'username': self.USERNAME, 'fullname': new_fullname},\n        )\n        self.assertStatus(200)\n        if expected_valid:\n            self.assertInBody(\"User information modified successfully.\")\n            self.assertNotInBody(\"Fullname: Must not contain any special characters.\")\n        else:\n            self.assertNotInBody(\"User information modified successfully.\")\n            self.assertInBody(\"Fullname: Must not contain any special characters.\")\n\n    @parameterized.expand(\n        [\n            # Invalid\n            ('http://username', False),\n            ('username@test.test', False),\n            ('/username/', False),\n            # Valid\n            ('username.com', True),\n            ('admin_user', True),\n            ('test.test', True),\n            ('test-test', True),\n        ]\n    )\n    def test_add_user_with_special_character(self, new_username, expected_valid):\n        self._add_user(new_username, \"eric@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        if expected_valid:\n            self.assertInBody(\"User added successfully.\")\n            self.assertNotInBody(\"Username: Must not contain any special characters.\")\n        else:\n            self.assertNotInBody(\"User added successfully.\")\n            self.assertInBody(\"Username: Must not contain any special characters.\")\n\n    def test_add_user_with_empty_username(self):\n        \"\"\"\n        Verify failure trying to create user without username.\n        \"\"\"\n        self._add_user(\"\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        self.assertInBody(\"Username: This field is required.\")\n\n    def test_add_user_with_existing_username(self):\n        \"\"\"\n        Verify failure trying to add the same user.\n        \"\"\"\n        # Given a user named `test1`\n        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # When trying to create a new user with the same name\n        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then the user list is displayed with an error message.\n        self.assertStatus(200)\n        self.assertInBody(\"User test1 already exists.\")\n\n    def test_add_user_with_invalid_root_directory(self):\n        \"\"\"\n        Verify failure to add a user with invalid root directory.\n        \"\"\"\n        try:\n            self._delete_user(\"test5\")\n        except Exception:\n            pass\n        self._add_user(\"test5\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")\n\n    def test_add_without_email(self):\n        #  Add user to be listed\n        self._add_user(\"test2\", None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n\n    def test_add_without_user_root(self):\n        #  Add user to be listed\n        self._add_user(\"test6\", None, \"pr3j5Dwi\", None, UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n\n        user = UserObject.get_user('test6')\n        self.assertEqual('', user.user_root)\n\n    def test_add_with_username_too_long(self):\n        # Given a too long username\n        username = \"test2\" * 52\n        # When trying to create the user\n        self._add_user(username, None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Username too long.\")\n\n    def test_add_with_email_too_long(self):\n        # Given a too long username\n        email = (\"test2\" * 50) + \"@test.com\"\n        # When trying to create the user\n        self._add_user(\"test2\", email, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Email too long.\")\n\n    def test_add_with_user_root_too_long(self):\n        # Given a too long user root\n        user_root = \"/temp/\" * 50\n        # When trying to create the user\n        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", user_root, UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Root directory too long.\")\n\n    def test_add_with_fullname_too_long(self):\n        # Given a too long user root\n        fullname = \"fullname\" * 50\n        # When trying to create the user\n        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE, fullname=fullname)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Fullname too long.\")\n\n    def test_delete_user_with_not_existing_username(self):\n        \"\"\"\n        Verify failure to delete invalid username.\n        \"\"\"\n        self._delete_user(\"test3\")\n        self.assertInBody(\"User doesn&#39;t exists!\")\n\n    def test_delete_our_self(self):\n        \"\"\"\n        Verify failure to delete our self.\n        \"\"\"\n        self._delete_user(self.USERNAME)\n        self.assertInBody(\"You cannot remove your own account!\")\n\n    def test_delete_user_admin(self):\n        \"\"\"\n        Verify failure to delete our self.\n        \"\"\"\n        # Create another admin user\n        self._add_user('admin2', '', 'pr3j5Dwi', '', UserObject.ADMIN_ROLE)\n        self.getPage(\"/logout\")\n        self.assertStatus(303)\n        self.assertHeaderItemValue('Location', self.baseurl + '/')\n        self._login('admin2', 'pr3j5Dwi')\n\n        # Try deleting admin user\n        self._delete_user(self.USERNAME)\n        self.assertStatus(200)\n        self.assertInBody(\"can&#39;t delete admin user\")\n\n    def test_delete_user_method_get(self):\n        # Given a user\n        user = UserObject.add_user('newuser')\n        user.commit()\n        # When trying to delete this user using method GET\n        self.getPage(\"/admin/users/?action=delete&username=newuser\", method='GET')\n        # Then page return without error\n        self.assertStatus(200)\n        # Then user is not deleted\n        self.assertIsNotNone(UserObject.get_user('newuser'))\n\n    def test_change_password_with_too_short(self):\n        self._edit_user(self.USERNAME, password='short')\n        self.assertInBody(\"Password must have between 8 and 128 characters.\")\n\n    def test_change_password_with_too_long(self):\n        new_password = 'a' * 129\n        self._edit_user(self.USERNAME, password=new_password)\n        self.assertInBody(\"Password must have between 8 and 128 characters.\")\n\n    def test_change_admin_password(self):\n        # Given rdiffweb is configured with admin-password option\n        self.app.cfg.admin_password = 'hardcoded'\n        try:\n            # When trying to update admin password\n            self._edit_user('admin', password='new-password')\n            # Then the form is refused with 200 OK with an error message.\n            self.assertStatus(200)\n            self.assertInBody(\"can&#39;t update admin-password defined in configuration file\")\n        finally:\n            self.app.cfg.admin_password = None\n\n    def test_edit_user_with_invalid_path(self):\n        \"\"\"\n        Verify failure trying to update user with invalid path.\n        \"\"\"\n        userobj = UserObject.add_user('test1')\n        userobj.commit()\n        self._edit_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)\n        self.assertNotInBody(\"User added successfully.\")\n        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")\n\n    def test_list(self):\n        self.getPage(\"/admin/users/\")\n        self.assertInBody(\"Users\")\n        self.assertInBody(\"User management\")\n        self.assertInBody(\"Add user\")\n\n    def test_edit_user_with_not_existing_username(self):\n        \"\"\"\n        Verify failure trying to update invalid user.\n        \"\"\"\n        # Given an invalid username\n        username = 'invalid'\n        # When trying to edit the user\n        self._edit_user(username, \"test1@test.com\", \"test\", \"/var/invalid/\", UserObject.USER_ROLE)\n        # Then the user list is displayed with an error message\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot edit user `invalid`: user doesn&#39;t exists\")\n\n    def test_user_invalid_root(self):\n        # Delete all user's\n        for user in UserObject.query.all():\n            if user.username != self.USERNAME:\n                user.delete().commit()\n        # Change the user's root\n        user = UserObject.get_user('admin')\n        user.user_root = \"/invalid\"\n        user.commit()\n        self.getPage(\"/admin/users\")\n        self.assertInBody(\"Root directory not accessible!\")\n\n        # Query the page by default\n        user = UserObject.get_user('admin')\n        user.user_root = \"/tmp/\"\n        user.commit()\n        self.getPage(\"/admin/users\")\n        self.assertNotInBody(\"Root directory not accessible!\")\n\n    def test_get_quota(self):\n        # Mock a quota.\n        self.listener.get_disk_quota.side_effect = None\n        self.listener.get_disk_quota.return_value = 654321\n        # When querying the user list\n        self.getPage(\"/admin/users/\")\n        self.assertStatus(200)\n        # Then get_disk_quota listenre is called\n        self.listener.get_disk_quota.assert_called()\n        # Then the quota value is displayed in human readable format\n        self.assertInBody(\"638.99 KiB\")\n        self.assertStatus(200)\n\n    def test_set_quota(self):\n        # When updating user quota.\n        self._edit_user(\"admin\", disk_quota='8765432')\n        # Then listenr get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_gib(self):\n        # When updating user quota\n        self._edit_user(\"admin\", disk_quota='1GiB')\n        # Then listern get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 1073741824)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_with_comma(self):\n        # When updating quota with comma value\n        self._edit_user(\"admin\", disk_quota='1,5 GiB')\n        # Then listner get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 1610612736)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_with_leading_dot(self):\n        # When updating quota with leading dot\n        self._edit_user(\"admin\", disk_quota='.5 GiB')\n        # Then listener get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 536870912)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_empty(self):\n        # When quota is not defined\n        self._edit_user(\"admin\", disk_quota='')\n        # Then listener is not called.\n        self.listener.set_disk_quota.assert_not_called()\n        # Then message is not displayed\n        self.assertStatus(200)\n\n    def test_set_quota_same_value(self):\n        # Given an exiting quota\n        self.listener.get_disk_quota.side_effect = None\n        self.listener.get_disk_quota.return_value = 1234567890\n        # When setting the quota value to the same value\n        self._edit_user(\"admin\", disk_quota='1.15 GiB')\n        #  Then listener is not called\n        self.listener.set_disk_quota.assert_not_called()\n        # Then message is not displayed\n        self.assertStatus(200)\n\n    def test_set_quota_unsupported(self):\n        # Given setting quota is not supported\n        self.listener.set_disk_quota.side_effect = None\n        self.listener.set_disk_quota.return_value = None\n        # When updating the quota\n        self._edit_user(\"admin\", disk_quota='8765432')\n        # Then\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)\n        self.assertInBody(\"Setting user&#39;s quota is not supported\")\n        self.assertStatus(200)\n\n    def test_edit_own_role(self):\n        # Given an administrator\n        # When trygin to update your own role\n        self._edit_user(username=self.USERNAME, role=UserObject.MAINTAINER_ROLE)\n        # Then an error is returned\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot edit your own role.\")\n\n    def test_edit_own_mfa(self):\n        # Given an administrator\n        # When trygin to update your own role\n        self._edit_user(username=self.USERNAME, mfa=UserObject.ENABLED_MFA)\n        # Then an error is returned\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot change your own two-factor authentication settings.\")\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport bisect\nimport calendar\nimport encodings\nimport logging\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport threading\nimport time\nfrom datetime import timedelta\nfrom subprocess import CalledProcessError\n\nimport psutil\nfrom cached_property import cached_property\n\nfrom rdiffweb.tools.i18n import ugettext as _\n\n# Define the logger\nlogger = logging.getLogger(__name__)\n\n# Constant for the rdiff-backup-data folder name.\nRDIFF_BACKUP_DATA = b\"rdiff-backup-data\"\n\n# Increment folder name.\nINCREMENTS = b\"increments\"\n\n# Define the default LANG environment variable to be passed to rdiff-backup\n# restore command line to make sure the binary output stdout as utf8 otherwise\n# we end up with \\x encoded characters.\nSTDOUT_ENCODING = 'utf-8'\nLANG = \"en_US.\" + STDOUT_ENCODING\n\n\ndef rdiff_backup_version():\n    \"\"\"\n    Get rdiff-backup version\n    \"\"\"\n    try:\n        output = subprocess.check_output([find_rdiff_backup(), '--version'])\n        m = re.search(b'([0-9]+).([0-9]+).([0-9]+)', output)\n        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))\n    except Exception:\n        return (0, 0, 0)\n\n\ndef find_rdiff_backup():\n    \"\"\"\n    Lookup for `rdiff-backup` executable. Raise an exception if not found.\n    \"\"\"\n    cmd = shutil.which('rdiff-backup')\n    if not cmd:\n        raise FileNotFoundError(\"can't find `rdiff-backup` executable in PATH: %s\" % os.environ['PATH'])\n    return os.fsencode(cmd)\n\n\ndef find_rdiff_backup_delete():\n    \"\"\"\n    Lookup for `rdiff-backup-delete` executable. Raise an exception if not found.\n    \"\"\"\n    cmd = shutil.which('rdiff-backup-delete')\n    if not cmd:\n        raise FileNotFoundError(\n            \"can't find `rdiff-backup-delete` executable in PATH: %s, make sure you have rdiff-backup >= 2.0.1 installed\"\n            % os.environ['PATH']\n        )\n    return os.fsencode(cmd)\n\n\ndef unquote(name):\n    \"\"\"Remove quote from the given name.\"\"\"\n    assert isinstance(name, bytes)\n\n    # This function just gives back the original text if it can decode it\n    def unquoted_char(match):\n        \"\"\"For each ;000 return the corresponding byte.\"\"\"\n        if len(match.group()) != 4:\n            return match.group\n        try:\n            return bytes([int(match.group()[1:])])\n        except ValueError:\n            return match.group\n\n    # Remove quote using regex\n    return re.sub(b\";[0-9]{3}\", unquoted_char, name, re.S)\n\n\ndef popen(cmd, stderr=None, env=None):\n    \"\"\"\n    Alternative to os.popen() to support a `cmd` with a list of arguments and\n    return a file object that return bytes instead of string.\n\n    `stderr` could be subprocess.STDOUT or subprocess.DEVNULL or a function.\n    Otherwise, the error is redirect to logger.\n    \"\"\"\n    # Check if stderr should be pipe.\n    pipe_stderr = stderr == subprocess.PIPE or hasattr(stderr, '__call__') or stderr is None\n    proc = subprocess.Popen(\n        cmd,\n        shell=False,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE if pipe_stderr else stderr,\n        env=env,\n    )\n    if pipe_stderr:\n        t = threading.Thread(target=_readerthread, args=(proc.stderr, stderr))\n        t.daemon = True\n        t.start()\n    return _wrap_close(proc.stdout, proc)\n\n\n# Helper for popen() to redirect stderr to a logger.\n\n\ndef _readerthread(stream, func):\n    \"\"\"\n    Read stderr and pipe each line to logger.\n    \"\"\"\n    func = func or logger.debug\n    for line in stream:\n        func(line.decode(STDOUT_ENCODING, 'replace').strip('\\n'))\n    stream.close()\n\n\n# Helper for popen() to close process when the pipe is closed.\n\n\nclass _wrap_close:\n    def __init__(self, stream, proc):\n        self._stream = stream\n        self._proc = proc\n\n    def close(self):\n        self._stream.close()\n        returncode = self._proc.wait()\n        if returncode == 0:\n            return None\n        return returncode\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getattr__(self, name):\n        return getattr(self._stream, name)\n\n    def __iter__(self):\n        return iter(self._stream)\n\n\nclass AccessDeniedError(Exception):\n    pass\n\n\nclass DoesNotExistError(Exception):\n    pass\n\n\nclass RdiffTime(object):\n\n    \"\"\"Time information has two components: the local time, stored in GMT as\n    seconds since Epoch, and the timezone, stored as a seconds offset. Since\n    the server may not be in the same timezone as the user, we cannot rely on\n    the built-in localtime() functions, but look at the rdiff-backup string\n    for timezone information.  As a general rule, we always display the\n    \"local\" time, but pass the timezone information on to rdiff-backup, so\n    it can restore to the correct state\"\"\"\n\n    def __init__(self, value=None, tz_offset=None):\n        assert value is None or isinstance(value, int) or isinstance(value, str)\n        if value is None:\n            # Get GMT time.\n            self._time_seconds = int(time.time())\n            self._tz_offset = 0\n        elif isinstance(value, int):\n            self._time_seconds = value\n            self._tz_offset = tz_offset or 0\n        else:\n            self._from_str(value)\n\n    def _from_str(self, time_string):\n        if time_string[10] != 'T':\n            raise ValueError('missing date time separator (T): ' + time_string)\n        if time_string[19] not in ['-', '+', 'Z']:\n            raise ValueError('missing timezone info (-, + or Z): ' + time_string)\n        if time_string[4] != '-' or time_string[7] != '-':\n            raise ValueError('missing date separator (-): ' + time_string)\n        if not (time_string[13] in [':', '-'] and time_string[16] in [':', '-']):\n            raise ValueError('missing date separator (-): ' + time_string)\n        try:\n            year = int(time_string[0:4])\n            if not (1900 < year < 2200):\n                raise ValueError('unexpected year value between 1900 and 2200: ' + str(year))\n            month = int(time_string[5:7])\n            if not (1 <= month <= 12):\n                raise ValueError('unexpected month value between 1 and 12: ' + str(month))\n            day = int(time_string[8:10])\n            if not (1 <= day <= 31):\n                raise ValueError('unexpected day value between 1 and 31: ' + str(day))\n            hour = int(time_string[11:13])\n            if not (0 <= hour <= 23):\n                raise ValueError('unexpected hour value between 1 and 23: ' + str(hour))\n            minute = int(time_string[14:16])\n            if not (0 <= minute <= 60):\n                raise ValueError('unexpected minute value between 1 and 60: ' + str(minute))\n            second = int(time_string[17:19])\n            if not (0 <= second <= 61):  # leap seconds\n                raise ValueError('unexpected second value between 1 and 61: ' + str(second))\n            timetuple = (year, month, day, hour, minute, second, -1, -1, 0)\n            self._time_seconds = calendar.timegm(timetuple)\n            self._tz_offset = self._tzdtoseconds(time_string[19:])\n            self._tz_str()  # to get assertions there\n        except (TypeError, ValueError, AssertionError):\n            raise ValueError(time_string)\n\n    def epoch(self):\n        return self._time_seconds - self._tz_offset\n\n    def _tz_str(self):\n        if self._tz_offset:\n            hours, minutes = divmod(abs(self._tz_offset) // 60, 60)\n            assert 0 <= hours <= 23\n            assert 0 <= minutes <= 59\n            if self._tz_offset > 0:\n                plus_minus = \"+\"\n            else:\n                plus_minus = \"-\"\n            return \"%s%s:%s\" % (plus_minus, \"%02d\" % hours, \"%02d\" % minutes)\n        else:\n            return \"Z\"\n\n    def set_time(self, hour, minute, second):\n        year = time.gmtime(self._time_seconds)[0]\n        month = time.gmtime(self._time_seconds)[1]\n        day = time.gmtime(self._time_seconds)[2]\n        _time_seconds = calendar.timegm((year, month, day, hour, minute, second, -1, -1, 0))\n        return RdiffTime(_time_seconds, self._tz_offset)\n\n    def _tzdtoseconds(self, tzd):\n        \"\"\"Given w3 compliant TZD, converts it to number of seconds from UTC\"\"\"\n        if tzd == \"Z\":\n            return 0\n        assert len(tzd) == 6  # only accept forms like +08:00 or +08-00 for now\n        assert (tzd[0] == \"-\" or tzd[0] == \"+\") and tzd[3] in [\":\", '-']\n        if tzd[0] == \"+\":\n            plus_minus = 1\n        else:\n            plus_minus = -1\n        return plus_minus * 60 * (60 * int(tzd[1:3]) + int(tzd[4:]))\n\n    def __add__(self, other):\n        \"\"\"Support plus (+) timedelta\"\"\"\n        assert isinstance(other, timedelta)\n        return RdiffTime(self._time_seconds + int(other.total_seconds()), self._tz_offset)\n\n    def __sub__(self, other):\n        \"\"\"Support minus (-) timedelta\"\"\"\n        assert isinstance(other, timedelta) or isinstance(other, RdiffTime)\n        # Sub with timedelta, return RdiffTime\n        if isinstance(other, timedelta):\n            return RdiffTime(self._time_seconds - int(other.total_seconds()), self._tz_offset)\n\n        # Sub with RdiffTime, return timedelta\n        if isinstance(other, RdiffTime):\n            return timedelta(seconds=self._time_seconds - other._time_seconds)\n\n    def __int__(self):\n        \"\"\"Return this date as seconds since epoch.\"\"\"\n        return self.epoch()\n\n    def __lt__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() < other.epoch()\n\n    def __le__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() <= other.epoch()\n\n    def __gt__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() > other.epoch()\n\n    def __ge__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() >= other.epoch()\n\n    def __eq__(self, other):\n        return isinstance(other, RdiffTime) and self.epoch() == other.epoch()\n\n    def __hash__(self):\n        return hash(self.epoch())\n\n    def __str__(self):\n        \"\"\"return utf-8 string\"\"\"\n        value = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(self._time_seconds))\n        return value + self._tz_str()\n\n    def __repr__(self):\n        \"\"\"return second since epoch\"\"\"\n        return \"RdiffTime('\" + str(self) + \"')\"\n\n\nclass RdiffDirEntry(object):\n    \"\"\"\n    Includes name, isdir, file_size, exists, and dict (change_dates) of sorted\n    local dates when backed up.\n    \"\"\"\n\n    def __init__(self, repo, path, exists, increments):\n        assert isinstance(repo, RdiffRepo)\n        assert isinstance(path, bytes)\n        # Keep reference to the path and repo object.\n        self._repo = repo\n        self.path = path\n        # Absolute path to the directory\n        if self.isroot:\n            self.full_path = self._repo.full_path\n        else:\n            self.full_path = os.path.join(self._repo.full_path, self.path)\n        # May need to compute our own state if not provided.\n        self.exists = exists\n        # Store the increments sorted by date.\n        # See self.last_change_date()\n        self._increments = sorted(increments, key=lambda x: x.date)\n\n    @property\n    def display_name(self):\n        \"\"\"Return the most human readable filename. Without quote.\"\"\"\n        return self._repo.get_display_name(self.path)\n\n    @property\n    def isroot(self):\n        \"\"\"\n        Check if the directory entry represent the root of the repository.\n        Return True when path is empty.\n        \"\"\"\n        return self.path == b''\n\n    @cached_property\n    def isdir(self):\n        \"\"\"Lazy check if entry is a directory\"\"\"\n        if self.exists:\n            # If the entry exists, check if it's a directory\n            return os.path.isdir(self.full_path)\n        # Check if increments is a directory\n        for increment in self._increments:\n            if increment.is_missing:\n                # Ignore missing increment...\n                continue\n            return increment.isdir\n\n    @cached_property\n    def file_size(self):\n        \"\"\"\n        Return the current file size in bytes.\n        Return negative value (-1) for folder and deleted files.\n        \"\"\"\n        if self.isdir or not self.exists:\n            return -1\n        else:\n            try:\n                return os.lstat(self.full_path).st_size\n            except Exception:\n                logger.warning(\"cannot lstat on file [%s]\", self.full_path, exc_info=1)\n                return 0\n\n    def get_file_size(self, date=None):\n        # A viable place to get the filesize of a deleted entry\n        # it to get it from file_statistics\n        try:\n            stats = self._repo.file_statistics[date]\n            # File stats uses unquoted name.\n            unquote_path = unquote(self.path)\n            return stats.get_source_size(unquote_path)\n        except Exception:\n            logger.warning(\"cannot find file statistic [%s]\", self.last_change_date, exc_info=1)\n        return -1\n\n    @cached_property\n    def change_dates(self):\n        \"\"\"\n        Return a list of dates when this item has changes. Represent the\n        previous revision. From old to new.\n        \"\"\"\n        # Exception for root path, use backups dates.\n        if self.isroot:\n            return self._repo.backup_dates\n\n        # Compute the dates\n        change_dates = set()\n        for increment in self._increments:\n            # Get date of the increment as reference\n            change_date = increment.date\n            # If the increment is a \"missing\" increment, need to get the date\n            # before the folder was removed.\n            if increment.is_missing:\n                change_date = self._get_previous_backup_date(change_date)\n\n            if change_date:\n                change_dates.add(change_date)\n\n        # If the directory exists, add the last known backup date.\n        if self.exists and self._repo.last_backup_date:\n            change_dates.add(self._repo.last_backup_date)\n\n        # Return the list of dates.\n        return sorted(change_dates)\n\n    def _get_previous_backup_date(self, date):\n        \"\"\"Return the previous backup date.\"\"\"\n        index = bisect.bisect_left(self._repo.backup_dates, date)\n        if index == 0:\n            return None\n        return self._repo.backup_dates[index - 1]\n\n    @cached_property\n    def last_change_date(self):\n        \"\"\"Return last change date or False.\"\"\"\n        return self.change_dates and self.change_dates[-1]\n\n\nclass AbstractEntry:\n    SUFFIXES = None\n\n    @classmethod\n    def _extract_date(cls, filename, onerror=None):\n        \"\"\"\n        Extract date from rdiff-backup filenames.\n        \"\"\"\n        # Extract suffix\n        suffix = None\n        for s in cls.SUFFIXES:\n            if filename.endswith(s):\n                suffix = s\n                break\n        if not suffix:\n            raise ValueError(filename)\n        # Parse date\n        filename_without_suffix = filename[: -len(suffix)]\n        parts = filename_without_suffix.rsplit(b'.', 1)\n        if len(parts) != 2:\n            return onerror(ValueError(''))\n        date_string = unquote(parts[1]).decode('ascii')\n        try:\n            return RdiffTime(date_string)\n        except Exception as e:\n            if onerror is None:\n                raise\n            return onerror(e)\n\n\nclass MetadataEntry(AbstractEntry):\n    PREFIX = None\n    SUFFIXES = None\n    on_date_error = None\n\n    def __init__(self, repo, name):\n        assert isinstance(repo, RdiffRepo)\n        assert isinstance(name, bytes)\n        assert name.startswith(self.PREFIX)\n        assert any(name.endswith(s) for s in self.SUFFIXES), 'name %s should ends with: %s' % (name, self.SUFFIXES)\n        self.repo = repo\n        self.name = name\n        self.path = os.path.join(self.repo._data_path, self.name)\n        self.date = self._extract_date(name, onerror=self.on_date_error)\n\n    def _open(self):\n        \"\"\"\n        Should be used to open the increment file. This method handle\n        compressed vs not-compressed file.\n        \"\"\"\n        if self._is_compressed:\n            return popen(['zcat', self.path])\n        return open(self.path, 'rb')\n\n    @property\n    def _is_compressed(self):\n        return self.name.endswith(b\".gz\")\n\n\nclass MirrorMetadataEntry(MetadataEntry):\n    PREFIX = b'mirror_metadata.'\n    SUFFIXES = [\n        b'.diff',\n        b'.diff.gz',\n        b\".snapshot.gz\",\n        b\".snapshot\",\n    ]\n\n\nclass IncrementEntry(AbstractEntry):\n\n    \"\"\"Instance of the class represent one increment at a specific date for one\n    repository. The base repository is provided in the default constructor\n    and the date is provided using an error_log.* file\"\"\"\n\n    SUFFIXES = [\n        b\".missing\",\n        b\".snapshot.gz\",\n        b\".snapshot\",\n        b\".diff\",\n        b\".diff.gz\",\n        b\".dir\",\n    ]\n\n    def __init__(self, name):\n        \"\"\"Default constructor for an increment entry. User must provide the\n        repository directory and an entry name. The entry name correspond\n        to an error_log.* filename.\"\"\"\n        self.name, self.date, self.suffix = IncrementEntry._split(name)\n\n    @property\n    def isdir(self):\n        return self.suffix == b\".dir\"\n\n    @property\n    def is_missing(self):\n        \"\"\"Check if the curent entry is a missing increment.\"\"\"\n        return self.suffix == b\".missing\"\n\n    @property\n    def is_snapshot(self):\n        \"\"\"Check if the current entry is a snapshot increment.\"\"\"\n        return self.suffix in [b\".snapshot.gz\", b\".snapshot\"]\n\n    @classmethod\n    def _split(cls, filename):\n        \"\"\"Return tuple with filename, date, suffix\"\"\"\n        assert isinstance(filename, bytes)\n        # Extract suffix\n        suffix = None\n        for s in cls.SUFFIXES:\n            if filename.endswith(s):\n                suffix = s\n                break\n        if not suffix:\n            raise ValueError(filename)\n        # Parse date and raise error on failure\n        filename_without_suffix = filename[: -len(suffix)]\n        name, date_string = filename_without_suffix.rsplit(b'.', 1)\n        date_string = unquote(date_string).decode('ascii')\n        date = RdiffTime(date_string)\n        return (name, date, suffix)\n\n    def __gt__(self, other):\n        return self.date.__gt__(other.date)\n\n    def __lt__(self, other):\n        return self.date.__lt__(other.date)\n\n\nclass FileStatisticsEntry(MetadataEntry):\n\n    \"\"\"\n    Represent a single file_statistics.\n\n    File Statistics contains different information related to each file of\n    the backup. This class provide a simple and easy way to access this\n    data.\n    \"\"\"\n\n    PREFIX = b'file_statistics.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    def get_mirror_size(self, path):\n        \"\"\"Return the value of MirrorSize for the given file.\n        path is the relative path from repo root.\"\"\"\n        try:\n            return int(self._search(path)[\"mirror_size\"])\n        except ValueError:\n            logger.warning(\"mirror size not found for [%r]\", path, exc_info=1)\n            return 0\n\n    def get_source_size(self, path):\n        \"\"\"Return the value of SourceSize for the given file.\n        path is the relative path from repo root.\"\"\"\n        try:\n            return int(self._search(path)[\"source_size\"])\n        except ValueError:\n            logger.warning(\"source size not found for [%r]\", path, exc_info=1)\n            return 0\n\n    def _search(self, path):\n        \"\"\"\n        This function search for a file entry in the file_statistics compress\n        file. Since python gzip.open() seams to be 2 time slower, we directly use\n        zlib library on python2.\n        \"\"\"\n        logger.debug(\"read file_statistics [%r]\", self.name)\n\n        path += b' '\n\n        with self._open() as f:\n            for line in f:\n                if not line.startswith(path):\n                    continue\n                break\n\n        # Split the line into array\n        data = line.rstrip(b'\\r\\n').rsplit(b' ', 4)\n        # From array create an entry\n        return {'changed': data[1], 'source_size': data[2], 'mirror_size': data[3], 'increment_size': data[4]}\n\n\nclass SessionStatisticsEntry(MetadataEntry):\n    \"\"\"Represent a single session_statistics.\"\"\"\n\n    PREFIX = b'session_statistics.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    ATTRS = [\n        'starttime',\n        'endtime',\n        'elapsedtime',\n        'sourcefiles',\n        'sourcefilesize',\n        'mirrorfiles',\n        'mirrorfilesize',\n        'newfiles',\n        'newfilesize',\n        'deletedfiles',\n        'deletedfilesize',\n        'changedfiles',\n        'changedsourcesize',\n        'changedmirrorsize',\n        'incrementfiles',\n        'incrementfilesize',\n        'totaldestinationsizechange',\n        'errors',\n    ]\n\n    def _load(self):\n        \"\"\"This method is used to read the session_statistics and create the\n        appropriate structure to quickly get the data.\n\n        File Statistics contains different information related to each file of\n        the backup. This class provide a simple and easy way to access this\n        data.\"\"\"\n\n        with self._open() as f:\n            for line in f.readlines():\n                # Read the line into array\n                line = line.rstrip(b'\\r\\n')\n                data_line = line.split(b\" \", 2)\n                # Read line into tuple\n                (key, value) = tuple(data_line)[0:2]\n                if b'.' in value:\n                    value = float(value)\n                else:\n                    value = int(value)\n                setattr(self, key.lower().decode('ascii'), value)\n\n    def __getattr__(self, name):\n        \"\"\"\n        Intercept attribute getter to load the file.\n        \"\"\"\n        if name in self.ATTRS:\n            self._load()\n        return self.__dict__[name]\n\n\nclass CurrentMirrorEntry(MetadataEntry):\n    PID_RE = re.compile(b\"^PID\\\\s*([0-9]+)\", re.I | re.M)\n\n    PREFIX = b'current_mirror.'\n    SUFFIXES = [b'.data']\n\n    def extract_pid(self):\n        \"\"\"\n        Return process ID from a current mirror marker, if any\n        \"\"\"\n        with open(self.path, 'rb') as f:\n            match = self.PID_RE.search(f.read())\n        if not match:\n            return None\n        return int(match.group(1))\n\n\nclass LogEntry(MetadataEntry):\n    PREFIX = b'error_log.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    @cached_property\n    def is_empty(self):\n        \"\"\"\n        Check if the increment entry is empty.\n        \"\"\"\n        return os.path.getsize(self.path) == 0\n\n    def read(self):\n        \"\"\"Read the error file and return it's content. Raise exception if the\n        file can't be read.\"\"\"\n        # To avoid opening empty file, check the file size first.\n        if self.is_empty:\n            return \"\"\n        encoding = self.repo._encoding.name\n        if self._is_compressed:\n            return subprocess.check_output(\n                ['zcat', self.path],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n                encoding=encoding,\n                errors='replace',\n            )\n        with open(self.path, 'r', encoding=encoding, errors='replace') as f:\n            return f.read()\n\n    def tail(self, num=2000):\n        \"\"\"\n        Tail content of the file. This is used for logs.\n        \"\"\"\n        # To avoid opening empty file, check the file size first.\n        if self.is_empty:\n            return b''\n        encoding = self.repo._encoding.name\n        if self._is_compressed:\n            zcat = subprocess.Popen([b'zcat', self.path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n            return subprocess.check_output(\n                ['tail', '-n', str(num)],\n                stdin=zcat.stdout,\n                stderr=subprocess.STDOUT,\n                encoding=encoding,\n                errors='replace',\n            )\n        return subprocess.check_output(\n            ['tail', '-n', str(num), self.path], stderr=subprocess.STDOUT, encoding=encoding, errors='replace'\n        )\n\n\nclass RestoreLogEntry(LogEntry):\n    PREFIX = b'restore.'\n    SUFFIXES = [b'.log']\n\n    @staticmethod\n    def on_date_error(e):\n        return None\n\n\nclass BackupLogEntry(LogEntry):\n    PREFIX = b'backup.'\n    SUFFIXES = [b'.log']\n\n    @staticmethod\n    def on_date_error(e):\n        return None\n\n\nclass MetadataKeys:\n    \"\"\"\n    Provide a view on metadata dict keys. See MetadataDict#keys()\n    \"\"\"\n\n    def __init__(self, function, sequence):\n        self._f = function\n        self._sequence = sequence\n\n    def __iter__(self):\n        return map(self._f, self._sequence)\n\n    def __getitem__(self, i):\n        if isinstance(i, slice):\n            return list(map(self._f, self._sequence[i]))\n        else:\n            return self._f(self._sequence[i])\n\n    def __len__(self):\n        return len(self._sequence)\n\n\nclass MetadataDict(object):\n    \"\"\"\n    This is used to access repository metadata quickly in a pythonic way. It\n    make an abstraction to access a range of increment entries using index and\n    date while also supporting slice to get a range of entries.\n    \"\"\"\n\n    def __init__(self, repo, cls):\n        assert isinstance(repo, RdiffRepo)\n        assert hasattr(cls, '__call__')\n        self._repo = repo\n        assert cls.PREFIX\n        self._prefix = cls.PREFIX\n        self._cls = cls\n\n    @cached_property\n    def _entries(self):\n        return [e for e in self._repo._entries if e.startswith(self._prefix)]\n\n    def __getitem__(self, key):\n        if isinstance(key, RdiffTime):\n            idx = bisect.bisect_left(self.keys(), key)\n            if idx < len(self._entries):\n                item = self._cls(self._repo, self._entries[idx])\n                if item.date == key:\n                    return item\n            raise KeyError(key)\n        elif isinstance(key, slice):\n            if isinstance(key.start, RdiffTime):\n                idx = bisect.bisect_left(self.keys(), key.start)\n                key = slice(idx, key.stop, key.step)\n            if isinstance(key.stop, RdiffTime):\n                idx = bisect.bisect_right(self.keys(), key.stop)\n                key = slice(key.start, idx, key.step)\n            return [self._cls(self._repo, e) for e in self._entries[key]]\n        elif isinstance(key, int):\n            try:\n                return self._cls(self._repo, self._entries[key])\n            except IndexError:\n                raise KeyError(key)\n        else:\n            raise KeyError(key)\n\n    def __iter__(self):\n        for e in self._entries:\n            yield self._cls(self._repo, e)\n\n    def __len__(self):\n        return len(self._entries)\n\n    def keys(self):\n        return MetadataKeys(lambda e: self._cls._extract_date(e), self._entries)\n\n\nclass RdiffRepo(object):\n\n    \"\"\"Represent one rdiff-backup repository.\"\"\"\n\n    def __init__(self, user_root, path, encoding):\n        if isinstance(user_root, str):\n            user_root = os.fsencode(user_root)\n        if isinstance(path, str):\n            path = os.fsencode(path)\n        assert isinstance(user_root, bytes)\n        assert isinstance(path, bytes)\n        assert encoding\n        self._encoding = encodings.search_function(encoding)\n        assert self._encoding\n        self.path = path.strip(b\"/\")\n        if self.path:\n            self.full_path = os.path.normpath(os.path.join(user_root, self.path))\n        else:\n            self.full_path = os.path.normpath(user_root)\n\n        # The location of rdiff-backup-data directory.\n        self._data_path = os.path.join(self.full_path, RDIFF_BACKUP_DATA)\n        assert isinstance(self._data_path, bytes)\n        self._increment_path = os.path.join(self._data_path, INCREMENTS)\n        self.current_mirror = MetadataDict(self, CurrentMirrorEntry)\n        self.error_log = MetadataDict(self, LogEntry)\n        self.mirror_metadata = MetadataDict(self, MirrorMetadataEntry)\n        self.file_statistics = MetadataDict(self, FileStatisticsEntry)\n        self.session_statistics = MetadataDict(self, SessionStatisticsEntry)\n\n    @property\n    def backup_dates(self):\n        \"\"\"Return a list of dates when backup was executed. This list is\n        sorted from old to new (ascending order). To identify dates,\n        'mirror_metadata' file located in rdiff-backup-data are used.\"\"\"\n        return self.mirror_metadata.keys()\n\n    @property\n    def backup_log(self):\n        \"\"\"\n        Return the location of the backup log.\n        \"\"\"\n        return BackupLogEntry(self, b'backup.log')\n\n    def delete(self, path):\n        \"\"\"\n        Delete this entry from the repository history using rdiff-backup-delete.\n        \"\"\"\n        path_obj = self.fstat(path)\n        if path_obj.isroot:\n            return self.delete_repo()\n\n        rdiff_backup_delete = find_rdiff_backup_delete()\n        cmdline = [rdiff_backup_delete, path_obj.full_path]\n        logger.info('executing: %r' % cmdline)\n        process = subprocess.Popen(cmdline, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env={'LANG': LANG})\n        for line in process.stdout:\n            line = line.rstrip(b'\\n').decode('utf-8', errors='replace')\n            logger.info('rdiff-backup-delete: %s' % line)\n        retcode = process.wait()\n        if retcode:\n            raise CalledProcessError(retcode, cmdline)\n\n    def delete_repo(self):\n        \"\"\"Delete the repository permanently.\"\"\"\n        # Try to change the permissions of the file or directory to delete\n        # them.\n        def handle_error(func, path, exc_info):\n            if exc_info[0] == PermissionError:\n                # Parent directory must allow rwx\n                if not os.access(os.path.dirname(path), os.W_OK | os.R_OK | os.X_OK):\n                    os.chmod(os.path.dirname(path), 0o0700)\n                if not os.access(path, os.W_OK | os.R_OK):\n                    os.chmod(path, 0o0600)\n                if os.path.isdir(path):\n                    return shutil.rmtree(path, onerror=handle_error)\n                else:\n                    return os.unlink(path)\n            raise\n\n        try:\n            shutil.rmtree(self.full_path, onerror=handle_error)\n        except Exception:\n            logger.warning('fail to delete repo', exc_info=1)\n\n    @property\n    def display_name(self):\n        \"\"\"Return the most human representation of the repository name.\"\"\"\n        return self.get_display_name(b'')\n\n    def _decode(self, value, errors='replace'):\n        \"\"\"Used to decode a repository path into unicode.\"\"\"\n        assert isinstance(value, bytes)\n        return self._encoding.decode(value, errors)[0]\n\n    @cached_property\n    def _entries(self):\n        return sorted(os.listdir(self._data_path))\n\n    def expire(self):\n        \"\"\"\n        Clear the cache to refresh metadata.\n        \"\"\"\n        cached_properties = [\n            (self, '_entries'),\n            (self, 'status'),\n            (self.current_mirror, '_entries'),\n            (self.error_log, '_entries'),\n            (self.mirror_metadata, '_entries'),\n            (self.file_statistics, '_entries'),\n            (self.session_statistics, '_entries'),\n        ]\n        for obj, attr in cached_properties:\n            if attr in obj.__dict__:\n                del obj.__dict__[attr]\n\n    def listdir(self, path):\n        \"\"\"\n        Return a list of RdiffDirEntry each representing a file or a folder in the given path.\n        \"\"\"\n        # Compute increment directory location.\n        full_path = os.path.realpath(os.path.join(self.full_path, path.strip(b'/')))\n        relative_path = os.path.relpath(full_path, self.full_path)\n        if relative_path.startswith(RDIFF_BACKUP_DATA):\n            raise DoesNotExistError(path)\n        increment_path = os.path.normpath(os.path.join(self._increment_path, relative_path))\n        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):\n            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))\n\n        # Get list of all increments and existing file and folder\n        try:\n            existing_items = os.listdir(full_path)\n            if relative_path == b'.':\n                existing_items.remove(RDIFF_BACKUP_DATA)\n        except (NotADirectoryError, FileNotFoundError):\n            existing_items = None\n        except OSError:\n            raise AccessDeniedError(path)\n        try:\n            increment_items = os.listdir(increment_path)\n        except (NotADirectoryError, FileNotFoundError):\n            increment_items = None\n        except OSError:\n            raise AccessDeniedError(path)\n        # Raise error if nothing is found\n        if existing_items is None and increment_items is None:\n            raise DoesNotExistError(path)\n\n        # Merge information from both location\n        # Regroup all information into RdiffDirEntry\n        entries = {}\n        for name in existing_items or []:\n            entries[name] = RdiffDirEntry(\n                self,\n                os.path.normpath(os.path.join(relative_path, name)),\n                exists=True,\n                increments=[],\n            )\n        for item in increment_items or []:\n            try:\n                increment = IncrementEntry(item)\n            except ValueError:\n                # Ignore any increment that cannot be parsed\n                continue\n            entry = entries.get(increment.name, None)\n            if not entry:\n                # Create a new Direntry\n                entry = entries[increment.name] = RdiffDirEntry(\n                    self,\n                    os.path.normpath(os.path.join(relative_path, increment.name)),\n                    exists=False,\n                    increments=[increment] if increment else [],\n                )\n            else:\n                # Add increment to dir entry\n                bisect.insort_left(entry._increments, increment)\n        return sorted(list(entries.values()), key=lambda e: e.path)\n\n    def fstat(self, path):\n        \"\"\"Return a new instance of DirEntry to represent the given path.\"\"\"\n        # Compute increment directory location.\n        assert isinstance(path, bytes)\n        full_path = os.path.normpath(os.path.join(self.full_path, path.strip(b'/')))\n        increment_path = os.path.normpath(os.path.join(self._increment_path, path.strip(b'/'), b'..'))\n        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):\n            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))\n        relative_path = os.path.relpath(full_path, self.full_path)\n        if relative_path.startswith(RDIFF_BACKUP_DATA):\n            raise DoesNotExistError(path)\n        # Get if the path request is the root path.\n        if relative_path == b'.':\n            return RdiffDirEntry(self, b'', True, [])\n\n        # Check if path exists\n        try:\n            os.lstat(full_path)\n            exists = True\n        except (OSError, ValueError):\n            exists = False\n\n        # Get incrmement data\n        increment_items = os.listdir(increment_path)\n\n        # Create dir entry\n        prefix = os.path.basename(full_path)\n        entry = RdiffDirEntry(self, relative_path, exists, [])\n        for item in increment_items:\n            if not item.startswith(prefix):\n                # Ignore increment not matching our path\n                continue\n            try:\n                increment = IncrementEntry(item)\n            except ValueError:\n                # Ignore any increment that cannot be parsed\n                continue\n            if increment.name != prefix:\n                # Ignore increment not matching our path\n                continue\n            # Add increment to dir entry\n            bisect.insort_left(entry._increments, increment)\n\n        # Check if path exists or has increment. If not raise an exception.\n        if not exists and not entry._increments:\n            logger.error(\"path [%r] doesn't exists\", path)\n            raise DoesNotExistError(path)\n\n        # Create a directory entry.\n        return entry\n\n    @property\n    def last_backup_date(self):\n        \"\"\"Return the last known backup dates.\"\"\"\n        try:\n            if len(self.current_mirror) > 0:\n                return self.current_mirror[-1].date\n            return None\n        except (PermissionError, FileNotFoundError):\n            return None\n\n    def get_display_name(self, path):\n        \"\"\"\n        Return proper display name of the given path according to repository encoding and quoted characters.\n        \"\"\"\n        assert isinstance(path, bytes)\n        path = path.strip(b'/')\n        if path in [b'.', b'']:\n            # For repository we use either path if defined or the directory base name\n            if not self.path:\n                return self._decode(unquote(os.path.basename(self.full_path)))\n            return self._decode(unquote(self.path))\n        else:\n            # For path, we use the dir name\n            return self._decode(unquote(os.path.basename(path)))\n\n    def remove_older(self, remove_older_than):\n        assert type(remove_older_than) is int, 'invalid remove_older_than, expect an integer: ' + remove_older_than\n        logger.info(\n            \"execute rdiff-backup --force --remove-older-than=%sD %r\",\n            remove_older_than,\n            self.full_path.decode(sys.getfilesystemencoding(), 'replace'),\n        )\n        subprocess.check_output(\n            [\n                b'rdiff-backup',\n                b'--force',\n                b'--remove-older-than=' + str(remove_older_than).encode(encoding='latin1') + b'D',\n                self.full_path,\n            ]\n        )\n        self.expire()\n\n    def restore(self, path, restore_as_of, kind=None):\n        \"\"\"\n        Restore the current directory entry into a fileobj containing the\n        file content of the directory compressed into an archive.\n\n        `kind` must be one of the supported archive type or none to use `zip` for folder and `raw` for file.\n\n        Return a filename and a fileobj.\n        \"\"\"\n        assert isinstance(path, bytes)\n        assert restore_as_of, \"restore_as_of must be defined\"\n        assert kind in ['tar', 'tar.bz2', 'tar.gz', 'tbz2', 'tgz', 'zip', 'raw', None]\n\n        # Define proper kind according to path type.\n        path_obj = self.fstat(path)\n        if path_obj.isdir:\n            if kind == 'raw':\n                raise ValueError('raw type not supported for directory')\n            kind = kind or 'zip'\n        else:\n            kind = kind or 'raw'\n\n        # Define proper filename according to the path\n        if kind == 'raw':\n            filename = path_obj.display_name\n        else:\n            filename = \"%s.%s\" % (path_obj.display_name, kind)\n\n        # Call external process to offload processing.\n        # python -m rdiffweb.core.restore --restore-as-of 123456 --encoding utf-8 --kind zip -\n        cmdline = [\n            os.fsencode(sys.executable),\n            b'-m',\n            b'rdiffweb.core.restore',\n            b'--restore-as-of',\n            str(restore_as_of).encode('latin'),\n            b'--encoding',\n            self._encoding.name.encode('latin'),\n            b'--kind',\n            kind.encode('latin'),\n            os.path.join(self.full_path, unquote(path_obj.path)),\n            b'-',\n        ]\n        proc = subprocess.Popen(\n            cmdline,\n            shell=False,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            env=None,\n        )\n        # Check if the restore process is properly starting\n        # Read the first 100 line until \"Processing changed file\"\n        max_line = 100\n        output = b''\n        success = False\n        line = proc.stderr.readline()\n        while max_line > 0 and line:\n            max_line -= 1\n            output += line\n            if b'Processing changed file' in line:\n                success = True\n                break\n            line = proc.stderr.readline()\n        if not success:\n            raise CalledProcessError(1, cmdline, output)\n        # Start a Thread to pipe the rest of the stream to the log\n        t = threading.Thread(target=_readerthread, args=(proc.stderr, logger.debug))\n        t.daemon = True\n        t.start()\n        return filename, _wrap_close(proc.stdout, proc)\n\n    @property\n    def restore_log(self):\n        \"\"\"\n        Return the location of the restore log.\n        \"\"\"\n        return RestoreLogEntry(self, b'restore.log')\n\n    @cached_property\n    def status(self):\n        \"\"\"Check if a backup is in progress for the current repo.\"\"\"\n\n        # Read content of the file and check if pid still exists\n        try:\n            # Make sure repoRoot is a valid rdiff-backup repository\n            for current_mirror in self.current_mirror:\n                pid = current_mirror.extract_pid()\n                try:\n                    p = psutil.Process(pid)\n                    if any('rdiff-backup' in c for c in p.cmdline()):\n                        return ('in_progress', _('A backup is currently in progress to this repository.'))\n                except psutil.NoSuchProcess:\n                    logger.debug('pid [%s] does not exists', pid)\n\n            # If multiple current_mirror file exists and none of them are associated to a PID, this mean the last backup was interrupted.\n            # Also, if the last backup date is undefined, this mean the first\n            # initial backup was interrupted.\n            if len(self.current_mirror) > 1 or len(self.current_mirror) == 0:\n                return ('interrupted', _('The previous backup seams to have failed.'))\n        except FileNotFoundError:\n            self._entries = []\n            return ('failed', _('The repository cannot be found or is badly damaged.'))\n        except PermissionError:\n            self._entries = []\n            logger.warning('error reading current_mirror files', exc_info=1)\n            return ('failed', _(\"Permissions denied. Contact administrator to check repository's permissions.\"))\n\n        return ('ok', '')\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport codecs\nimport encodings\nimport logging\nimport os\nimport sys\n\nimport cherrypy\nfrom sqlalchemy import Column, Integer, SmallInteger, String, and_, case, event, orm\nfrom sqlalchemy.ext.hybrid import hybrid_property\nfrom sqlalchemy.orm import relationship, validates\n\nimport rdiffweb.tools.db  # noqa\nfrom rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError, RdiffRepo\nfrom rdiffweb.tools.i18n import ugettext as _\n\nBase = cherrypy.tools.db.get_base()\n\nlogger = logging.getLogger(__name__)\n\n\ndef _split_path(path):\n    \"\"\"\n    Split the given path into <username as str> / <path as bytes>\n    \"\"\"\n    # First part is the username\n    assert path\n    if isinstance(path, str):\n        path = os.fsencode(path)\n    path = path.strip(b'/')\n    if b'/' in path:\n        username, path = path.split(b'/', 1)\n        return username.decode('utf-8'), path\n    else:\n        return path.decode('utf-8'), b''\n\n\nclass RepoObject(Base, RdiffRepo):\n    DEFAULT_REPO_ENCODING = codecs.lookup((sys.getfilesystemencoding() or 'utf-8').lower()).name\n\n    __tablename__ = 'repos'\n    __table_args__ = {'sqlite_autoincrement': True}\n\n    repoid = Column('RepoID', Integer, primary_key=True, autoincrement=True)\n    userid = Column('UserID', Integer, nullable=False)\n    user = relationship(\n        'UserObject',\n        foreign_keys=[userid],\n        primaryjoin='UserObject.userid == RepoObject.userid',\n        uselist=False,\n        lazy=True,\n    )\n    repopath = Column('RepoPath', String, nullable=False, default='')\n    maxage = Column('MaxAge', SmallInteger, nullable=False, server_default=\"0\")\n    encoding = Column('Encoding', String, default=DEFAULT_REPO_ENCODING)\n    _keepdays = Column('keepdays', String, nullable=False, default=\"-1\")\n\n    @classmethod\n    def get_repo(cls, name, as_user=None, refresh=False):\n        \"\"\"\n        Return the repository identified as `name`.\n        `name` should be <username>/<repopath>\n        \"\"\"\n        from ._user import UserObject\n\n        username, repopath = _split_path(name)\n        repopath = os.fsdecode(repopath).strip('/')\n\n        # Check permissions\n        as_user = as_user or cherrypy.tree.apps[''].currentuser\n        if not as_user:\n            raise AccessDeniedError(\"as_user or current user must be defined\")\n        if username != as_user.username and not as_user.is_admin:\n            raise AccessDeniedError(name)\n\n        # Search the repo in database\n        query = RepoObject.query.join(UserObject, UserObject.userid == RepoObject.userid).filter(\n            and_(UserObject.username == username, RepoObject.repopath == repopath)\n        )\n        record = query.first()\n        # If the repo is not found but refresh is requested\n        if refresh and not record:\n            if as_user.refresh_repos():\n                as_user.commit()\n            record = query.first()\n        # If repo is not found, raise an error\n        if not record:\n            raise DoesNotExistError(username, repopath)\n        return record\n\n    @classmethod\n    def get_repo_path(cls, path, as_user=None, refresh=False):\n        \"\"\"\n        Return a the repository identified by the given `path`.\n        `path` should be <username>/<repopath>/<subdir>\n        \"\"\"\n        assert isinstance(path, bytes) or isinstance(path, str)\n        sep = b'/' if isinstance(path, bytes) else '/'\n        path = path.strip(sep) + sep\n\n        # Since we don't know which part of the \"path\" is the repopath,\n        # we need to do multiple search.\n        try:\n            startpos = 0\n            while True:\n                pos = path.index(sep, startpos)\n                try:\n                    # Run refresh only on first run.\n                    repo_obj = cls.get_repo(path[:pos], as_user, refresh=refresh and startpos == 0)\n                    break\n                except DoesNotExistError:\n                    # Raised when repo doesn't exists\n                    startpos = pos + 1\n            return repo_obj, path[pos + 1 :]\n        except ValueError:\n            raise DoesNotExistError(path)\n\n    @orm.reconstructor\n    def __init_on_load__(self):\n        RdiffRepo.__init__(\n            self, self.user.user_root, self.repopath, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING\n        )\n\n    @property\n    def displayname(self):\n        # Repository displayName is the \"repopath\" too.\n        return self.repopath.strip('/')\n\n    @property\n    def name(self):\n        # Repository name is the \"repopath\"\n        return self.repopath\n\n    @property\n    def owner(self):\n        return self.user.username\n\n    @hybrid_property\n    def keepdays(self):\n        try:\n            return int(self._keepdays) if self._keepdays else -1\n        except ValueError:\n            return -1\n\n    @keepdays.expression\n    def keepdays(cls):\n        return case(\n            (cls._keepdays.is_(None), -1),\n            (cls._keepdays == '', -1),\n            else_=cls._keepdays.cast(Integer),\n        )\n\n    @keepdays.setter\n    def keepdays(self, value):\n        self._keepdays = value\n\n    def delete(self, path=b''):\n        \"\"\"Properly remove the given repository by updating the user's repositories.\"\"\"\n        logger.info(\"deleting repository %s\", self)\n        # Remove data from disk\n        RdiffRepo.delete(self, path=path)\n        # Remove entry from database after deleting files.\n        # Otherwise, refresh will add this repo back.\n        return super().delete()\n\n    @validates('encoding')\n    def validate_encoding(self, key, value):\n        codec = encodings.search_function(value.lower())\n        if not codec:\n            raise ValueError(_('invalid encoding %s') % value)\n        return codec.name\n\n    @validates('maxage')\n    def validate_maxage(self, key, value):\n        int(value)\n        return value\n\n    @validates('_keepdays')\n    def validate_keepdays(self, key, value):\n        int(value)\n        return value\n\n    def __str__(self):\n        return \"RepoObject[%s, %s]\" % (self.userid, self.repopath)\n\n\n@event.listens_for(RepoObject.encoding, \"set\")\ndef encoding_set(target, value, oldvalue, initiator):\n    codec = encodings.search_function(value)\n    if codec:\n        target._encoding = codec\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"\nCreated on June 30, 2022\n\nModule to test `user` model.\n\n@author: Patrik Dufresne <patrik@ikus-soft.com>\n\"\"\"\nimport os\nfrom io import StringIO, open\nfrom unittest.mock import MagicMock\n\nimport cherrypy\nimport pkg_resources\nfrom parameterized import parameterized\n\nimport rdiffweb.test\nfrom rdiffweb.core import authorizedkeys\nfrom rdiffweb.core.model import DuplicateSSHKeyError, RepoObject, UserObject\nfrom rdiffweb.core.passwd import check_password\n\n\nclass UserObjectTest(rdiffweb.test.WebCase):\n    def _read_ssh_key(self):\n        \"\"\"Readthe pub key from test packages\"\"\"\n        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_publickey_ssh_rsa.pub')\n        with open(filename, 'r', encoding='utf8') as f:\n            return f.readline()\n\n    def _read_authorized_keys(self):\n        \"\"\"Read the content of test_authorized_keys\"\"\"\n        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_authorized_keys')\n        with open(filename, 'r', encoding='utf8') as f:\n            return f.read()\n\n    def setUp(self):\n        super().setUp()\n        self.listener = MagicMock()\n        cherrypy.engine.subscribe('access_token_added', self.listener.access_token_added, priority=50)\n        cherrypy.engine.subscribe('queue_mail', self.listener.queue_mail, priority=50)\n        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)\n        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)\n        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)\n        cherrypy.engine.subscribe('user_login', self.listener.user_login, priority=50)\n        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)\n\n    def tearDown(self):\n        cherrypy.engine.unsubscribe('access_token_added', self.listener.access_token_added)\n        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_mail)\n        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)\n        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)\n        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)\n        cherrypy.engine.unsubscribe('user_login', self.listener.user_login)\n        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)\n        return super().tearDown()\n\n    def test_add_user(self):\n        \"\"\"Add user to database.\"\"\"\n        userobj = UserObject.add_user('joe')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('joe'))\n        # Check if listener called\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_add_user_updated_by_listener(self):\n        \"\"\"Add user to database.\"\"\"\n        # Given a listener with side effet\n        def change_user_obj(userobj):\n            userobj.user_root = '/new/value'\n\n        self.listener.user_added.side_effect = change_user_obj\n        # When adding user\n        userobj = UserObject.add_user('joe')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('joe'))\n        # Then lister get called\n        self.listener.user_added.assert_called_once_with(userobj)\n        # Then object was updated by listener\n        self.assertEqual('/new/value', userobj.user_root)\n\n    def test_add_user_with_duplicate(self):\n        \"\"\"Add user to database.\"\"\"\n        user = UserObject.add_user('denise')\n        user.commit()\n        self.listener.user_added.reset_mock()\n        with self.assertRaises(ValueError):\n            UserObject.add_user('denise')\n        # Check if listener called\n        self.listener.user_added.assert_not_called()\n\n    def test_add_user_with_password(self):\n        \"\"\"Add user to database with password.\"\"\"\n        userobj = UserObject.add_user('jo', 'password')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('jo'))\n        # Check if listener called\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_delete_admin_user(self):\n        # Trying to delete admin user should raise an error.\n        userobj = UserObject.get_user('admin')\n        with self.assertRaises(ValueError):\n            userobj.delete()\n\n    def test_users(self):\n        # Check admin exists\n        self.assertEqual(1, UserObject.query.count())\n        # Create user.\n        user = UserObject.add_user('annik')\n        user.commit()\n        users = UserObject.query.all()\n        self.assertEqual(2, len(users))\n        self.assertEqual('annik', users[1].username)\n        # Then 2 user exists\n        self.assertEqual(2, UserObject.query.count())\n\n    def test_get_user(self):\n        # Create new user\n        user = UserObject.add_user('bernie', 'my-password')\n        user.user_root = self.testcases\n        user.role = UserObject.ADMIN_ROLE\n        user.email = 'bernie@gmail.com'\n        user.refresh_repos()\n        user.commit()\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))\n        user.repo_objs[0].maxage = -1\n        user.repo_objs[1].maxage = 3\n        user.commit()\n\n        # Get user record.\n        obj = UserObject.get_user('bernie')\n        self.assertIsNotNone(obj)\n        self.assertEqual('bernie', obj.username)\n        self.assertEqual('bernie@gmail.com', obj.email)\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in obj.repo_objs]))\n        self.assertEqual(self.testcases, obj.user_root)\n        self.assertEqual(True, obj.is_admin)\n        self.assertEqual(UserObject.ADMIN_ROLE, obj.role)\n\n        # Get repo object\n        self.assertEqual('broker-repo', obj.repo_objs[0].name)\n        self.assertEqual(-1, obj.repo_objs[0].maxage)\n        self.assertEqual('testcases', obj.repo_objs[1].name)\n        self.assertEqual(3, obj.repo_objs[1].maxage)\n\n    def test_get_user_with_invalid_user(self):\n        self.assertIsNone(UserObject.get_user('invalid'))\n\n    def test_get_set(self):\n        user = UserObject.add_user('larry', 'password')\n        user.add().commit()\n\n        self.assertEqual('', user.email)\n        self.assertEqual([], user.repo_objs)\n        self.assertEqual('', user.user_root)\n        self.assertEqual(False, user.is_admin)\n        self.assertEqual(UserObject.USER_ROLE, user.role)\n\n        user.user_root = self.testcases\n        user.refresh_repos()\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(user, {'user_root': ('', self.testcases)})\n        self.listener.user_attr_changed.reset_mock()\n        user = UserObject.get_user('larry')\n        user.role = UserObject.ADMIN_ROLE\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(\n            user, {'role': (UserObject.USER_ROLE, UserObject.ADMIN_ROLE)}\n        )\n        self.listener.user_attr_changed.reset_mock()\n        user = UserObject.get_user('larry')\n        user.email = 'larry@gmail.com'\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(user, {'email': ('', 'larry@gmail.com')})\n        self.listener.user_attr_changed.reset_mock()\n\n        self.assertEqual('larry@gmail.com', user.email)\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))\n        self.assertEqual(self.testcases, user.user_root)\n        self.assertEqual(True, user.is_admin)\n        self.assertEqual(UserObject.ADMIN_ROLE, user.role)\n\n    def test_set_role_null(self):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        user.add().commit()\n        # When trying to set the role to null\n        user.role = None\n        # Then an exception is raised\n        with self.assertRaises(Exception):\n            user.add().commit()\n\n    @parameterized.expand(\n        [\n            (-1, True),\n            (0, True),\n            (5, False),\n            (10, False),\n            (15, False),\n        ]\n    )\n    def test_is_admin(self, role, expected_is_admin):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        # When setting the role value\n        user.role = role\n        user.commit()\n        # Then the is_admin value get updated too\n        self.assertEqual(expected_is_admin, user.is_admin)\n\n    @parameterized.expand(\n        [\n            (-1, True),\n            (0, True),\n            (5, True),\n            (10, False),\n            (15, False),\n        ]\n    )\n    def test_is_maintainer(self, role, expected_is_maintainer):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        # When setting the role value\n        user.role = role\n        user.commit()\n        # Then the is_admin value get updated too\n        self.assertEqual(expected_is_maintainer, user.is_maintainer)\n\n    def test_set_password_update(self):\n        # Given a user in database with a password\n        userobj = UserObject.add_user('annik', 'password')\n        userobj.commit()\n        self.listener.user_password_changed.reset_mock()\n        # When updating the user's password\n        userobj.set_password('new_password')\n        userobj.commit()\n        # Then password is SSHA\n        self.assertTrue(check_password('new_password', userobj.hash_password))\n        # Check if listener called\n        self.listener.user_password_changed.assert_called_once_with(userobj)\n\n    def test_delete_user(self):\n        # Given an existing user in database\n        userobj = UserObject.add_user('vicky')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('vicky'))\n        # When deleting that user\n        userobj.delete()\n        userobj.commit()\n        # Then user it no longer in database\n        self.assertIsNone(UserObject.get_user('vicky'))\n        # Then listner was called\n        self.listener.user_deleted.assert_called_once_with('vicky')\n\n    def test_set_password_empty(self):\n        \"\"\"Expect error when trying to update password of invalid user.\"\"\"\n        userobj = UserObject.add_user('john')\n        userobj.commit()\n        with self.assertRaises(ValueError):\n            self.assertFalse(userobj.set_password(''))\n\n    def test_disk_quota(self):\n        \"\"\"\n        Just make a call to the function.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.disk_quota\n\n    def test_disk_usage(self):\n        \"\"\"\n        Just make a call to the function.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n        disk_usage = userobj.disk_usage\n        self.assertIsInstance(disk_usage, int)\n\n    def test_add_authorizedkey_without_file(self):\n        \"\"\"\n        Add an ssh key for a user without an authorizedkey file.\n        \"\"\"\n        # Read the pub key\n        key = self._read_ssh_key()\n        # Add the key to the user\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n\n        # validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(1, len(keys), \"expecting one key\")\n        self.assertEqual(\"3c:99:ed:a7:82:a8:71:09:2c:15:3d:78:4a:8c:11:99\", keys[0].fingerprint)\n\n    def test_add_authorizedkey_duplicate(self):\n        # Read the pub key\n        key = self._read_ssh_key()\n        # Add the key to the user\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n        # Add the same key\n        with self.assertRaises(DuplicateSSHKeyError):\n            userobj.add_authorizedkey(key)\n            userobj.commit()\n\n    def test_add_authorizedkey_with_file(self):\n        \"\"\"\n        Add an ssh key for a user with an authorizedkey file.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n\n        # Create empty authorized_keys file\n        os.mkdir(os.path.join(userobj.user_root, '.ssh'))\n        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')\n        open(filename, 'a').close()\n\n        # Read the pub key\n        key = self._read_ssh_key()\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n\n        # Validate\n        with open(filename, 'r') as fh:\n            self.assertEqual(key, fh.read())\n\n    def test_delete_authorizedkey_without_file(self):\n        \"\"\"\n        Remove an ssh key for a user without authorizedkey file.\n        \"\"\"\n        # Update user with ssh keys.\n        data = self._read_authorized_keys()\n        userobj = UserObject.get_user(self.USERNAME)\n        for k in authorizedkeys.read(StringIO(data)):\n            try:\n                userobj.add_authorizedkey(k.getvalue())\n            except ValueError:\n                # Some ssh key in the testing file are not valid.\n                pass\n\n        # Get the keys\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(2, len(keys))\n\n        # Remove a key\n        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")\n        userobj.commit()\n\n        # Validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(1, len(keys))\n\n    def test_delete_authorizedkey_with_file(self):\n        \"\"\"\n        Remove an ssh key for a user with authorizedkey file.\n        \"\"\"\n        # Create authorized_keys file\n        data = self._read_authorized_keys()\n        userobj = UserObject.get_user(self.USERNAME)\n        os.mkdir(os.path.join(userobj.user_root, '.ssh'))\n        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')\n        with open(filename, 'w') as f:\n            f.write(data)\n\n        # Get the keys\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(5, len(keys))\n\n        # Remove a key\n        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")\n\n        # Validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(4, len(keys))\n\n    def test_repo_objs(self):\n        # Given a user with a list of repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        repos = sorted(userobj.repo_objs, key=lambda r: r.name)\n        self.assertEqual(['broker-repo', 'testcases'], [r.name for r in repos])\n        # When deleting a repository empty list\n        repos[1].delete()\n        repos[1].commit()\n        # Then the repository is removed from the list.\n        self.assertEqual(['broker-repo'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_without_delete(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        RepoObject.query.delete()\n        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()\n        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))\n        # When updating the repository list without deletion\n        userobj.refresh_repos()\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_with_delete(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        RepoObject.query.delete()\n        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()\n        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))\n        # When updating the repository list without deletion\n        userobj.refresh_repos(delete=True)\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        userobj.expire()\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_with_single_repo(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.user_root = os.path.join(self.testcases, 'testcases')\n        # When updating the repository list without deletion\n        userobj.refresh_repos(delete=True)\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        userobj.expire()\n        self.assertEqual([''], sorted([r.name for r in userobj.repo_objs]))\n\n\nclass UserObjectWithAdminPassword(rdiffweb.test.WebCase):\n\n    # password: test\n    default_config = {'admin-password': '{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e'}\n\n    def setUp(self):\n        # Do nothing - We need to skip the default setup to avoid deleting the records.\n        pass\n\n    def test_create_admin_user(self):\n        # Given admin-password is configure\n        # When database get created\n        # Then admin user get created with 'test' password\n        userobj = UserObject.get_user(self.USERNAME)\n        self.assertIsNotNone(userobj)\n        self.assertEqual('{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e', userobj.hash_password)\n        self.assertTrue(check_password('test', userobj.hash_password))\n\n        # Given admin-password is configure\n        # When trying to update admin password\n        # Then an exception is raised\n        userobj = UserObject.get_user(self.USERNAME)\n        with self.assertRaises(ValueError):\n            userobj.set_password('newpassword')\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport datetime\nimport logging\nimport os\nfrom collections import OrderedDict, namedtuple\nfrom io import StringIO\n\nimport cherrypy\nimport humanfriendly\nimport jinja2\nfrom jinja2 import Environment, PackageLoader\nfrom jinja2.filters import do_mark_safe\nfrom jinja2.loaders import ChoiceLoader\n\nfrom rdiffweb.core import librdiff, rdw_helpers\nfrom rdiffweb.core.model import RepoObject\nfrom rdiffweb.tools import i18n\nfrom rdiffweb.tools.i18n import ugettext as _\n\n# Define the logger\nlogger = logging.getLogger(__name__)\n\n_ParentEntry = namedtuple(\"_ParentEntry\", 'path,display_name')\n\n\ndef attrib(**kwargs):\n    \"\"\"Generate an attribute list from the keyword argument.\"\"\"\n\n    def _escape(text):\n        if isinstance(text, bytes):\n            text = text.decode('ascii', 'replace')\n        text = str(text)\n        if \"&\" in text:\n            text = text.replace(\"&\", \"&amp;\")\n        if \"<\" in text:\n            text = text.replace(\"<\", \"&lt;\")\n        if \">\" in text:\n            text = text.replace(\">\", \"&gt;\")\n        if \"\\\"\" in text:\n            text = text.replace(\"\\\"\", \"&quot;\")\n        return text\n\n    def _format(key, val):\n        # Don't write the attribute if value is False\n        if val is False:\n            return\n        if val is True:\n            yield str(key)\n            return\n        if isinstance(val, list):\n            val = ' '.join([_escape(v) for v in val if v])\n        else:\n            val = _escape(val)\n        if not val:\n            return\n        yield '%s=\"%s\"' % (str(key), val)\n\n    first = True\n    buf = StringIO()\n    for key, val in sorted(kwargs.items()):\n        for t in _format(key, val):\n            if not first:\n                buf.write(' ')\n            first = False\n            buf.write(t)\n    data = buf.getvalue()\n    buf.close()\n    return do_mark_safe(data)\n\n\ndef do_filter(sequence, attribute_name):\n    \"\"\"Filter sequence of objects.\"\"\"\n    return [\n        x\n        for x in sequence\n        if (isinstance(x, dict) and attribute_name in x and x[attribute_name])\n        or (hasattr(x, attribute_name) and getattr(x, attribute_name))\n    ]\n\n\ndef do_format_lastupdated(value, now=None):\n    \"\"\"\n    Used to format date as \"Updated 10 minutes ago\".\n\n    Value could be a RdiffTime or an epoch as int.\n    \"\"\"\n    if not value:\n        return \"\"\n    now = librdiff.RdiffTime(now)\n    if isinstance(value, librdiff.RdiffTime):\n        delta = now.epoch() - value.epoch()\n    elif isinstance(value, datetime.datetime):\n        delta = now.epoch() - value.timestamp()\n    else:\n        delta = now.epoch() - value\n    delta = datetime.timedelta(seconds=delta)\n    if delta.days > 365:\n        return _('%d years ago') % (delta.days / 365)\n    if delta.days > 60:\n        return _('%d months ago') % (delta.days / 30)\n    if delta.days > 7:\n        return _('%d weeks ago') % (delta.days / 7)\n    elif delta.days > 1:\n        return _('%d days ago') % delta.days\n    elif delta.seconds > 3600:\n        return _('%d hours ago') % (delta.seconds / 3600)\n    elif delta.seconds > 60:\n        return _('%d minutes ago') % (delta.seconds / 60)\n    return _('%d seconds ago') % delta.seconds\n\n\ndef create_repo_tree(repos):\n    \"\"\"\n    Organise the repositories into a tree.\n    \"\"\"\n    repos = sorted(repos, key=lambda r: r.display_name)\n    repo_tree = OrderedDict()\n    for repo in repos:\n        h = repo_tree\n        key = repo.display_name.strip('/').split('/')\n        for p in key[:-1]:\n            if p in h and isinstance(h[p], RepoObject):\n                h[p] = {'.': h[p]}\n            h = h.setdefault(p, {})\n        h[key[-1]] = repo\n    return repo_tree\n\n\ndef list_parents(repo, path):\n    assert isinstance(path, bytes)\n    # Build the parameters\n    # Build \"parent directories\" links\n    parents = [_ParentEntry(b'', repo.display_name)]\n    parent_path_b = b''\n    for part_b in path.split(b'/'):\n        if part_b:\n            parent_path_b = os.path.join(parent_path_b, part_b)\n            display_name = repo._decode(librdiff.unquote(part_b))\n            parents.append(_ParentEntry(parent_path_b, display_name))\n    return parents\n\n\ndef url_for(*args, **kwargs):\n    \"\"\"\n    Generate a url for the given endpoint, path (*args) with parameters (**kwargs)\n\n    This could be used to generate a path with userobject and repo object\n\n    \"\"\"\n    path = \"\"\n    for chunk in args:\n        if not chunk:\n            continue\n        if hasattr(chunk, 'owner') and hasattr(chunk, 'path'):\n            # This is a RepoObject\n            path += \"/\"\n            path += chunk.owner\n            path += \"/\"\n            path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))\n        elif hasattr(chunk, 'path'):\n            # This is a DirEntry\n            if chunk.path:\n                path += \"/\"\n                path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))\n        elif chunk and isinstance(chunk, bytes):\n            path += \"/\"\n            path += rdw_helpers.quote_url(chunk.strip(b\"/\"))\n        elif chunk and isinstance(chunk, str):\n            path += \"/\"\n            path += chunk.strip(\"/\")\n        else:\n            raise ValueError('invalid positional arguments, url_for accept str, bytes or RepoPath: %r' % chunk)\n    # Sort the arguments to have predictable results.\n    qs = [(k, v.epoch() if hasattr(v, 'epoch') else v) for k, v in sorted(kwargs.items()) if v is not None]\n    return cherrypy.url(path=path, qs=qs)\n\n\nclass TemplateManager(object):\n    \"\"\"\n    Uses to generate HTML page from template using Jinja2 templating.\n    \"\"\"\n\n    def __init__(self):\n        # Load all the templates from /templates directory\n        loader = ChoiceLoader([PackageLoader('rdiffweb', 'templates')])\n\n        # With and autoescape are included by dfault in Jinja2>=3\n        extensions = ['jinja2.ext.i18n']\n        if jinja2.__version__[0] <= '2':\n            extensions.extend(['jinja2.ext.with_', 'jinja2.ext.autoescape'])\n        self.jinja_env = Environment(\n            loader=loader,\n            auto_reload=True,\n            autoescape=True,\n            extensions=extensions,\n        )\n\n        # Register filters\n        self.jinja_env.filters['filter'] = do_filter\n        self.jinja_env.filters['lastupdated'] = do_format_lastupdated\n        self.jinja_env.filters['filesize'] = lambda x: humanfriendly.format_size(x, binary=True)\n\n        # Register method\n        self.jinja_env.globals['attrib'] = attrib\n        self.jinja_env.globals['create_repo_tree'] = create_repo_tree\n        self.jinja_env.globals['list_parents'] = list_parents\n        self.jinja_env.globals['url_for'] = url_for\n\n    def compile_template(self, template_name, **kwargs):\n        \"\"\"Very simple implementation to render template using jinja2.\n        `templateName`\n            The filename to be used as template.\n        `kwargs`\n            The arguments to be passed to the template.\n        \"\"\"\n        logger.log(1, \"compiling template [%s]\", template_name)\n        self.jinja_env.install_gettext_callables(i18n.ugettext, i18n.ungettext, newstyle=True)\n        template = self.jinja_env.get_template(template_name)\n        data = template.render(kwargs)\n        logger.log(1, \"template [%s] compiled\", template_name)\n        return data\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nCreated on Oct 3, 2015\n\nModule used to test the librdiff.\n\n@author: Patrik Dufresne\n\"\"\"\nimport datetime\nimport os\nimport shutil\nimport tarfile\nimport tempfile\nimport time\nimport unittest\nfrom inspect import isclass\nfrom unittest.case import skipIf\n\nimport pkg_resources\nfrom parameterized import parameterized\n\nfrom rdiffweb.core.librdiff import (\n    AccessDeniedError,\n    DoesNotExistError,\n    FileStatisticsEntry,\n    IncrementEntry,\n    RdiffDirEntry,\n    RdiffRepo,\n    RdiffTime,\n    SessionStatisticsEntry,\n    rdiff_backup_version,\n    unquote,\n)\n\n\nclass MockRdiffRepo(RdiffRepo):\n    def __init__(self):\n        p = bytes(pkg_resources.resource_filename('rdiffweb.core', 'tests'), encoding='utf-8')  # @UndefinedVariable\n        RdiffRepo.__init__(self, os.path.dirname(p), os.path.basename(p), encoding='utf-8')\n        self.root_path = MockDirEntry(self)\n\n\nclass MockDirEntry(RdiffDirEntry):\n    def __init__(self, repo):\n        self._repo = repo\n        self.path = b''\n\n\nclass IncrementEntryTest(unittest.TestCase):\n    def test_init(self):\n        increment = IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')\n        self.assertEqual(b'my_filename.txt', increment.name)\n        self.assertEqual(RdiffTime(1414967021), increment.date)\n        self.assertEqual(b'.diff.gz', increment.suffix)\n\n    def test_extract_date(self):\n        self.assertEqual(\n            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')\n        )\n        self.assertEqual(\n            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17-23-41-05-00.diff.gz')\n        )\n        # Check if date with quoted characther are proerply parsed.\n        # On NTFS, colon (:) are not supported.\n        self.assertEqual(\n            RdiffTime(1483443123),\n            IncrementEntry._extract_date(b'my_filename.txt.2017-01-03T06;05832;05803-05;05800.diff.gz'),\n        )\n\n\nclass RdiffDirEntryTest(unittest.TestCase):\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n\n    def test_init(self):\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, [])\n        self.assertFalse(entry.isdir)\n        self.assertFalse(entry.exists)\n        self.assertEqual(os.path.join(b'my_filename.txt'), entry.path)\n        self.assertEqual(os.path.join(self.repo.full_path, b'my_filename.txt'), entry.full_path)\n\n    def test_change_dates(self):\n        \"\"\"Check if dates are properly sorted.\"\"\"\n        increments = [\n            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),\n            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),\n            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),\n        ]\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, increments)\n\n        self.assertEqual(\n            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates\n        )\n\n    def test_change_dates_with_exists(self):\n        \"\"\"Check if dates are properly sorted.\"\"\"\n        increments = [\n            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),\n            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),\n            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),\n        ]\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', True, increments)\n\n        self.assertEqual(\n            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates\n        )\n\n    def test_display_name(self):\n        \"\"\"Check if display name is unquoted and unicode.\"\"\"\n        entry = RdiffDirEntry(self.repo, b'my_dir', True, [])\n        self.assertEqual('my_dir', entry.display_name)\n\n        entry = RdiffDirEntry(self.repo, b'my;090dir', True, [])\n        self.assertEqual('myZdir', entry.display_name)\n\n    def test_file_size(self):\n        # Given a dir increment\n        increments = [\n            IncrementEntry(\n                bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial.2014-11-05T16:05:07-05:00.dir', encoding='utf-8'),\n            )\n        ]\n        entry = RdiffDirEntry(\n            self.repo, bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'), False, increments\n        )\n        # When getting the file_size\n        # Then the size is 0\n        self.assertEqual(-1, entry.file_size)\n\n    def test_file_size_without_stats(self):\n        increments = [IncrementEntry(b'my_file.2014-11-05T16:04:30-05:00.dir')]\n        entry = RdiffDirEntry(self.repo, b'my_file', False, increments)\n        self.assertEqual(-1, entry.file_size)\n\n\nclass FileErrorTest(unittest.TestCase):\n    def test_init(self):\n        e = DoesNotExistError('some/path')\n        self.assertEqual('some/path', str(e))\n\n        e = AccessDeniedError('some/path')\n        self.assertEqual('some/path', str(e))\n\n\nclass FileStatisticsEntryTest(unittest.TestCase):\n    \"\"\"\n    Test the file statistics entry.\n    \"\"\"\n\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n\n    def test_get_mirror_size(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')\n        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(143, size)\n\n    def test_get_source_size(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')\n        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(286, size)\n\n    def test_get_mirror_size_gzip(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')\n        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(143, size)\n\n    def test_get_source_size_gzip(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')\n        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(286, size)\n\n\nclass LogEntryTest(unittest.TestCase):\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n        self.root_path = self.repo.root_path\n\n    @parameterized.expand(\n        [\n            (\n                'with_uncompress',\n                '2015-11-19T07:27:46-05:00',\n                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',\n            ),\n            (\n                'with_compress',\n                '2015-11-20T07:27:46-05:00',\n                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',\n            ),\n        ]\n    )\n    def test_errors_tail(self, unused, date, expected_content):\n        entry = self.repo.error_log[RdiffTime(date)]\n        self.assertIsNotNone(entry)\n        self.assertEqual(entry.tail(), expected_content)\n\n\nclass RdiffRepoTest(unittest.TestCase):\n    def setUp(self):\n        # Extract 'testcases.tar.gz'\n        testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable\n        self.temp_dir = tempfile.mkdtemp(prefix='rdiffweb_tests_')\n        tarfile.open(testcases).extractall(self.temp_dir)\n        # Define location of testcases\n        self.testcases_dir = os.path.normpath(os.path.join(self.temp_dir, 'testcases'))\n        self.testcases_dir = self.testcases_dir.encode('utf8')\n        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')\n\n    def tearDown(self):\n        shutil.rmtree(self.temp_dir.encode('utf8'), True)\n\n    def test_init(self):\n        self.assertEqual('testcases', self.repo.display_name)\n\n    def test_init_with_absolute(self):\n        self.repo = RdiffRepo(self.temp_dir, '/testcases', encoding='utf-8')\n        self.assertEqual('testcases', self.repo.display_name)\n\n    def test_init_with_invalid(self):\n        self.repo = RdiffRepo(self.temp_dir, 'invalid', encoding='utf-8')\n        self.assertEqual('failed', self.repo.status[0])\n        self.assertEqual(None, self.repo.last_backup_date)\n        self.assertEqual(b'invalid', self.repo.path)\n        self.assertEqual('invalid', self.repo.display_name)\n\n    @parameterized.expand(\n        [\n            (\n                \"with_root\",\n                b\"/\",\n                'testcases',\n                b'',\n                True,\n                True,\n                True,\n                -1,\n                [\n                    '2014-11-01T15:49:47-04:00',\n                    '2014-11-01T15:50:26-04:00',\n                    '2014-11-01T15:50:48-04:00',\n                    '2014-11-01T15:51:15-04:00',\n                    '2014-11-01T15:51:29-04:00',\n                    '2014-11-01T16:30:22-04:00',\n                    '2014-11-01T16:30:50-04:00',\n                    '2014-11-01T18:07:19-04:00',\n                    '2014-11-01T20:12:45-04:00',\n                    '2014-11-01T20:18:11-04:00',\n                    '2014-11-01T20:51:18-04:00',\n                    '2014-11-02T09:16:43-05:00',\n                    '2014-11-02T09:50:53-05:00',\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:01:02-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-01-20T10:42:21-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_dir\",\n                b\"Subdirectory\",\n                'Subdirectory',\n                b'Subdirectory',\n                True,\n                True,\n                False,\n                -1,\n                [\n                    '2014-11-05T16:04:55-05:00',\n                    '2016-01-20T10:42:21-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_dir_utf8_char\",\n                b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\",\n                'Fold\u00e8r with \u00e9ncod\u00efng',\n                b'Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:04:55-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_dir\",\n                b\"Revisions\",\n                'Revisions',\n                b'Revisions',\n                True,\n                True,\n                False,\n                -1,\n                [\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_file\",\n                b'Revisions/Data',\n                'Data',\n                b'Revisions/Data',\n                True,\n                False,\n                False,\n                9,\n                [\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_broken_symlink\",\n                b'BrokenSymlink',\n                'BrokenSymlink',\n                b'BrokenSymlink',\n                True,\n                False,\n                False,\n                7,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;090 to quote',\n                'Char Z to quote',\n                b'Char ;090 to quote',\n                False,\n                True,\n                False,\n                -1,\n                ['2014-11-01T18:07:19-04:00', '2014-11-01T20:18:11-04:00', '2014-11-03T19:04:57-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;059090 to quote',\n                'Char ;090 to quote',\n                b'Char ;059090 to quote',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-03T15:46:47-05:00', '2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;059059090 to quote',\n                'Char ;059090 to quote',\n                b'Char ;059059090 to quote',\n                False,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:04:55-05:00', '2016-01-20T10:42:21-05:00'],\n            ),\n            (\n                \"with_loop_symlink\",\n                b'Subdirectory/LoopSymlink',\n                'LoopSymlink',\n                b'Subdirectory/LoopSymlink',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_subdir_symlink\",\n                b'SymlinkToSubdirectory',\n                'SymlinkToSubdirectory',\n                b'SymlinkToSubdirectory',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n        ]\n    )\n    def test_fstat(self, unused, input, display_name, path, exists, isdir, isroot, file_size, change_dates):\n        dir_entry = self.repo.fstat(input)\n        self.assertEqual(display_name, dir_entry.display_name)\n        self.assertEqual(path, dir_entry.path)\n        self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)\n        self.assertEqual(exists, dir_entry.exists)\n        self.assertEqual(isdir, dir_entry.isdir)\n        self.assertEqual(isroot, dir_entry.isroot)\n        self.assertEqual(file_size, dir_entry.file_size)\n        self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))\n        # For consistency, check if the same value are retreived using listdir\n        if not isroot:\n            parent_dir = os.path.dirname(input)\n            children = self.repo.listdir(parent_dir)\n            dir_entry = next(c for c in children if c.path == input)\n            self.assertEqual(display_name, dir_entry.display_name)\n            self.assertEqual(path, dir_entry.path)\n            self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)\n            self.assertEqual(exists, dir_entry.exists)\n            self.assertEqual(isdir, dir_entry.isdir)\n            self.assertEqual(isroot, dir_entry.isroot)\n            self.assertEqual(file_size, dir_entry.file_size)\n            self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))\n\n    def test_fstat_outside_repo(self):\n        with self.assertRaises(AccessDeniedError):\n            self.repo.fstat(b\"../\")\n\n    @parameterized.expand(\n        [\n            (\n                \"with_root\",\n                b\"\",\n                [\n                    '<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',\n                    'BrokenSymlink',\n                    'Char ;059090 to quote',\n                    'Char ;090 to quote',\n                    'Char Z to quote',\n                    'DIR\ufffd',\n                    'Fichier @ <root>',\n                    'Fichier avec non asci char \ufffdvelyne M\ufffdre.txt',\n                    'Revisions',\n                    'R\u00e9pertoire (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',\n                    'R\u00e9pertoire Existant',\n                    'R\u00e9pertoire Supprim\u00e9',\n                    'Subdirectory',\n                    'SymlinkToSubdirectory',\n                    'test\\\\test',\n                    '\uc774\ub8e8\ub9c8 YIRUMA - River Flows in You.mp3',\n                ],\n            ),\n            (\"with_children utf8_char\", b\"Subdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\", ['my file']),\n            (\"with_dir\", b\"Revisions\", ['Data']),\n            (\"with_file\", b\"Revisions/Data\", DoesNotExistError),\n            (\"with_broken_symlink\", b\"BrokenSymlink\", DoesNotExistError),\n            (\"with_loop_symlink\", b\"Subdirectory/LoopSymlink\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n            (\"with_subdir_symlink\", b\"SymlinkToSubdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n        ]\n    )\n    def test_listdir(self, unused, path, listdir):\n        if isclass(listdir) and issubclass(listdir, Exception):\n            with self.assertRaises(listdir):\n                self.repo.listdir(path)\n            return\n        self.assertEqual(listdir, sorted([d.display_name for d in self.repo.listdir(path)]))\n\n    def test_listdir_outside_repo(self):\n        with self.assertRaises(AccessDeniedError):\n            self.repo.listdir(b\"../\")\n\n    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")\n    def test_listdir_empty_folder(self):\n        # Given a folder without data\n        self.repo.delete(b\"Revisions/Data\")\n        # When listing entries\n        entries = self.repo.listdir(b\"Revisions\")\n        # Then the list is empty.\n        self.assertEqual([], entries)\n\n    def test_listdir_attributes(self):\n        children = self.repo.listdir(b\"Revisions\")\n        self.assertEqual(1, len(children))\n        dir_entry = children[0]\n        self.assertEqual('Data', dir_entry.display_name)\n        self.assertEqual(b'Revisions/Data', dir_entry.path)\n        self.assertEqual(os.path.join(self.testcases_dir, b'Revisions/Data'), dir_entry.full_path)\n        self.assertEqual(True, dir_entry.exists)\n        self.assertEqual(False, dir_entry.isdir)\n        self.assertEqual(False, dir_entry.isroot)\n        self.assertEqual(9, dir_entry.file_size)\n        self.assertEqual(\n            [\n                RdiffTime('2014-11-03T19:04:57-05:00'),\n                RdiffTime('2014-11-05T16:04:30-05:00'),\n                RdiffTime('2014-11-05T16:04:55-05:00'),\n                RdiffTime('2014-11-05T16:05:07-05:00'),\n                RdiffTime('2016-02-02T16:30:40-05:00'),\n            ],\n            list(dir_entry.change_dates),\n        )\n\n    def test_with_rdiff_backup_data(self):\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(b'rdiff-backup-data')\n        with self.assertRaises(DoesNotExistError):\n            self.repo.listdir(b'rdiff-backup-data')\n\n    def test_with_invalid(self):\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(b'invalid')\n        with self.assertRaises(DoesNotExistError):\n            self.repo.listdir(b'invalid')\n\n    def test_status(self):\n        status = self.repo.status\n        self.assertEqual('ok', status[0])\n        self.assertEqual('', status[1])\n\n    def test_status_access_denied_current_mirror(self):\n        # Skip test if running as root. Because root as access to everything.\n        if os.geteuid() == 0:\n            return\n        # Change the permissions of the files.\n        os.chmod(\n            os.path.join(self.testcases_dir, b'rdiff-backup-data', b'current_mirror.2016-02-02T16:30:40-05:00.data'),\n            0000,\n        )\n        # Create repo again to query status\n        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')\n        status = self.repo.status\n        self.assertEqual('failed', status[0])\n\n    def test_status_access_denied_rdiff_backup_data(self):\n        # Skip test if running as root. Because root as access to everything.\n        if os.geteuid() == 0:\n            return\n        # Change the permissions of the files.\n        os.chmod(os.path.join(self.testcases_dir, b'rdiff-backup-data'), 0000)\n        # Query status.\n        self.repo = RdiffRepo(self.temp_dir, b'testcases', encoding='utf-8')\n        status = self.repo.status\n        self.assertEqual('failed', status[0])\n        # Make sure history entry doesn't raise error\n        list(self.repo.mirror_metadata)\n\n    def test_remove_older(self):\n        # Given a repository with history\n        self.assertEqual(22, len(self.repo.mirror_metadata))\n        # When removing older then 1D\n        self.repo.remove_older(1)\n        # Then all history get deleted up to one\n        self.assertEqual(1, len(self.repo.mirror_metadata))\n\n    @parameterized.expand(\n        [\n            (\"with_root\", b'/', 1454448640, 'zip', 'testcases.zip', b'PK\\x03\\x04'),\n            (\"with_zip\", b'Revisions', 1454448640, 'zip', 'Revisions.zip', b'PK\\x03\\x04'),\n            (\"with_tar\", b'Revisions', 1454448640, 'tar', 'Revisions.tar', b'././@PaxHeader'),\n            (\"with_tar_gz\", b'Revisions', 1454448640, 'tar.gz', 'Revisions.tar.gz', b'\\x1f\\x8b'),\n            (\"with_tar_bz2\", b'Revisions', 1454448640, 'tar.bz2', 'Revisions.tar.bz2', b'BZh'),\n            (\"with_none_file\", b'Revisions/Data', 1454448640, None, 'Data', b'Version3\\n'),\n            (\"with_raw_file\", b'Revisions/Data', 1454448640, 'raw', 'Data', b'Version3\\n'),\n            (\"with_zip_file\", b'Revisions/Data', 1454448640, 'zip', 'Data.zip', b'PK\\x03\\x04'),\n        ]\n    )\n    def test_restore(self, unused, path, restore_as_of, kind, expected_filename, expected_startswith):\n        filename, stream = self.repo.restore(path, restore_as_of=restore_as_of, kind=kind)\n        self.assertEqual(expected_filename, filename)\n        data = stream.read()\n        self.assertTrue(data.startswith(expected_startswith))\n\n    def test_unquote(self):\n        self.assertEqual(b'Char ;090 to quote', unquote(b'Char ;059090 to quote'))\n\n    def test_error_log_range(self):\n        logs = self.repo.error_log[0:1]\n        self.assertEqual(1, len(logs))\n        self.assertEqual(\"\", self.repo.error_log[0].read())\n\n    def test_backup_log(self):\n        self.assertEqual(\"\", self.repo.backup_log.read())\n\n    def test_restore_log(self):\n        self.assertEqual(\n            self.repo.restore_log.read(),\n            \"\"\"Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpKDNO4t/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpnG33kc/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpGUEHJC/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBlFPsW/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpkfCejo/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmphXpFnS as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_udS97a/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_LL4rCm/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_zpYgT3/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_7H93yy/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_Xe2CfG/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_rHFERA/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpF7rSar/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpgHTL2j/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpVo1u4Z/root as it was as of Wed Jan 20 10:42:21 2016.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBRxRxe/root as it was as of Wed Jan 20 10:42:21 2016.\n\"\"\",\n        )\n\n    @parameterized.expand(\n        [\n            (\n                \"with_idx_1\",\n                1,\n                '2014-11-01T15:50:26-04:00',\n            ),\n            (\n                \"with_idx_2\",\n                2,\n                '2014-11-01T15:50:48-04:00',\n            ),\n            (\n                \"with_idx_3\",\n                3,\n                '2014-11-01T15:51:15-04:00',\n            ),\n            (\n                \"with_neg_idx_1\",\n                -1,\n                '2016-02-02T16:30:40-05:00',\n            ),\n            (\n                \"with_date\",\n                RdiffTime('2016-02-02T16:30:40-05:00'),\n                '2016-02-02T16:30:40-05:00',\n            ),\n            (\n                \"with_slice_idx\",\n                slice(0, 2),\n                [\n                    '2014-11-01T15:49:47-04:00',\n                    '2014-11-01T15:50:26-04:00',\n                ],\n            ),\n            (\n                \"with_slice_date_start\",\n                slice(RdiffTime('2016-01-20T10:42:21-05:00'), None),\n                ['2016-01-20T10:42:21-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_slice_date_start_stop\",\n                slice(\n                    RdiffTime('2014-11-02T17:00:00-05:00'),\n                    RdiffTime('2014-11-04T00:00:00-05:00'),\n                ),\n                [\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                ],\n            ),\n            (\n                \"with_slice_date_start_stop_exact_match\",\n                slice(RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')),\n                [\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                ],\n            ),\n            (\n                \"with_slice_invalid_idx\",\n                slice(100, 120),\n                [],\n            ),\n            (\n                \"with_keyerror_date\",\n                RdiffTime('2022-11-03T15:46:47-05:00'),\n                KeyError,\n            ),\n            (\n                \"with_keyerror_int\",\n                1024,\n                KeyError,\n            ),\n        ]\n    )\n    def test_session_statistics(self, unsed, value, expected_value):\n        if isinstance(expected_value, list):\n            self.assertEqual(expected_value, [str(o.date) for o in self.repo.session_statistics[value]])\n        elif isclass(expected_value) and issubclass(expected_value, Exception):\n            with self.assertRaises(expected_value):\n                self.repo.session_statistics[value]\n        else:\n            self.assertEqual(expected_value, str(self.repo.session_statistics[value].date))\n\n    @parameterized.expand(\n        [\n            (\"with_file\", b'Revisions/Data'),\n            (\"with_folder\", b'Subdirectory'),\n            (\"with_folder_ending_slash\", b'Subdirectory/'),\n            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\"),\n            (\"with_broken_symlink\", b'BrokenSymlink'),\n        ]\n    )\n    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")\n    def test_delete_file(self, unused, path):\n        # Delete a file\n        self.repo.delete(path)\n        # Check file is deleted\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(path)\n\n\nclass SessionStatisticsEntryTest(unittest.TestCase):\n    def test_getattr(self):\n        \"\"\"\n        Check how a session statistic is read.\n        \"\"\"\n        entry = SessionStatisticsEntry(MockRdiffRepo(), b'session_statistics.2014-11-02T09:16:43-05:00.data')\n        self.assertEqual(1414937803.00, entry.starttime)\n        self.assertEqual(1414937764.82, entry.endtime)\n        self.assertAlmostEqual(-38.18, entry.elapsedtime, delta=-0.01)\n        self.assertEqual(14, entry.sourcefiles)\n        self.assertEqual(3666973, entry.sourcefilesize)\n        self.assertEqual(13, entry.mirrorfiles)\n        self.assertEqual(30242, entry.mirrorfilesize)\n        self.assertEqual(1, entry.newfiles)\n        self.assertEqual(3636731, entry.newfilesize)\n        self.assertEqual(0, entry.deletedfiles)\n        self.assertEqual(0, entry.deletedfilesize)\n        self.assertEqual(1, entry.changedfiles)\n        self.assertEqual(0, entry.changedsourcesize)\n        self.assertEqual(0, entry.changedmirrorsize)\n        self.assertEqual(2, entry.incrementfiles)\n        self.assertEqual(0, entry.incrementfilesize)\n        self.assertEqual(3636731, entry.totaldestinationsizechange)\n        self.assertEqual(0, entry.errors)\n\n\nclass RdiffTimeTest(unittest.TestCase):\n    def test_add(self):\n        \"\"\"Check if addition with timedelta is working as expected.\"\"\"\n        # Without timezone\n        self.assertEqual(\n            RdiffTime('2014-11-08T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') + datetime.timedelta(days=3)\n        )\n        # With timezone\n        self.assertEqual(\n            RdiffTime('2014-11-08T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') + datetime.timedelta(days=3)\n        )\n\n    def test_compare(self):\n        \"\"\"Check behaviour of comparison operator operator.\"\"\"\n\n        self.assertTrue(RdiffTime('2014-11-07T21:04:30-04:00') < RdiffTime('2014-11-08T21:04:30Z'))\n        self.assertTrue(RdiffTime('2014-11-08T21:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))\n        self.assertFalse(RdiffTime('2014-11-08T22:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))\n\n        self.assertFalse(RdiffTime('2014-11-07T21:04:30-04:00') > RdiffTime('2014-11-08T21:04:30Z'))\n        self.assertFalse(RdiffTime('2014-11-08T21:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))\n        self.assertTrue(RdiffTime('2014-11-08T22:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))\n\n    def test_init_now(self):\n        t0 = RdiffTime()\n        self.assertAlmostEqual(int(time.time()), t0.epoch(), delta=5000)\n\n    @parameterized.expand(\n        [\n            (1415221470, 1415221470),\n            ('2014-11-05T21:04:30Z', 1415221470),\n            ('2014-11-05T16:04:30-05:00', 1415221470),\n            ('2014-11-05T23:04:30+02:00', 1415221470),\n            ('2014-11-05T23-04-30+02-00', 1415221470),\n        ]\n    )\n    def test_init(self, value, expected_epoch):\n        t1 = RdiffTime(value)\n        self.assertEqual(expected_epoch, t1.epoch())\n\n    def test_int(self):\n        \"\"\"Check if int(RdiffTime) return expected value.\"\"\"\n        self.assertEqual(1415221470, int(RdiffTime(1415221470)))\n        self.assertEqual(1415217870, int(RdiffTime(1415221470, 3600)))\n\n    def test_str(self):\n        \"\"\"Check if __str__ is working.\"\"\"\n        self.assertEqual('2014-11-05T21:04:30Z', str(RdiffTime(1415221470)))\n        self.assertEqual('2014-11-05T21:04:30+01:00', str(RdiffTime(1415221470, 3600)))\n\n    def test_sub(self):\n        \"\"\"Check if addition with timedelta is working as expected.\"\"\"\n        # Without timezone\n        self.assertEqual(\n            RdiffTime('2014-11-02T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') - datetime.timedelta(days=3)\n        )\n        # With timezone\n        self.assertEqual(\n            RdiffTime('2014-11-02T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') - datetime.timedelta(days=3)\n        )\n\n        # With datetime\n        self.assertTrue((RdiffTime('2014-11-02T21:04:30Z') - RdiffTime()).days < 0)\n        self.assertTrue((RdiffTime() - RdiffTime('2014-11-02T21:04:30Z')).days > 0)\n\n    def test_set_time(self):\n        self.assertEqual(RdiffTime('2014-11-05T00:00:00Z'), RdiffTime('2014-11-05T21:04:30Z').set_time(0, 0, 0))\n        self.assertEqual(\n            RdiffTime('2014-11-02T00:00:00-04:00'), RdiffTime('2014-11-02T21:04:30-04:00').set_time(0, 0, 0)\n        )\n", "# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n[tox]\nenvlist = py3,doc,flake8,black,isort,djlint,buster,bullseye,bookworm\n\n[testenv]\npassenv = RDIFFWEB_TEST_DATABASE_URI\ndeps=\n  pytest\n  coverage\n  pytest-cov\n  psycopg2-binary\n  #cherrypy<9 depends on nosetest\n  buster: nose\n  buster: apscheduler==3.5.3\n  buster: argon2-cffi==18.3.0\n  buster: cherrypy==8.9.1\n  buster: configargparse==0.13.0\n  buster: distro==1.3.0\n  buster: humanfriendly==4.18\n  buster: Jinja2==2.10\n  buster: ldap3==2.4.1\n  buster: MarkupSafe==1.1.0\n  buster: psutil==5.7.2\n  buster: sqlalchemy==1.2.18\n  buster: WTForms==2.2.1\n  bullseye: apscheduler==3.7.0\n  bullseye: argon2-cffi==18.3.0\n  bullseye: cherrypy==18.6.1\n  bullseye: configargparse==1.2.3\n  bullseye: distro==1.5.0\n  bullseye: humanfriendly==9.1\n  bullseye: Jinja2==2.11.3\n  bullseye: ldap3==2.8.1\n  bullseye: MarkupSafe==1.1.1\n  bullseye: psutil==5.8.0\n  bullseye: sqlalchemy==1.3.22\n  bullseye: WTForms==2.2.1\n  bookworm: apscheduler==3.9.1\n  bookworm: argon2-cffi==21.1.0\n  bookworm: cherrypy==18.8.0\n  bookworm: configargparse==1.5.3\n  bookworm: distro==1.7.0\n  bookworm: humanfriendly==10.0\n  bookworm: Jinja2==3.0.3\n  bookworm: ldap3==2.9.1\n  bookworm: MarkupSafe==2.1.1\n  bookworm: psutil==5.9.0\n  bookworm: sqlalchemy==1.4.31\n  bookworm: WTForms==2.2.1\nextras = test\ncommands=\n  pytest -v --debug --override-ini junit_family=xunit1 --junit-xml=xunit-{envname}.xml --cov=rdiffweb --cov-report xml:coverage-{envname}.xml\n\n[testenv:doc]\ndeps =\n  sphinx\n  sphinx_md\n  recommonmark\n  sphinx-markdown-tables==0.0.3\ncommands = sphinx-build -W -b html -d {envtmpdir}/doctrees doc {envtmpdir}/html\n\n[testenv:black]\ndeps = black\ncommands = black --check --diff setup.py rdiffweb\nskip_install = true\n\n[testenv:djlint]\ndeps = djlint==1.19.2\nallowlist_externals = sh\ncommands = sh -c 'djlint --check rdiffweb/templates/*.html  rdiffweb/templates/**/*.html'\nskip_install = true\n\n[testenv:flake8]\ndeps =\n  flake8\ncommands = flake8 setup.py rdiffweb\nskip_install = true\n\n[testenv:isort]\ndeps = isort>=5.0.1\ncommands = isort --check --diff setup.py rdiffweb\nskip_install = true\n\n[flake8]\nignore =\n  E203 # whitespace before ':'\n  E501 # line too long (86 > 79 characters)\n  W503 # line break before binary operator\n  E741 # ambiguous variable name 'I'\nfilename =\n  *.py\n  setup.py\nmax-complexity = 20\n\n[isort]\nprofile = black\nline_length = 120"], "fixing_code": ["![Rdiffweb Banner](https://gitlab.com/ikus-soft/rdiffweb/-/raw/master/doc/_static/banner.png)\n\n<p align=\"center\">\n<strong>\n<a href=\"https://www.rdiffweb.org\">website</a>\n\u2022 <a href=\"https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/\">docs</a>\n\u2022 <a href=\"https://groups.google.com/d/forum/rdiffweb\">community</a>\n\u2022 <a href=\"https://rdiffweb-demo.ikus-soft.com/\">demo</a>\n</strong>\n</p>\n\n<p align=\"center\">\n<a href=\"LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/ikus060/rdiffweb\"></a>\n<a href=\"https://gitlab.com/ikus-soft/rdiffweb/pipelines\"><img alt=\"Build\" src=\"https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Quality Gate Minarca Client\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=alert_status\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Coverage\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=coverage\"></a>\n<a href=\"https://bestpractices.coreinfrastructure.org/projects/6583\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/6583/badge\"></a>\n</p>\n\n<h1 align=\"center\">\nWelcome to Rdiffweb\n</h1>\n\nRdiffweb is a web application that allows you to view repositories generated\nby [rdiff-backup](https://rdiff-backup.net/). The purpose of this\napplication is to ease the management of backups and quickly restore your data\nwith a rich and powerful web interface.\n\nRdiffweb is written in Python and is released as open source project under the \nGNU GENERAL PUBLIC LICENSE (GPL). All source code and documentation are\nCopyright Rdiffweb contributors.\n\nRdiffweb is actively developed by [IKUS Soft](https://www.ikus-soft.com/)\nsince November 2014.\n\nThe Rdiffweb source code is hosted on [Gitlab](https://gitlab.com/ikus-soft/rdiffweb)\nand mirrored to [Github](https://github.com/ikus060/rdiffweb).\n\nThe Rdiffweb website is https://rdiffweb.org/.\n\n## Features\n\nWith its rich web interface Rdiffweb provide a notable list of features:\n\n * Browse your backup\n * Restore single file or multiple files as an archived\n * Users authentication via local database and LDAP\n * Users authorization\n * Email notification when backup is not successful\n * Configurable repository encoding\n * Configurable retention period\n * Backup statistics visualization using graphs\n * SSH Keys management\n * Disk quota visualization\n * File and folder deletion\n\n## Demo\n\nIf you quickly want to check how Rdiffweb is behaving, you may try our demo server hosted on:\n\n[https://rdiffweb-demo.ikus-soft.com/](https://rdiffweb-demo.ikus-soft.com/)\n\nUse the following credential to login:\n\n * Username: admin\n * Password: admin123\n\n## Installation & Docker usage\n\nFor detailed installation steps, read the [Installation documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/installation.html).\n\n## Current Build Status\n\n[![Build Status](https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg)](https://gitlab.com/ikus-soft/rdiffweb/pipelines)\n\n## Download\n\nYou should read the [Documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/index.html) to properly install Rdiffweb in your environment.\n\n**Docker**\n\n    docker pull ikus060/rdiffweb\n    \n**Debian**\n\n    curl -L https://www.ikus-soft.com/archive/rdiffweb/public.key | apt-key add - \n    echo \"deb https://nexus.ikus-soft.com/repository/apt-release-bullseye/ bullseye main\" > /etc/apt/sources.list.d/rdiffweb.list\n    apt update\n    apt install rdiffweb\n\n**Pypi**\n\n    pip install rdiffweb\n\n## Support\n\n### Mailing list\n\nRdiffweb users should use the [Rdiffweb mailing list](https://groups.google.com/forum/#!forum/rdiffweb).\n\n### Bug Reports\n\nBug reports should be reported on the Rdiffweb Gitlab at https://gitlab.com/ikus-soft/rdiffweb/-/issues\n\n### Professional support\n\nProfessional support for Rdiffweb is available by contacting [IKUS Soft](https://www.ikus-soft.com/en/support/#form).\n\n# Changelog\n\n## Next Rlease 2.5.2\n\n* Block repository access when user_root directory is empty or a relative path\n\n## 2.5.1 (2022-11-11)\n\n* Add support for Ubuntu Kinetic #240\n* Disable filesize for deleted files to improve page loading #241\n\n## 2.5.0 (2022-11-09)\n\nThis next release focus on two-factor-authentication as a measure to increase security of user's account.\n\n* Store User's session information into database\n* Update ldap plugin to load additional attributes from LDAP server\n* Improve `/status` page error handling when `session_statistics` cannot be read\n* Add support for Ubuntu Jammy\n* Upgrade from Bootstrap v3 to v4 #204\n* Replace Fontello by Font-Awesome v4\n* Use CSS variables `var()` to customize themes using `--branding-X` options #239\n* Remove usage of Jquery.validate\n* Replace custom timsort by jquery DataTables #205\n* Add Active Session managements #203\n  * Active session should be visible in user's profiles\n  * Active session may be revoked by user\n  * Active session should be visible in administration view\n  * Action session may be revoke by administrator\n  * Show number of active users within the last 24 hours in dashboard\n* Handle migration of older Rdiffweb database by adding the missing `repos.Encoding`, `repos.keepdays` and `users.role` columns #185\n* Replace deprecated references of `disutils.spawn.find_executable()` by `shutil.which()` #208\n* Add two-factor authentication with email verification #201\n* Generate a new session on login and 2FA #220\n* Enforce permission on /etc/rdiffweb configuration folder\n* Enforce validation on fullname, username and email\n* Limit incorrect attempts to change the user's password to prevent brute force attacks #225 [CVE-2022-3273](https://nvd.nist.gov/vuln/detail/CVE-2022-3273)\n* Enforce password policy new password cannot be set as new password [CVE-2022-3376](https://nvd.nist.gov/vuln/detail/CVE-2022-3376)\n* Enforce better rate limit on login, mfa, password change and API [CVE-2022-3439](https://nvd.nist.gov/vuln/detail/CVE-2022-3439) [CVE-2022-3456](https://nvd.nist.gov/vuln/detail/CVE-2022-3456)\n* Enforce 'Origin' validation [CVE-2022-3457](https://nvd.nist.gov/vuln/detail/CVE-2022-3457)\n* Define idle and absolute session timeout with agressive default to protect usage on public computer [CVE-2022-3327](https://nvd.nist.gov/vuln/detail/CVE-2022-3327)\n* Send email notification when enabling or disabling MFA [CVE-2022-3363](https://nvd.nist.gov/vuln/detail/CVE-2022-3363)\n* Use Argon2id to store password hash #231\n* Fixed plugin priorities to ensure that jobs are scheduled at each startup #232\n* Revoke previous user's sessions on password change [CVE-2022-3362](https://nvd.nist.gov/vuln/detail/CVE-2022-3362)\n\nBreaking changes:\n\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n* `session-dir` is deprecated and should be replace by `rate-limit-dir`. User's session are stored in database.\n* previous `.css` customization are not barkward compatible. Make usage of the `--branding-X` options.\n\n## 2.4.10 (2022-10-03)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate path traversal vulnerability [CVE-2022-3389](https://nvd.nist.gov/vuln/detail/CVE-2022-3389)\n\n## 2.4.9 (2022-09-28)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add `Cache-Control` and other security headers [CVE-2022-3292](https://nvd.nist.gov/vuln/detail/CVE-2022-3292)\n* Enforce password policy using `password-score` based on [zxcvbn](https://github.com/dropbox/zxcvbn) [CVE-2022-3326](https://nvd.nist.gov/vuln/detail/CVE-2022-3326)\n\n## 2.4.8 (2022-09-26)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Clean-up invalid path on error page\n* Limit username field length [CVE-2022-3290](https://nvd.nist.gov/vuln/detail/CVE-2022-3290)\n* Limit user's email field length [CVE-2022-3272](https://nvd.nist.gov/vuln/detail/CVE-2022-3272)\n* Limit user's root directory field length [CVE-2022-3295](https://nvd.nist.gov/vuln/detail/CVE-2022-3295)\n* Limit SSH Key title field length [CVE-2022-3298](https://nvd.nist.gov/vuln/detail/CVE-2022-3298)\n\n## 2.4.7 (2002-09-21)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Generate a new session on login and 2FA #220 [CVE-2022-3269](https://nvd.nist.gov/vuln/detail/CVE-2022-3269)\n* Mitigate CSRF on user's settings #221 [CVE-2022-3274](https://nvd.nist.gov/vuln/detail/CVE-2022-3274)\n\n## 2.4.6 (2022-09-20)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Support MarkupSafe<3 for Debian bookworm\n* Mitigate CSRF on user's notification settings #216 [CVE-2022-3233](https://nvd.nist.gov/vuln/detail/CVE-2022-3233)\n* Mitigate CSRF on repository settings #217 [CVE-2022-3267](https://nvd.nist.gov/vuln/detail/CVE-2022-3267)\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session on HTTP Error #218 [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174)\n\n## 2.4.5 (2002-09-16)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF on repository deletion and user deletion [CVE-2022-3232](https://nvd.nist.gov/vuln/detail/CVE-2022-3232) #214 #215\n\n## 2.4.4 (2002-09-15)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use `X-Real-IP` to identify client IP address to mitigate Brute-Force attack #213\n\n## 2.4.3 (2022-09-14)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF in profile's SSH Keys [CVE-2022-3221](https://nvd.nist.gov/vuln/detail/CVE-2022-3221) #212\n\n## 2.4.2 (2022-09-12)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session. [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174) #209\n* Avoid leakage of the stack trace in the default error page. [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3175) #210\n* Enforce minimum and maximum password length [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3179) #211\n\n## 2.4.1 (2022-09-08)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add Clickjacking Defense [CVE-2022-3167](https://nvd.nist.gov/vuln/detail/CVE-2022-3167)\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n\n## 2.4.0 (2022-06-21)\n\nThis new release brings a lot of improvement since the last version, multiple bug fixes\nto make the application stable. A couple of new features to improve the overall\nusability and a new security feature to block a brute force attack.\n\n* Add RateLimit to login page and API to mitigate robots attacks #167\n* Send email notification only if `email-sender` option is defined to avoid raising exception in logs #176\n* Support file restore cancellation without leaving `rdiffweb-restore` process in `<defunct>` state #174\n* Replace `python-ldap` by `ldap3` a pure python implementation to avoid dependencies on `sasl` and `ldap` binaries #186\n* Reffactor core module to allow better extendability and reusability #183\n* Add support for Debian Bookworm #180\n* Add support for Ubuntu Impish #175\n* Add rdiff-backup version to administration view\n* Run unit test during Debian build package\n* Refresh repository list automatically when required #188 #189\n* Fix error 500 displayed in status page #191\n* Improve repository browsing speed by minimizing the number of I/O call #192\n* Publish Docker image directly to DockerHub #144\n* Add REST API to manage sshkeys\n\nBreaking changes:\n\n* Ldap Password changes is not supported anymore.\n* Ldap Check Shadow expire config is not supported anymore. It should be replace by a custom filter.\n* Drop CentOS 7 and CentOS 8 support\n\n## 2.3.9 (2022-01-05)\n\nMaintenance release to fix minor issues\n\n* Improve date parsing for `backup.log` to avoid printing exception in logs #170\n* Return HTTP error 403 for invalid symlink to avoid returning a misleading HTTP 500 Server Error #168\n* Show a user friendly error message when trying to create a new user with an existing username #169\n* Handle repository without last-backup date during the notification process to ensure notifications are sent #171\n* Replace CherryPy `storage_type` by `storage_class` to avoid warning in logs\n* Update code to avoid deprecation warning where applicable\n* Add Flake8 validation to improve code quality\n* Remove Ubuntu Groovy support\n\n## 2.3.8 (2021-12-01)\n\n* Push all artefacts to nexus server including binaries and documentation\n* Fix `Chart.js` loading on Debian bullseye #164\n* Update installation steps documentation\n* Improve LDAP authentication to lookup entire directory\n* Fix usage of `--ldap-add-user-default-userroot` to avoid error related to wrong encoding\n* Improve authentication mechanics\n* Avoid raising an HTTP error 500 when login form receive invalid payload\n* Mitigate open redirect vulnerability in login form\n\n## 2.3.7 (2021-10-21)\n\n * To avoid backward compatibility issue, revert CSRF Token validation\n * Mitigate CSRF vulnerability using cookies with `SameSite=Lax`\n * Mitigate CSRF vulnerability by validating the `Origin` header when a form is submited\n * Improve usage of WTForm for all form validation\n * Update installation stepd for debian #162\n * Build Ubuntu packages and publish them to our APT repo\n\n## 2.3.6 (2021-10-20)\n\n * Broken build\n\n## 2.3.5 (2021-10-18)\n\n * Mitigate CSRF vulnerability to user, ssh and repo management with CSRF Token\n\n## 2.3.4 (2021-09-20)\n\n * Skip email notification if `email-host` configuration is not provided #157\n * Skip email notification when the new attribute value has the same value #159\n * USE LDAP `mail` attribute when creating new user from LDAP directory #156\n\n## 2.3.3 (2021-09-10)\n\n * Provide a new theme `blue` to match IKUS Soft colors #158\n\n## 2.3.2 (2021-09-07)\n\n * Automatically update user's repository list based on user's home directory\n\n## 2.3.1 (2021-07-14)\n\n * Update default `session-dir` location to `/var/lib/rdiffweb/session` to avoid using `/var/run` #148\n\n## 2.3.0 (2021-07-06)\n\n * Improve timezone handling to display date with local timezone using javascript #143\n * Improve charts by replacing d3js by chartkick #122\n * Replace the status view by something meaningful with chartkick #122\n * Provide Docker image with Rdiffweb `docker pull ikus060/rdiffweb` #55\n * Fix file and folder sorting #143\n\n## 2.2.0 (2021-05-11)\n \n * Debian package:\n   * Add rdiff-backup as dependencies to comply with Debian packaging rules\n   * Multiple other fixed to control files\n   * Use debhelper-compat (= 13)\n   * Use debhelper-compat (= 13)\n   * Run test during packaging\n   * Create default folder `/var/run/rdiffweb/sessions` to store user session\n * Use ConfigArgPare for configuration to support configuration file, environment variables and arguments to configure rdiffweb #114\n * Fix cache in localization module\n * Add `ldap-add-default-role` and `ldap-add-default-userroot` option to define default value for role and user root when creating user from LDAP #125\n * Support PostgreSQL database by replacing our storage layer by SQLAlchemy #126\n * Fix to retrieve user quota only for valid user_root #135\n * Add option `disable-ssh-keys` to disable SSH Key management\n * Use absolute URL everywhere\n * Add support for `X-Forwarded-For`, `X-Forwarded-proto` and other reverse proxy header when generating absolute URL\n * Drop Debian Stretch support\n * Implement a new background scheduler using apscheduler #82\n * Use background job to send email notification to avoid blocking web page loading #47\n * Use background job to delete repository to avoid blocking web page loading #48\n * Allow deleting a specific file or folder from the history using `rdiff-backup-delete` #128\n * Improve support for `session-dir` #131\n * Add option `admin-password` to define administrator password for better security\n * Improve performance of repository browsing \n * Add a new view to display logs of a specific repository\n * Allow downloading the log\n * Define a default limit to graph statistics to make it display faster\n * Fix `get-quota-cmd` option to properly return a value\n\n## 2.1.0 (2021-01-15)\n\n* Debian package: Remove dh-systemd from Debian build dependencies (https://bugs.debian.org/871312we)\n* Improve Quota management:\n  * `QuotaSetCmd`, `QuotaGetCmd` and `QuotaUsedCmd` options could be used to customize how to set the quota for your environment.\n  * Display user's quota in User View\n  * Display user's quota in Admin View\n  * Allow admin to update user quota from Admin View when `QuotaSetCmd` is defined.\n  * Allow admin to define user quota using human readable value (e.g.: GiB, TiB, etc.)\n  * Improve logging around quota management\n* Improve robustness when service is starting\n* Improve robustness when repository has wrong permission defined (e.g.: when some files not readable)\n* Add user id in Admin view\n* Replace `UserObject(1)` by the actual username in log file to improve debugging\n\n## 2.0.0 (2020-12-04)\n\n* Re-implement logic to update repositories views to remove duplicates and avoid nesting repo. #107\n* Handle elapsed time of days in the graph. Thanks [Nathaniel van Diepen](https://github.com/Eeems) contributions.\n* Rebrand all link to ikus-soft.com\n* Update documentation to install rdiffweb\n* Remove obsolete minify dependency\n* Drop support for python2\n* Provide null translation if translation catalogues are not found\n* Pass a LANG environment variable to rdiff-backup restore process to fix encoding issue #112\n* Remove obsolete python shebang\n* Remove execution bit (+x) on python modules\n* Provide `--help` and `--version` on `rdiffweb` executable\n* Improve cherrypy version detection\n* Do not update translation files (.mo) during build\n\n## 1.5.0 (2020-06-24)\n\nThis minor release introduce official support of rdiffweb on Debian Bullseye. It also includes some usability improvements.\n\n * Change formatting of Last Backup date for \"Updated 3 weeks ago\" to ease the readability\n * Add support for Debian Bullseye\n * Add support for Python 3.8 (#104)\n * Add warning in the users list view when a root directory is invalid (#30)\n * Add options to control search depthness (#1)\n * Print a warning in the log when the \"DefaultTheme\" value is not valid (#90)\n\n## 1.4.0 (2020-05-20)\n\nThanks to our sponsor, this release introduce a feature to have better control over the user's permission by defining 3 different levels of privilege: Admin, Maintainer and User. This addition allows you to have better control on what your users can or can't do.\n\n * Fix single repository discovery when a user's home is a rdiff-backup repository\n * [SPONSORED] Add a new setting at the user level to define the user's role. Admin,\n   Maintainer and User. Admin are allowed to do everything. Maintainer are\n   allow to browse and delete repo. Users are only allowed to browse. #94\n * Add \"Powered by\" in the web interface footer #91\n * Display a nice error message when trying to delete admin user #93\n * Introduce usage of wtforms and flash in admin users for better form validation. #96 #97\n * Update French translation\n\n## 1.3.2 (2020-04-23)\n\nThis minor releases fixed issues found while testing release 1.3.0.\n\n * Fix lookup of executable rdiff-backup and rdiffweb-restore to search in current virtualenv first\n * Fix repository view when multiple repo path are conflicting\n * Fix logging of rdiffweb-restore subprocess\n\n## 1.3.1 (2020-04-10)\n\nThis minor release enforces security of the password stored in rdiffweb database to make use of a better encryption using SSHA.\nOnly new passwords will make use of the SSHA scheme.\n\n * Enforce password encryption by using SSHA scheme #88\n\n## 1.3.0 (2020-04-07)\n\nThis release focuses on improving the restore of big archives. The download should be much faster to start. Major enhancement was made to offload the processing outside the web server. And all of this is still compatible with rdiff-backup v1.2.8 and the latest v2.0.0.\n\n * Restore file and folder in a subprocess to make the download start faster\n * Fix encoding of archive on Python3.6 (CentOS 7) by using PAX format\n * Add support to restore files and folders using rdiff-backup2\n * Remove obsolete dependencies `pysqlite2`\n * Fix issue creating duplicate entries of repository in the database\n\n## 1.2.2 (2020-03-05)\n\nThis release provides little improvement to the v1.2.x including official support of rdiff-backup v2.0.0.\n\n * Enhance the repository to invite users to refresh the repository when the view is empty.\n * Support rdiff-backup v2.0.0\n * Deprecate support for cherrypy 4, 5, 6 and 7\n * Improve loading of repository data (cache status and entries)\n * Restore compatibility with SQLite 3.7 (CentOS7)\n\nKnown issues:\n\n * Filename encoding in tar.gz and zip file might not be accurate if you are running Python 3.6 (CentOS7)\n\n\n## 1.2.1 (2020-02-08)\n\nLittle bug fix following the previous release\n\n * Fix 404 error when trying to access other users repo as admin\n * Fix logging format for cherrypy logs to matches rdiffweb format\n * Add log rotation by default\n\n## 1.2.0 (2020-01-30)\n\nThis release focus on improving the database layers for better extendability to add more type of data and to support more databases backend like postgresql in the near future.\n\n * Add explicit testing for Debian Stretch & Buster\n * Change the persistence layers\n   * Minimize number of SQL queries\n   * Add object lazy loading\n   * Add object data caching\n * Fix bugs with SQLite <= 3.16 (Debian Stretch)\n\n## 1.1.0 (2019-10-31)\n\nThis release focus on improving the admin area and building the fundation for repository access control list (ACL).\n\n * Update documentation from PDSL web site\n * Improve the navigation bar layout\n * Update the login page headline\n * Update jinja2 version to allow 2.10.x\n * Show server log in admin area\n * Reduce code smell\n * Add System information in admin area\n * Validate credential using local database before LDAP\n * Reffactoring templates macros\n * Enhance user's view search bar\n * Change repository URL to username/repopath\n * Add System information in admin area\n * Improve testcases\n * Clean-up obsolete code\n * Fix issue with captital case encoding name\n * Fix compilation of less files\n * Fix google font import\n\n## 1.0.3 (2019-10-04)\n * Removing the auto update repos\n\n## 1.0.2 (2019-10-01)\n * Create \"admin\" user if missing\n * Update french translation\n\n## 1.0.1 (2019-09-22)\n * Update installation documentation \n * Fix removal of SSH Key\n * Return meaningful error to the user trying to add an existing SSH key\n\n## 1.0.0 (2019-09-11)\n * Make repository removal more robust\n * Improve performance of librdiff\n * Add new RESTful api\n * Return the right HTTP 401 or 402 error code for authentication\n * Fix bug introduce by upgrade to Jinja2 + python3\n * Store ssh keys in database and disk\n * Add support for theme (default, orange)\n * Remove deprecated profiling code\n * Add disk usage support / quota\n * Add support of cherrypy v18\n * Drop support of cherrypy v3.2.2\n * Add wsgi entry point\n * Replace the plugins architecture to ease implementation\n * Numerous bug fixes\n\n## 0.10.9 (2019-05-22)\n * Better error handling when error.log file are not valid gzip file\n\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nfrom unittest.mock import ANY, MagicMock\n\nimport cherrypy\nfrom parameterized import parameterized\n\nimport rdiffweb.test\nfrom rdiffweb.core.model import UserObject\n\n\nclass AbstractAdminTest(rdiffweb.test.WebCase):\n\n    login = True\n\n    def setUp(self):\n        super().setUp()\n        self._quota = {}\n        self.listener = MagicMock()\n        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)\n        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)\n        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)\n        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)\n        self.listener.get_disk_quota.side_effect = self._load_quota\n        cherrypy.engine.subscribe('get_disk_quota', self.listener.get_disk_quota, priority=40)\n        self.listener.get_disk_usage.return_value = 0\n        cherrypy.engine.subscribe('get_disk_usage', self.listener.get_disk_usage, priority=40)\n        self.listener.set_disk_quota.side_effect = self._store_quota\n        cherrypy.engine.subscribe('set_disk_quota', self.listener.set_disk_quota, priority=40)\n\n    def tearDown(self):\n        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)\n        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)\n        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)\n        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)\n        cherrypy.engine.unsubscribe('get_disk_quota', self.listener.get_disk_quota)\n        cherrypy.engine.unsubscribe('get_disk_usage', self.listener.get_disk_usage)\n        cherrypy.engine.unsubscribe('set_disk_quota', self.listener.set_disk_quota)\n        return super().tearDown()\n\n    def _store_quota(self, userobj, value):\n        self._quota[userobj.username] = value\n\n    def _load_quota(self, userobj):\n        return self._quota.get(userobj.username, 0)\n\n    def _add_user(self, username=None, email=None, password=None, user_root=None, role=None, mfa=None, fullname=None):\n        b = {}\n        b['action'] = 'add'\n        if username is not None:\n            b['username'] = username\n        if email is not None:\n            b['email'] = email\n        if password is not None:\n            b['password'] = password\n        if user_root is not None:\n            b['user_root'] = user_root\n        if role is not None:\n            b['role'] = str(role)\n        if mfa is not None:\n            b['mfa'] = str(mfa)\n        if fullname is not None:\n            b['fullname'] = str(fullname)\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def _edit_user(\n        self, username=None, email=None, password=None, user_root=None, role=None, disk_quota=None, mfa=None\n    ):\n        b = {}\n        b['action'] = 'edit'\n        if username is not None:\n            b['username'] = username\n        if email is not None:\n            b['email'] = email\n        if password is not None:\n            b['password'] = password\n        if user_root is not None:\n            b['user_root'] = user_root\n        if role is not None:\n            b['role'] = str(role)\n        if disk_quota is not None:\n            b['disk_quota'] = disk_quota\n        if mfa is not None:\n            b['mfa'] = str(mfa)\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def _delete_user(self, username='test1'):\n        b = {'action': 'delete', 'username': username}\n        self.getPage(\"/admin/users/\", method='POST', body=b)\n\n    def test_add_user_with_role_admin(self):\n        # When trying to create a new user with role admin\n        self._add_user(\"admin_role\", \"admin_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.ADMIN_ROLE)\n        # Then page return success\n        self.assertStatus(200)\n        # Then database is updated\n        userobj = UserObject.get_user('admin_role')\n        self.assertEqual(UserObject.ADMIN_ROLE, userobj.role)\n        # Then notification was raised\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_add_user_with_role_maintainer(self):\n        self._add_user(\"maintainer_role\", \"maintainer_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.MAINTAINER_ROLE)\n        self.assertStatus(200)\n        self.assertEqual(UserObject.MAINTAINER_ROLE, UserObject.get_user('maintainer_role').role)\n\n    def test_add_user_with_role_user(self):\n        self._add_user(\"user_role\", \"user_role@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        self.assertEqual(UserObject.USER_ROLE, UserObject.get_user('user_role').role)\n\n    def test_add_user_with_invalid_role(self):\n        # When trying to create a new user with an invalid role (admin instead of 0)\n        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", 'admin')\n        # Then an error message is displayed to the user\n        self.assertStatus(200)\n        self.assertInBody('Role: Invalid Choice: could not coerce')\n        # Then listener are not called\n        self.listener.user_added.assert_not_called()\n\n        # When trying to create a new user with an invalid role (-1)\n        self._add_user(\"invalid\", \"invalid@test.com\", \"pr3j5Dwi\", \"/home/\", -1)\n        # Then an error message is displayed to the user\n        self.assertStatus(200)\n        self.assertInBody('User Role: Not a valid choice')\n        # Then listener are not called\n        self.listener.user_added.assert_not_called()\n\n    def test_add_edit_delete(self):\n        #  Add user to be listed\n        self.listener.user_password_changed.reset_mock()\n        self._add_user(\n            \"test2\", \"test2@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE, mfa=UserObject.DISABLED_MFA\n        )\n        self.assertInBody(\"User added successfully.\")\n        self.assertInBody(\"test2\")\n        self.assertInBody(\"test2@test.com\")\n        self.listener.user_added.assert_called_once()\n        self.listener.user_password_changed.assert_called_once()\n        self.listener.user_password_changed.reset_mock()\n        #  Update user\n        self._edit_user(\n            \"test2\", \"chaned@test.com\", \"new-password\", \"/tmp/\", UserObject.ADMIN_ROLE, mfa=UserObject.ENABLED_MFA\n        )\n        self.listener.user_attr_changed.assert_called()\n        self.listener.user_password_changed.assert_called_once()\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertInBody(\"test2\")\n        self.assertInBody(\"chaned@test.com\")\n        self.assertNotInBody(\"/home/\")\n        self.assertInBody(\"/tmp/\")\n\n        self._delete_user(\"test2\")\n        self.listener.user_deleted.assert_called()\n        self.assertStatus(200)\n        self.assertInBody(\"User account removed.\")\n        self.assertNotInBody(\"test2\")\n\n    @parameterized.expand(\n        [\n            # Invalid\n            ('evil.com', False),\n            ('http://test', False),\n            ('email@test.test', False),\n            ('/test/', False),\n            # Valid\n            ('My fullname', True),\n            ('Test Test', True),\n            ('\u00c9ric Terrien-Pascal', True),\n            (\"Tel'c\", True),\n        ]\n    )\n    def test_edit_fullname_with_special_character(self, new_fullname, expected_valid):\n        # Given an existing user\n        # When updating the user's fullname\n        self.getPage(\n            \"/admin/users/\",\n            method='POST',\n            body={'action': 'edit', 'username': self.USERNAME, 'fullname': new_fullname},\n        )\n        self.assertStatus(200)\n        if expected_valid:\n            self.assertInBody(\"User information modified successfully.\")\n            self.assertNotInBody(\"Fullname: Must not contain any special characters.\")\n        else:\n            self.assertNotInBody(\"User information modified successfully.\")\n            self.assertInBody(\"Fullname: Must not contain any special characters.\")\n\n    @parameterized.expand(\n        [\n            # Invalid\n            ('http://username', False),\n            ('username@test.test', False),\n            ('/username/', False),\n            # Valid\n            ('username.com', True),\n            ('admin_user', True),\n            ('test.test', True),\n            ('test-test', True),\n        ]\n    )\n    def test_add_user_with_special_character(self, new_username, expected_valid):\n        self._add_user(new_username, \"eric@test.com\", \"pr3j5Dwi\", \"/home/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        if expected_valid:\n            self.assertInBody(\"User added successfully.\")\n            self.assertNotInBody(\"Username: Must not contain any special characters.\")\n        else:\n            self.assertNotInBody(\"User added successfully.\")\n            self.assertInBody(\"Username: Must not contain any special characters.\")\n\n    def test_add_user_with_empty_username(self):\n        \"\"\"\n        Verify failure trying to create user without username.\n        \"\"\"\n        self._add_user(\"\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        self.assertStatus(200)\n        self.assertInBody(\"Username: This field is required.\")\n\n    def test_add_user_with_existing_username(self):\n        \"\"\"\n        Verify failure trying to add the same user.\n        \"\"\"\n        # Given a user named `test1`\n        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # When trying to create a new user with the same name\n        self._add_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then the user list is displayed with an error message.\n        self.assertStatus(200)\n        self.assertInBody(\"User test1 already exists.\")\n\n    def test_add_user_with_invalid_root_directory(self):\n        \"\"\"\n        Verify failure to add a user with invalid root directory.\n        \"\"\"\n        try:\n            self._delete_user(\"test5\")\n        except Exception:\n            pass\n        self._add_user(\"test5\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")\n\n    def test_add_without_email(self):\n        #  Add user to be listed\n        self._add_user(\"test2\", None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n\n    def test_add_without_user_root(self):\n        #  Add user to be listed\n        self._add_user(\"test6\", None, \"pr3j5Dwi\", None, UserObject.USER_ROLE)\n        self.assertInBody(\"User added successfully.\")\n\n        user = UserObject.get_user('test6')\n        self.assertEqual('', user.user_root)\n\n    def test_add_with_username_too_long(self):\n        # Given a too long username\n        username = \"test2\" * 52\n        # When trying to create the user\n        self._add_user(username, None, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Username too long.\")\n\n    def test_add_with_email_too_long(self):\n        # Given a too long username\n        email = (\"test2\" * 50) + \"@test.com\"\n        # When trying to create the user\n        self._add_user(\"test2\", email, \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Email too long.\")\n\n    def test_add_with_user_root_too_long(self):\n        # Given a too long user root\n        user_root = \"/temp/\" * 50\n        # When trying to create the user\n        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", user_root, UserObject.USER_ROLE)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Root directory too long.\")\n\n    def test_add_with_fullname_too_long(self):\n        # Given a too long user root\n        fullname = \"fullname\" * 50\n        # When trying to create the user\n        self._add_user(\"test2\", \"test@test,com\", \"pr3j5Dwi\", \"/tmp/\", UserObject.USER_ROLE, fullname=fullname)\n        # Then an error is raised\n        self.assertStatus(200)\n        self.assertInBody(\"Fullname too long.\")\n\n    def test_delete_user_with_not_existing_username(self):\n        \"\"\"\n        Verify failure to delete invalid username.\n        \"\"\"\n        self._delete_user(\"test3\")\n        self.assertInBody(\"User doesn&#39;t exists!\")\n\n    def test_delete_our_self(self):\n        \"\"\"\n        Verify failure to delete our self.\n        \"\"\"\n        self._delete_user(self.USERNAME)\n        self.assertInBody(\"You cannot remove your own account!\")\n\n    def test_delete_user_admin(self):\n        \"\"\"\n        Verify failure to delete our self.\n        \"\"\"\n        # Create another admin user\n        self._add_user('admin2', '', 'pr3j5Dwi', '', UserObject.ADMIN_ROLE)\n        self.getPage(\"/logout\")\n        self.assertStatus(303)\n        self.assertHeaderItemValue('Location', self.baseurl + '/')\n        self._login('admin2', 'pr3j5Dwi')\n\n        # Try deleting admin user\n        self._delete_user(self.USERNAME)\n        self.assertStatus(200)\n        self.assertInBody(\"can&#39;t delete admin user\")\n\n    def test_delete_user_method_get(self):\n        # Given a user\n        user = UserObject.add_user('newuser')\n        user.commit()\n        # When trying to delete this user using method GET\n        self.getPage(\"/admin/users/?action=delete&username=newuser\", method='GET')\n        # Then page return without error\n        self.assertStatus(200)\n        # Then user is not deleted\n        self.assertIsNotNone(UserObject.get_user('newuser'))\n\n    def test_change_password_with_too_short(self):\n        self._edit_user(self.USERNAME, password='short')\n        self.assertInBody(\"Password must have between 8 and 128 characters.\")\n\n    def test_change_password_with_too_long(self):\n        new_password = 'a' * 129\n        self._edit_user(self.USERNAME, password=new_password)\n        self.assertInBody(\"Password must have between 8 and 128 characters.\")\n\n    def test_change_admin_password(self):\n        # Given rdiffweb is configured with admin-password option\n        self.app.cfg.admin_password = 'hardcoded'\n        try:\n            # When trying to update admin password\n            self._edit_user('admin', password='new-password')\n            # Then the form is refused with 200 OK with an error message.\n            self.assertStatus(200)\n            self.assertInBody(\"can&#39;t update admin-password defined in configuration file\")\n        finally:\n            self.app.cfg.admin_password = None\n\n    def test_edit_user_with_invalid_path(self):\n        \"\"\"\n        Verify failure trying to update user with invalid path.\n        \"\"\"\n        userobj = UserObject.add_user('test1')\n        userobj.commit()\n        self._edit_user(\"test1\", \"test1@test.com\", \"pr3j5Dwi\", \"/var/invalid/\", UserObject.USER_ROLE)\n        self.assertNotInBody(\"User added successfully.\")\n        self.assertInBody(\"User&#39;s root directory /var/invalid/ is not accessible!\")\n\n    def test_list(self):\n        self.getPage(\"/admin/users/\")\n        self.assertInBody(\"Users\")\n        self.assertInBody(\"User management\")\n        self.assertInBody(\"Add user\")\n\n    def test_edit_user_with_not_existing_username(self):\n        \"\"\"\n        Verify failure trying to update invalid user.\n        \"\"\"\n        # Given an invalid username\n        username = 'invalid'\n        # When trying to edit the user\n        self._edit_user(username, \"test1@test.com\", \"test\", \"/var/invalid/\", UserObject.USER_ROLE)\n        # Then the user list is displayed with an error message\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot edit user `invalid`: user doesn&#39;t exists\")\n\n    def test_user_invalid_root(self):\n        # Change the user's root\n        user = UserObject.get_user(self.USERNAME)\n        user.user_root = \"/invalid\"\n        user.commit()\n        self.getPage(\"/admin/users\")\n        self.assertInBody(\"Root directory not accessible!\")\n\n        # Query the page by default\n        user = UserObject.get_user('admin')\n        user.user_root = \"/tmp/\"\n        user.commit()\n        self.getPage(\"/admin/users\")\n        self.assertNotInBody(\"Root directory not accessible!\")\n\n    def test_get_quota(self):\n        # Mock a quota.\n        self.listener.get_disk_quota.side_effect = None\n        self.listener.get_disk_quota.return_value = 654321\n        # When querying the user list\n        self.getPage(\"/admin/users/\")\n        self.assertStatus(200)\n        # Then get_disk_quota listenre is called\n        self.listener.get_disk_quota.assert_called()\n        # Then the quota value is displayed in human readable format\n        self.assertInBody(\"638.99 KiB\")\n        self.assertStatus(200)\n\n    def test_set_quota(self):\n        # When updating user quota.\n        self._edit_user(\"admin\", disk_quota='8765432')\n        # Then listenr get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_gib(self):\n        # When updating user quota\n        self._edit_user(\"admin\", disk_quota='1GiB')\n        # Then listern get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 1073741824)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_with_comma(self):\n        # When updating quota with comma value\n        self._edit_user(\"admin\", disk_quota='1,5 GiB')\n        # Then listner get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 1610612736)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_as_with_leading_dot(self):\n        # When updating quota with leading dot\n        self._edit_user(\"admin\", disk_quota='.5 GiB')\n        # Then listener get called\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 536870912)\n        # Then a success message is displayed\n        self.assertInBody(\"User information modified successfully.\")\n        self.assertStatus(200)\n\n    def test_set_quota_empty(self):\n        # When quota is not defined\n        self._edit_user(\"admin\", disk_quota='')\n        # Then listener is not called.\n        self.listener.set_disk_quota.assert_not_called()\n        # Then message is not displayed\n        self.assertStatus(200)\n\n    def test_set_quota_same_value(self):\n        # Given an exiting quota\n        self.listener.get_disk_quota.side_effect = None\n        self.listener.get_disk_quota.return_value = 1234567890\n        # When setting the quota value to the same value\n        self._edit_user(\"admin\", disk_quota='1.15 GiB')\n        #  Then listener is not called\n        self.listener.set_disk_quota.assert_not_called()\n        # Then message is not displayed\n        self.assertStatus(200)\n\n    def test_set_quota_unsupported(self):\n        # Given setting quota is not supported\n        self.listener.set_disk_quota.side_effect = None\n        self.listener.set_disk_quota.return_value = None\n        # When updating the quota\n        self._edit_user(\"admin\", disk_quota='8765432')\n        # Then\n        self.listener.set_disk_quota.assert_called_once_with(ANY, 8765432)\n        self.assertInBody(\"Setting user&#39;s quota is not supported\")\n        self.assertStatus(200)\n\n    def test_edit_own_role(self):\n        # Given an administrator\n        # When trygin to update your own role\n        self._edit_user(username=self.USERNAME, role=UserObject.MAINTAINER_ROLE)\n        # Then an error is returned\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot edit your own role.\")\n\n    def test_edit_own_mfa(self):\n        # Given an administrator\n        # When trygin to update your own role\n        self._edit_user(username=self.USERNAME, mfa=UserObject.ENABLED_MFA)\n        # Then an error is returned\n        self.assertStatus(200)\n        self.assertInBody(\"Cannot change your own two-factor authentication settings.\")\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport bisect\nimport calendar\nimport encodings\nimport logging\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport threading\nimport time\nfrom datetime import timedelta\nfrom subprocess import CalledProcessError\n\nimport psutil\nfrom cached_property import cached_property\n\nfrom rdiffweb.tools.i18n import ugettext as _\n\n# Define the logger\nlogger = logging.getLogger(__name__)\n\n# Constant for the rdiff-backup-data folder name.\nRDIFF_BACKUP_DATA = b\"rdiff-backup-data\"\n\n# Increment folder name.\nINCREMENTS = b\"increments\"\n\n# Define the default LANG environment variable to be passed to rdiff-backup\n# restore command line to make sure the binary output stdout as utf8 otherwise\n# we end up with \\x encoded characters.\nSTDOUT_ENCODING = 'utf-8'\nLANG = \"en_US.\" + STDOUT_ENCODING\n\n\ndef rdiff_backup_version():\n    \"\"\"\n    Get rdiff-backup version\n    \"\"\"\n    try:\n        output = subprocess.check_output([find_rdiff_backup(), '--version'])\n        m = re.search(b'([0-9]+).([0-9]+).([0-9]+)', output)\n        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))\n    except Exception:\n        return (0, 0, 0)\n\n\ndef find_rdiff_backup():\n    \"\"\"\n    Lookup for `rdiff-backup` executable. Raise an exception if not found.\n    \"\"\"\n    cmd = shutil.which('rdiff-backup')\n    if not cmd:\n        raise FileNotFoundError(\"can't find `rdiff-backup` executable in PATH: %s\" % os.environ['PATH'])\n    return os.fsencode(cmd)\n\n\ndef find_rdiff_backup_delete():\n    \"\"\"\n    Lookup for `rdiff-backup-delete` executable. Raise an exception if not found.\n    \"\"\"\n    cmd = shutil.which('rdiff-backup-delete')\n    if not cmd:\n        raise FileNotFoundError(\n            \"can't find `rdiff-backup-delete` executable in PATH: %s, make sure you have rdiff-backup >= 2.0.1 installed\"\n            % os.environ['PATH']\n        )\n    return os.fsencode(cmd)\n\n\ndef unquote(name):\n    \"\"\"Remove quote from the given name.\"\"\"\n    assert isinstance(name, bytes)\n\n    # This function just gives back the original text if it can decode it\n    def unquoted_char(match):\n        \"\"\"For each ;000 return the corresponding byte.\"\"\"\n        if len(match.group()) != 4:\n            return match.group\n        try:\n            return bytes([int(match.group()[1:])])\n        except ValueError:\n            return match.group\n\n    # Remove quote using regex\n    return re.sub(b\";[0-9]{3}\", unquoted_char, name, re.S)\n\n\ndef popen(cmd, stderr=None, env=None):\n    \"\"\"\n    Alternative to os.popen() to support a `cmd` with a list of arguments and\n    return a file object that return bytes instead of string.\n\n    `stderr` could be subprocess.STDOUT or subprocess.DEVNULL or a function.\n    Otherwise, the error is redirect to logger.\n    \"\"\"\n    # Check if stderr should be pipe.\n    pipe_stderr = stderr == subprocess.PIPE or hasattr(stderr, '__call__') or stderr is None\n    proc = subprocess.Popen(\n        cmd,\n        shell=False,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE if pipe_stderr else stderr,\n        env=env,\n    )\n    if pipe_stderr:\n        t = threading.Thread(target=_readerthread, args=(proc.stderr, stderr))\n        t.daemon = True\n        t.start()\n    return _wrap_close(proc.stdout, proc)\n\n\n# Helper for popen() to redirect stderr to a logger.\n\n\ndef _readerthread(stream, func):\n    \"\"\"\n    Read stderr and pipe each line to logger.\n    \"\"\"\n    func = func or logger.debug\n    for line in stream:\n        func(line.decode(STDOUT_ENCODING, 'replace').strip('\\n'))\n    stream.close()\n\n\n# Helper for popen() to close process when the pipe is closed.\n\n\nclass _wrap_close:\n    def __init__(self, stream, proc):\n        self._stream = stream\n        self._proc = proc\n\n    def close(self):\n        self._stream.close()\n        returncode = self._proc.wait()\n        if returncode == 0:\n            return None\n        return returncode\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getattr__(self, name):\n        return getattr(self._stream, name)\n\n    def __iter__(self):\n        return iter(self._stream)\n\n\nclass AccessDeniedError(Exception):\n    pass\n\n\nclass DoesNotExistError(Exception):\n    pass\n\n\nclass RdiffTime(object):\n\n    \"\"\"Time information has two components: the local time, stored in GMT as\n    seconds since Epoch, and the timezone, stored as a seconds offset. Since\n    the server may not be in the same timezone as the user, we cannot rely on\n    the built-in localtime() functions, but look at the rdiff-backup string\n    for timezone information.  As a general rule, we always display the\n    \"local\" time, but pass the timezone information on to rdiff-backup, so\n    it can restore to the correct state\"\"\"\n\n    def __init__(self, value=None, tz_offset=None):\n        assert value is None or isinstance(value, int) or isinstance(value, str)\n        if value is None:\n            # Get GMT time.\n            self._time_seconds = int(time.time())\n            self._tz_offset = 0\n        elif isinstance(value, int):\n            self._time_seconds = value\n            self._tz_offset = tz_offset or 0\n        else:\n            self._from_str(value)\n\n    def _from_str(self, time_string):\n        if time_string[10] != 'T':\n            raise ValueError('missing date time separator (T): ' + time_string)\n        if time_string[19] not in ['-', '+', 'Z']:\n            raise ValueError('missing timezone info (-, + or Z): ' + time_string)\n        if time_string[4] != '-' or time_string[7] != '-':\n            raise ValueError('missing date separator (-): ' + time_string)\n        if not (time_string[13] in [':', '-'] and time_string[16] in [':', '-']):\n            raise ValueError('missing date separator (-): ' + time_string)\n        try:\n            year = int(time_string[0:4])\n            if not (1900 < year < 2200):\n                raise ValueError('unexpected year value between 1900 and 2200: ' + str(year))\n            month = int(time_string[5:7])\n            if not (1 <= month <= 12):\n                raise ValueError('unexpected month value between 1 and 12: ' + str(month))\n            day = int(time_string[8:10])\n            if not (1 <= day <= 31):\n                raise ValueError('unexpected day value between 1 and 31: ' + str(day))\n            hour = int(time_string[11:13])\n            if not (0 <= hour <= 23):\n                raise ValueError('unexpected hour value between 1 and 23: ' + str(hour))\n            minute = int(time_string[14:16])\n            if not (0 <= minute <= 60):\n                raise ValueError('unexpected minute value between 1 and 60: ' + str(minute))\n            second = int(time_string[17:19])\n            if not (0 <= second <= 61):  # leap seconds\n                raise ValueError('unexpected second value between 1 and 61: ' + str(second))\n            timetuple = (year, month, day, hour, minute, second, -1, -1, 0)\n            self._time_seconds = calendar.timegm(timetuple)\n            self._tz_offset = self._tzdtoseconds(time_string[19:])\n            self._tz_str()  # to get assertions there\n        except (TypeError, ValueError, AssertionError):\n            raise ValueError(time_string)\n\n    def epoch(self):\n        return self._time_seconds - self._tz_offset\n\n    def _tz_str(self):\n        if self._tz_offset:\n            hours, minutes = divmod(abs(self._tz_offset) // 60, 60)\n            assert 0 <= hours <= 23\n            assert 0 <= minutes <= 59\n            if self._tz_offset > 0:\n                plus_minus = \"+\"\n            else:\n                plus_minus = \"-\"\n            return \"%s%s:%s\" % (plus_minus, \"%02d\" % hours, \"%02d\" % minutes)\n        else:\n            return \"Z\"\n\n    def set_time(self, hour, minute, second):\n        year = time.gmtime(self._time_seconds)[0]\n        month = time.gmtime(self._time_seconds)[1]\n        day = time.gmtime(self._time_seconds)[2]\n        _time_seconds = calendar.timegm((year, month, day, hour, minute, second, -1, -1, 0))\n        return RdiffTime(_time_seconds, self._tz_offset)\n\n    def _tzdtoseconds(self, tzd):\n        \"\"\"Given w3 compliant TZD, converts it to number of seconds from UTC\"\"\"\n        if tzd == \"Z\":\n            return 0\n        assert len(tzd) == 6  # only accept forms like +08:00 or +08-00 for now\n        assert (tzd[0] == \"-\" or tzd[0] == \"+\") and tzd[3] in [\":\", '-']\n        if tzd[0] == \"+\":\n            plus_minus = 1\n        else:\n            plus_minus = -1\n        return plus_minus * 60 * (60 * int(tzd[1:3]) + int(tzd[4:]))\n\n    def __add__(self, other):\n        \"\"\"Support plus (+) timedelta\"\"\"\n        assert isinstance(other, timedelta)\n        return RdiffTime(self._time_seconds + int(other.total_seconds()), self._tz_offset)\n\n    def __sub__(self, other):\n        \"\"\"Support minus (-) timedelta\"\"\"\n        assert isinstance(other, timedelta) or isinstance(other, RdiffTime)\n        # Sub with timedelta, return RdiffTime\n        if isinstance(other, timedelta):\n            return RdiffTime(self._time_seconds - int(other.total_seconds()), self._tz_offset)\n\n        # Sub with RdiffTime, return timedelta\n        if isinstance(other, RdiffTime):\n            return timedelta(seconds=self._time_seconds - other._time_seconds)\n\n    def __int__(self):\n        \"\"\"Return this date as seconds since epoch.\"\"\"\n        return self.epoch()\n\n    def __lt__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() < other.epoch()\n\n    def __le__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() <= other.epoch()\n\n    def __gt__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() > other.epoch()\n\n    def __ge__(self, other):\n        assert isinstance(other, RdiffTime)\n        return self.epoch() >= other.epoch()\n\n    def __eq__(self, other):\n        return isinstance(other, RdiffTime) and self.epoch() == other.epoch()\n\n    def __hash__(self):\n        return hash(self.epoch())\n\n    def __str__(self):\n        \"\"\"return utf-8 string\"\"\"\n        value = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime(self._time_seconds))\n        return value + self._tz_str()\n\n    def __repr__(self):\n        \"\"\"return second since epoch\"\"\"\n        return \"RdiffTime('\" + str(self) + \"')\"\n\n\nclass RdiffDirEntry(object):\n    \"\"\"\n    Includes name, isdir, file_size, exists, and dict (change_dates) of sorted\n    local dates when backed up.\n    \"\"\"\n\n    def __init__(self, repo, path, exists, increments):\n        assert isinstance(repo, RdiffRepo)\n        assert isinstance(path, bytes)\n        # Keep reference to the path and repo object.\n        self._repo = repo\n        self.path = path\n        # Absolute path to the directory\n        if self.isroot:\n            self.full_path = self._repo.full_path\n        else:\n            self.full_path = os.path.join(self._repo.full_path, self.path)\n        # May need to compute our own state if not provided.\n        self.exists = exists\n        # Store the increments sorted by date.\n        # See self.last_change_date()\n        self._increments = sorted(increments, key=lambda x: x.date)\n\n    @property\n    def display_name(self):\n        \"\"\"Return the most human readable filename. Without quote.\"\"\"\n        return self._repo.get_display_name(self.path)\n\n    @property\n    def isroot(self):\n        \"\"\"\n        Check if the directory entry represent the root of the repository.\n        Return True when path is empty.\n        \"\"\"\n        return self.path == b''\n\n    @cached_property\n    def isdir(self):\n        \"\"\"Lazy check if entry is a directory\"\"\"\n        if self.exists:\n            # If the entry exists, check if it's a directory\n            return os.path.isdir(self.full_path)\n        # Check if increments is a directory\n        for increment in self._increments:\n            if increment.is_missing:\n                # Ignore missing increment...\n                continue\n            return increment.isdir\n\n    @cached_property\n    def file_size(self):\n        \"\"\"\n        Return the current file size in bytes.\n        Return negative value (-1) for folder and deleted files.\n        \"\"\"\n        if self.isdir or not self.exists:\n            return -1\n        else:\n            try:\n                return os.lstat(self.full_path).st_size\n            except Exception:\n                logger.warning(\"cannot lstat on file [%s]\", self.full_path, exc_info=1)\n                return 0\n\n    def get_file_size(self, date=None):\n        # A viable place to get the filesize of a deleted entry\n        # it to get it from file_statistics\n        try:\n            stats = self._repo.file_statistics[date]\n            # File stats uses unquoted name.\n            unquote_path = unquote(self.path)\n            return stats.get_source_size(unquote_path)\n        except Exception:\n            logger.warning(\"cannot find file statistic [%s]\", self.last_change_date, exc_info=1)\n        return -1\n\n    @cached_property\n    def change_dates(self):\n        \"\"\"\n        Return a list of dates when this item has changes. Represent the\n        previous revision. From old to new.\n        \"\"\"\n        # Exception for root path, use backups dates.\n        if self.isroot:\n            return self._repo.backup_dates\n\n        # Compute the dates\n        change_dates = set()\n        for increment in self._increments:\n            # Get date of the increment as reference\n            change_date = increment.date\n            # If the increment is a \"missing\" increment, need to get the date\n            # before the folder was removed.\n            if increment.is_missing:\n                change_date = self._get_previous_backup_date(change_date)\n\n            if change_date:\n                change_dates.add(change_date)\n\n        # If the directory exists, add the last known backup date.\n        if self.exists and self._repo.last_backup_date:\n            change_dates.add(self._repo.last_backup_date)\n\n        # Return the list of dates.\n        return sorted(change_dates)\n\n    def _get_previous_backup_date(self, date):\n        \"\"\"Return the previous backup date.\"\"\"\n        index = bisect.bisect_left(self._repo.backup_dates, date)\n        if index == 0:\n            return None\n        return self._repo.backup_dates[index - 1]\n\n    @cached_property\n    def last_change_date(self):\n        \"\"\"Return last change date or False.\"\"\"\n        return self.change_dates and self.change_dates[-1]\n\n\nclass AbstractEntry:\n    SUFFIXES = None\n\n    @classmethod\n    def _extract_date(cls, filename, onerror=None):\n        \"\"\"\n        Extract date from rdiff-backup filenames.\n        \"\"\"\n        # Extract suffix\n        suffix = None\n        for s in cls.SUFFIXES:\n            if filename.endswith(s):\n                suffix = s\n                break\n        if not suffix:\n            raise ValueError(filename)\n        # Parse date\n        filename_without_suffix = filename[: -len(suffix)]\n        parts = filename_without_suffix.rsplit(b'.', 1)\n        if len(parts) != 2:\n            return onerror(ValueError(''))\n        date_string = unquote(parts[1]).decode('ascii')\n        try:\n            return RdiffTime(date_string)\n        except Exception as e:\n            if onerror is None:\n                raise\n            return onerror(e)\n\n\nclass MetadataEntry(AbstractEntry):\n    PREFIX = None\n    SUFFIXES = None\n    on_date_error = None\n\n    def __init__(self, repo, name):\n        assert isinstance(repo, RdiffRepo)\n        assert isinstance(name, bytes)\n        assert name.startswith(self.PREFIX)\n        assert any(name.endswith(s) for s in self.SUFFIXES), 'name %s should ends with: %s' % (name, self.SUFFIXES)\n        self.repo = repo\n        self.name = name\n        self.path = os.path.join(self.repo._data_path, self.name)\n        self.date = self._extract_date(name, onerror=self.on_date_error)\n\n    def _open(self):\n        \"\"\"\n        Should be used to open the increment file. This method handle\n        compressed vs not-compressed file.\n        \"\"\"\n        if self._is_compressed:\n            return popen(['zcat', self.path])\n        return open(self.path, 'rb')\n\n    @property\n    def _is_compressed(self):\n        return self.name.endswith(b\".gz\")\n\n\nclass MirrorMetadataEntry(MetadataEntry):\n    PREFIX = b'mirror_metadata.'\n    SUFFIXES = [\n        b'.diff',\n        b'.diff.gz',\n        b\".snapshot.gz\",\n        b\".snapshot\",\n    ]\n\n\nclass IncrementEntry(AbstractEntry):\n\n    \"\"\"Instance of the class represent one increment at a specific date for one\n    repository. The base repository is provided in the default constructor\n    and the date is provided using an error_log.* file\"\"\"\n\n    SUFFIXES = [\n        b\".missing\",\n        b\".snapshot.gz\",\n        b\".snapshot\",\n        b\".diff\",\n        b\".diff.gz\",\n        b\".dir\",\n    ]\n\n    def __init__(self, name):\n        \"\"\"Default constructor for an increment entry. User must provide the\n        repository directory and an entry name. The entry name correspond\n        to an error_log.* filename.\"\"\"\n        self.name, self.date, self.suffix = IncrementEntry._split(name)\n\n    @property\n    def isdir(self):\n        return self.suffix == b\".dir\"\n\n    @property\n    def is_missing(self):\n        \"\"\"Check if the curent entry is a missing increment.\"\"\"\n        return self.suffix == b\".missing\"\n\n    @property\n    def is_snapshot(self):\n        \"\"\"Check if the current entry is a snapshot increment.\"\"\"\n        return self.suffix in [b\".snapshot.gz\", b\".snapshot\"]\n\n    @classmethod\n    def _split(cls, filename):\n        \"\"\"Return tuple with filename, date, suffix\"\"\"\n        assert isinstance(filename, bytes)\n        # Extract suffix\n        suffix = None\n        for s in cls.SUFFIXES:\n            if filename.endswith(s):\n                suffix = s\n                break\n        if not suffix:\n            raise ValueError(filename)\n        # Parse date and raise error on failure\n        filename_without_suffix = filename[: -len(suffix)]\n        name, date_string = filename_without_suffix.rsplit(b'.', 1)\n        date_string = unquote(date_string).decode('ascii')\n        date = RdiffTime(date_string)\n        return (name, date, suffix)\n\n    def __gt__(self, other):\n        return self.date.__gt__(other.date)\n\n    def __lt__(self, other):\n        return self.date.__lt__(other.date)\n\n\nclass FileStatisticsEntry(MetadataEntry):\n\n    \"\"\"\n    Represent a single file_statistics.\n\n    File Statistics contains different information related to each file of\n    the backup. This class provide a simple and easy way to access this\n    data.\n    \"\"\"\n\n    PREFIX = b'file_statistics.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    def get_mirror_size(self, path):\n        \"\"\"Return the value of MirrorSize for the given file.\n        path is the relative path from repo root.\"\"\"\n        try:\n            return int(self._search(path)[\"mirror_size\"])\n        except ValueError:\n            logger.warning(\"mirror size not found for [%r]\", path, exc_info=1)\n            return 0\n\n    def get_source_size(self, path):\n        \"\"\"Return the value of SourceSize for the given file.\n        path is the relative path from repo root.\"\"\"\n        try:\n            return int(self._search(path)[\"source_size\"])\n        except ValueError:\n            logger.warning(\"source size not found for [%r]\", path, exc_info=1)\n            return 0\n\n    def _search(self, path):\n        \"\"\"\n        This function search for a file entry in the file_statistics compress\n        file. Since python gzip.open() seams to be 2 time slower, we directly use\n        zlib library on python2.\n        \"\"\"\n        logger.debug(\"read file_statistics [%r]\", self.name)\n\n        path += b' '\n\n        with self._open() as f:\n            for line in f:\n                if not line.startswith(path):\n                    continue\n                break\n\n        # Split the line into array\n        data = line.rstrip(b'\\r\\n').rsplit(b' ', 4)\n        # From array create an entry\n        return {'changed': data[1], 'source_size': data[2], 'mirror_size': data[3], 'increment_size': data[4]}\n\n\nclass SessionStatisticsEntry(MetadataEntry):\n    \"\"\"Represent a single session_statistics.\"\"\"\n\n    PREFIX = b'session_statistics.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    ATTRS = [\n        'starttime',\n        'endtime',\n        'elapsedtime',\n        'sourcefiles',\n        'sourcefilesize',\n        'mirrorfiles',\n        'mirrorfilesize',\n        'newfiles',\n        'newfilesize',\n        'deletedfiles',\n        'deletedfilesize',\n        'changedfiles',\n        'changedsourcesize',\n        'changedmirrorsize',\n        'incrementfiles',\n        'incrementfilesize',\n        'totaldestinationsizechange',\n        'errors',\n    ]\n\n    def _load(self):\n        \"\"\"This method is used to read the session_statistics and create the\n        appropriate structure to quickly get the data.\n\n        File Statistics contains different information related to each file of\n        the backup. This class provide a simple and easy way to access this\n        data.\"\"\"\n\n        with self._open() as f:\n            for line in f.readlines():\n                # Read the line into array\n                line = line.rstrip(b'\\r\\n')\n                data_line = line.split(b\" \", 2)\n                # Read line into tuple\n                (key, value) = tuple(data_line)[0:2]\n                if b'.' in value:\n                    value = float(value)\n                else:\n                    value = int(value)\n                setattr(self, key.lower().decode('ascii'), value)\n\n    def __getattr__(self, name):\n        \"\"\"\n        Intercept attribute getter to load the file.\n        \"\"\"\n        if name in self.ATTRS:\n            self._load()\n        return self.__dict__[name]\n\n\nclass CurrentMirrorEntry(MetadataEntry):\n    PID_RE = re.compile(b\"^PID\\\\s*([0-9]+)\", re.I | re.M)\n\n    PREFIX = b'current_mirror.'\n    SUFFIXES = [b'.data']\n\n    def extract_pid(self):\n        \"\"\"\n        Return process ID from a current mirror marker, if any\n        \"\"\"\n        with open(self.path, 'rb') as f:\n            match = self.PID_RE.search(f.read())\n        if not match:\n            return None\n        return int(match.group(1))\n\n\nclass LogEntry(MetadataEntry):\n    PREFIX = b'error_log.'\n    SUFFIXES = [b'.data', b'.data.gz']\n\n    @cached_property\n    def is_empty(self):\n        \"\"\"\n        Check if the increment entry is empty.\n        \"\"\"\n        return os.path.getsize(self.path) == 0\n\n    def read(self):\n        \"\"\"Read the error file and return it's content. Raise exception if the\n        file can't be read.\"\"\"\n        # To avoid opening empty file, check the file size first.\n        if self.is_empty:\n            return \"\"\n        encoding = self.repo._encoding.name\n        if self._is_compressed:\n            return subprocess.check_output(\n                ['zcat', self.path],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.STDOUT,\n                encoding=encoding,\n                errors='replace',\n            )\n        with open(self.path, 'r', encoding=encoding, errors='replace') as f:\n            return f.read()\n\n    def tail(self, num=2000):\n        \"\"\"\n        Tail content of the file. This is used for logs.\n        \"\"\"\n        # To avoid opening empty file, check the file size first.\n        if self.is_empty:\n            return b''\n        encoding = self.repo._encoding.name\n        if self._is_compressed:\n            zcat = subprocess.Popen([b'zcat', self.path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n            return subprocess.check_output(\n                ['tail', '-n', str(num)],\n                stdin=zcat.stdout,\n                stderr=subprocess.STDOUT,\n                encoding=encoding,\n                errors='replace',\n            )\n        return subprocess.check_output(\n            ['tail', '-n', str(num), self.path], stderr=subprocess.STDOUT, encoding=encoding, errors='replace'\n        )\n\n\nclass RestoreLogEntry(LogEntry):\n    PREFIX = b'restore.'\n    SUFFIXES = [b'.log']\n\n    @staticmethod\n    def on_date_error(e):\n        return None\n\n\nclass BackupLogEntry(LogEntry):\n    PREFIX = b'backup.'\n    SUFFIXES = [b'.log']\n\n    @staticmethod\n    def on_date_error(e):\n        return None\n\n\nclass MetadataKeys:\n    \"\"\"\n    Provide a view on metadata dict keys. See MetadataDict#keys()\n    \"\"\"\n\n    def __init__(self, function, sequence):\n        self._f = function\n        self._sequence = sequence\n\n    def __iter__(self):\n        return map(self._f, self._sequence)\n\n    def __getitem__(self, i):\n        if isinstance(i, slice):\n            return list(map(self._f, self._sequence[i]))\n        else:\n            return self._f(self._sequence[i])\n\n    def __len__(self):\n        return len(self._sequence)\n\n\nclass MetadataDict(object):\n    \"\"\"\n    This is used to access repository metadata quickly in a pythonic way. It\n    make an abstraction to access a range of increment entries using index and\n    date while also supporting slice to get a range of entries.\n    \"\"\"\n\n    def __init__(self, repo, cls):\n        assert isinstance(repo, RdiffRepo)\n        assert hasattr(cls, '__call__')\n        self._repo = repo\n        assert cls.PREFIX\n        self._prefix = cls.PREFIX\n        self._cls = cls\n\n    @cached_property\n    def _entries(self):\n        return [e for e in self._repo._entries if e.startswith(self._prefix)]\n\n    def __getitem__(self, key):\n        if isinstance(key, RdiffTime):\n            idx = bisect.bisect_left(self.keys(), key)\n            if idx < len(self._entries):\n                item = self._cls(self._repo, self._entries[idx])\n                if item.date == key:\n                    return item\n            raise KeyError(key)\n        elif isinstance(key, slice):\n            if isinstance(key.start, RdiffTime):\n                idx = bisect.bisect_left(self.keys(), key.start)\n                key = slice(idx, key.stop, key.step)\n            if isinstance(key.stop, RdiffTime):\n                idx = bisect.bisect_right(self.keys(), key.stop)\n                key = slice(key.start, idx, key.step)\n            return [self._cls(self._repo, e) for e in self._entries[key]]\n        elif isinstance(key, int):\n            try:\n                return self._cls(self._repo, self._entries[key])\n            except IndexError:\n                raise KeyError(key)\n        else:\n            raise KeyError(key)\n\n    def __iter__(self):\n        for e in self._entries:\n            yield self._cls(self._repo, e)\n\n    def __len__(self):\n        return len(self._entries)\n\n    def keys(self):\n        return MetadataKeys(lambda e: self._cls._extract_date(e), self._entries)\n\n\nclass RdiffRepo(object):\n\n    \"\"\"Represent one rdiff-backup repository.\"\"\"\n\n    def __init__(self, full_path, encoding):\n        assert encoding, 'encoding is required'\n        self._encoding = encodings.search_function(encoding)\n        assert self._encoding, 'encoding must be a valid charset'\n\n        # Validate and sanitize the full_path\n        assert full_path, 'full path is required'\n        self.full_path = os.fsencode(full_path) if isinstance(full_path, str) else full_path\n        assert os.path.isabs(self.full_path), 'full_path must be absolute path'\n        self.full_path = os.path.normpath(self.full_path)\n\n        # The location of rdiff-backup-data directory.\n        self._data_path = os.path.join(self.full_path, RDIFF_BACKUP_DATA)\n        assert isinstance(self._data_path, bytes)\n        self._increment_path = os.path.join(self._data_path, INCREMENTS)\n        self.current_mirror = MetadataDict(self, CurrentMirrorEntry)\n        self.error_log = MetadataDict(self, LogEntry)\n        self.mirror_metadata = MetadataDict(self, MirrorMetadataEntry)\n        self.file_statistics = MetadataDict(self, FileStatisticsEntry)\n        self.session_statistics = MetadataDict(self, SessionStatisticsEntry)\n\n    @property\n    def backup_dates(self):\n        \"\"\"Return a list of dates when backup was executed. This list is\n        sorted from old to new (ascending order). To identify dates,\n        'mirror_metadata' file located in rdiff-backup-data are used.\"\"\"\n        return self.mirror_metadata.keys()\n\n    @property\n    def backup_log(self):\n        \"\"\"\n        Return the location of the backup log.\n        \"\"\"\n        return BackupLogEntry(self, b'backup.log')\n\n    def delete(self, path):\n        \"\"\"\n        Delete this entry from the repository history using rdiff-backup-delete.\n        \"\"\"\n        path_obj = self.fstat(path)\n        if path_obj.isroot:\n            return self.delete_repo()\n\n        rdiff_backup_delete = find_rdiff_backup_delete()\n        cmdline = [rdiff_backup_delete, path_obj.full_path]\n        logger.info('executing: %r' % cmdline)\n        process = subprocess.Popen(cmdline, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env={'LANG': LANG})\n        for line in process.stdout:\n            line = line.rstrip(b'\\n').decode('utf-8', errors='replace')\n            logger.info('rdiff-backup-delete: %s' % line)\n        retcode = process.wait()\n        if retcode:\n            raise CalledProcessError(retcode, cmdline)\n\n    def delete_repo(self):\n        \"\"\"Delete the repository permanently.\"\"\"\n        # Try to change the permissions of the file or directory to delete\n        # them.\n        def handle_error(func, path, exc_info):\n            if exc_info[0] == PermissionError:\n                # Parent directory must allow rwx\n                if not os.access(os.path.dirname(path), os.W_OK | os.R_OK | os.X_OK):\n                    os.chmod(os.path.dirname(path), 0o0700)\n                if not os.access(path, os.W_OK | os.R_OK):\n                    os.chmod(path, 0o0600)\n                if os.path.isdir(path):\n                    return shutil.rmtree(path, onerror=handle_error)\n                else:\n                    return os.unlink(path)\n            raise\n\n        try:\n            shutil.rmtree(self.full_path, onerror=handle_error)\n        except Exception:\n            logger.warning('fail to delete repo', exc_info=1)\n\n    @property\n    def display_name(self):\n        \"\"\"Return the most human representation of the repository name.\"\"\"\n        return self.get_display_name(b'')\n\n    def _decode(self, value, errors='replace'):\n        \"\"\"Used to decode a repository path into unicode.\"\"\"\n        assert isinstance(value, bytes)\n        return self._encoding.decode(value, errors)[0]\n\n    @cached_property\n    def _entries(self):\n        return sorted(os.listdir(self._data_path))\n\n    def expire(self):\n        \"\"\"\n        Clear the cache to refresh metadata.\n        \"\"\"\n        cached_properties = [\n            (self, '_entries'),\n            (self, 'status'),\n            (self.current_mirror, '_entries'),\n            (self.error_log, '_entries'),\n            (self.mirror_metadata, '_entries'),\n            (self.file_statistics, '_entries'),\n            (self.session_statistics, '_entries'),\n        ]\n        for obj, attr in cached_properties:\n            if attr in obj.__dict__:\n                del obj.__dict__[attr]\n\n    def listdir(self, path):\n        \"\"\"\n        Return a list of RdiffDirEntry each representing a file or a folder in the given path.\n        \"\"\"\n        # Compute increment directory location.\n        full_path = os.path.realpath(os.path.join(self.full_path, path.strip(b'/')))\n        relative_path = os.path.relpath(full_path, self.full_path)\n        if relative_path.startswith(RDIFF_BACKUP_DATA):\n            raise DoesNotExistError(path)\n        increment_path = os.path.normpath(os.path.join(self._increment_path, relative_path))\n        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):\n            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))\n\n        # Get list of all increments and existing file and folder\n        try:\n            existing_items = os.listdir(full_path)\n            if relative_path == b'.':\n                existing_items.remove(RDIFF_BACKUP_DATA)\n        except (NotADirectoryError, FileNotFoundError):\n            existing_items = None\n        except OSError:\n            raise AccessDeniedError(path)\n        try:\n            increment_items = os.listdir(increment_path)\n        except (NotADirectoryError, FileNotFoundError):\n            increment_items = None\n        except OSError:\n            raise AccessDeniedError(path)\n        # Raise error if nothing is found\n        if existing_items is None and increment_items is None:\n            raise DoesNotExistError(path)\n\n        # Merge information from both location\n        # Regroup all information into RdiffDirEntry\n        entries = {}\n        for name in existing_items or []:\n            entries[name] = RdiffDirEntry(\n                self,\n                os.path.normpath(os.path.join(relative_path, name)),\n                exists=True,\n                increments=[],\n            )\n        for item in increment_items or []:\n            try:\n                increment = IncrementEntry(item)\n            except ValueError:\n                # Ignore any increment that cannot be parsed\n                continue\n            entry = entries.get(increment.name, None)\n            if not entry:\n                # Create a new Direntry\n                entry = entries[increment.name] = RdiffDirEntry(\n                    self,\n                    os.path.normpath(os.path.join(relative_path, increment.name)),\n                    exists=False,\n                    increments=[increment] if increment else [],\n                )\n            else:\n                # Add increment to dir entry\n                bisect.insort_left(entry._increments, increment)\n        return sorted(list(entries.values()), key=lambda e: e.path)\n\n    def fstat(self, path):\n        \"\"\"Return a new instance of DirEntry to represent the given path.\"\"\"\n        # Compute increment directory location.\n        assert isinstance(path, bytes)\n        full_path = os.path.normpath(os.path.join(self.full_path, path.strip(b'/')))\n        increment_path = os.path.normpath(os.path.join(self._increment_path, path.strip(b'/'), b'..'))\n        if not full_path.startswith(self.full_path) or not increment_path.startswith(self.full_path):\n            raise AccessDeniedError('%s make reference outside the repository' % self._decode(path))\n        relative_path = os.path.relpath(full_path, self.full_path)\n        if relative_path.startswith(RDIFF_BACKUP_DATA):\n            raise DoesNotExistError(path)\n        # Get if the path request is the root path.\n        if relative_path == b'.':\n            return RdiffDirEntry(self, b'', True, [])\n\n        # Check if path exists\n        try:\n            os.lstat(full_path)\n            exists = True\n        except (OSError, ValueError):\n            exists = False\n\n        # Get incrmement data\n        increment_items = os.listdir(increment_path)\n\n        # Create dir entry\n        prefix = os.path.basename(full_path)\n        entry = RdiffDirEntry(self, relative_path, exists, [])\n        for item in increment_items:\n            if not item.startswith(prefix):\n                # Ignore increment not matching our path\n                continue\n            try:\n                increment = IncrementEntry(item)\n            except ValueError:\n                # Ignore any increment that cannot be parsed\n                continue\n            if increment.name != prefix:\n                # Ignore increment not matching our path\n                continue\n            # Add increment to dir entry\n            bisect.insort_left(entry._increments, increment)\n\n        # Check if path exists or has increment. If not raise an exception.\n        if not exists and not entry._increments:\n            logger.error(\"path [%r] doesn't exists\", path)\n            raise DoesNotExistError(path)\n\n        # Create a directory entry.\n        return entry\n\n    @property\n    def last_backup_date(self):\n        \"\"\"Return the last known backup dates.\"\"\"\n        try:\n            if len(self.current_mirror) > 0:\n                return self.current_mirror[-1].date\n            return None\n        except (PermissionError, FileNotFoundError):\n            return None\n\n    def get_display_name(self, path):\n        \"\"\"\n        Return proper display name of the given path according to repository encoding and quoted characters.\n        \"\"\"\n        assert isinstance(path, bytes)\n        path = path.strip(b'/')\n        if path in [b'.', b'']:\n            # For repository the directory base name\n            return self._decode(unquote(os.path.basename(self.full_path)))\n        else:\n            # For path, we use the dir name\n            return self._decode(unquote(os.path.basename(path)))\n\n    def remove_older(self, remove_older_than):\n        assert type(remove_older_than) is int, 'invalid remove_older_than, expect an integer: ' + remove_older_than\n        logger.info(\n            \"execute rdiff-backup --force --remove-older-than=%sD %r\",\n            remove_older_than,\n            self.full_path.decode(sys.getfilesystemencoding(), 'replace'),\n        )\n        subprocess.check_output(\n            [\n                b'rdiff-backup',\n                b'--force',\n                b'--remove-older-than=' + str(remove_older_than).encode(encoding='latin1') + b'D',\n                self.full_path,\n            ]\n        )\n        self.expire()\n\n    def restore(self, path, restore_as_of, kind=None):\n        \"\"\"\n        Restore the current directory entry into a fileobj containing the\n        file content of the directory compressed into an archive.\n\n        `kind` must be one of the supported archive type or none to use `zip` for folder and `raw` for file.\n\n        Return a filename and a fileobj.\n        \"\"\"\n        assert isinstance(path, bytes)\n        assert restore_as_of, \"restore_as_of must be defined\"\n        assert kind in ['tar', 'tar.bz2', 'tar.gz', 'tbz2', 'tgz', 'zip', 'raw', None]\n\n        # Define proper kind according to path type.\n        path_obj = self.fstat(path)\n        if path_obj.isdir:\n            if kind == 'raw':\n                raise ValueError('raw type not supported for directory')\n            kind = kind or 'zip'\n        else:\n            kind = kind or 'raw'\n\n        # Define proper filename according to the path\n        if kind == 'raw':\n            filename = path_obj.display_name\n        else:\n            filename = \"%s.%s\" % (path_obj.display_name, kind)\n\n        # Call external process to offload processing.\n        # python -m rdiffweb.core.restore --restore-as-of 123456 --encoding utf-8 --kind zip -\n        cmdline = [\n            os.fsencode(sys.executable),\n            b'-m',\n            b'rdiffweb.core.restore',\n            b'--restore-as-of',\n            str(restore_as_of).encode('latin'),\n            b'--encoding',\n            self._encoding.name.encode('latin'),\n            b'--kind',\n            kind.encode('latin'),\n            os.path.join(self.full_path, unquote(path_obj.path)),\n            b'-',\n        ]\n        proc = subprocess.Popen(\n            cmdline,\n            shell=False,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            env=None,\n        )\n        # Check if the restore process is properly starting\n        # Read the first 100 line until \"Processing changed file\"\n        max_line = 100\n        output = b''\n        success = False\n        line = proc.stderr.readline()\n        while max_line > 0 and line:\n            max_line -= 1\n            output += line\n            if b'Processing changed file' in line:\n                success = True\n                break\n            line = proc.stderr.readline()\n        if not success:\n            raise CalledProcessError(1, cmdline, output)\n        # Start a Thread to pipe the rest of the stream to the log\n        t = threading.Thread(target=_readerthread, args=(proc.stderr, logger.debug))\n        t.daemon = True\n        t.start()\n        return filename, _wrap_close(proc.stdout, proc)\n\n    @property\n    def restore_log(self):\n        \"\"\"\n        Return the location of the restore log.\n        \"\"\"\n        return RestoreLogEntry(self, b'restore.log')\n\n    @cached_property\n    def status(self):\n        \"\"\"Check if a backup is in progress for the current repo.\"\"\"\n\n        # Read content of the file and check if pid still exists\n        try:\n            # Make sure repoRoot is a valid rdiff-backup repository\n            for current_mirror in self.current_mirror:\n                pid = current_mirror.extract_pid()\n                try:\n                    p = psutil.Process(pid)\n                    if any('rdiff-backup' in c for c in p.cmdline()):\n                        return ('in_progress', _('A backup is currently in progress to this repository.'))\n                except psutil.NoSuchProcess:\n                    logger.debug('pid [%s] does not exists', pid)\n\n            # If multiple current_mirror file exists and none of them are associated to a PID, this mean the last backup was interrupted.\n            # Also, if the last backup date is undefined, this mean the first\n            # initial backup was interrupted.\n            if len(self.current_mirror) > 1 or len(self.current_mirror) == 0:\n                return ('interrupted', _('The previous backup seams to have failed.'))\n        except FileNotFoundError:\n            self._entries = []\n            return ('failed', _('The repository cannot be found or is badly damaged.'))\n        except PermissionError:\n            self._entries = []\n            logger.warning('error reading current_mirror files', exc_info=1)\n            return ('failed', _(\"Permissions denied. Contact administrator to check repository's permissions.\"))\n\n        return ('ok', '')\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport codecs\nimport encodings\nimport logging\nimport os\nimport sys\n\nimport cherrypy\nfrom sqlalchemy import Column, Integer, SmallInteger, String, and_, case, event, orm\nfrom sqlalchemy.ext.hybrid import hybrid_property\nfrom sqlalchemy.orm import relationship, validates\n\nimport rdiffweb.tools.db  # noqa\nfrom rdiffweb.core.librdiff import AccessDeniedError, DoesNotExistError, RdiffRepo\nfrom rdiffweb.tools.i18n import ugettext as _\n\nBase = cherrypy.tools.db.get_base()\n\nlogger = logging.getLogger(__name__)\n\n\ndef _split_path(path):\n    \"\"\"\n    Split the given path into <username as str> / <path as bytes>\n    \"\"\"\n    # First part is the username\n    assert path\n    if isinstance(path, str):\n        path = os.fsencode(path)\n    path = path.strip(b'/')\n    if b'/' in path:\n        username, path = path.split(b'/', 1)\n        return username.decode('utf-8'), path\n    else:\n        return path.decode('utf-8'), b''\n\n\nclass RepoObject(Base, RdiffRepo):\n    DEFAULT_REPO_ENCODING = codecs.lookup((sys.getfilesystemencoding() or 'utf-8').lower()).name\n\n    __tablename__ = 'repos'\n    __table_args__ = {'sqlite_autoincrement': True}\n\n    repoid = Column('RepoID', Integer, primary_key=True, autoincrement=True)\n    userid = Column('UserID', Integer, nullable=False)\n    user = relationship(\n        'UserObject',\n        foreign_keys=[userid],\n        primaryjoin='UserObject.userid == RepoObject.userid',\n        uselist=False,\n        lazy=True,\n    )\n    repopath = Column('RepoPath', String, nullable=False, default='')\n    maxage = Column('MaxAge', SmallInteger, nullable=False, server_default=\"0\")\n    encoding = Column('Encoding', String, default=DEFAULT_REPO_ENCODING)\n    _keepdays = Column('keepdays', String, nullable=False, default=\"-1\")\n\n    @classmethod\n    def get_repo(cls, name, as_user=None, refresh=False):\n        \"\"\"\n        Return the repository identified as `name`.\n        `name` should be <username>/<repopath>\n        \"\"\"\n        from ._user import UserObject\n\n        username, repopath = _split_path(name)\n        repopath = os.fsdecode(repopath).strip('/')\n\n        # Check permissions\n        as_user = as_user or cherrypy.tree.apps[''].currentuser\n        if not as_user:\n            raise AccessDeniedError(\"as_user or current user must be defined\")\n        if username != as_user.username and not as_user.is_admin:\n            raise AccessDeniedError(name)\n\n        # Search the repo in database\n        query = RepoObject.query.join(UserObject, UserObject.userid == RepoObject.userid).filter(\n            and_(UserObject.username == username, RepoObject.repopath == repopath)\n        )\n        record = query.first()\n        # If the repo is not found but refresh is requested\n        if refresh and not record:\n            if as_user.refresh_repos():\n                as_user.commit()\n            record = query.first()\n        # If repo is not found, raise an error\n        if not record:\n            raise DoesNotExistError(username, repopath)\n        return record\n\n    @classmethod\n    def get_repo_path(cls, path, as_user=None, refresh=False):\n        \"\"\"\n        Return a the repository identified by the given `path`.\n        `path` should be <username>/<repopath>/<subdir>\n        \"\"\"\n        assert isinstance(path, bytes) or isinstance(path, str)\n        sep = b'/' if isinstance(path, bytes) else '/'\n        path = path.strip(sep) + sep\n\n        # Since we don't know which part of the \"path\" is the repopath,\n        # we need to do multiple search.\n        try:\n            startpos = 0\n            while True:\n                pos = path.index(sep, startpos)\n                try:\n                    # Run refresh only on first run.\n                    repo_obj = cls.get_repo(path[:pos], as_user, refresh=refresh and startpos == 0)\n                    break\n                except DoesNotExistError:\n                    # Raised when repo doesn't exists\n                    startpos = pos + 1\n            return repo_obj, path[pos + 1 :]\n        except ValueError:\n            raise DoesNotExistError(path)\n\n    @orm.reconstructor\n    def __init_on_load__(self):\n        # RdiffRepo required an absolute full path, When the user_root is invalid, let generate an invalid full path.\n        if not self.user.user_root:\n            full_path = os.path.join('/user_has_an_empty_user_root/', self.repopath.strip('/'))\n        elif not os.path.isabs(self.user.user_root):\n            full_path = os.path.join('/user_has_a_relative_user_root/', self.repopath.strip('/'))\n        else:\n            full_path = os.path.join(self.user.user_root, self.repopath.strip('/'))\n        RdiffRepo.__init__(self, full_path, encoding=self.encoding or RepoObject.DEFAULT_REPO_ENCODING)\n\n    @property\n    def name(self):\n        # Repository name is the \"repopath\"\n        return self.repopath\n\n    @property\n    def owner(self):\n        return self.user.username\n\n    @hybrid_property\n    def keepdays(self):\n        try:\n            return int(self._keepdays) if self._keepdays else -1\n        except ValueError:\n            return -1\n\n    @keepdays.expression\n    def keepdays(cls):\n        return case(\n            (cls._keepdays.is_(None), -1),\n            (cls._keepdays == '', -1),\n            else_=cls._keepdays.cast(Integer),\n        )\n\n    @keepdays.setter\n    def keepdays(self, value):\n        self._keepdays = value\n\n    def delete(self, path=b''):\n        \"\"\"Properly remove the given repository by updating the user's repositories.\"\"\"\n        logger.info(\"deleting repository %s\", self)\n        # Remove data from disk\n        RdiffRepo.delete(self, path=path)\n        # Remove entry from database after deleting files.\n        # Otherwise, refresh will add this repo back.\n        return super().delete()\n\n    @validates('encoding')\n    def validate_encoding(self, key, value):\n        codec = encodings.search_function(value.lower())\n        if not codec:\n            raise ValueError(_('invalid encoding %s') % value)\n        return codec.name\n\n    @validates('maxage')\n    def validate_maxage(self, key, value):\n        int(value)\n        return value\n\n    @validates('_keepdays')\n    def validate_keepdays(self, key, value):\n        int(value)\n        return value\n\n    def __str__(self):\n        return \"RepoObject[%s, %s]\" % (self.userid, self.repopath)\n\n\n@event.listens_for(RepoObject.encoding, \"set\")\ndef encoding_set(target, value, oldvalue, initiator):\n    codec = encodings.search_function(value)\n    if codec:\n        target._encoding = codec\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\"\"\"\nCreated on June 30, 2022\n\nModule to test `user` model.\n\n@author: Patrik Dufresne <patrik@ikus-soft.com>\n\"\"\"\nimport os\nfrom io import StringIO, open\nfrom unittest.mock import MagicMock\n\nimport cherrypy\nimport pkg_resources\nfrom parameterized import parameterized\n\nimport rdiffweb.test\nfrom rdiffweb.core import authorizedkeys\nfrom rdiffweb.core.model import DuplicateSSHKeyError, RepoObject, UserObject\nfrom rdiffweb.core.passwd import check_password\n\n\nclass UserObjectTest(rdiffweb.test.WebCase):\n    def _read_ssh_key(self):\n        \"\"\"Readthe pub key from test packages\"\"\"\n        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_publickey_ssh_rsa.pub')\n        with open(filename, 'r', encoding='utf8') as f:\n            return f.readline()\n\n    def _read_authorized_keys(self):\n        \"\"\"Read the content of test_authorized_keys\"\"\"\n        filename = pkg_resources.resource_filename('rdiffweb.core.tests', 'test_authorized_keys')\n        with open(filename, 'r', encoding='utf8') as f:\n            return f.read()\n\n    def setUp(self):\n        super().setUp()\n        self.listener = MagicMock()\n        cherrypy.engine.subscribe('access_token_added', self.listener.access_token_added, priority=50)\n        cherrypy.engine.subscribe('queue_mail', self.listener.queue_mail, priority=50)\n        cherrypy.engine.subscribe('user_added', self.listener.user_added, priority=50)\n        cherrypy.engine.subscribe('user_attr_changed', self.listener.user_attr_changed, priority=50)\n        cherrypy.engine.subscribe('user_deleted', self.listener.user_deleted, priority=50)\n        cherrypy.engine.subscribe('user_login', self.listener.user_login, priority=50)\n        cherrypy.engine.subscribe('user_password_changed', self.listener.user_password_changed, priority=50)\n\n    def tearDown(self):\n        cherrypy.engine.unsubscribe('access_token_added', self.listener.access_token_added)\n        cherrypy.engine.unsubscribe('queue_mail', self.listener.queue_mail)\n        cherrypy.engine.unsubscribe('user_added', self.listener.user_added)\n        cherrypy.engine.unsubscribe('user_attr_changed', self.listener.user_attr_changed)\n        cherrypy.engine.unsubscribe('user_deleted', self.listener.user_deleted)\n        cherrypy.engine.unsubscribe('user_login', self.listener.user_login)\n        cherrypy.engine.unsubscribe('user_password_changed', self.listener.user_password_changed)\n        return super().tearDown()\n\n    def test_add_user(self):\n        \"\"\"Add user to database.\"\"\"\n        userobj = UserObject.add_user('joe')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('joe'))\n        # Check if listener called\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_add_user_updated_by_listener(self):\n        \"\"\"Add user to database.\"\"\"\n        # Given a listener with side effet\n        def change_user_obj(userobj):\n            userobj.user_root = '/new/value'\n\n        self.listener.user_added.side_effect = change_user_obj\n        # When adding user\n        userobj = UserObject.add_user('joe')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('joe'))\n        # Then lister get called\n        self.listener.user_added.assert_called_once_with(userobj)\n        # Then object was updated by listener\n        self.assertEqual('/new/value', userobj.user_root)\n\n    def test_add_user_with_duplicate(self):\n        \"\"\"Add user to database.\"\"\"\n        user = UserObject.add_user('denise')\n        user.commit()\n        self.listener.user_added.reset_mock()\n        with self.assertRaises(ValueError):\n            UserObject.add_user('denise')\n        # Check if listener called\n        self.listener.user_added.assert_not_called()\n\n    def test_add_user_with_password(self):\n        \"\"\"Add user to database with password.\"\"\"\n        userobj = UserObject.add_user('jo', 'password')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('jo'))\n        # Check if listener called\n        self.listener.user_added.assert_called_once_with(userobj)\n\n    def test_delete_admin_user(self):\n        # Trying to delete admin user should raise an error.\n        userobj = UserObject.get_user('admin')\n        with self.assertRaises(ValueError):\n            userobj.delete()\n\n    def test_users(self):\n        # Check admin exists\n        self.assertEqual(1, UserObject.query.count())\n        # Create user.\n        user = UserObject.add_user('annik')\n        user.commit()\n        users = UserObject.query.all()\n        self.assertEqual(2, len(users))\n        self.assertEqual('annik', users[1].username)\n        # Then 2 user exists\n        self.assertEqual(2, UserObject.query.count())\n\n    def test_get_user(self):\n        # Create new user\n        user = UserObject.add_user('bernie', 'my-password')\n        user.user_root = self.testcases\n        user.role = UserObject.ADMIN_ROLE\n        user.email = 'bernie@gmail.com'\n        user.refresh_repos()\n        user.commit()\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))\n        user.repo_objs[0].maxage = -1\n        user.repo_objs[1].maxage = 3\n        user.commit()\n\n        # Get user record.\n        obj = UserObject.get_user('bernie')\n        self.assertIsNotNone(obj)\n        self.assertEqual('bernie', obj.username)\n        self.assertEqual('bernie@gmail.com', obj.email)\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in obj.repo_objs]))\n        self.assertEqual(self.testcases, obj.user_root)\n        self.assertEqual(True, obj.is_admin)\n        self.assertEqual(UserObject.ADMIN_ROLE, obj.role)\n\n        # Get repo object\n        self.assertEqual('broker-repo', obj.repo_objs[0].name)\n        self.assertEqual(-1, obj.repo_objs[0].maxage)\n        self.assertEqual('testcases', obj.repo_objs[1].name)\n        self.assertEqual(3, obj.repo_objs[1].maxage)\n\n    def test_get_user_with_invalid_user(self):\n        self.assertIsNone(UserObject.get_user('invalid'))\n\n    def test_get_set(self):\n        user = UserObject.add_user('larry', 'password')\n        user.add().commit()\n\n        self.assertEqual('', user.email)\n        self.assertEqual([], user.repo_objs)\n        self.assertEqual('', user.user_root)\n        self.assertEqual(False, user.is_admin)\n        self.assertEqual(UserObject.USER_ROLE, user.role)\n\n        user.user_root = self.testcases\n        user.refresh_repos()\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(user, {'user_root': ('', self.testcases)})\n        self.listener.user_attr_changed.reset_mock()\n        user = UserObject.get_user('larry')\n        user.role = UserObject.ADMIN_ROLE\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(\n            user, {'role': (UserObject.USER_ROLE, UserObject.ADMIN_ROLE)}\n        )\n        self.listener.user_attr_changed.reset_mock()\n        user = UserObject.get_user('larry')\n        user.email = 'larry@gmail.com'\n        user.commit()\n        self.listener.user_attr_changed.assert_called_with(user, {'email': ('', 'larry@gmail.com')})\n        self.listener.user_attr_changed.reset_mock()\n\n        self.assertEqual('larry@gmail.com', user.email)\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in user.repo_objs]))\n        self.assertEqual(self.testcases, user.user_root)\n        self.assertEqual(True, user.is_admin)\n        self.assertEqual(UserObject.ADMIN_ROLE, user.role)\n\n    def test_set_role_null(self):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        user.add().commit()\n        # When trying to set the role to null\n        user.role = None\n        # Then an exception is raised\n        with self.assertRaises(Exception):\n            user.add().commit()\n\n    @parameterized.expand(\n        [\n            (-1, True),\n            (0, True),\n            (5, False),\n            (10, False),\n            (15, False),\n        ]\n    )\n    def test_is_admin(self, role, expected_is_admin):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        # When setting the role value\n        user.role = role\n        user.commit()\n        # Then the is_admin value get updated too\n        self.assertEqual(expected_is_admin, user.is_admin)\n\n    @parameterized.expand(\n        [\n            (-1, True),\n            (0, True),\n            (5, True),\n            (10, False),\n            (15, False),\n        ]\n    )\n    def test_is_maintainer(self, role, expected_is_maintainer):\n        # Given a user\n        user = UserObject.add_user('annik', 'password')\n        # When setting the role value\n        user.role = role\n        user.commit()\n        # Then the is_admin value get updated too\n        self.assertEqual(expected_is_maintainer, user.is_maintainer)\n\n    def test_set_password_update(self):\n        # Given a user in database with a password\n        userobj = UserObject.add_user('annik', 'password')\n        userobj.commit()\n        self.listener.user_password_changed.reset_mock()\n        # When updating the user's password\n        userobj.set_password('new_password')\n        userobj.commit()\n        # Then password is SSHA\n        self.assertTrue(check_password('new_password', userobj.hash_password))\n        # Check if listener called\n        self.listener.user_password_changed.assert_called_once_with(userobj)\n\n    def test_delete_user(self):\n        # Given an existing user in database\n        userobj = UserObject.add_user('vicky')\n        userobj.commit()\n        self.assertIsNotNone(UserObject.get_user('vicky'))\n        # When deleting that user\n        userobj.delete()\n        userobj.commit()\n        # Then user it no longer in database\n        self.assertIsNone(UserObject.get_user('vicky'))\n        # Then listner was called\n        self.listener.user_deleted.assert_called_once_with('vicky')\n\n    def test_set_password_empty(self):\n        \"\"\"Expect error when trying to update password of invalid user.\"\"\"\n        userobj = UserObject.add_user('john')\n        userobj.commit()\n        with self.assertRaises(ValueError):\n            self.assertFalse(userobj.set_password(''))\n\n    def test_disk_quota(self):\n        \"\"\"\n        Just make a call to the function.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.disk_quota\n\n    def test_disk_usage(self):\n        \"\"\"\n        Just make a call to the function.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n        disk_usage = userobj.disk_usage\n        self.assertIsInstance(disk_usage, int)\n\n    def test_add_authorizedkey_without_file(self):\n        \"\"\"\n        Add an ssh key for a user without an authorizedkey file.\n        \"\"\"\n        # Read the pub key\n        key = self._read_ssh_key()\n        # Add the key to the user\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n\n        # validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(1, len(keys), \"expecting one key\")\n        self.assertEqual(\"3c:99:ed:a7:82:a8:71:09:2c:15:3d:78:4a:8c:11:99\", keys[0].fingerprint)\n\n    def test_add_authorizedkey_duplicate(self):\n        # Read the pub key\n        key = self._read_ssh_key()\n        # Add the key to the user\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n        # Add the same key\n        with self.assertRaises(DuplicateSSHKeyError):\n            userobj.add_authorizedkey(key)\n            userobj.commit()\n\n    def test_add_authorizedkey_with_file(self):\n        \"\"\"\n        Add an ssh key for a user with an authorizedkey file.\n        \"\"\"\n        userobj = UserObject.get_user(self.USERNAME)\n\n        # Create empty authorized_keys file\n        os.mkdir(os.path.join(userobj.user_root, '.ssh'))\n        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')\n        open(filename, 'a').close()\n\n        # Read the pub key\n        key = self._read_ssh_key()\n        userobj.add_authorizedkey(key)\n        userobj.commit()\n\n        # Validate\n        with open(filename, 'r') as fh:\n            self.assertEqual(key, fh.read())\n\n    def test_delete_authorizedkey_without_file(self):\n        \"\"\"\n        Remove an ssh key for a user without authorizedkey file.\n        \"\"\"\n        # Update user with ssh keys.\n        data = self._read_authorized_keys()\n        userobj = UserObject.get_user(self.USERNAME)\n        for k in authorizedkeys.read(StringIO(data)):\n            try:\n                userobj.add_authorizedkey(k.getvalue())\n            except ValueError:\n                # Some ssh key in the testing file are not valid.\n                pass\n\n        # Get the keys\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(2, len(keys))\n\n        # Remove a key\n        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")\n        userobj.commit()\n\n        # Validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(1, len(keys))\n\n    def test_delete_authorizedkey_with_file(self):\n        \"\"\"\n        Remove an ssh key for a user with authorizedkey file.\n        \"\"\"\n        # Create authorized_keys file\n        data = self._read_authorized_keys()\n        userobj = UserObject.get_user(self.USERNAME)\n        os.mkdir(os.path.join(userobj.user_root, '.ssh'))\n        filename = os.path.join(userobj.user_root, '.ssh', 'authorized_keys')\n        with open(filename, 'w') as f:\n            f.write(data)\n\n        # Get the keys\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(5, len(keys))\n\n        # Remove a key\n        userobj.delete_authorizedkey(\"9a:f1:69:3c:bc:5a:cd:02:5e:33:bc:cd:c0:01:eb:4c\")\n\n        # Validate\n        keys = list(userobj.authorizedkeys)\n        self.assertEqual(4, len(keys))\n\n    def test_repo_objs(self):\n        # Given a user with a list of repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        repos = sorted(userobj.repo_objs, key=lambda r: r.name)\n        self.assertEqual(['broker-repo', 'testcases'], [r.name for r in repos])\n        # When deleting a repository empty list\n        repos[1].delete()\n        repos[1].commit()\n        # Then the repository is removed from the list.\n        self.assertEqual(['broker-repo'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_without_delete(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        RepoObject.query.delete()\n        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()\n        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))\n        # When updating the repository list without deletion\n        userobj.refresh_repos()\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        self.assertEqual(['broker-repo', 'invalid', 'testcases'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_with_delete(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        RepoObject.query.delete()\n        RepoObject(userid=userobj.userid, repopath='invalid').add().commit()\n        self.assertEqual(['invalid'], sorted([r.name for r in userobj.repo_objs]))\n        # When updating the repository list without deletion\n        userobj.refresh_repos(delete=True)\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        userobj.expire()\n        self.assertEqual(['broker-repo', 'testcases'], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_with_single_repo(self):\n        # Given a user with invalid repositories\n        userobj = UserObject.get_user(self.USERNAME)\n        userobj.user_root = os.path.join(self.testcases, 'testcases')\n        # When updating the repository list without deletion\n        userobj.refresh_repos(delete=True)\n        userobj.commit()\n        # Then the list invlaid the invalid repo and new repos\n        userobj.expire()\n        self.assertEqual([''], sorted([r.name for r in userobj.repo_objs]))\n\n    def test_refresh_repos_with_empty_userroot(self):\n        # Given a user with valid repositories relative to root\n        userobj = UserObject.get_user(self.USERNAME)\n        for repo in userobj.repo_objs:\n            repo.repopath = self.testcases[1:] + '/' + repo.repopath\n            repo.add().commit()\n        userobj.user_root = '/'\n        userobj.add().commit()\n        self.assertEqual(['interrupted', 'ok'], sorted([r.status[0] for r in userobj.repo_objs]))\n        # When updating it's userroot directory to an empty value\n        userobj.user_root = ''\n        userobj.add().commit()\n        UserObject.session.expire_all()\n        # Then close session\n        cherrypy.tools.db.on_end_resource()\n        # Then repo status is \"broken\"\n        userobj = UserObject.get_user(self.USERNAME)\n        self.assertFalse(userobj.valid_user_root())\n        self.assertEqual(['failed', 'failed'], [r.status[0] for r in userobj.repo_objs])\n\n\nclass UserObjectWithAdminPassword(rdiffweb.test.WebCase):\n\n    # password: test\n    default_config = {'admin-password': '{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e'}\n\n    def setUp(self):\n        # Do nothing - We need to skip the default setup to avoid deleting the records.\n        pass\n\n    def test_create_admin_user(self):\n        # Given admin-password is configure\n        # When database get created\n        # Then admin user get created with 'test' password\n        userobj = UserObject.get_user(self.USERNAME)\n        self.assertIsNotNone(userobj)\n        self.assertEqual('{SSHA}wbSK4hlEX7mtGJplFi2oN6ABm6Y3Bo1e', userobj.hash_password)\n        self.assertTrue(check_password('test', userobj.hash_password))\n\n        # Given admin-password is configure\n        # When trying to update admin password\n        # Then an exception is raised\n        userobj = UserObject.get_user(self.USERNAME)\n        with self.assertRaises(ValueError):\n            userobj.set_password('newpassword')\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport datetime\nimport logging\nimport os\nfrom collections import OrderedDict, namedtuple\nfrom io import StringIO\n\nimport cherrypy\nimport humanfriendly\nimport jinja2\nfrom jinja2 import Environment, PackageLoader\nfrom jinja2.filters import do_mark_safe\nfrom jinja2.loaders import ChoiceLoader\n\nfrom rdiffweb.core import librdiff, rdw_helpers\nfrom rdiffweb.core.model import RepoObject\nfrom rdiffweb.tools import i18n\nfrom rdiffweb.tools.i18n import ugettext as _\n\n# Define the logger\nlogger = logging.getLogger(__name__)\n\n_ParentEntry = namedtuple(\"_ParentEntry\", 'path,display_name')\n\n\ndef attrib(**kwargs):\n    \"\"\"Generate an attribute list from the keyword argument.\"\"\"\n\n    def _escape(text):\n        if isinstance(text, bytes):\n            text = text.decode('ascii', 'replace')\n        text = str(text)\n        if \"&\" in text:\n            text = text.replace(\"&\", \"&amp;\")\n        if \"<\" in text:\n            text = text.replace(\"<\", \"&lt;\")\n        if \">\" in text:\n            text = text.replace(\">\", \"&gt;\")\n        if \"\\\"\" in text:\n            text = text.replace(\"\\\"\", \"&quot;\")\n        return text\n\n    def _format(key, val):\n        # Don't write the attribute if value is False\n        if val is False:\n            return\n        if val is True:\n            yield str(key)\n            return\n        if isinstance(val, list):\n            val = ' '.join([_escape(v) for v in val if v])\n        else:\n            val = _escape(val)\n        if not val:\n            return\n        yield '%s=\"%s\"' % (str(key), val)\n\n    first = True\n    buf = StringIO()\n    for key, val in sorted(kwargs.items()):\n        for t in _format(key, val):\n            if not first:\n                buf.write(' ')\n            first = False\n            buf.write(t)\n    data = buf.getvalue()\n    buf.close()\n    return do_mark_safe(data)\n\n\ndef do_filter(sequence, attribute_name):\n    \"\"\"Filter sequence of objects.\"\"\"\n    return [\n        x\n        for x in sequence\n        if (isinstance(x, dict) and attribute_name in x and x[attribute_name])\n        or (hasattr(x, attribute_name) and getattr(x, attribute_name))\n    ]\n\n\ndef do_format_lastupdated(value, now=None):\n    \"\"\"\n    Used to format date as \"Updated 10 minutes ago\".\n\n    Value could be a RdiffTime or an epoch as int.\n    \"\"\"\n    if not value:\n        return \"\"\n    now = librdiff.RdiffTime(now)\n    if isinstance(value, librdiff.RdiffTime):\n        delta = now.epoch() - value.epoch()\n    elif isinstance(value, datetime.datetime):\n        delta = now.epoch() - value.timestamp()\n    else:\n        delta = now.epoch() - value\n    delta = datetime.timedelta(seconds=delta)\n    if delta.days > 365:\n        return _('%d years ago') % (delta.days / 365)\n    if delta.days > 60:\n        return _('%d months ago') % (delta.days / 30)\n    if delta.days > 7:\n        return _('%d weeks ago') % (delta.days / 7)\n    elif delta.days > 1:\n        return _('%d days ago') % delta.days\n    elif delta.seconds > 3600:\n        return _('%d hours ago') % (delta.seconds / 3600)\n    elif delta.seconds > 60:\n        return _('%d minutes ago') % (delta.seconds / 60)\n    return _('%d seconds ago') % delta.seconds\n\n\ndef create_repo_tree(repos):\n    \"\"\"\n    Organise the repositories into a tree.\n    \"\"\"\n    repos = sorted(repos, key=lambda r: r.display_name)\n    repo_tree = OrderedDict()\n    for repo in repos:\n        h = repo_tree\n        key = repo.display_name.strip('/').split('/')\n        for p in key[:-1]:\n            if p in h and isinstance(h[p], RepoObject):\n                h[p] = {'.': h[p]}\n            h = h.setdefault(p, {})\n        h[key[-1]] = repo\n    return repo_tree\n\n\ndef list_parents(repo, path):\n    assert isinstance(path, bytes)\n    # Build the parameters\n    # Build \"parent directories\" links\n    parents = [_ParentEntry(b'', repo.display_name)]\n    parent_path_b = b''\n    for part_b in path.split(b'/'):\n        if part_b:\n            parent_path_b = os.path.join(parent_path_b, part_b)\n            display_name = repo._decode(librdiff.unquote(part_b))\n            parents.append(_ParentEntry(parent_path_b, display_name))\n    return parents\n\n\ndef url_for(*args, **kwargs):\n    \"\"\"\n    Generate a url for the given endpoint, path (*args) with parameters (**kwargs)\n\n    This could be used to generate a path with userobject and repo object\n\n    \"\"\"\n    path = \"\"\n    for chunk in args:\n        if not chunk:\n            continue\n        if hasattr(chunk, 'owner') and hasattr(chunk, 'repopath'):\n            # This is a RepoObject\n            path += \"/\"\n            path += chunk.owner\n            path += \"/\"\n            path += rdw_helpers.quote_url(chunk.repopath.strip(\"/\"))\n        elif hasattr(chunk, 'path'):\n            # This is a DirEntry\n            if chunk.path:\n                path += \"/\"\n                path += rdw_helpers.quote_url(chunk.path.strip(b\"/\"))\n        elif chunk and isinstance(chunk, bytes):\n            path += \"/\"\n            path += rdw_helpers.quote_url(chunk.strip(b\"/\"))\n        elif chunk and isinstance(chunk, str):\n            path += \"/\"\n            path += chunk.strip(\"/\")\n        else:\n            raise ValueError('invalid positional arguments, url_for accept str, bytes or RepoPath: %r' % chunk)\n    # Sort the arguments to have predictable results.\n    qs = [(k, v.epoch() if hasattr(v, 'epoch') else v) for k, v in sorted(kwargs.items()) if v is not None]\n    return cherrypy.url(path=path, qs=qs)\n\n\nclass TemplateManager(object):\n    \"\"\"\n    Uses to generate HTML page from template using Jinja2 templating.\n    \"\"\"\n\n    def __init__(self):\n        # Load all the templates from /templates directory\n        loader = ChoiceLoader([PackageLoader('rdiffweb', 'templates')])\n\n        # With and autoescape are included by dfault in Jinja2>=3\n        extensions = ['jinja2.ext.i18n']\n        if jinja2.__version__[0] <= '2':\n            extensions.extend(['jinja2.ext.with_', 'jinja2.ext.autoescape'])\n        self.jinja_env = Environment(\n            loader=loader,\n            auto_reload=True,\n            autoescape=True,\n            extensions=extensions,\n        )\n\n        # Register filters\n        self.jinja_env.filters['filter'] = do_filter\n        self.jinja_env.filters['lastupdated'] = do_format_lastupdated\n        self.jinja_env.filters['filesize'] = lambda x: humanfriendly.format_size(x, binary=True)\n\n        # Register method\n        self.jinja_env.globals['attrib'] = attrib\n        self.jinja_env.globals['create_repo_tree'] = create_repo_tree\n        self.jinja_env.globals['list_parents'] = list_parents\n        self.jinja_env.globals['url_for'] = url_for\n\n    def compile_template(self, template_name, **kwargs):\n        \"\"\"Very simple implementation to render template using jinja2.\n        `templateName`\n            The filename to be used as template.\n        `kwargs`\n            The arguments to be passed to the template.\n        \"\"\"\n        logger.log(1, \"compiling template [%s]\", template_name)\n        self.jinja_env.install_gettext_callables(i18n.ugettext, i18n.ungettext, newstyle=True)\n        template = self.jinja_env.get_template(template_name)\n        data = template.render(kwargs)\n        logger.log(1, \"template [%s] compiled\", template_name)\n        return data\n", "# -*- coding: utf-8 -*-\n# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\"\"\"\nCreated on Oct 3, 2015\n\nModule used to test the librdiff.\n\n@author: Patrik Dufresne\n\"\"\"\nimport datetime\nimport os\nimport shutil\nimport tarfile\nimport tempfile\nimport time\nimport unittest\nfrom inspect import isclass\nfrom unittest.case import skipIf\n\nimport pkg_resources\nfrom parameterized import parameterized\n\nfrom rdiffweb.core.librdiff import (\n    AccessDeniedError,\n    DoesNotExistError,\n    FileStatisticsEntry,\n    IncrementEntry,\n    RdiffDirEntry,\n    RdiffRepo,\n    RdiffTime,\n    SessionStatisticsEntry,\n    rdiff_backup_version,\n    unquote,\n)\n\n\nclass MockRdiffRepo(RdiffRepo):\n    def __init__(self):\n        p = bytes(pkg_resources.resource_filename('rdiffweb.core', 'tests'), encoding='utf-8')  # @UndefinedVariable\n        RdiffRepo.__init__(self, p, encoding='utf-8')\n        self.root_path = MockDirEntry(self)\n\n\nclass MockDirEntry(RdiffDirEntry):\n    def __init__(self, repo):\n        self._repo = repo\n        self.path = b''\n\n\nclass IncrementEntryTest(unittest.TestCase):\n    def test_init(self):\n        increment = IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')\n        self.assertEqual(b'my_filename.txt', increment.name)\n        self.assertEqual(RdiffTime(1414967021), increment.date)\n        self.assertEqual(b'.diff.gz', increment.suffix)\n\n    def test_extract_date(self):\n        self.assertEqual(\n            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz')\n        )\n        self.assertEqual(\n            RdiffTime(1414967021), IncrementEntry._extract_date(b'my_filename.txt.2014-11-02T17-23-41-05-00.diff.gz')\n        )\n        # Check if date with quoted characther are proerply parsed.\n        # On NTFS, colon (:) are not supported.\n        self.assertEqual(\n            RdiffTime(1483443123),\n            IncrementEntry._extract_date(b'my_filename.txt.2017-01-03T06;05832;05803-05;05800.diff.gz'),\n        )\n\n\nclass RdiffDirEntryTest(unittest.TestCase):\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n\n    def test_init(self):\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, [])\n        self.assertFalse(entry.isdir)\n        self.assertFalse(entry.exists)\n        self.assertEqual(os.path.join(b'my_filename.txt'), entry.path)\n        self.assertEqual(os.path.join(self.repo.full_path, b'my_filename.txt'), entry.full_path)\n\n    def test_change_dates(self):\n        \"\"\"Check if dates are properly sorted.\"\"\"\n        increments = [\n            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),\n            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),\n            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),\n        ]\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', False, increments)\n\n        self.assertEqual(\n            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates\n        )\n\n    def test_change_dates_with_exists(self):\n        \"\"\"Check if dates are properly sorted.\"\"\"\n        increments = [\n            IncrementEntry(b'my_filename.txt.2014-11-02T17:23:41-05:00.diff.gz'),\n            IncrementEntry(b'my_filename.txt.2014-11-02T09:16:43-05:00.missing'),\n            IncrementEntry(b'my_filename.txt.2014-11-03T19:04:57-05:00.diff.gz'),\n        ]\n        entry = RdiffDirEntry(self.repo, b'my_filename.txt', True, increments)\n\n        self.assertEqual(\n            [RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')], entry.change_dates\n        )\n\n    def test_display_name(self):\n        \"\"\"Check if display name is unquoted and unicode.\"\"\"\n        entry = RdiffDirEntry(self.repo, b'my_dir', True, [])\n        self.assertEqual('my_dir', entry.display_name)\n\n        entry = RdiffDirEntry(self.repo, b'my;090dir', True, [])\n        self.assertEqual('myZdir', entry.display_name)\n\n    def test_file_size(self):\n        # Given a dir increment\n        increments = [\n            IncrementEntry(\n                bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial.2014-11-05T16:05:07-05:00.dir', encoding='utf-8'),\n            )\n        ]\n        entry = RdiffDirEntry(\n            self.repo, bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'), False, increments\n        )\n        # When getting the file_size\n        # Then the size is 0\n        self.assertEqual(-1, entry.file_size)\n\n    def test_file_size_without_stats(self):\n        increments = [IncrementEntry(b'my_file.2014-11-05T16:04:30-05:00.dir')]\n        entry = RdiffDirEntry(self.repo, b'my_file', False, increments)\n        self.assertEqual(-1, entry.file_size)\n\n\nclass FileErrorTest(unittest.TestCase):\n    def test_init(self):\n        e = DoesNotExistError('some/path')\n        self.assertEqual('some/path', str(e))\n\n        e = AccessDeniedError('some/path')\n        self.assertEqual('some/path', str(e))\n\n\nclass FileStatisticsEntryTest(unittest.TestCase):\n    \"\"\"\n    Test the file statistics entry.\n    \"\"\"\n\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n\n    def test_get_mirror_size(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')\n        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(143, size)\n\n    def test_get_source_size(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data')\n        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(286, size)\n\n    def test_get_mirror_size_gzip(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')\n        size = entry.get_mirror_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(143, size)\n\n    def test_get_source_size_gzip(self):\n        entry = FileStatisticsEntry(self.repo, b'file_statistics.2014-11-05T16:05:07-05:00.data.gz')\n        size = entry.get_source_size(bytes('<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial', encoding='utf-8'))\n        self.assertEqual(286, size)\n\n\nclass LogEntryTest(unittest.TestCase):\n    def setUp(self):\n        self.repo = MockRdiffRepo()\n        self.root_path = self.repo.root_path\n\n    @parameterized.expand(\n        [\n            (\n                'with_uncompress',\n                '2015-11-19T07:27:46-05:00',\n                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',\n            ),\n            (\n                'with_compress',\n                '2015-11-20T07:27:46-05:00',\n                'SpecialFileError home/coucou Socket error: AF_UNIX path too long',\n            ),\n        ]\n    )\n    def test_errors_tail(self, unused, date, expected_content):\n        entry = self.repo.error_log[RdiffTime(date)]\n        self.assertIsNotNone(entry)\n        self.assertEqual(entry.tail(), expected_content)\n\n\nclass RdiffRepoTest(unittest.TestCase):\n    def setUp(self):\n        # Extract 'testcases.tar.gz'\n        testcases = pkg_resources.resource_filename('rdiffweb.tests', 'testcases.tar.gz')  # @UndefinedVariable\n        self.temp_dir = tempfile.mkdtemp(prefix='rdiffweb_tests_')\n        tarfile.open(testcases).extractall(self.temp_dir)\n        # Define location of testcases\n        self.testcases_dir = os.path.normpath(os.path.join(self.temp_dir, 'testcases'))\n        self.testcases_dir = self.testcases_dir.encode('utf8')\n        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')\n\n    def tearDown(self):\n        shutil.rmtree(self.temp_dir.encode('utf8'), True)\n\n    def test_init(self):\n        self.assertEqual('testcases', self.repo.display_name)\n\n    def test_init_with_absolute(self):\n        self.repo = RdiffRepo(os.path.join(self.temp_dir, '/testcases'), encoding='utf-8')\n        self.assertEqual('testcases', self.repo.display_name)\n\n    def test_init_with_invalid(self):\n        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'invalid'), encoding='utf-8')\n        self.assertEqual('failed', self.repo.status[0])\n        self.assertEqual(None, self.repo.last_backup_date)\n        self.assertEqual('invalid', self.repo.display_name)\n\n    @parameterized.expand(\n        [\n            (\n                \"with_root\",\n                b\"/\",\n                'testcases',\n                b'',\n                True,\n                True,\n                True,\n                -1,\n                [\n                    '2014-11-01T15:49:47-04:00',\n                    '2014-11-01T15:50:26-04:00',\n                    '2014-11-01T15:50:48-04:00',\n                    '2014-11-01T15:51:15-04:00',\n                    '2014-11-01T15:51:29-04:00',\n                    '2014-11-01T16:30:22-04:00',\n                    '2014-11-01T16:30:50-04:00',\n                    '2014-11-01T18:07:19-04:00',\n                    '2014-11-01T20:12:45-04:00',\n                    '2014-11-01T20:18:11-04:00',\n                    '2014-11-01T20:51:18-04:00',\n                    '2014-11-02T09:16:43-05:00',\n                    '2014-11-02T09:50:53-05:00',\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:01:02-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-01-20T10:42:21-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_dir\",\n                b\"Subdirectory\",\n                'Subdirectory',\n                b'Subdirectory',\n                True,\n                True,\n                False,\n                -1,\n                [\n                    '2014-11-05T16:04:55-05:00',\n                    '2016-01-20T10:42:21-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_dir_utf8_char\",\n                b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\",\n                'Fold\u00e8r with \u00e9ncod\u00efng',\n                b'Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:04:55-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_dir\",\n                b\"Revisions\",\n                'Revisions',\n                b'Revisions',\n                True,\n                True,\n                False,\n                -1,\n                [\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_file\",\n                b'Revisions/Data',\n                'Data',\n                b'Revisions/Data',\n                True,\n                False,\n                False,\n                9,\n                [\n                    '2014-11-03T19:04:57-05:00',\n                    '2014-11-05T16:04:30-05:00',\n                    '2014-11-05T16:04:55-05:00',\n                    '2014-11-05T16:05:07-05:00',\n                    '2016-02-02T16:30:40-05:00',\n                ],\n            ),\n            (\n                \"with_broken_symlink\",\n                b'BrokenSymlink',\n                'BrokenSymlink',\n                b'BrokenSymlink',\n                True,\n                False,\n                False,\n                7,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;090 to quote',\n                'Char Z to quote',\n                b'Char ;090 to quote',\n                False,\n                True,\n                False,\n                -1,\n                ['2014-11-01T18:07:19-04:00', '2014-11-01T20:18:11-04:00', '2014-11-03T19:04:57-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;059090 to quote',\n                'Char ;090 to quote',\n                b'Char ;059090 to quote',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-03T15:46:47-05:00', '2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_char_to_quote\",\n                b'Char ;059059090 to quote',\n                'Char ;059090 to quote',\n                b'Char ;059059090 to quote',\n                False,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:04:55-05:00', '2016-01-20T10:42:21-05:00'],\n            ),\n            (\n                \"with_loop_symlink\",\n                b'Subdirectory/LoopSymlink',\n                'LoopSymlink',\n                b'Subdirectory/LoopSymlink',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_subdir_symlink\",\n                b'SymlinkToSubdirectory',\n                'SymlinkToSubdirectory',\n                b'SymlinkToSubdirectory',\n                True,\n                True,\n                False,\n                -1,\n                ['2014-11-05T16:05:07-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n        ]\n    )\n    def test_fstat(self, unused, input, display_name, path, exists, isdir, isroot, file_size, change_dates):\n        dir_entry = self.repo.fstat(input)\n        self.assertEqual(display_name, dir_entry.display_name)\n        self.assertEqual(path, dir_entry.path)\n        self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)\n        self.assertEqual(exists, dir_entry.exists)\n        self.assertEqual(isdir, dir_entry.isdir)\n        self.assertEqual(isroot, dir_entry.isroot)\n        self.assertEqual(file_size, dir_entry.file_size)\n        self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))\n        # For consistency, check if the same value are retreived using listdir\n        if not isroot:\n            parent_dir = os.path.dirname(input)\n            children = self.repo.listdir(parent_dir)\n            dir_entry = next(c for c in children if c.path == input)\n            self.assertEqual(display_name, dir_entry.display_name)\n            self.assertEqual(path, dir_entry.path)\n            self.assertEqual(os.path.join(self.testcases_dir, path).rstrip(b'/'), dir_entry.full_path)\n            self.assertEqual(exists, dir_entry.exists)\n            self.assertEqual(isdir, dir_entry.isdir)\n            self.assertEqual(isroot, dir_entry.isroot)\n            self.assertEqual(file_size, dir_entry.file_size)\n            self.assertEqual([RdiffTime(t) for t in change_dates], list(dir_entry.change_dates))\n\n    def test_fstat_outside_repo(self):\n        with self.assertRaises(AccessDeniedError):\n            self.repo.fstat(b\"../\")\n\n    @parameterized.expand(\n        [\n            (\n                \"with_root\",\n                b\"\",\n                [\n                    '<F!ch\u00efer> (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',\n                    'BrokenSymlink',\n                    'Char ;059090 to quote',\n                    'Char ;090 to quote',\n                    'Char Z to quote',\n                    'DIR\ufffd',\n                    'Fichier @ <root>',\n                    'Fichier avec non asci char \ufffdvelyne M\ufffdre.txt',\n                    'Revisions',\n                    'R\u00e9pertoire (@vec) {c\u00e0ra\u00e7t#\u00e8r\u00eb} $\u00e9p\u00eacial',\n                    'R\u00e9pertoire Existant',\n                    'R\u00e9pertoire Supprim\u00e9',\n                    'Subdirectory',\n                    'SymlinkToSubdirectory',\n                    'test\\\\test',\n                    '\uc774\ub8e8\ub9c8 YIRUMA - River Flows in You.mp3',\n                ],\n            ),\n            (\"with_children utf8_char\", b\"Subdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\", ['my file']),\n            (\"with_dir\", b\"Revisions\", ['Data']),\n            (\"with_file\", b\"Revisions/Data\", DoesNotExistError),\n            (\"with_broken_symlink\", b\"BrokenSymlink\", DoesNotExistError),\n            (\"with_loop_symlink\", b\"Subdirectory/LoopSymlink\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n            (\"with_subdir_symlink\", b\"SymlinkToSubdirectory\", ['Fold\u00e8r with \u00e9ncod\u00efng', 'LoopSymlink']),\n        ]\n    )\n    def test_listdir(self, unused, path, listdir):\n        if isclass(listdir) and issubclass(listdir, Exception):\n            with self.assertRaises(listdir):\n                self.repo.listdir(path)\n            return\n        self.assertEqual(listdir, sorted([d.display_name for d in self.repo.listdir(path)]))\n\n    def test_listdir_outside_repo(self):\n        with self.assertRaises(AccessDeniedError):\n            self.repo.listdir(b\"../\")\n\n    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")\n    def test_listdir_empty_folder(self):\n        # Given a folder without data\n        self.repo.delete(b\"Revisions/Data\")\n        # When listing entries\n        entries = self.repo.listdir(b\"Revisions\")\n        # Then the list is empty.\n        self.assertEqual([], entries)\n\n    def test_listdir_attributes(self):\n        children = self.repo.listdir(b\"Revisions\")\n        self.assertEqual(1, len(children))\n        dir_entry = children[0]\n        self.assertEqual('Data', dir_entry.display_name)\n        self.assertEqual(b'Revisions/Data', dir_entry.path)\n        self.assertEqual(os.path.join(self.testcases_dir, b'Revisions/Data'), dir_entry.full_path)\n        self.assertEqual(True, dir_entry.exists)\n        self.assertEqual(False, dir_entry.isdir)\n        self.assertEqual(False, dir_entry.isroot)\n        self.assertEqual(9, dir_entry.file_size)\n        self.assertEqual(\n            [\n                RdiffTime('2014-11-03T19:04:57-05:00'),\n                RdiffTime('2014-11-05T16:04:30-05:00'),\n                RdiffTime('2014-11-05T16:04:55-05:00'),\n                RdiffTime('2014-11-05T16:05:07-05:00'),\n                RdiffTime('2016-02-02T16:30:40-05:00'),\n            ],\n            list(dir_entry.change_dates),\n        )\n\n    def test_with_rdiff_backup_data(self):\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(b'rdiff-backup-data')\n        with self.assertRaises(DoesNotExistError):\n            self.repo.listdir(b'rdiff-backup-data')\n\n    def test_with_invalid(self):\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(b'invalid')\n        with self.assertRaises(DoesNotExistError):\n            self.repo.listdir(b'invalid')\n\n    def test_status(self):\n        status = self.repo.status\n        self.assertEqual('ok', status[0])\n        self.assertEqual('', status[1])\n\n    def test_status_access_denied_current_mirror(self):\n        # Skip test if running as root. Because root as access to everything.\n        if os.geteuid() == 0:\n            return\n        # Change the permissions of the files.\n        os.chmod(\n            os.path.join(self.testcases_dir, b'rdiff-backup-data', b'current_mirror.2016-02-02T16:30:40-05:00.data'),\n            0000,\n        )\n        # Create repo again to query status\n        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')\n        status = self.repo.status\n        self.assertEqual('failed', status[0])\n\n    def test_status_access_denied_rdiff_backup_data(self):\n        # Skip test if running as root. Because root as access to everything.\n        if os.geteuid() == 0:\n            return\n        # Change the permissions of the files.\n        os.chmod(os.path.join(self.testcases_dir, b'rdiff-backup-data'), 0000)\n        # Query status.\n        self.repo = RdiffRepo(os.path.join(self.temp_dir, 'testcases'), encoding='utf-8')\n        status = self.repo.status\n        self.assertEqual('failed', status[0])\n        # Make sure history entry doesn't raise error\n        list(self.repo.mirror_metadata)\n\n    def test_remove_older(self):\n        # Given a repository with history\n        self.assertEqual(22, len(self.repo.mirror_metadata))\n        # When removing older then 1D\n        self.repo.remove_older(1)\n        # Then all history get deleted up to one\n        self.assertEqual(1, len(self.repo.mirror_metadata))\n\n    @parameterized.expand(\n        [\n            (\"with_root\", b'/', 1454448640, 'zip', 'testcases.zip', b'PK\\x03\\x04'),\n            (\"with_zip\", b'Revisions', 1454448640, 'zip', 'Revisions.zip', b'PK\\x03\\x04'),\n            (\"with_tar\", b'Revisions', 1454448640, 'tar', 'Revisions.tar', b'././@PaxHeader'),\n            (\"with_tar_gz\", b'Revisions', 1454448640, 'tar.gz', 'Revisions.tar.gz', b'\\x1f\\x8b'),\n            (\"with_tar_bz2\", b'Revisions', 1454448640, 'tar.bz2', 'Revisions.tar.bz2', b'BZh'),\n            (\"with_none_file\", b'Revisions/Data', 1454448640, None, 'Data', b'Version3\\n'),\n            (\"with_raw_file\", b'Revisions/Data', 1454448640, 'raw', 'Data', b'Version3\\n'),\n            (\"with_zip_file\", b'Revisions/Data', 1454448640, 'zip', 'Data.zip', b'PK\\x03\\x04'),\n        ]\n    )\n    def test_restore(self, unused, path, restore_as_of, kind, expected_filename, expected_startswith):\n        filename, stream = self.repo.restore(path, restore_as_of=restore_as_of, kind=kind)\n        self.assertEqual(expected_filename, filename)\n        data = stream.read()\n        self.assertTrue(data.startswith(expected_startswith))\n\n    def test_unquote(self):\n        self.assertEqual(b'Char ;090 to quote', unquote(b'Char ;059090 to quote'))\n\n    def test_error_log_range(self):\n        logs = self.repo.error_log[0:1]\n        self.assertEqual(1, len(logs))\n        self.assertEqual(\"\", self.repo.error_log[0].read())\n\n    def test_backup_log(self):\n        self.assertEqual(\"\", self.repo.backup_log.read())\n\n    def test_restore_log(self):\n        self.assertEqual(\n            self.repo.restore_log.read(),\n            \"\"\"Starting restore of /home/ikus060/Downloads/testcases to /tmp/tmpKDNO4t/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpnG33kc/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpGUEHJC/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBlFPsW/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpkfCejo/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmphXpFnS as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_udS97a/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_LL4rCm/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_zpYgT3/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_7H93yy/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_Xe2CfG/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/rdiffweb_restore_rHFERA/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpF7rSar/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpgHTL2j/root as it was as of Wed Nov  5 16:05:07 2014.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpVo1u4Z/root as it was as of Wed Jan 20 10:42:21 2016.\nStarting restore of /home/ikus060/Downloads/testcases to /tmp/tmpBRxRxe/root as it was as of Wed Jan 20 10:42:21 2016.\n\"\"\",\n        )\n\n    @parameterized.expand(\n        [\n            (\n                \"with_idx_1\",\n                1,\n                '2014-11-01T15:50:26-04:00',\n            ),\n            (\n                \"with_idx_2\",\n                2,\n                '2014-11-01T15:50:48-04:00',\n            ),\n            (\n                \"with_idx_3\",\n                3,\n                '2014-11-01T15:51:15-04:00',\n            ),\n            (\n                \"with_neg_idx_1\",\n                -1,\n                '2016-02-02T16:30:40-05:00',\n            ),\n            (\n                \"with_date\",\n                RdiffTime('2016-02-02T16:30:40-05:00'),\n                '2016-02-02T16:30:40-05:00',\n            ),\n            (\n                \"with_slice_idx\",\n                slice(0, 2),\n                [\n                    '2014-11-01T15:49:47-04:00',\n                    '2014-11-01T15:50:26-04:00',\n                ],\n            ),\n            (\n                \"with_slice_date_start\",\n                slice(RdiffTime('2016-01-20T10:42:21-05:00'), None),\n                ['2016-01-20T10:42:21-05:00', '2016-02-02T16:30:40-05:00'],\n            ),\n            (\n                \"with_slice_date_start_stop\",\n                slice(\n                    RdiffTime('2014-11-02T17:00:00-05:00'),\n                    RdiffTime('2014-11-04T00:00:00-05:00'),\n                ),\n                [\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                ],\n            ),\n            (\n                \"with_slice_date_start_stop_exact_match\",\n                slice(RdiffTime('2014-11-02T17:23:41-05:00'), RdiffTime('2014-11-03T19:04:57-05:00')),\n                [\n                    '2014-11-02T17:23:41-05:00',\n                    '2014-11-03T15:46:47-05:00',\n                    '2014-11-03T19:04:57-05:00',\n                ],\n            ),\n            (\n                \"with_slice_invalid_idx\",\n                slice(100, 120),\n                [],\n            ),\n            (\n                \"with_keyerror_date\",\n                RdiffTime('2022-11-03T15:46:47-05:00'),\n                KeyError,\n            ),\n            (\n                \"with_keyerror_int\",\n                1024,\n                KeyError,\n            ),\n        ]\n    )\n    def test_session_statistics(self, unsed, value, expected_value):\n        if isinstance(expected_value, list):\n            self.assertEqual(expected_value, [str(o.date) for o in self.repo.session_statistics[value]])\n        elif isclass(expected_value) and issubclass(expected_value, Exception):\n            with self.assertRaises(expected_value):\n                self.repo.session_statistics[value]\n        else:\n            self.assertEqual(expected_value, str(self.repo.session_statistics[value].date))\n\n    @parameterized.expand(\n        [\n            (\"with_file\", b'Revisions/Data'),\n            (\"with_folder\", b'Subdirectory'),\n            (\"with_folder_ending_slash\", b'Subdirectory/'),\n            (\"with_dir_utf8_char\", b\"Subdirectory/Fold\\xc3\\xa8r with \\xc3\\xa9ncod\\xc3\\xafng\"),\n            (\"with_broken_symlink\", b'BrokenSymlink'),\n        ]\n    )\n    @skipIf(rdiff_backup_version() < (2, 0, 1), \"rdiff-backup-delete is available since 2.0.1\")\n    def test_delete_file(self, unused, path):\n        # Delete a file\n        self.repo.delete(path)\n        # Check file is deleted\n        with self.assertRaises(DoesNotExistError):\n            self.repo.fstat(path)\n\n\nclass SessionStatisticsEntryTest(unittest.TestCase):\n    def test_getattr(self):\n        \"\"\"\n        Check how a session statistic is read.\n        \"\"\"\n        entry = SessionStatisticsEntry(MockRdiffRepo(), b'session_statistics.2014-11-02T09:16:43-05:00.data')\n        self.assertEqual(1414937803.00, entry.starttime)\n        self.assertEqual(1414937764.82, entry.endtime)\n        self.assertAlmostEqual(-38.18, entry.elapsedtime, delta=-0.01)\n        self.assertEqual(14, entry.sourcefiles)\n        self.assertEqual(3666973, entry.sourcefilesize)\n        self.assertEqual(13, entry.mirrorfiles)\n        self.assertEqual(30242, entry.mirrorfilesize)\n        self.assertEqual(1, entry.newfiles)\n        self.assertEqual(3636731, entry.newfilesize)\n        self.assertEqual(0, entry.deletedfiles)\n        self.assertEqual(0, entry.deletedfilesize)\n        self.assertEqual(1, entry.changedfiles)\n        self.assertEqual(0, entry.changedsourcesize)\n        self.assertEqual(0, entry.changedmirrorsize)\n        self.assertEqual(2, entry.incrementfiles)\n        self.assertEqual(0, entry.incrementfilesize)\n        self.assertEqual(3636731, entry.totaldestinationsizechange)\n        self.assertEqual(0, entry.errors)\n\n\nclass RdiffTimeTest(unittest.TestCase):\n    def test_add(self):\n        \"\"\"Check if addition with timedelta is working as expected.\"\"\"\n        # Without timezone\n        self.assertEqual(\n            RdiffTime('2014-11-08T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') + datetime.timedelta(days=3)\n        )\n        # With timezone\n        self.assertEqual(\n            RdiffTime('2014-11-08T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') + datetime.timedelta(days=3)\n        )\n\n    def test_compare(self):\n        \"\"\"Check behaviour of comparison operator operator.\"\"\"\n\n        self.assertTrue(RdiffTime('2014-11-07T21:04:30-04:00') < RdiffTime('2014-11-08T21:04:30Z'))\n        self.assertTrue(RdiffTime('2014-11-08T21:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))\n        self.assertFalse(RdiffTime('2014-11-08T22:04:30Z') < RdiffTime('2014-11-08T21:50:30Z'))\n\n        self.assertFalse(RdiffTime('2014-11-07T21:04:30-04:00') > RdiffTime('2014-11-08T21:04:30Z'))\n        self.assertFalse(RdiffTime('2014-11-08T21:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))\n        self.assertTrue(RdiffTime('2014-11-08T22:04:30Z') > RdiffTime('2014-11-08T21:50:30Z'))\n\n    def test_init_now(self):\n        t0 = RdiffTime()\n        self.assertAlmostEqual(int(time.time()), t0.epoch(), delta=5000)\n\n    @parameterized.expand(\n        [\n            (1415221470, 1415221470),\n            ('2014-11-05T21:04:30Z', 1415221470),\n            ('2014-11-05T16:04:30-05:00', 1415221470),\n            ('2014-11-05T23:04:30+02:00', 1415221470),\n            ('2014-11-05T23-04-30+02-00', 1415221470),\n        ]\n    )\n    def test_init(self, value, expected_epoch):\n        t1 = RdiffTime(value)\n        self.assertEqual(expected_epoch, t1.epoch())\n\n    def test_int(self):\n        \"\"\"Check if int(RdiffTime) return expected value.\"\"\"\n        self.assertEqual(1415221470, int(RdiffTime(1415221470)))\n        self.assertEqual(1415217870, int(RdiffTime(1415221470, 3600)))\n\n    def test_str(self):\n        \"\"\"Check if __str__ is working.\"\"\"\n        self.assertEqual('2014-11-05T21:04:30Z', str(RdiffTime(1415221470)))\n        self.assertEqual('2014-11-05T21:04:30+01:00', str(RdiffTime(1415221470, 3600)))\n\n    def test_sub(self):\n        \"\"\"Check if addition with timedelta is working as expected.\"\"\"\n        # Without timezone\n        self.assertEqual(\n            RdiffTime('2014-11-02T21:04:30Z'), RdiffTime('2014-11-05T21:04:30Z') - datetime.timedelta(days=3)\n        )\n        # With timezone\n        self.assertEqual(\n            RdiffTime('2014-11-02T21:04:30-04:00'), RdiffTime('2014-11-05T21:04:30-04:00') - datetime.timedelta(days=3)\n        )\n\n        # With datetime\n        self.assertTrue((RdiffTime('2014-11-02T21:04:30Z') - RdiffTime()).days < 0)\n        self.assertTrue((RdiffTime() - RdiffTime('2014-11-02T21:04:30Z')).days > 0)\n\n    def test_set_time(self):\n        self.assertEqual(RdiffTime('2014-11-05T00:00:00Z'), RdiffTime('2014-11-05T21:04:30Z').set_time(0, 0, 0))\n        self.assertEqual(\n            RdiffTime('2014-11-02T00:00:00-04:00'), RdiffTime('2014-11-02T21:04:30-04:00').set_time(0, 0, 0)\n        )\n", "# rdiffweb, A web interface to rdiff-backup repositories\n# Copyright (C) 2012-2021 rdiffweb contributors\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n[tox]\nenvlist = py3,doc,flake8,black,isort,djlint,buster,bullseye,bookworm\n\n[testenv]\npassenv = RDIFFWEB_TEST_DATABASE_URI\ndeps=\n  pytest\n  coverage\n  pytest-cov\n  psycopg2-binary\n  #cherrypy<9 depends on nosetest\n  buster: nose\n  buster: apscheduler==3.5.3\n  buster: argon2-cffi==18.3.0\n  buster: cherrypy==8.9.1\n  buster: configargparse==0.13.0\n  buster: distro==1.3.0\n  buster: humanfriendly==4.18\n  buster: Jinja2==2.10\n  buster: ldap3==2.4.1\n  buster: MarkupSafe==1.1.0\n  buster: psutil==5.7.2\n  buster: sqlalchemy==1.2.18\n  buster: WTForms==2.2.1\n  bullseye: apscheduler==3.7.0\n  bullseye: argon2-cffi==18.3.0\n  bullseye: cherrypy==18.6.1\n  bullseye: configargparse==1.2.3\n  bullseye: distro==1.5.0\n  bullseye: humanfriendly==9.1\n  bullseye: Jinja2==2.11.3\n  bullseye: ldap3==2.8.1\n  bullseye: MarkupSafe==1.1.1\n  bullseye: psutil==5.8.0\n  bullseye: sqlalchemy==1.3.22\n  bullseye: WTForms==2.2.1\n  bookworm: apscheduler==3.9.1\n  bookworm: argon2-cffi==21.1.0\n  bookworm: cherrypy==18.8.0\n  bookworm: configargparse==1.5.3\n  bookworm: distro==1.7.0\n  bookworm: humanfriendly==10.0\n  bookworm: Jinja2==3.0.3\n  bookworm: ldap3==2.9.1\n  bookworm: MarkupSafe==2.1.1\n  bookworm: psutil==5.9.0\n  bookworm: sqlalchemy==1.4.31\n  bookworm: WTForms==2.2.1\nextras = test\ncommands=\n  pytest -v --debug --override-ini junit_family=xunit1 --junit-xml=xunit-{envname}.xml --cov=rdiffweb --cov-report xml:coverage-{envname}.xml\n\n[testenv:doc]\ndeps =\n  sphinx\n  sphinx_md\n  recommonmark\n  sphinx-markdown-tables==0.0.3\ncommands = sphinx-build -W -b html -d {envtmpdir}/doctrees doc {envtmpdir}/html\n\n[testenv:black]\ndeps = black\ncommands = black --check --diff setup.py rdiffweb\nskip_install = true\n\n[testenv:djlint]\ndeps = djlint==1.19.2\nallowlist_externals = sh\ncommands = sh -c 'djlint --check rdiffweb/templates/*.html  rdiffweb/templates/**/*.html'\nskip_install = true\n\n[testenv:flake8]\ndeps =\n  flake8\ncommands = flake8 setup.py rdiffweb\nskip_install = true\n\n[testenv:isort]\ndeps = isort>=5.0.1\ncommands = isort --check --diff setup.py rdiffweb\nskip_install = true\n\n[flake8]\nignore =\n  # whitespace before ':'\n  E203\n  # line too long (86 > 79 characters)\n  E501\n  # line break before binary operator\n  W503\n  # ambiguous variable name 'I'\n  E741\nfilename =\n  *.py\n  setup.py\nmax-complexity = 20\n\n[isort]\nprofile = black\nline_length = 120"], "buggy_code_start_loc": [111, 399, 848, 136, 435, 170, 55, 101], "buggy_code_end_loc": [112, 405, 1094, 144, 435, 176, 549, 105], "fixing_code_start_loc": [111, 398, 848, 136, 436, 170, 55, 101], "fixing_code_end_loc": [116, 401, 1087, 144, 456, 176, 548, 109], "type": "CWE-269", "message": "Improper Privilege Management in GitHub repository ikus060/rdiffweb prior to 2.5.2.", "other": {"cve": {"id": "CVE-2022-4314", "sourceIdentifier": "security@huntr.dev", "published": "2022-12-12T18:15:13.473", "lastModified": "2022-12-15T14:02:39.087", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Improper Privilege Management in GitHub repository ikus060/rdiffweb prior to 2.5.2."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "LOW", "baseScore": 6.0, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.5, "impactScore": 5.5}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-269"}]}, {"source": "security@huntr.dev", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-269"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ikus-soft:rdiffweb:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.5.2", "matchCriteriaId": "79564F90-37BF-40CC-A5DA-DE01637082A8"}]}]}], "references": [{"url": "https://github.com/ikus060/rdiffweb/commit/b2df3679564d0daa2856213bb307d3e34bd89a25", "source": "security@huntr.dev", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://huntr.dev/bounties/b2dc504d-92ae-4221-a096-12ff223d95a8", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/ikus060/rdiffweb/commit/b2df3679564d0daa2856213bb307d3e34bd89a25"}}