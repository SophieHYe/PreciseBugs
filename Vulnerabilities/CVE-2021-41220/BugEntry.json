{"buggy_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <string>\n#include <utility>\n\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/str_format.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/collective.h\"\n#include \"tensorflow/core/framework/device_attributes.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/op_requires.h\"\n#include \"tensorflow/core/framework/resource_handle.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/core/framework/tensor_util.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/refcount.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\n\nnamespace {\n\nstatic string CollectiveKey(OpKernelContext* ctx, int32_t group_key,\n                            int32_t instance_key) {\n  return strings::StrCat(group_key, \":\", instance_key, \":\",\n                         ctx->frame_iter().frame_id, \":\",\n                         ctx->frame_iter().iter_id);\n}\n\nstatic std::unique_ptr<OpKernel> BuildOpKernel(OpKernelConstruction* c,\n                                               const string& name,\n                                               NodeDef* sub_node) {\n  std::unique_ptr<OpKernel> k;\n  if (name.empty() || name == \"Id\") return k;\n  sub_node->set_name(name);\n  sub_node->set_op(name);\n  Status status;\n  k = CreateOpKernel(c->device_type(), c->device(),\n                     c->device()->GetAllocator(AllocatorAttributes()),\n                     *sub_node, c->graph_def_version(), &status);\n  if (!status.ok()) {\n    c->CtxFailureWithWarning(errors::Internal(\n        \"Failed to build OpKernel for \", name, \" : \", status.error_message()));\n  }\n  return k;\n}\n\nclass CollectiveOpV1Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV1Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), col_params_(new CollectiveParams()) {}\n\n  ~CollectiveOpV1Kernel() override { col_params_->Unref(); }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    const CancellationToken token =\n        c->cancellation_manager()->get_cancellation_token();\n    const bool already_cancelled =\n        !c->cancellation_manager()->RegisterCallback(token, [col_exec]() {\n          // We must call StartAbort() within the callback. StartAbort() relies\n          // on resources that may be deallocated if all execution of a graph is\n          // finished.\n          col_exec->StartAbort(errors::Cancelled(\"op cancelled\"));\n        });\n    OP_REQUIRES_ASYNC(c, !already_cancelled,\n                      errors::Cancelled(\"op cancelled \", name_), done);\n\n    auto deregister_and_done = [c, token, done = std::move(done)]() {\n      // Once done() is called, StartAbort() won't have any effect, so we\n      // don't need to block on the deregistration. Also StartAbort() may call\n      // done() and DeregisterCallback may deadlock.\n      c->cancellation_manager()->TryDeregisterCallback(token);\n      done();\n    };\n    ComputeAsyncImpl(c, col_exec, std::move(deregister_and_done));\n  }\n\n  // A string encoding instance, frame and iter to be handed off to\n  // the implementation for use in generating RecvBuf keys.\n  string GetCollectiveKey(OpKernelContext* c) {\n    return CollectiveKey(c, col_params_->group.group_key,\n                         col_params_->instance.instance_key);\n  }\n\n  // Returns false if calling invocation of ComputeAsync should return\n  // immediately.\n  bool CanProceedWithCompute(OpKernelContext* c, CollectiveExecutor* col_exec,\n                             const DoneCallback& done) {\n    if (col_params_->group.group_size > col_params_->group.members.size()) {\n      // This is the first invocation: Finish initializing col_params_.\n      // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n      // blocking work because it's not guaranteed that this call cannot block.\n      c->collective_executor()->RunClosure([this, c, col_exec, done]() {\n        VLOG(1) << \"CollectiveOpKernel CompleteParams for collective \"\n                << col_params_->name << \" device \" << c->device()->name()\n                << \" group \" << col_params_->group.group_key << \" instance \"\n                << col_params_->instance.instance_key;\n        col_exec->CompleteParamsAsync(\n            c->device()->attributes(), col_params_, c->cancellation_manager(),\n            [this, c, done](const Status& s) {\n              if (s.ok()) {\n                col_params_->instance.impl_details.dependencies = dependencies_;\n                ComputeAsync(c, done);\n              } else {\n                c->SetStatus(s);\n                done();\n              }\n            });\n      });\n      return false;\n    }\n    return true;\n  }\n\n protected:\n  virtual void ComputeAsyncImpl(OpKernelContext* c,\n                                CollectiveExecutor* col_exec,\n                                DoneCallback done) = 0;\n\n  string name_;\n  CollectiveParams* col_params_;\n  std::vector<int32> dependencies_;\n};\n\nclass CollectiveGatherOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveGatherOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = GATHER_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    const NodeDef& real_node = c->def();\n    col_params_->name = strings::StrCat(real_node.name(), \": Gather\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    auto output_shape = c->input(0).shape();\n    output_shape.set_dim(\n        0, output_shape.dim_size(0) * col_params_->group.group_size);\n    col_params_->instance.shape = output_shape;\n\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(\n          c, c->allocate_output(0, col_params_->instance.shape, &output), done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveGatherOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveGatherOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveGatherOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGather\").Device(DEVICE_CPU),\n                        CollectiveGatherOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGather\").Device(DEVICE_GPU),\n                        CollectiveGatherOpKernel);\n\nclass CollectiveReduceOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveReduceOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = REDUCTION_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"subdiv_offsets\",\n                      &col_params_->instance.impl_details.subdiv_offsets));\n    string merge_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"merge_op\", &merge_op_name));\n    if (merge_op_name == \"Max\") {\n      merge_op_name = \"Maximum\";\n    } else if (merge_op_name == \"Min\") {\n      merge_op_name = \"Minimum\";\n    }\n    string final_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"final_op\", &final_op_name));\n    OP_REQUIRES(c, final_op_name == \"Id\" || final_op_name == \"Div\",\n                errors::InvalidArgument(\n                    \"final_op must be one of {\\\"Id\\\", \\\"Div\\\"} but got \",\n                    final_op_name));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"wait_for\", &dependencies_));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    VLOG(2) << \"CollectiveReduce instance \"\n            << col_params_->instance.instance_key << \" merge_op \"\n            << merge_op_name << \" final_op \" << final_op_name\n            << \" communication_hint \"\n            << col_params_->instance.impl_details.communication_hint\n            << \" timeout \"\n            << col_params_->instance.impl_details.timeout_seconds;\n\n    const NodeDef& real_node = c->def();\n    col_params_->name = strings::StrCat(real_node.name(), \": Reduce(\",\n                                        merge_op_name, \",\", final_op_name, \")\");\n    col_params_->group.device_type = c->device_type();\n\n    // Find the OpKernels by name, type and device type.\n    NodeDef sub_node;\n    // The merge_op takes two inputs\n    sub_node.add_input(real_node.input(0));\n    sub_node.add_input(real_node.input(0));\n    sub_node.set_device(real_node.device());\n    SetAttrValue(col_params_->instance.data_type,\n                 &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, merge_op_name, &sub_node);\n    final_op_ = BuildOpKernel(c, final_op_name, &sub_node);\n    col_params_->merge_op = merge_op_.get();\n    col_params_->final_op = final_op_.get();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor, trying to reuse the input.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(c,\n                           c->forward_input_or_allocate_output(\n                               {0}, 0, c->input(0).shape(), &output),\n                           done);\n      col_params_->instance.shape = c->input(0).shape();\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveReduceOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveReduceOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveReduceOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduce\").Device(DEVICE_CPU),\n                        CollectiveReduceOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduce\").Device(DEVICE_GPU),\n                        CollectiveReduceOpKernel);\n\nclass CollectiveBcastSendOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveBcastSendOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = BROADCAST_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"shape\", &col_params_->instance.shape));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    col_params_->is_source = true;\n    col_params_->instance.impl_details.subdiv_offsets = {0};\n\n    col_params_->name =\n        strings::StrCat(name(), \": Broadcast(\", col_params_->is_source, \")\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor, trying to reuse the input.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(c,\n                           c->forward_input_or_allocate_output(\n                               {0}, 0, col_params_->instance.shape, &output),\n                           done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n    OP_REQUIRES_ASYNC(\n        c, col_params_->instance.shape.IsSameSize(c->input(0).shape()),\n        errors::Internal(\"Declared shape of op \", col_params_->name,\n                         \" does not match shape of input\"),\n        done);\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveBcastSendOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveBcastSendOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveBcastSendOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSend\").Device(DEVICE_CPU),\n                        CollectiveBcastSendOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSend\").Device(DEVICE_DEFAULT),\n                        CollectiveBcastSendOpKernel);\n\nclass CollectiveBcastRecvOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveBcastRecvOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = BROADCAST_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"shape\", &col_params_->instance.shape));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    col_params_->is_source = false;\n    col_params_->instance.impl_details.subdiv_offsets = {0};\n\n    col_params_->name =\n        strings::StrCat(name(), \": Broadcast(\", col_params_->is_source, \")\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // No input, so must allocate output.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(\n          c, c->allocate_output(0, col_params_->instance.shape, &output), done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveBcastRecvOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance_key \"\n              << col_params->instance.instance_key << \" status  \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveBcastRecvOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveBcastRecvOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecv\").Device(DEVICE_CPU),\n                        CollectiveBcastRecvOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecv\").Device(DEVICE_DEFAULT),\n                        CollectiveBcastRecvOpKernel);\n\nclass CollectiveOpV2Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV2Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &data_type_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"communication_hint\", &communication_hint_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    device_type_ = c->device_type();\n  }\n\n protected:\n  // Fills common parts of CollectiveParams according to the Op, *excluding\n  // output_shape*. Kernels should further work on the CollectiveParams if they\n  // need to set additional fields.\n  Status FillCollectiveParams(CollectiveParams* col_params,\n                              CollectiveType collective_type,\n                              const Tensor& group_size, const Tensor& group_key,\n                              const Tensor& instance_key) {\n    if (group_size.dims() > 0) {\n      return errors::Internal(\"Unexpected dimensions on input group_size, got \",\n                              group_size.shape().DebugString());\n    }\n    if (group_key.dims() > 0) {\n      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n                              group_key.shape().DebugString());\n    }\n    if (instance_key.dims() > 0) {\n      return errors::Internal(\n          \"Unexpected dimensions on input instance_key, got \",\n          instance_key.shape().DebugString());\n    }\n    col_params->name = name_;\n    col_params->group.device_type = device_type_;\n    col_params->group.group_size = group_size.unaligned_flat<int32>()(0);\n    if (col_params->group.group_size <= 0) {\n      return errors::InvalidArgument(\n          \"group_size must be positive integer but got \",\n          col_params->group.group_size);\n    }\n    col_params->group.group_key = group_key.unaligned_flat<int32>()(0);\n    col_params->instance.type = collective_type;\n    col_params->instance.instance_key = instance_key.unaligned_flat<int32>()(0);\n    col_params->instance.data_type = data_type_;\n    col_params->instance.impl_details.communication_hint = communication_hint_;\n    col_params->instance.impl_details.timeout_seconds = timeout_seconds_;\n    return Status::OK();\n  }\n\n  // Runs a collective. The output tensor must be allocated before calling this\n  // method. col_params must live until done is called.\n  void Run(OpKernelContext* c, CollectiveParams* col_params,\n           DoneCallback done) {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    // Resolve the collective params.\n    // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n    // blocking work because it's not guaranteed that this call cannot block.\n    c->collective_executor()->RunClosure([c, done = std::move(done), col_params,\n                                          col_exec]() {\n      VLOG(1) << \"Collective CompleteParams for \" << col_params->name\n              << \" device \" << c->device()->name() << \" group \"\n              << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key;\n      col_exec->CompleteParamsAsync(\n          c->device()->attributes(), col_params, c->cancellation_manager(),\n          [c, done = std::move(done), col_params, col_exec](const Status& s) {\n            if (s.ok()) {\n              auto actual_done = [c, col_params,\n                                  done = std::move(done)](const Status& s) {\n                VLOG(1) << \"Collective ExecuteAsync done for \"\n                        << col_params->name << \" device \" << c->device()->name()\n                        << \" group \" << col_params->group.group_key\n                        << \" instance \" << col_params->instance.instance_key\n                        << \" status \" << s;\n                if (!s.ok()) {\n                  c->SetStatus(s);\n                }\n                done();\n              };\n              VLOG(1) << \"Collective ExecuteAsync start for \"\n                      << col_params->name << \" device \" << c->device()->name()\n                      << \" group \" << col_params->group.group_key\n                      << \" instance \" << col_params->instance.instance_key;\n              col_exec->ExecuteAsync(\n                  c, col_params,\n                  CollectiveKey(c, col_params->group.group_key,\n                                col_params->instance.instance_key),\n                  actual_done);\n            } else {\n              c->SetStatus(s);\n              done();\n            }\n          });\n    });\n  }\n\n protected:\n  string name_;\n  DataType data_type_ = DT_INVALID;\n  string communication_hint_;\n  float timeout_seconds_ = 0;\n  DeviceType device_type_;\n};\n\nclass CollectiveReduceV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveReduceV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    string merge_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"merge_op\", &merge_op_name));\n    if (merge_op_name == \"Max\") {\n      merge_op_name = \"Maximum\";\n    } else if (merge_op_name == \"Min\") {\n      merge_op_name = \"Minimum\";\n    }\n    string final_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"final_op\", &final_op_name));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"max_subdivs_per_device\", &max_subdivs_per_device_));\n    // Prepare OpKernels for reduction and final operations.\n    // The merge_op takes two inputs\n    NodeDef sub_node;\n    sub_node.add_input(c->def().input(0));\n    sub_node.add_input(c->def().input(0));\n    sub_node.set_device(c->def().device());\n    SetAttrValue(data_type_, &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, merge_op_name, &sub_node);\n    final_op_ = BuildOpKernel(c, final_op_name, &sub_node);\n    name_ = strings::StrCat(c->def().name(), \": ReduceV2(\", merge_op_name, \",\",\n                            final_op_name, \")\");\n    VLOG(2) << \"CollectiveReduceV2 \" << this << \" name \" << name_\n            << \" communication_hint \" << communication_hint_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, REDUCTION_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/ c->input(3)),\n                         done);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV2 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n\n private:\n  int max_subdivs_per_device_;\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV2\").Device(DEVICE_CPU),\n                        CollectiveReduceV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveReduceV2OpKernel);\n\nclass CollectiveGatherV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveGatherV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    name_ = strings::StrCat(c->def().name(), \": GatherV2\");\n    VLOG(2) << \"CollectiveGatherV2 \" << this << \" name \" << name_\n            << \" communication_hint \" << communication_hint_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, GATHER_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/\n                                              c->input(3)),\n                         done_with_cleanup);\n    auto output_shape = c->input(0).shape();\n    output_shape.set_dim(\n        0, output_shape.dim_size(0) * col_params->group.group_size);\n    col_params->instance.shape = output_shape;\n    VLOG(1) << \"CollectiveGatherV2 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, col_params->instance.shape, &output),\n        done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGatherV2\").Device(DEVICE_CPU),\n                        CollectiveGatherV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGatherV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveGatherV2OpKernel);\n\nclass CollectiveBcastSendV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveBcastSendV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    const bool is_source = true;\n    name_ = strings::StrCat(name(), \": Broadcast(\", is_source, \")\");\n  }\n\n protected:\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, BROADCAST_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/ c->input(3)),\n                         done_with_cleanup);\n    col_params->is_source = true;\n    col_params->instance.shape = c->input(0).shape();\n    // Add a default value for subdiv offsets, which is the same as the default\n    // value in the V1 op's attribute.\n    col_params->instance.impl_details.subdiv_offsets.push_back(0);\n    VLOG(1) << \"CollectiveBcastSendV2 group_size \"\n            << col_params->group.group_size << \" group_key \"\n            << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSendV2\").Device(DEVICE_CPU),\n                        CollectiveBcastSendV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSendV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveBcastSendV2OpKernel);\n\nclass CollectiveBcastRecvV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveBcastRecvV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    const bool is_source = false;\n    name_ = strings::StrCat(name(), \": Broadcast(\", is_source, \")\");\n  }\n\n protected:\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, BROADCAST_COLLECTIVE,\n                                              /*group_size*/ c->input(0),\n                                              /*group_key*/ c->input(1),\n                                              /*instance_key*/ c->input(2)),\n                         done_with_cleanup);\n    col_params->is_source = false;\n    TensorShape output_shape;\n    OP_REQUIRES_OK_ASYNC(c, tensor::MakeShape(c->input(3), &output_shape),\n                         done_with_cleanup);\n    col_params->instance.shape = output_shape;\n    // Add a default value for subdiv offsets, which is the same as the default\n    // value in the V1 op's attribute.\n    col_params->instance.impl_details.subdiv_offsets.push_back(0);\n    VLOG(1) << \"CollectiveBcastRecvV2 group_size \"\n            << col_params->group.group_size << \" group_key \"\n            << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, col_params->instance.shape, &output),\n        done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecvV2\").Device(DEVICE_CPU),\n                        CollectiveBcastRecvV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecvV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\")\n                            .HostMemory(\"shape\"),\n                        CollectiveBcastRecvV2OpKernel);\n\n/*\n * Resource for holding group for CollectiveOps.\n * This resource is returned from CollectiveInitializeCommunicatorOpKernel\n * It generates next instance key for the group for each collective operation.\n */\nclass CollectiveGroupResource : public ResourceBase {\n public:\n  CollectiveGroupResource(int32 group_key, int32 rank, int32 group_size,\n                          string communication_hint, float timeout_seconds)\n      : group_key_(group_key),\n        rank_(rank),\n        group_size_(group_size),\n        communication_hint_(communication_hint),\n        timeout_seconds_(timeout_seconds) {}\n\n  std::string DebugString() const override {\n    return absl::StrFormat(\n        \"Collective Group with group_key = %d, group_size = %d, rank = %d\",\n        group_key_, group_size_, rank_);\n  }\n\n  int get_next_instance_key() {\n    return instance_key_.fetch_add(1, std::memory_order_relaxed);\n  }\n\n  int32 group_key() const { return group_key_; }\n\n  int32 rank() const { return rank_; }\n\n  int32 group_size() const { return group_size_; }\n\n  string communication_hint() const { return communication_hint_; }\n\n  float timeout_seconds() const { return timeout_seconds_; }\n\n private:\n  int32 group_key_, rank_, group_size_;\n  string communication_hint_;\n  std::atomic<int> instance_key_{0};\n  float timeout_seconds_ = 0;\n};\n\nclass CollectiveInitializeCommunicatorOpKernel : public AsyncOpKernel {\n public:\n  explicit CollectiveInitializeCommunicatorOpKernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"communication_hint\", &communication_hint_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    device_type_ = c->device_type();\n  }\n\n  Status CheckInputs(Tensor group_size_t, Tensor group_key_t) {\n    if (group_size_t.dims() > 0) {\n      return errors::Internal(\n          \"Unexpected dimensions on input group_size. \"\n          \"It shoulbe a scalar, got tensor with shape \",\n          group_size_t.shape().DebugString());\n    }\n    if (group_key_t.dims() > 0) {\n      return errors::Internal(\"Unexpected dimensions on input group_key, got \",\n                              group_key_t.shape().DebugString());\n    }\n\n    auto group_size = group_size_t.unaligned_flat<int32>()(0);\n    if (group_size <= 0) {\n      return errors::InvalidArgument(\n          \"group_size must be positive integer but got \", group_size);\n    }\n    return Status::OK();\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto group_key_t = c->input(0);\n    auto rank_t = c->input(1);\n    auto group_size_t = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(c, CheckInputs(group_size_t, group_key_t), done);\n\n    auto group_size = group_size_t.unaligned_flat<int32>()(0);\n    auto group_key = group_key_t.unaligned_flat<int32>()(0);\n    auto rank = rank_t.unaligned_flat<int32>()(0);\n\n    ResourceHandle resource_handle =\n        MakeResourceHandle<CollectiveGroupResource>(\n            c, \"collective_op_group\", absl::StrFormat(\"%d\", group_key));\n\n    Tensor* output_handle = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, TensorShape({}), &output_handle), done);\n    output_handle->scalar<ResourceHandle>()() = resource_handle;\n\n    CollectiveGroupResource* resource = new CollectiveGroupResource(\n        group_key, rank, group_size, this->communication_hint_,\n        this->timeout_seconds_);\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        CreateResource<CollectiveGroupResource>(c, resource_handle, resource),\n        done);\n    auto group_params = new CollGroupParams();\n    group_params->device_type = device_type_;\n    group_params->group_size = resource->group_size();\n    group_params->group_key = resource->group_key();\n\n    auto* col_exec = c->collective_executor();\n\n    c->collective_executor()->RunClosure([c, done = std::move(done),\n                                          group_params, col_exec]() {\n      VLOG(1) << \"Collective Group initialization for \"\n              << \" device \" << c->device()->name() << \" group \"\n              << group_params->group_key;\n      col_exec->CompleteGroupAsync(\n          c->device()->attributes(), group_params, c->cancellation_manager(),\n          [c, done = std::move(done), group_params](const Status& s) {\n            if (s.ok()) {\n              VLOG(1) << \"Collective Group initialization done for device \"\n                      << c->device()->name() << \" group \"\n                      << group_params->group_key << \" status \" << s;\n            } else {\n              c->SetStatus(s);\n            }\n            delete group_params;\n            done();\n          });\n    });\n  }\n\n private:\n  string communication_hint_;\n  DeviceType device_type_;\n  float timeout_seconds_ = 0;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"CollectiveInitializeCommunicator\").Device(DEVICE_CPU),\n    CollectiveInitializeCommunicatorOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveInitializeCommunicator\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"rank\"),\n                        CollectiveInitializeCommunicatorOpKernel);\n\nclass CollectiveOpV3Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV3Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &data_type_));\n    if (c->HasAttr(\"timeout_seconds\")) {\n      OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    } else {\n      timeout_seconds_ = -1;\n    }\n    device_type_ = c->device_type();\n  }\n\n protected:\n  // Fills common parts of CollectiveParams according to the Op, *excluding\n  // output_shape*. Kernels should further work on the CollectiveParams if they\n  // need to set additional fields.\n  Status FillCollectiveParams(CollectiveParams* col_params,\n                              const Tensor& group_assignment,\n                              CollectiveType collective_type,\n                              CollectiveGroupResource* resource) {\n    int64 group_id;\n    int64 group_size;\n    if (group_assignment.NumElements() == 0) {\n      // No group assignments, perform collective as a single group.\n      group_id = 0;\n      group_size = resource->group_size();\n    } else {\n      return errors::Unimplemented(\"Group assignments are not supported yet.\");\n    }\n\n    // Construct instance key with format:\n    // <11 bits for group><21 bits for atomic incremented instance key>\n    int32 instance_key = group_id << 21 | resource->get_next_instance_key();\n    col_params->name = name_;\n    col_params->group.device_type = device_type_;\n    col_params->group.group_size = group_size;\n    col_params->group.group_key = resource->group_key();\n    col_params->instance.type = collective_type;\n    col_params->instance.instance_key = instance_key;\n    col_params->instance.data_type = data_type_;\n    col_params->instance.impl_details.communication_hint =\n        resource->communication_hint();\n    col_params->instance.impl_details.timeout_seconds =\n        timeout_seconds_ > 0 ? resource->timeout_seconds() : timeout_seconds_;\n    col_params->run_group_initialization = false;\n    return Status::OK();\n  }\n\n  // Runs a collective. The output tensor must be allocated before calling this\n  // method. col_params must live until done is called.\n  void Run(OpKernelContext* c, CollectiveParams* col_params,\n           DoneCallback done) {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    // Resolve the collective params.\n    // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n    // blocking work because it's not guaranteed that this call cannot block.\n    col_exec->RunClosure([c, done = std::move(done), col_params, col_exec]() {\n      VLOG(1) << \"Collective CompleteParams for \" << col_params->name\n              << \" device \" << c->device()->name() << \" group \"\n              << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key;\n      col_exec->CompleteParamsAsync(\n          c->device()->attributes(), col_params, c->cancellation_manager(),\n          [c, done = std::move(done), col_params, col_exec](const Status& s) {\n            if (s.ok()) {\n              auto actual_done = [c, col_params,\n                                  done = std::move(done)](const Status& s) {\n                VLOG(1) << \"Collective ExecuteAsync done for \"\n                        << col_params->name << \" device \" << c->device()->name()\n                        << \" group \" << col_params->group.group_key\n                        << \" instance \" << col_params->instance.instance_key\n                        << \" status \" << s;\n                if (!s.ok()) {\n                  c->SetStatus(s);\n                }\n                done();\n              };\n              VLOG(1) << \"Collective ExecuteAsync start for \"\n                      << col_params->name << \" device \" << c->device()->name()\n                      << \" group \" << col_params->group.group_key\n                      << \" instance \" << col_params->instance.instance_key;\n              col_exec->ExecuteAsync(\n                  c, col_params,\n                  CollectiveKey(c, col_params->group.group_key,\n                                col_params->instance.instance_key),\n                  actual_done);\n            } else {\n              c->SetStatus(s);\n              done();\n            }\n          });\n    });\n  }\n\n protected:\n  string name_;\n  DataType data_type_ = DT_INVALID;\n  DeviceType device_type_;\n  float timeout_seconds_ = 0;\n};\n\nclass CollectiveReduceV3OpKernel : public CollectiveOpV3Kernel {\n public:\n  explicit CollectiveReduceV3OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV3Kernel(c) {\n    string reduction;\n    OP_REQUIRES_OK(c, c->GetAttr(\"reduction\", &reduction));\n    if (reduction == \"Max\") {\n      reduction = \"Maximum\";\n    } else if (reduction == \"Min\") {\n      reduction = \"Minimum\";\n    }\n    // Prepare OpKernels for reduction and final operations.\n    // The merge_op takes two inputs\n    NodeDef sub_node;\n    sub_node.add_input(c->def().input(0));\n    sub_node.add_input(c->def().input(0));\n    sub_node.set_device(c->def().device());\n    SetAttrValue(data_type_, &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, reduction, &sub_node);\n    final_op_ = BuildOpKernel(c, \"Id\", &sub_node);\n    name_ = strings::StrCat(c->def().name(), \": ReduceV3(\", reduction, \")\");\n    VLOG(2) << \"CollectiveReduceV3 \" << this << \" name \" << name_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment, REDUCTION_COLLECTIVE,\n                             resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV3 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n\n private:\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV3\").Device(DEVICE_CPU),\n                        CollectiveReduceV3OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV3\").Device(DEVICE_GPU),\n                        CollectiveReduceV3OpKernel);\n\nclass CollectiveAllToAllV3OpKernel : public CollectiveOpV3Kernel {\n public:\n  explicit CollectiveAllToAllV3OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV3Kernel(c) {\n    name_ = strings::StrCat(c->def().name(), \": AllToAllV3\");\n    VLOG(2) << \"CollectiveAllToAllV3 \" << this << \" name \" << name_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment,\n                             ALL_TO_ALL_COLLECTIVE, resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    VLOG(1) << \"CollectiveAllToAll group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveAllToAllV3\").Device(DEVICE_CPU),\n                        CollectiveAllToAllV3OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveAllToAllV3\").Device(DEVICE_GPU),\n                        CollectiveAllToAllV3OpKernel);\n}  // namespace\n}  // namespace tensorflow\n", "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for V2 Collective Operations.\"\"\"\n\nimport os\nimport threading\nimport time\n\nfrom absl.testing import parameterized\n\nfrom tensorflow.python.compat import v2_compat\nfrom tensorflow.python.data.experimental.ops import testing as dataset_testing\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.distribute import combinations\nfrom tensorflow.python.distribute import test_util\nfrom tensorflow.python.eager import cancellation\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import check_ops\nfrom tensorflow.python.ops import collective_ops as _collective_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.platform import test\n\n\nclass CollectiveOpsV1(object):\n  all_reduce = _collective_ops.all_reduce\n  all_gather = _collective_ops.all_gather\n  broadcast_send = _collective_ops.broadcast_send\n  broadcast_recv = _collective_ops.broadcast_recv\n\n\nclass CollectiveOpsV2(object):\n\n  @staticmethod\n  def all_reduce(t, group_size, group_key, instance_key, *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.all_reduce_v2(t, group_size, group_key, instance_key,\n                                         *args, **kwargs)\n\n  @staticmethod\n  def all_gather(t, group_size, group_key, instance_key, *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.all_gather_v2(t, group_size, group_key, instance_key,\n                                         *args, **kwargs)\n\n  @staticmethod\n  def broadcast_send(t, shape, dtype, group_size, group_key, instance_key,\n                     *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.broadcast_send_v2(t, group_size, group_key,\n                                             instance_key, *args, **kwargs)\n\n  @staticmethod\n  def broadcast_recv(shape, dtype, group_size, group_key, instance_key, *args,\n                     **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    shape = array_ops.identity(shape)\n    return _collective_ops.broadcast_recv_v2(\n        shape, dtype, group_size, group_key, instance_key, *args, **kwargs)\n\n\ndevice_combination = (\n    combinations.combine(device='CPU', communication='RING', required_gpus=0) +\n    combinations.combine(\n        device='GPU', communication=['RING', 'NCCL'], required_gpus=2))\n\ncollective_op_combinations = combinations.combine(collective_op=[\n    combinations.NamedObject('all_reduce', CollectiveOpsV1.all_reduce),\n    combinations.NamedObject('all_reduce_v2', CollectiveOpsV2.all_reduce),\n    combinations.NamedObject('all_gather', CollectiveOpsV1.all_gather),\n    combinations.NamedObject('all_gather_v2', CollectiveOpsV2.all_gather)\n])\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_ops=[\n                combinations.NamedObject('v1', CollectiveOpsV1),\n                combinations.NamedObject('v2', CollectiveOpsV2)\n            ],\n            mode='eager'), device_combination))\nclass CollectiveOpsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testReduce(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        return collective_ops.all_reduce(\n            in_value,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_reduce_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [2.], rtol=1e-5, atol=1e-5)\n\n  def testGather(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_gather_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        return collective_ops.all_gather(\n            in_value,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    @def_function.function\n    def run_all_gather_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_gather(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_gather(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_gather_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_gather_2devices():\n      self.assertAllClose(result, [1., 1.], rtol=1e-5, atol=1e-5)\n\n  def testBroadcast(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_broadcast_2devices():\n      shape = [3]\n      in_value = constant_op.constant([1., 2., 3.], shape=shape)\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.broadcast_send(\n                in_value,\n                shape,\n                in_value.dtype,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.broadcast_recv(\n                shape,\n                in_value.dtype,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    for result in run_broadcast_2devices():\n      self.assertAllClose(result, [1., 2., 3.], rtol=1e-5, atol=1e-5)\n\n  def testInstanceKeyScopedUnderGroupKey(self, collective_ops, device,\n                                         communication):\n    if device == 'GPU' and context.num_gpus() < 4:\n      self.skipTest('not enough GPU')\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    dev2 = '/device:%s:2' % device\n    dev3 = '/device:%s:3' % device\n\n    @def_function.function\n    def run_all_reduce_4devices_same_instance_key():\n      # Use a common instance key for both groups.\n      instance_key = 0\n      # We will create 2 groups each with 2 devices.\n      group_size = 2\n      # Group 0 comprises dev0 and dev1.\n      group0_key = 0\n      # Group 1 comprises dev2 and dev3.\n      group1_key = 1\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(1.), group_size, group0_key, instance_key))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(2.), group_size, group0_key, instance_key))\n      with ops.device(dev2):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(3.), group_size, group1_key, instance_key))\n      with ops.device(dev3):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(4.), group_size, group1_key, instance_key))\n      return collectives\n\n    results = run_all_reduce_4devices_same_instance_key()\n    self.assertAllClose(results[0], 3., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[1], 3., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[2], 7., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[3], 7., rtol=1e-5, atol=1e-5)\n\n  def testCollectiveGroupSizeOne(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n\n    group_size = 1\n    group_key = 100\n    in_value = [1., 2., 3., 4.]\n    in_tensor = constant_op.constant(in_value)\n\n    with ops.device(dev0):\n      reduced_tensor = collective_ops.all_reduce(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key=100,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, reduced_tensor.numpy())\n\n    with ops.device(dev0):\n      gathered_tensor = collective_ops.all_gather(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key=200,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, gathered_tensor.numpy())\n\n  def testCollectiveInvalidKey(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n\n    group_size = 1\n    group_key = 100\n    instance_key = 100\n    in_value = [1., 2., 3., 4.]\n    in_tensor = constant_op.constant(in_value)\n\n    with ops.device(dev0):\n      reduced_tensor = collective_ops.all_reduce(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, reduced_tensor.numpy())\n\n    with self.assertRaisesRegex(\n        errors.InternalError, 'instance 100 expected type 0 and data_type 1 but'\n        ' got type 2 and data_type 1'):\n      with ops.device(dev0):\n        collective_ops.all_gather(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  def testMultipleGroups(self, collective_ops, device, communication):\n    if device == 'GPU' and context.num_gpus() < 4:\n      self.skipTest('not enough GPU')\n\n    num_elements = 4\n\n    @def_function.function\n    def run_all_reduce(group_size, group_key):\n      instance_key = group_key\n      input_value = [float(group_key) for i in range(num_elements)]\n      collectives = []\n      for device_idx in range(group_size):\n        with ops.device('/{}:{}'.format(device, device_idx)):\n          input_tensor = constant_op.constant(input_value)\n          collectives.append(\n              collective_ops.all_reduce(\n                  input_tensor,\n                  group_size,\n                  group_key,\n                  instance_key,\n                  communication_hint=communication))\n      return collectives\n\n    def run_and_assert(group_size, group_key):\n      for reduced_tensor in run_all_reduce(group_size, group_key):\n        self.assertAllEqual(\n            [float(group_key) * group_size for i in range(num_elements)],\n            reduced_tensor.numpy())\n\n    run_and_assert(group_size=2, group_key=1)\n    run_and_assert(group_size=3, group_key=2)\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_ops=[\n                combinations.NamedObject('v2', CollectiveOpsV2)\n            ],\n            mode='eager',\n            max_subdivs_per_device=[-1, 0, 16]), device_combination))\nclass AllReduceWithSubdivisionsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testReduce(self, collective_ops, device, communication,\n                 max_subdivs_per_device):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        if max_subdivs_per_device == -1:\n          return collective_ops.all_reduce(\n              in_value,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n        else:\n          return collective_ops.all_reduce(\n              in_value,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication,\n              max_subdivs_per_device=max_subdivs_per_device)\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_reduce_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [2.], rtol=1e-5, atol=1e-5)\n\n\n@combinations.generate(\n    combinations.combine(required_physical_gpus=2, mode='eager'))\nclass XlaTest(test.TestCase, parameterized.TestCase):\n\n  def testReduce(self):\n    device0 = '/device:GPU:0'\n    device1 = '/device:GPU:1'\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    results = []\n\n    def all_reduce(device):\n\n      @def_function.function(jit_compile=True)\n      def f():\n        return _collective_ops.all_reduce_v2([1.], group_size, group_key,\n                                             instance_key)\n\n      with ops.device(device):\n        results.append(f())\n\n    t0 = threading.Thread(target=all_reduce, args=(device0,))\n    t1 = threading.Thread(target=all_reduce, args=(device1,))\n    t0.start()\n    t1.start()\n    t0.join()\n    t1.join()\n\n    self.assertAllEqual(results, [[2.], [2.]])\n\n\n@combinations.generate(\n    combinations.times(collective_op_combinations, device_combination))\nclass AbortCollectiveOpsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testAbortGroupParamsResolution(self, collective_op, device,\n                                     communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      # This hangs on params resolution since we're only launching one\n      # collective for a group size of 2.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    t.join()\n    # Reset the context in order to reset the collective executor.\n    _setup_context()\n\n    # After reset non-NCCL collectives should work.\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    def_function.function(collective_fn)()\n\n  def testAbortInstanceParamsResolution(self, collective_op, device,\n                                        communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    # First perform a normal all-reduce to complete the group resolution.\n    def_function.function(collective_fn)()\n\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    # Use a different instance key to trigger another instance resolution.\n    instance_key = 101\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      # This hangs on params resolution since we're only launching one\n      # collective for a group size of 2.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    context._reset_context()  # pylint: disable=protected-access\n    t.join()\n    # Reset the context in order to reset the collective executor.\n    _setup_context()\n\n    # After reset non-NCCL collectives should work.\n    def_function.function(collective_fn)()\n\n  def testAbortCommunication(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    # First perform a normal collective to finish resolution.\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    def_function.function(collective_fn)()\n\n    # Launch a collective that hangs, and abort the collective executor after\n    # the launch.\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # Reset the context in order to reset the collective executor.\n    t.join()\n    _setup_context()\n    def_function.function(collective_fn)()\n\n\nclass OpCancellationTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce',\n                                           CollectiveOpsV1.all_reduce),\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather',\n                                           CollectiveOpsV1.all_gather),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorNotAbortIfNoCollective(self, collective_op, device,\n                                        communication):\n    # Do not abort if there's no active collective ops. There could be\n    # exceptions like EOF which we expect users to catch, aborting collective\n    # ops on all op errors intervenes with this workflow.\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    dataset = dataset_ops.Dataset.from_tensors([1.])\n\n    @def_function.function\n    def collective_fn(in_tensor):\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    @def_function.function\n    def f():\n      iterator = iter(dataset)\n      collective_fn(next(iterator))\n      # This next(iterator) should raise EOF.\n      collective_fn(next(iterator))\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    collective_fn(constant_op.constant([1.]))\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce',\n                                           CollectiveOpsV1.all_reduce),\n                  combinations.NamedObject('all_gather',\n                                           CollectiveOpsV1.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorAbortWithCollective(self, collective_op, device,\n                                     communication):\n    # Abort v1 collective ops if there're active collective ops at the time of\n    # an op error. This is due to the inability to cancel collective ops, and op\n    # errors may cause running collective ops to hang.\n    dev0 = '/device:%s:0' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n    # Make the dataset sleep a while so that the collective is being executed\n    # when the EOF happens.\n    dataset = dataset_ops.Dataset.from_tensors([1.]).apply(\n        dataset_testing.sleep(sleep_microseconds=200))\n\n    @def_function.function\n    def f():\n      # Launch a collective op that won't be able to finish to test abortion\n      # when other ops error.\n      with ops.device(dev0):\n        ret = collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n      iterator = iter(dataset)\n      next(iterator)\n      # This should raise EOF.\n      next(iterator)\n      return ret\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    # Now collective ops is aborted, subsequent collective ops should fail with\n    # the previous error.\n    with self.assertRaises(errors.CancelledError):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorNotAbortWithCollective(self, collective_op, device,\n                                        communication):\n    # Do not abort v2 collective ops even if there're active collective ops at\n    # the time of an op error. We rely cancellation to terminate active\n    # collective ops.\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    @def_function.function\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    # Local params resolution cannot be cancelled yet, so we perform a normal\n    # collective so that the group is resolved.\n    collective_fn()\n\n    # Make the dataset sleep a while so that the collective is being executed\n    # when the EOF happens.\n    dataset = dataset_ops.Dataset.from_tensors([1.]).apply(\n        dataset_testing.sleep(sleep_microseconds=200))\n\n    @def_function.function\n    def f():\n      # Launch a collective op that won't be able to finish to test cancellation\n      # when other ops error.\n      with ops.device(dev0):\n        ret = collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n      iterator = iter(dataset)\n      next(iterator)\n      # This should raise EOF.\n      next(iterator)\n      return ret\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    # Collective ops shouldn't be aborted and new collectives should be able to\n    # proceed.\n    collective_fn()\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testCancelDuringParamResolution(self, collective_op, device,\n                                      communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n    t1_cancellation_manager = cancellation.CancellationManager()\n    t2_cancellation_manager = cancellation.CancellationManager()\n\n    @def_function.function\n    def _collective_fn(x):\n      # Run an assertion to crash one of the two function executions running\n      # collectives. We explicitly cancel the other in response.\n      assert_op = check_ops.assert_equal(x, in_tensor)\n      with ops.control_dependencies([assert_op]):\n        return collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    collective_concrete = _collective_fn.get_concrete_function(in_tensor)\n\n    finish_mu = threading.Lock()\n    finishes = 0\n\n    def _placement_wrapper(device, x, my_cancellation, other_cancellation):\n      try:\n        with ops.device(device):\n          cancelable_collective = my_cancellation.get_cancelable_function(\n              collective_concrete)\n          return cancelable_collective(x)\n      except errors.InvalidArgumentError:\n        # `assert_equal` failed for this execution of the function. The other\n        # function would deadlock without cancellation.\n        other_cancellation.start_cancel()\n      except errors.CancelledError:\n        pass\n      nonlocal finishes\n      with finish_mu:\n        finishes += 1\n\n    t1 = threading.Thread(\n        target=_placement_wrapper,\n        args=(dev0, constant_op.constant([1.]), t1_cancellation_manager,\n              t2_cancellation_manager))\n    t2 = threading.Thread(\n        target=_placement_wrapper,\n        # Will cause the assertion to fail\n        args=(dev1, constant_op.constant([2.]), t2_cancellation_manager,\n              t1_cancellation_manager))\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n    self.assertEqual(finishes, 2)\n\n\n@combinations.generate(\n    combinations.times(collective_op_combinations, device_combination))\nclass TimeoutTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testTimeout(self, collective_op, device, communication):\n    timeout = 1.5\n\n    @def_function.function\n    def run(group_size, reported_group_size=None):\n      group_key = 20\n      instance_key = 30\n      tensor = [1., 2., 3., 4.]\n      results = []\n      if reported_group_size is None:\n        reported_group_size = group_size\n      for i in range(group_size):\n        with ops.device('/{}:{}'.format(device, i)):\n          input_data = constant_op.constant(tensor)\n          result = collective_op(\n              input_data,\n              group_size=reported_group_size,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint=communication,\n              timeout=timeout)\n          results.append(result)\n      return results\n\n    run(2, 2)\n\n    start_time = time.time()\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      run(1, 2)\n    elapsed = time.time() - start_time\n    self.assertAllGreaterEqual(elapsed, timeout)\n\n  def testParamResolutionAfterTimeout(self, collective_op, device,\n                                      communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    timeout = 1.5\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    # This timeout comes from param solution.\n    with self.assertRaisesRegex(\n        errors.DeadlineExceededError,\n        'Collective has timed out waiting for other workers'):\n      with ops.device(dev0):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication,\n            timeout=timeout)\n\n    # We launch the second device after the first device times out. This is to\n    # simulate the situation when other workers are slow and the timeout is\n    # short. It should error immediately.\n    with self.assertRaisesRegex(\n        errors.DeadlineExceededError,\n        'Collective has timed out waiting for other workers'):\n      with ops.device(dev1):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication)\n\n  def testExecutionAfterTimeout(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    timeout = 1.5\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    @def_function.function\n    def run():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              input_data,\n              group_size=2,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint=communication,\n              timeout=timeout)\n\n    # Run a normal all-reduce to complete param resolution.\n    run()\n\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      with ops.device(dev0):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication,\n            timeout=timeout)\n\n    # We launch the second device after the first device times out. This is to\n    # simulate the situation when other workers are slow and the timeout is\n    # short. It should error immediately.\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      with ops.device(dev1):\n        # No timeout.\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication)\n\n\nclass CommunicationHintTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  @combinations.generate(\n      combinations.times(collective_op_combinations,\n                         combinations.combine(required_gpus=[0, 1])))\n  def testNCCLFallbackOnCPU(self, collective_op):\n    # communication_hint=NCCL should work for CPU by falling back to RING. The\n    # test doesn't actually require GPU, only GPU builds. We specify\n    # required_gpus=1 so that it's tested with GPU builds.\n    dev0 = '/device:CPU:0'\n    dev1 = '/device:CPU:1'\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    @def_function.function\n    def run():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              input_data,\n              group_size=2,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint='NCCL')\n\n    run()\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_op=[\n                combinations.NamedObject('all_reduce_v2',\n                                         CollectiveOpsV2.all_reduce),\n                combinations.NamedObject('all_gather_v2',\n                                         CollectiveOpsV2.all_gather),\n            ],\n            mode='eager'), device_combination))\nclass OrderingTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testOrdering(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    with ops.device(dev0):\n      token0 = resource_variable_ops.ResourceVariable(0.)\n    with ops.device(dev1):\n      token1 = resource_variable_ops.ResourceVariable(0.)\n\n    @def_function.function\n    def f():\n      # Launch the first collective with token.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token0.handle)\n      with ops.device(dev1):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token1.handle)\n      # Launch the second collective without token.\n      with ops.device(dev0):\n        collective_op(in_tensor, group_size, group_key, instance_key)\n      with ops.device(dev1):\n        collective_op(in_tensor, group_size, group_key, instance_key)\n      # Launch the third collective with token.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token0.handle)\n      with ops.device(dev1):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token1.handle)\n\n    graph = f.get_concrete_function().graph\n    for device in [dev0, dev1]:\n      # Try to find the third collective, which should have the first collective\n      # as a control input.\n      third = None\n      for op in graph.get_operations():\n        if (op.type.startswith('Collective') and op.device.endswith(device) and\n            op.control_inputs and\n            op.control_inputs[0].type.startswith('Collective')):\n          self.assertIsNone(third)\n          third = op\n      self.assertIsNotNone(third)\n      # Verify it's not the second collective by looking at the inputs.\n      self.assertTrue(any(v.dtype == dtypes.resource for v in third.inputs))\n      first = third.control_inputs[0]\n      self.assertEqual(third.device, first.device)\n      # Verify it's not the second collective by looking at the inputs.\n      self.assertTrue(any(v.dtype == dtypes.resource for v in first.inputs))\n      self.assertEmpty(first.control_inputs)\n\n\nclass InputPipelineTest(test.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    _setup_context()\n\n  def testMap(self):\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n\n    def create_dataset_and_fetch_one(t):\n      dataset = dataset_ops.Dataset.from_tensor_slices([t])\n\n      def reduce_fn(t):\n        return CollectiveOpsV2.all_reduce(\n            t,\n            group_size=group_size,\n            group_key=group_key,\n            instance_key=instance_key)\n\n      dataset = dataset.map(reduce_fn)\n      return next(iter(dataset))\n\n    @def_function.function\n    def f():\n      with ops.device('CPU:0'):\n        value0 = create_dataset_and_fetch_one([1.])\n      with ops.device('CPU:1'):\n        value1 = create_dataset_and_fetch_one([2.])\n      return value0, value1\n\n    self.assertAllEqual(self.evaluate(f()), [[3.], [3.]])\n\n\nclass CollectiveOpsV3Test(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    _setup_context()\n\n  def testGroupInitialization(self):\n    group_size = 2\n    group_key = 100\n\n    @def_function.function\n    def f():\n      with ops.device('CPU:0'):\n        _collective_ops.initialize_communicator(\n            group_key=group_key, rank=0, group_size=group_size)\n      with ops.device('CPU:1'):\n        _collective_ops.initialize_communicator(\n            group_key=group_key, rank=1, group_size=group_size)\n\n      # TODO(b/193864859): Add validation with reduction op.\n\n    self.evaluate(f())\n\n  @combinations.generate(device_combination)\n  def testAllReduceV3(self, device, communication):\n    group_size = 2\n    group_key = 101\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      collectives = []\n      with ops.device(dev0):\n        group_handle0 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=0,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_reduce_v3(\n                group_handle0, [1.0], reduction='Add'))\n      with ops.device(dev1):\n        group_handle1 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=1,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_reduce_v3(\n                group_handle1, [2.0], reduction='Add'))\n      return collectives\n\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [3.], rtol=1e-5, atol=1e-5)\n\n  @combinations.generate(device_combination)\n  def testAllToAllV3(self, device, communication):\n    group_size = 2\n    group_key = 104\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_to_all_2devices():\n      collectives = []\n      with ops.device(dev0):\n        group_handle0 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=0,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_to_all_v3(group_handle0, [1.0, 3.0]))\n      with ops.device(dev1):\n        group_handle1 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=1,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_to_all_v3(group_handle1, [2.0, 4.0]))\n      return collectives\n\n    result = run_all_to_all_2devices()\n    self.assertAllClose(result[0], [1.0, 2.0], rtol=1e-5, atol=1e-5)\n    self.assertAllClose(result[1], [3.0, 4.0], rtol=1e-5, atol=1e-5)\n\n\ndef _setup_context():\n  context._reset_context()\n  test_util.set_logical_devices_to_at_least('CPU', 4)\n  context.ensure_initialized()\n\n\nif __name__ == '__main__':\n  os.environ['NCCL_DEBUG'] = 'INFO'\n  v2_compat.enable_v2_behavior()\n  test.main()\n"], "fixing_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <string>\n#include <utility>\n\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/str_format.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/collective.h\"\n#include \"tensorflow/core/framework/device_attributes.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/op_requires.h\"\n#include \"tensorflow/core/framework/resource_handle.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/core/framework/tensor_util.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/refcount.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\n\nnamespace {\n\nstatic string CollectiveKey(OpKernelContext* ctx, int32_t group_key,\n                            int32_t instance_key) {\n  return strings::StrCat(group_key, \":\", instance_key, \":\",\n                         ctx->frame_iter().frame_id, \":\",\n                         ctx->frame_iter().iter_id);\n}\n\nstatic std::unique_ptr<OpKernel> BuildOpKernel(OpKernelConstruction* c,\n                                               const string& name,\n                                               NodeDef* sub_node) {\n  std::unique_ptr<OpKernel> k;\n  if (name.empty() || name == \"Id\") return k;\n  sub_node->set_name(name);\n  sub_node->set_op(name);\n  Status status;\n  k = CreateOpKernel(c->device_type(), c->device(),\n                     c->device()->GetAllocator(AllocatorAttributes()),\n                     *sub_node, c->graph_def_version(), &status);\n  if (!status.ok()) {\n    c->CtxFailureWithWarning(errors::Internal(\n        \"Failed to build OpKernel for \", name, \" : \", status.error_message()));\n  }\n  return k;\n}\n\nclass CollectiveOpV1Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV1Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), col_params_(new CollectiveParams()) {}\n\n  ~CollectiveOpV1Kernel() override { col_params_->Unref(); }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    const CancellationToken token =\n        c->cancellation_manager()->get_cancellation_token();\n    const bool already_cancelled =\n        !c->cancellation_manager()->RegisterCallback(token, [col_exec]() {\n          // We must call StartAbort() within the callback. StartAbort() relies\n          // on resources that may be deallocated if all execution of a graph is\n          // finished.\n          col_exec->StartAbort(errors::Cancelled(\"op cancelled\"));\n        });\n    OP_REQUIRES_ASYNC(c, !already_cancelled,\n                      errors::Cancelled(\"op cancelled \", name_), done);\n\n    auto deregister_and_done = [c, token, done = std::move(done)]() {\n      // Once done() is called, StartAbort() won't have any effect, so we\n      // don't need to block on the deregistration. Also StartAbort() may call\n      // done() and DeregisterCallback may deadlock.\n      c->cancellation_manager()->TryDeregisterCallback(token);\n      done();\n    };\n    ComputeAsyncImpl(c, col_exec, std::move(deregister_and_done));\n  }\n\n  // A string encoding instance, frame and iter to be handed off to\n  // the implementation for use in generating RecvBuf keys.\n  string GetCollectiveKey(OpKernelContext* c) {\n    return CollectiveKey(c, col_params_->group.group_key,\n                         col_params_->instance.instance_key);\n  }\n\n  // Returns false if calling invocation of ComputeAsync should return\n  // immediately.\n  bool CanProceedWithCompute(OpKernelContext* c, CollectiveExecutor* col_exec,\n                             const DoneCallback& done) {\n    if (col_params_->group.group_size > col_params_->group.members.size()) {\n      // This is the first invocation: Finish initializing col_params_.\n      // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n      // blocking work because it's not guaranteed that this call cannot block.\n      c->collective_executor()->RunClosure([this, c, col_exec, done]() {\n        VLOG(1) << \"CollectiveOpKernel CompleteParams for collective \"\n                << col_params_->name << \" device \" << c->device()->name()\n                << \" group \" << col_params_->group.group_key << \" instance \"\n                << col_params_->instance.instance_key;\n        col_exec->CompleteParamsAsync(\n            c->device()->attributes(), col_params_, c->cancellation_manager(),\n            [this, c, done](const Status& s) {\n              if (s.ok()) {\n                col_params_->instance.impl_details.dependencies = dependencies_;\n                ComputeAsync(c, done);\n              } else {\n                c->SetStatus(s);\n                done();\n              }\n            });\n      });\n      return false;\n    }\n    return true;\n  }\n\n protected:\n  virtual void ComputeAsyncImpl(OpKernelContext* c,\n                                CollectiveExecutor* col_exec,\n                                DoneCallback done) = 0;\n\n  string name_;\n  CollectiveParams* col_params_;\n  std::vector<int32> dependencies_;\n};\n\nclass CollectiveGatherOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveGatherOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = GATHER_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    const NodeDef& real_node = c->def();\n    col_params_->name = strings::StrCat(real_node.name(), \": Gather\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    auto output_shape = c->input(0).shape();\n    output_shape.set_dim(\n        0, output_shape.dim_size(0) * col_params_->group.group_size);\n    col_params_->instance.shape = output_shape;\n\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(\n          c, c->allocate_output(0, col_params_->instance.shape, &output), done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveGatherOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveGatherOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveGatherOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGather\").Device(DEVICE_CPU),\n                        CollectiveGatherOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGather\").Device(DEVICE_GPU),\n                        CollectiveGatherOpKernel);\n\nclass CollectiveReduceOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveReduceOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = REDUCTION_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"subdiv_offsets\",\n                      &col_params_->instance.impl_details.subdiv_offsets));\n    string merge_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"merge_op\", &merge_op_name));\n    if (merge_op_name == \"Max\") {\n      merge_op_name = \"Maximum\";\n    } else if (merge_op_name == \"Min\") {\n      merge_op_name = \"Minimum\";\n    }\n    string final_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"final_op\", &final_op_name));\n    OP_REQUIRES(c, final_op_name == \"Id\" || final_op_name == \"Div\",\n                errors::InvalidArgument(\n                    \"final_op must be one of {\\\"Id\\\", \\\"Div\\\"} but got \",\n                    final_op_name));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"wait_for\", &dependencies_));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    VLOG(2) << \"CollectiveReduce instance \"\n            << col_params_->instance.instance_key << \" merge_op \"\n            << merge_op_name << \" final_op \" << final_op_name\n            << \" communication_hint \"\n            << col_params_->instance.impl_details.communication_hint\n            << \" timeout \"\n            << col_params_->instance.impl_details.timeout_seconds;\n\n    const NodeDef& real_node = c->def();\n    col_params_->name = strings::StrCat(real_node.name(), \": Reduce(\",\n                                        merge_op_name, \",\", final_op_name, \")\");\n    col_params_->group.device_type = c->device_type();\n\n    // Find the OpKernels by name, type and device type.\n    NodeDef sub_node;\n    // The merge_op takes two inputs\n    sub_node.add_input(real_node.input(0));\n    sub_node.add_input(real_node.input(0));\n    sub_node.set_device(real_node.device());\n    SetAttrValue(col_params_->instance.data_type,\n                 &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, merge_op_name, &sub_node);\n    final_op_ = BuildOpKernel(c, final_op_name, &sub_node);\n    col_params_->merge_op = merge_op_.get();\n    col_params_->final_op = final_op_.get();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor, trying to reuse the input.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(c,\n                           c->forward_input_or_allocate_output(\n                               {0}, 0, c->input(0).shape(), &output),\n                           done);\n      col_params_->instance.shape = c->input(0).shape();\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveReduceOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveReduceOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveReduceOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduce\").Device(DEVICE_CPU),\n                        CollectiveReduceOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduce\").Device(DEVICE_GPU),\n                        CollectiveReduceOpKernel);\n\nclass CollectiveBcastSendOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveBcastSendOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = BROADCAST_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"shape\", &col_params_->instance.shape));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    col_params_->is_source = true;\n    col_params_->instance.impl_details.subdiv_offsets = {0};\n\n    col_params_->name =\n        strings::StrCat(name(), \": Broadcast(\", col_params_->is_source, \")\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // Allocate the output tensor, trying to reuse the input.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(c,\n                           c->forward_input_or_allocate_output(\n                               {0}, 0, col_params_->instance.shape, &output),\n                           done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n    OP_REQUIRES_ASYNC(\n        c, col_params_->instance.shape.IsSameSize(c->input(0).shape()),\n        errors::Internal(\"Declared shape of op \", col_params_->name,\n                         \" does not match shape of input\"),\n        done);\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveBcastSendOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key << \" status \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveBcastSendOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveBcastSendOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSend\").Device(DEVICE_CPU),\n                        CollectiveBcastSendOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSend\").Device(DEVICE_DEFAULT),\n                        CollectiveBcastSendOpKernel);\n\nclass CollectiveBcastRecvOpKernel : public CollectiveOpV1Kernel {\n public:\n  explicit CollectiveBcastRecvOpKernel(OpKernelConstruction* c)\n      : CollectiveOpV1Kernel(c) {\n    col_params_->instance.type = BROADCAST_COLLECTIVE;\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_size\", &col_params_->group.group_size));\n    OP_REQUIRES(\n        c, col_params_->group.group_size > 0,\n        errors::InvalidArgument(\"group_size must be positive integer but got \",\n                                col_params_->group.group_size));\n    OP_REQUIRES_OK(c, c->GetAttr(\"group_key\", &col_params_->group.group_key));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"instance_key\", &col_params_->instance.instance_key));\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &col_params_->instance.data_type));\n    OP_REQUIRES_OK(c, c->GetAttr(\"shape\", &col_params_->instance.shape));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"communication_hint\",\n                      &col_params_->instance.impl_details.communication_hint));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"timeout_seconds\",\n                      &col_params_->instance.impl_details.timeout_seconds));\n    col_params_->is_source = false;\n    col_params_->instance.impl_details.subdiv_offsets = {0};\n\n    col_params_->name =\n        strings::StrCat(name(), \": Broadcast(\", col_params_->is_source, \")\");\n    col_params_->group.device_type = c->device_type();\n  }\n\n protected:\n  void ComputeAsyncImpl(OpKernelContext* c, CollectiveExecutor* col_exec,\n                        DoneCallback done) override {\n    // Allocate output on the first pass through this function.  This must be\n    // done immediately, while we're still in the executor thread.  Otherwise\n    // the memory is not guaranteed to be unused by any concurrently executing\n    // GPU kernel.\n    if (c->mutable_output(0) == nullptr) {\n      // No input, so must allocate output.\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK_ASYNC(\n          c, c->allocate_output(0, col_params_->instance.shape, &output), done);\n    }\n    if (!CanProceedWithCompute(c, col_exec, done)) return;\n\n    auto actual_done = [c, col_params = col_params_, done](const Status& s) {\n      VLOG(1) << \"CollectiveBcastRecvOpKernel ExecuteAsync done for collective \"\n              << c->op_kernel().name() << \" device \" << c->device()->name()\n              << \" group \" << col_params->group.group_key << \" instance_key \"\n              << col_params->instance.instance_key << \" status  \" << s;\n      col_params->Unref();\n      OP_REQUIRES_OK_ASYNC(c, s, done);\n      done();\n    };\n    VLOG(1) << \"CollectiveBcastRecvOpKernel ExecuteAsync start for collective \"\n            << col_params_->name << \" device \" << c->device()->name()\n            << \" group \" << col_params_->group.group_key << \" instance \"\n            << col_params_->instance.instance_key;\n    col_params_->Ref();\n    col_exec->ExecuteAsync(c, col_params_, GetCollectiveKey(c), actual_done);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(CollectiveBcastRecvOpKernel);\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecv\").Device(DEVICE_CPU),\n                        CollectiveBcastRecvOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecv\").Device(DEVICE_DEFAULT),\n                        CollectiveBcastRecvOpKernel);\n\nclass CollectiveOpV2Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV2Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &data_type_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"communication_hint\", &communication_hint_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    device_type_ = c->device_type();\n  }\n\n protected:\n  // Fills common parts of CollectiveParams according to the Op, *excluding\n  // output_shape*. Kernels should further work on the CollectiveParams if they\n  // need to set additional fields.\n  Status FillCollectiveParams(CollectiveParams* col_params,\n                              CollectiveType collective_type,\n                              const Tensor& group_size, const Tensor& group_key,\n                              const Tensor& instance_key) {\n    if (group_size.dims() > 0) {\n      return errors::InvalidArgument(\n          \"Unexpected dimensions on input group_size, got \",\n          group_size.shape().DebugString());\n    }\n    if (group_key.dims() > 0) {\n      return errors::InvalidArgument(\n          \"Unexpected dimensions on input group_key, got \",\n          group_key.shape().DebugString());\n    }\n    if (instance_key.dims() > 0) {\n      return errors::InvalidArgument(\n          \"Unexpected dimensions on input instance_key, got \",\n          instance_key.shape().DebugString());\n    }\n    col_params->name = name_;\n    col_params->group.device_type = device_type_;\n    col_params->group.group_size = group_size.unaligned_flat<int32>()(0);\n    if (col_params->group.group_size <= 0) {\n      return errors::InvalidArgument(\n          \"group_size must be positive integer but got \",\n          col_params->group.group_size);\n    }\n    col_params->group.group_key = group_key.unaligned_flat<int32>()(0);\n    col_params->instance.type = collective_type;\n    col_params->instance.instance_key = instance_key.unaligned_flat<int32>()(0);\n    col_params->instance.data_type = data_type_;\n    col_params->instance.impl_details.communication_hint = communication_hint_;\n    col_params->instance.impl_details.timeout_seconds = timeout_seconds_;\n    return Status::OK();\n  }\n\n  // Runs a collective. The output tensor must be allocated before calling this\n  // method. col_params must live until done is called.\n  void Run(OpKernelContext* c, CollectiveParams* col_params,\n           DoneCallback done) {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    // Resolve the collective params.\n    // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n    // blocking work because it's not guaranteed that this call cannot block.\n    c->collective_executor()->RunClosure([c, done = std::move(done), col_params,\n                                          col_exec]() {\n      VLOG(1) << \"Collective CompleteParams for \" << col_params->name\n              << \" device \" << c->device()->name() << \" group \"\n              << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key;\n      col_exec->CompleteParamsAsync(\n          c->device()->attributes(), col_params, c->cancellation_manager(),\n          [c, done = std::move(done), col_params, col_exec](const Status& s) {\n            if (s.ok()) {\n              auto actual_done = [c, col_params,\n                                  done = std::move(done)](const Status& s) {\n                VLOG(1) << \"Collective ExecuteAsync done for \"\n                        << col_params->name << \" device \" << c->device()->name()\n                        << \" group \" << col_params->group.group_key\n                        << \" instance \" << col_params->instance.instance_key\n                        << \" status \" << s;\n                if (!s.ok()) {\n                  c->SetStatus(s);\n                }\n                done();\n              };\n              VLOG(1) << \"Collective ExecuteAsync start for \"\n                      << col_params->name << \" device \" << c->device()->name()\n                      << \" group \" << col_params->group.group_key\n                      << \" instance \" << col_params->instance.instance_key;\n              col_exec->ExecuteAsync(\n                  c, col_params,\n                  CollectiveKey(c, col_params->group.group_key,\n                                col_params->instance.instance_key),\n                  actual_done);\n            } else {\n              c->SetStatus(s);\n              done();\n            }\n          });\n    });\n  }\n\n protected:\n  string name_;\n  DataType data_type_ = DT_INVALID;\n  string communication_hint_;\n  float timeout_seconds_ = 0;\n  DeviceType device_type_;\n};\n\nclass CollectiveReduceV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveReduceV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    string merge_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"merge_op\", &merge_op_name));\n    if (merge_op_name == \"Max\") {\n      merge_op_name = \"Maximum\";\n    } else if (merge_op_name == \"Min\") {\n      merge_op_name = \"Minimum\";\n    }\n    string final_op_name;\n    OP_REQUIRES_OK(c, c->GetAttr(\"final_op\", &final_op_name));\n    OP_REQUIRES_OK(\n        c, c->GetAttr(\"max_subdivs_per_device\", &max_subdivs_per_device_));\n    // Prepare OpKernels for reduction and final operations.\n    // The merge_op takes two inputs\n    NodeDef sub_node;\n    sub_node.add_input(c->def().input(0));\n    sub_node.add_input(c->def().input(0));\n    sub_node.set_device(c->def().device());\n    SetAttrValue(data_type_, &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, merge_op_name, &sub_node);\n    final_op_ = BuildOpKernel(c, final_op_name, &sub_node);\n    name_ = strings::StrCat(c->def().name(), \": ReduceV2(\", merge_op_name, \",\",\n                            final_op_name, \")\");\n    VLOG(2) << \"CollectiveReduceV2 \" << this << \" name \" << name_\n            << \" communication_hint \" << communication_hint_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, REDUCTION_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/ c->input(3)),\n                         done_with_cleanup);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV2 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n\n private:\n  int max_subdivs_per_device_;\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV2\").Device(DEVICE_CPU),\n                        CollectiveReduceV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveReduceV2OpKernel);\n\nclass CollectiveGatherV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveGatherV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    name_ = strings::StrCat(c->def().name(), \": GatherV2\");\n    VLOG(2) << \"CollectiveGatherV2 \" << this << \" name \" << name_\n            << \" communication_hint \" << communication_hint_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, GATHER_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/\n                                              c->input(3)),\n                         done_with_cleanup);\n    auto output_shape = c->input(0).shape();\n    output_shape.set_dim(\n        0, output_shape.dim_size(0) * col_params->group.group_size);\n    col_params->instance.shape = output_shape;\n    VLOG(1) << \"CollectiveGatherV2 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, col_params->instance.shape, &output),\n        done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGatherV2\").Device(DEVICE_CPU),\n                        CollectiveGatherV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveGatherV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveGatherV2OpKernel);\n\nclass CollectiveBcastSendV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveBcastSendV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    const bool is_source = true;\n    name_ = strings::StrCat(name(), \": Broadcast(\", is_source, \")\");\n  }\n\n protected:\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, BROADCAST_COLLECTIVE,\n                                              /*group_size*/ c->input(1),\n                                              /*group_key*/ c->input(2),\n                                              /*instance_key*/ c->input(3)),\n                         done_with_cleanup);\n    col_params->is_source = true;\n    col_params->instance.shape = c->input(0).shape();\n    // Add a default value for subdiv offsets, which is the same as the default\n    // value in the V1 op's attribute.\n    col_params->instance.impl_details.subdiv_offsets.push_back(0);\n    VLOG(1) << \"CollectiveBcastSendV2 group_size \"\n            << col_params->group.group_size << \" group_key \"\n            << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSendV2\").Device(DEVICE_CPU),\n                        CollectiveBcastSendV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastSendV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\"),\n                        CollectiveBcastSendV2OpKernel);\n\nclass CollectiveBcastRecvV2OpKernel : public CollectiveOpV2Kernel {\n public:\n  explicit CollectiveBcastRecvV2OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV2Kernel(c) {\n    const bool is_source = false;\n    name_ = strings::StrCat(name(), \": Broadcast(\", is_source, \")\");\n  }\n\n protected:\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    OP_REQUIRES_OK_ASYNC(c,\n                         FillCollectiveParams(col_params, BROADCAST_COLLECTIVE,\n                                              /*group_size*/ c->input(0),\n                                              /*group_key*/ c->input(1),\n                                              /*instance_key*/ c->input(2)),\n                         done_with_cleanup);\n    col_params->is_source = false;\n    TensorShape output_shape;\n    OP_REQUIRES_OK_ASYNC(c, tensor::MakeShape(c->input(3), &output_shape),\n                         done_with_cleanup);\n    col_params->instance.shape = output_shape;\n    // Add a default value for subdiv offsets, which is the same as the default\n    // value in the V1 op's attribute.\n    col_params->instance.impl_details.subdiv_offsets.push_back(0);\n    VLOG(1) << \"CollectiveBcastRecvV2 group_size \"\n            << col_params->group.group_size << \" group_key \"\n            << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, col_params->instance.shape, &output),\n        done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecvV2\").Device(DEVICE_CPU),\n                        CollectiveBcastRecvV2OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveBcastRecvV2\")\n                            .Device(DEVICE_DEFAULT)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"instance_key\")\n                            .HostMemory(\"shape\"),\n                        CollectiveBcastRecvV2OpKernel);\n\n/*\n * Resource for holding group for CollectiveOps.\n * This resource is returned from CollectiveInitializeCommunicatorOpKernel\n * It generates next instance key for the group for each collective operation.\n */\nclass CollectiveGroupResource : public ResourceBase {\n public:\n  CollectiveGroupResource(int32 group_key, int32 rank, int32 group_size,\n                          string communication_hint, float timeout_seconds)\n      : group_key_(group_key),\n        rank_(rank),\n        group_size_(group_size),\n        communication_hint_(communication_hint),\n        timeout_seconds_(timeout_seconds) {}\n\n  std::string DebugString() const override {\n    return absl::StrFormat(\n        \"Collective Group with group_key = %d, group_size = %d, rank = %d\",\n        group_key_, group_size_, rank_);\n  }\n\n  int get_next_instance_key() {\n    return instance_key_.fetch_add(1, std::memory_order_relaxed);\n  }\n\n  int32 group_key() const { return group_key_; }\n\n  int32 rank() const { return rank_; }\n\n  int32 group_size() const { return group_size_; }\n\n  string communication_hint() const { return communication_hint_; }\n\n  float timeout_seconds() const { return timeout_seconds_; }\n\n private:\n  int32 group_key_, rank_, group_size_;\n  string communication_hint_;\n  std::atomic<int> instance_key_{0};\n  float timeout_seconds_ = 0;\n};\n\nclass CollectiveInitializeCommunicatorOpKernel : public AsyncOpKernel {\n public:\n  explicit CollectiveInitializeCommunicatorOpKernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"communication_hint\", &communication_hint_));\n    OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    device_type_ = c->device_type();\n  }\n\n  Status CheckInputs(Tensor group_size_t, Tensor group_key_t) {\n    if (group_size_t.dims() > 0) {\n      return errors::InvalidArgument(\n          \"Unexpected dimensions on input group_size. \"\n          \"It shoulbe a scalar, got tensor with shape \",\n          group_size_t.shape().DebugString());\n    }\n    if (group_key_t.dims() > 0) {\n      return errors::InvalidArgument(\n          \"Unexpected dimensions on input group_key, got \",\n          group_key_t.shape().DebugString());\n    }\n\n    auto group_size = group_size_t.unaligned_flat<int32>()(0);\n    if (group_size <= 0) {\n      return errors::InvalidArgument(\n          \"group_size must be positive integer but got \", group_size);\n    }\n    return Status::OK();\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto group_key_t = c->input(0);\n    auto rank_t = c->input(1);\n    auto group_size_t = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(c, CheckInputs(group_size_t, group_key_t), done);\n\n    auto group_size = group_size_t.unaligned_flat<int32>()(0);\n    auto group_key = group_key_t.unaligned_flat<int32>()(0);\n    auto rank = rank_t.unaligned_flat<int32>()(0);\n\n    ResourceHandle resource_handle =\n        MakeResourceHandle<CollectiveGroupResource>(\n            c, \"collective_op_group\", absl::StrFormat(\"%d\", group_key));\n\n    Tensor* output_handle = nullptr;\n    OP_REQUIRES_OK_ASYNC(\n        c, c->allocate_output(0, TensorShape({}), &output_handle), done);\n    output_handle->scalar<ResourceHandle>()() = resource_handle;\n\n    CollectiveGroupResource* resource = new CollectiveGroupResource(\n        group_key, rank, group_size, this->communication_hint_,\n        this->timeout_seconds_);\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        CreateResource<CollectiveGroupResource>(c, resource_handle, resource),\n        done);\n    auto group_params = new CollGroupParams();\n    group_params->device_type = device_type_;\n    group_params->group_size = resource->group_size();\n    group_params->group_key = resource->group_key();\n\n    auto* col_exec = c->collective_executor();\n\n    c->collective_executor()->RunClosure([c, done = std::move(done),\n                                          group_params, col_exec]() {\n      VLOG(1) << \"Collective Group initialization for \"\n              << \" device \" << c->device()->name() << \" group \"\n              << group_params->group_key;\n      col_exec->CompleteGroupAsync(\n          c->device()->attributes(), group_params, c->cancellation_manager(),\n          [c, done = std::move(done), group_params](const Status& s) {\n            if (s.ok()) {\n              VLOG(1) << \"Collective Group initialization done for device \"\n                      << c->device()->name() << \" group \"\n                      << group_params->group_key << \" status \" << s;\n            } else {\n              c->SetStatus(s);\n            }\n            delete group_params;\n            done();\n          });\n    });\n  }\n\n private:\n  string communication_hint_;\n  DeviceType device_type_;\n  float timeout_seconds_ = 0;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"CollectiveInitializeCommunicator\").Device(DEVICE_CPU),\n    CollectiveInitializeCommunicatorOpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveInitializeCommunicator\")\n                            .Device(DEVICE_GPU)\n                            .HostMemory(\"group_size\")\n                            .HostMemory(\"group_key\")\n                            .HostMemory(\"rank\"),\n                        CollectiveInitializeCommunicatorOpKernel);\n\nclass CollectiveOpV3Kernel : public AsyncOpKernel {\n public:\n  explicit CollectiveOpV3Kernel(OpKernelConstruction* c)\n      : AsyncOpKernel(c), name_(name()), device_type_(DEVICE_DEFAULT) {\n    OP_REQUIRES_OK(c, c->GetAttr(\"T\", &data_type_));\n    if (c->HasAttr(\"timeout_seconds\")) {\n      OP_REQUIRES_OK(c, c->GetAttr(\"timeout_seconds\", &timeout_seconds_));\n    } else {\n      timeout_seconds_ = -1;\n    }\n    device_type_ = c->device_type();\n  }\n\n protected:\n  // Fills common parts of CollectiveParams according to the Op, *excluding\n  // output_shape*. Kernels should further work on the CollectiveParams if they\n  // need to set additional fields.\n  Status FillCollectiveParams(CollectiveParams* col_params,\n                              const Tensor& group_assignment,\n                              CollectiveType collective_type,\n                              CollectiveGroupResource* resource) {\n    int64 group_id;\n    int64 group_size;\n    if (group_assignment.NumElements() == 0) {\n      // No group assignments, perform collective as a single group.\n      group_id = 0;\n      group_size = resource->group_size();\n    } else {\n      return errors::Unimplemented(\"Group assignments are not supported yet.\");\n    }\n\n    // Construct instance key with format:\n    // <11 bits for group><21 bits for atomic incremented instance key>\n    int32 instance_key = group_id << 21 | resource->get_next_instance_key();\n    col_params->name = name_;\n    col_params->group.device_type = device_type_;\n    col_params->group.group_size = group_size;\n    col_params->group.group_key = resource->group_key();\n    col_params->instance.type = collective_type;\n    col_params->instance.instance_key = instance_key;\n    col_params->instance.data_type = data_type_;\n    col_params->instance.impl_details.communication_hint =\n        resource->communication_hint();\n    col_params->instance.impl_details.timeout_seconds =\n        timeout_seconds_ > 0 ? resource->timeout_seconds() : timeout_seconds_;\n    col_params->run_group_initialization = false;\n    return Status::OK();\n  }\n\n  // Runs a collective. The output tensor must be allocated before calling this\n  // method. col_params must live until done is called.\n  void Run(OpKernelContext* c, CollectiveParams* col_params,\n           DoneCallback done) {\n    CollectiveExecutor* col_exec = c->collective_executor();\n    OP_REQUIRES_ASYNC(\n        c, col_exec,\n        errors::Internal(\n            \"Failed to get CollectiveExecutor from OpKernelContext for Op \",\n            name_),\n        done);\n    // Resolve the collective params.\n    // Schedule the `CompleteParamsAsync` call on a work queue that can handle\n    // blocking work because it's not guaranteed that this call cannot block.\n    col_exec->RunClosure([c, done = std::move(done), col_params, col_exec]() {\n      VLOG(1) << \"Collective CompleteParams for \" << col_params->name\n              << \" device \" << c->device()->name() << \" group \"\n              << col_params->group.group_key << \" instance \"\n              << col_params->instance.instance_key;\n      col_exec->CompleteParamsAsync(\n          c->device()->attributes(), col_params, c->cancellation_manager(),\n          [c, done = std::move(done), col_params, col_exec](const Status& s) {\n            if (s.ok()) {\n              auto actual_done = [c, col_params,\n                                  done = std::move(done)](const Status& s) {\n                VLOG(1) << \"Collective ExecuteAsync done for \"\n                        << col_params->name << \" device \" << c->device()->name()\n                        << \" group \" << col_params->group.group_key\n                        << \" instance \" << col_params->instance.instance_key\n                        << \" status \" << s;\n                if (!s.ok()) {\n                  c->SetStatus(s);\n                }\n                done();\n              };\n              VLOG(1) << \"Collective ExecuteAsync start for \"\n                      << col_params->name << \" device \" << c->device()->name()\n                      << \" group \" << col_params->group.group_key\n                      << \" instance \" << col_params->instance.instance_key;\n              col_exec->ExecuteAsync(\n                  c, col_params,\n                  CollectiveKey(c, col_params->group.group_key,\n                                col_params->instance.instance_key),\n                  actual_done);\n            } else {\n              c->SetStatus(s);\n              done();\n            }\n          });\n    });\n  }\n\n protected:\n  string name_;\n  DataType data_type_ = DT_INVALID;\n  DeviceType device_type_;\n  float timeout_seconds_ = 0;\n};\n\nclass CollectiveReduceV3OpKernel : public CollectiveOpV3Kernel {\n public:\n  explicit CollectiveReduceV3OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV3Kernel(c) {\n    string reduction;\n    OP_REQUIRES_OK(c, c->GetAttr(\"reduction\", &reduction));\n    if (reduction == \"Max\") {\n      reduction = \"Maximum\";\n    } else if (reduction == \"Min\") {\n      reduction = \"Minimum\";\n    }\n    // Prepare OpKernels for reduction and final operations.\n    // The merge_op takes two inputs\n    NodeDef sub_node;\n    sub_node.add_input(c->def().input(0));\n    sub_node.add_input(c->def().input(0));\n    sub_node.set_device(c->def().device());\n    SetAttrValue(data_type_, &(*sub_node.mutable_attr())[\"T\"]);\n    merge_op_ = BuildOpKernel(c, reduction, &sub_node);\n    final_op_ = BuildOpKernel(c, \"Id\", &sub_node);\n    name_ = strings::StrCat(c->def().name(), \": ReduceV3(\", reduction, \")\");\n    VLOG(2) << \"CollectiveReduceV3 \" << this << \" name \" << name_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done_with_cleanup);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment, REDUCTION_COLLECTIVE,\n                             resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV3 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n\n private:\n  std::unique_ptr<OpKernel> merge_op_;\n  std::unique_ptr<OpKernel> final_op_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV3\").Device(DEVICE_CPU),\n                        CollectiveReduceV3OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveReduceV3\").Device(DEVICE_GPU),\n                        CollectiveReduceV3OpKernel);\n\nclass CollectiveAllToAllV3OpKernel : public CollectiveOpV3Kernel {\n public:\n  explicit CollectiveAllToAllV3OpKernel(OpKernelConstruction* c)\n      : CollectiveOpV3Kernel(c) {\n    name_ = strings::StrCat(c->def().name(), \": AllToAllV3\");\n    VLOG(2) << \"CollectiveAllToAllV3 \" << this << \" name \" << name_;\n  }\n\n  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done_with_cleanup);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment,\n                             ALL_TO_ALL_COLLECTIVE, resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    VLOG(1) << \"CollectiveAllToAll group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveAllToAllV3\").Device(DEVICE_CPU),\n                        CollectiveAllToAllV3OpKernel);\nREGISTER_KERNEL_BUILDER(Name(\"CollectiveAllToAllV3\").Device(DEVICE_GPU),\n                        CollectiveAllToAllV3OpKernel);\n}  // namespace\n}  // namespace tensorflow\n", "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for V2 Collective Operations.\"\"\"\n\nimport os\nimport threading\nimport time\n\nfrom absl.testing import parameterized\n\nfrom tensorflow.python.compat import v2_compat\nfrom tensorflow.python.data.experimental.ops import testing as dataset_testing\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.distribute import combinations\nfrom tensorflow.python.distribute import test_util\nfrom tensorflow.python.eager import cancellation\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import check_ops\nfrom tensorflow.python.ops import collective_ops as _collective_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.platform import test\n\n\nclass CollectiveOpsV1(object):\n  all_reduce = _collective_ops.all_reduce\n  all_gather = _collective_ops.all_gather\n  broadcast_send = _collective_ops.broadcast_send\n  broadcast_recv = _collective_ops.broadcast_recv\n\n\nclass CollectiveOpsV2(object):\n\n  @staticmethod\n  def all_reduce(t, group_size, group_key, instance_key, *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.all_reduce_v2(t, group_size, group_key, instance_key,\n                                         *args, **kwargs)\n\n  @staticmethod\n  def all_gather(t, group_size, group_key, instance_key, *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.all_gather_v2(t, group_size, group_key, instance_key,\n                                         *args, **kwargs)\n\n  @staticmethod\n  def broadcast_send(t, shape, dtype, group_size, group_key, instance_key,\n                     *args, **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    return _collective_ops.broadcast_send_v2(t, group_size, group_key,\n                                             instance_key, *args, **kwargs)\n\n  @staticmethod\n  def broadcast_recv(shape, dtype, group_size, group_key, instance_key, *args,\n                     **kwargs):\n    group_size = array_ops.identity(group_size)\n    group_key = array_ops.identity(group_key)\n    instance_key = array_ops.identity(instance_key)\n    shape = array_ops.identity(shape)\n    return _collective_ops.broadcast_recv_v2(\n        shape, dtype, group_size, group_key, instance_key, *args, **kwargs)\n\n\ndevice_combination = (\n    combinations.combine(device='CPU', communication='RING', required_gpus=0) +\n    combinations.combine(\n        device='GPU', communication=['RING', 'NCCL'], required_gpus=2))\n\ncollective_op_combinations = combinations.combine(collective_op=[\n    combinations.NamedObject('all_reduce', CollectiveOpsV1.all_reduce),\n    combinations.NamedObject('all_reduce_v2', CollectiveOpsV2.all_reduce),\n    combinations.NamedObject('all_gather', CollectiveOpsV1.all_gather),\n    combinations.NamedObject('all_gather_v2', CollectiveOpsV2.all_gather)\n])\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_ops=[\n                combinations.NamedObject('v1', CollectiveOpsV1),\n                combinations.NamedObject('v2', CollectiveOpsV2)\n            ],\n            mode='eager'), device_combination))\nclass CollectiveOpsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testReduce(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        return collective_ops.all_reduce(\n            in_value,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_reduce_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [2.], rtol=1e-5, atol=1e-5)\n\n  def testGather(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_gather_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        return collective_ops.all_gather(\n            in_value,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    @def_function.function\n    def run_all_gather_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_gather(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_gather(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_gather_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_gather_2devices():\n      self.assertAllClose(result, [1., 1.], rtol=1e-5, atol=1e-5)\n\n  def testBroadcast(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_broadcast_2devices():\n      shape = [3]\n      in_value = constant_op.constant([1., 2., 3.], shape=shape)\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.broadcast_send(\n                in_value,\n                shape,\n                in_value.dtype,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.broadcast_recv(\n                shape,\n                in_value.dtype,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    for result in run_broadcast_2devices():\n      self.assertAllClose(result, [1., 2., 3.], rtol=1e-5, atol=1e-5)\n\n  def testInstanceKeyScopedUnderGroupKey(self, collective_ops, device,\n                                         communication):\n    if device == 'GPU' and context.num_gpus() < 4:\n      self.skipTest('not enough GPU')\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    dev2 = '/device:%s:2' % device\n    dev3 = '/device:%s:3' % device\n\n    @def_function.function\n    def run_all_reduce_4devices_same_instance_key():\n      # Use a common instance key for both groups.\n      instance_key = 0\n      # We will create 2 groups each with 2 devices.\n      group_size = 2\n      # Group 0 comprises dev0 and dev1.\n      group0_key = 0\n      # Group 1 comprises dev2 and dev3.\n      group1_key = 1\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(1.), group_size, group0_key, instance_key))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(2.), group_size, group0_key, instance_key))\n      with ops.device(dev2):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(3.), group_size, group1_key, instance_key))\n      with ops.device(dev3):\n        collectives.append(\n            collective_ops.all_reduce(\n                constant_op.constant(4.), group_size, group1_key, instance_key))\n      return collectives\n\n    results = run_all_reduce_4devices_same_instance_key()\n    self.assertAllClose(results[0], 3., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[1], 3., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[2], 7., rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[3], 7., rtol=1e-5, atol=1e-5)\n\n  def testCollectiveGroupSizeOne(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n\n    group_size = 1\n    group_key = 100\n    in_value = [1., 2., 3., 4.]\n    in_tensor = constant_op.constant(in_value)\n\n    with ops.device(dev0):\n      reduced_tensor = collective_ops.all_reduce(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key=100,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, reduced_tensor.numpy())\n\n    with ops.device(dev0):\n      gathered_tensor = collective_ops.all_gather(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key=200,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, gathered_tensor.numpy())\n\n  def testCollectiveInvalidKey(self, collective_ops, device, communication):\n    dev0 = '/device:%s:0' % device\n\n    group_size = 1\n    group_key = 100\n    instance_key = 100\n    in_value = [1., 2., 3., 4.]\n    in_tensor = constant_op.constant(in_value)\n\n    with ops.device(dev0):\n      reduced_tensor = collective_ops.all_reduce(\n          in_tensor,\n          group_size,\n          group_key,\n          instance_key,\n          communication_hint=communication)\n    self.assertAllEqual(in_value, reduced_tensor.numpy())\n\n    with self.assertRaisesRegex(\n        errors.InternalError, 'instance 100 expected type 0 and data_type 1 but'\n        ' got type 2 and data_type 1'):\n      with ops.device(dev0):\n        collective_ops.all_gather(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  def testMultipleGroups(self, collective_ops, device, communication):\n    if device == 'GPU' and context.num_gpus() < 4:\n      self.skipTest('not enough GPU')\n\n    num_elements = 4\n\n    @def_function.function\n    def run_all_reduce(group_size, group_key):\n      instance_key = group_key\n      input_value = [float(group_key) for i in range(num_elements)]\n      collectives = []\n      for device_idx in range(group_size):\n        with ops.device('/{}:{}'.format(device, device_idx)):\n          input_tensor = constant_op.constant(input_value)\n          collectives.append(\n              collective_ops.all_reduce(\n                  input_tensor,\n                  group_size,\n                  group_key,\n                  instance_key,\n                  communication_hint=communication))\n      return collectives\n\n    def run_and_assert(group_size, group_key):\n      for reduced_tensor in run_all_reduce(group_size, group_key):\n        self.assertAllEqual(\n            [float(group_key) * group_size for i in range(num_elements)],\n            reduced_tensor.numpy())\n\n    run_and_assert(group_size=2, group_key=1)\n    run_and_assert(group_size=3, group_key=2)\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_ops=[\n                combinations.NamedObject('v2', CollectiveOpsV2)\n            ],\n            mode='eager',\n            max_subdivs_per_device=[-1, 0, 16]), device_combination))\nclass AllReduceWithSubdivisionsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testReduce(self, collective_ops, device, communication,\n                 max_subdivs_per_device):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_1device():\n      with ops.device(dev0):\n        in_value = constant_op.constant([1.])\n        group_size = 1\n        group_key = 1\n        instance_key = 1\n        if max_subdivs_per_device == -1:\n          return collective_ops.all_reduce(\n              in_value,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n        else:\n          return collective_ops.all_reduce(\n              in_value,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication,\n              max_subdivs_per_device=max_subdivs_per_device)\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      in_value = constant_op.constant([1.])\n      group_size = 2\n      group_key = 2\n      instance_key = 2\n      collectives = []\n      with ops.device(dev0):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      with ops.device(dev1):\n        collectives.append(\n            collective_ops.all_reduce(\n                in_value,\n                group_size,\n                group_key,\n                instance_key,\n                communication_hint=communication))\n      return collectives\n\n    self.assertAllClose(run_all_reduce_1device(), [1.], rtol=1e-5, atol=1e-5)\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [2.], rtol=1e-5, atol=1e-5)\n\n\n@combinations.generate(\n    combinations.combine(required_physical_gpus=2, mode='eager'))\nclass XlaTest(test.TestCase, parameterized.TestCase):\n\n  def testReduce(self):\n    device0 = '/device:GPU:0'\n    device1 = '/device:GPU:1'\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    results = []\n\n    def all_reduce(device):\n\n      @def_function.function(jit_compile=True)\n      def f():\n        return _collective_ops.all_reduce_v2([1.], group_size, group_key,\n                                             instance_key)\n\n      with ops.device(device):\n        results.append(f())\n\n    t0 = threading.Thread(target=all_reduce, args=(device0,))\n    t1 = threading.Thread(target=all_reduce, args=(device1,))\n    t0.start()\n    t1.start()\n    t0.join()\n    t1.join()\n\n    self.assertAllEqual(results, [[2.], [2.]])\n\n\n@combinations.generate(\n    combinations.times(collective_op_combinations, device_combination))\nclass AbortCollectiveOpsTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testAbortGroupParamsResolution(self, collective_op, device,\n                                     communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      # This hangs on params resolution since we're only launching one\n      # collective for a group size of 2.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    t.join()\n    # Reset the context in order to reset the collective executor.\n    _setup_context()\n\n    # After reset non-NCCL collectives should work.\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    def_function.function(collective_fn)()\n\n  def testAbortInstanceParamsResolution(self, collective_op, device,\n                                        communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    # First perform a normal all-reduce to complete the group resolution.\n    def_function.function(collective_fn)()\n\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    # Use a different instance key to trigger another instance resolution.\n    instance_key = 101\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      # This hangs on params resolution since we're only launching one\n      # collective for a group size of 2.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    context._reset_context()  # pylint: disable=protected-access\n    t.join()\n    # Reset the context in order to reset the collective executor.\n    _setup_context()\n\n    # After reset non-NCCL collectives should work.\n    def_function.function(collective_fn)()\n\n  def testAbortCommunication(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    # First perform a normal collective to finish resolution.\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    def_function.function(collective_fn)()\n\n    # Launch a collective that hangs, and abort the collective executor after\n    # the launch.\n    def abort_fn():\n      time.sleep(2)\n      context.context().abort_collective_ops(errors.UNAVAILABLE, 'peer down')\n\n    t = threading.Thread(target=abort_fn)\n    t.start()\n\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # After abortion, subsequent collectives should fail immediately.\n    with self.assertRaisesRegex(errors.UnavailableError, 'peer down'):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    # Reset the context in order to reset the collective executor.\n    t.join()\n    _setup_context()\n    def_function.function(collective_fn)()\n\n\nclass OpCancellationTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce',\n                                           CollectiveOpsV1.all_reduce),\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather',\n                                           CollectiveOpsV1.all_gather),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorNotAbortIfNoCollective(self, collective_op, device,\n                                        communication):\n    # Do not abort if there's no active collective ops. There could be\n    # exceptions like EOF which we expect users to catch, aborting collective\n    # ops on all op errors intervenes with this workflow.\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    dataset = dataset_ops.Dataset.from_tensors([1.])\n\n    @def_function.function\n    def collective_fn(in_tensor):\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    @def_function.function\n    def f():\n      iterator = iter(dataset)\n      collective_fn(next(iterator))\n      # This next(iterator) should raise EOF.\n      collective_fn(next(iterator))\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    collective_fn(constant_op.constant([1.]))\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce',\n                                           CollectiveOpsV1.all_reduce),\n                  combinations.NamedObject('all_gather',\n                                           CollectiveOpsV1.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorAbortWithCollective(self, collective_op, device,\n                                     communication):\n    # Abort v1 collective ops if there're active collective ops at the time of\n    # an op error. This is due to the inability to cancel collective ops, and op\n    # errors may cause running collective ops to hang.\n    dev0 = '/device:%s:0' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n    # Make the dataset sleep a while so that the collective is being executed\n    # when the EOF happens.\n    dataset = dataset_ops.Dataset.from_tensors([1.]).apply(\n        dataset_testing.sleep(sleep_microseconds=200))\n\n    @def_function.function\n    def f():\n      # Launch a collective op that won't be able to finish to test abortion\n      # when other ops error.\n      with ops.device(dev0):\n        ret = collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n      iterator = iter(dataset)\n      next(iterator)\n      # This should raise EOF.\n      next(iterator)\n      return ret\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    # Now collective ops is aborted, subsequent collective ops should fail with\n    # the previous error.\n    with self.assertRaises(errors.CancelledError):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testOpErrorNotAbortWithCollective(self, collective_op, device,\n                                        communication):\n    # Do not abort v2 collective ops even if there're active collective ops at\n    # the time of an op error. We rely cancellation to terminate active\n    # collective ops.\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    @def_function.function\n    def collective_fn():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              in_tensor,\n              group_size,\n              group_key,\n              instance_key,\n              communication_hint=communication)\n\n    # Local params resolution cannot be cancelled yet, so we perform a normal\n    # collective so that the group is resolved.\n    collective_fn()\n\n    # Make the dataset sleep a while so that the collective is being executed\n    # when the EOF happens.\n    dataset = dataset_ops.Dataset.from_tensors([1.]).apply(\n        dataset_testing.sleep(sleep_microseconds=200))\n\n    @def_function.function\n    def f():\n      # Launch a collective op that won't be able to finish to test cancellation\n      # when other ops error.\n      with ops.device(dev0):\n        ret = collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n      iterator = iter(dataset)\n      next(iterator)\n      # This should raise EOF.\n      next(iterator)\n      return ret\n\n    with self.assertRaises(errors.OutOfRangeError):\n      f()\n    # Collective ops shouldn't be aborted and new collectives should be able to\n    # proceed.\n    collective_fn()\n\n  @combinations.generate(\n      combinations.times(\n          combinations.combine(\n              collective_op=[\n                  combinations.NamedObject('all_reduce_v2',\n                                           CollectiveOpsV2.all_reduce),\n                  combinations.NamedObject('all_gather_v2',\n                                           CollectiveOpsV2.all_gather),\n              ],\n              mode='eager'), device_combination))\n  def testCancelDuringParamResolution(self, collective_op, device,\n                                      communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n    t1_cancellation_manager = cancellation.CancellationManager()\n    t2_cancellation_manager = cancellation.CancellationManager()\n\n    @def_function.function\n    def _collective_fn(x):\n      # Run an assertion to crash one of the two function executions running\n      # collectives. We explicitly cancel the other in response.\n      assert_op = check_ops.assert_equal(x, in_tensor)\n      with ops.control_dependencies([assert_op]):\n        return collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n    collective_concrete = _collective_fn.get_concrete_function(in_tensor)\n\n    finish_mu = threading.Lock()\n    finishes = 0\n\n    def _placement_wrapper(device, x, my_cancellation, other_cancellation):\n      try:\n        with ops.device(device):\n          cancelable_collective = my_cancellation.get_cancelable_function(\n              collective_concrete)\n          return cancelable_collective(x)\n      except errors.InvalidArgumentError:\n        # `assert_equal` failed for this execution of the function. The other\n        # function would deadlock without cancellation.\n        other_cancellation.start_cancel()\n      except errors.CancelledError:\n        pass\n      nonlocal finishes\n      with finish_mu:\n        finishes += 1\n\n    t1 = threading.Thread(\n        target=_placement_wrapper,\n        args=(dev0, constant_op.constant([1.]), t1_cancellation_manager,\n              t2_cancellation_manager))\n    t2 = threading.Thread(\n        target=_placement_wrapper,\n        # Will cause the assertion to fail\n        args=(dev1, constant_op.constant([2.]), t2_cancellation_manager,\n              t1_cancellation_manager))\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n    self.assertEqual(finishes, 2)\n\n\n@combinations.generate(\n    combinations.times(collective_op_combinations, device_combination))\nclass TimeoutTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testTimeout(self, collective_op, device, communication):\n    timeout = 1.5\n\n    @def_function.function\n    def run(group_size, reported_group_size=None):\n      group_key = 20\n      instance_key = 30\n      tensor = [1., 2., 3., 4.]\n      results = []\n      if reported_group_size is None:\n        reported_group_size = group_size\n      for i in range(group_size):\n        with ops.device('/{}:{}'.format(device, i)):\n          input_data = constant_op.constant(tensor)\n          result = collective_op(\n              input_data,\n              group_size=reported_group_size,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint=communication,\n              timeout=timeout)\n          results.append(result)\n      return results\n\n    run(2, 2)\n\n    start_time = time.time()\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      run(1, 2)\n    elapsed = time.time() - start_time\n    self.assertAllGreaterEqual(elapsed, timeout)\n\n  def testParamResolutionAfterTimeout(self, collective_op, device,\n                                      communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    timeout = 1.5\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    # This timeout comes from param solution.\n    with self.assertRaisesRegex(\n        errors.DeadlineExceededError,\n        'Collective has timed out waiting for other workers'):\n      with ops.device(dev0):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication,\n            timeout=timeout)\n\n    # We launch the second device after the first device times out. This is to\n    # simulate the situation when other workers are slow and the timeout is\n    # short. It should error immediately.\n    with self.assertRaisesRegex(\n        errors.DeadlineExceededError,\n        'Collective has timed out waiting for other workers'):\n      with ops.device(dev1):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication)\n\n  def testExecutionAfterTimeout(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    timeout = 1.5\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    @def_function.function\n    def run():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              input_data,\n              group_size=2,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint=communication,\n              timeout=timeout)\n\n    # Run a normal all-reduce to complete param resolution.\n    run()\n\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      with ops.device(dev0):\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication,\n            timeout=timeout)\n\n    # We launch the second device after the first device times out. This is to\n    # simulate the situation when other workers are slow and the timeout is\n    # short. It should error immediately.\n    with self.assertRaisesRegex(errors.DeadlineExceededError,\n                                'Collective has timed out during execution'):\n      with ops.device(dev1):\n        # No timeout.\n        collective_op(\n            input_data,\n            group_size=2,\n            group_key=group_key,\n            instance_key=instance_key,\n            communication_hint=communication)\n\n\nclass CommunicationHintTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  @combinations.generate(\n      combinations.times(collective_op_combinations,\n                         combinations.combine(required_gpus=[0, 1])))\n  def testNCCLFallbackOnCPU(self, collective_op):\n    # communication_hint=NCCL should work for CPU by falling back to RING. The\n    # test doesn't actually require GPU, only GPU builds. We specify\n    # required_gpus=1 so that it's tested with GPU builds.\n    dev0 = '/device:CPU:0'\n    dev1 = '/device:CPU:1'\n    group_key = 20\n    instance_key = 30\n    input_data = constant_op.constant([1., 2., 3., 4.])\n\n    @def_function.function\n    def run():\n      for device in [dev0, dev1]:\n        with ops.device(device):\n          collective_op(\n              input_data,\n              group_size=2,\n              group_key=group_key,\n              instance_key=instance_key,\n              communication_hint='NCCL')\n\n    run()\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(\n            collective_op=[\n                combinations.NamedObject('all_reduce_v2',\n                                         CollectiveOpsV2.all_reduce),\n                combinations.NamedObject('all_gather_v2',\n                                         CollectiveOpsV2.all_gather),\n            ],\n            mode='eager'), device_combination))\nclass OrderingTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testOrdering(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    with ops.device(dev0):\n      token0 = resource_variable_ops.ResourceVariable(0.)\n    with ops.device(dev1):\n      token1 = resource_variable_ops.ResourceVariable(0.)\n\n    @def_function.function\n    def f():\n      # Launch the first collective with token.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token0.handle)\n      with ops.device(dev1):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token1.handle)\n      # Launch the second collective without token.\n      with ops.device(dev0):\n        collective_op(in_tensor, group_size, group_key, instance_key)\n      with ops.device(dev1):\n        collective_op(in_tensor, group_size, group_key, instance_key)\n      # Launch the third collective with token.\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token0.handle)\n      with ops.device(dev1):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            ordering_token=token1.handle)\n\n    graph = f.get_concrete_function().graph\n    for device in [dev0, dev1]:\n      # Try to find the third collective, which should have the first collective\n      # as a control input.\n      third = None\n      for op in graph.get_operations():\n        if (op.type.startswith('Collective') and op.device.endswith(device) and\n            op.control_inputs and\n            op.control_inputs[0].type.startswith('Collective')):\n          self.assertIsNone(third)\n          third = op\n      self.assertIsNotNone(third)\n      # Verify it's not the second collective by looking at the inputs.\n      self.assertTrue(any(v.dtype == dtypes.resource for v in third.inputs))\n      first = third.control_inputs[0]\n      self.assertEqual(third.device, first.device)\n      # Verify it's not the second collective by looking at the inputs.\n      self.assertTrue(any(v.dtype == dtypes.resource for v in first.inputs))\n      self.assertEmpty(first.control_inputs)\n\n\nclass InputPipelineTest(test.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    _setup_context()\n\n  def testMap(self):\n    group_size = 2\n    group_key = 100\n    instance_key = 100\n\n    def create_dataset_and_fetch_one(t):\n      dataset = dataset_ops.Dataset.from_tensor_slices([t])\n\n      def reduce_fn(t):\n        return CollectiveOpsV2.all_reduce(\n            t,\n            group_size=group_size,\n            group_key=group_key,\n            instance_key=instance_key)\n\n      dataset = dataset.map(reduce_fn)\n      return next(iter(dataset))\n\n    @def_function.function\n    def f():\n      with ops.device('CPU:0'):\n        value0 = create_dataset_and_fetch_one([1.])\n      with ops.device('CPU:1'):\n        value1 = create_dataset_and_fetch_one([2.])\n      return value0, value1\n\n    self.assertAllEqual(self.evaluate(f()), [[3.], [3.]])\n\n\n@combinations.generate(\n    combinations.times(\n        combinations.combine(collective_op=[\n            combinations.NamedObject('all_reduce_v2',\n                                     CollectiveOpsV2.all_reduce),\n            combinations.NamedObject('all_gather_v2',\n                                     CollectiveOpsV2.all_gather)\n        ]), device_combination))\nclass InvalidInputTest(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    _setup_context()\n    super().setUp()\n\n  def testInvalidGroupKey(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    group_size = 2\n    group_key = [100]\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    with self.assertRaises(errors.InvalidArgumentError):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  def testInvalidGroupSize(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    group_size = -2\n    group_key = 100\n    instance_key = 100\n    in_tensor = constant_op.constant([1.])\n\n    with self.assertRaises(errors.InvalidArgumentError):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n  def testInvalidInstanceKey(self, collective_op, device, communication):\n    dev0 = '/device:%s:0' % device\n    group_size = 2\n    group_key = 100\n    instance_key = [100]\n    in_tensor = constant_op.constant([1.])\n\n    with self.assertRaises(errors.InvalidArgumentError):\n      with ops.device(dev0):\n        collective_op(\n            in_tensor,\n            group_size,\n            group_key,\n            instance_key,\n            communication_hint=communication)\n\n\nclass CollectiveOpsV3Test(test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    _setup_context()\n\n  def testGroupInitialization(self):\n    group_size = 2\n    group_key = 100\n\n    @def_function.function\n    def f():\n      with ops.device('CPU:0'):\n        _collective_ops.initialize_communicator(\n            group_key=group_key, rank=0, group_size=group_size)\n      with ops.device('CPU:1'):\n        _collective_ops.initialize_communicator(\n            group_key=group_key, rank=1, group_size=group_size)\n\n      # TODO(b/193864859): Add validation with reduction op.\n\n    self.evaluate(f())\n\n  @combinations.generate(device_combination)\n  def testAllReduceV3(self, device, communication):\n    group_size = 2\n    group_key = 101\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_reduce_2devices():\n      collectives = []\n      with ops.device(dev0):\n        group_handle0 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=0,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_reduce_v3(\n                group_handle0, [1.0], reduction='Add'))\n      with ops.device(dev1):\n        group_handle1 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=1,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_reduce_v3(\n                group_handle1, [2.0], reduction='Add'))\n      return collectives\n\n    for result in run_all_reduce_2devices():\n      self.assertAllClose(result, [3.], rtol=1e-5, atol=1e-5)\n\n  @combinations.generate(device_combination)\n  def testAllToAllV3(self, device, communication):\n    group_size = 2\n    group_key = 104\n\n    dev0 = '/device:%s:0' % device\n    dev1 = '/device:%s:1' % device\n\n    @def_function.function\n    def run_all_to_all_2devices():\n      collectives = []\n      with ops.device(dev0):\n        group_handle0 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=0,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_to_all_v3(group_handle0, [1.0, 3.0]))\n      with ops.device(dev1):\n        group_handle1 = _collective_ops.initialize_communicator(\n            group_key=group_key,\n            rank=1,\n            group_size=group_size,\n            communication_hint=communication)\n        collectives.append(\n            _collective_ops.all_to_all_v3(group_handle1, [2.0, 4.0]))\n      return collectives\n\n    result = run_all_to_all_2devices()\n    self.assertAllClose(result[0], [1.0, 2.0], rtol=1e-5, atol=1e-5)\n    self.assertAllClose(result[1], [3.0, 4.0], rtol=1e-5, atol=1e-5)\n\n\ndef _setup_context():\n  context._reset_context()\n  test_util.set_logical_devices_to_at_least('CPU', 4)\n  context.ensure_initialized()\n\n\nif __name__ == '__main__':\n  os.environ['NCCL_DEBUG'] = 'INFO'\n  v2_compat.enable_v2_behavior()\n  test.main()\n"], "filenames": ["tensorflow/core/kernels/collective_ops.cc", "tensorflow/python/kernel_tests/collective_ops_test.py"], "buggy_code_start_loc": [497, 1184], "buggy_code_end_loc": [1138, 1184], "fixing_code_start_loc": [497, 1185], "fixing_code_end_loc": [1141, 1248], "type": "CWE-416", "message": "TensorFlow is an open source platform for machine learning. In affected versions the async implementation of `CollectiveReduceV2` suffers from a memory leak and a use after free. This occurs due to the asynchronous computation and the fact that objects that have been `std::move()`d from are still accessed. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected.", "other": {"cve": {"id": "CVE-2021-41220", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T23:15:08.350", "lastModified": "2021-11-10T13:16:42.890", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions the async implementation of `CollectiveReduceV2` suffers from a memory leak and a use after free. This occurs due to the asynchronous computation and the fact that objects that have been `std::move()`d from are still accessed. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas, la implementaci\u00f3n as\u00edncrona de \"CollectiveReduceV2\" sufre una perdida de memoria y un uso de memoria previamente liberada. Esto ocurre debido al c\u00e1lculo as\u00edncrono y al hecho de que se sigue accediendo a los objetos que han sido \"std::move()\"d. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.6.1, ya que esta versi\u00f3n es la \u00fanica que tambi\u00e9n est\u00e1 afectada"}], "metrics": {"cvssMetricV31": [{"source": "security-advisories@github.com", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "2.6.1", "matchCriteriaId": "5D68D8D1-DB27-4395-9D3D-2BED901B852C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.7.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "A58EDA5C-66D6-46F1-962E-60AFB7C784A7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.7.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "89522760-C2DF-400D-9624-626D8F160CBA"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/ca38dab9d3ee66c5de06f11af9a4b1200da5ef75", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-gpfh-jvf9-7wg5", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/ca38dab9d3ee66c5de06f11af9a4b1200da5ef75"}}