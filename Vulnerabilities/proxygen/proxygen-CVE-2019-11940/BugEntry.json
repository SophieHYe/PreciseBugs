{"buggy_code": ["/*\n *  Copyright (c) 2017, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <proxygen/lib/http/codec/compress/HeaderTable.h>\n\n#include <glog/logging.h>\n\nusing std::list;\nusing std::pair;\nusing std::string;\n\nnamespace proxygen {\n\nvoid HeaderTable::init(uint32_t capacityVal) {\n  bytes_ = 0;\n  size_ = 0;\n  head_ = 0;\n  capacity_ = capacityVal;\n  // at a minimum an entry will take 32 bytes\n  uint32_t length = (capacityVal >> 5) + 1;\n  table_.assign(length, HPACKHeader());\n  names_.clear();\n}\n\nbool HeaderTable::add(const HPACKHeader& header) {\n  // handle size overflow\n  if (bytes_ + header.bytes() > capacity_) {\n    evict(header.bytes());\n  }\n  // this means the header entry is larger than our table\n  if (bytes_ + header.bytes() > capacity_) {\n    return false;\n  }\n  if (size_ > 0) {\n    head_ = next(head_);\n  }\n  table_[head_] = header;\n  // index name\n  names_[header.name].push_back(head_);\n  bytes_ += header.bytes();\n  ++size_;\n  return true;\n}\n\nuint32_t HeaderTable::getIndex(const HPACKHeader& header) const {\n  auto it = names_.find(header.name);\n  if (it == names_.end()) {\n    return 0;\n  }\n  for (auto i : it->second) {\n    if (table_[i].value == header.value) {\n      return toExternal(i);\n    }\n  }\n  return 0;\n}\n\nbool HeaderTable::hasName(const std::string& name) {\n  return names_.find(name) != names_.end();\n}\n\nuint32_t HeaderTable::nameIndex(const std::string& name) const {\n  auto it = names_.find(name);\n  if (it == names_.end()) {\n    return 0;\n  }\n  return toExternal(it->second.back());\n}\n\nconst HPACKHeader& HeaderTable::operator[](uint32_t i) const {\n  CHECK(isValid(i));\n  return table_[toInternal(i)];\n}\n\nbool HeaderTable::inReferenceSet(uint32_t index) const {\n  return refset_.find(toInternal(index)) != refset_.end();\n}\n\nbool HeaderTable::isSkippedReference(uint32_t index) const {\n  return skippedRefs_.find(toInternal(index)) != skippedRefs_.end();\n}\n\nvoid HeaderTable::clearSkippedReferences() {\n  skippedRefs_.clear();\n}\n\nvoid HeaderTable::addSkippedReference(uint32_t index) {\n  skippedRefs_.insert(toInternal(index));\n}\n\nvoid HeaderTable::addReference(uint32_t index) {\n  refset_.insert(toInternal(index));\n}\n\nvoid HeaderTable::removeReference(uint32_t index) {\n  refset_.erase(toInternal(index));\n}\n\nvoid HeaderTable::clearReferenceSet() {\n  refset_.clear();\n}\n\nlist<uint32_t> HeaderTable::referenceSet() const {\n  list<uint32_t> external;\n  for (auto& i : refset_) {\n    external.push_back(toExternal(i));\n  }\n  // seems like the compiler will avoid the copy here\n  return external;\n}\n\nvoid HeaderTable::removeLast() {\n  auto t = tail();\n  refset_.erase(t);\n  skippedRefs_.erase(t);\n  // remove the first element from the names index\n  auto names_it = names_.find(table_[t].name);\n  DCHECK(names_it != names_.end());\n  list<uint32_t> &ilist = names_it->second;\n  DCHECK(ilist.front() ==t);\n  ilist.pop_front();\n  // remove the name if there are no indices associated with it\n  if (ilist.empty()) {\n    names_.erase(names_it);\n  }\n  bytes_ -= table_[t].bytes();\n  --size_;\n}\n\nvoid HeaderTable::setCapacity(uint32_t capacity) {\n  auto oldCapacity = capacity_;\n  capacity_ = capacity;\n  if (capacity_ <= oldCapacity) {\n    evict(0);\n  } else {\n    auto oldTail = tail();\n    auto oldLength = table_.size();\n    uint32_t newLength = (capacity_ >> 5) + 1;\n    table_.resize(newLength);\n    if (size_ > 0 && oldTail > head_) {\n      // the list wrapped around, need to move oldTail..oldLength to the end of\n      // the now-larger table_\n      std::copy(table_.begin() + oldTail, table_.begin() + oldLength,\n                table_.begin() + newLength - (oldLength - oldTail));\n      // Update the names indecies that pointed to the old range\n      for (auto& names_it: names_) {\n        for (auto& idx: names_it.second) {\n          if (idx >= oldTail) {\n            DCHECK_LT(idx + (table_.size() - oldLength), table_.size());\n            idx += (table_.size() - oldLength);\n          } else {\n            // remaining indecies in the list were smaller than oldTail, so\n            // should be indexed from 0\n            break;\n          }\n        }\n      }\n    }\n  }\n}\n\nuint32_t HeaderTable::evict(uint32_t needed) {\n  uint32_t evicted = 0;\n  while (size_ > 0 && (bytes_ + needed > capacity_)) {\n    removeLast();\n    ++evicted;\n  }\n  return evicted;\n}\n\nbool HeaderTable::isValid(uint32_t index) const {\n  return 0 < index && index <= size_;\n}\n\nuint32_t HeaderTable::next(uint32_t i) const {\n  return (i + 1) % table_.size();\n}\n\nuint32_t HeaderTable::tail() const {\n  return (head_ + table_.size() - size_ + 1) % table_.size();\n}\n\nuint32_t HeaderTable::toExternal(uint32_t internalIndex) const {\n  return toExternal(head_, table_.size(), internalIndex);\n}\n\nuint32_t HeaderTable::toExternal(uint32_t head, uint32_t length,\n                                 uint32_t internalIndex) {\n  return ((head + length - internalIndex) % length) + 1;\n}\n\nuint32_t HeaderTable::toInternal(uint32_t externalIndex) const {\n  return toInternal(head_, table_.size(), externalIndex);\n}\n\nuint32_t HeaderTable::toInternal(uint32_t head, uint32_t length,\n                                 uint32_t externalIndex) {\n  // remove the offset\n  --externalIndex;\n  return (head + length - externalIndex) % length;\n}\n\nbool HeaderTable::operator==(const HeaderTable& other) const {\n  if (size() != other.size()) {\n    return false;\n  }\n  if (bytes() != other.bytes()) {\n    return false;\n  }\n  list<uint32_t> refset = referenceSet();\n  refset.sort();\n  list<uint32_t> otherRefset = other.referenceSet();\n  otherRefset.sort();\n  if (refset != otherRefset) {\n    return false;\n  }\n  return true;\n}\n\nstd::ostream& operator<<(std::ostream& os, const HeaderTable& table) {\n  os << std::endl;\n  for (size_t i = 1; i <= table.size(); i++) {\n    const HPACKHeader& h = table[i];\n    os << '[' << i << \"] (s=\" << h.bytes() << \") \"\n       << h.name << \": \" << h.value << std::endl;\n  }\n  os << \"reference set: [\";\n  for (const auto& index : table.referenceSet()) {\n    os << index << \", \";\n  }\n  os << \"]\" << std::endl;\n  os << \"total size: \" << table.bytes() << std::endl;\n  return os;\n}\n\n}\n", "/*\n *  Copyright (c) 2017, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <folly/portability/GTest.h>\n#include <memory>\n#include <proxygen/lib/http/codec/compress/HeaderTable.h>\n#include <proxygen/lib/http/codec/compress/Logging.h>\n#include <sstream>\n\nusing namespace std;\nusing namespace testing;\n\nnamespace proxygen {\n\nclass HeaderTableTests : public testing::Test {\n protected:\n  void xcheck(uint32_t internal, uint32_t external) {\n    EXPECT_EQ(HeaderTable::toExternal(head_, length_, internal), external);\n    EXPECT_EQ(HeaderTable::toInternal(head_, length_, external), internal);\n  }\n\n  uint32_t head_{0};\n  uint32_t length_{0};\n};\n\nTEST_F(HeaderTableTests, index_translation) {\n  // simple cases\n  length_ = 10;\n  head_ = 5;\n  xcheck(0, 6);\n  xcheck(3, 3);\n  xcheck(5, 1);\n\n  // wrap\n  head_ = 1;\n  xcheck(0, 2);\n  xcheck(8, 4);\n  xcheck(5, 7);\n}\n\nTEST_F(HeaderTableTests, add) {\n  HeaderTable table(4096);\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  EXPECT_EQ(table.names().size(), 1);\n  EXPECT_EQ(table.hasName(\"accept-encoding\"), true);\n  auto it = table.names().find(\"accept-encoding\");\n  EXPECT_EQ(it->second.size(), 3);\n  EXPECT_EQ(table.nameIndex(\"accept-encoding\"), 1);\n}\n\nTEST_F(HeaderTableTests, evict) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  HPACKHeader accept2(\"accept-encoding\", \"----\"); // same size, different header\n  HPACKHeader accept3(\"accept-encoding\", \"third\"); // size is larger with 1 byte\n  uint32_t max = 10;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n  // fill the table\n  for (size_t i = 0; i < max; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table.add(accept2), true);\n  // evict the first one\n  EXPECT_EQ(table[1], accept2);\n  auto ilist = table.names().find(\"accept-encoding\")->second;\n  EXPECT_EQ(ilist.size(), max);\n  // evict all the 'accept' headers\n  for (size_t i = 0; i < max - 1; i++) {\n    EXPECT_EQ(table.add(accept2), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table[max], accept2);\n  EXPECT_EQ(table.names().size(), 1);\n  // add an entry that will cause 2 evictions\n  EXPECT_EQ(table.add(accept3), true);\n  EXPECT_EQ(table[1], accept3);\n  EXPECT_EQ(table.size(), max - 1);\n\n  // add a super huge header\n  string bigvalue;\n  bigvalue.append(capacity, 'x');\n  HPACKHeader bigheader(\"user-agent\", bigvalue);\n  EXPECT_EQ(table.add(bigheader), false);\n  EXPECT_EQ(table.size(), 0);\n  EXPECT_EQ(table.names().size(), 0);\n}\n\nTEST_F(HeaderTableTests, set_capacity) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 10;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n\n  // fill the table\n  for (size_t i = 0; i < max; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  // change capacity\n  table.setCapacity(capacity / 2);\n  EXPECT_EQ(table.size(), max / 2);\n  EXPECT_EQ(table.bytes(), capacity / 2);\n}\n\nTEST_F(HeaderTableTests, comparison) {\n  uint32_t capacity = 128;\n  HeaderTable t1(capacity);\n  HeaderTable t2(capacity);\n\n  HPACKHeader h1(\"Content-Encoding\", \"gzip\");\n  HPACKHeader h2(\"Content-Encoding\", \"deflate\");\n  // different in number of elements\n  t1.add(h1);\n  EXPECT_FALSE(t1 == t2);\n  // different in size (bytes)\n  t2.add(h2);\n  EXPECT_FALSE(t1 == t2);\n\n  // make them the same\n  t1.add(h2);\n  t2.add(h1);\n  EXPECT_TRUE(t1 == t2);\n\n  // make them mismatch on refset\n  t1.addReference(1);\n  EXPECT_FALSE(t1 == t2);\n}\n\nTEST_F(HeaderTableTests, print) {\n  stringstream out;\n  HeaderTable t(128);\n  t.add(HPACKHeader(\"Accept-Encoding\", \"gzip\"));\n  t.addReference(1);\n  out << t;\n  EXPECT_EQ(out.str(),\n  \"\\n[1] (s=51) Accept-Encoding: gzip\\nreference set: [1, ]\\ntotal size: 51\\n\");\n}\n\nTEST_F(HeaderTableTests, increaseCapacity) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 4;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n  EXPECT_GT(table.length(), max);\n\n  // fill the table\n  for (size_t i = 0; i < table.length() + 1; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table.getIndex(accept), 4);\n  // head should be 0, tail should be 2\n  max = 8;\n  table.setCapacity(accept.bytes() * max);\n\n  EXPECT_GT(table.length(), max);\n  // external index didn't change\n  EXPECT_EQ(table.getIndex(accept), 4);\n\n}\n\n}\n"], "fixing_code": ["/*\n *  Copyright (c) 2017, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <proxygen/lib/http/codec/compress/HeaderTable.h>\n\n#include <glog/logging.h>\n\nusing std::list;\nusing std::pair;\nusing std::string;\n\nnamespace proxygen {\n\nvoid HeaderTable::init(uint32_t capacityVal) {\n  bytes_ = 0;\n  size_ = 0;\n  head_ = 0;\n  capacity_ = capacityVal;\n  // at a minimum an entry will take 32 bytes\n  uint32_t length = (capacityVal >> 5) + 1;\n  table_.assign(length, HPACKHeader());\n  names_.clear();\n}\n\nbool HeaderTable::add(const HPACKHeader& header) {\n  // handle size overflow\n  if (bytes_ + header.bytes() > capacity_) {\n    evict(header.bytes());\n  }\n  // this means the header entry is larger than our table\n  if (bytes_ + header.bytes() > capacity_) {\n    return false;\n  }\n  if (size_ > 0) {\n    head_ = next(head_);\n  }\n  table_[head_] = header;\n  // index name\n  names_[header.name].push_back(head_);\n  bytes_ += header.bytes();\n  ++size_;\n  return true;\n}\n\nuint32_t HeaderTable::getIndex(const HPACKHeader& header) const {\n  auto it = names_.find(header.name);\n  if (it == names_.end()) {\n    return 0;\n  }\n  for (auto i : it->second) {\n    if (table_[i].value == header.value) {\n      return toExternal(i);\n    }\n  }\n  return 0;\n}\n\nbool HeaderTable::hasName(const std::string& name) {\n  return names_.find(name) != names_.end();\n}\n\nuint32_t HeaderTable::nameIndex(const std::string& name) const {\n  auto it = names_.find(name);\n  if (it == names_.end()) {\n    return 0;\n  }\n  return toExternal(it->second.back());\n}\n\nconst HPACKHeader& HeaderTable::operator[](uint32_t i) const {\n  CHECK(isValid(i));\n  return table_[toInternal(i)];\n}\n\nbool HeaderTable::inReferenceSet(uint32_t index) const {\n  return refset_.find(toInternal(index)) != refset_.end();\n}\n\nbool HeaderTable::isSkippedReference(uint32_t index) const {\n  return skippedRefs_.find(toInternal(index)) != skippedRefs_.end();\n}\n\nvoid HeaderTable::clearSkippedReferences() {\n  skippedRefs_.clear();\n}\n\nvoid HeaderTable::addSkippedReference(uint32_t index) {\n  skippedRefs_.insert(toInternal(index));\n}\n\nvoid HeaderTable::addReference(uint32_t index) {\n  refset_.insert(toInternal(index));\n}\n\nvoid HeaderTable::removeReference(uint32_t index) {\n  refset_.erase(toInternal(index));\n}\n\nvoid HeaderTable::clearReferenceSet() {\n  refset_.clear();\n}\n\nlist<uint32_t> HeaderTable::referenceSet() const {\n  list<uint32_t> external;\n  for (auto& i : refset_) {\n    external.push_back(toExternal(i));\n  }\n  // seems like the compiler will avoid the copy here\n  return external;\n}\n\nvoid HeaderTable::removeLast() {\n  auto t = tail();\n  refset_.erase(t);\n  skippedRefs_.erase(t);\n  // remove the first element from the names index\n  auto names_it = names_.find(table_[t].name);\n  DCHECK(names_it != names_.end());\n  list<uint32_t> &ilist = names_it->second;\n  DCHECK(ilist.front() ==t);\n  ilist.pop_front();\n  // remove the name if there are no indices associated with it\n  if (ilist.empty()) {\n    names_.erase(names_it);\n  }\n  bytes_ -= table_[t].bytes();\n  --size_;\n}\n\nvoid HeaderTable::setCapacity(uint32_t capacity) {\n  // TODO: ddmello - the below is a little dangerous as we update the\n  // capacity right away.  Some properties of the class utilize that variable\n  // and so might be better to refactor and update capacity at the end of the\n  // method (and update other methods)\n  auto oldCapacity = capacity_;\n  capacity_ = capacity;\n  if (capacity_ == oldCapacity) {\n    return;\n  } else if (capacity_ < oldCapacity) {\n    // NOTE: currently no actual resizing is performed...\n    evict(0);\n  } else {\n    // NOTE: due to the above lack of resizing, we must determine whether a\n    // resize is actually appropriate (to handle cases where the underlying\n    // vector is still >= to the size related to the new capacity requested)\n    uint32_t newLength = (capacity_ >> 5) + 1;\n    if (newLength > table_.size()) {\n      auto oldTail = tail();\n      auto oldLength = table_.size();\n      table_.resize(newLength);\n      if (size_ > 0 && oldTail > head_) {\n        // the list wrapped around, need to move oldTail..oldLength to the end\n        // of the now-larger table_\n        std::copy(table_.begin() + oldTail, table_.begin() + oldLength,\n                  table_.begin() + newLength - (oldLength - oldTail));\n        // Update the names indecies that pointed to the old range\n        for (auto& names_it: names_) {\n          for (auto& idx: names_it.second) {\n            if (idx >= oldTail) {\n              DCHECK_LT(idx + (table_.size() - oldLength), table_.size());\n              idx += (table_.size() - oldLength);\n            } else {\n              // remaining indecies in the list were smaller than oldTail, so\n              // should be indexed from 0\n              break;\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\nuint32_t HeaderTable::evict(uint32_t needed) {\n  uint32_t evicted = 0;\n  while (size_ > 0 && (bytes_ + needed > capacity_)) {\n    removeLast();\n    ++evicted;\n  }\n  return evicted;\n}\n\nbool HeaderTable::isValid(uint32_t index) const {\n  return 0 < index && index <= size_;\n}\n\nuint32_t HeaderTable::next(uint32_t i) const {\n  return (i + 1) % table_.size();\n}\n\nuint32_t HeaderTable::tail() const {\n  return (head_ + table_.size() - size_ + 1) % table_.size();\n}\n\nuint32_t HeaderTable::toExternal(uint32_t internalIndex) const {\n  return toExternal(head_, table_.size(), internalIndex);\n}\n\nuint32_t HeaderTable::toExternal(uint32_t head, uint32_t length,\n                                 uint32_t internalIndex) {\n  return ((head + length - internalIndex) % length) + 1;\n}\n\nuint32_t HeaderTable::toInternal(uint32_t externalIndex) const {\n  return toInternal(head_, table_.size(), externalIndex);\n}\n\nuint32_t HeaderTable::toInternal(uint32_t head, uint32_t length,\n                                 uint32_t externalIndex) {\n  // remove the offset\n  --externalIndex;\n  return (head + length - externalIndex) % length;\n}\n\nbool HeaderTable::operator==(const HeaderTable& other) const {\n  if (size() != other.size()) {\n    return false;\n  }\n  if (bytes() != other.bytes()) {\n    return false;\n  }\n  list<uint32_t> refset = referenceSet();\n  refset.sort();\n  list<uint32_t> otherRefset = other.referenceSet();\n  otherRefset.sort();\n  if (refset != otherRefset) {\n    return false;\n  }\n  return true;\n}\n\nstd::ostream& operator<<(std::ostream& os, const HeaderTable& table) {\n  os << std::endl;\n  for (size_t i = 1; i <= table.size(); i++) {\n    const HPACKHeader& h = table[i];\n    os << '[' << i << \"] (s=\" << h.bytes() << \") \"\n       << h.name << \": \" << h.value << std::endl;\n  }\n  os << \"reference set: [\";\n  for (const auto& index : table.referenceSet()) {\n    os << index << \", \";\n  }\n  os << \"]\" << std::endl;\n  os << \"total size: \" << table.bytes() << std::endl;\n  return os;\n}\n\n}\n", "/*\n *  Copyright (c) 2017, Facebook, Inc.\n *  All rights reserved.\n *\n *  This source code is licensed under the BSD-style license found in the\n *  LICENSE file in the root directory of this source tree. An additional grant\n *  of patent rights can be found in the PATENTS file in the same directory.\n *\n */\n#include <folly/portability/GTest.h>\n#include <memory>\n#include <proxygen/lib/http/codec/compress/HeaderTable.h>\n#include <proxygen/lib/http/codec/compress/Logging.h>\n#include <sstream>\n\nusing namespace std;\nusing namespace testing;\n\nnamespace proxygen {\n\nclass HeaderTableTests : public testing::Test {\n protected:\n  void xcheck(uint32_t internal, uint32_t external) {\n    EXPECT_EQ(HeaderTable::toExternal(head_, length_, internal), external);\n    EXPECT_EQ(HeaderTable::toInternal(head_, length_, external), internal);\n  }\n\n  void resizeTable(HeaderTable& table, uint32_t newCapacity, uint32_t newMax) {\n    table.setCapacity(newCapacity);\n    // On resizing the table size (count of headers) remains the same or sizes\n    // down; can not size up\n    EXPECT_LE(table.size(), newMax);\n  }\n\n  void resizeAndFillTable(\n      HeaderTable& table, HPACKHeader& header, uint32_t newMax,\n      uint32_t fillCount) {\n    uint32_t newCapacity = header.bytes() * newMax;\n    resizeTable(table, newCapacity, newMax);\n    // Fill the table (with one extra) and make sure we haven't violated our\n    // size (bytes) limits (expected one entry to be evicted)\n    for (size_t i = 0; i <= fillCount; ++i) {\n      EXPECT_EQ(table.add(header), true);\n    }\n    EXPECT_EQ(table.size(), newMax);\n    EXPECT_EQ(table.bytes(), newCapacity);\n  }\n\n  uint32_t head_{0};\n  uint32_t length_{0};\n};\n\nTEST_F(HeaderTableTests, index_translation) {\n  // simple cases\n  length_ = 10;\n  head_ = 5;\n  xcheck(0, 6);\n  xcheck(3, 3);\n  xcheck(5, 1);\n\n  // wrap\n  head_ = 1;\n  xcheck(0, 2);\n  xcheck(8, 4);\n  xcheck(5, 7);\n}\n\nTEST_F(HeaderTableTests, add) {\n  HeaderTable table(4096);\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  table.add(HPACKHeader(\"accept-encoding\", \"gzip\"));\n  EXPECT_EQ(table.names().size(), 1);\n  EXPECT_EQ(table.hasName(\"accept-encoding\"), true);\n  auto it = table.names().find(\"accept-encoding\");\n  EXPECT_EQ(it->second.size(), 3);\n  EXPECT_EQ(table.nameIndex(\"accept-encoding\"), 1);\n}\n\nTEST_F(HeaderTableTests, evict) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  HPACKHeader accept2(\"accept-encoding\", \"----\"); // same size, different header\n  HPACKHeader accept3(\"accept-encoding\", \"third\"); // size is larger with 1 byte\n  uint32_t max = 10;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n  // fill the table\n  for (size_t i = 0; i < max; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table.add(accept2), true);\n  // evict the first one\n  EXPECT_EQ(table[1], accept2);\n  auto ilist = table.names().find(\"accept-encoding\")->second;\n  EXPECT_EQ(ilist.size(), max);\n  // evict all the 'accept' headers\n  for (size_t i = 0; i < max - 1; i++) {\n    EXPECT_EQ(table.add(accept2), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table[max], accept2);\n  EXPECT_EQ(table.names().size(), 1);\n  // add an entry that will cause 2 evictions\n  EXPECT_EQ(table.add(accept3), true);\n  EXPECT_EQ(table[1], accept3);\n  EXPECT_EQ(table.size(), max - 1);\n\n  // add a super huge header\n  string bigvalue;\n  bigvalue.append(capacity, 'x');\n  HPACKHeader bigheader(\"user-agent\", bigvalue);\n  EXPECT_EQ(table.add(bigheader), false);\n  EXPECT_EQ(table.size(), 0);\n  EXPECT_EQ(table.names().size(), 0);\n}\n\nTEST_F(HeaderTableTests, reduce_capacity) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 10;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n  EXPECT_GT(table.length(), max);\n\n  // fill the table\n  for (size_t i = 0; i < max; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  // change capacity\n  table.setCapacity(capacity / 2);\n  EXPECT_EQ(table.size(), max / 2);\n  EXPECT_EQ(table.bytes(), capacity / 2);\n}\n\nTEST_F(HeaderTableTests, comparison) {\n  uint32_t capacity = 128;\n  HeaderTable t1(capacity);\n  HeaderTable t2(capacity);\n\n  HPACKHeader h1(\"Content-Encoding\", \"gzip\");\n  HPACKHeader h2(\"Content-Encoding\", \"deflate\");\n  // different in number of elements\n  t1.add(h1);\n  EXPECT_FALSE(t1 == t2);\n  // different in size (bytes)\n  t2.add(h2);\n  EXPECT_FALSE(t1 == t2);\n\n  // make them the same\n  t1.add(h2);\n  t2.add(h1);\n  EXPECT_TRUE(t1 == t2);\n\n  // make them mismatch on refset\n  t1.addReference(1);\n  EXPECT_FALSE(t1 == t2);\n}\n\nTEST_F(HeaderTableTests, print) {\n  stringstream out;\n  HeaderTable t(128);\n  t.add(HPACKHeader(\"Accept-Encoding\", \"gzip\"));\n  t.addReference(1);\n  out << t;\n  EXPECT_EQ(out.str(),\n  \"\\n[1] (s=51) Accept-Encoding: gzip\\nreference set: [1, ]\\ntotal size: 51\\n\");\n}\n\nTEST_F(HeaderTableTests, increaseCapacity) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 4;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n  EXPECT_GT(table.length(), max);\n\n  // fill the table\n  for (size_t i = 0; i < table.length() + 1; i++) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table.getIndex(accept), 4);\n  // head should be 0, tail should be 2\n  max = 8;\n  table.setCapacity(accept.bytes() * max);\n\n  EXPECT_GT(table.length(), max);\n  // external index didn't change\n  EXPECT_EQ(table.getIndex(accept), 4);\n\n}\n\nTEST_F(HeaderTableTests, varyCapacity) {\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 6;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n\n  // Fill the table (extra) and make sure we haven't violated our\n  // size (bytes) limits (expected one entry to be evicted)\n  for (size_t i = 0; i <= table.length(); ++i) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n\n  // Size down the table and verify we are still honoring our size (bytes)\n  // limits\n  resizeAndFillTable(table, accept, 4, 5);\n\n  // Size up the table (in between previous max and min within test) and verify\n  // we are still horing our size (bytes) limits\n  resizeAndFillTable(table, accept, 5, 6);\n\n  // Finally reize up one last timestamps\n  resizeAndFillTable(table, accept, 8, 9);\n}\n\nTEST_F(HeaderTableTests, varyCapacityMalignHeadIndex) {\n  // Test checks for a previous bug/crash condition where due to resizing\n  // the underlying table to a size lower than a previous max but up from the\n  // current size and the position of the head_ index an out of bounds index\n  // would occur\n\n  // Initialize header table\n  HPACKHeader accept(\"accept-encoding\", \"gzip\");\n  uint32_t max = 6;\n  uint32_t capacity = accept.bytes() * max;\n  HeaderTable table(capacity);\n\n  // Push head_ to last index in underlying table before potential wrap\n  // This is our max table size for the duration of the test\n  for (size_t i = 0; i < table.length(); ++i) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n  EXPECT_EQ(table.bytes(), capacity);\n\n  // Flush underlying table (head_ remains the same at the previous max index)\n  // Header guranteed to cause a flush as header itself requires 32 bytes plus\n  // the sizes of the name and value anyways (which themselves would cause a\n  // flush)\n  string strLargerThanTableCapacity = string(capacity + 1, 'a');\n  HPACKHeader flush(\"flush\", strLargerThanTableCapacity);\n  EXPECT_EQ(table.add(flush), false);\n  EXPECT_EQ(table.size(), 0);\n\n  // Now reduce capacity of table (in functional terms table.size() is lowered\n  // but currently table.length() remains the same)\n  max = 3;\n  resizeTable(table, accept.bytes() * max, max);\n\n  // Increase capacity of table (but smaller than all time max; head_ still at\n  // previous max index).  Previously (now fixed) this size up resulted in\n  // incorrect resizing semantics\n  max = 4;\n  resizeTable(table, accept.bytes() * max, max);\n\n  // Now try and add headers; there should be no crash with current position of\n  // head_ in the underlying table.  Note this is merely one possible way we\n  // could force the test to crash as a result of the resize bug this test was\n  // added for\n  for (size_t i = 0; i <= table.length(); ++i) {\n    EXPECT_EQ(table.add(accept), true);\n  }\n  EXPECT_EQ(table.size(), max);\n}\n\n}\n"], "buggy_code_start_loc": [136, 27], "buggy_code_end_loc": [161, 171], "fixing_code_start_loc": [137, 28], "fixing_code_end_loc": [173, 268], "type": "CWE-416", "message": "In the course of decompressing HPACK inside the HTTP2 protocol, an unexpected sequence of header table resize operations can place the header table into a corrupted state, leading to a use-after-free condition and undefined behavior. This issue affects Proxygen from v0.29.0 until v2017.04.03.00.", "other": {"cve": {"id": "CVE-2019-11940", "sourceIdentifier": "cve-assign@fb.com", "published": "2019-12-04T17:16:43.773", "lastModified": "2019-12-17T20:18:50.240", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In the course of decompressing HPACK inside the HTTP2 protocol, an unexpected sequence of header table resize operations can place the header table into a corrupted state, leading to a use-after-free condition and undefined behavior. This issue affects Proxygen from v0.29.0 until v2017.04.03.00."}, {"lang": "es", "value": "En el curso de una descompresi\u00f3n HPACK dentro del protocolo HTTP2, una secuencia no prevista de operaciones de cambio de tama\u00f1o de la tabla de encabezado puede colocar la tabla de encabezado en un estado corrupto, lo que conlleva a una condici\u00f3n de uso de la memoria previamente liberada y un comportamiento no definido. Este problema afecta a Proxygen desde la versi\u00f3n v0.29.0 hasta v2017.04.03.00."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}, {"source": "cve-assign@fb.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:facebook:proxygen:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.29.0", "versionEndIncluding": "2017.04.03.00", "matchCriteriaId": "79F3A695-DEBF-4C2B-B8EB-1BFB2874FDD5"}]}]}], "references": [{"url": "https://github.com/facebook/proxygen/commit/f43b134cc5c19d8532e7fb670a1c02e85f7a8d4f", "source": "cve-assign@fb.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://www.facebook.com/security/advisories/cve-2019-11940", "source": "cve-assign@fb.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/facebook/proxygen/commit/f43b134cc5c19d8532e7fb670a1c02e85f7a8d4f"}}