{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * net/tipc/crypto.c: TIPC crypto for key handling & packet en/decryption\n *\n * Copyright (c) 2019, Ericsson AB\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the names of the copyright holders nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * Alternatively, this software may be distributed under the terms of the\n * GNU General Public License (\"GPL\") version 2 as published by the Free\n * Software Foundation.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <crypto/aead.h>\n#include <crypto/aes.h>\n#include <crypto/rng.h>\n#include \"crypto.h\"\n#include \"msg.h\"\n#include \"bcast.h\"\n\n#define TIPC_TX_GRACE_PERIOD\tmsecs_to_jiffies(5000) /* 5s */\n#define TIPC_TX_LASTING_TIME\tmsecs_to_jiffies(10000) /* 10s */\n#define TIPC_RX_ACTIVE_LIM\tmsecs_to_jiffies(3000) /* 3s */\n#define TIPC_RX_PASSIVE_LIM\tmsecs_to_jiffies(15000) /* 15s */\n\n#define TIPC_MAX_TFMS_DEF\t10\n#define TIPC_MAX_TFMS_LIM\t1000\n\n#define TIPC_REKEYING_INTV_DEF\t(60 * 24) /* default: 1 day */\n\n/*\n * TIPC Key ids\n */\nenum {\n\tKEY_MASTER = 0,\n\tKEY_MIN = KEY_MASTER,\n\tKEY_1 = 1,\n\tKEY_2,\n\tKEY_3,\n\tKEY_MAX = KEY_3,\n};\n\n/*\n * TIPC Crypto statistics\n */\nenum {\n\tSTAT_OK,\n\tSTAT_NOK,\n\tSTAT_ASYNC,\n\tSTAT_ASYNC_OK,\n\tSTAT_ASYNC_NOK,\n\tSTAT_BADKEYS, /* tx only */\n\tSTAT_BADMSGS = STAT_BADKEYS, /* rx only */\n\tSTAT_NOKEYS,\n\tSTAT_SWITCHES,\n\n\tMAX_STATS,\n};\n\n/* TIPC crypto statistics' header */\nstatic const char *hstats[MAX_STATS] = {\"ok\", \"nok\", \"async\", \"async_ok\",\n\t\t\t\t\t\"async_nok\", \"badmsgs\", \"nokeys\",\n\t\t\t\t\t\"switches\"};\n\n/* Max TFMs number per key */\nint sysctl_tipc_max_tfms __read_mostly = TIPC_MAX_TFMS_DEF;\n/* Key exchange switch, default: on */\nint sysctl_tipc_key_exchange_enabled __read_mostly = 1;\n\n/*\n * struct tipc_key - TIPC keys' status indicator\n *\n *         7     6     5     4     3     2     1     0\n *      +-----+-----+-----+-----+-----+-----+-----+-----+\n * key: | (reserved)|passive idx| active idx|pending idx|\n *      +-----+-----+-----+-----+-----+-----+-----+-----+\n */\nstruct tipc_key {\n#define KEY_BITS (2)\n#define KEY_MASK ((1 << KEY_BITS) - 1)\n\tunion {\n\t\tstruct {\n#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t\tu8 pending:2,\n\t\t\t   active:2,\n\t\t\t   passive:2, /* rx only */\n\t\t\t   reserved:2;\n#elif defined(__BIG_ENDIAN_BITFIELD)\n\t\t\tu8 reserved:2,\n\t\t\t   passive:2, /* rx only */\n\t\t\t   active:2,\n\t\t\t   pending:2;\n#else\n#error  \"Please fix <asm/byteorder.h>\"\n#endif\n\t\t} __packed;\n\t\tu8 keys;\n\t};\n};\n\n/**\n * struct tipc_tfm - TIPC TFM structure to form a list of TFMs\n * @tfm: cipher handle/key\n * @list: linked list of TFMs\n */\nstruct tipc_tfm {\n\tstruct crypto_aead *tfm;\n\tstruct list_head list;\n};\n\n/**\n * struct tipc_aead - TIPC AEAD key structure\n * @tfm_entry: per-cpu pointer to one entry in TFM list\n * @crypto: TIPC crypto owns this key\n * @cloned: reference to the source key in case cloning\n * @users: the number of the key users (TX/RX)\n * @salt: the key's SALT value\n * @authsize: authentication tag size (max = 16)\n * @mode: crypto mode is applied to the key\n * @hint: a hint for user key\n * @rcu: struct rcu_head\n * @key: the aead key\n * @gen: the key's generation\n * @seqno: the key seqno (cluster scope)\n * @refcnt: the key reference counter\n */\nstruct tipc_aead {\n#define TIPC_AEAD_HINT_LEN (5)\n\tstruct tipc_tfm * __percpu *tfm_entry;\n\tstruct tipc_crypto *crypto;\n\tstruct tipc_aead *cloned;\n\tatomic_t users;\n\tu32 salt;\n\tu8 authsize;\n\tu8 mode;\n\tchar hint[2 * TIPC_AEAD_HINT_LEN + 1];\n\tstruct rcu_head rcu;\n\tstruct tipc_aead_key *key;\n\tu16 gen;\n\n\tatomic64_t seqno ____cacheline_aligned;\n\trefcount_t refcnt ____cacheline_aligned;\n\n} ____cacheline_aligned;\n\n/**\n * struct tipc_crypto_stats - TIPC Crypto statistics\n * @stat: array of crypto statistics\n */\nstruct tipc_crypto_stats {\n\tunsigned int stat[MAX_STATS];\n};\n\n/**\n * struct tipc_crypto - TIPC TX/RX crypto structure\n * @net: struct net\n * @node: TIPC node (RX)\n * @aead: array of pointers to AEAD keys for encryption/decryption\n * @peer_rx_active: replicated peer RX active key index\n * @key_gen: TX/RX key generation\n * @key: the key states\n * @skey_mode: session key's mode\n * @skey: received session key\n * @wq: common workqueue on TX crypto\n * @work: delayed work sched for TX/RX\n * @key_distr: key distributing state\n * @rekeying_intv: rekeying interval (in minutes)\n * @stats: the crypto statistics\n * @name: the crypto name\n * @sndnxt: the per-peer sndnxt (TX)\n * @timer1: general timer 1 (jiffies)\n * @timer2: general timer 2 (jiffies)\n * @working: the crypto is working or not\n * @key_master: flag indicates if master key exists\n * @legacy_user: flag indicates if a peer joins w/o master key (for bwd comp.)\n * @nokey: no key indication\n * @flags: combined flags field\n * @lock: tipc_key lock\n */\nstruct tipc_crypto {\n\tstruct net *net;\n\tstruct tipc_node *node;\n\tstruct tipc_aead __rcu *aead[KEY_MAX + 1];\n\tatomic_t peer_rx_active;\n\tu16 key_gen;\n\tstruct tipc_key key;\n\tu8 skey_mode;\n\tstruct tipc_aead_key *skey;\n\tstruct workqueue_struct *wq;\n\tstruct delayed_work work;\n#define KEY_DISTR_SCHED\t\t1\n#define KEY_DISTR_COMPL\t\t2\n\tatomic_t key_distr;\n\tu32 rekeying_intv;\n\n\tstruct tipc_crypto_stats __percpu *stats;\n\tchar name[48];\n\n\tatomic64_t sndnxt ____cacheline_aligned;\n\tunsigned long timer1;\n\tunsigned long timer2;\n\tunion {\n\t\tstruct {\n\t\t\tu8 working:1;\n\t\t\tu8 key_master:1;\n\t\t\tu8 legacy_user:1;\n\t\t\tu8 nokey: 1;\n\t\t};\n\t\tu8 flags;\n\t};\n\tspinlock_t lock; /* crypto lock */\n\n} ____cacheline_aligned;\n\n/* struct tipc_crypto_tx_ctx - TX context for callbacks */\nstruct tipc_crypto_tx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n\tstruct tipc_media_addr dst;\n};\n\n/* struct tipc_crypto_rx_ctx - RX context for callbacks */\nstruct tipc_crypto_rx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n};\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead);\nstatic inline void tipc_aead_put(struct tipc_aead *aead);\nstatic void tipc_aead_free(struct rcu_head *rp);\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead);\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val);\nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead);\nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode);\nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src);\nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg);\nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode);\nstatic void tipc_aead_encrypt_done(struct crypto_async_request *base, int err);\nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b);\nstatic void tipc_aead_decrypt_done(struct crypto_async_request *base, int err);\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr);\nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx);\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending);\nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key);\nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending);\nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key);\nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb);\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key);\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type);\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err);\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd);\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf);\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf);\nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode);\nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr);\nstatic void tipc_crypto_work_tx(struct work_struct *work);\nstatic void tipc_crypto_work_rx(struct work_struct *work);\nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey);\n\n#define is_tx(crypto) (!(crypto)->node)\n#define is_rx(crypto) (!is_tx(crypto))\n\n#define key_next(cur) ((cur) % KEY_MAX + 1)\n\n#define tipc_aead_rcu_ptr(rcu_ptr, lock)\t\t\t\t\\\n\trcu_dereference_protected((rcu_ptr), lockdep_is_held(lock))\n\n#define tipc_aead_rcu_replace(rcu_ptr, ptr, lock)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstruct tipc_aead *__tmp = rcu_dereference_protected((rcu_ptr),\t\\\n\t\t\t\t\t\tlockdep_is_held(lock));\t\\\n\trcu_assign_pointer((rcu_ptr), (ptr));\t\t\t\t\\\n\ttipc_aead_put(__tmp);\t\t\t\t\t\t\\\n} while (0)\n\n#define tipc_crypto_key_detach(rcu_ptr, lock)\t\t\t\t\\\n\ttipc_aead_rcu_replace((rcu_ptr), NULL, lock)\n\n/**\n * tipc_aead_key_validate - Validate a AEAD user key\n * @ukey: pointer to user key data\n * @info: netlink info pointer\n */\nint tipc_aead_key_validate(struct tipc_aead_key *ukey, struct genl_info *info)\n{\n\tint keylen;\n\n\t/* Check if algorithm exists */\n\tif (unlikely(!crypto_has_alg(ukey->alg_name, 0, 0))) {\n\t\tGENL_SET_ERR_MSG(info, \"unable to load the algorithm (module existed?)\");\n\t\treturn -ENODEV;\n\t}\n\n\t/* Currently, we only support the \"gcm(aes)\" cipher algorithm */\n\tif (strcmp(ukey->alg_name, \"gcm(aes)\")) {\n\t\tGENL_SET_ERR_MSG(info, \"not supported yet the algorithm\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\t/* Check if key size is correct */\n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\tif (unlikely(keylen != TIPC_AES_GCM_KEY_SIZE_128 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_192 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_256)) {\n\t\tGENL_SET_ERR_MSG(info, \"incorrect key length (20, 28 or 36 octets?)\");\n\t\treturn -EKEYREJECTED;\n\t}\n\n\treturn 0;\n}\n\n/**\n * tipc_aead_key_generate - Generate new session key\n * @skey: input/output key with new content\n *\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey)\n{\n\tint rc = 0;\n\n\t/* Fill the key's content with a random value via RNG cipher */\n\trc = crypto_get_default_rng();\n\tif (likely(!rc)) {\n\t\trc = crypto_rng_get_bytes(crypto_default_rng, skey->key,\n\t\t\t\t\t  skey->keylen);\n\t\tcrypto_put_default_rng();\n\t}\n\n\treturn rc;\n}\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (unlikely(!tmp || !refcount_inc_not_zero(&tmp->refcnt)))\n\t\ttmp = NULL;\n\trcu_read_unlock();\n\n\treturn tmp;\n}\n\nstatic inline void tipc_aead_put(struct tipc_aead *aead)\n{\n\tif (aead && refcount_dec_and_test(&aead->refcnt))\n\t\tcall_rcu(&aead->rcu, tipc_aead_free);\n}\n\n/**\n * tipc_aead_free - Release AEAD key incl. all the TFMs in the list\n * @rp: rcu head pointer\n */\nstatic void tipc_aead_free(struct rcu_head *rp)\n{\n\tstruct tipc_aead *aead = container_of(rp, struct tipc_aead, rcu);\n\tstruct tipc_tfm *tfm_entry, *head, *tmp;\n\n\tif (aead->cloned) {\n\t\ttipc_aead_put(aead->cloned);\n\t} else {\n\t\thead = *get_cpu_ptr(aead->tfm_entry);\n\t\tput_cpu_ptr(aead->tfm_entry);\n\t\tlist_for_each_entry_safe(tfm_entry, tmp, &head->list, list) {\n\t\t\tcrypto_free_aead(tfm_entry->tfm);\n\t\t\tlist_del(&tfm_entry->list);\n\t\t\tkfree(tfm_entry);\n\t\t}\n\t\t/* Free the head */\n\t\tcrypto_free_aead(head->tfm);\n\t\tlist_del(&head->list);\n\t\tkfree(head);\n\t}\n\tfree_percpu(aead->tfm_entry);\n\tkfree_sensitive(aead->key);\n\tkfree(aead);\n}\n\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\tint users = 0;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tusers = atomic_read(&tmp->users);\n\trcu_read_unlock();\n\n\treturn users;\n}\n\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&tmp->users, 1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&rcu_dereference(aead)->users, -1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val)\n{\n\tstruct tipc_aead *tmp;\n\tint cur;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp) {\n\t\tdo {\n\t\t\tcur = atomic_read(&tmp->users);\n\t\t\tif (cur == val)\n\t\t\t\tbreak;\n\t\t} while (atomic_cmpxchg(&tmp->users, cur, val) != cur);\n\t}\n\trcu_read_unlock();\n}\n\n/**\n * tipc_aead_tfm_next - Move TFM entry to the next one in list and return it\n * @aead: the AEAD key pointer\n */\nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead)\n{\n\tstruct tipc_tfm **tfm_entry;\n\tstruct crypto_aead *tfm;\n\n\ttfm_entry = get_cpu_ptr(aead->tfm_entry);\n\t*tfm_entry = list_next_entry(*tfm_entry, list);\n\ttfm = (*tfm_entry)->tfm;\n\tput_cpu_ptr(tfm_entry);\n\n\treturn tfm;\n}\n\n/**\n * tipc_aead_init - Initiate TIPC AEAD\n * @aead: returned new TIPC AEAD key handle pointer\n * @ukey: pointer to user key data\n * @mode: the key mode\n *\n * Allocate a (list of) new cipher transformation (TFM) with the specific user\n * key data if valid. The number of the allocated TFMs can be set via the sysfs\n * \"net/tipc/max_tfms\" first.\n * Also, all the other AEAD data are also initialized.\n *\n * Return: 0 if the initiation is successful, otherwise: < 0\n */\nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode)\n{\n\tstruct tipc_tfm *tfm_entry, *head;\n\tstruct crypto_aead *tfm;\n\tstruct tipc_aead *tmp;\n\tint keylen, err, cpu;\n\tint tfm_cnt = 0;\n\n\tif (unlikely(*aead))\n\t\treturn -EEXIST;\n\n\t/* Allocate a new AEAD */\n\ttmp = kzalloc(sizeof(*tmp), GFP_ATOMIC);\n\tif (unlikely(!tmp))\n\t\treturn -ENOMEM;\n\n\t/* The key consists of two parts: [AES-KEY][SALT] */\n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\n\t/* Allocate per-cpu TFM entry pointer */\n\ttmp->tfm_entry = alloc_percpu(struct tipc_tfm *);\n\tif (!tmp->tfm_entry) {\n\t\tkfree_sensitive(tmp);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Make a list of TFMs with the user key data */\n\tdo {\n\t\ttfm = crypto_alloc_aead(ukey->alg_name, 0, 0);\n\t\tif (IS_ERR(tfm)) {\n\t\t\terr = PTR_ERR(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(!tfm_cnt &&\n\t\t\t     crypto_aead_ivsize(tfm) != TIPC_AES_GCM_IV_SIZE)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = crypto_aead_setauthsize(tfm, TIPC_AES_GCM_TAG_SIZE);\n\t\terr |= crypto_aead_setkey(tfm, ukey->key, keylen);\n\t\tif (unlikely(err)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\ttfm_entry = kmalloc(sizeof(*tfm_entry), GFP_KERNEL);\n\t\tif (unlikely(!tfm_entry)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tINIT_LIST_HEAD(&tfm_entry->list);\n\t\ttfm_entry->tfm = tfm;\n\n\t\t/* First entry? */\n\t\tif (!tfm_cnt) {\n\t\t\thead = tfm_entry;\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t*per_cpu_ptr(tmp->tfm_entry, cpu) = head;\n\t\t\t}\n\t\t} else {\n\t\t\tlist_add_tail(&tfm_entry->list, &head->list);\n\t\t}\n\n\t} while (++tfm_cnt < sysctl_tipc_max_tfms);\n\n\t/* Not any TFM is allocated? */\n\tif (!tfm_cnt) {\n\t\tfree_percpu(tmp->tfm_entry);\n\t\tkfree_sensitive(tmp);\n\t\treturn err;\n\t}\n\n\t/* Form a hex string of some last bytes as the key's hint */\n\tbin2hex(tmp->hint, ukey->key + keylen - TIPC_AEAD_HINT_LEN,\n\t\tTIPC_AEAD_HINT_LEN);\n\n\t/* Initialize the other data */\n\ttmp->mode = mode;\n\ttmp->cloned = NULL;\n\ttmp->authsize = TIPC_AES_GCM_TAG_SIZE;\n\ttmp->key = kmemdup(ukey, tipc_aead_key_size(ukey), GFP_KERNEL);\n\tmemcpy(&tmp->salt, ukey->key + keylen, TIPC_AES_GCM_SALT_SIZE);\n\tatomic_set(&tmp->users, 0);\n\tatomic64_set(&tmp->seqno, 0);\n\trefcount_set(&tmp->refcnt, 1);\n\n\t*aead = tmp;\n\treturn 0;\n}\n\n/**\n * tipc_aead_clone - Clone a TIPC AEAD key\n * @dst: dest key for the cloning\n * @src: source key to clone from\n *\n * Make a \"copy\" of the source AEAD key data to the dest, the TFMs list is\n * common for the keys.\n * A reference to the source is hold in the \"cloned\" pointer for the later\n * freeing purposes.\n *\n * Note: this must be done in cluster-key mode only!\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src)\n{\n\tstruct tipc_aead *aead;\n\tint cpu;\n\n\tif (!src)\n\t\treturn -ENOKEY;\n\n\tif (src->mode != CLUSTER_KEY)\n\t\treturn -EINVAL;\n\n\tif (unlikely(*dst))\n\t\treturn -EEXIST;\n\n\taead = kzalloc(sizeof(*aead), GFP_ATOMIC);\n\tif (unlikely(!aead))\n\t\treturn -ENOMEM;\n\n\taead->tfm_entry = alloc_percpu_gfp(struct tipc_tfm *, GFP_ATOMIC);\n\tif (unlikely(!aead->tfm_entry)) {\n\t\tkfree_sensitive(aead);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\t*per_cpu_ptr(aead->tfm_entry, cpu) =\n\t\t\t\t*per_cpu_ptr(src->tfm_entry, cpu);\n\t}\n\n\tmemcpy(aead->hint, src->hint, sizeof(src->hint));\n\taead->mode = src->mode;\n\taead->salt = src->salt;\n\taead->authsize = src->authsize;\n\tatomic_set(&aead->users, 0);\n\tatomic64_set(&aead->seqno, 0);\n\trefcount_set(&aead->refcnt, 1);\n\n\tWARN_ON(!refcount_inc_not_zero(&src->refcnt));\n\taead->cloned = src;\n\n\t*dst = aead;\n\treturn 0;\n}\n\n/**\n * tipc_aead_mem_alloc - Allocate memory for AEAD request operations\n * @tfm: cipher handle to be registered with the request\n * @crypto_ctx_size: size of crypto context for callback\n * @iv: returned pointer to IV data\n * @req: returned pointer to AEAD request data\n * @sg: returned pointer to SG lists\n * @nsg: number of SG lists to be allocated\n *\n * Allocate memory to store the crypto context data, AEAD request, IV and SG\n * lists, the memory layout is as follows:\n * crypto_ctx || iv || aead_req || sg[]\n *\n * Return: the pointer to the memory areas in case of success, otherwise NULL\n */\nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg)\n{\n\tunsigned int iv_size, req_size;\n\tunsigned int len;\n\tu8 *mem;\n\n\tiv_size = crypto_aead_ivsize(tfm);\n\treq_size = sizeof(**req) + crypto_aead_reqsize(tfm);\n\n\tlen = crypto_ctx_size;\n\tlen += iv_size;\n\tlen += crypto_aead_alignmask(tfm) & ~(crypto_tfm_ctx_alignment() - 1);\n\tlen = ALIGN(len, crypto_tfm_ctx_alignment());\n\tlen += req_size;\n\tlen = ALIGN(len, __alignof__(struct scatterlist));\n\tlen += nsg * sizeof(**sg);\n\n\tmem = kmalloc(len, GFP_ATOMIC);\n\tif (!mem)\n\t\treturn NULL;\n\n\t*iv = (u8 *)PTR_ALIGN(mem + crypto_ctx_size,\n\t\t\t      crypto_aead_alignmask(tfm) + 1);\n\t*req = (struct aead_request *)PTR_ALIGN(*iv + iv_size,\n\t\t\t\t\t\tcrypto_tfm_ctx_alignment());\n\t*sg = (struct scatterlist *)PTR_ALIGN((u8 *)*req + req_size,\n\t\t\t\t\t      __alignof__(struct scatterlist));\n\n\treturn (void *)mem;\n}\n\n/**\n * tipc_aead_encrypt - Encrypt a message\n * @aead: TIPC AEAD key for the message encryption\n * @skb: the input/output skb\n * @b: TIPC bearer where the message will be delivered after the encryption\n * @dst: the destination media address\n * @__dnode: TIPC dest node if \"known\"\n *\n * Return:\n * * 0                   : if the encryption has completed\n * * -EINPROGRESS/-EBUSY : if a callback will be performed\n * * < 0                 : the encryption has failed\n */\nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode)\n{\n\tstruct crypto_aead *tfm = tipc_aead_tfm_next(aead);\n\tstruct tipc_crypto_tx_ctx *tx_ctx;\n\tstruct aead_request *req;\n\tstruct sk_buff *trailer;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, len, tailen, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\t/* Make sure message len at least 4-byte aligned */\n\tlen = ALIGN(skb->len, 4);\n\ttailen = len - skb->len + aead->authsize;\n\n\t/* Expand skb tail for authentication tag:\n\t * As for simplicity, we'd have made sure skb having enough tailroom\n\t * for authentication tag @skb allocation. Even when skb is nonlinear\n\t * but there is no frag_list, it should be still fine!\n\t * Otherwise, we must cow it to be a writable buffer with the tailroom.\n\t */\n\tSKB_LINEAR_ASSERT(skb);\n\tif (tailen > skb_tailroom(skb)) {\n\t\tpr_debug(\"TX(): skb tailroom is not enough: %d, requires: %d\\n\",\n\t\t\t skb_tailroom(skb), tailen);\n\t}\n\n\tif (unlikely(!skb_cloned(skb) && tailen <= skb_tailroom(skb))) {\n\t\tnsg = 1;\n\t\ttrailer = skb;\n\t} else {\n\t\t/* TODO: We could avoid skb_cow_data() if skb has no frag_list\n\t\t * e.g. by skb_fill_page_desc() to add another page to the skb\n\t\t * with the wanted tailen... However, page skbs look not often,\n\t\t * so take it easy now!\n\t\t * Cloned skbs e.g. from link_xmit() seems no choice though :(\n\t\t */\n\t\tnsg = skb_cow_data(skb, tailen, &trailer);\n\t\tif (unlikely(nsg < 0)) {\n\t\t\tpr_err(\"TX: skb_cow_data() returned %d\\n\", nsg);\n\t\t\treturn nsg;\n\t\t}\n\t}\n\n\tpskb_put(skb, trailer, tailen);\n\n\t/* Allocate memory for the AEAD operation */\n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*tx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t/* Map skb to the sg lists */\n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"TX: skb_to_sgvec() returned %d, nsg %d!\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t/* Prepare IV: [SALT (4 octets)][SEQNO (8 octets)]\n\t * In case we're in cluster-key mode, SALT is varied by xor-ing with\n\t * the source address (or w0 of id), otherwise with the dest address\n\t * if dest is known.\n\t */\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (__dnode)\n\t\tsalt ^= tipc_node_get_addr(__dnode);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t/* Prepare request */\n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, len - ehsz, iv);\n\n\t/* Set callback function & data */\n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_encrypt_done, skb);\n\ttx_ctx = (struct tipc_crypto_tx_ctx *)ctx;\n\ttx_ctx->aead = aead;\n\ttx_ctx->bearer = b;\n\tmemcpy(&tx_ctx->dst, dst, sizeof(*dst));\n\n\t/* Hold bearer */\n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t/* Now, do encrypt */\n\trc = crypto_aead_encrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_encrypt_done(struct crypto_async_request *base, int err)\n{\n\tstruct sk_buff *skb = base->data;\n\tstruct tipc_crypto_tx_ctx *tx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = tx_ctx->bearer;\n\tstruct tipc_aead *aead = tx_ctx->aead;\n\tstruct tipc_crypto *tx = aead->crypto;\n\tstruct net *net = tx->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_OK]);\n\t\trcu_read_lock();\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\tb->media->send_msg(net, skb, b, &tx_ctx->dst);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t\trcu_read_unlock();\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_NOK]);\n\t\tkfree_skb(skb);\n\t\tbreak;\n\t}\n\n\tkfree(tx_ctx);\n\ttipc_bearer_put(b);\n\ttipc_aead_put(aead);\n}\n\n/**\n * tipc_aead_decrypt - Decrypt an encrypted message\n * @net: struct net\n * @aead: TIPC AEAD for the message decryption\n * @skb: the input/output skb\n * @b: TIPC bearer where the message has been received\n *\n * Return:\n * * 0                   : if the decryption has completed\n * * -EINPROGRESS/-EBUSY : if a callback will be performed\n * * < 0                 : the decryption has failed\n */\nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto_rx_ctx *rx_ctx;\n\tstruct aead_request *req;\n\tstruct crypto_aead *tfm;\n\tstruct sk_buff *unused;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\tif (unlikely(!aead))\n\t\treturn -ENOKEY;\n\n\tnsg = skb_cow_data(skb, 0, &unused);\n\tif (unlikely(nsg < 0)) {\n\t\tpr_err(\"RX: skb_cow_data() returned %d\\n\", nsg);\n\t\treturn nsg;\n\t}\n\n\t/* Allocate memory for the AEAD operation */\n\ttfm = tipc_aead_tfm_next(aead);\n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*rx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t/* Map skb to the sg lists */\n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"RX: skb_to_sgvec() returned %d, nsg %d\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t/* Reconstruct IV: */\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (ehdr->destined)\n\t\tsalt ^= tipc_own_addr(net);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t/* Prepare request */\n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, skb->len - ehsz, iv);\n\n\t/* Set callback function & data */\n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_decrypt_done, skb);\n\trx_ctx = (struct tipc_crypto_rx_ctx *)ctx;\n\trx_ctx->aead = aead;\n\trx_ctx->bearer = b;\n\n\t/* Hold bearer */\n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t/* Now, do decrypt */\n\trc = crypto_aead_decrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_decrypt_done(struct crypto_async_request *base, int err)\n{\n\tstruct sk_buff *skb = base->data;\n\tstruct tipc_crypto_rx_ctx *rx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = rx_ctx->bearer;\n\tstruct tipc_aead *aead = rx_ctx->aead;\n\tstruct tipc_crypto_stats __percpu *stats = aead->crypto->stats;\n\tstruct net *net = aead->crypto->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_NOK]);\n\t\tbreak;\n\t}\n\n\tkfree(rx_ctx);\n\ttipc_crypto_rcv_complete(net, aead, b, &skb, err);\n\tif (likely(skb)) {\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\ttipc_rcv(net, skb, b);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t}\n\n\ttipc_bearer_put(b);\n}\n\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr)\n{\n\treturn (ehdr->user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n}\n\n/**\n * tipc_ehdr_validate - Validate an encryption message\n * @skb: the message buffer\n *\n * Return: \"true\" if this is a valid encryption message, otherwise \"false\"\n */\nbool tipc_ehdr_validate(struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz;\n\n\tif (unlikely(!pskb_may_pull(skb, EHDR_MIN_SIZE)))\n\t\treturn false;\n\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tif (unlikely(ehdr->version != TIPC_EVERSION))\n\t\treturn false;\n\tehsz = tipc_ehdr_size(ehdr);\n\tif (unlikely(!pskb_may_pull(skb, ehsz)))\n\t\treturn false;\n\tif (unlikely(skb->len <= ehsz + TIPC_AES_GCM_TAG_SIZE))\n\t\treturn false;\n\n\treturn true;\n}\n\n/**\n * tipc_ehdr_build - Build TIPC encryption message header\n * @net: struct net\n * @aead: TX AEAD key to be used for the message encryption\n * @tx_key: key id used for the message encryption\n * @skb: input/output message skb\n * @__rx: RX crypto handle if dest is \"known\"\n *\n * Return: the header size if the building is successful, otherwise < 0\n */\nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_ehdr *ehdr;\n\tu32 user = msg_user(hdr);\n\tu64 seqno;\n\tint ehsz;\n\n\t/* Make room for encryption header */\n\tehsz = (user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n\tWARN_ON(skb_headroom(skb) < ehsz);\n\tehdr = (struct tipc_ehdr *)skb_push(skb, ehsz);\n\n\t/* Obtain a seqno first:\n\t * Use the key seqno (= cluster wise) if dest is unknown or we're in\n\t * cluster key mode, otherwise it's better for a per-peer seqno!\n\t */\n\tif (!__rx || aead->mode == CLUSTER_KEY)\n\t\tseqno = atomic64_inc_return(&aead->seqno);\n\telse\n\t\tseqno = atomic64_inc_return(&__rx->sndnxt);\n\n\t/* Revoke the key if seqno is wrapped around */\n\tif (unlikely(!seqno))\n\t\treturn tipc_crypto_key_revoke(net, tx_key);\n\n\t/* Word 1-2 */\n\tehdr->seqno = cpu_to_be64(seqno);\n\n\t/* Words 0, 3- */\n\tehdr->version = TIPC_EVERSION;\n\tehdr->user = 0;\n\tehdr->keepalive = 0;\n\tehdr->tx_key = tx_key;\n\tehdr->destined = (__rx) ? 1 : 0;\n\tehdr->rx_key_active = (__rx) ? __rx->key.active : 0;\n\tehdr->rx_nokey = (__rx) ? __rx->nokey : 0;\n\tehdr->master_key = aead->crypto->key_master;\n\tehdr->reserved_1 = 0;\n\tehdr->reserved_2 = 0;\n\n\tswitch (user) {\n\tcase LINK_CONFIG:\n\t\tehdr->user = LINK_CONFIG;\n\t\tmemcpy(ehdr->id, tipc_own_id(net), NODE_ID_LEN);\n\t\tbreak;\n\tdefault:\n\t\tif (user == LINK_PROTOCOL && msg_type(hdr) == STATE_MSG) {\n\t\t\tehdr->user = LINK_PROTOCOL;\n\t\t\tehdr->keepalive = msg_is_keepalive(hdr);\n\t\t}\n\t\tehdr->addr = hdr->hdr[3];\n\t\tbreak;\n\t}\n\n\treturn ehsz;\n}\n\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending)\n{\n\tstruct tipc_key old = c->key;\n\tchar buf[32];\n\n\tc->key.keys = ((new_passive & KEY_MASK) << (KEY_BITS * 2)) |\n\t\t      ((new_active  & KEY_MASK) << (KEY_BITS)) |\n\t\t      ((new_pending & KEY_MASK));\n\n\tpr_debug(\"%s: key changing %s ::%pS\\n\", c->name,\n\t\t tipc_key_change_dump(old, c->key, buf),\n\t\t __builtin_return_address(0));\n}\n\n/**\n * tipc_crypto_key_init - Initiate a new user / AEAD key\n * @c: TIPC crypto to which new key is attached\n * @ukey: the user key\n * @mode: the key mode (CLUSTER_KEY or PER_NODE_KEY)\n * @master_key: specify this is a cluster master key\n *\n * A new TIPC AEAD key will be allocated and initiated with the specified user\n * key, then attached to the TIPC crypto.\n *\n * Return: new key id in case of success, otherwise: < 0\n */\nint tipc_crypto_key_init(struct tipc_crypto *c, struct tipc_aead_key *ukey,\n\t\t\t u8 mode, bool master_key)\n{\n\tstruct tipc_aead *aead = NULL;\n\tint rc = 0;\n\n\t/* Initiate with the new user key */\n\trc = tipc_aead_init(&aead, ukey, mode);\n\n\t/* Attach it to the crypto */\n\tif (likely(!rc)) {\n\t\trc = tipc_crypto_key_attach(c, aead, 0, master_key);\n\t\tif (rc < 0)\n\t\t\ttipc_aead_free(&aead->rcu);\n\t}\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_attach - Attach a new AEAD key to TIPC crypto\n * @c: TIPC crypto to which the new AEAD key is attached\n * @aead: the new AEAD key pointer\n * @pos: desired slot in the crypto key array, = 0 if any!\n * @master_key: specify this is a cluster master key\n *\n * Return: new key id in case of success, otherwise: -EBUSY\n */\nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key)\n{\n\tstruct tipc_key key;\n\tint rc = -EBUSY;\n\tu8 new_key;\n\n\tspin_lock_bh(&c->lock);\n\tkey = c->key;\n\tif (master_key) {\n\t\tnew_key = KEY_MASTER;\n\t\tgoto attach;\n\t}\n\tif (key.active && key.passive)\n\t\tgoto exit;\n\tif (key.pending) {\n\t\tif (tipc_aead_users(c->aead[key.pending]) > 0)\n\t\t\tgoto exit;\n\t\t/* if (pos): ok with replacing, will be aligned when needed */\n\t\t/* Replace it */\n\t\tnew_key = key.pending;\n\t} else {\n\t\tif (pos) {\n\t\t\tif (key.active && pos != key_next(key.active)) {\n\t\t\t\tkey.passive = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t} else if (!key.active && !key.passive) {\n\t\t\t\tkey.pending = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t}\n\t\t}\n\t\tkey.pending = key_next(key.active ?: key.passive);\n\t\tnew_key = key.pending;\n\t}\n\nattach:\n\taead->crypto = c;\n\taead->gen = (is_tx(c)) ? ++c->key_gen : c->key_gen;\n\ttipc_aead_rcu_replace(c->aead[new_key], aead, &c->lock);\n\tif (likely(c->key.keys != key.keys))\n\t\ttipc_crypto_key_set_state(c, key.passive, key.active,\n\t\t\t\t\t  key.pending);\n\tc->working = 1;\n\tc->nokey = 0;\n\tc->key_master |= master_key;\n\trc = new_key;\n\nexit:\n\tspin_unlock_bh(&c->lock);\n\treturn rc;\n}\n\nvoid tipc_crypto_key_flush(struct tipc_crypto *c)\n{\n\tstruct tipc_crypto *tx, *rx;\n\tint k;\n\n\tspin_lock_bh(&c->lock);\n\tif (is_rx(c)) {\n\t\t/* Try to cancel pending work */\n\t\trx = c;\n\t\ttx = tipc_net(rx->net)->crypto_tx;\n\t\tif (cancel_delayed_work(&rx->work)) {\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tatomic_xchg(&rx->key_distr, 0);\n\t\t\ttipc_node_put(rx->node);\n\t\t}\n\t\t/* RX stopping => decrease TX key users if any */\n\t\tk = atomic_xchg(&rx->peer_rx_active, 0);\n\t\tif (k) {\n\t\t\ttipc_aead_users_dec(tx->aead[k], 0);\n\t\t\t/* Mark the point TX key users changed */\n\t\t\ttx->timer1 = jiffies;\n\t\t}\n\t}\n\n\tc->flags = 0;\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_crypto_key_detach(c->aead[k], &c->lock);\n\tatomic64_set(&c->sndnxt, 0);\n\tspin_unlock_bh(&c->lock);\n}\n\n/**\n * tipc_crypto_key_try_align - Align RX keys if possible\n * @rx: RX crypto handle\n * @new_pending: new pending slot if aligned (= TX key from peer)\n *\n * Peer has used an unknown key slot, this only happens when peer has left and\n * rejoned, or we are newcomer.\n * That means, there must be no active key but a pending key at unaligned slot.\n * If so, we try to move the pending key to the new slot.\n * Note: A potential passive key can exist, it will be shifted correspondingly!\n *\n * Return: \"true\" if key is successfully aligned, otherwise \"false\"\n */\nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending)\n{\n\tstruct tipc_aead *tmp1, *tmp2 = NULL;\n\tstruct tipc_key key;\n\tbool aligned = false;\n\tu8 new_passive = 0;\n\tint x;\n\n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (key.pending == new_pending) {\n\t\taligned = true;\n\t\tgoto exit;\n\t}\n\tif (key.active)\n\t\tgoto exit;\n\tif (!key.pending)\n\t\tgoto exit;\n\tif (tipc_aead_users(rx->aead[key.pending]) > 0)\n\t\tgoto exit;\n\n\t/* Try to \"isolate\" this pending key first */\n\ttmp1 = tipc_aead_rcu_ptr(rx->aead[key.pending], &rx->lock);\n\tif (!refcount_dec_if_one(&tmp1->refcnt))\n\t\tgoto exit;\n\trcu_assign_pointer(rx->aead[key.pending], NULL);\n\n\t/* Move passive key if any */\n\tif (key.passive) {\n\t\ttmp2 = rcu_replace_pointer(rx->aead[key.passive], tmp2, lockdep_is_held(&rx->lock));\n\t\tx = (key.passive - key.pending + new_pending) % KEY_MAX;\n\t\tnew_passive = (x <= 0) ? x + KEY_MAX : x;\n\t}\n\n\t/* Re-allocate the key(s) */\n\ttipc_crypto_key_set_state(rx, new_passive, 0, new_pending);\n\trcu_assign_pointer(rx->aead[new_pending], tmp1);\n\tif (new_passive)\n\t\trcu_assign_pointer(rx->aead[new_passive], tmp2);\n\trefcount_set(&tmp1->refcnt, 1);\n\taligned = true;\n\tpr_info_ratelimited(\"%s: key[%d] -> key[%d]\\n\", rx->name, key.pending,\n\t\t\t    new_pending);\n\nexit:\n\tspin_unlock(&rx->lock);\n\treturn aligned;\n}\n\n/**\n * tipc_crypto_key_pick_tx - Pick one TX key for message decryption\n * @tx: TX crypto handle\n * @rx: RX crypto handle (can be NULL)\n * @skb: the message skb which will be decrypted later\n * @tx_key: peer TX key id\n *\n * This function looks up the existing TX keys and pick one which is suitable\n * for the message decryption, that must be a cluster key and not used before\n * on the same message (i.e. recursive).\n *\n * Return: the TX AEAD key handle in case of success, otherwise NULL\n */\nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(skb);\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key = tx->key;\n\tu8 k, i = 0;\n\n\t/* Initialize data if not yet */\n\tif (!skb_cb->tx_clone_deferred) {\n\t\tskb_cb->tx_clone_deferred = 1;\n\t\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\t}\n\n\tskb_cb->tx_clone_ctx.rx = rx;\n\tif (++skb_cb->tx_clone_ctx.recurs > 2)\n\t\treturn NULL;\n\n\t/* Pick one TX key */\n\tspin_lock(&tx->lock);\n\tif (tx_key == KEY_MASTER) {\n\t\taead = tipc_aead_rcu_ptr(tx->aead[KEY_MASTER], &tx->lock);\n\t\tgoto done;\n\t}\n\tdo {\n\t\tk = (i == 0) ? key.pending :\n\t\t\t((i == 1) ? key.active : key.passive);\n\t\tif (!k)\n\t\t\tcontinue;\n\t\taead = tipc_aead_rcu_ptr(tx->aead[k], &tx->lock);\n\t\tif (!aead)\n\t\t\tcontinue;\n\t\tif (aead->mode != CLUSTER_KEY ||\n\t\t    aead == skb_cb->tx_clone_ctx.last) {\n\t\t\taead = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t/* Ok, found one cluster key */\n\t\tskb_cb->tx_clone_ctx.last = aead;\n\t\tWARN_ON(skb->next);\n\t\tskb->next = skb_clone(skb, GFP_ATOMIC);\n\t\tif (unlikely(!skb->next))\n\t\t\tpr_warn(\"Failed to clone skb for next round if any\\n\");\n\t\tbreak;\n\t} while (++i < 3);\n\ndone:\n\tif (likely(aead))\n\t\tWARN_ON(!refcount_inc_not_zero(&aead->refcnt));\n\tspin_unlock(&tx->lock);\n\n\treturn aead;\n}\n\n/**\n * tipc_crypto_key_synch: Synch own key data according to peer key status\n * @rx: RX crypto handle\n * @skb: TIPCv2 message buffer (incl. the ehdr from peer)\n *\n * This function updates the peer node related data as the peer RX active key\n * has changed, so the number of TX keys' users on this node are increased and\n * decreased correspondingly.\n *\n * It also considers if peer has no key, then we need to make own master key\n * (if any) taking over i.e. starting grace period and also trigger key\n * distributing process.\n *\n * The \"per-peer\" sndnxt is also reset when the peer key has switched.\n */\nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr = (struct tipc_ehdr *)skb_network_header(skb);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tu32 self = tipc_own_addr(rx->net);\n\tu8 cur, new;\n\tunsigned long delay;\n\n\t/* Update RX 'key_master' flag according to peer, also mark \"legacy\" if\n\t * a peer has no master key.\n\t */\n\trx->key_master = ehdr->master_key;\n\tif (!rx->key_master)\n\t\ttx->legacy_user = 1;\n\n\t/* For later cases, apply only if message is destined to this node */\n\tif (!ehdr->destined || msg_short(hdr) || msg_destnode(hdr) != self)\n\t\treturn;\n\n\t/* Case 1: Peer has no keys, let's make master key take over */\n\tif (ehdr->rx_nokey) {\n\t\t/* Set or extend grace period */\n\t\ttx->timer2 = jiffies;\n\t\t/* Schedule key distributing for the peer if not yet */\n\t\tif (tx->key.keys &&\n\t\t    !atomic_cmpxchg(&rx->key_distr, 0, KEY_DISTR_SCHED)) {\n\t\t\tget_random_bytes(&delay, 2);\n\t\t\tdelay %= 5;\n\t\t\tdelay = msecs_to_jiffies(500 * ++delay);\n\t\t\tif (queue_delayed_work(tx->wq, &rx->work, delay))\n\t\t\t\ttipc_node_get(rx->node);\n\t\t}\n\t} else {\n\t\t/* Cancel a pending key distributing if any */\n\t\tatomic_xchg(&rx->key_distr, 0);\n\t}\n\n\t/* Case 2: Peer RX active key has changed, let's update own TX users */\n\tcur = atomic_read(&rx->peer_rx_active);\n\tnew = ehdr->rx_key_active;\n\tif (tx->key.keys &&\n\t    cur != new &&\n\t    atomic_cmpxchg(&rx->peer_rx_active, cur, new) == cur) {\n\t\tif (new)\n\t\t\ttipc_aead_users_inc(tx->aead[new], INT_MAX);\n\t\tif (cur)\n\t\t\ttipc_aead_users_dec(tx->aead[cur], 0);\n\n\t\tatomic64_set(&rx->sndnxt, 0);\n\t\t/* Mark the point TX key users changed */\n\t\ttx->timer1 = jiffies;\n\n\t\tpr_debug(\"%s: key users changed %d-- %d++, peer %s\\n\",\n\t\t\t tx->name, cur, new, rx->name);\n\t}\n}\n\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_key key;\n\n\tspin_lock(&tx->lock);\n\tkey = tx->key;\n\tWARN_ON(!key.active || tx_key != key.active);\n\n\t/* Free the active key */\n\ttipc_crypto_key_set_state(tx, key.passive, 0, key.pending);\n\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tspin_unlock(&tx->lock);\n\n\tpr_warn(\"%s: key is revoked\\n\", tx->name);\n\treturn -EKEYREVOKED;\n}\n\nint tipc_crypto_start(struct tipc_crypto **crypto, struct net *net,\n\t\t      struct tipc_node *node)\n{\n\tstruct tipc_crypto *c;\n\n\tif (*crypto)\n\t\treturn -EEXIST;\n\n\t/* Allocate crypto */\n\tc = kzalloc(sizeof(*c), GFP_ATOMIC);\n\tif (!c)\n\t\treturn -ENOMEM;\n\n\t/* Allocate workqueue on TX */\n\tif (!node) {\n\t\tc->wq = alloc_ordered_workqueue(\"tipc_crypto\", 0);\n\t\tif (!c->wq) {\n\t\t\tkfree(c);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t/* Allocate statistic structure */\n\tc->stats = alloc_percpu_gfp(struct tipc_crypto_stats, GFP_ATOMIC);\n\tif (!c->stats) {\n\t\tif (c->wq)\n\t\t\tdestroy_workqueue(c->wq);\n\t\tkfree_sensitive(c);\n\t\treturn -ENOMEM;\n\t}\n\n\tc->flags = 0;\n\tc->net = net;\n\tc->node = node;\n\tget_random_bytes(&c->key_gen, 2);\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tatomic_set(&c->key_distr, 0);\n\tatomic_set(&c->peer_rx_active, 0);\n\tatomic64_set(&c->sndnxt, 0);\n\tc->timer1 = jiffies;\n\tc->timer2 = jiffies;\n\tc->rekeying_intv = TIPC_REKEYING_INTV_DEF;\n\tspin_lock_init(&c->lock);\n\tscnprintf(c->name, 48, \"%s(%s)\", (is_rx(c)) ? \"RX\" : \"TX\",\n\t\t  (is_rx(c)) ? tipc_node_get_id_str(c->node) :\n\t\t\t       tipc_own_id_string(c->net));\n\n\tif (is_rx(c))\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_rx);\n\telse\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_tx);\n\n\t*crypto = c;\n\treturn 0;\n}\n\nvoid tipc_crypto_stop(struct tipc_crypto **crypto)\n{\n\tstruct tipc_crypto *c = *crypto;\n\tu8 k;\n\n\tif (!c)\n\t\treturn;\n\n\t/* Flush any queued works & destroy wq */\n\tif (is_tx(c)) {\n\t\tc->rekeying_intv = 0;\n\t\tcancel_delayed_work_sync(&c->work);\n\t\tdestroy_workqueue(c->wq);\n\t}\n\n\t/* Release AEAD keys */\n\trcu_read_lock();\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_aead_put(rcu_dereference(c->aead[k]));\n\trcu_read_unlock();\n\tpr_debug(\"%s: has been stopped\\n\", c->name);\n\n\t/* Free this crypto statistics */\n\tfree_percpu(c->stats);\n\n\t*crypto = NULL;\n\tkfree_sensitive(c);\n}\n\nvoid tipc_crypto_timeout(struct tipc_crypto *rx)\n{\n\tstruct tipc_net *tn = tipc_net(rx->net);\n\tstruct tipc_crypto *tx = tn->crypto_tx;\n\tstruct tipc_key key;\n\tint cmd;\n\n\t/* TX pending: taking all users & stable -> active */\n\tspin_lock(&tx->lock);\n\tkey = tx->key;\n\tif (key.active && tipc_aead_users(tx->aead[key.active]) > 0)\n\t\tgoto s1;\n\tif (!key.pending || tipc_aead_users(tx->aead[key.pending]) <= 0)\n\t\tgoto s1;\n\tif (time_before(jiffies, tx->timer1 + TIPC_TX_LASTING_TIME))\n\t\tgoto s1;\n\n\ttipc_crypto_key_set_state(tx, key.passive, key.pending, 0);\n\tif (key.active)\n\t\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tthis_cpu_inc(tx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", tx->name, key.pending);\n\ns1:\n\tspin_unlock(&tx->lock);\n\n\t/* RX pending: having user -> active */\n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) <= 0)\n\t\tgoto s2;\n\n\tif (key.active)\n\t\tkey.passive = key.active;\n\tkey.active = key.pending;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\tthis_cpu_inc(rx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns2:\n\t/* RX pending: not working -> remove */\n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) > -10)\n\t\tgoto s3;\n\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\ttipc_crypto_key_detach(rx->aead[key.pending], &rx->lock);\n\tpr_debug(\"%s: key[%d] is removed\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns3:\n\t/* RX active: timed out or no user -> pending */\n\tif (!key.active)\n\t\tgoto s4;\n\tif (time_before(jiffies, rx->timer1 + TIPC_RX_ACTIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.active]) > 0)\n\t\tgoto s4;\n\n\tif (key.pending)\n\t\tkey.passive = key.active;\n\telse\n\t\tkey.pending = key.active;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, 0, key.pending);\n\ttipc_aead_users_set(rx->aead[key.pending], 0);\n\tpr_debug(\"%s: key[%d] is deactivated\\n\", rx->name, key.active);\n\tgoto s5;\n\ns4:\n\t/* RX passive: outdated or not working -> free */\n\tif (!key.passive)\n\t\tgoto s5;\n\tif (time_before(jiffies, rx->timer2 + TIPC_RX_PASSIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.passive]) > -10)\n\t\tgoto s5;\n\n\ttipc_crypto_key_set_state(rx, 0, key.active, key.pending);\n\ttipc_crypto_key_detach(rx->aead[key.passive], &rx->lock);\n\tpr_debug(\"%s: key[%d] is freed\\n\", rx->name, key.passive);\n\ns5:\n\tspin_unlock(&rx->lock);\n\n\t/* Relax it here, the flag will be set again if it really is, but only\n\t * when we are not in grace period for safety!\n\t */\n\tif (time_after(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\ttx->legacy_user = 0;\n\n\t/* Limit max_tfms & do debug commands if needed */\n\tif (likely(sysctl_tipc_max_tfms <= TIPC_MAX_TFMS_LIM))\n\t\treturn;\n\n\tcmd = sysctl_tipc_max_tfms;\n\tsysctl_tipc_max_tfms = TIPC_MAX_TFMS_DEF;\n\ttipc_crypto_do_cmd(rx->net, cmd);\n}\n\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type)\n{\n\tstruct sk_buff *skb;\n\n\tskb = skb_clone(_skb, GFP_ATOMIC);\n\tif (skb) {\n\t\tTIPC_SKB_CB(skb)->xmit_type = type;\n\t\ttipc_crypto_xmit(net, &skb, b, dst, __dnode);\n\t\tif (skb)\n\t\t\tb->media->send_msg(net, skb, b, dst);\n\t}\n}\n\n/**\n * tipc_crypto_xmit - Build & encrypt TIPC message for xmit\n * @net: struct net\n * @skb: input/output message skb pointer\n * @b: bearer used for xmit later\n * @dst: destination media address\n * @__dnode: destination node for reference if any\n *\n * First, build an encryption message header on the top of the message, then\n * encrypt the original TIPC message by using the pending, master or active\n * key with this preference order.\n * If the encryption is successful, the encrypted skb is returned directly or\n * via the callback.\n * Otherwise, the skb is freed!\n *\n * Return:\n * * 0                   : the encryption has succeeded (or no encryption)\n * * -EINPROGRESS/-EBUSY : the encryption is ongoing, a callback will be made\n * * -ENOKEK             : the encryption has failed due to no key\n * * -EKEYREVOKED        : the encryption has failed due to key revoked\n * * -ENOMEM             : the encryption has failed due to no memory\n * * < 0                 : the encryption has failed due to other reasons\n */\nint tipc_crypto_xmit(struct net *net, struct sk_buff **skb,\n\t\t     struct tipc_bearer *b, struct tipc_media_addr *dst,\n\t\t     struct tipc_node *__dnode)\n{\n\tstruct tipc_crypto *__rx = tipc_node_crypto_rx(__dnode);\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats = tx->stats;\n\tstruct tipc_msg *hdr = buf_msg(*skb);\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead = NULL;\n\tu32 user = msg_user(hdr);\n\tu32 type = msg_type(hdr);\n\tint rc = -ENOKEY;\n\tu8 tx_key = 0;\n\n\t/* No encryption? */\n\tif (!tx->working)\n\t\treturn 0;\n\n\t/* Pending key if peer has active on it or probing time */\n\tif (unlikely(key.pending)) {\n\t\ttx_key = key.pending;\n\t\tif (!tx->key_master && !key.active)\n\t\t\tgoto encrypt;\n\t\tif (__rx && atomic_read(&__rx->peer_rx_active) == tx_key)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_PROBING) {\n\t\t\tpr_debug(\"%s: probing for key[%d]\\n\", tx->name,\n\t\t\t\t key.pending);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG || user == LINK_PROTOCOL)\n\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst, __dnode,\n\t\t\t\t\t      SKB_PROBING);\n\t}\n\n\t/* Master key if this is a *vital* message or in grace period */\n\tif (tx->key_master) {\n\t\ttx_key = KEY_MASTER;\n\t\tif (!key.active)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_GRACING) {\n\t\t\tpr_debug(\"%s: gracing for msg (%d %d)\\n\", tx->name,\n\t\t\t\t user, type);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG ||\n\t\t    (user == LINK_PROTOCOL && type == RESET_MSG) ||\n\t\t    (user == MSG_CRYPTO && type == KEY_DISTR_MSG) ||\n\t\t    time_before(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD)) {\n\t\t\tif (__rx && __rx->key_master &&\n\t\t\t    !atomic_read(&__rx->peer_rx_active))\n\t\t\t\tgoto encrypt;\n\t\t\tif (!__rx) {\n\t\t\t\tif (likely(!tx->legacy_user))\n\t\t\t\t\tgoto encrypt;\n\t\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst,\n\t\t\t\t\t\t      __dnode, SKB_GRACING);\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Else, use the active key if any */\n\tif (likely(key.active)) {\n\t\ttx_key = key.active;\n\t\tgoto encrypt;\n\t}\n\n\tgoto exit;\n\nencrypt:\n\taead = tipc_aead_get(tx->aead[tx_key]);\n\tif (unlikely(!aead))\n\t\tgoto exit;\n\trc = tipc_ehdr_build(net, aead, tx_key, *skb, __rx);\n\tif (likely(rc > 0))\n\t\trc = tipc_aead_encrypt(aead, *skb, b, dst, __dnode);\n\nexit:\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY)\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\telse if (rc == -EKEYREVOKED)\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADKEYS]);\n\t\tkfree_skb(*skb);\n\t\t*skb = NULL;\n\t\tbreak;\n\t}\n\n\ttipc_aead_put(aead);\n\treturn rc;\n}\n\n/**\n * tipc_crypto_rcv - Decrypt an encrypted TIPC message from peer\n * @net: struct net\n * @rx: RX crypto handle\n * @skb: input/output message skb pointer\n * @b: bearer where the message has been received\n *\n * If the decryption is successful, the decrypted skb is returned directly or\n * as the callback, the encryption header and auth tag will be trimed out\n * before forwarding to tipc_rcv() via the tipc_crypto_rcv_complete().\n * Otherwise, the skb will be freed!\n * Note: RX key(s) can be re-aligned, or in case of no key suitable, TX\n * cluster key(s) can be taken for decryption (- recursive).\n *\n * Return:\n * * 0                   : the decryption has successfully completed\n * * -EINPROGRESS/-EBUSY : the decryption is ongoing, a callback will be made\n * * -ENOKEY             : the decryption has failed due to no key\n * * -EBADMSG            : the decryption has failed due to bad message\n * * -ENOMEM             : the decryption has failed due to no memory\n * * < 0                 : the decryption has failed due to other reasons\n */\nint tipc_crypto_rcv(struct net *net, struct tipc_crypto *rx,\n\t\t    struct sk_buff **skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats;\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key;\n\tint rc = -ENOKEY;\n\tu8 tx_key, n;\n\n\ttx_key = ((struct tipc_ehdr *)(*skb)->data)->tx_key;\n\n\t/* New peer?\n\t * Let's try with TX key (i.e. cluster mode) & verify the skb first!\n\t */\n\tif (unlikely(!rx || tx_key == KEY_MASTER))\n\t\tgoto pick_tx;\n\n\t/* Pick RX key according to TX key if any */\n\tkey = rx->key;\n\tif (tx_key == key.active || tx_key == key.pending ||\n\t    tx_key == key.passive)\n\t\tgoto decrypt;\n\n\t/* Unknown key, let's try to align RX key(s) */\n\tif (tipc_crypto_key_try_align(rx, tx_key))\n\t\tgoto decrypt;\n\npick_tx:\n\t/* No key suitable? Try to pick one from TX... */\n\taead = tipc_crypto_key_pick_tx(tx, rx, *skb, tx_key);\n\tif (aead)\n\t\tgoto decrypt;\n\tgoto exit;\n\ndecrypt:\n\trcu_read_lock();\n\tif (!aead)\n\t\taead = tipc_aead_get(rx->aead[tx_key]);\n\trc = tipc_aead_decrypt(net, aead, *skb, b);\n\trcu_read_unlock();\n\nexit:\n\tstats = ((rx) ?: tx)->stats;\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY) {\n\t\t\tkfree_skb(*skb);\n\t\t\t*skb = NULL;\n\t\t\tif (rx) {\n\t\t\t\t/* Mark rx->nokey only if we dont have a\n\t\t\t\t * pending received session key, nor a newer\n\t\t\t\t * one i.e. in the next slot.\n\t\t\t\t */\n\t\t\t\tn = key_next(tx_key);\n\t\t\t\trx->nokey = !(rx->skey ||\n\t\t\t\t\t      rcu_access_pointer(rx->aead[n]));\n\t\t\t\tpr_debug_ratelimited(\"%s: nokey %d, key %d/%x\\n\",\n\t\t\t\t\t\t     rx->name, rx->nokey,\n\t\t\t\t\t\t     tx_key, rx->key.keys);\n\t\t\t\ttipc_node_put(rx->node);\n\t\t\t}\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\t\treturn rc;\n\t\t} else if (rc == -EBADMSG) {\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADMSGS]);\n\t\t}\n\t\tbreak;\n\t}\n\n\ttipc_crypto_rcv_complete(net, aead, b, skb, rc);\n\treturn rc;\n}\n\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(*skb);\n\tstruct tipc_crypto *rx = aead->crypto;\n\tstruct tipc_aead *tmp = NULL;\n\tstruct tipc_ehdr *ehdr;\n\tstruct tipc_node *n;\n\n\t/* Is this completed by TX? */\n\tif (unlikely(is_tx(aead->crypto))) {\n\t\trx = skb_cb->tx_clone_ctx.rx;\n\t\tpr_debug(\"TX->RX(%s): err %d, aead %p, skb->next %p, flags %x\\n\",\n\t\t\t (rx) ? tipc_node_get_id_str(rx->node) : \"-\", err, aead,\n\t\t\t (*skb)->next, skb_cb->flags);\n\t\tpr_debug(\"skb_cb [recurs %d, last %p], tx->aead [%p %p %p]\\n\",\n\t\t\t skb_cb->tx_clone_ctx.recurs, skb_cb->tx_clone_ctx.last,\n\t\t\t aead->crypto->aead[1], aead->crypto->aead[2],\n\t\t\t aead->crypto->aead[3]);\n\t\tif (unlikely(err)) {\n\t\t\tif (err == -EBADMSG && (*skb)->next)\n\t\t\t\ttipc_rcv(net, (*skb)->next, b);\n\t\t\tgoto free_skb;\n\t\t}\n\n\t\tif (likely((*skb)->next)) {\n\t\t\tkfree_skb((*skb)->next);\n\t\t\t(*skb)->next = NULL;\n\t\t}\n\t\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\t\tif (!rx) {\n\t\t\tWARN_ON(ehdr->user != LINK_CONFIG);\n\t\t\tn = tipc_node_create(net, 0, ehdr->id, 0xffffu, 0,\n\t\t\t\t\t     true);\n\t\t\trx = tipc_node_crypto_rx(n);\n\t\t\tif (unlikely(!rx))\n\t\t\t\tgoto free_skb;\n\t\t}\n\n\t\t/* Ignore cloning if it was TX master key */\n\t\tif (ehdr->tx_key == KEY_MASTER)\n\t\t\tgoto rcv;\n\t\tif (tipc_aead_clone(&tmp, aead) < 0)\n\t\t\tgoto rcv;\n\t\tWARN_ON(!refcount_inc_not_zero(&tmp->refcnt));\n\t\tif (tipc_crypto_key_attach(rx, tmp, ehdr->tx_key, false) < 0) {\n\t\t\ttipc_aead_free(&tmp->rcu);\n\t\t\tgoto rcv;\n\t\t}\n\t\ttipc_aead_put(aead);\n\t\taead = tmp;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttipc_aead_users_dec((struct tipc_aead __force __rcu *)aead, INT_MIN);\n\t\tgoto free_skb;\n\t}\n\n\t/* Set the RX key's user */\n\ttipc_aead_users_set((struct tipc_aead __force __rcu *)aead, 1);\n\n\t/* Mark this point, RX works */\n\trx->timer1 = jiffies;\n\nrcv:\n\t/* Remove ehdr & auth. tag prior to tipc_rcv() */\n\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\n\t/* Mark this point, RX passive still works */\n\tif (rx->key.passive && ehdr->tx_key == rx->key.passive)\n\t\trx->timer2 = jiffies;\n\n\tskb_reset_network_header(*skb);\n\tskb_pull(*skb, tipc_ehdr_size(ehdr));\n\tpskb_trim(*skb, (*skb)->len - aead->authsize);\n\n\t/* Validate TIPCv2 message */\n\tif (unlikely(!tipc_msg_validate(skb))) {\n\t\tpr_err_ratelimited(\"Packet dropped after decryption!\\n\");\n\t\tgoto free_skb;\n\t}\n\n\t/* Ok, everything's fine, try to synch own keys according to peers' */\n\ttipc_crypto_key_synch(rx, *skb);\n\n\t/* Mark skb decrypted */\n\tskb_cb->decrypted = 1;\n\n\t/* Clear clone cxt if any */\n\tif (likely(!skb_cb->tx_clone_deferred))\n\t\tgoto exit;\n\tskb_cb->tx_clone_deferred = 0;\n\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\tgoto exit;\n\nfree_skb:\n\tkfree_skb(*skb);\n\t*skb = NULL;\n\nexit:\n\ttipc_aead_put(aead);\n\tif (rx)\n\t\ttipc_node_put(rx->node);\n}\n\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd)\n{\n\tstruct tipc_net *tn = tipc_net(net);\n\tstruct tipc_crypto *tx = tn->crypto_tx, *rx;\n\tstruct list_head *p;\n\tunsigned int stat;\n\tint i, j, cpu;\n\tchar buf[200];\n\n\t/* Currently only one command is supported */\n\tswitch (cmd) {\n\tcase 0xfff1:\n\t\tgoto print_stats;\n\tdefault:\n\t\treturn;\n\t}\n\nprint_stats:\n\t/* Print a header */\n\tpr_info(\"\\n=============== TIPC Crypto Statistics ===============\\n\\n\");\n\n\t/* Print key status */\n\tpr_info(\"Key status:\\n\");\n\tpr_info(\"TX(%7.7s)\\n%s\", tipc_own_id_string(net),\n\t\ttipc_crypto_key_dump(tx, buf));\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tpr_info(\"RX(%7.7s)\\n%s\", tipc_node_get_id_str(rx->node),\n\t\t\ttipc_crypto_key_dump(rx, buf));\n\t}\n\trcu_read_unlock();\n\n\t/* Print crypto statistics */\n\tfor (i = 0, j = 0; i < MAX_STATS; i++)\n\t\tj += scnprintf(buf + j, 200 - j, \"|%11s \", hstats[i]);\n\tpr_info(\"Counter     %s\", buf);\n\n\tmemset(buf, '-', 115);\n\tbuf[115] = '\\0';\n\tpr_info(\"%s\\n\", buf);\n\n\tj = scnprintf(buf, 200, \"TX(%7.7s) \", tipc_own_id_string(net));\n\tfor_each_possible_cpu(cpu) {\n\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\tstat = per_cpu_ptr(tx->stats, cpu)->stat[i];\n\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \", stat);\n\t\t}\n\t\tpr_info(\"%s\", buf);\n\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t}\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tj = scnprintf(buf, 200, \"RX(%7.7s) \",\n\t\t\t      tipc_node_get_id_str(rx->node));\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\t\tstat = per_cpu_ptr(rx->stats, cpu)->stat[i];\n\t\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \",\n\t\t\t\t\t       stat);\n\t\t\t}\n\t\t\tpr_info(\"%s\", buf);\n\t\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tpr_info(\"\\n======================== Done ========================\\n\");\n}\n\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf)\n{\n\tstruct tipc_key key = c->key;\n\tstruct tipc_aead *aead;\n\tint k, i = 0;\n\tchar *s;\n\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++) {\n\t\tif (k == KEY_MASTER) {\n\t\t\tif (is_rx(c))\n\t\t\t\tcontinue;\n\t\t\tif (time_before(jiffies,\n\t\t\t\t\tc->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\t\t\ts = \"ACT\";\n\t\t\telse\n\t\t\t\ts = \"PAS\";\n\t\t} else {\n\t\t\tif (k == key.passive)\n\t\t\t\ts = \"PAS\";\n\t\t\telse if (k == key.active)\n\t\t\t\ts = \"ACT\";\n\t\t\telse if (k == key.pending)\n\t\t\t\ts = \"PEN\";\n\t\t\telse\n\t\t\t\ts = \"-\";\n\t\t}\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tKey%d: %s\", k, s);\n\n\t\trcu_read_lock();\n\t\taead = rcu_dereference(c->aead[k]);\n\t\tif (aead)\n\t\t\ti += scnprintf(buf + i, 200 - i,\n\t\t\t\t       \"{\\\"0x...%s\\\", \\\"%s\\\"}/%d:%d\",\n\t\t\t\t       aead->hint,\n\t\t\t\t       (aead->mode == CLUSTER_KEY) ? \"c\" : \"p\",\n\t\t\t\t       atomic_read(&aead->users),\n\t\t\t\t       refcount_read(&aead->refcnt));\n\t\trcu_read_unlock();\n\t\ti += scnprintf(buf + i, 200 - i, \"\\n\");\n\t}\n\n\tif (is_rx(c))\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tPeer RX active: %d\\n\",\n\t\t\t       atomic_read(&c->peer_rx_active));\n\n\treturn buf;\n}\n\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf)\n{\n\tstruct tipc_key *key = &old;\n\tint k, i = 0;\n\tchar *s;\n\n\t/* Output format: \"[%s %s %s] -> [%s %s %s]\", max len = 32 */\nagain:\n\ti += scnprintf(buf + i, 32 - i, \"[\");\n\tfor (k = KEY_1; k <= KEY_3; k++) {\n\t\tif (k == key->passive)\n\t\t\ts = \"pas\";\n\t\telse if (k == key->active)\n\t\t\ts = \"act\";\n\t\telse if (k == key->pending)\n\t\t\ts = \"pen\";\n\t\telse\n\t\t\ts = \"-\";\n\t\ti += scnprintf(buf + i, 32 - i,\n\t\t\t       (k != KEY_3) ? \"%s \" : \"%s\", s);\n\t}\n\tif (key != &new) {\n\t\ti += scnprintf(buf + i, 32 - i, \"] -> \");\n\t\tkey = &new;\n\t\tgoto again;\n\t}\n\ti += scnprintf(buf + i, 32 - i, \"]\");\n\treturn buf;\n}\n\n/**\n * tipc_crypto_msg_rcv - Common 'MSG_CRYPTO' processing point\n * @net: the struct net\n * @skb: the receiving message buffer\n */\nvoid tipc_crypto_msg_rcv(struct net *net, struct sk_buff *skb)\n{\n\tstruct tipc_crypto *rx;\n\tstruct tipc_msg *hdr;\n\n\tif (unlikely(skb_linearize(skb)))\n\t\tgoto exit;\n\n\thdr = buf_msg(skb);\n\trx = tipc_node_crypto_rx_by_addr(net, msg_prevnode(hdr));\n\tif (unlikely(!rx))\n\t\tgoto exit;\n\n\tswitch (msg_type(hdr)) {\n\tcase KEY_DISTR_MSG:\n\t\tif (tipc_crypto_key_rcv(rx, hdr))\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttipc_node_put(rx->node);\n\nexit:\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_crypto_key_distr - Distribute a TX key\n * @tx: the TX crypto\n * @key: the key's index\n * @dest: the destination tipc node, = NULL if distributing to all nodes\n *\n * Return: 0 in case of success, otherwise < 0\n */\nint tipc_crypto_key_distr(struct tipc_crypto *tx, u8 key,\n\t\t\t  struct tipc_node *dest)\n{\n\tstruct tipc_aead *aead;\n\tu32 dnode = tipc_node_get_addr(dest);\n\tint rc = -ENOKEY;\n\n\tif (!sysctl_tipc_key_exchange_enabled)\n\t\treturn 0;\n\n\tif (key) {\n\t\trcu_read_lock();\n\t\taead = tipc_aead_get(tx->aead[key]);\n\t\tif (likely(aead)) {\n\t\t\trc = tipc_crypto_key_xmit(tx->net, aead->key,\n\t\t\t\t\t\t  aead->gen, aead->mode,\n\t\t\t\t\t\t  dnode);\n\t\t\ttipc_aead_put(aead);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_xmit - Send a session key\n * @net: the struct net\n * @skey: the session key to be sent\n * @gen: the key's generation\n * @mode: the key's mode\n * @dnode: the destination node address, = 0 if broadcasting to all nodes\n *\n * The session key 'skey' is packed in a TIPC v2 'MSG_CRYPTO/KEY_DISTR_MSG'\n * as its data section, then xmit-ed through the uc/bc link.\n *\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode)\n{\n\tstruct sk_buff_head pkts;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tu16 size, cong_link_cnt;\n\tu8 *data;\n\tint rc;\n\n\tsize = tipc_aead_key_size(skey);\n\tskb = tipc_buf_acquire(INT_H_SIZE + size, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thdr = buf_msg(skb);\n\ttipc_msg_init(tipc_own_addr(net), hdr, MSG_CRYPTO, KEY_DISTR_MSG,\n\t\t      INT_H_SIZE, dnode);\n\tmsg_set_size(hdr, INT_H_SIZE + size);\n\tmsg_set_key_gen(hdr, gen);\n\tmsg_set_key_mode(hdr, mode);\n\n\tdata = msg_data(hdr);\n\t*((__be32 *)(data + TIPC_AEAD_ALG_NAME)) = htonl(skey->keylen);\n\tmemcpy(data, skey->alg_name, TIPC_AEAD_ALG_NAME);\n\tmemcpy(data + TIPC_AEAD_ALG_NAME + sizeof(__be32), skey->key,\n\t       skey->keylen);\n\n\t__skb_queue_head_init(&pkts);\n\t__skb_queue_tail(&pkts, skb);\n\tif (dnode)\n\t\trc = tipc_node_xmit(net, &pkts, dnode, 0);\n\telse\n\t\trc = tipc_bcast_xmit(net, &pkts, &cong_link_cnt);\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_rcv - Receive a session key\n * @rx: the RX crypto\n * @hdr: the TIPC v2 message incl. the receiving session key in its data\n *\n * This function retrieves the session key in the message from peer, then\n * schedules a RX work to attach the key to the corresponding RX crypto.\n *\n * Return: \"true\" if the key has been scheduled for attaching, otherwise\n * \"false\".\n */\nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)\n{\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_aead_key *skey = NULL;\n\tu16 key_gen = msg_key_gen(hdr);\n\tu16 size = msg_data_sz(hdr);\n\tu8 *data = msg_data(hdr);\n\n\tspin_lock(&rx->lock);\n\tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n\t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n\t\t       rx->skey, key_gen, rx->key_gen);\n\t\tgoto exit;\n\t}\n\n\t/* Allocate memory for the key */\n\tskey = kmalloc(size, GFP_ATOMIC);\n\tif (unlikely(!skey)) {\n\t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\t/* Copy key from msg data */\n\tskey->keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n\tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n\tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n\t       skey->keylen);\n\n\t/* Sanity check */\n\tif (unlikely(size != tipc_aead_key_size(skey))) {\n\t\tkfree(skey);\n\t\tskey = NULL;\n\t\tgoto exit;\n\t}\n\n\trx->key_gen = key_gen;\n\trx->skey_mode = msg_key_mode(hdr);\n\trx->skey = skey;\n\trx->nokey = 0;\n\tmb(); /* for nokey flag */\n\nexit:\n\tspin_unlock(&rx->lock);\n\n\t/* Schedule the key attaching on this crypto */\n\tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n\t\treturn true;\n\n\treturn false;\n}\n\n/**\n * tipc_crypto_work_rx - Scheduled RX works handler\n * @work: the struct RX work\n *\n * The function processes the previous scheduled works i.e. distributing TX key\n * or attaching a received session key on RX crypto.\n */\nstatic void tipc_crypto_work_rx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *rx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tunsigned long delay = msecs_to_jiffies(5000);\n\tbool resched = false;\n\tu8 key;\n\tint rc;\n\n\t/* Case 1: Distribute TX key to peer if scheduled */\n\tif (atomic_cmpxchg(&rx->key_distr,\n\t\t\t   KEY_DISTR_SCHED,\n\t\t\t   KEY_DISTR_COMPL) == KEY_DISTR_SCHED) {\n\t\t/* Always pick the newest one for distributing */\n\t\tkey = tx->key.pending ?: tx->key.active;\n\t\trc = tipc_crypto_key_distr(tx, key, rx->node);\n\t\tif (unlikely(rc))\n\t\t\tpr_warn(\"%s: unable to distr key[%d] to %s, err %d\\n\",\n\t\t\t\ttx->name, key, tipc_node_get_id_str(rx->node),\n\t\t\t\trc);\n\n\t\t/* Sched for key_distr releasing */\n\t\tresched = true;\n\t} else {\n\t\tatomic_cmpxchg(&rx->key_distr, KEY_DISTR_COMPL, 0);\n\t}\n\n\t/* Case 2: Attach a pending received session key from peer if any */\n\tif (rx->skey) {\n\t\trc = tipc_crypto_key_init(rx, rx->skey, rx->skey_mode, false);\n\t\tif (unlikely(rc < 0))\n\t\t\tpr_warn(\"%s: unable to attach received skey, err %d\\n\",\n\t\t\t\trx->name, rc);\n\t\tswitch (rc) {\n\t\tcase -EBUSY:\n\t\tcase -ENOMEM:\n\t\t\t/* Resched the key attaching */\n\t\t\tresched = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsynchronize_rcu();\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (resched && queue_delayed_work(tx->wq, &rx->work, delay))\n\t\treturn;\n\n\ttipc_node_put(rx->node);\n}\n\n/**\n * tipc_crypto_rekeying_sched - (Re)schedule rekeying w/o new interval\n * @tx: TX crypto\n * @changed: if the rekeying needs to be rescheduled with new interval\n * @new_intv: new rekeying interval (when \"changed\" = true)\n */\nvoid tipc_crypto_rekeying_sched(struct tipc_crypto *tx, bool changed,\n\t\t\t\tu32 new_intv)\n{\n\tunsigned long delay;\n\tbool now = false;\n\n\tif (changed) {\n\t\tif (new_intv == TIPC_REKEYING_NOW)\n\t\t\tnow = true;\n\t\telse\n\t\t\ttx->rekeying_intv = new_intv;\n\t\tcancel_delayed_work_sync(&tx->work);\n\t}\n\n\tif (tx->rekeying_intv || now) {\n\t\tdelay = (now) ? 0 : tx->rekeying_intv * 60 * 1000;\n\t\tqueue_delayed_work(tx->wq, &tx->work, msecs_to_jiffies(delay));\n\t}\n}\n\n/**\n * tipc_crypto_work_tx - Scheduled TX works handler\n * @work: the struct TX work\n *\n * The function processes the previous scheduled work, i.e. key rekeying, by\n * generating a new session key based on current one, then attaching it to the\n * TX crypto and finally distributing it to peers. It also re-schedules the\n * rekeying if needed.\n */\nstatic void tipc_crypto_work_tx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *tx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_aead_key *skey = NULL;\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead;\n\tint rc = -ENOMEM;\n\n\tif (unlikely(key.pending))\n\t\tgoto resched;\n\n\t/* Take current key as a template */\n\trcu_read_lock();\n\taead = rcu_dereference(tx->aead[key.active ?: KEY_MASTER]);\n\tif (unlikely(!aead)) {\n\t\trcu_read_unlock();\n\t\t/* At least one key should exist for securing */\n\t\treturn;\n\t}\n\n\t/* Lets duplicate it first */\n\tskey = kmemdup(aead->key, tipc_aead_key_size(aead->key), GFP_ATOMIC);\n\trcu_read_unlock();\n\n\t/* Now, generate new key, initiate & distribute it */\n\tif (likely(skey)) {\n\t\trc = tipc_aead_key_generate(skey) ?:\n\t\t     tipc_crypto_key_init(tx, skey, PER_NODE_KEY, false);\n\t\tif (likely(rc > 0))\n\t\t\trc = tipc_crypto_key_distr(tx, rc, NULL);\n\t\tkfree_sensitive(skey);\n\t}\n\n\tif (unlikely(rc))\n\t\tpr_warn_ratelimited(\"%s: rekeying returns %d\\n\", tx->name, rc);\n\nresched:\n\t/* Re-schedule rekeying if any */\n\ttipc_crypto_rekeying_sched(tx, false, 0);\n}\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n * net/tipc/crypto.c: TIPC crypto for key handling & packet en/decryption\n *\n * Copyright (c) 2019, Ericsson AB\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the names of the copyright holders nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * Alternatively, this software may be distributed under the terms of the\n * GNU General Public License (\"GPL\") version 2 as published by the Free\n * Software Foundation.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <crypto/aead.h>\n#include <crypto/aes.h>\n#include <crypto/rng.h>\n#include \"crypto.h\"\n#include \"msg.h\"\n#include \"bcast.h\"\n\n#define TIPC_TX_GRACE_PERIOD\tmsecs_to_jiffies(5000) /* 5s */\n#define TIPC_TX_LASTING_TIME\tmsecs_to_jiffies(10000) /* 10s */\n#define TIPC_RX_ACTIVE_LIM\tmsecs_to_jiffies(3000) /* 3s */\n#define TIPC_RX_PASSIVE_LIM\tmsecs_to_jiffies(15000) /* 15s */\n\n#define TIPC_MAX_TFMS_DEF\t10\n#define TIPC_MAX_TFMS_LIM\t1000\n\n#define TIPC_REKEYING_INTV_DEF\t(60 * 24) /* default: 1 day */\n\n/*\n * TIPC Key ids\n */\nenum {\n\tKEY_MASTER = 0,\n\tKEY_MIN = KEY_MASTER,\n\tKEY_1 = 1,\n\tKEY_2,\n\tKEY_3,\n\tKEY_MAX = KEY_3,\n};\n\n/*\n * TIPC Crypto statistics\n */\nenum {\n\tSTAT_OK,\n\tSTAT_NOK,\n\tSTAT_ASYNC,\n\tSTAT_ASYNC_OK,\n\tSTAT_ASYNC_NOK,\n\tSTAT_BADKEYS, /* tx only */\n\tSTAT_BADMSGS = STAT_BADKEYS, /* rx only */\n\tSTAT_NOKEYS,\n\tSTAT_SWITCHES,\n\n\tMAX_STATS,\n};\n\n/* TIPC crypto statistics' header */\nstatic const char *hstats[MAX_STATS] = {\"ok\", \"nok\", \"async\", \"async_ok\",\n\t\t\t\t\t\"async_nok\", \"badmsgs\", \"nokeys\",\n\t\t\t\t\t\"switches\"};\n\n/* Max TFMs number per key */\nint sysctl_tipc_max_tfms __read_mostly = TIPC_MAX_TFMS_DEF;\n/* Key exchange switch, default: on */\nint sysctl_tipc_key_exchange_enabled __read_mostly = 1;\n\n/*\n * struct tipc_key - TIPC keys' status indicator\n *\n *         7     6     5     4     3     2     1     0\n *      +-----+-----+-----+-----+-----+-----+-----+-----+\n * key: | (reserved)|passive idx| active idx|pending idx|\n *      +-----+-----+-----+-----+-----+-----+-----+-----+\n */\nstruct tipc_key {\n#define KEY_BITS (2)\n#define KEY_MASK ((1 << KEY_BITS) - 1)\n\tunion {\n\t\tstruct {\n#if defined(__LITTLE_ENDIAN_BITFIELD)\n\t\t\tu8 pending:2,\n\t\t\t   active:2,\n\t\t\t   passive:2, /* rx only */\n\t\t\t   reserved:2;\n#elif defined(__BIG_ENDIAN_BITFIELD)\n\t\t\tu8 reserved:2,\n\t\t\t   passive:2, /* rx only */\n\t\t\t   active:2,\n\t\t\t   pending:2;\n#else\n#error  \"Please fix <asm/byteorder.h>\"\n#endif\n\t\t} __packed;\n\t\tu8 keys;\n\t};\n};\n\n/**\n * struct tipc_tfm - TIPC TFM structure to form a list of TFMs\n * @tfm: cipher handle/key\n * @list: linked list of TFMs\n */\nstruct tipc_tfm {\n\tstruct crypto_aead *tfm;\n\tstruct list_head list;\n};\n\n/**\n * struct tipc_aead - TIPC AEAD key structure\n * @tfm_entry: per-cpu pointer to one entry in TFM list\n * @crypto: TIPC crypto owns this key\n * @cloned: reference to the source key in case cloning\n * @users: the number of the key users (TX/RX)\n * @salt: the key's SALT value\n * @authsize: authentication tag size (max = 16)\n * @mode: crypto mode is applied to the key\n * @hint: a hint for user key\n * @rcu: struct rcu_head\n * @key: the aead key\n * @gen: the key's generation\n * @seqno: the key seqno (cluster scope)\n * @refcnt: the key reference counter\n */\nstruct tipc_aead {\n#define TIPC_AEAD_HINT_LEN (5)\n\tstruct tipc_tfm * __percpu *tfm_entry;\n\tstruct tipc_crypto *crypto;\n\tstruct tipc_aead *cloned;\n\tatomic_t users;\n\tu32 salt;\n\tu8 authsize;\n\tu8 mode;\n\tchar hint[2 * TIPC_AEAD_HINT_LEN + 1];\n\tstruct rcu_head rcu;\n\tstruct tipc_aead_key *key;\n\tu16 gen;\n\n\tatomic64_t seqno ____cacheline_aligned;\n\trefcount_t refcnt ____cacheline_aligned;\n\n} ____cacheline_aligned;\n\n/**\n * struct tipc_crypto_stats - TIPC Crypto statistics\n * @stat: array of crypto statistics\n */\nstruct tipc_crypto_stats {\n\tunsigned int stat[MAX_STATS];\n};\n\n/**\n * struct tipc_crypto - TIPC TX/RX crypto structure\n * @net: struct net\n * @node: TIPC node (RX)\n * @aead: array of pointers to AEAD keys for encryption/decryption\n * @peer_rx_active: replicated peer RX active key index\n * @key_gen: TX/RX key generation\n * @key: the key states\n * @skey_mode: session key's mode\n * @skey: received session key\n * @wq: common workqueue on TX crypto\n * @work: delayed work sched for TX/RX\n * @key_distr: key distributing state\n * @rekeying_intv: rekeying interval (in minutes)\n * @stats: the crypto statistics\n * @name: the crypto name\n * @sndnxt: the per-peer sndnxt (TX)\n * @timer1: general timer 1 (jiffies)\n * @timer2: general timer 2 (jiffies)\n * @working: the crypto is working or not\n * @key_master: flag indicates if master key exists\n * @legacy_user: flag indicates if a peer joins w/o master key (for bwd comp.)\n * @nokey: no key indication\n * @flags: combined flags field\n * @lock: tipc_key lock\n */\nstruct tipc_crypto {\n\tstruct net *net;\n\tstruct tipc_node *node;\n\tstruct tipc_aead __rcu *aead[KEY_MAX + 1];\n\tatomic_t peer_rx_active;\n\tu16 key_gen;\n\tstruct tipc_key key;\n\tu8 skey_mode;\n\tstruct tipc_aead_key *skey;\n\tstruct workqueue_struct *wq;\n\tstruct delayed_work work;\n#define KEY_DISTR_SCHED\t\t1\n#define KEY_DISTR_COMPL\t\t2\n\tatomic_t key_distr;\n\tu32 rekeying_intv;\n\n\tstruct tipc_crypto_stats __percpu *stats;\n\tchar name[48];\n\n\tatomic64_t sndnxt ____cacheline_aligned;\n\tunsigned long timer1;\n\tunsigned long timer2;\n\tunion {\n\t\tstruct {\n\t\t\tu8 working:1;\n\t\t\tu8 key_master:1;\n\t\t\tu8 legacy_user:1;\n\t\t\tu8 nokey: 1;\n\t\t};\n\t\tu8 flags;\n\t};\n\tspinlock_t lock; /* crypto lock */\n\n} ____cacheline_aligned;\n\n/* struct tipc_crypto_tx_ctx - TX context for callbacks */\nstruct tipc_crypto_tx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n\tstruct tipc_media_addr dst;\n};\n\n/* struct tipc_crypto_rx_ctx - RX context for callbacks */\nstruct tipc_crypto_rx_ctx {\n\tstruct tipc_aead *aead;\n\tstruct tipc_bearer *bearer;\n};\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead);\nstatic inline void tipc_aead_put(struct tipc_aead *aead);\nstatic void tipc_aead_free(struct rcu_head *rp);\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead);\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim);\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val);\nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead);\nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode);\nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src);\nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg);\nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode);\nstatic void tipc_aead_encrypt_done(struct crypto_async_request *base, int err);\nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b);\nstatic void tipc_aead_decrypt_done(struct crypto_async_request *base, int err);\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr);\nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx);\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending);\nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key);\nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending);\nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key);\nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb);\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key);\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type);\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err);\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd);\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf);\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf);\nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode);\nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr);\nstatic void tipc_crypto_work_tx(struct work_struct *work);\nstatic void tipc_crypto_work_rx(struct work_struct *work);\nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey);\n\n#define is_tx(crypto) (!(crypto)->node)\n#define is_rx(crypto) (!is_tx(crypto))\n\n#define key_next(cur) ((cur) % KEY_MAX + 1)\n\n#define tipc_aead_rcu_ptr(rcu_ptr, lock)\t\t\t\t\\\n\trcu_dereference_protected((rcu_ptr), lockdep_is_held(lock))\n\n#define tipc_aead_rcu_replace(rcu_ptr, ptr, lock)\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstruct tipc_aead *__tmp = rcu_dereference_protected((rcu_ptr),\t\\\n\t\t\t\t\t\tlockdep_is_held(lock));\t\\\n\trcu_assign_pointer((rcu_ptr), (ptr));\t\t\t\t\\\n\ttipc_aead_put(__tmp);\t\t\t\t\t\t\\\n} while (0)\n\n#define tipc_crypto_key_detach(rcu_ptr, lock)\t\t\t\t\\\n\ttipc_aead_rcu_replace((rcu_ptr), NULL, lock)\n\n/**\n * tipc_aead_key_validate - Validate a AEAD user key\n * @ukey: pointer to user key data\n * @info: netlink info pointer\n */\nint tipc_aead_key_validate(struct tipc_aead_key *ukey, struct genl_info *info)\n{\n\tint keylen;\n\n\t/* Check if algorithm exists */\n\tif (unlikely(!crypto_has_alg(ukey->alg_name, 0, 0))) {\n\t\tGENL_SET_ERR_MSG(info, \"unable to load the algorithm (module existed?)\");\n\t\treturn -ENODEV;\n\t}\n\n\t/* Currently, we only support the \"gcm(aes)\" cipher algorithm */\n\tif (strcmp(ukey->alg_name, \"gcm(aes)\")) {\n\t\tGENL_SET_ERR_MSG(info, \"not supported yet the algorithm\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\t/* Check if key size is correct */\n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\tif (unlikely(keylen != TIPC_AES_GCM_KEY_SIZE_128 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_192 &&\n\t\t     keylen != TIPC_AES_GCM_KEY_SIZE_256)) {\n\t\tGENL_SET_ERR_MSG(info, \"incorrect key length (20, 28 or 36 octets?)\");\n\t\treturn -EKEYREJECTED;\n\t}\n\n\treturn 0;\n}\n\n/**\n * tipc_aead_key_generate - Generate new session key\n * @skey: input/output key with new content\n *\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_aead_key_generate(struct tipc_aead_key *skey)\n{\n\tint rc = 0;\n\n\t/* Fill the key's content with a random value via RNG cipher */\n\trc = crypto_get_default_rng();\n\tif (likely(!rc)) {\n\t\trc = crypto_rng_get_bytes(crypto_default_rng, skey->key,\n\t\t\t\t\t  skey->keylen);\n\t\tcrypto_put_default_rng();\n\t}\n\n\treturn rc;\n}\n\nstatic struct tipc_aead *tipc_aead_get(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (unlikely(!tmp || !refcount_inc_not_zero(&tmp->refcnt)))\n\t\ttmp = NULL;\n\trcu_read_unlock();\n\n\treturn tmp;\n}\n\nstatic inline void tipc_aead_put(struct tipc_aead *aead)\n{\n\tif (aead && refcount_dec_and_test(&aead->refcnt))\n\t\tcall_rcu(&aead->rcu, tipc_aead_free);\n}\n\n/**\n * tipc_aead_free - Release AEAD key incl. all the TFMs in the list\n * @rp: rcu head pointer\n */\nstatic void tipc_aead_free(struct rcu_head *rp)\n{\n\tstruct tipc_aead *aead = container_of(rp, struct tipc_aead, rcu);\n\tstruct tipc_tfm *tfm_entry, *head, *tmp;\n\n\tif (aead->cloned) {\n\t\ttipc_aead_put(aead->cloned);\n\t} else {\n\t\thead = *get_cpu_ptr(aead->tfm_entry);\n\t\tput_cpu_ptr(aead->tfm_entry);\n\t\tlist_for_each_entry_safe(tfm_entry, tmp, &head->list, list) {\n\t\t\tcrypto_free_aead(tfm_entry->tfm);\n\t\t\tlist_del(&tfm_entry->list);\n\t\t\tkfree(tfm_entry);\n\t\t}\n\t\t/* Free the head */\n\t\tcrypto_free_aead(head->tfm);\n\t\tlist_del(&head->list);\n\t\tkfree(head);\n\t}\n\tfree_percpu(aead->tfm_entry);\n\tkfree_sensitive(aead->key);\n\tkfree(aead);\n}\n\nstatic int tipc_aead_users(struct tipc_aead __rcu *aead)\n{\n\tstruct tipc_aead *tmp;\n\tint users = 0;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tusers = atomic_read(&tmp->users);\n\trcu_read_unlock();\n\n\treturn users;\n}\n\nstatic void tipc_aead_users_inc(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&tmp->users, 1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_dec(struct tipc_aead __rcu *aead, int lim)\n{\n\tstruct tipc_aead *tmp;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp)\n\t\tatomic_add_unless(&rcu_dereference(aead)->users, -1, lim);\n\trcu_read_unlock();\n}\n\nstatic void tipc_aead_users_set(struct tipc_aead __rcu *aead, int val)\n{\n\tstruct tipc_aead *tmp;\n\tint cur;\n\n\trcu_read_lock();\n\ttmp = rcu_dereference(aead);\n\tif (tmp) {\n\t\tdo {\n\t\t\tcur = atomic_read(&tmp->users);\n\t\t\tif (cur == val)\n\t\t\t\tbreak;\n\t\t} while (atomic_cmpxchg(&tmp->users, cur, val) != cur);\n\t}\n\trcu_read_unlock();\n}\n\n/**\n * tipc_aead_tfm_next - Move TFM entry to the next one in list and return it\n * @aead: the AEAD key pointer\n */\nstatic struct crypto_aead *tipc_aead_tfm_next(struct tipc_aead *aead)\n{\n\tstruct tipc_tfm **tfm_entry;\n\tstruct crypto_aead *tfm;\n\n\ttfm_entry = get_cpu_ptr(aead->tfm_entry);\n\t*tfm_entry = list_next_entry(*tfm_entry, list);\n\ttfm = (*tfm_entry)->tfm;\n\tput_cpu_ptr(tfm_entry);\n\n\treturn tfm;\n}\n\n/**\n * tipc_aead_init - Initiate TIPC AEAD\n * @aead: returned new TIPC AEAD key handle pointer\n * @ukey: pointer to user key data\n * @mode: the key mode\n *\n * Allocate a (list of) new cipher transformation (TFM) with the specific user\n * key data if valid. The number of the allocated TFMs can be set via the sysfs\n * \"net/tipc/max_tfms\" first.\n * Also, all the other AEAD data are also initialized.\n *\n * Return: 0 if the initiation is successful, otherwise: < 0\n */\nstatic int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,\n\t\t\t  u8 mode)\n{\n\tstruct tipc_tfm *tfm_entry, *head;\n\tstruct crypto_aead *tfm;\n\tstruct tipc_aead *tmp;\n\tint keylen, err, cpu;\n\tint tfm_cnt = 0;\n\n\tif (unlikely(*aead))\n\t\treturn -EEXIST;\n\n\t/* Allocate a new AEAD */\n\ttmp = kzalloc(sizeof(*tmp), GFP_ATOMIC);\n\tif (unlikely(!tmp))\n\t\treturn -ENOMEM;\n\n\t/* The key consists of two parts: [AES-KEY][SALT] */\n\tkeylen = ukey->keylen - TIPC_AES_GCM_SALT_SIZE;\n\n\t/* Allocate per-cpu TFM entry pointer */\n\ttmp->tfm_entry = alloc_percpu(struct tipc_tfm *);\n\tif (!tmp->tfm_entry) {\n\t\tkfree_sensitive(tmp);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* Make a list of TFMs with the user key data */\n\tdo {\n\t\ttfm = crypto_alloc_aead(ukey->alg_name, 0, 0);\n\t\tif (IS_ERR(tfm)) {\n\t\t\terr = PTR_ERR(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(!tfm_cnt &&\n\t\t\t     crypto_aead_ivsize(tfm) != TIPC_AES_GCM_IV_SIZE)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = crypto_aead_setauthsize(tfm, TIPC_AES_GCM_TAG_SIZE);\n\t\terr |= crypto_aead_setkey(tfm, ukey->key, keylen);\n\t\tif (unlikely(err)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\tbreak;\n\t\t}\n\n\t\ttfm_entry = kmalloc(sizeof(*tfm_entry), GFP_KERNEL);\n\t\tif (unlikely(!tfm_entry)) {\n\t\t\tcrypto_free_aead(tfm);\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tINIT_LIST_HEAD(&tfm_entry->list);\n\t\ttfm_entry->tfm = tfm;\n\n\t\t/* First entry? */\n\t\tif (!tfm_cnt) {\n\t\t\thead = tfm_entry;\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t*per_cpu_ptr(tmp->tfm_entry, cpu) = head;\n\t\t\t}\n\t\t} else {\n\t\t\tlist_add_tail(&tfm_entry->list, &head->list);\n\t\t}\n\n\t} while (++tfm_cnt < sysctl_tipc_max_tfms);\n\n\t/* Not any TFM is allocated? */\n\tif (!tfm_cnt) {\n\t\tfree_percpu(tmp->tfm_entry);\n\t\tkfree_sensitive(tmp);\n\t\treturn err;\n\t}\n\n\t/* Form a hex string of some last bytes as the key's hint */\n\tbin2hex(tmp->hint, ukey->key + keylen - TIPC_AEAD_HINT_LEN,\n\t\tTIPC_AEAD_HINT_LEN);\n\n\t/* Initialize the other data */\n\ttmp->mode = mode;\n\ttmp->cloned = NULL;\n\ttmp->authsize = TIPC_AES_GCM_TAG_SIZE;\n\ttmp->key = kmemdup(ukey, tipc_aead_key_size(ukey), GFP_KERNEL);\n\tmemcpy(&tmp->salt, ukey->key + keylen, TIPC_AES_GCM_SALT_SIZE);\n\tatomic_set(&tmp->users, 0);\n\tatomic64_set(&tmp->seqno, 0);\n\trefcount_set(&tmp->refcnt, 1);\n\n\t*aead = tmp;\n\treturn 0;\n}\n\n/**\n * tipc_aead_clone - Clone a TIPC AEAD key\n * @dst: dest key for the cloning\n * @src: source key to clone from\n *\n * Make a \"copy\" of the source AEAD key data to the dest, the TFMs list is\n * common for the keys.\n * A reference to the source is hold in the \"cloned\" pointer for the later\n * freeing purposes.\n *\n * Note: this must be done in cluster-key mode only!\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src)\n{\n\tstruct tipc_aead *aead;\n\tint cpu;\n\n\tif (!src)\n\t\treturn -ENOKEY;\n\n\tif (src->mode != CLUSTER_KEY)\n\t\treturn -EINVAL;\n\n\tif (unlikely(*dst))\n\t\treturn -EEXIST;\n\n\taead = kzalloc(sizeof(*aead), GFP_ATOMIC);\n\tif (unlikely(!aead))\n\t\treturn -ENOMEM;\n\n\taead->tfm_entry = alloc_percpu_gfp(struct tipc_tfm *, GFP_ATOMIC);\n\tif (unlikely(!aead->tfm_entry)) {\n\t\tkfree_sensitive(aead);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor_each_possible_cpu(cpu) {\n\t\t*per_cpu_ptr(aead->tfm_entry, cpu) =\n\t\t\t\t*per_cpu_ptr(src->tfm_entry, cpu);\n\t}\n\n\tmemcpy(aead->hint, src->hint, sizeof(src->hint));\n\taead->mode = src->mode;\n\taead->salt = src->salt;\n\taead->authsize = src->authsize;\n\tatomic_set(&aead->users, 0);\n\tatomic64_set(&aead->seqno, 0);\n\trefcount_set(&aead->refcnt, 1);\n\n\tWARN_ON(!refcount_inc_not_zero(&src->refcnt));\n\taead->cloned = src;\n\n\t*dst = aead;\n\treturn 0;\n}\n\n/**\n * tipc_aead_mem_alloc - Allocate memory for AEAD request operations\n * @tfm: cipher handle to be registered with the request\n * @crypto_ctx_size: size of crypto context for callback\n * @iv: returned pointer to IV data\n * @req: returned pointer to AEAD request data\n * @sg: returned pointer to SG lists\n * @nsg: number of SG lists to be allocated\n *\n * Allocate memory to store the crypto context data, AEAD request, IV and SG\n * lists, the memory layout is as follows:\n * crypto_ctx || iv || aead_req || sg[]\n *\n * Return: the pointer to the memory areas in case of success, otherwise NULL\n */\nstatic void *tipc_aead_mem_alloc(struct crypto_aead *tfm,\n\t\t\t\t unsigned int crypto_ctx_size,\n\t\t\t\t u8 **iv, struct aead_request **req,\n\t\t\t\t struct scatterlist **sg, int nsg)\n{\n\tunsigned int iv_size, req_size;\n\tunsigned int len;\n\tu8 *mem;\n\n\tiv_size = crypto_aead_ivsize(tfm);\n\treq_size = sizeof(**req) + crypto_aead_reqsize(tfm);\n\n\tlen = crypto_ctx_size;\n\tlen += iv_size;\n\tlen += crypto_aead_alignmask(tfm) & ~(crypto_tfm_ctx_alignment() - 1);\n\tlen = ALIGN(len, crypto_tfm_ctx_alignment());\n\tlen += req_size;\n\tlen = ALIGN(len, __alignof__(struct scatterlist));\n\tlen += nsg * sizeof(**sg);\n\n\tmem = kmalloc(len, GFP_ATOMIC);\n\tif (!mem)\n\t\treturn NULL;\n\n\t*iv = (u8 *)PTR_ALIGN(mem + crypto_ctx_size,\n\t\t\t      crypto_aead_alignmask(tfm) + 1);\n\t*req = (struct aead_request *)PTR_ALIGN(*iv + iv_size,\n\t\t\t\t\t\tcrypto_tfm_ctx_alignment());\n\t*sg = (struct scatterlist *)PTR_ALIGN((u8 *)*req + req_size,\n\t\t\t\t\t      __alignof__(struct scatterlist));\n\n\treturn (void *)mem;\n}\n\n/**\n * tipc_aead_encrypt - Encrypt a message\n * @aead: TIPC AEAD key for the message encryption\n * @skb: the input/output skb\n * @b: TIPC bearer where the message will be delivered after the encryption\n * @dst: the destination media address\n * @__dnode: TIPC dest node if \"known\"\n *\n * Return:\n * * 0                   : if the encryption has completed\n * * -EINPROGRESS/-EBUSY : if a callback will be performed\n * * < 0                 : the encryption has failed\n */\nstatic int tipc_aead_encrypt(struct tipc_aead *aead, struct sk_buff *skb,\n\t\t\t     struct tipc_bearer *b,\n\t\t\t     struct tipc_media_addr *dst,\n\t\t\t     struct tipc_node *__dnode)\n{\n\tstruct crypto_aead *tfm = tipc_aead_tfm_next(aead);\n\tstruct tipc_crypto_tx_ctx *tx_ctx;\n\tstruct aead_request *req;\n\tstruct sk_buff *trailer;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, len, tailen, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\t/* Make sure message len at least 4-byte aligned */\n\tlen = ALIGN(skb->len, 4);\n\ttailen = len - skb->len + aead->authsize;\n\n\t/* Expand skb tail for authentication tag:\n\t * As for simplicity, we'd have made sure skb having enough tailroom\n\t * for authentication tag @skb allocation. Even when skb is nonlinear\n\t * but there is no frag_list, it should be still fine!\n\t * Otherwise, we must cow it to be a writable buffer with the tailroom.\n\t */\n\tSKB_LINEAR_ASSERT(skb);\n\tif (tailen > skb_tailroom(skb)) {\n\t\tpr_debug(\"TX(): skb tailroom is not enough: %d, requires: %d\\n\",\n\t\t\t skb_tailroom(skb), tailen);\n\t}\n\n\tif (unlikely(!skb_cloned(skb) && tailen <= skb_tailroom(skb))) {\n\t\tnsg = 1;\n\t\ttrailer = skb;\n\t} else {\n\t\t/* TODO: We could avoid skb_cow_data() if skb has no frag_list\n\t\t * e.g. by skb_fill_page_desc() to add another page to the skb\n\t\t * with the wanted tailen... However, page skbs look not often,\n\t\t * so take it easy now!\n\t\t * Cloned skbs e.g. from link_xmit() seems no choice though :(\n\t\t */\n\t\tnsg = skb_cow_data(skb, tailen, &trailer);\n\t\tif (unlikely(nsg < 0)) {\n\t\t\tpr_err(\"TX: skb_cow_data() returned %d\\n\", nsg);\n\t\t\treturn nsg;\n\t\t}\n\t}\n\n\tpskb_put(skb, trailer, tailen);\n\n\t/* Allocate memory for the AEAD operation */\n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*tx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t/* Map skb to the sg lists */\n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"TX: skb_to_sgvec() returned %d, nsg %d!\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t/* Prepare IV: [SALT (4 octets)][SEQNO (8 octets)]\n\t * In case we're in cluster-key mode, SALT is varied by xor-ing with\n\t * the source address (or w0 of id), otherwise with the dest address\n\t * if dest is known.\n\t */\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (__dnode)\n\t\tsalt ^= tipc_node_get_addr(__dnode);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t/* Prepare request */\n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, len - ehsz, iv);\n\n\t/* Set callback function & data */\n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_encrypt_done, skb);\n\ttx_ctx = (struct tipc_crypto_tx_ctx *)ctx;\n\ttx_ctx->aead = aead;\n\ttx_ctx->bearer = b;\n\tmemcpy(&tx_ctx->dst, dst, sizeof(*dst));\n\n\t/* Hold bearer */\n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t/* Now, do encrypt */\n\trc = crypto_aead_encrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_encrypt_done(struct crypto_async_request *base, int err)\n{\n\tstruct sk_buff *skb = base->data;\n\tstruct tipc_crypto_tx_ctx *tx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = tx_ctx->bearer;\n\tstruct tipc_aead *aead = tx_ctx->aead;\n\tstruct tipc_crypto *tx = aead->crypto;\n\tstruct net *net = tx->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_OK]);\n\t\trcu_read_lock();\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\tb->media->send_msg(net, skb, b, &tx_ctx->dst);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t\trcu_read_unlock();\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(tx->stats->stat[STAT_ASYNC_NOK]);\n\t\tkfree_skb(skb);\n\t\tbreak;\n\t}\n\n\tkfree(tx_ctx);\n\ttipc_bearer_put(b);\n\ttipc_aead_put(aead);\n}\n\n/**\n * tipc_aead_decrypt - Decrypt an encrypted message\n * @net: struct net\n * @aead: TIPC AEAD for the message decryption\n * @skb: the input/output skb\n * @b: TIPC bearer where the message has been received\n *\n * Return:\n * * 0                   : if the decryption has completed\n * * -EINPROGRESS/-EBUSY : if a callback will be performed\n * * < 0                 : the decryption has failed\n */\nstatic int tipc_aead_decrypt(struct net *net, struct tipc_aead *aead,\n\t\t\t     struct sk_buff *skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto_rx_ctx *rx_ctx;\n\tstruct aead_request *req;\n\tstruct crypto_aead *tfm;\n\tstruct sk_buff *unused;\n\tstruct scatterlist *sg;\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz, nsg, rc;\n\tvoid *ctx;\n\tu32 salt;\n\tu8 *iv;\n\n\tif (unlikely(!aead))\n\t\treturn -ENOKEY;\n\n\tnsg = skb_cow_data(skb, 0, &unused);\n\tif (unlikely(nsg < 0)) {\n\t\tpr_err(\"RX: skb_cow_data() returned %d\\n\", nsg);\n\t\treturn nsg;\n\t}\n\n\t/* Allocate memory for the AEAD operation */\n\ttfm = tipc_aead_tfm_next(aead);\n\tctx = tipc_aead_mem_alloc(tfm, sizeof(*rx_ctx), &iv, &req, &sg, nsg);\n\tif (unlikely(!ctx))\n\t\treturn -ENOMEM;\n\tTIPC_SKB_CB(skb)->crypto_ctx = ctx;\n\n\t/* Map skb to the sg lists */\n\tsg_init_table(sg, nsg);\n\trc = skb_to_sgvec(skb, sg, 0, skb->len);\n\tif (unlikely(rc < 0)) {\n\t\tpr_err(\"RX: skb_to_sgvec() returned %d, nsg %d\\n\", rc, nsg);\n\t\tgoto exit;\n\t}\n\n\t/* Reconstruct IV: */\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tsalt = aead->salt;\n\tif (aead->mode == CLUSTER_KEY)\n\t\tsalt ^= __be32_to_cpu(ehdr->addr);\n\telse if (ehdr->destined)\n\t\tsalt ^= tipc_own_addr(net);\n\tmemcpy(iv, &salt, 4);\n\tmemcpy(iv + 4, (u8 *)&ehdr->seqno, 8);\n\n\t/* Prepare request */\n\tehsz = tipc_ehdr_size(ehdr);\n\taead_request_set_tfm(req, tfm);\n\taead_request_set_ad(req, ehsz);\n\taead_request_set_crypt(req, sg, sg, skb->len - ehsz, iv);\n\n\t/* Set callback function & data */\n\taead_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t  tipc_aead_decrypt_done, skb);\n\trx_ctx = (struct tipc_crypto_rx_ctx *)ctx;\n\trx_ctx->aead = aead;\n\trx_ctx->bearer = b;\n\n\t/* Hold bearer */\n\tif (unlikely(!tipc_bearer_hold(b))) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t/* Now, do decrypt */\n\trc = crypto_aead_decrypt(req);\n\tif (rc == -EINPROGRESS || rc == -EBUSY)\n\t\treturn rc;\n\n\ttipc_bearer_put(b);\n\nexit:\n\tkfree(ctx);\n\tTIPC_SKB_CB(skb)->crypto_ctx = NULL;\n\treturn rc;\n}\n\nstatic void tipc_aead_decrypt_done(struct crypto_async_request *base, int err)\n{\n\tstruct sk_buff *skb = base->data;\n\tstruct tipc_crypto_rx_ctx *rx_ctx = TIPC_SKB_CB(skb)->crypto_ctx;\n\tstruct tipc_bearer *b = rx_ctx->bearer;\n\tstruct tipc_aead *aead = rx_ctx->aead;\n\tstruct tipc_crypto_stats __percpu *stats = aead->crypto->stats;\n\tstruct net *net = aead->crypto->net;\n\n\tswitch (err) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\t\treturn;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC_NOK]);\n\t\tbreak;\n\t}\n\n\tkfree(rx_ctx);\n\ttipc_crypto_rcv_complete(net, aead, b, &skb, err);\n\tif (likely(skb)) {\n\t\tif (likely(test_bit(0, &b->up)))\n\t\t\ttipc_rcv(net, skb, b);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t}\n\n\ttipc_bearer_put(b);\n}\n\nstatic inline int tipc_ehdr_size(struct tipc_ehdr *ehdr)\n{\n\treturn (ehdr->user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n}\n\n/**\n * tipc_ehdr_validate - Validate an encryption message\n * @skb: the message buffer\n *\n * Return: \"true\" if this is a valid encryption message, otherwise \"false\"\n */\nbool tipc_ehdr_validate(struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr;\n\tint ehsz;\n\n\tif (unlikely(!pskb_may_pull(skb, EHDR_MIN_SIZE)))\n\t\treturn false;\n\n\tehdr = (struct tipc_ehdr *)skb->data;\n\tif (unlikely(ehdr->version != TIPC_EVERSION))\n\t\treturn false;\n\tehsz = tipc_ehdr_size(ehdr);\n\tif (unlikely(!pskb_may_pull(skb, ehsz)))\n\t\treturn false;\n\tif (unlikely(skb->len <= ehsz + TIPC_AES_GCM_TAG_SIZE))\n\t\treturn false;\n\n\treturn true;\n}\n\n/**\n * tipc_ehdr_build - Build TIPC encryption message header\n * @net: struct net\n * @aead: TX AEAD key to be used for the message encryption\n * @tx_key: key id used for the message encryption\n * @skb: input/output message skb\n * @__rx: RX crypto handle if dest is \"known\"\n *\n * Return: the header size if the building is successful, otherwise < 0\n */\nstatic int tipc_ehdr_build(struct net *net, struct tipc_aead *aead,\n\t\t\t   u8 tx_key, struct sk_buff *skb,\n\t\t\t   struct tipc_crypto *__rx)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_ehdr *ehdr;\n\tu32 user = msg_user(hdr);\n\tu64 seqno;\n\tint ehsz;\n\n\t/* Make room for encryption header */\n\tehsz = (user != LINK_CONFIG) ? EHDR_SIZE : EHDR_CFG_SIZE;\n\tWARN_ON(skb_headroom(skb) < ehsz);\n\tehdr = (struct tipc_ehdr *)skb_push(skb, ehsz);\n\n\t/* Obtain a seqno first:\n\t * Use the key seqno (= cluster wise) if dest is unknown or we're in\n\t * cluster key mode, otherwise it's better for a per-peer seqno!\n\t */\n\tif (!__rx || aead->mode == CLUSTER_KEY)\n\t\tseqno = atomic64_inc_return(&aead->seqno);\n\telse\n\t\tseqno = atomic64_inc_return(&__rx->sndnxt);\n\n\t/* Revoke the key if seqno is wrapped around */\n\tif (unlikely(!seqno))\n\t\treturn tipc_crypto_key_revoke(net, tx_key);\n\n\t/* Word 1-2 */\n\tehdr->seqno = cpu_to_be64(seqno);\n\n\t/* Words 0, 3- */\n\tehdr->version = TIPC_EVERSION;\n\tehdr->user = 0;\n\tehdr->keepalive = 0;\n\tehdr->tx_key = tx_key;\n\tehdr->destined = (__rx) ? 1 : 0;\n\tehdr->rx_key_active = (__rx) ? __rx->key.active : 0;\n\tehdr->rx_nokey = (__rx) ? __rx->nokey : 0;\n\tehdr->master_key = aead->crypto->key_master;\n\tehdr->reserved_1 = 0;\n\tehdr->reserved_2 = 0;\n\n\tswitch (user) {\n\tcase LINK_CONFIG:\n\t\tehdr->user = LINK_CONFIG;\n\t\tmemcpy(ehdr->id, tipc_own_id(net), NODE_ID_LEN);\n\t\tbreak;\n\tdefault:\n\t\tif (user == LINK_PROTOCOL && msg_type(hdr) == STATE_MSG) {\n\t\t\tehdr->user = LINK_PROTOCOL;\n\t\t\tehdr->keepalive = msg_is_keepalive(hdr);\n\t\t}\n\t\tehdr->addr = hdr->hdr[3];\n\t\tbreak;\n\t}\n\n\treturn ehsz;\n}\n\nstatic inline void tipc_crypto_key_set_state(struct tipc_crypto *c,\n\t\t\t\t\t     u8 new_passive,\n\t\t\t\t\t     u8 new_active,\n\t\t\t\t\t     u8 new_pending)\n{\n\tstruct tipc_key old = c->key;\n\tchar buf[32];\n\n\tc->key.keys = ((new_passive & KEY_MASK) << (KEY_BITS * 2)) |\n\t\t      ((new_active  & KEY_MASK) << (KEY_BITS)) |\n\t\t      ((new_pending & KEY_MASK));\n\n\tpr_debug(\"%s: key changing %s ::%pS\\n\", c->name,\n\t\t tipc_key_change_dump(old, c->key, buf),\n\t\t __builtin_return_address(0));\n}\n\n/**\n * tipc_crypto_key_init - Initiate a new user / AEAD key\n * @c: TIPC crypto to which new key is attached\n * @ukey: the user key\n * @mode: the key mode (CLUSTER_KEY or PER_NODE_KEY)\n * @master_key: specify this is a cluster master key\n *\n * A new TIPC AEAD key will be allocated and initiated with the specified user\n * key, then attached to the TIPC crypto.\n *\n * Return: new key id in case of success, otherwise: < 0\n */\nint tipc_crypto_key_init(struct tipc_crypto *c, struct tipc_aead_key *ukey,\n\t\t\t u8 mode, bool master_key)\n{\n\tstruct tipc_aead *aead = NULL;\n\tint rc = 0;\n\n\t/* Initiate with the new user key */\n\trc = tipc_aead_init(&aead, ukey, mode);\n\n\t/* Attach it to the crypto */\n\tif (likely(!rc)) {\n\t\trc = tipc_crypto_key_attach(c, aead, 0, master_key);\n\t\tif (rc < 0)\n\t\t\ttipc_aead_free(&aead->rcu);\n\t}\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_attach - Attach a new AEAD key to TIPC crypto\n * @c: TIPC crypto to which the new AEAD key is attached\n * @aead: the new AEAD key pointer\n * @pos: desired slot in the crypto key array, = 0 if any!\n * @master_key: specify this is a cluster master key\n *\n * Return: new key id in case of success, otherwise: -EBUSY\n */\nstatic int tipc_crypto_key_attach(struct tipc_crypto *c,\n\t\t\t\t  struct tipc_aead *aead, u8 pos,\n\t\t\t\t  bool master_key)\n{\n\tstruct tipc_key key;\n\tint rc = -EBUSY;\n\tu8 new_key;\n\n\tspin_lock_bh(&c->lock);\n\tkey = c->key;\n\tif (master_key) {\n\t\tnew_key = KEY_MASTER;\n\t\tgoto attach;\n\t}\n\tif (key.active && key.passive)\n\t\tgoto exit;\n\tif (key.pending) {\n\t\tif (tipc_aead_users(c->aead[key.pending]) > 0)\n\t\t\tgoto exit;\n\t\t/* if (pos): ok with replacing, will be aligned when needed */\n\t\t/* Replace it */\n\t\tnew_key = key.pending;\n\t} else {\n\t\tif (pos) {\n\t\t\tif (key.active && pos != key_next(key.active)) {\n\t\t\t\tkey.passive = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t} else if (!key.active && !key.passive) {\n\t\t\t\tkey.pending = pos;\n\t\t\t\tnew_key = pos;\n\t\t\t\tgoto attach;\n\t\t\t}\n\t\t}\n\t\tkey.pending = key_next(key.active ?: key.passive);\n\t\tnew_key = key.pending;\n\t}\n\nattach:\n\taead->crypto = c;\n\taead->gen = (is_tx(c)) ? ++c->key_gen : c->key_gen;\n\ttipc_aead_rcu_replace(c->aead[new_key], aead, &c->lock);\n\tif (likely(c->key.keys != key.keys))\n\t\ttipc_crypto_key_set_state(c, key.passive, key.active,\n\t\t\t\t\t  key.pending);\n\tc->working = 1;\n\tc->nokey = 0;\n\tc->key_master |= master_key;\n\trc = new_key;\n\nexit:\n\tspin_unlock_bh(&c->lock);\n\treturn rc;\n}\n\nvoid tipc_crypto_key_flush(struct tipc_crypto *c)\n{\n\tstruct tipc_crypto *tx, *rx;\n\tint k;\n\n\tspin_lock_bh(&c->lock);\n\tif (is_rx(c)) {\n\t\t/* Try to cancel pending work */\n\t\trx = c;\n\t\ttx = tipc_net(rx->net)->crypto_tx;\n\t\tif (cancel_delayed_work(&rx->work)) {\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tatomic_xchg(&rx->key_distr, 0);\n\t\t\ttipc_node_put(rx->node);\n\t\t}\n\t\t/* RX stopping => decrease TX key users if any */\n\t\tk = atomic_xchg(&rx->peer_rx_active, 0);\n\t\tif (k) {\n\t\t\ttipc_aead_users_dec(tx->aead[k], 0);\n\t\t\t/* Mark the point TX key users changed */\n\t\t\ttx->timer1 = jiffies;\n\t\t}\n\t}\n\n\tc->flags = 0;\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_crypto_key_detach(c->aead[k], &c->lock);\n\tatomic64_set(&c->sndnxt, 0);\n\tspin_unlock_bh(&c->lock);\n}\n\n/**\n * tipc_crypto_key_try_align - Align RX keys if possible\n * @rx: RX crypto handle\n * @new_pending: new pending slot if aligned (= TX key from peer)\n *\n * Peer has used an unknown key slot, this only happens when peer has left and\n * rejoned, or we are newcomer.\n * That means, there must be no active key but a pending key at unaligned slot.\n * If so, we try to move the pending key to the new slot.\n * Note: A potential passive key can exist, it will be shifted correspondingly!\n *\n * Return: \"true\" if key is successfully aligned, otherwise \"false\"\n */\nstatic bool tipc_crypto_key_try_align(struct tipc_crypto *rx, u8 new_pending)\n{\n\tstruct tipc_aead *tmp1, *tmp2 = NULL;\n\tstruct tipc_key key;\n\tbool aligned = false;\n\tu8 new_passive = 0;\n\tint x;\n\n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (key.pending == new_pending) {\n\t\taligned = true;\n\t\tgoto exit;\n\t}\n\tif (key.active)\n\t\tgoto exit;\n\tif (!key.pending)\n\t\tgoto exit;\n\tif (tipc_aead_users(rx->aead[key.pending]) > 0)\n\t\tgoto exit;\n\n\t/* Try to \"isolate\" this pending key first */\n\ttmp1 = tipc_aead_rcu_ptr(rx->aead[key.pending], &rx->lock);\n\tif (!refcount_dec_if_one(&tmp1->refcnt))\n\t\tgoto exit;\n\trcu_assign_pointer(rx->aead[key.pending], NULL);\n\n\t/* Move passive key if any */\n\tif (key.passive) {\n\t\ttmp2 = rcu_replace_pointer(rx->aead[key.passive], tmp2, lockdep_is_held(&rx->lock));\n\t\tx = (key.passive - key.pending + new_pending) % KEY_MAX;\n\t\tnew_passive = (x <= 0) ? x + KEY_MAX : x;\n\t}\n\n\t/* Re-allocate the key(s) */\n\ttipc_crypto_key_set_state(rx, new_passive, 0, new_pending);\n\trcu_assign_pointer(rx->aead[new_pending], tmp1);\n\tif (new_passive)\n\t\trcu_assign_pointer(rx->aead[new_passive], tmp2);\n\trefcount_set(&tmp1->refcnt, 1);\n\taligned = true;\n\tpr_info_ratelimited(\"%s: key[%d] -> key[%d]\\n\", rx->name, key.pending,\n\t\t\t    new_pending);\n\nexit:\n\tspin_unlock(&rx->lock);\n\treturn aligned;\n}\n\n/**\n * tipc_crypto_key_pick_tx - Pick one TX key for message decryption\n * @tx: TX crypto handle\n * @rx: RX crypto handle (can be NULL)\n * @skb: the message skb which will be decrypted later\n * @tx_key: peer TX key id\n *\n * This function looks up the existing TX keys and pick one which is suitable\n * for the message decryption, that must be a cluster key and not used before\n * on the same message (i.e. recursive).\n *\n * Return: the TX AEAD key handle in case of success, otherwise NULL\n */\nstatic struct tipc_aead *tipc_crypto_key_pick_tx(struct tipc_crypto *tx,\n\t\t\t\t\t\t struct tipc_crypto *rx,\n\t\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t\t u8 tx_key)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(skb);\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key = tx->key;\n\tu8 k, i = 0;\n\n\t/* Initialize data if not yet */\n\tif (!skb_cb->tx_clone_deferred) {\n\t\tskb_cb->tx_clone_deferred = 1;\n\t\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\t}\n\n\tskb_cb->tx_clone_ctx.rx = rx;\n\tif (++skb_cb->tx_clone_ctx.recurs > 2)\n\t\treturn NULL;\n\n\t/* Pick one TX key */\n\tspin_lock(&tx->lock);\n\tif (tx_key == KEY_MASTER) {\n\t\taead = tipc_aead_rcu_ptr(tx->aead[KEY_MASTER], &tx->lock);\n\t\tgoto done;\n\t}\n\tdo {\n\t\tk = (i == 0) ? key.pending :\n\t\t\t((i == 1) ? key.active : key.passive);\n\t\tif (!k)\n\t\t\tcontinue;\n\t\taead = tipc_aead_rcu_ptr(tx->aead[k], &tx->lock);\n\t\tif (!aead)\n\t\t\tcontinue;\n\t\tif (aead->mode != CLUSTER_KEY ||\n\t\t    aead == skb_cb->tx_clone_ctx.last) {\n\t\t\taead = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\t/* Ok, found one cluster key */\n\t\tskb_cb->tx_clone_ctx.last = aead;\n\t\tWARN_ON(skb->next);\n\t\tskb->next = skb_clone(skb, GFP_ATOMIC);\n\t\tif (unlikely(!skb->next))\n\t\t\tpr_warn(\"Failed to clone skb for next round if any\\n\");\n\t\tbreak;\n\t} while (++i < 3);\n\ndone:\n\tif (likely(aead))\n\t\tWARN_ON(!refcount_inc_not_zero(&aead->refcnt));\n\tspin_unlock(&tx->lock);\n\n\treturn aead;\n}\n\n/**\n * tipc_crypto_key_synch: Synch own key data according to peer key status\n * @rx: RX crypto handle\n * @skb: TIPCv2 message buffer (incl. the ehdr from peer)\n *\n * This function updates the peer node related data as the peer RX active key\n * has changed, so the number of TX keys' users on this node are increased and\n * decreased correspondingly.\n *\n * It also considers if peer has no key, then we need to make own master key\n * (if any) taking over i.e. starting grace period and also trigger key\n * distributing process.\n *\n * The \"per-peer\" sndnxt is also reset when the peer key has switched.\n */\nstatic void tipc_crypto_key_synch(struct tipc_crypto *rx, struct sk_buff *skb)\n{\n\tstruct tipc_ehdr *ehdr = (struct tipc_ehdr *)skb_network_header(skb);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tu32 self = tipc_own_addr(rx->net);\n\tu8 cur, new;\n\tunsigned long delay;\n\n\t/* Update RX 'key_master' flag according to peer, also mark \"legacy\" if\n\t * a peer has no master key.\n\t */\n\trx->key_master = ehdr->master_key;\n\tif (!rx->key_master)\n\t\ttx->legacy_user = 1;\n\n\t/* For later cases, apply only if message is destined to this node */\n\tif (!ehdr->destined || msg_short(hdr) || msg_destnode(hdr) != self)\n\t\treturn;\n\n\t/* Case 1: Peer has no keys, let's make master key take over */\n\tif (ehdr->rx_nokey) {\n\t\t/* Set or extend grace period */\n\t\ttx->timer2 = jiffies;\n\t\t/* Schedule key distributing for the peer if not yet */\n\t\tif (tx->key.keys &&\n\t\t    !atomic_cmpxchg(&rx->key_distr, 0, KEY_DISTR_SCHED)) {\n\t\t\tget_random_bytes(&delay, 2);\n\t\t\tdelay %= 5;\n\t\t\tdelay = msecs_to_jiffies(500 * ++delay);\n\t\t\tif (queue_delayed_work(tx->wq, &rx->work, delay))\n\t\t\t\ttipc_node_get(rx->node);\n\t\t}\n\t} else {\n\t\t/* Cancel a pending key distributing if any */\n\t\tatomic_xchg(&rx->key_distr, 0);\n\t}\n\n\t/* Case 2: Peer RX active key has changed, let's update own TX users */\n\tcur = atomic_read(&rx->peer_rx_active);\n\tnew = ehdr->rx_key_active;\n\tif (tx->key.keys &&\n\t    cur != new &&\n\t    atomic_cmpxchg(&rx->peer_rx_active, cur, new) == cur) {\n\t\tif (new)\n\t\t\ttipc_aead_users_inc(tx->aead[new], INT_MAX);\n\t\tif (cur)\n\t\t\ttipc_aead_users_dec(tx->aead[cur], 0);\n\n\t\tatomic64_set(&rx->sndnxt, 0);\n\t\t/* Mark the point TX key users changed */\n\t\ttx->timer1 = jiffies;\n\n\t\tpr_debug(\"%s: key users changed %d-- %d++, peer %s\\n\",\n\t\t\t tx->name, cur, new, rx->name);\n\t}\n}\n\nstatic int tipc_crypto_key_revoke(struct net *net, u8 tx_key)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_key key;\n\n\tspin_lock(&tx->lock);\n\tkey = tx->key;\n\tWARN_ON(!key.active || tx_key != key.active);\n\n\t/* Free the active key */\n\ttipc_crypto_key_set_state(tx, key.passive, 0, key.pending);\n\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tspin_unlock(&tx->lock);\n\n\tpr_warn(\"%s: key is revoked\\n\", tx->name);\n\treturn -EKEYREVOKED;\n}\n\nint tipc_crypto_start(struct tipc_crypto **crypto, struct net *net,\n\t\t      struct tipc_node *node)\n{\n\tstruct tipc_crypto *c;\n\n\tif (*crypto)\n\t\treturn -EEXIST;\n\n\t/* Allocate crypto */\n\tc = kzalloc(sizeof(*c), GFP_ATOMIC);\n\tif (!c)\n\t\treturn -ENOMEM;\n\n\t/* Allocate workqueue on TX */\n\tif (!node) {\n\t\tc->wq = alloc_ordered_workqueue(\"tipc_crypto\", 0);\n\t\tif (!c->wq) {\n\t\t\tkfree(c);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t/* Allocate statistic structure */\n\tc->stats = alloc_percpu_gfp(struct tipc_crypto_stats, GFP_ATOMIC);\n\tif (!c->stats) {\n\t\tif (c->wq)\n\t\t\tdestroy_workqueue(c->wq);\n\t\tkfree_sensitive(c);\n\t\treturn -ENOMEM;\n\t}\n\n\tc->flags = 0;\n\tc->net = net;\n\tc->node = node;\n\tget_random_bytes(&c->key_gen, 2);\n\ttipc_crypto_key_set_state(c, 0, 0, 0);\n\tatomic_set(&c->key_distr, 0);\n\tatomic_set(&c->peer_rx_active, 0);\n\tatomic64_set(&c->sndnxt, 0);\n\tc->timer1 = jiffies;\n\tc->timer2 = jiffies;\n\tc->rekeying_intv = TIPC_REKEYING_INTV_DEF;\n\tspin_lock_init(&c->lock);\n\tscnprintf(c->name, 48, \"%s(%s)\", (is_rx(c)) ? \"RX\" : \"TX\",\n\t\t  (is_rx(c)) ? tipc_node_get_id_str(c->node) :\n\t\t\t       tipc_own_id_string(c->net));\n\n\tif (is_rx(c))\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_rx);\n\telse\n\t\tINIT_DELAYED_WORK(&c->work, tipc_crypto_work_tx);\n\n\t*crypto = c;\n\treturn 0;\n}\n\nvoid tipc_crypto_stop(struct tipc_crypto **crypto)\n{\n\tstruct tipc_crypto *c = *crypto;\n\tu8 k;\n\n\tif (!c)\n\t\treturn;\n\n\t/* Flush any queued works & destroy wq */\n\tif (is_tx(c)) {\n\t\tc->rekeying_intv = 0;\n\t\tcancel_delayed_work_sync(&c->work);\n\t\tdestroy_workqueue(c->wq);\n\t}\n\n\t/* Release AEAD keys */\n\trcu_read_lock();\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++)\n\t\ttipc_aead_put(rcu_dereference(c->aead[k]));\n\trcu_read_unlock();\n\tpr_debug(\"%s: has been stopped\\n\", c->name);\n\n\t/* Free this crypto statistics */\n\tfree_percpu(c->stats);\n\n\t*crypto = NULL;\n\tkfree_sensitive(c);\n}\n\nvoid tipc_crypto_timeout(struct tipc_crypto *rx)\n{\n\tstruct tipc_net *tn = tipc_net(rx->net);\n\tstruct tipc_crypto *tx = tn->crypto_tx;\n\tstruct tipc_key key;\n\tint cmd;\n\n\t/* TX pending: taking all users & stable -> active */\n\tspin_lock(&tx->lock);\n\tkey = tx->key;\n\tif (key.active && tipc_aead_users(tx->aead[key.active]) > 0)\n\t\tgoto s1;\n\tif (!key.pending || tipc_aead_users(tx->aead[key.pending]) <= 0)\n\t\tgoto s1;\n\tif (time_before(jiffies, tx->timer1 + TIPC_TX_LASTING_TIME))\n\t\tgoto s1;\n\n\ttipc_crypto_key_set_state(tx, key.passive, key.pending, 0);\n\tif (key.active)\n\t\ttipc_crypto_key_detach(tx->aead[key.active], &tx->lock);\n\tthis_cpu_inc(tx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", tx->name, key.pending);\n\ns1:\n\tspin_unlock(&tx->lock);\n\n\t/* RX pending: having user -> active */\n\tspin_lock(&rx->lock);\n\tkey = rx->key;\n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) <= 0)\n\t\tgoto s2;\n\n\tif (key.active)\n\t\tkey.passive = key.active;\n\tkey.active = key.pending;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\tthis_cpu_inc(rx->stats->stat[STAT_SWITCHES]);\n\tpr_info(\"%s: key[%d] is activated\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns2:\n\t/* RX pending: not working -> remove */\n\tif (!key.pending || tipc_aead_users(rx->aead[key.pending]) > -10)\n\t\tgoto s3;\n\n\ttipc_crypto_key_set_state(rx, key.passive, key.active, 0);\n\ttipc_crypto_key_detach(rx->aead[key.pending], &rx->lock);\n\tpr_debug(\"%s: key[%d] is removed\\n\", rx->name, key.pending);\n\tgoto s5;\n\ns3:\n\t/* RX active: timed out or no user -> pending */\n\tif (!key.active)\n\t\tgoto s4;\n\tif (time_before(jiffies, rx->timer1 + TIPC_RX_ACTIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.active]) > 0)\n\t\tgoto s4;\n\n\tif (key.pending)\n\t\tkey.passive = key.active;\n\telse\n\t\tkey.pending = key.active;\n\trx->timer2 = jiffies;\n\ttipc_crypto_key_set_state(rx, key.passive, 0, key.pending);\n\ttipc_aead_users_set(rx->aead[key.pending], 0);\n\tpr_debug(\"%s: key[%d] is deactivated\\n\", rx->name, key.active);\n\tgoto s5;\n\ns4:\n\t/* RX passive: outdated or not working -> free */\n\tif (!key.passive)\n\t\tgoto s5;\n\tif (time_before(jiffies, rx->timer2 + TIPC_RX_PASSIVE_LIM) &&\n\t    tipc_aead_users(rx->aead[key.passive]) > -10)\n\t\tgoto s5;\n\n\ttipc_crypto_key_set_state(rx, 0, key.active, key.pending);\n\ttipc_crypto_key_detach(rx->aead[key.passive], &rx->lock);\n\tpr_debug(\"%s: key[%d] is freed\\n\", rx->name, key.passive);\n\ns5:\n\tspin_unlock(&rx->lock);\n\n\t/* Relax it here, the flag will be set again if it really is, but only\n\t * when we are not in grace period for safety!\n\t */\n\tif (time_after(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\ttx->legacy_user = 0;\n\n\t/* Limit max_tfms & do debug commands if needed */\n\tif (likely(sysctl_tipc_max_tfms <= TIPC_MAX_TFMS_LIM))\n\t\treturn;\n\n\tcmd = sysctl_tipc_max_tfms;\n\tsysctl_tipc_max_tfms = TIPC_MAX_TFMS_DEF;\n\ttipc_crypto_do_cmd(rx->net, cmd);\n}\n\nstatic inline void tipc_crypto_clone_msg(struct net *net, struct sk_buff *_skb,\n\t\t\t\t\t struct tipc_bearer *b,\n\t\t\t\t\t struct tipc_media_addr *dst,\n\t\t\t\t\t struct tipc_node *__dnode, u8 type)\n{\n\tstruct sk_buff *skb;\n\n\tskb = skb_clone(_skb, GFP_ATOMIC);\n\tif (skb) {\n\t\tTIPC_SKB_CB(skb)->xmit_type = type;\n\t\ttipc_crypto_xmit(net, &skb, b, dst, __dnode);\n\t\tif (skb)\n\t\t\tb->media->send_msg(net, skb, b, dst);\n\t}\n}\n\n/**\n * tipc_crypto_xmit - Build & encrypt TIPC message for xmit\n * @net: struct net\n * @skb: input/output message skb pointer\n * @b: bearer used for xmit later\n * @dst: destination media address\n * @__dnode: destination node for reference if any\n *\n * First, build an encryption message header on the top of the message, then\n * encrypt the original TIPC message by using the pending, master or active\n * key with this preference order.\n * If the encryption is successful, the encrypted skb is returned directly or\n * via the callback.\n * Otherwise, the skb is freed!\n *\n * Return:\n * * 0                   : the encryption has succeeded (or no encryption)\n * * -EINPROGRESS/-EBUSY : the encryption is ongoing, a callback will be made\n * * -ENOKEK             : the encryption has failed due to no key\n * * -EKEYREVOKED        : the encryption has failed due to key revoked\n * * -ENOMEM             : the encryption has failed due to no memory\n * * < 0                 : the encryption has failed due to other reasons\n */\nint tipc_crypto_xmit(struct net *net, struct sk_buff **skb,\n\t\t     struct tipc_bearer *b, struct tipc_media_addr *dst,\n\t\t     struct tipc_node *__dnode)\n{\n\tstruct tipc_crypto *__rx = tipc_node_crypto_rx(__dnode);\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats = tx->stats;\n\tstruct tipc_msg *hdr = buf_msg(*skb);\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead = NULL;\n\tu32 user = msg_user(hdr);\n\tu32 type = msg_type(hdr);\n\tint rc = -ENOKEY;\n\tu8 tx_key = 0;\n\n\t/* No encryption? */\n\tif (!tx->working)\n\t\treturn 0;\n\n\t/* Pending key if peer has active on it or probing time */\n\tif (unlikely(key.pending)) {\n\t\ttx_key = key.pending;\n\t\tif (!tx->key_master && !key.active)\n\t\t\tgoto encrypt;\n\t\tif (__rx && atomic_read(&__rx->peer_rx_active) == tx_key)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_PROBING) {\n\t\t\tpr_debug(\"%s: probing for key[%d]\\n\", tx->name,\n\t\t\t\t key.pending);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG || user == LINK_PROTOCOL)\n\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst, __dnode,\n\t\t\t\t\t      SKB_PROBING);\n\t}\n\n\t/* Master key if this is a *vital* message or in grace period */\n\tif (tx->key_master) {\n\t\ttx_key = KEY_MASTER;\n\t\tif (!key.active)\n\t\t\tgoto encrypt;\n\t\tif (TIPC_SKB_CB(*skb)->xmit_type == SKB_GRACING) {\n\t\t\tpr_debug(\"%s: gracing for msg (%d %d)\\n\", tx->name,\n\t\t\t\t user, type);\n\t\t\tgoto encrypt;\n\t\t}\n\t\tif (user == LINK_CONFIG ||\n\t\t    (user == LINK_PROTOCOL && type == RESET_MSG) ||\n\t\t    (user == MSG_CRYPTO && type == KEY_DISTR_MSG) ||\n\t\t    time_before(jiffies, tx->timer2 + TIPC_TX_GRACE_PERIOD)) {\n\t\t\tif (__rx && __rx->key_master &&\n\t\t\t    !atomic_read(&__rx->peer_rx_active))\n\t\t\t\tgoto encrypt;\n\t\t\tif (!__rx) {\n\t\t\t\tif (likely(!tx->legacy_user))\n\t\t\t\t\tgoto encrypt;\n\t\t\t\ttipc_crypto_clone_msg(net, *skb, b, dst,\n\t\t\t\t\t\t      __dnode, SKB_GRACING);\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Else, use the active key if any */\n\tif (likely(key.active)) {\n\t\ttx_key = key.active;\n\t\tgoto encrypt;\n\t}\n\n\tgoto exit;\n\nencrypt:\n\taead = tipc_aead_get(tx->aead[tx_key]);\n\tif (unlikely(!aead))\n\t\tgoto exit;\n\trc = tipc_ehdr_build(net, aead, tx_key, *skb, __rx);\n\tif (likely(rc > 0))\n\t\trc = tipc_aead_encrypt(aead, *skb, b, dst, __dnode);\n\nexit:\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY)\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\telse if (rc == -EKEYREVOKED)\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADKEYS]);\n\t\tkfree_skb(*skb);\n\t\t*skb = NULL;\n\t\tbreak;\n\t}\n\n\ttipc_aead_put(aead);\n\treturn rc;\n}\n\n/**\n * tipc_crypto_rcv - Decrypt an encrypted TIPC message from peer\n * @net: struct net\n * @rx: RX crypto handle\n * @skb: input/output message skb pointer\n * @b: bearer where the message has been received\n *\n * If the decryption is successful, the decrypted skb is returned directly or\n * as the callback, the encryption header and auth tag will be trimed out\n * before forwarding to tipc_rcv() via the tipc_crypto_rcv_complete().\n * Otherwise, the skb will be freed!\n * Note: RX key(s) can be re-aligned, or in case of no key suitable, TX\n * cluster key(s) can be taken for decryption (- recursive).\n *\n * Return:\n * * 0                   : the decryption has successfully completed\n * * -EINPROGRESS/-EBUSY : the decryption is ongoing, a callback will be made\n * * -ENOKEY             : the decryption has failed due to no key\n * * -EBADMSG            : the decryption has failed due to bad message\n * * -ENOMEM             : the decryption has failed due to no memory\n * * < 0                 : the decryption has failed due to other reasons\n */\nint tipc_crypto_rcv(struct net *net, struct tipc_crypto *rx,\n\t\t    struct sk_buff **skb, struct tipc_bearer *b)\n{\n\tstruct tipc_crypto *tx = tipc_net(net)->crypto_tx;\n\tstruct tipc_crypto_stats __percpu *stats;\n\tstruct tipc_aead *aead = NULL;\n\tstruct tipc_key key;\n\tint rc = -ENOKEY;\n\tu8 tx_key, n;\n\n\ttx_key = ((struct tipc_ehdr *)(*skb)->data)->tx_key;\n\n\t/* New peer?\n\t * Let's try with TX key (i.e. cluster mode) & verify the skb first!\n\t */\n\tif (unlikely(!rx || tx_key == KEY_MASTER))\n\t\tgoto pick_tx;\n\n\t/* Pick RX key according to TX key if any */\n\tkey = rx->key;\n\tif (tx_key == key.active || tx_key == key.pending ||\n\t    tx_key == key.passive)\n\t\tgoto decrypt;\n\n\t/* Unknown key, let's try to align RX key(s) */\n\tif (tipc_crypto_key_try_align(rx, tx_key))\n\t\tgoto decrypt;\n\npick_tx:\n\t/* No key suitable? Try to pick one from TX... */\n\taead = tipc_crypto_key_pick_tx(tx, rx, *skb, tx_key);\n\tif (aead)\n\t\tgoto decrypt;\n\tgoto exit;\n\ndecrypt:\n\trcu_read_lock();\n\tif (!aead)\n\t\taead = tipc_aead_get(rx->aead[tx_key]);\n\trc = tipc_aead_decrypt(net, aead, *skb, b);\n\trcu_read_unlock();\n\nexit:\n\tstats = ((rx) ?: tx)->stats;\n\tswitch (rc) {\n\tcase 0:\n\t\tthis_cpu_inc(stats->stat[STAT_OK]);\n\t\tbreak;\n\tcase -EINPROGRESS:\n\tcase -EBUSY:\n\t\tthis_cpu_inc(stats->stat[STAT_ASYNC]);\n\t\t*skb = NULL;\n\t\treturn rc;\n\tdefault:\n\t\tthis_cpu_inc(stats->stat[STAT_NOK]);\n\t\tif (rc == -ENOKEY) {\n\t\t\tkfree_skb(*skb);\n\t\t\t*skb = NULL;\n\t\t\tif (rx) {\n\t\t\t\t/* Mark rx->nokey only if we dont have a\n\t\t\t\t * pending received session key, nor a newer\n\t\t\t\t * one i.e. in the next slot.\n\t\t\t\t */\n\t\t\t\tn = key_next(tx_key);\n\t\t\t\trx->nokey = !(rx->skey ||\n\t\t\t\t\t      rcu_access_pointer(rx->aead[n]));\n\t\t\t\tpr_debug_ratelimited(\"%s: nokey %d, key %d/%x\\n\",\n\t\t\t\t\t\t     rx->name, rx->nokey,\n\t\t\t\t\t\t     tx_key, rx->key.keys);\n\t\t\t\ttipc_node_put(rx->node);\n\t\t\t}\n\t\t\tthis_cpu_inc(stats->stat[STAT_NOKEYS]);\n\t\t\treturn rc;\n\t\t} else if (rc == -EBADMSG) {\n\t\t\tthis_cpu_inc(stats->stat[STAT_BADMSGS]);\n\t\t}\n\t\tbreak;\n\t}\n\n\ttipc_crypto_rcv_complete(net, aead, b, skb, rc);\n\treturn rc;\n}\n\nstatic void tipc_crypto_rcv_complete(struct net *net, struct tipc_aead *aead,\n\t\t\t\t     struct tipc_bearer *b,\n\t\t\t\t     struct sk_buff **skb, int err)\n{\n\tstruct tipc_skb_cb *skb_cb = TIPC_SKB_CB(*skb);\n\tstruct tipc_crypto *rx = aead->crypto;\n\tstruct tipc_aead *tmp = NULL;\n\tstruct tipc_ehdr *ehdr;\n\tstruct tipc_node *n;\n\n\t/* Is this completed by TX? */\n\tif (unlikely(is_tx(aead->crypto))) {\n\t\trx = skb_cb->tx_clone_ctx.rx;\n\t\tpr_debug(\"TX->RX(%s): err %d, aead %p, skb->next %p, flags %x\\n\",\n\t\t\t (rx) ? tipc_node_get_id_str(rx->node) : \"-\", err, aead,\n\t\t\t (*skb)->next, skb_cb->flags);\n\t\tpr_debug(\"skb_cb [recurs %d, last %p], tx->aead [%p %p %p]\\n\",\n\t\t\t skb_cb->tx_clone_ctx.recurs, skb_cb->tx_clone_ctx.last,\n\t\t\t aead->crypto->aead[1], aead->crypto->aead[2],\n\t\t\t aead->crypto->aead[3]);\n\t\tif (unlikely(err)) {\n\t\t\tif (err == -EBADMSG && (*skb)->next)\n\t\t\t\ttipc_rcv(net, (*skb)->next, b);\n\t\t\tgoto free_skb;\n\t\t}\n\n\t\tif (likely((*skb)->next)) {\n\t\t\tkfree_skb((*skb)->next);\n\t\t\t(*skb)->next = NULL;\n\t\t}\n\t\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\t\tif (!rx) {\n\t\t\tWARN_ON(ehdr->user != LINK_CONFIG);\n\t\t\tn = tipc_node_create(net, 0, ehdr->id, 0xffffu, 0,\n\t\t\t\t\t     true);\n\t\t\trx = tipc_node_crypto_rx(n);\n\t\t\tif (unlikely(!rx))\n\t\t\t\tgoto free_skb;\n\t\t}\n\n\t\t/* Ignore cloning if it was TX master key */\n\t\tif (ehdr->tx_key == KEY_MASTER)\n\t\t\tgoto rcv;\n\t\tif (tipc_aead_clone(&tmp, aead) < 0)\n\t\t\tgoto rcv;\n\t\tWARN_ON(!refcount_inc_not_zero(&tmp->refcnt));\n\t\tif (tipc_crypto_key_attach(rx, tmp, ehdr->tx_key, false) < 0) {\n\t\t\ttipc_aead_free(&tmp->rcu);\n\t\t\tgoto rcv;\n\t\t}\n\t\ttipc_aead_put(aead);\n\t\taead = tmp;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttipc_aead_users_dec((struct tipc_aead __force __rcu *)aead, INT_MIN);\n\t\tgoto free_skb;\n\t}\n\n\t/* Set the RX key's user */\n\ttipc_aead_users_set((struct tipc_aead __force __rcu *)aead, 1);\n\n\t/* Mark this point, RX works */\n\trx->timer1 = jiffies;\n\nrcv:\n\t/* Remove ehdr & auth. tag prior to tipc_rcv() */\n\tehdr = (struct tipc_ehdr *)(*skb)->data;\n\n\t/* Mark this point, RX passive still works */\n\tif (rx->key.passive && ehdr->tx_key == rx->key.passive)\n\t\trx->timer2 = jiffies;\n\n\tskb_reset_network_header(*skb);\n\tskb_pull(*skb, tipc_ehdr_size(ehdr));\n\tpskb_trim(*skb, (*skb)->len - aead->authsize);\n\n\t/* Validate TIPCv2 message */\n\tif (unlikely(!tipc_msg_validate(skb))) {\n\t\tpr_err_ratelimited(\"Packet dropped after decryption!\\n\");\n\t\tgoto free_skb;\n\t}\n\n\t/* Ok, everything's fine, try to synch own keys according to peers' */\n\ttipc_crypto_key_synch(rx, *skb);\n\n\t/* Mark skb decrypted */\n\tskb_cb->decrypted = 1;\n\n\t/* Clear clone cxt if any */\n\tif (likely(!skb_cb->tx_clone_deferred))\n\t\tgoto exit;\n\tskb_cb->tx_clone_deferred = 0;\n\tmemset(&skb_cb->tx_clone_ctx, 0, sizeof(skb_cb->tx_clone_ctx));\n\tgoto exit;\n\nfree_skb:\n\tkfree_skb(*skb);\n\t*skb = NULL;\n\nexit:\n\ttipc_aead_put(aead);\n\tif (rx)\n\t\ttipc_node_put(rx->node);\n}\n\nstatic void tipc_crypto_do_cmd(struct net *net, int cmd)\n{\n\tstruct tipc_net *tn = tipc_net(net);\n\tstruct tipc_crypto *tx = tn->crypto_tx, *rx;\n\tstruct list_head *p;\n\tunsigned int stat;\n\tint i, j, cpu;\n\tchar buf[200];\n\n\t/* Currently only one command is supported */\n\tswitch (cmd) {\n\tcase 0xfff1:\n\t\tgoto print_stats;\n\tdefault:\n\t\treturn;\n\t}\n\nprint_stats:\n\t/* Print a header */\n\tpr_info(\"\\n=============== TIPC Crypto Statistics ===============\\n\\n\");\n\n\t/* Print key status */\n\tpr_info(\"Key status:\\n\");\n\tpr_info(\"TX(%7.7s)\\n%s\", tipc_own_id_string(net),\n\t\ttipc_crypto_key_dump(tx, buf));\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tpr_info(\"RX(%7.7s)\\n%s\", tipc_node_get_id_str(rx->node),\n\t\t\ttipc_crypto_key_dump(rx, buf));\n\t}\n\trcu_read_unlock();\n\n\t/* Print crypto statistics */\n\tfor (i = 0, j = 0; i < MAX_STATS; i++)\n\t\tj += scnprintf(buf + j, 200 - j, \"|%11s \", hstats[i]);\n\tpr_info(\"Counter     %s\", buf);\n\n\tmemset(buf, '-', 115);\n\tbuf[115] = '\\0';\n\tpr_info(\"%s\\n\", buf);\n\n\tj = scnprintf(buf, 200, \"TX(%7.7s) \", tipc_own_id_string(net));\n\tfor_each_possible_cpu(cpu) {\n\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\tstat = per_cpu_ptr(tx->stats, cpu)->stat[i];\n\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \", stat);\n\t\t}\n\t\tpr_info(\"%s\", buf);\n\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t}\n\n\trcu_read_lock();\n\tfor (p = tn->node_list.next; p != &tn->node_list; p = p->next) {\n\t\trx = tipc_node_crypto_rx_by_list(p);\n\t\tj = scnprintf(buf, 200, \"RX(%7.7s) \",\n\t\t\t      tipc_node_get_id_str(rx->node));\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tfor (i = 0; i < MAX_STATS; i++) {\n\t\t\t\tstat = per_cpu_ptr(rx->stats, cpu)->stat[i];\n\t\t\t\tj += scnprintf(buf + j, 200 - j, \"|%11d \",\n\t\t\t\t\t       stat);\n\t\t\t}\n\t\t\tpr_info(\"%s\", buf);\n\t\t\tj = scnprintf(buf, 200, \"%12s\", \" \");\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tpr_info(\"\\n======================== Done ========================\\n\");\n}\n\nstatic char *tipc_crypto_key_dump(struct tipc_crypto *c, char *buf)\n{\n\tstruct tipc_key key = c->key;\n\tstruct tipc_aead *aead;\n\tint k, i = 0;\n\tchar *s;\n\n\tfor (k = KEY_MIN; k <= KEY_MAX; k++) {\n\t\tif (k == KEY_MASTER) {\n\t\t\tif (is_rx(c))\n\t\t\t\tcontinue;\n\t\t\tif (time_before(jiffies,\n\t\t\t\t\tc->timer2 + TIPC_TX_GRACE_PERIOD))\n\t\t\t\ts = \"ACT\";\n\t\t\telse\n\t\t\t\ts = \"PAS\";\n\t\t} else {\n\t\t\tif (k == key.passive)\n\t\t\t\ts = \"PAS\";\n\t\t\telse if (k == key.active)\n\t\t\t\ts = \"ACT\";\n\t\t\telse if (k == key.pending)\n\t\t\t\ts = \"PEN\";\n\t\t\telse\n\t\t\t\ts = \"-\";\n\t\t}\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tKey%d: %s\", k, s);\n\n\t\trcu_read_lock();\n\t\taead = rcu_dereference(c->aead[k]);\n\t\tif (aead)\n\t\t\ti += scnprintf(buf + i, 200 - i,\n\t\t\t\t       \"{\\\"0x...%s\\\", \\\"%s\\\"}/%d:%d\",\n\t\t\t\t       aead->hint,\n\t\t\t\t       (aead->mode == CLUSTER_KEY) ? \"c\" : \"p\",\n\t\t\t\t       atomic_read(&aead->users),\n\t\t\t\t       refcount_read(&aead->refcnt));\n\t\trcu_read_unlock();\n\t\ti += scnprintf(buf + i, 200 - i, \"\\n\");\n\t}\n\n\tif (is_rx(c))\n\t\ti += scnprintf(buf + i, 200 - i, \"\\tPeer RX active: %d\\n\",\n\t\t\t       atomic_read(&c->peer_rx_active));\n\n\treturn buf;\n}\n\nstatic char *tipc_key_change_dump(struct tipc_key old, struct tipc_key new,\n\t\t\t\t  char *buf)\n{\n\tstruct tipc_key *key = &old;\n\tint k, i = 0;\n\tchar *s;\n\n\t/* Output format: \"[%s %s %s] -> [%s %s %s]\", max len = 32 */\nagain:\n\ti += scnprintf(buf + i, 32 - i, \"[\");\n\tfor (k = KEY_1; k <= KEY_3; k++) {\n\t\tif (k == key->passive)\n\t\t\ts = \"pas\";\n\t\telse if (k == key->active)\n\t\t\ts = \"act\";\n\t\telse if (k == key->pending)\n\t\t\ts = \"pen\";\n\t\telse\n\t\t\ts = \"-\";\n\t\ti += scnprintf(buf + i, 32 - i,\n\t\t\t       (k != KEY_3) ? \"%s \" : \"%s\", s);\n\t}\n\tif (key != &new) {\n\t\ti += scnprintf(buf + i, 32 - i, \"] -> \");\n\t\tkey = &new;\n\t\tgoto again;\n\t}\n\ti += scnprintf(buf + i, 32 - i, \"]\");\n\treturn buf;\n}\n\n/**\n * tipc_crypto_msg_rcv - Common 'MSG_CRYPTO' processing point\n * @net: the struct net\n * @skb: the receiving message buffer\n */\nvoid tipc_crypto_msg_rcv(struct net *net, struct sk_buff *skb)\n{\n\tstruct tipc_crypto *rx;\n\tstruct tipc_msg *hdr;\n\n\tif (unlikely(skb_linearize(skb)))\n\t\tgoto exit;\n\n\thdr = buf_msg(skb);\n\trx = tipc_node_crypto_rx_by_addr(net, msg_prevnode(hdr));\n\tif (unlikely(!rx))\n\t\tgoto exit;\n\n\tswitch (msg_type(hdr)) {\n\tcase KEY_DISTR_MSG:\n\t\tif (tipc_crypto_key_rcv(rx, hdr))\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttipc_node_put(rx->node);\n\nexit:\n\tkfree_skb(skb);\n}\n\n/**\n * tipc_crypto_key_distr - Distribute a TX key\n * @tx: the TX crypto\n * @key: the key's index\n * @dest: the destination tipc node, = NULL if distributing to all nodes\n *\n * Return: 0 in case of success, otherwise < 0\n */\nint tipc_crypto_key_distr(struct tipc_crypto *tx, u8 key,\n\t\t\t  struct tipc_node *dest)\n{\n\tstruct tipc_aead *aead;\n\tu32 dnode = tipc_node_get_addr(dest);\n\tint rc = -ENOKEY;\n\n\tif (!sysctl_tipc_key_exchange_enabled)\n\t\treturn 0;\n\n\tif (key) {\n\t\trcu_read_lock();\n\t\taead = tipc_aead_get(tx->aead[key]);\n\t\tif (likely(aead)) {\n\t\t\trc = tipc_crypto_key_xmit(tx->net, aead->key,\n\t\t\t\t\t\t  aead->gen, aead->mode,\n\t\t\t\t\t\t  dnode);\n\t\t\ttipc_aead_put(aead);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_xmit - Send a session key\n * @net: the struct net\n * @skey: the session key to be sent\n * @gen: the key's generation\n * @mode: the key's mode\n * @dnode: the destination node address, = 0 if broadcasting to all nodes\n *\n * The session key 'skey' is packed in a TIPC v2 'MSG_CRYPTO/KEY_DISTR_MSG'\n * as its data section, then xmit-ed through the uc/bc link.\n *\n * Return: 0 in case of success, otherwise < 0\n */\nstatic int tipc_crypto_key_xmit(struct net *net, struct tipc_aead_key *skey,\n\t\t\t\tu16 gen, u8 mode, u32 dnode)\n{\n\tstruct sk_buff_head pkts;\n\tstruct tipc_msg *hdr;\n\tstruct sk_buff *skb;\n\tu16 size, cong_link_cnt;\n\tu8 *data;\n\tint rc;\n\n\tsize = tipc_aead_key_size(skey);\n\tskb = tipc_buf_acquire(INT_H_SIZE + size, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\thdr = buf_msg(skb);\n\ttipc_msg_init(tipc_own_addr(net), hdr, MSG_CRYPTO, KEY_DISTR_MSG,\n\t\t      INT_H_SIZE, dnode);\n\tmsg_set_size(hdr, INT_H_SIZE + size);\n\tmsg_set_key_gen(hdr, gen);\n\tmsg_set_key_mode(hdr, mode);\n\n\tdata = msg_data(hdr);\n\t*((__be32 *)(data + TIPC_AEAD_ALG_NAME)) = htonl(skey->keylen);\n\tmemcpy(data, skey->alg_name, TIPC_AEAD_ALG_NAME);\n\tmemcpy(data + TIPC_AEAD_ALG_NAME + sizeof(__be32), skey->key,\n\t       skey->keylen);\n\n\t__skb_queue_head_init(&pkts);\n\t__skb_queue_tail(&pkts, skb);\n\tif (dnode)\n\t\trc = tipc_node_xmit(net, &pkts, dnode, 0);\n\telse\n\t\trc = tipc_bcast_xmit(net, &pkts, &cong_link_cnt);\n\n\treturn rc;\n}\n\n/**\n * tipc_crypto_key_rcv - Receive a session key\n * @rx: the RX crypto\n * @hdr: the TIPC v2 message incl. the receiving session key in its data\n *\n * This function retrieves the session key in the message from peer, then\n * schedules a RX work to attach the key to the corresponding RX crypto.\n *\n * Return: \"true\" if the key has been scheduled for attaching, otherwise\n * \"false\".\n */\nstatic bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)\n{\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_aead_key *skey = NULL;\n\tu16 key_gen = msg_key_gen(hdr);\n\tu16 size = msg_data_sz(hdr);\n\tu8 *data = msg_data(hdr);\n\tunsigned int keylen;\n\n\t/* Verify whether the size can exist in the packet */\n\tif (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {\n\t\tpr_debug(\"%s: message data size is too small\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tkeylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n\n\t/* Verify the supplied size values */\n\tif (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||\n\t\t     keylen > TIPC_AEAD_KEY_SIZE_MAX)) {\n\t\tpr_debug(\"%s: invalid MSG_CRYPTO key size\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tspin_lock(&rx->lock);\n\tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n\t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n\t\t       rx->skey, key_gen, rx->key_gen);\n\t\tgoto exit_unlock;\n\t}\n\n\t/* Allocate memory for the key */\n\tskey = kmalloc(size, GFP_ATOMIC);\n\tif (unlikely(!skey)) {\n\t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n\t\tgoto exit_unlock;\n\t}\n\n\t/* Copy key from msg data */\n\tskey->keylen = keylen;\n\tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n\tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n\t       skey->keylen);\n\n\trx->key_gen = key_gen;\n\trx->skey_mode = msg_key_mode(hdr);\n\trx->skey = skey;\n\trx->nokey = 0;\n\tmb(); /* for nokey flag */\n\nexit_unlock:\n\tspin_unlock(&rx->lock);\n\nexit:\n\t/* Schedule the key attaching on this crypto */\n\tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n\t\treturn true;\n\n\treturn false;\n}\n\n/**\n * tipc_crypto_work_rx - Scheduled RX works handler\n * @work: the struct RX work\n *\n * The function processes the previous scheduled works i.e. distributing TX key\n * or attaching a received session key on RX crypto.\n */\nstatic void tipc_crypto_work_rx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *rx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tunsigned long delay = msecs_to_jiffies(5000);\n\tbool resched = false;\n\tu8 key;\n\tint rc;\n\n\t/* Case 1: Distribute TX key to peer if scheduled */\n\tif (atomic_cmpxchg(&rx->key_distr,\n\t\t\t   KEY_DISTR_SCHED,\n\t\t\t   KEY_DISTR_COMPL) == KEY_DISTR_SCHED) {\n\t\t/* Always pick the newest one for distributing */\n\t\tkey = tx->key.pending ?: tx->key.active;\n\t\trc = tipc_crypto_key_distr(tx, key, rx->node);\n\t\tif (unlikely(rc))\n\t\t\tpr_warn(\"%s: unable to distr key[%d] to %s, err %d\\n\",\n\t\t\t\ttx->name, key, tipc_node_get_id_str(rx->node),\n\t\t\t\trc);\n\n\t\t/* Sched for key_distr releasing */\n\t\tresched = true;\n\t} else {\n\t\tatomic_cmpxchg(&rx->key_distr, KEY_DISTR_COMPL, 0);\n\t}\n\n\t/* Case 2: Attach a pending received session key from peer if any */\n\tif (rx->skey) {\n\t\trc = tipc_crypto_key_init(rx, rx->skey, rx->skey_mode, false);\n\t\tif (unlikely(rc < 0))\n\t\t\tpr_warn(\"%s: unable to attach received skey, err %d\\n\",\n\t\t\t\trx->name, rc);\n\t\tswitch (rc) {\n\t\tcase -EBUSY:\n\t\tcase -ENOMEM:\n\t\t\t/* Resched the key attaching */\n\t\t\tresched = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsynchronize_rcu();\n\t\t\tkfree(rx->skey);\n\t\t\trx->skey = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (resched && queue_delayed_work(tx->wq, &rx->work, delay))\n\t\treturn;\n\n\ttipc_node_put(rx->node);\n}\n\n/**\n * tipc_crypto_rekeying_sched - (Re)schedule rekeying w/o new interval\n * @tx: TX crypto\n * @changed: if the rekeying needs to be rescheduled with new interval\n * @new_intv: new rekeying interval (when \"changed\" = true)\n */\nvoid tipc_crypto_rekeying_sched(struct tipc_crypto *tx, bool changed,\n\t\t\t\tu32 new_intv)\n{\n\tunsigned long delay;\n\tbool now = false;\n\n\tif (changed) {\n\t\tif (new_intv == TIPC_REKEYING_NOW)\n\t\t\tnow = true;\n\t\telse\n\t\t\ttx->rekeying_intv = new_intv;\n\t\tcancel_delayed_work_sync(&tx->work);\n\t}\n\n\tif (tx->rekeying_intv || now) {\n\t\tdelay = (now) ? 0 : tx->rekeying_intv * 60 * 1000;\n\t\tqueue_delayed_work(tx->wq, &tx->work, msecs_to_jiffies(delay));\n\t}\n}\n\n/**\n * tipc_crypto_work_tx - Scheduled TX works handler\n * @work: the struct TX work\n *\n * The function processes the previous scheduled work, i.e. key rekeying, by\n * generating a new session key based on current one, then attaching it to the\n * TX crypto and finally distributing it to peers. It also re-schedules the\n * rekeying if needed.\n */\nstatic void tipc_crypto_work_tx(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct tipc_crypto *tx = container_of(dwork, struct tipc_crypto, work);\n\tstruct tipc_aead_key *skey = NULL;\n\tstruct tipc_key key = tx->key;\n\tstruct tipc_aead *aead;\n\tint rc = -ENOMEM;\n\n\tif (unlikely(key.pending))\n\t\tgoto resched;\n\n\t/* Take current key as a template */\n\trcu_read_lock();\n\taead = rcu_dereference(tx->aead[key.active ?: KEY_MASTER]);\n\tif (unlikely(!aead)) {\n\t\trcu_read_unlock();\n\t\t/* At least one key should exist for securing */\n\t\treturn;\n\t}\n\n\t/* Lets duplicate it first */\n\tskey = kmemdup(aead->key, tipc_aead_key_size(aead->key), GFP_ATOMIC);\n\trcu_read_unlock();\n\n\t/* Now, generate new key, initiate & distribute it */\n\tif (likely(skey)) {\n\t\trc = tipc_aead_key_generate(skey) ?:\n\t\t     tipc_crypto_key_init(tx, skey, PER_NODE_KEY, false);\n\t\tif (likely(rc > 0))\n\t\t\trc = tipc_crypto_key_distr(tx, rc, NULL);\n\t\tkfree_sensitive(skey);\n\t}\n\n\tif (unlikely(rc))\n\t\tpr_warn_ratelimited(\"%s: rekeying returns %d\\n\", tx->name, rc);\n\nresched:\n\t/* Re-schedule rekeying if any */\n\ttipc_crypto_rekeying_sched(tx, false, 0);\n}\n"], "buggy_code_start_loc": [2287], "buggy_code_end_loc": [2325], "fixing_code_start_loc": [2288], "fixing_code_end_loc": [2334], "type": "CWE-20", "message": "An issue was discovered in net/tipc/crypto.c in the Linux kernel before 5.14.16. The Transparent Inter-Process Communication (TIPC) functionality allows remote attackers to exploit insufficient validation of user-supplied sizes for the MSG_CRYPTO message type.", "other": {"cve": {"id": "CVE-2021-43267", "sourceIdentifier": "cve@mitre.org", "published": "2021-11-02T23:15:07.487", "lastModified": "2022-11-03T02:51:29.570", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in net/tipc/crypto.c in the Linux kernel before 5.14.16. The Transparent Inter-Process Communication (TIPC) functionality allows remote attackers to exploit insufficient validation of user-supplied sizes for the MSG_CRYPTO message type."}, {"lang": "es", "value": "Se ha detectado un problema en el archivo net/tipc/crypto.c en el kernel de Linux versiones anteriores a 5.14.16. La funcionalidad Transparent Inter-Process Communication (TIPC) permite a atacantes remotos explotar una comprobaci\u00f3n insuficiente de los tama\u00f1os suministrados por el usuario para el tipo de mensaje MSG_CRYPTO"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.10", "versionEndExcluding": "5.10.77", "matchCriteriaId": "B96ED468-9053-475E-8C7C-98F6E133DADB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.11", "versionEndExcluding": "5.14.16", "matchCriteriaId": "2681B950-4548-4649-A9E1-4124B59FC09C"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:34:*:*:*:*:*:*:*", "matchCriteriaId": "A930E247-0B43-43CB-98FF-6CE7B8189835"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:35:*:*:*:*:*:*:*", "matchCriteriaId": "80E516C0-98A4-4ADE-B69F-66A772E2BAAA"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h300s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "6770B6C3-732E-4E22-BF1C-2D2FD610061C"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h300s:-:*:*:*:*:*:*:*", "matchCriteriaId": "9F9C8C20-42EB-4AB5-BD97-212DEB070C43"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h500s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "7FFF7106-ED78-49BA-9EC5-B889E3685D53"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h500s:-:*:*:*:*:*:*:*", "matchCriteriaId": "E63D8B0F-006E-4801-BF9D-1C001BBFB4F9"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "56409CEC-5A1E-4450-AA42-641E459CC2AF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "B06F4839-D16A-4A61-9BB5-55B13F41E47F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h300e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "108A2215-50FB-4074-94CF-C130FA14566D"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h300e:-:*:*:*:*:*:*:*", "matchCriteriaId": "7AFC73CE-ABB9-42D3-9A71-3F5BC5381E0E"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h500e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "32F0B6C0-F930-480D-962B-3F4EFDCC13C7"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h500e:-:*:*:*:*:*:*:*", "matchCriteriaId": "803BC414-B250-4E3A-A478-A3881340D6B8"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h700e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "0FEB3337-BFDE-462A-908B-176F92053CEC"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h700e:-:*:*:*:*:*:*:*", "matchCriteriaId": "736AEAE9-782B-4F71-9893-DED53367E102"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h410s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "D0B4AD8A-F172-4558-AEC6-FF424BA2D912"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h410s:-:*:*:*:*:*:*:*", "matchCriteriaId": "8497A4C9-8474-4A62-8331-3FE862ED4098"}]}]}], "references": [{"url": "http://www.openwall.com/lists/oss-security/2022/02/10/1", "source": "cve@mitre.org", "tags": ["Exploit", "Mailing List", "Third Party Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.14.16", "source": "cve@mitre.org", "tags": ["Mailing List", "Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/fa40d9734a57bcbfa79a280189799f76c88f7bb0", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/CVWL7HZV5T5OEKJPO2D67RMFMKBBXGGB/", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/RDDEW4APTYKJK365HC2JZIVXYUV7ZRN7/", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20211125-0002/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/fa40d9734a57bcbfa79a280189799f76c88f7bb0"}}