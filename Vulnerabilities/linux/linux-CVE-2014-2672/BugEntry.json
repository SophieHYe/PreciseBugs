{"buggy_code": ["/*\n * Copyright (c) 2008-2011 Atheros Communications Inc.\n *\n * Permission to use, copy, modify, and/or distribute this software for any\n * purpose with or without fee is hereby granted, provided that the above\n * copyright notice and this permission notice appear in all copies.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n */\n\n#include <linux/dma-mapping.h>\n#include \"ath9k.h\"\n#include \"ar9003_mac.h\"\n\n#define BITS_PER_BYTE           8\n#define OFDM_PLCP_BITS          22\n#define HT_RC_2_STREAMS(_rc)    ((((_rc) & 0x78) >> 3) + 1)\n#define L_STF                   8\n#define L_LTF                   8\n#define L_SIG                   4\n#define HT_SIG                  8\n#define HT_STF                  4\n#define HT_LTF(_ns)             (4 * (_ns))\n#define SYMBOL_TIME(_ns)        ((_ns) << 2) /* ns * 4 us */\n#define SYMBOL_TIME_HALFGI(_ns) (((_ns) * 18 + 4) / 5)  /* ns * 3.6 us */\n#define TIME_SYMBOLS(t)         ((t) >> 2)\n#define TIME_SYMBOLS_HALFGI(t)  (((t) * 5 - 4) / 18)\n#define NUM_SYMBOLS_PER_USEC(_usec) (_usec >> 2)\n#define NUM_SYMBOLS_PER_USEC_HALFGI(_usec) (((_usec*5)-4)/18)\n\n\nstatic u16 bits_per_symbol[][2] = {\n\t/* 20MHz 40MHz */\n\t{    26,   54 },     /*  0: BPSK */\n\t{    52,  108 },     /*  1: QPSK 1/2 */\n\t{    78,  162 },     /*  2: QPSK 3/4 */\n\t{   104,  216 },     /*  3: 16-QAM 1/2 */\n\t{   156,  324 },     /*  4: 16-QAM 3/4 */\n\t{   208,  432 },     /*  5: 64-QAM 2/3 */\n\t{   234,  486 },     /*  6: 64-QAM 3/4 */\n\t{   260,  540 },     /*  7: 64-QAM 5/6 */\n};\n\nstatic void ath_tx_send_normal(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct ath_atx_tid *tid, struct sk_buff *skb);\nstatic void ath_tx_complete(struct ath_softc *sc, struct sk_buff *skb,\n\t\t\t    int tx_flags, struct ath_txq *txq);\nstatic void ath_tx_complete_buf(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t\tstruct ath_txq *txq, struct list_head *bf_q,\n\t\t\t\tstruct ath_tx_status *ts, int txok);\nstatic void ath_tx_txqaddbuf(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct list_head *head, bool internal);\nstatic void ath_tx_rc_status(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_status *ts, int nframes, int nbad,\n\t\t\t     int txok);\nstatic void ath_tx_update_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t      int seqno);\nstatic struct ath_buf *ath_tx_setup_buffer(struct ath_softc *sc,\n\t\t\t\t\t   struct ath_txq *txq,\n\t\t\t\t\t   struct ath_atx_tid *tid,\n\t\t\t\t\t   struct sk_buff *skb);\n\nenum {\n\tMCS_HT20,\n\tMCS_HT20_SGI,\n\tMCS_HT40,\n\tMCS_HT40_SGI,\n};\n\n/*********************/\n/* Aggregation logic */\n/*********************/\n\nvoid ath_txq_lock(struct ath_softc *sc, struct ath_txq *txq)\n\t__acquires(&txq->axq_lock)\n{\n\tspin_lock_bh(&txq->axq_lock);\n}\n\nvoid ath_txq_unlock(struct ath_softc *sc, struct ath_txq *txq)\n\t__releases(&txq->axq_lock)\n{\n\tspin_unlock_bh(&txq->axq_lock);\n}\n\nvoid ath_txq_unlock_complete(struct ath_softc *sc, struct ath_txq *txq)\n\t__releases(&txq->axq_lock)\n{\n\tstruct sk_buff_head q;\n\tstruct sk_buff *skb;\n\n\t__skb_queue_head_init(&q);\n\tskb_queue_splice_init(&txq->complete_q, &q);\n\tspin_unlock_bh(&txq->axq_lock);\n\n\twhile ((skb = __skb_dequeue(&q)))\n\t\tieee80211_tx_status(sc->hw, skb);\n}\n\nstatic void ath_tx_queue_tid(struct ath_txq *txq, struct ath_atx_tid *tid)\n{\n\tstruct ath_atx_ac *ac = tid->ac;\n\n\tif (tid->paused)\n\t\treturn;\n\n\tif (tid->sched)\n\t\treturn;\n\n\ttid->sched = true;\n\tlist_add_tail(&tid->list, &ac->tid_q);\n\n\tif (ac->sched)\n\t\treturn;\n\n\tac->sched = true;\n\tlist_add_tail(&ac->list, &txq->axq_acq);\n}\n\nstatic struct ath_frame_info *get_frame_info(struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tBUILD_BUG_ON(sizeof(struct ath_frame_info) >\n\t\t     sizeof(tx_info->rate_driver_data));\n\treturn (struct ath_frame_info *) &tx_info->rate_driver_data[0];\n}\n\nstatic void ath_send_bar(struct ath_atx_tid *tid, u16 seqno)\n{\n\tif (!tid->an->sta)\n\t\treturn;\n\n\tieee80211_send_bar(tid->an->vif, tid->an->sta->addr, tid->tidno,\n\t\t\t   seqno << IEEE80211_SEQ_SEQ_SHIFT);\n}\n\nstatic void ath_set_rates(struct ieee80211_vif *vif, struct ieee80211_sta *sta,\n\t\t\t  struct ath_buf *bf)\n{\n\tieee80211_get_tx_rates(vif, sta, bf->bf_mpdu, bf->rates,\n\t\t\t       ARRAY_SIZE(bf->rates));\n}\n\nstatic void ath_txq_skb_done(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct sk_buff *skb)\n{\n\tint q;\n\n\tq = skb_get_queue_mapping(skb);\n\tif (txq == sc->tx.uapsdq)\n\t\ttxq = sc->tx.txq_map[q];\n\n\tif (txq != sc->tx.txq_map[q])\n\t\treturn;\n\n\tif (WARN_ON(--txq->pending_frames < 0))\n\t\ttxq->pending_frames = 0;\n\n\tif (txq->stopped &&\n\t    txq->pending_frames < sc->tx.txq_max_pending[q]) {\n\t\tieee80211_wake_queue(sc->hw, q);\n\t\ttxq->stopped = false;\n\t}\n}\n\nstatic struct ath_atx_tid *\nath_get_skb_tid(struct ath_softc *sc, struct ath_node *an, struct sk_buff *skb)\n{\n\tu8 tidno = skb->priority & IEEE80211_QOS_CTL_TID_MASK;\n\treturn ATH_AN_2_TID(an, tidno);\n}\n\nstatic bool ath_tid_has_buffered(struct ath_atx_tid *tid)\n{\n\treturn !skb_queue_empty(&tid->buf_q) || !skb_queue_empty(&tid->retry_q);\n}\n\nstatic struct sk_buff *ath_tid_dequeue(struct ath_atx_tid *tid)\n{\n\tstruct sk_buff *skb;\n\n\tskb = __skb_dequeue(&tid->retry_q);\n\tif (!skb)\n\t\tskb = __skb_dequeue(&tid->buf_q);\n\n\treturn skb;\n}\n\n/*\n * ath_tx_tid_change_state:\n * - clears a-mpdu flag of previous session\n * - force sequence number allocation to fix next BlockAck Window\n */\nstatic void\nath_tx_tid_change_state(struct ath_softc *sc, struct ath_atx_tid *tid)\n{\n\tstruct ath_txq *txq = tid->ac->txq;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct sk_buff *skb, *tskb;\n\tstruct ath_buf *bf;\n\tstruct ath_frame_info *fi;\n\n\tskb_queue_walk_safe(&tid->buf_q, skb, tskb) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\ttx_info->flags &= ~IEEE80211_TX_CTL_AMPDU;\n\n\t\tif (bf)\n\t\t\tcontinue;\n\n\t\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\t\tif (!bf) {\n\t\t\t__skb_unlink(skb, &tid->buf_q);\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\t}\n\n}\n\nstatic void ath_tx_flush_tid(struct ath_softc *sc, struct ath_atx_tid *tid)\n{\n\tstruct ath_txq *txq = tid->ac->txq;\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\tstruct ath_frame_info *fi;\n\tbool sendbar = false;\n\n\tINIT_LIST_HEAD(&bf_head);\n\n\tmemset(&ts, 0, sizeof(ts));\n\n\twhile ((skb = __skb_dequeue(&tid->retry_q))) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\t\tif (!bf) {\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (fi->baw_tracked) {\n\t\t\tath_tx_update_baw(sc, tid, bf->bf_state.seqno);\n\t\t\tsendbar = true;\n\t\t}\n\n\t\tlist_add_tail(&bf->list, &bf_head);\n\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t}\n\n\tif (sendbar) {\n\t\tath_txq_unlock(sc, txq);\n\t\tath_send_bar(tid, tid->seq_start);\n\t\tath_txq_lock(sc, txq);\n\t}\n}\n\nstatic void ath_tx_update_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t      int seqno)\n{\n\tint index, cindex;\n\n\tindex  = ATH_BA_INDEX(tid->seq_start, seqno);\n\tcindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\n\n\t__clear_bit(cindex, tid->tx_buf);\n\n\twhile (tid->baw_head != tid->baw_tail && !test_bit(tid->baw_head, tid->tx_buf)) {\n\t\tINCR(tid->seq_start, IEEE80211_SEQ_MAX);\n\t\tINCR(tid->baw_head, ATH_TID_MAX_BUFS);\n\t\tif (tid->bar_index >= 0)\n\t\t\ttid->bar_index--;\n\t}\n}\n\nstatic void ath_tx_addto_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t     struct ath_buf *bf)\n{\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\tu16 seqno = bf->bf_state.seqno;\n\tint index, cindex;\n\n\tindex  = ATH_BA_INDEX(tid->seq_start, seqno);\n\tcindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\n\t__set_bit(cindex, tid->tx_buf);\n\tfi->baw_tracked = 1;\n\n\tif (index >= ((tid->baw_tail - tid->baw_head) &\n\t\t(ATH_TID_MAX_BUFS - 1))) {\n\t\ttid->baw_tail = cindex;\n\t\tINCR(tid->baw_tail, ATH_TID_MAX_BUFS);\n\t}\n}\n\nstatic void ath_tid_drain(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t  struct ath_atx_tid *tid)\n\n{\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\tstruct ath_frame_info *fi;\n\n\tmemset(&ts, 0, sizeof(ts));\n\tINIT_LIST_HEAD(&bf_head);\n\n\twhile ((skb = ath_tid_dequeue(tid))) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\n\t\tif (!bf) {\n\t\t\tath_tx_complete(sc, skb, ATH_TX_ERROR, txq);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_add_tail(&bf->list, &bf_head);\n\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t}\n}\n\nstatic void ath_tx_set_retry(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct sk_buff *skb, int count)\n{\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_buf *bf = fi->bf;\n\tstruct ieee80211_hdr *hdr;\n\tint prev = fi->retries;\n\n\tTX_STAT_INC(txq->axq_qnum, a_retries);\n\tfi->retries += count;\n\n\tif (prev > 0)\n\t\treturn;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\thdr->frame_control |= cpu_to_le16(IEEE80211_FCTL_RETRY);\n\tdma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\n\t\tsizeof(*hdr), DMA_TO_DEVICE);\n}\n\nstatic struct ath_buf *ath_tx_get_buffer(struct ath_softc *sc)\n{\n\tstruct ath_buf *bf = NULL;\n\n\tspin_lock_bh(&sc->tx.txbuflock);\n\n\tif (unlikely(list_empty(&sc->tx.txbuf))) {\n\t\tspin_unlock_bh(&sc->tx.txbuflock);\n\t\treturn NULL;\n\t}\n\n\tbf = list_first_entry(&sc->tx.txbuf, struct ath_buf, list);\n\tlist_del(&bf->list);\n\n\tspin_unlock_bh(&sc->tx.txbuflock);\n\n\treturn bf;\n}\n\nstatic void ath_tx_return_buffer(struct ath_softc *sc, struct ath_buf *bf)\n{\n\tspin_lock_bh(&sc->tx.txbuflock);\n\tlist_add_tail(&bf->list, &sc->tx.txbuf);\n\tspin_unlock_bh(&sc->tx.txbuflock);\n}\n\nstatic struct ath_buf* ath_clone_txbuf(struct ath_softc *sc, struct ath_buf *bf)\n{\n\tstruct ath_buf *tbf;\n\n\ttbf = ath_tx_get_buffer(sc);\n\tif (WARN_ON(!tbf))\n\t\treturn NULL;\n\n\tATH_TXBUF_RESET(tbf);\n\n\ttbf->bf_mpdu = bf->bf_mpdu;\n\ttbf->bf_buf_addr = bf->bf_buf_addr;\n\tmemcpy(tbf->bf_desc, bf->bf_desc, sc->sc_ah->caps.tx_desc_len);\n\ttbf->bf_state = bf->bf_state;\n\ttbf->bf_state.stale = false;\n\n\treturn tbf;\n}\n\nstatic void ath_tx_count_frames(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t        struct ath_tx_status *ts, int txok,\n\t\t\t        int *nframes, int *nbad)\n{\n\tstruct ath_frame_info *fi;\n\tu16 seq_st = 0;\n\tu32 ba[WME_BA_BMP_SIZE >> 5];\n\tint ba_index;\n\tint isaggr = 0;\n\n\t*nbad = 0;\n\t*nframes = 0;\n\n\tisaggr = bf_isaggr(bf);\n\tif (isaggr) {\n\t\tseq_st = ts->ts_seqnum;\n\t\tmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\n\t}\n\n\twhile (bf) {\n\t\tfi = get_frame_info(bf->bf_mpdu);\n\t\tba_index = ATH_BA_INDEX(seq_st, bf->bf_state.seqno);\n\n\t\t(*nframes)++;\n\t\tif (!txok || (isaggr && !ATH_BA_ISSET(ba, ba_index)))\n\t\t\t(*nbad)++;\n\n\t\tbf = bf->bf_next;\n\t}\n}\n\n\nstatic void ath_tx_complete_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t\t struct ath_buf *bf, struct list_head *bf_q,\n\t\t\t\t struct ath_tx_status *ts, int txok)\n{\n\tstruct ath_node *an = NULL;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_sta *sta;\n\tstruct ieee80211_hw *hw = sc->hw;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_atx_tid *tid = NULL;\n\tstruct ath_buf *bf_next, *bf_last = bf->bf_lastbf;\n\tstruct list_head bf_head;\n\tstruct sk_buff_head bf_pending;\n\tu16 seq_st = 0, acked_cnt = 0, txfail_cnt = 0, seq_first;\n\tu32 ba[WME_BA_BMP_SIZE >> 5];\n\tint isaggr, txfail, txpending, sendbar = 0, needreset = 0, nbad = 0;\n\tbool rc_update = true, isba;\n\tstruct ieee80211_tx_rate rates[4];\n\tstruct ath_frame_info *fi;\n\tint nframes;\n\tbool flush = !!(ts->ts_status & ATH9K_TX_FLUSH);\n\tint i, retries;\n\tint bar_index = -1;\n\n\tskb = bf->bf_mpdu;\n\thdr = (struct ieee80211_hdr *)skb->data;\n\n\ttx_info = IEEE80211_SKB_CB(skb);\n\n\tmemcpy(rates, bf->rates, sizeof(rates));\n\n\tretries = ts->ts_longretry + 1;\n\tfor (i = 0; i < ts->ts_rateindex; i++)\n\t\tretries += rates[i].count;\n\n\trcu_read_lock();\n\n\tsta = ieee80211_find_sta_by_ifaddr(hw, hdr->addr1, hdr->addr2);\n\tif (!sta) {\n\t\trcu_read_unlock();\n\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\twhile (bf) {\n\t\t\tbf_next = bf->bf_next;\n\n\t\t\tif (!bf->bf_state.stale || bf_next != NULL)\n\t\t\t\tlist_move_tail(&bf->list, &bf_head);\n\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, ts, 0);\n\n\t\t\tbf = bf_next;\n\t\t}\n\t\treturn;\n\t}\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttid = ath_get_skb_tid(sc, an, skb);\n\tseq_first = tid->seq_start;\n\tisba = ts->ts_flags & ATH9K_TX_BA;\n\n\t/*\n\t * The hardware occasionally sends a tx status for the wrong TID.\n\t * In this case, the BA status cannot be considered valid and all\n\t * subframes need to be retransmitted\n\t *\n\t * Only BlockAcks have a TID and therefore normal Acks cannot be\n\t * checked\n\t */\n\tif (isba && tid->tidno != ts->tid)\n\t\ttxok = false;\n\n\tisaggr = bf_isaggr(bf);\n\tmemset(ba, 0, WME_BA_BMP_SIZE >> 3);\n\n\tif (isaggr && txok) {\n\t\tif (ts->ts_flags & ATH9K_TX_BA) {\n\t\t\tseq_st = ts->ts_seqnum;\n\t\t\tmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\n\t\t} else {\n\t\t\t/*\n\t\t\t * AR5416 can become deaf/mute when BA\n\t\t\t * issue happens. Chip needs to be reset.\n\t\t\t * But AP code may have sychronization issues\n\t\t\t * when perform internal reset in this routine.\n\t\t\t * Only enable reset in STA mode for now.\n\t\t\t */\n\t\t\tif (sc->sc_ah->opmode == NL80211_IFTYPE_STATION)\n\t\t\t\tneedreset = 1;\n\t\t}\n\t}\n\n\t__skb_queue_head_init(&bf_pending);\n\n\tath_tx_count_frames(sc, bf, ts, txok, &nframes, &nbad);\n\twhile (bf) {\n\t\tu16 seqno = bf->bf_state.seqno;\n\n\t\ttxfail = txpending = sendbar = 0;\n\t\tbf_next = bf->bf_next;\n\n\t\tskb = bf->bf_mpdu;\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\tfi = get_frame_info(skb);\n\n\t\tif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno) ||\n\t\t    !tid->active) {\n\t\t\t/*\n\t\t\t * Outside of the current BlockAck window,\n\t\t\t * maybe part of a previous session\n\t\t\t */\n\t\t\ttxfail = 1;\n\t\t} else if (ATH_BA_ISSET(ba, ATH_BA_INDEX(seq_st, seqno))) {\n\t\t\t/* transmit completion, subframe is\n\t\t\t * acked by block ack */\n\t\t\tacked_cnt++;\n\t\t} else if (!isaggr && txok) {\n\t\t\t/* transmit completion */\n\t\t\tacked_cnt++;\n\t\t} else if (flush) {\n\t\t\ttxpending = 1;\n\t\t} else if (fi->retries < ATH_MAX_SW_RETRIES) {\n\t\t\tif (txok || !an->sleeping)\n\t\t\t\tath_tx_set_retry(sc, txq, bf->bf_mpdu,\n\t\t\t\t\t\t retries);\n\n\t\t\ttxpending = 1;\n\t\t} else {\n\t\t\ttxfail = 1;\n\t\t\ttxfail_cnt++;\n\t\t\tbar_index = max_t(int, bar_index,\n\t\t\t\tATH_BA_INDEX(seq_first, seqno));\n\t\t}\n\n\t\t/*\n\t\t * Make sure the last desc is reclaimed if it\n\t\t * not a holding desc.\n\t\t */\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (bf_next != NULL || !bf_last->bf_state.stale)\n\t\t\tlist_move_tail(&bf->list, &bf_head);\n\n\t\tif (!txpending) {\n\t\t\t/*\n\t\t\t * complete the acked-ones/xretried ones; update\n\t\t\t * block-ack window\n\t\t\t */\n\t\t\tath_tx_update_baw(sc, tid, seqno);\n\n\t\t\tif (rc_update && (acked_cnt == 1 || txfail_cnt == 1)) {\n\t\t\t\tmemcpy(tx_info->control.rates, rates, sizeof(rates));\n\t\t\t\tath_tx_rc_status(sc, bf, ts, nframes, nbad, txok);\n\t\t\t\trc_update = false;\n\t\t\t}\n\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, ts,\n\t\t\t\t!txfail);\n\t\t} else {\n\t\t\tif (tx_info->flags & IEEE80211_TX_STATUS_EOSP) {\n\t\t\t\ttx_info->flags &= ~IEEE80211_TX_STATUS_EOSP;\n\t\t\t\tieee80211_sta_eosp(sta);\n\t\t\t}\n\t\t\t/* retry the un-acked ones */\n\t\t\tif (bf->bf_next == NULL && bf_last->bf_state.stale) {\n\t\t\t\tstruct ath_buf *tbf;\n\n\t\t\t\ttbf = ath_clone_txbuf(sc, bf_last);\n\t\t\t\t/*\n\t\t\t\t * Update tx baw and complete the\n\t\t\t\t * frame with failed status if we\n\t\t\t\t * run out of tx buf.\n\t\t\t\t */\n\t\t\t\tif (!tbf) {\n\t\t\t\t\tath_tx_update_baw(sc, tid, seqno);\n\n\t\t\t\t\tath_tx_complete_buf(sc, bf, txq,\n\t\t\t\t\t\t\t    &bf_head, ts, 0);\n\t\t\t\t\tbar_index = max_t(int, bar_index,\n\t\t\t\t\t\tATH_BA_INDEX(seq_first, seqno));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tfi->bf = tbf;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Put this buffer to the temporary pending\n\t\t\t * queue to retain ordering\n\t\t\t */\n\t\t\t__skb_queue_tail(&bf_pending, skb);\n\t\t}\n\n\t\tbf = bf_next;\n\t}\n\n\t/* prepend un-acked frames to the beginning of the pending frame queue */\n\tif (!skb_queue_empty(&bf_pending)) {\n\t\tif (an->sleeping)\n\t\t\tieee80211_sta_set_buffered(sta, tid->tidno, true);\n\n\t\tskb_queue_splice_tail(&bf_pending, &tid->retry_q);\n\t\tif (!an->sleeping) {\n\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\t\tif (ts->ts_status & (ATH9K_TXERR_FILT | ATH9K_TXERR_XRETRY))\n\t\t\t\ttid->ac->clear_ps_filter = true;\n\t\t}\n\t}\n\n\tif (bar_index >= 0) {\n\t\tu16 bar_seq = ATH_BA_INDEX2SEQ(seq_first, bar_index);\n\n\t\tif (BAW_WITHIN(tid->seq_start, tid->baw_size, bar_seq))\n\t\t\ttid->bar_index = ATH_BA_INDEX(tid->seq_start, bar_seq);\n\n\t\tath_txq_unlock(sc, txq);\n\t\tath_send_bar(tid, ATH_BA_INDEX2SEQ(seq_first, bar_index + 1));\n\t\tath_txq_lock(sc, txq);\n\t}\n\n\trcu_read_unlock();\n\n\tif (needreset)\n\t\tath9k_queue_reset(sc, RESET_TYPE_TX_ERROR);\n}\n\nstatic bool bf_is_ampdu_not_probing(struct ath_buf *bf)\n{\n    struct ieee80211_tx_info *info = IEEE80211_SKB_CB(bf->bf_mpdu);\n    return bf_isampdu(bf) && !(info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE);\n}\n\nstatic void ath_tx_process_buffer(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t\t  struct ath_tx_status *ts, struct ath_buf *bf,\n\t\t\t\t  struct list_head *bf_head)\n{\n\tstruct ieee80211_tx_info *info;\n\tbool txok, flush;\n\n\ttxok = !(ts->ts_status & ATH9K_TXERR_MASK);\n\tflush = !!(ts->ts_status & ATH9K_TX_FLUSH);\n\ttxq->axq_tx_inprogress = false;\n\n\ttxq->axq_depth--;\n\tif (bf_is_ampdu_not_probing(bf))\n\t\ttxq->axq_ampdu_depth--;\n\n\tif (!bf_isampdu(bf)) {\n\t\tif (!flush) {\n\t\t\tinfo = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\t\tmemcpy(info->control.rates, bf->rates,\n\t\t\t       sizeof(info->control.rates));\n\t\t\tath_tx_rc_status(sc, bf, ts, 1, txok ? 0 : 1, txok);\n\t\t}\n\t\tath_tx_complete_buf(sc, bf, txq, bf_head, ts, txok);\n\t} else\n\t\tath_tx_complete_aggr(sc, txq, bf, bf_head, ts, txok);\n\n\tif (!flush)\n\t\tath_txq_schedule(sc, txq);\n}\n\nstatic bool ath_lookup_legacy(struct ath_buf *bf)\n{\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tint i;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = tx_info->control.rates;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tif (!rates[i].count || rates[i].idx < 0)\n\t\t\tbreak;\n\n\t\tif (!(rates[i].flags & IEEE80211_TX_RC_MCS))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic u32 ath_lookup_rate(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t   struct ath_atx_tid *tid)\n{\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tu32 max_4ms_framelen, frmlen;\n\tu16 aggr_limit, bt_aggr_limit, legacy = 0;\n\tint q = tid->ac->txq->mac80211_qnum;\n\tint i;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = bf->rates;\n\n\t/*\n\t * Find the lowest frame length among the rate series that will have a\n\t * 4ms (or TXOP limited) transmit duration.\n\t */\n\tmax_4ms_framelen = ATH_AMPDU_LIMIT_MAX;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tint modeidx;\n\n\t\tif (!rates[i].count)\n\t\t\tcontinue;\n\n\t\tif (!(rates[i].flags & IEEE80211_TX_RC_MCS)) {\n\t\t\tlegacy = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\n\t\t\tmodeidx = MCS_HT40;\n\t\telse\n\t\t\tmodeidx = MCS_HT20;\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\n\t\t\tmodeidx++;\n\n\t\tfrmlen = sc->tx.max_aggr_framelen[q][modeidx][rates[i].idx];\n\t\tmax_4ms_framelen = min(max_4ms_framelen, frmlen);\n\t}\n\n\t/*\n\t * limit aggregate size by the minimum rate if rate selected is\n\t * not a probe rate, if rate selected is a probe rate then\n\t * avoid aggregation of this packet.\n\t */\n\tif (tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE || legacy)\n\t\treturn 0;\n\n\taggr_limit = min(max_4ms_framelen, (u32)ATH_AMPDU_LIMIT_MAX);\n\n\t/*\n\t * Override the default aggregation limit for BTCOEX.\n\t */\n\tbt_aggr_limit = ath9k_btcoex_aggr_limit(sc, max_4ms_framelen);\n\tif (bt_aggr_limit)\n\t\taggr_limit = bt_aggr_limit;\n\n\tif (tid->an->maxampdu)\n\t\taggr_limit = min(aggr_limit, tid->an->maxampdu);\n\n\treturn aggr_limit;\n}\n\n/*\n * Returns the number of delimiters to be added to\n * meet the minimum required mpdudensity.\n */\nstatic int ath_compute_num_delims(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t\t  struct ath_buf *bf, u16 frmlen,\n\t\t\t\t  bool first_subfrm)\n{\n#define FIRST_DESC_NDELIMS 60\n\tu32 nsymbits, nsymbols;\n\tu16 minlen;\n\tu8 flags, rix;\n\tint width, streams, half_gi, ndelim, mindelim;\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\n\t/* Select standard number of delimiters based on frame length alone */\n\tndelim = ATH_AGGR_GET_NDELIM(frmlen);\n\n\t/*\n\t * If encryption enabled, hardware requires some more padding between\n\t * subframes.\n\t * TODO - this could be improved to be dependent on the rate.\n\t *      The hardware can keep up at lower rates, but not higher rates\n\t */\n\tif ((fi->keyix != ATH9K_TXKEYIX_INVALID) &&\n\t    !(sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA))\n\t\tndelim += ATH_AGGR_ENCRYPTDELIM;\n\n\t/*\n\t * Add delimiter when using RTS/CTS with aggregation\n\t * and non enterprise AR9003 card\n\t */\n\tif (first_subfrm && !AR_SREV_9580_10_OR_LATER(sc->sc_ah) &&\n\t    (sc->sc_ah->ent_mode & AR_ENT_OTP_MIN_PKT_SIZE_DISABLE))\n\t\tndelim = max(ndelim, FIRST_DESC_NDELIMS);\n\n\t/*\n\t * Convert desired mpdu density from microeconds to bytes based\n\t * on highest rate in rate series (i.e. first rate) to determine\n\t * required minimum length for subframe. Take into account\n\t * whether high rate is 20 or 40Mhz and half or full GI.\n\t *\n\t * If there is no mpdu density restriction, no further calculation\n\t * is needed.\n\t */\n\n\tif (tid->an->mpdudensity == 0)\n\t\treturn ndelim;\n\n\trix = bf->rates[0].idx;\n\tflags = bf->rates[0].flags;\n\twidth = (flags & IEEE80211_TX_RC_40_MHZ_WIDTH) ? 1 : 0;\n\thalf_gi = (flags & IEEE80211_TX_RC_SHORT_GI) ? 1 : 0;\n\n\tif (half_gi)\n\t\tnsymbols = NUM_SYMBOLS_PER_USEC_HALFGI(tid->an->mpdudensity);\n\telse\n\t\tnsymbols = NUM_SYMBOLS_PER_USEC(tid->an->mpdudensity);\n\n\tif (nsymbols == 0)\n\t\tnsymbols = 1;\n\n\tstreams = HT_RC_2_STREAMS(rix);\n\tnsymbits = bits_per_symbol[rix % 8][width] * streams;\n\tminlen = (nsymbols * nsymbits) / BITS_PER_BYTE;\n\n\tif (frmlen < minlen) {\n\t\tmindelim = (minlen - frmlen) / ATH_AGGR_DELIM_SZ;\n\t\tndelim = max(mindelim, ndelim);\n\t}\n\n\treturn ndelim;\n}\n\nstatic struct ath_buf *\nath_tx_get_tid_subframe(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\tstruct ath_atx_tid *tid, struct sk_buff_head **q)\n{\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_frame_info *fi;\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tu16 seqno;\n\n\twhile (1) {\n\t\t*q = &tid->retry_q;\n\t\tif (skb_queue_empty(*q))\n\t\t\t*q = &tid->buf_q;\n\n\t\tskb = skb_peek(*q);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\t\tif (!fi->bf)\n\t\t\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\t\telse\n\t\t\tbf->bf_state.stale = false;\n\n\t\tif (!bf) {\n\t\t\t__skb_unlink(skb, *q);\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbf->bf_next = NULL;\n\t\tbf->bf_lastbf = bf;\n\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\ttx_info->flags &= ~IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\t\tif (!(tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\n\t\t\tbf->bf_state.bf_type = 0;\n\t\t\treturn bf;\n\t\t}\n\n\t\tbf->bf_state.bf_type = BUF_AMPDU | BUF_AGGR;\n\t\tseqno = bf->bf_state.seqno;\n\n\t\t/* do not step over block-ack window */\n\t\tif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno))\n\t\t\tbreak;\n\n\t\tif (tid->bar_index > ATH_BA_INDEX(tid->seq_start, seqno)) {\n\t\t\tstruct ath_tx_status ts = {};\n\t\t\tstruct list_head bf_head;\n\n\t\t\tINIT_LIST_HEAD(&bf_head);\n\t\t\tlist_add(&bf->list, &bf_head);\n\t\t\t__skb_unlink(skb, *q);\n\t\t\tath_tx_update_baw(sc, tid, seqno);\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn bf;\n\t}\n\n\treturn NULL;\n}\n\nstatic bool\nath_tx_form_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t struct ath_atx_tid *tid, struct list_head *bf_q,\n\t\t struct ath_buf *bf_first, struct sk_buff_head *tid_q,\n\t\t int *aggr_len)\n{\n#define PADBYTES(_len) ((4 - ((_len) % 4)) % 4)\n\tstruct ath_buf *bf = bf_first, *bf_prev = NULL;\n\tint nframes = 0, ndelim;\n\tu16 aggr_limit = 0, al = 0, bpad = 0,\n\t    al_delta, h_baw = tid->baw_size / 2;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_frame_info *fi;\n\tstruct sk_buff *skb;\n\tbool closed = false;\n\n\tbf = bf_first;\n\taggr_limit = ath_lookup_rate(sc, bf, tid);\n\n\tdo {\n\t\tskb = bf->bf_mpdu;\n\t\tfi = get_frame_info(skb);\n\n\t\t/* do not exceed aggregation limit */\n\t\tal_delta = ATH_AGGR_DELIM_SZ + fi->framelen;\n\t\tif (nframes) {\n\t\t\tif (aggr_limit < al + bpad + al_delta ||\n\t\t\t    ath_lookup_legacy(bf) || nframes >= h_baw)\n\t\t\t\tbreak;\n\n\t\t\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\t\tif ((tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE) ||\n\t\t\t    !(tx_info->flags & IEEE80211_TX_CTL_AMPDU))\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* add padding for previous frame to aggregation length */\n\t\tal += bpad + al_delta;\n\n\t\t/*\n\t\t * Get the delimiters needed to meet the MPDU\n\t\t * density for this node.\n\t\t */\n\t\tndelim = ath_compute_num_delims(sc, tid, bf_first, fi->framelen,\n\t\t\t\t\t\t!nframes);\n\t\tbpad = PADBYTES(al_delta) + (ndelim << 2);\n\n\t\tnframes++;\n\t\tbf->bf_next = NULL;\n\n\t\t/* link buffers of this frame to the aggregate */\n\t\tif (!fi->baw_tracked)\n\t\t\tath_tx_addto_baw(sc, tid, bf);\n\t\tbf->bf_state.ndelim = ndelim;\n\n\t\t__skb_unlink(skb, tid_q);\n\t\tlist_add_tail(&bf->list, bf_q);\n\t\tif (bf_prev)\n\t\t\tbf_prev->bf_next = bf;\n\n\t\tbf_prev = bf;\n\n\t\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\t\tif (!bf) {\n\t\t\tclosed = true;\n\t\t\tbreak;\n\t\t}\n\t} while (ath_tid_has_buffered(tid));\n\n\tbf = bf_first;\n\tbf->bf_lastbf = bf_prev;\n\n\tif (bf == bf_prev) {\n\t\tal = get_frame_info(bf->bf_mpdu)->framelen;\n\t\tbf->bf_state.bf_type = BUF_AMPDU;\n\t} else {\n\t\tTX_STAT_INC(txq->axq_qnum, a_aggr);\n\t}\n\n\t*aggr_len = al;\n\n\treturn closed;\n#undef PADBYTES\n}\n\n/*\n * rix - rate index\n * pktlen - total bytes (delims + data + fcs + pads + pad delims)\n * width  - 0 for 20 MHz, 1 for 40 MHz\n * half_gi - to use 4us v/s 3.6 us for symbol time\n */\nstatic u32 ath_pkt_duration(struct ath_softc *sc, u8 rix, int pktlen,\n\t\t\t    int width, int half_gi, bool shortPreamble)\n{\n\tu32 nbits, nsymbits, duration, nsymbols;\n\tint streams;\n\n\t/* find number of symbols: PLCP + data */\n\tstreams = HT_RC_2_STREAMS(rix);\n\tnbits = (pktlen << 3) + OFDM_PLCP_BITS;\n\tnsymbits = bits_per_symbol[rix % 8][width] * streams;\n\tnsymbols = (nbits + nsymbits - 1) / nsymbits;\n\n\tif (!half_gi)\n\t\tduration = SYMBOL_TIME(nsymbols);\n\telse\n\t\tduration = SYMBOL_TIME_HALFGI(nsymbols);\n\n\t/* addup duration for legacy/ht training and signal fields */\n\tduration += L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\n\n\treturn duration;\n}\n\nstatic int ath_max_framelen(int usec, int mcs, bool ht40, bool sgi)\n{\n\tint streams = HT_RC_2_STREAMS(mcs);\n\tint symbols, bits;\n\tint bytes = 0;\n\n\tsymbols = sgi ? TIME_SYMBOLS_HALFGI(usec) : TIME_SYMBOLS(usec);\n\tbits = symbols * bits_per_symbol[mcs % 8][ht40] * streams;\n\tbits -= OFDM_PLCP_BITS;\n\tbytes = bits / 8;\n\tbytes -= L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\n\tif (bytes > 65532)\n\t\tbytes = 65532;\n\n\treturn bytes;\n}\n\nvoid ath_update_max_aggr_framelen(struct ath_softc *sc, int queue, int txop)\n{\n\tu16 *cur_ht20, *cur_ht20_sgi, *cur_ht40, *cur_ht40_sgi;\n\tint mcs;\n\n\t/* 4ms is the default (and maximum) duration */\n\tif (!txop || txop > 4096)\n\t\ttxop = 4096;\n\n\tcur_ht20 = sc->tx.max_aggr_framelen[queue][MCS_HT20];\n\tcur_ht20_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT20_SGI];\n\tcur_ht40 = sc->tx.max_aggr_framelen[queue][MCS_HT40];\n\tcur_ht40_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT40_SGI];\n\tfor (mcs = 0; mcs < 32; mcs++) {\n\t\tcur_ht20[mcs] = ath_max_framelen(txop, mcs, false, false);\n\t\tcur_ht20_sgi[mcs] = ath_max_framelen(txop, mcs, false, true);\n\t\tcur_ht40[mcs] = ath_max_framelen(txop, mcs, true, false);\n\t\tcur_ht40_sgi[mcs] = ath_max_framelen(txop, mcs, true, true);\n\t}\n}\n\nstatic void ath_buf_set_rate(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_info *info, int len, bool rts)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tconst struct ieee80211_rate *rate;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\tu32 rts_thresh = sc->hw->wiphy->rts_threshold;\n\tint i;\n\tu8 rix = 0;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = bf->rates;\n\thdr = (struct ieee80211_hdr *)skb->data;\n\n\t/* set dur_update_en for l-sig computation except for PS-Poll frames */\n\tinfo->dur_update = !ieee80211_is_pspoll(hdr->frame_control);\n\tinfo->rtscts_rate = fi->rtscts_rate;\n\n\tfor (i = 0; i < ARRAY_SIZE(bf->rates); i++) {\n\t\tbool is_40, is_sgi, is_sp;\n\t\tint phy;\n\n\t\tif (!rates[i].count || (rates[i].idx < 0))\n\t\t\tcontinue;\n\n\t\trix = rates[i].idx;\n\t\tinfo->rates[i].Tries = rates[i].count;\n\n\t\t/*\n\t\t * Handle RTS threshold for unaggregated HT frames.\n\t\t */\n\t\tif (bf_isampdu(bf) && !bf_isaggr(bf) &&\n\t\t    (rates[i].flags & IEEE80211_TX_RC_MCS) &&\n\t\t    unlikely(rts_thresh != (u32) -1)) {\n\t\t\tif (!rts_thresh || (len > rts_thresh))\n\t\t\t\trts = true;\n\t\t}\n\n\t\tif (rts || rates[i].flags & IEEE80211_TX_RC_USE_RTS_CTS) {\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\n\t\t\tinfo->flags |= ATH9K_TXDESC_RTSENA;\n\t\t} else if (rates[i].flags & IEEE80211_TX_RC_USE_CTS_PROTECT) {\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\n\t\t\tinfo->flags |= ATH9K_TXDESC_CTSENA;\n\t\t}\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_2040;\n\t\tif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_HALFGI;\n\n\t\tis_sgi = !!(rates[i].flags & IEEE80211_TX_RC_SHORT_GI);\n\t\tis_40 = !!(rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH);\n\t\tis_sp = !!(rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE);\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_MCS) {\n\t\t\t/* MCS rates */\n\t\t\tinfo->rates[i].Rate = rix | 0x80;\n\t\t\tinfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\n\t\t\t\t\tah->txchainmask, info->rates[i].Rate);\n\t\t\tinfo->rates[i].PktDuration = ath_pkt_duration(sc, rix, len,\n\t\t\t\t is_40, is_sgi, is_sp);\n\t\t\tif (rix < 8 && (tx_info->flags & IEEE80211_TX_CTL_STBC))\n\t\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_STBC;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* legacy rates */\n\t\trate = &sc->sbands[tx_info->band].bitrates[rates[i].idx];\n\t\tif ((tx_info->band == IEEE80211_BAND_2GHZ) &&\n\t\t    !(rate->flags & IEEE80211_RATE_ERP_G))\n\t\t\tphy = WLAN_RC_PHY_CCK;\n\t\telse\n\t\t\tphy = WLAN_RC_PHY_OFDM;\n\n\t\tinfo->rates[i].Rate = rate->hw_value;\n\t\tif (rate->hw_value_short) {\n\t\t\tif (rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE)\n\t\t\t\tinfo->rates[i].Rate |= rate->hw_value_short;\n\t\t} else {\n\t\t\tis_sp = false;\n\t\t}\n\n\t\tif (bf->bf_state.bfs_paprd)\n\t\t\tinfo->rates[i].ChSel = ah->txchainmask;\n\t\telse\n\t\t\tinfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\n\t\t\t\t\tah->txchainmask, info->rates[i].Rate);\n\n\t\tinfo->rates[i].PktDuration = ath9k_hw_computetxtime(sc->sc_ah,\n\t\t\tphy, rate->bitrate * 100, len, rix, is_sp);\n\t}\n\n\t/* For AR5416 - RTS cannot be followed by a frame larger than 8K */\n\tif (bf_isaggr(bf) && (len > sc->sc_ah->caps.rts_aggr_limit))\n\t\tinfo->flags &= ~ATH9K_TXDESC_RTSENA;\n\n\t/* ATH9K_TXDESC_RTSENA and ATH9K_TXDESC_CTSENA are mutually exclusive. */\n\tif (info->flags & ATH9K_TXDESC_RTSENA)\n\t\tinfo->flags &= ~ATH9K_TXDESC_CTSENA;\n}\n\nstatic enum ath9k_pkt_type get_hw_packet_type(struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\tenum ath9k_pkt_type htype;\n\t__le16 fc;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tfc = hdr->frame_control;\n\n\tif (ieee80211_is_beacon(fc))\n\t\thtype = ATH9K_PKT_TYPE_BEACON;\n\telse if (ieee80211_is_probe_resp(fc))\n\t\thtype = ATH9K_PKT_TYPE_PROBE_RESP;\n\telse if (ieee80211_is_atim(fc))\n\t\thtype = ATH9K_PKT_TYPE_ATIM;\n\telse if (ieee80211_is_pspoll(fc))\n\t\thtype = ATH9K_PKT_TYPE_PSPOLL;\n\telse\n\t\thtype = ATH9K_PKT_TYPE_NORMAL;\n\n\treturn htype;\n}\n\nstatic void ath_tx_fill_desc(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_txq *txq, int len)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_buf *bf_first = NULL;\n\tstruct ath_tx_info info;\n\tu32 rts_thresh = sc->hw->wiphy->rts_threshold;\n\tbool rts = false;\n\n\tmemset(&info, 0, sizeof(info));\n\tinfo.is_first = true;\n\tinfo.is_last = true;\n\tinfo.txpower = MAX_RATE_POWER;\n\tinfo.qcu = txq->axq_qnum;\n\n\twhile (bf) {\n\t\tstruct sk_buff *skb = bf->bf_mpdu;\n\t\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\t\tstruct ath_frame_info *fi = get_frame_info(skb);\n\t\tbool aggr = !!(bf->bf_state.bf_type & BUF_AGGR);\n\n\t\tinfo.type = get_hw_packet_type(skb);\n\t\tif (bf->bf_next)\n\t\t\tinfo.link = bf->bf_next->bf_daddr;\n\t\telse\n\t\t\tinfo.link = (sc->tx99_state) ? bf->bf_daddr : 0;\n\n\t\tif (!bf_first) {\n\t\t\tbf_first = bf;\n\n\t\t\tif (!sc->tx99_state)\n\t\t\t\tinfo.flags = ATH9K_TXDESC_INTREQ;\n\t\t\tif ((tx_info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT) ||\n\t\t\t    txq == sc->tx.uapsdq)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_CLRDMASK;\n\n\t\t\tif (tx_info->flags & IEEE80211_TX_CTL_NO_ACK)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_NOACK;\n\t\t\tif (tx_info->flags & IEEE80211_TX_CTL_LDPC)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_LDPC;\n\n\t\t\tif (bf->bf_state.bfs_paprd)\n\t\t\t\tinfo.flags |= (u32) bf->bf_state.bfs_paprd <<\n\t\t\t\t\t      ATH9K_TXDESC_PAPRD_S;\n\n\t\t\t/*\n\t\t\t * mac80211 doesn't handle RTS threshold for HT because\n\t\t\t * the decision has to be taken based on AMPDU length\n\t\t\t * and aggregation is done entirely inside ath9k.\n\t\t\t * Set the RTS/CTS flag for the first subframe based\n\t\t\t * on the threshold.\n\t\t\t */\n\t\t\tif (aggr && (bf == bf_first) &&\n\t\t\t    unlikely(rts_thresh != (u32) -1)) {\n\t\t\t\t/*\n\t\t\t\t * \"len\" is the size of the entire AMPDU.\n\t\t\t\t */\n\t\t\t\tif (!rts_thresh || (len > rts_thresh))\n\t\t\t\t\trts = true;\n\t\t\t}\n\n\t\t\tif (!aggr)\n\t\t\t\tlen = fi->framelen;\n\n\t\t\tath_buf_set_rate(sc, bf, &info, len, rts);\n\t\t}\n\n\t\tinfo.buf_addr[0] = bf->bf_buf_addr;\n\t\tinfo.buf_len[0] = skb->len;\n\t\tinfo.pkt_len = fi->framelen;\n\t\tinfo.keyix = fi->keyix;\n\t\tinfo.keytype = fi->keytype;\n\n\t\tif (aggr) {\n\t\t\tif (bf == bf_first)\n\t\t\t\tinfo.aggr = AGGR_BUF_FIRST;\n\t\t\telse if (bf == bf_first->bf_lastbf)\n\t\t\t\tinfo.aggr = AGGR_BUF_LAST;\n\t\t\telse\n\t\t\t\tinfo.aggr = AGGR_BUF_MIDDLE;\n\n\t\t\tinfo.ndelim = bf->bf_state.ndelim;\n\t\t\tinfo.aggr_len = len;\n\t\t}\n\n\t\tif (bf == bf_first->bf_lastbf)\n\t\t\tbf_first = NULL;\n\n\t\tath9k_hw_set_txdesc(ah, bf->bf_desc, &info);\n\t\tbf = bf->bf_next;\n\t}\n}\n\nstatic void\nath_tx_form_burst(struct ath_softc *sc, struct ath_txq *txq,\n\t\t  struct ath_atx_tid *tid, struct list_head *bf_q,\n\t\t  struct ath_buf *bf_first, struct sk_buff_head *tid_q)\n{\n\tstruct ath_buf *bf = bf_first, *bf_prev = NULL;\n\tstruct sk_buff *skb;\n\tint nframes = 0;\n\n\tdo {\n\t\tstruct ieee80211_tx_info *tx_info;\n\t\tskb = bf->bf_mpdu;\n\n\t\tnframes++;\n\t\t__skb_unlink(skb, tid_q);\n\t\tlist_add_tail(&bf->list, bf_q);\n\t\tif (bf_prev)\n\t\t\tbf_prev->bf_next = bf;\n\t\tbf_prev = bf;\n\n\t\tif (nframes >= 2)\n\t\t\tbreak;\n\n\t\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\t\tif (!bf)\n\t\t\tbreak;\n\n\t\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\tif (tx_info->flags & IEEE80211_TX_CTL_AMPDU)\n\t\t\tbreak;\n\n\t\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\t} while (1);\n}\n\nstatic bool ath_tx_sched_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t      struct ath_atx_tid *tid, bool *stop)\n{\n\tstruct ath_buf *bf;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct sk_buff_head *tid_q;\n\tstruct list_head bf_q;\n\tint aggr_len = 0;\n\tbool aggr, last = true;\n\n\tif (!ath_tid_has_buffered(tid))\n\t\treturn false;\n\n\tINIT_LIST_HEAD(&bf_q);\n\n\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\tif (!bf)\n\t\treturn false;\n\n\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\taggr = !!(tx_info->flags & IEEE80211_TX_CTL_AMPDU);\n\tif ((aggr && txq->axq_ampdu_depth >= ATH_AGGR_MIN_QDEPTH) ||\n\t\t(!aggr && txq->axq_depth >= ATH_NON_AGGR_MIN_QDEPTH)) {\n\t\t*stop = true;\n\t\treturn false;\n\t}\n\n\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\tif (aggr)\n\t\tlast = ath_tx_form_aggr(sc, txq, tid, &bf_q, bf,\n\t\t\t\t\ttid_q, &aggr_len);\n\telse\n\t\tath_tx_form_burst(sc, txq, tid, &bf_q, bf, tid_q);\n\n\tif (list_empty(&bf_q))\n\t\treturn false;\n\n\tif (tid->ac->clear_ps_filter || tid->an->no_ps_filter) {\n\t\ttid->ac->clear_ps_filter = false;\n\t\ttx_info->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\t}\n\n\tath_tx_fill_desc(sc, bf, txq, aggr_len);\n\tath_tx_txqaddbuf(sc, txq, &bf_q, false);\n\treturn true;\n}\n\nint ath_tx_aggr_start(struct ath_softc *sc, struct ieee80211_sta *sta,\n\t\t      u16 tid, u16 *ssn)\n{\n\tstruct ath_atx_tid *txtid;\n\tstruct ath_txq *txq;\n\tstruct ath_node *an;\n\tu8 density;\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttxtid = ATH_AN_2_TID(an, tid);\n\ttxq = txtid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\n\t/* update ampdu factor/density, they may have changed. This may happen\n\t * in HT IBSS when a beacon with HT-info is received after the station\n\t * has already been added.\n\t */\n\tif (sta->ht_cap.ht_supported) {\n\t\tan->maxampdu = (1 << (IEEE80211_HT_MAX_AMPDU_FACTOR +\n\t\t\t\t      sta->ht_cap.ampdu_factor)) - 1;\n\t\tdensity = ath9k_parse_mpdudensity(sta->ht_cap.ampdu_density);\n\t\tan->mpdudensity = density;\n\t}\n\n\t/* force sequence number allocation for pending frames */\n\tath_tx_tid_change_state(sc, txtid);\n\n\ttxtid->active = true;\n\ttxtid->paused = true;\n\t*ssn = txtid->seq_start = txtid->seq_next;\n\ttxtid->bar_index = -1;\n\n\tmemset(txtid->tx_buf, 0, sizeof(txtid->tx_buf));\n\ttxtid->baw_head = txtid->baw_tail = 0;\n\n\tath_txq_unlock_complete(sc, txq);\n\n\treturn 0;\n}\n\nvoid ath_tx_aggr_stop(struct ath_softc *sc, struct ieee80211_sta *sta, u16 tid)\n{\n\tstruct ath_node *an = (struct ath_node *)sta->drv_priv;\n\tstruct ath_atx_tid *txtid = ATH_AN_2_TID(an, tid);\n\tstruct ath_txq *txq = txtid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\ttxtid->active = false;\n\ttxtid->paused = false;\n\tath_tx_flush_tid(sc, txtid);\n\tath_tx_tid_change_state(sc, txtid);\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath_tx_aggr_sleep(struct ieee80211_sta *sta, struct ath_softc *sc,\n\t\t       struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tstruct ath_txq *txq;\n\tbool buffered;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tif (!tid->sched)\n\t\t\tcontinue;\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tbuffered = ath_tid_has_buffered(tid);\n\n\t\ttid->sched = false;\n\t\tlist_del(&tid->list);\n\n\t\tif (ac->sched) {\n\t\t\tac->sched = false;\n\t\t\tlist_del(&ac->list);\n\t\t}\n\n\t\tath_txq_unlock(sc, txq);\n\n\t\tieee80211_sta_set_buffered(sta, tidno, buffered);\n\t}\n}\n\nvoid ath_tx_aggr_wakeup(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tstruct ath_txq *txq;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\t\tac->clear_ps_filter = true;\n\n\t\tif (!tid->paused && ath_tid_has_buffered(tid)) {\n\t\t\tath_tx_queue_tid(txq, tid);\n\t\t\tath_txq_schedule(sc, txq);\n\t\t}\n\n\t\tath_txq_unlock_complete(sc, txq);\n\t}\n}\n\nvoid ath_tx_aggr_resume(struct ath_softc *sc, struct ieee80211_sta *sta,\n\t\t\tu16 tidno)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_node *an;\n\tstruct ath_txq *txq;\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttid = ATH_AN_2_TID(an, tidno);\n\ttxq = tid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\n\ttid->baw_size = IEEE80211_MIN_AMPDU_BUF << sta->ht_cap.ampdu_factor;\n\ttid->paused = false;\n\n\tif (ath_tid_has_buffered(tid)) {\n\t\tath_tx_queue_tid(txq, tid);\n\t\tath_txq_schedule(sc, txq);\n\t}\n\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath9k_release_buffered_frames(struct ieee80211_hw *hw,\n\t\t\t\t   struct ieee80211_sta *sta,\n\t\t\t\t   u16 tids, int nframes,\n\t\t\t\t   enum ieee80211_frame_release_type reason,\n\t\t\t\t   bool more_data)\n{\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_node *an = (struct ath_node *)sta->drv_priv;\n\tstruct ath_txq *txq = sc->tx.uapsdq;\n\tstruct ieee80211_tx_info *info;\n\tstruct list_head bf_q;\n\tstruct ath_buf *bf_tail = NULL, *bf;\n\tstruct sk_buff_head *tid_q;\n\tint sent = 0;\n\tint i;\n\n\tINIT_LIST_HEAD(&bf_q);\n\tfor (i = 0; tids && nframes; i++, tids >>= 1) {\n\t\tstruct ath_atx_tid *tid;\n\n\t\tif (!(tids & 1))\n\t\t\tcontinue;\n\n\t\ttid = ATH_AN_2_TID(an, i);\n\t\tif (tid->paused)\n\t\t\tcontinue;\n\n\t\tath_txq_lock(sc, tid->ac->txq);\n\t\twhile (nframes > 0) {\n\t\t\tbf = ath_tx_get_tid_subframe(sc, sc->tx.uapsdq, tid, &tid_q);\n\t\t\tif (!bf)\n\t\t\t\tbreak;\n\n\t\t\t__skb_unlink(bf->bf_mpdu, tid_q);\n\t\t\tlist_add_tail(&bf->list, &bf_q);\n\t\t\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\t\t\tif (bf_isampdu(bf)) {\n\t\t\t\tath_tx_addto_baw(sc, tid, bf);\n\t\t\t\tbf->bf_state.bf_type &= ~BUF_AGGR;\n\t\t\t}\n\t\t\tif (bf_tail)\n\t\t\t\tbf_tail->bf_next = bf;\n\n\t\t\tbf_tail = bf;\n\t\t\tnframes--;\n\t\t\tsent++;\n\t\t\tTX_STAT_INC(txq->axq_qnum, a_queued_hw);\n\n\t\t\tif (an->sta && !ath_tid_has_buffered(tid))\n\t\t\t\tieee80211_sta_set_buffered(an->sta, i, false);\n\t\t}\n\t\tath_txq_unlock_complete(sc, tid->ac->txq);\n\t}\n\n\tif (list_empty(&bf_q))\n\t\treturn;\n\n\tinfo = IEEE80211_SKB_CB(bf_tail->bf_mpdu);\n\tinfo->flags |= IEEE80211_TX_STATUS_EOSP;\n\n\tbf = list_first_entry(&bf_q, struct ath_buf, list);\n\tath_txq_lock(sc, txq);\n\tath_tx_fill_desc(sc, bf, txq, 0);\n\tath_tx_txqaddbuf(sc, txq, &bf_q, false);\n\tath_txq_unlock(sc, txq);\n}\n\n/********************/\n/* Queue Management */\n/********************/\n\nstruct ath_txq *ath_txq_setup(struct ath_softc *sc, int qtype, int subtype)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath9k_tx_queue_info qi;\n\tstatic const int subtype_txq_to_hwq[] = {\n\t\t[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,\n\t\t[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,\n\t\t[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,\n\t\t[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,\n\t};\n\tint axq_qnum, i;\n\n\tmemset(&qi, 0, sizeof(qi));\n\tqi.tqi_subtype = subtype_txq_to_hwq[subtype];\n\tqi.tqi_aifs = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_physCompBuf = 0;\n\n\t/*\n\t * Enable interrupts only for EOL and DESC conditions.\n\t * We mark tx descriptors to receive a DESC interrupt\n\t * when a tx queue gets deep; otherwise waiting for the\n\t * EOL to reap descriptors.  Note that this is done to\n\t * reduce interrupt load and this only defers reaping\n\t * descriptors, never transmitting frames.  Aside from\n\t * reducing interrupts this also permits more concurrency.\n\t * The only potential downside is if the tx queue backs\n\t * up in which case the top half of the kernel may backup\n\t * due to a lack of tx descriptors.\n\t *\n\t * The UAPSD queue is an exception, since we take a desc-\n\t * based intr on the EOSP frames.\n\t */\n\tif (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\n\t\tqi.tqi_qflags = TXQ_FLAG_TXINT_ENABLE;\n\t} else {\n\t\tif (qtype == ATH9K_TX_QUEUE_UAPSD)\n\t\t\tqi.tqi_qflags = TXQ_FLAG_TXDESCINT_ENABLE;\n\t\telse\n\t\t\tqi.tqi_qflags = TXQ_FLAG_TXEOLINT_ENABLE |\n\t\t\t\t\tTXQ_FLAG_TXDESCINT_ENABLE;\n\t}\n\taxq_qnum = ath9k_hw_setuptxqueue(ah, qtype, &qi);\n\tif (axq_qnum == -1) {\n\t\t/*\n\t\t * NB: don't print a message, this happens\n\t\t * normally on parts with too few tx queues\n\t\t */\n\t\treturn NULL;\n\t}\n\tif (!ATH_TXQ_SETUP(sc, axq_qnum)) {\n\t\tstruct ath_txq *txq = &sc->tx.txq[axq_qnum];\n\n\t\ttxq->axq_qnum = axq_qnum;\n\t\ttxq->mac80211_qnum = -1;\n\t\ttxq->axq_link = NULL;\n\t\t__skb_queue_head_init(&txq->complete_q);\n\t\tINIT_LIST_HEAD(&txq->axq_q);\n\t\tINIT_LIST_HEAD(&txq->axq_acq);\n\t\tspin_lock_init(&txq->axq_lock);\n\t\ttxq->axq_depth = 0;\n\t\ttxq->axq_ampdu_depth = 0;\n\t\ttxq->axq_tx_inprogress = false;\n\t\tsc->tx.txqsetup |= 1<<axq_qnum;\n\n\t\ttxq->txq_headidx = txq->txq_tailidx = 0;\n\t\tfor (i = 0; i < ATH_TXFIFO_DEPTH; i++)\n\t\t\tINIT_LIST_HEAD(&txq->txq_fifo[i]);\n\t}\n\treturn &sc->tx.txq[axq_qnum];\n}\n\nint ath_txq_update(struct ath_softc *sc, int qnum,\n\t\t   struct ath9k_tx_queue_info *qinfo)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tint error = 0;\n\tstruct ath9k_tx_queue_info qi;\n\n\tBUG_ON(sc->tx.txq[qnum].axq_qnum != qnum);\n\n\tath9k_hw_get_txq_props(ah, qnum, &qi);\n\tqi.tqi_aifs = qinfo->tqi_aifs;\n\tqi.tqi_cwmin = qinfo->tqi_cwmin;\n\tqi.tqi_cwmax = qinfo->tqi_cwmax;\n\tqi.tqi_burstTime = qinfo->tqi_burstTime;\n\tqi.tqi_readyTime = qinfo->tqi_readyTime;\n\n\tif (!ath9k_hw_set_txq_props(ah, qnum, &qi)) {\n\t\tath_err(ath9k_hw_common(sc->sc_ah),\n\t\t\t\"Unable to update hardware queue %u!\\n\", qnum);\n\t\terror = -EIO;\n\t} else {\n\t\tath9k_hw_resettxqueue(ah, qnum);\n\t}\n\n\treturn error;\n}\n\nint ath_cabq_update(struct ath_softc *sc)\n{\n\tstruct ath9k_tx_queue_info qi;\n\tstruct ath_beacon_config *cur_conf = &sc->cur_beacon_conf;\n\tint qnum = sc->beacon.cabq->axq_qnum;\n\n\tath9k_hw_get_txq_props(sc->sc_ah, qnum, &qi);\n\n\tqi.tqi_readyTime = (cur_conf->beacon_interval *\n\t\t\t    ATH_CABQ_READY_TIME) / 100;\n\tath_txq_update(sc, qnum, &qi);\n\n\treturn 0;\n}\n\nstatic void ath_drain_txq_list(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct list_head *list)\n{\n\tstruct ath_buf *bf, *lastbf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\n\tmemset(&ts, 0, sizeof(ts));\n\tts.ts_status = ATH9K_TX_FLUSH;\n\tINIT_LIST_HEAD(&bf_head);\n\n\twhile (!list_empty(list)) {\n\t\tbf = list_first_entry(list, struct ath_buf, list);\n\n\t\tif (bf->bf_state.stale) {\n\t\t\tlist_del(&bf->list);\n\n\t\t\tath_tx_return_buffer(sc, bf);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\t\tlist_cut_position(&bf_head, list, &lastbf->list);\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t}\n}\n\n/*\n * Drain a given TX queue (could be Beacon or Data)\n *\n * This assumes output has been stopped and\n * we do not need to block ath_tx_tasklet.\n */\nvoid ath_draintxq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tath_txq_lock(sc, txq);\n\n\tif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\n\t\tint idx = txq->txq_tailidx;\n\n\t\twhile (!list_empty(&txq->txq_fifo[idx])) {\n\t\t\tath_drain_txq_list(sc, txq, &txq->txq_fifo[idx]);\n\n\t\t\tINCR(idx, ATH_TXFIFO_DEPTH);\n\t\t}\n\t\ttxq->txq_tailidx = idx;\n\t}\n\n\ttxq->axq_link = NULL;\n\ttxq->axq_tx_inprogress = false;\n\tath_drain_txq_list(sc, txq, &txq->axq_q);\n\n\tath_txq_unlock_complete(sc, txq);\n}\n\nbool ath_drain_all_txq(struct ath_softc *sc)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_txq *txq;\n\tint i;\n\tu32 npend = 0;\n\n\tif (test_bit(SC_OP_INVALID, &sc->sc_flags))\n\t\treturn true;\n\n\tath9k_hw_abort_tx_dma(ah);\n\n\t/* Check if any queue remains active */\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (!ATH_TXQ_SETUP(sc, i))\n\t\t\tcontinue;\n\n\t\tif (!sc->tx.txq[i].axq_depth)\n\t\t\tcontinue;\n\n\t\tif (ath9k_hw_numtxpending(ah, sc->tx.txq[i].axq_qnum))\n\t\t\tnpend |= BIT(i);\n\t}\n\n\tif (npend)\n\t\tath_err(common, \"Failed to stop TX DMA, queues=0x%03x!\\n\", npend);\n\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (!ATH_TXQ_SETUP(sc, i))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * The caller will resume queues with ieee80211_wake_queues.\n\t\t * Mark the queue as not stopped to prevent ath_tx_complete\n\t\t * from waking the queue too early.\n\t\t */\n\t\ttxq = &sc->tx.txq[i];\n\t\ttxq->stopped = false;\n\t\tath_draintxq(sc, txq);\n\t}\n\n\treturn !npend;\n}\n\nvoid ath_tx_cleanupq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tath9k_hw_releasetxqueue(sc->sc_ah, txq->axq_qnum);\n\tsc->tx.txqsetup &= ~(1<<txq->axq_qnum);\n}\n\n/* For each axq_acq entry, for each tid, try to schedule packets\n * for transmit until ampdu_depth has reached min Q depth.\n */\nvoid ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tstruct ath_atx_ac *ac, *last_ac;\n\tstruct ath_atx_tid *tid, *last_tid;\n\tbool sent = false;\n\n\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags) ||\n\t    list_empty(&txq->axq_acq))\n\t\treturn;\n\n\trcu_read_lock();\n\n\tlast_ac = list_entry(txq->axq_acq.prev, struct ath_atx_ac, list);\n\twhile (!list_empty(&txq->axq_acq)) {\n\t\tbool stop = false;\n\n\t\tac = list_first_entry(&txq->axq_acq, struct ath_atx_ac, list);\n\t\tlast_tid = list_entry(ac->tid_q.prev, struct ath_atx_tid, list);\n\t\tlist_del(&ac->list);\n\t\tac->sched = false;\n\n\t\twhile (!list_empty(&ac->tid_q)) {\n\n\t\t\ttid = list_first_entry(&ac->tid_q, struct ath_atx_tid,\n\t\t\t\t\t       list);\n\t\t\tlist_del(&tid->list);\n\t\t\ttid->sched = false;\n\n\t\t\tif (tid->paused)\n\t\t\t\tcontinue;\n\n\t\t\tif (ath_tx_sched_aggr(sc, txq, tid, &stop))\n\t\t\t\tsent = true;\n\n\t\t\t/*\n\t\t\t * add tid to round-robin queue if more frames\n\t\t\t * are pending for the tid\n\t\t\t */\n\t\t\tif (ath_tid_has_buffered(tid))\n\t\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\t\tif (stop || tid == last_tid)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!list_empty(&ac->tid_q) && !ac->sched) {\n\t\t\tac->sched = true;\n\t\t\tlist_add_tail(&ac->list, &txq->axq_acq);\n\t\t}\n\n\t\tif (stop)\n\t\t\tbreak;\n\n\t\tif (ac == last_ac) {\n\t\t\tif (!sent)\n\t\t\t\tbreak;\n\n\t\t\tsent = false;\n\t\t\tlast_ac = list_entry(txq->axq_acq.prev,\n\t\t\t\t\t     struct ath_atx_ac, list);\n\t\t}\n\t}\n\n\trcu_read_unlock();\n}\n\n/***********/\n/* TX, DMA */\n/***********/\n\n/*\n * Insert a chain of ath_buf (descriptors) on a txq and\n * assume the descriptors are already chained together by caller.\n */\nstatic void ath_tx_txqaddbuf(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct list_head *head, bool internal)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(ah);\n\tstruct ath_buf *bf, *bf_last;\n\tbool puttxbuf = false;\n\tbool edma;\n\n\t/*\n\t * Insert the frame on the outbound list and\n\t * pass it on to the hardware.\n\t */\n\n\tif (list_empty(head))\n\t\treturn;\n\n\tedma = !!(ah->caps.hw_caps & ATH9K_HW_CAP_EDMA);\n\tbf = list_first_entry(head, struct ath_buf, list);\n\tbf_last = list_entry(head->prev, struct ath_buf, list);\n\n\tath_dbg(common, QUEUE, \"qnum: %d, txq depth: %d\\n\",\n\t\ttxq->axq_qnum, txq->axq_depth);\n\n\tif (edma && list_empty(&txq->txq_fifo[txq->txq_headidx])) {\n\t\tlist_splice_tail_init(head, &txq->txq_fifo[txq->txq_headidx]);\n\t\tINCR(txq->txq_headidx, ATH_TXFIFO_DEPTH);\n\t\tputtxbuf = true;\n\t} else {\n\t\tlist_splice_tail_init(head, &txq->axq_q);\n\n\t\tif (txq->axq_link) {\n\t\t\tath9k_hw_set_desc_link(ah, txq->axq_link, bf->bf_daddr);\n\t\t\tath_dbg(common, XMIT, \"link[%u] (%p)=%llx (%p)\\n\",\n\t\t\t\ttxq->axq_qnum, txq->axq_link,\n\t\t\t\tito64(bf->bf_daddr), bf->bf_desc);\n\t\t} else if (!edma)\n\t\t\tputtxbuf = true;\n\n\t\ttxq->axq_link = bf_last->bf_desc;\n\t}\n\n\tif (puttxbuf) {\n\t\tTX_STAT_INC(txq->axq_qnum, puttxbuf);\n\t\tath9k_hw_puttxbuf(ah, txq->axq_qnum, bf->bf_daddr);\n\t\tath_dbg(common, XMIT, \"TXDP[%u] = %llx (%p)\\n\",\n\t\t\ttxq->axq_qnum, ito64(bf->bf_daddr), bf->bf_desc);\n\t}\n\n\tif (!edma || sc->tx99_state) {\n\t\tTX_STAT_INC(txq->axq_qnum, txstart);\n\t\tath9k_hw_txstart(ah, txq->axq_qnum);\n\t}\n\n\tif (!internal) {\n\t\twhile (bf) {\n\t\t\ttxq->axq_depth++;\n\t\t\tif (bf_is_ampdu_not_probing(bf))\n\t\t\t\ttxq->axq_ampdu_depth++;\n\n\t\t\tbf_last = bf->bf_lastbf;\n\t\t\tbf = bf_last->bf_next;\n\t\t\tbf_last->bf_next = NULL;\n\t\t}\n\t}\n}\n\nstatic void ath_tx_send_normal(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct ath_atx_tid *tid, struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct list_head bf_head;\n\tstruct ath_buf *bf = fi->bf;\n\n\tINIT_LIST_HEAD(&bf_head);\n\tlist_add_tail(&bf->list, &bf_head);\n\tbf->bf_state.bf_type = 0;\n\tif (tid && (tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\n\t\tbf->bf_state.bf_type = BUF_AMPDU;\n\t\tath_tx_addto_baw(sc, tid, bf);\n\t}\n\n\tbf->bf_next = NULL;\n\tbf->bf_lastbf = bf;\n\tath_tx_fill_desc(sc, bf, txq, fi->framelen);\n\tath_tx_txqaddbuf(sc, txq, &bf_head, false);\n\tTX_STAT_INC(txq->axq_qnum, queued);\n}\n\nstatic void setup_frame_info(struct ieee80211_hw *hw,\n\t\t\t     struct ieee80211_sta *sta,\n\t\t\t     struct sk_buff *skb,\n\t\t\t     int framelen)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_key_conf *hw_key = tx_info->control.hw_key;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tconst struct ieee80211_rate *rate;\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_node *an = NULL;\n\tenum ath9k_key_type keytype;\n\tbool short_preamble = false;\n\n\t/*\n\t * We check if Short Preamble is needed for the CTS rate by\n\t * checking the BSS's global flag.\n\t * But for the rate series, IEEE80211_TX_RC_USE_SHORT_PREAMBLE is used.\n\t */\n\tif (tx_info->control.vif &&\n\t    tx_info->control.vif->bss_conf.use_short_preamble)\n\t\tshort_preamble = true;\n\n\trate = ieee80211_get_rts_cts_rate(hw, tx_info);\n\tkeytype = ath9k_cmn_get_hw_crypto_keytype(skb);\n\n\tif (sta)\n\t\tan = (struct ath_node *) sta->drv_priv;\n\n\tmemset(fi, 0, sizeof(*fi));\n\tif (hw_key)\n\t\tfi->keyix = hw_key->hw_key_idx;\n\telse if (an && ieee80211_is_data(hdr->frame_control) && an->ps_key > 0)\n\t\tfi->keyix = an->ps_key;\n\telse\n\t\tfi->keyix = ATH9K_TXKEYIX_INVALID;\n\tfi->keytype = keytype;\n\tfi->framelen = framelen;\n\n\tif (!rate)\n\t\treturn;\n\tfi->rtscts_rate = rate->hw_value;\n\tif (short_preamble)\n\t\tfi->rtscts_rate |= rate->hw_value_short;\n}\n\nu8 ath_txchainmask_reduction(struct ath_softc *sc, u8 chainmask, u32 rate)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath9k_channel *curchan = ah->curchan;\n\n\tif ((ah->caps.hw_caps & ATH9K_HW_CAP_APM) && IS_CHAN_5GHZ(curchan) &&\n\t    (chainmask == 0x7) && (rate < 0x90))\n\t\treturn 0x3;\n\telse if (AR_SREV_9462(ah) && ath9k_hw_btcoex_is_enabled(ah) &&\n\t\t IS_CCK_RATE(rate))\n\t\treturn 0x2;\n\telse\n\t\treturn chainmask;\n}\n\n/*\n * Assign a descriptor (and sequence number if necessary,\n * and map buffer for DMA. Frees skb on error\n */\nstatic struct ath_buf *ath_tx_setup_buffer(struct ath_softc *sc,\n\t\t\t\t\t   struct ath_txq *txq,\n\t\t\t\t\t   struct ath_atx_tid *tid,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tstruct ath_buf *bf;\n\tint fragno;\n\tu16 seqno;\n\n\tbf = ath_tx_get_buffer(sc);\n\tif (!bf) {\n\t\tath_dbg(common, XMIT, \"TX buffers are full\\n\");\n\t\treturn NULL;\n\t}\n\n\tATH_TXBUF_RESET(bf);\n\n\tif (tid) {\n\t\tfragno = le16_to_cpu(hdr->seq_ctrl) & IEEE80211_SCTL_FRAG;\n\t\tseqno = tid->seq_next;\n\t\thdr->seq_ctrl = cpu_to_le16(tid->seq_next << IEEE80211_SEQ_SEQ_SHIFT);\n\n\t\tif (fragno)\n\t\t\thdr->seq_ctrl |= cpu_to_le16(fragno);\n\n\t\tif (!ieee80211_has_morefrags(hdr->frame_control))\n\t\t\tINCR(tid->seq_next, IEEE80211_SEQ_MAX);\n\n\t\tbf->bf_state.seqno = seqno;\n\t}\n\n\tbf->bf_mpdu = skb;\n\n\tbf->bf_buf_addr = dma_map_single(sc->dev, skb->data,\n\t\t\t\t\t skb->len, DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(sc->dev, bf->bf_buf_addr))) {\n\t\tbf->bf_mpdu = NULL;\n\t\tbf->bf_buf_addr = 0;\n\t\tath_err(ath9k_hw_common(sc->sc_ah),\n\t\t\t\"dma_mapping_error() on TX\\n\");\n\t\tath_tx_return_buffer(sc, bf);\n\t\treturn NULL;\n\t}\n\n\tfi->bf = bf;\n\n\treturn bf;\n}\n\nstatic int ath_tx_prepare(struct ieee80211_hw *hw, struct sk_buff *skb,\n\t\t\t  struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_sta *sta = txctl->sta;\n\tstruct ieee80211_vif *vif = info->control.vif;\n\tstruct ath_vif *avp;\n\tstruct ath_softc *sc = hw->priv;\n\tint frmlen = skb->len + FCS_LEN;\n\tint padpos, padsize;\n\n\t/* NOTE:  sta can be NULL according to net/mac80211.h */\n\tif (sta)\n\t\ttxctl->an = (struct ath_node *)sta->drv_priv;\n\telse if (vif && ieee80211_is_data(hdr->frame_control)) {\n\t\tavp = (void *)vif->drv_priv;\n\t\ttxctl->an = &avp->mcast_node;\n\t}\n\n\tif (info->control.hw_key)\n\t\tfrmlen += info->control.hw_key->icv_len;\n\n\t/*\n\t * As a temporary workaround, assign seq# here; this will likely need\n\t * to be cleaned up to work better with Beacon transmission and virtual\n\t * BSSes.\n\t */\n\tif (info->flags & IEEE80211_TX_CTL_ASSIGN_SEQ) {\n\t\tif (info->flags & IEEE80211_TX_CTL_FIRST_FRAGMENT)\n\t\t\tsc->tx.seq_no += 0x10;\n\t\thdr->seq_ctrl &= cpu_to_le16(IEEE80211_SCTL_FRAG);\n\t\thdr->seq_ctrl |= cpu_to_le16(sc->tx.seq_no);\n\t}\n\n\tif ((vif && vif->type != NL80211_IFTYPE_AP &&\n\t            vif->type != NL80211_IFTYPE_AP_VLAN) ||\n\t    !ieee80211_is_data(hdr->frame_control))\n\t\tinfo->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\n\t/* Add the padding after the header if this is not already done */\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\tif (padsize && skb->len > padpos) {\n\t\tif (skb_headroom(skb) < padsize)\n\t\t\treturn -ENOMEM;\n\n\t\tskb_push(skb, padsize);\n\t\tmemmove(skb->data, skb->data + padsize, padpos);\n\t}\n\n\tsetup_frame_info(hw, sta, skb, frmlen);\n\treturn 0;\n}\n\n\n/* Upon failure caller should free skb */\nint ath_tx_start(struct ieee80211_hw *hw, struct sk_buff *skb,\n\t\t struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_sta *sta = txctl->sta;\n\tstruct ieee80211_vif *vif = info->control.vif;\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_txq *txq = txctl->txq;\n\tstruct ath_atx_tid *tid = NULL;\n\tstruct ath_buf *bf;\n\tint q;\n\tint ret;\n\n\tret = ath_tx_prepare(hw, skb, txctl);\n\tif (ret)\n\t    return ret;\n\n\thdr = (struct ieee80211_hdr *) skb->data;\n\t/*\n\t * At this point, the vif, hw_key and sta pointers in the tx control\n\t * info are no longer valid (overwritten by the ath_frame_info data.\n\t */\n\n\tq = skb_get_queue_mapping(skb);\n\n\tath_txq_lock(sc, txq);\n\tif (txq == sc->tx.txq_map[q] &&\n\t    ++txq->pending_frames > sc->tx.txq_max_pending[q] &&\n\t    !txq->stopped) {\n\t\tieee80211_stop_queue(sc->hw, q);\n\t\ttxq->stopped = true;\n\t}\n\n\tif (info->flags & IEEE80211_TX_CTL_PS_RESPONSE) {\n\t\tath_txq_unlock(sc, txq);\n\t\ttxq = sc->tx.uapsdq;\n\t\tath_txq_lock(sc, txq);\n\t} else if (txctl->an &&\n\t\t   ieee80211_is_data_present(hdr->frame_control)) {\n\t\ttid = ath_get_skb_tid(sc, txctl->an, skb);\n\n\t\tWARN_ON(tid->ac->txq != txctl->txq);\n\n\t\tif (info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT)\n\t\t\ttid->ac->clear_ps_filter = true;\n\n\t\t/*\n\t\t * Add this frame to software queue for scheduling later\n\t\t * for aggregation.\n\t\t */\n\t\tTX_STAT_INC(txq->axq_qnum, a_queued_sw);\n\t\t__skb_queue_tail(&tid->buf_q, skb);\n\t\tif (!txctl->an->sleeping)\n\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\tath_txq_schedule(sc, txq);\n\t\tgoto out;\n\t}\n\n\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\tif (!bf) {\n\t\tath_txq_skb_done(sc, txq, skb);\n\t\tif (txctl->paprd)\n\t\t\tdev_kfree_skb_any(skb);\n\t\telse\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\tgoto out;\n\t}\n\n\tbf->bf_state.bfs_paprd = txctl->paprd;\n\n\tif (txctl->paprd)\n\t\tbf->bf_state.bfs_paprd_timestamp = jiffies;\n\n\tath_set_rates(vif, sta, bf);\n\tath_tx_send_normal(sc, txq, tid, skb);\n\nout:\n\tath_txq_unlock(sc, txq);\n\n\treturn 0;\n}\n\nvoid ath_tx_cabq(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t struct sk_buff *skb)\n{\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_tx_control txctl = {\n\t\t.txq = sc->beacon.cabq\n\t};\n\tstruct ath_tx_info info = {};\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath_buf *bf_tail = NULL;\n\tstruct ath_buf *bf;\n\tLIST_HEAD(bf_q);\n\tint duration = 0;\n\tint max_duration;\n\n\tmax_duration =\n\t\tsc->cur_beacon_conf.beacon_interval * 1000 *\n\t\tsc->cur_beacon_conf.dtim_period / ATH_BCBUF;\n\n\tdo {\n\t\tstruct ath_frame_info *fi = get_frame_info(skb);\n\n\t\tif (ath_tx_prepare(hw, skb, &txctl))\n\t\t\tbreak;\n\n\t\tbf = ath_tx_setup_buffer(sc, txctl.txq, NULL, skb);\n\t\tif (!bf)\n\t\t\tbreak;\n\n\t\tbf->bf_lastbf = bf;\n\t\tath_set_rates(vif, NULL, bf);\n\t\tath_buf_set_rate(sc, bf, &info, fi->framelen, false);\n\t\tduration += info.rates[0].PktDuration;\n\t\tif (bf_tail)\n\t\t\tbf_tail->bf_next = bf;\n\n\t\tlist_add_tail(&bf->list, &bf_q);\n\t\tbf_tail = bf;\n\t\tskb = NULL;\n\n\t\tif (duration > max_duration)\n\t\t\tbreak;\n\n\t\tskb = ieee80211_get_buffered_bc(hw, vif);\n\t} while(skb);\n\n\tif (skb)\n\t\tieee80211_free_txskb(hw, skb);\n\n\tif (list_empty(&bf_q))\n\t\treturn;\n\n\tbf = list_first_entry(&bf_q, struct ath_buf, list);\n\thdr = (struct ieee80211_hdr *) bf->bf_mpdu->data;\n\n\tif (hdr->frame_control & IEEE80211_FCTL_MOREDATA) {\n\t\thdr->frame_control &= ~IEEE80211_FCTL_MOREDATA;\n\t\tdma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\n\t\t\tsizeof(*hdr), DMA_TO_DEVICE);\n\t}\n\n\tath_txq_lock(sc, txctl.txq);\n\tath_tx_fill_desc(sc, bf, txctl.txq, 0);\n\tath_tx_txqaddbuf(sc, txctl.txq, &bf_q, false);\n\tTX_STAT_INC(txctl.txq->axq_qnum, queued);\n\tath_txq_unlock(sc, txctl.txq);\n}\n\n/*****************/\n/* TX Completion */\n/*****************/\n\nstatic void ath_tx_complete(struct ath_softc *sc, struct sk_buff *skb,\n\t\t\t    int tx_flags, struct ath_txq *txq)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ieee80211_hdr * hdr = (struct ieee80211_hdr *)skb->data;\n\tint padpos, padsize;\n\tunsigned long flags;\n\n\tath_dbg(common, XMIT, \"TX complete: skb: %p\\n\", skb);\n\n\tif (sc->sc_ah->caldata)\n\t\tset_bit(PAPRD_PACKET_SENT, &sc->sc_ah->caldata->cal_flags);\n\n\tif (!(tx_flags & ATH_TX_ERROR))\n\t\t/* Frame was ACKed */\n\t\ttx_info->flags |= IEEE80211_TX_STAT_ACK;\n\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\tif (padsize && skb->len>padpos+padsize) {\n\t\t/*\n\t\t * Remove MAC header padding before giving the frame back to\n\t\t * mac80211.\n\t\t */\n\t\tmemmove(skb->data + padsize, skb->data, padpos);\n\t\tskb_pull(skb, padsize);\n\t}\n\n\tspin_lock_irqsave(&sc->sc_pm_lock, flags);\n\tif ((sc->ps_flags & PS_WAIT_FOR_TX_ACK) && !txq->axq_depth) {\n\t\tsc->ps_flags &= ~PS_WAIT_FOR_TX_ACK;\n\t\tath_dbg(common, PS,\n\t\t\t\"Going back to sleep after having received TX status (0x%lx)\\n\",\n\t\t\tsc->ps_flags & (PS_WAIT_FOR_BEACON |\n\t\t\t\t\tPS_WAIT_FOR_CAB |\n\t\t\t\t\tPS_WAIT_FOR_PSPOLL_DATA |\n\t\t\t\t\tPS_WAIT_FOR_TX_ACK));\n\t}\n\tspin_unlock_irqrestore(&sc->sc_pm_lock, flags);\n\n\t__skb_queue_tail(&txq->complete_q, skb);\n\tath_txq_skb_done(sc, txq, skb);\n}\n\nstatic void ath_tx_complete_buf(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t\tstruct ath_txq *txq, struct list_head *bf_q,\n\t\t\t\tstruct ath_tx_status *ts, int txok)\n{\n\tstruct sk_buff *skb = bf->bf_mpdu;\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tunsigned long flags;\n\tint tx_flags = 0;\n\n\tif (!txok)\n\t\ttx_flags |= ATH_TX_ERROR;\n\n\tif (ts->ts_status & ATH9K_TXERR_FILT)\n\t\ttx_info->flags |= IEEE80211_TX_STAT_TX_FILTERED;\n\n\tdma_unmap_single(sc->dev, bf->bf_buf_addr, skb->len, DMA_TO_DEVICE);\n\tbf->bf_buf_addr = 0;\n\tif (sc->tx99_state)\n\t\tgoto skip_tx_complete;\n\n\tif (bf->bf_state.bfs_paprd) {\n\t\tif (time_after(jiffies,\n\t\t\t\tbf->bf_state.bfs_paprd_timestamp +\n\t\t\t\tmsecs_to_jiffies(ATH_PAPRD_TIMEOUT)))\n\t\t\tdev_kfree_skb_any(skb);\n\t\telse\n\t\t\tcomplete(&sc->paprd_complete);\n\t} else {\n\t\tath_debug_stat_tx(sc, bf, ts, txq, tx_flags);\n\t\tath_tx_complete(sc, skb, tx_flags, txq);\n\t}\nskip_tx_complete:\n\t/* At this point, skb (bf->bf_mpdu) is consumed...make sure we don't\n\t * accidentally reference it later.\n\t */\n\tbf->bf_mpdu = NULL;\n\n\t/*\n\t * Return the list of ath_buf of this mpdu to free queue\n\t */\n\tspin_lock_irqsave(&sc->tx.txbuflock, flags);\n\tlist_splice_tail_init(bf_q, &sc->tx.txbuf);\n\tspin_unlock_irqrestore(&sc->tx.txbuflock, flags);\n}\n\nstatic void ath_tx_rc_status(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_status *ts, int nframes, int nbad,\n\t\t\t     int txok)\n{\n\tstruct sk_buff *skb = bf->bf_mpdu;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_hw *hw = sc->hw;\n\tstruct ath_hw *ah = sc->sc_ah;\n\tu8 i, tx_rateindex;\n\n\tif (txok)\n\t\ttx_info->status.ack_signal = ts->ts_rssi;\n\n\ttx_rateindex = ts->ts_rateindex;\n\tWARN_ON(tx_rateindex >= hw->max_rates);\n\n\tif (tx_info->flags & IEEE80211_TX_CTL_AMPDU) {\n\t\ttx_info->flags |= IEEE80211_TX_STAT_AMPDU;\n\n\t\tBUG_ON(nbad > nframes);\n\t}\n\ttx_info->status.ampdu_len = nframes;\n\ttx_info->status.ampdu_ack_len = nframes - nbad;\n\n\tif ((ts->ts_status & ATH9K_TXERR_FILT) == 0 &&\n\t    (tx_info->flags & IEEE80211_TX_CTL_NO_ACK) == 0) {\n\t\t/*\n\t\t * If an underrun error is seen assume it as an excessive\n\t\t * retry only if max frame trigger level has been reached\n\t\t * (2 KB for single stream, and 4 KB for dual stream).\n\t\t * Adjust the long retry as if the frame was tried\n\t\t * hw->max_rate_tries times to affect how rate control updates\n\t\t * PER for the failed rate.\n\t\t * In case of congestion on the bus penalizing this type of\n\t\t * underruns should help hardware actually transmit new frames\n\t\t * successfully by eventually preferring slower rates.\n\t\t * This itself should also alleviate congestion on the bus.\n\t\t */\n\t\tif (unlikely(ts->ts_flags & (ATH9K_TX_DATA_UNDERRUN |\n\t\t                             ATH9K_TX_DELIM_UNDERRUN)) &&\n\t\t    ieee80211_is_data(hdr->frame_control) &&\n\t\t    ah->tx_trig_level >= sc->sc_ah->config.max_txtrig_level)\n\t\t\ttx_info->status.rates[tx_rateindex].count =\n\t\t\t\thw->max_rate_tries;\n\t}\n\n\tfor (i = tx_rateindex + 1; i < hw->max_rates; i++) {\n\t\ttx_info->status.rates[i].count = 0;\n\t\ttx_info->status.rates[i].idx = -1;\n\t}\n\n\ttx_info->status.rates[tx_rateindex].count = ts->ts_longretry + 1;\n}\n\nstatic void ath_tx_processq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(ah);\n\tstruct ath_buf *bf, *lastbf, *bf_held = NULL;\n\tstruct list_head bf_head;\n\tstruct ath_desc *ds;\n\tstruct ath_tx_status ts;\n\tint status;\n\n\tath_dbg(common, QUEUE, \"tx queue %d (%x), link %p\\n\",\n\t\ttxq->axq_qnum, ath9k_hw_gettxbuf(sc->sc_ah, txq->axq_qnum),\n\t\ttxq->axq_link);\n\n\tath_txq_lock(sc, txq);\n\tfor (;;) {\n\t\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags))\n\t\t\tbreak;\n\n\t\tif (list_empty(&txq->axq_q)) {\n\t\t\ttxq->axq_link = NULL;\n\t\t\tath_txq_schedule(sc, txq);\n\t\t\tbreak;\n\t\t}\n\t\tbf = list_first_entry(&txq->axq_q, struct ath_buf, list);\n\n\t\t/*\n\t\t * There is a race condition that a BH gets scheduled\n\t\t * after sw writes TxE and before hw re-load the last\n\t\t * descriptor to get the newly chained one.\n\t\t * Software must keep the last DONE descriptor as a\n\t\t * holding descriptor - software does so by marking\n\t\t * it with the STALE flag.\n\t\t */\n\t\tbf_held = NULL;\n\t\tif (bf->bf_state.stale) {\n\t\t\tbf_held = bf;\n\t\t\tif (list_is_last(&bf_held->list, &txq->axq_q))\n\t\t\t\tbreak;\n\n\t\t\tbf = list_entry(bf_held->list.next, struct ath_buf,\n\t\t\t\t\tlist);\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\t\tds = lastbf->bf_desc;\n\n\t\tmemset(&ts, 0, sizeof(ts));\n\t\tstatus = ath9k_hw_txprocdesc(ah, ds, &ts);\n\t\tif (status == -EINPROGRESS)\n\t\t\tbreak;\n\n\t\tTX_STAT_INC(txq->axq_qnum, txprocdesc);\n\n\t\t/*\n\t\t * Remove ath_buf's of the same transmit unit from txq,\n\t\t * however leave the last descriptor back as the holding\n\t\t * descriptor for hw.\n\t\t */\n\t\tlastbf->bf_state.stale = true;\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (!list_is_singular(&lastbf->list))\n\t\t\tlist_cut_position(&bf_head,\n\t\t\t\t&txq->axq_q, lastbf->list.prev);\n\n\t\tif (bf_held) {\n\t\t\tlist_del(&bf_held->list);\n\t\t\tath_tx_return_buffer(sc, bf_held);\n\t\t}\n\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t}\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath_tx_tasklet(struct ath_softc *sc)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tu32 qcumask = ((1 << ATH9K_NUM_TX_QUEUES) - 1) & ah->intr_txqs;\n\tint i;\n\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (ATH_TXQ_SETUP(sc, i) && (qcumask & (1 << i)))\n\t\t\tath_tx_processq(sc, &sc->tx.txq[i]);\n\t}\n}\n\nvoid ath_tx_edma_tasklet(struct ath_softc *sc)\n{\n\tstruct ath_tx_status ts;\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_txq *txq;\n\tstruct ath_buf *bf, *lastbf;\n\tstruct list_head bf_head;\n\tstruct list_head *fifo_list;\n\tint status;\n\n\tfor (;;) {\n\t\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags))\n\t\t\tbreak;\n\n\t\tstatus = ath9k_hw_txprocdesc(ah, NULL, (void *)&ts);\n\t\tif (status == -EINPROGRESS)\n\t\t\tbreak;\n\t\tif (status == -EIO) {\n\t\t\tath_dbg(common, XMIT, \"Error processing tx status\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Process beacon completions separately */\n\t\tif (ts.qid == sc->beacon.beaconq) {\n\t\t\tsc->beacon.tx_processed = true;\n\t\t\tsc->beacon.tx_last = !(ts.ts_status & ATH9K_TXERR_MASK);\n\n\t\t\tath9k_csa_is_finished(sc);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttxq = &sc->tx.txq[ts.qid];\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tTX_STAT_INC(txq->axq_qnum, txprocdesc);\n\n\t\tfifo_list = &txq->txq_fifo[txq->txq_tailidx];\n\t\tif (list_empty(fifo_list)) {\n\t\t\tath_txq_unlock(sc, txq);\n\t\t\treturn;\n\t\t}\n\n\t\tbf = list_first_entry(fifo_list, struct ath_buf, list);\n\t\tif (bf->bf_state.stale) {\n\t\t\tlist_del(&bf->list);\n\t\t\tath_tx_return_buffer(sc, bf);\n\t\t\tbf = list_first_entry(fifo_list, struct ath_buf, list);\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (list_is_last(&lastbf->list, fifo_list)) {\n\t\t\tlist_splice_tail_init(fifo_list, &bf_head);\n\t\t\tINCR(txq->txq_tailidx, ATH_TXFIFO_DEPTH);\n\n\t\t\tif (!list_empty(&txq->axq_q)) {\n\t\t\t\tstruct list_head bf_q;\n\n\t\t\t\tINIT_LIST_HEAD(&bf_q);\n\t\t\t\ttxq->axq_link = NULL;\n\t\t\t\tlist_splice_tail_init(&txq->axq_q, &bf_q);\n\t\t\t\tath_tx_txqaddbuf(sc, txq, &bf_q, true);\n\t\t\t}\n\t\t} else {\n\t\t\tlastbf->bf_state.stale = true;\n\t\t\tif (bf != lastbf)\n\t\t\t\tlist_cut_position(&bf_head, fifo_list,\n\t\t\t\t\t\t  lastbf->list.prev);\n\t\t}\n\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t\tath_txq_unlock_complete(sc, txq);\n\t}\n}\n\n/*****************/\n/* Init, Cleanup */\n/*****************/\n\nstatic int ath_txstatus_setup(struct ath_softc *sc, int size)\n{\n\tstruct ath_descdma *dd = &sc->txsdma;\n\tu8 txs_len = sc->sc_ah->caps.txs_len;\n\n\tdd->dd_desc_len = size * txs_len;\n\tdd->dd_desc = dmam_alloc_coherent(sc->dev, dd->dd_desc_len,\n\t\t\t\t\t  &dd->dd_desc_paddr, GFP_KERNEL);\n\tif (!dd->dd_desc)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int ath_tx_edma_init(struct ath_softc *sc)\n{\n\tint err;\n\n\terr = ath_txstatus_setup(sc, ATH_TXSTATUS_RING_SIZE);\n\tif (!err)\n\t\tath9k_hw_setup_statusring(sc->sc_ah, sc->txsdma.dd_desc,\n\t\t\t\t\t  sc->txsdma.dd_desc_paddr,\n\t\t\t\t\t  ATH_TXSTATUS_RING_SIZE);\n\n\treturn err;\n}\n\nint ath_tx_init(struct ath_softc *sc, int nbufs)\n{\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tint error = 0;\n\n\tspin_lock_init(&sc->tx.txbuflock);\n\n\terror = ath_descdma_setup(sc, &sc->tx.txdma, &sc->tx.txbuf,\n\t\t\t\t  \"tx\", nbufs, 1, 1);\n\tif (error != 0) {\n\t\tath_err(common,\n\t\t\t\"Failed to allocate tx descriptors: %d\\n\", error);\n\t\treturn error;\n\t}\n\n\terror = ath_descdma_setup(sc, &sc->beacon.bdma, &sc->beacon.bbuf,\n\t\t\t\t  \"beacon\", ATH_BCBUF, 1, 1);\n\tif (error != 0) {\n\t\tath_err(common,\n\t\t\t\"Failed to allocate beacon descriptors: %d\\n\", error);\n\t\treturn error;\n\t}\n\n\tINIT_DELAYED_WORK(&sc->tx_complete_work, ath_tx_complete_poll_work);\n\n\tif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)\n\t\terror = ath_tx_edma_init(sc);\n\n\treturn error;\n}\n\nvoid ath_tx_node_init(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tint tidno, acno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS;\n\t     tidno++, tid++) {\n\t\ttid->an        = an;\n\t\ttid->tidno     = tidno;\n\t\ttid->seq_start = tid->seq_next = 0;\n\t\ttid->baw_size  = WME_MAX_BA;\n\t\ttid->baw_head  = tid->baw_tail = 0;\n\t\ttid->sched     = false;\n\t\ttid->paused    = false;\n\t\ttid->active\t   = false;\n\t\t__skb_queue_head_init(&tid->buf_q);\n\t\t__skb_queue_head_init(&tid->retry_q);\n\t\tacno = TID_TO_WME_AC(tidno);\n\t\ttid->ac = &an->ac[acno];\n\t}\n\n\tfor (acno = 0, ac = &an->ac[acno];\n\t     acno < IEEE80211_NUM_ACS; acno++, ac++) {\n\t\tac->sched    = false;\n\t\tac->clear_ps_filter = true;\n\t\tac->txq = sc->tx.txq_map[acno];\n\t\tINIT_LIST_HEAD(&ac->tid_q);\n\t}\n}\n\nvoid ath_tx_node_cleanup(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_ac *ac;\n\tstruct ath_atx_tid *tid;\n\tstruct ath_txq *txq;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tif (tid->sched) {\n\t\t\tlist_del(&tid->list);\n\t\t\ttid->sched = false;\n\t\t}\n\n\t\tif (ac->sched) {\n\t\t\tlist_del(&ac->list);\n\t\t\ttid->ac->sched = false;\n\t\t}\n\n\t\tath_tid_drain(sc, txq, tid);\n\t\ttid->active = false;\n\n\t\tath_txq_unlock(sc, txq);\n\t}\n}\n\n#ifdef CONFIG_ATH9K_TX99\n\nint ath9k_tx99_send(struct ath_softc *sc, struct sk_buff *skb,\n\t\t    struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_buf *bf;\n\tint padpos, padsize;\n\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\n\tif (padsize && skb->len > padpos) {\n\t\tif (skb_headroom(skb) < padsize) {\n\t\t\tath_dbg(common, XMIT,\n\t\t\t\t\"tx99 padding failed\\n\");\n\t\treturn -EINVAL;\n\t\t}\n\n\t\tskb_push(skb, padsize);\n\t\tmemmove(skb->data, skb->data + padsize, padpos);\n\t}\n\n\tfi->keyix = ATH9K_TXKEYIX_INVALID;\n\tfi->framelen = skb->len + FCS_LEN;\n\tfi->keytype = ATH9K_KEY_TYPE_CLEAR;\n\n\tbf = ath_tx_setup_buffer(sc, txctl->txq, NULL, skb);\n\tif (!bf) {\n\t\tath_dbg(common, XMIT, \"tx99 buffer setup failed\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tath_set_rates(sc->tx99_vif, NULL, bf);\n\n\tath9k_hw_set_desc_link(sc->sc_ah, bf->bf_desc, bf->bf_daddr);\n\tath9k_hw_tx99_start(sc->sc_ah, txctl->txq->axq_qnum);\n\n\tath_tx_send_normal(sc, txctl->txq, NULL, skb);\n\n\treturn 0;\n}\n\n#endif /* CONFIG_ATH9K_TX99 */\n"], "fixing_code": ["/*\n * Copyright (c) 2008-2011 Atheros Communications Inc.\n *\n * Permission to use, copy, modify, and/or distribute this software for any\n * purpose with or without fee is hereby granted, provided that the above\n * copyright notice and this permission notice appear in all copies.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n */\n\n#include <linux/dma-mapping.h>\n#include \"ath9k.h\"\n#include \"ar9003_mac.h\"\n\n#define BITS_PER_BYTE           8\n#define OFDM_PLCP_BITS          22\n#define HT_RC_2_STREAMS(_rc)    ((((_rc) & 0x78) >> 3) + 1)\n#define L_STF                   8\n#define L_LTF                   8\n#define L_SIG                   4\n#define HT_SIG                  8\n#define HT_STF                  4\n#define HT_LTF(_ns)             (4 * (_ns))\n#define SYMBOL_TIME(_ns)        ((_ns) << 2) /* ns * 4 us */\n#define SYMBOL_TIME_HALFGI(_ns) (((_ns) * 18 + 4) / 5)  /* ns * 3.6 us */\n#define TIME_SYMBOLS(t)         ((t) >> 2)\n#define TIME_SYMBOLS_HALFGI(t)  (((t) * 5 - 4) / 18)\n#define NUM_SYMBOLS_PER_USEC(_usec) (_usec >> 2)\n#define NUM_SYMBOLS_PER_USEC_HALFGI(_usec) (((_usec*5)-4)/18)\n\n\nstatic u16 bits_per_symbol[][2] = {\n\t/* 20MHz 40MHz */\n\t{    26,   54 },     /*  0: BPSK */\n\t{    52,  108 },     /*  1: QPSK 1/2 */\n\t{    78,  162 },     /*  2: QPSK 3/4 */\n\t{   104,  216 },     /*  3: 16-QAM 1/2 */\n\t{   156,  324 },     /*  4: 16-QAM 3/4 */\n\t{   208,  432 },     /*  5: 64-QAM 2/3 */\n\t{   234,  486 },     /*  6: 64-QAM 3/4 */\n\t{   260,  540 },     /*  7: 64-QAM 5/6 */\n};\n\nstatic void ath_tx_send_normal(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct ath_atx_tid *tid, struct sk_buff *skb);\nstatic void ath_tx_complete(struct ath_softc *sc, struct sk_buff *skb,\n\t\t\t    int tx_flags, struct ath_txq *txq);\nstatic void ath_tx_complete_buf(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t\tstruct ath_txq *txq, struct list_head *bf_q,\n\t\t\t\tstruct ath_tx_status *ts, int txok);\nstatic void ath_tx_txqaddbuf(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct list_head *head, bool internal);\nstatic void ath_tx_rc_status(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_status *ts, int nframes, int nbad,\n\t\t\t     int txok);\nstatic void ath_tx_update_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t      int seqno);\nstatic struct ath_buf *ath_tx_setup_buffer(struct ath_softc *sc,\n\t\t\t\t\t   struct ath_txq *txq,\n\t\t\t\t\t   struct ath_atx_tid *tid,\n\t\t\t\t\t   struct sk_buff *skb);\n\nenum {\n\tMCS_HT20,\n\tMCS_HT20_SGI,\n\tMCS_HT40,\n\tMCS_HT40_SGI,\n};\n\n/*********************/\n/* Aggregation logic */\n/*********************/\n\nvoid ath_txq_lock(struct ath_softc *sc, struct ath_txq *txq)\n\t__acquires(&txq->axq_lock)\n{\n\tspin_lock_bh(&txq->axq_lock);\n}\n\nvoid ath_txq_unlock(struct ath_softc *sc, struct ath_txq *txq)\n\t__releases(&txq->axq_lock)\n{\n\tspin_unlock_bh(&txq->axq_lock);\n}\n\nvoid ath_txq_unlock_complete(struct ath_softc *sc, struct ath_txq *txq)\n\t__releases(&txq->axq_lock)\n{\n\tstruct sk_buff_head q;\n\tstruct sk_buff *skb;\n\n\t__skb_queue_head_init(&q);\n\tskb_queue_splice_init(&txq->complete_q, &q);\n\tspin_unlock_bh(&txq->axq_lock);\n\n\twhile ((skb = __skb_dequeue(&q)))\n\t\tieee80211_tx_status(sc->hw, skb);\n}\n\nstatic void ath_tx_queue_tid(struct ath_txq *txq, struct ath_atx_tid *tid)\n{\n\tstruct ath_atx_ac *ac = tid->ac;\n\n\tif (tid->paused)\n\t\treturn;\n\n\tif (tid->sched)\n\t\treturn;\n\n\ttid->sched = true;\n\tlist_add_tail(&tid->list, &ac->tid_q);\n\n\tif (ac->sched)\n\t\treturn;\n\n\tac->sched = true;\n\tlist_add_tail(&ac->list, &txq->axq_acq);\n}\n\nstatic struct ath_frame_info *get_frame_info(struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tBUILD_BUG_ON(sizeof(struct ath_frame_info) >\n\t\t     sizeof(tx_info->rate_driver_data));\n\treturn (struct ath_frame_info *) &tx_info->rate_driver_data[0];\n}\n\nstatic void ath_send_bar(struct ath_atx_tid *tid, u16 seqno)\n{\n\tif (!tid->an->sta)\n\t\treturn;\n\n\tieee80211_send_bar(tid->an->vif, tid->an->sta->addr, tid->tidno,\n\t\t\t   seqno << IEEE80211_SEQ_SEQ_SHIFT);\n}\n\nstatic void ath_set_rates(struct ieee80211_vif *vif, struct ieee80211_sta *sta,\n\t\t\t  struct ath_buf *bf)\n{\n\tieee80211_get_tx_rates(vif, sta, bf->bf_mpdu, bf->rates,\n\t\t\t       ARRAY_SIZE(bf->rates));\n}\n\nstatic void ath_txq_skb_done(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct sk_buff *skb)\n{\n\tint q;\n\n\tq = skb_get_queue_mapping(skb);\n\tif (txq == sc->tx.uapsdq)\n\t\ttxq = sc->tx.txq_map[q];\n\n\tif (txq != sc->tx.txq_map[q])\n\t\treturn;\n\n\tif (WARN_ON(--txq->pending_frames < 0))\n\t\ttxq->pending_frames = 0;\n\n\tif (txq->stopped &&\n\t    txq->pending_frames < sc->tx.txq_max_pending[q]) {\n\t\tieee80211_wake_queue(sc->hw, q);\n\t\ttxq->stopped = false;\n\t}\n}\n\nstatic struct ath_atx_tid *\nath_get_skb_tid(struct ath_softc *sc, struct ath_node *an, struct sk_buff *skb)\n{\n\tu8 tidno = skb->priority & IEEE80211_QOS_CTL_TID_MASK;\n\treturn ATH_AN_2_TID(an, tidno);\n}\n\nstatic bool ath_tid_has_buffered(struct ath_atx_tid *tid)\n{\n\treturn !skb_queue_empty(&tid->buf_q) || !skb_queue_empty(&tid->retry_q);\n}\n\nstatic struct sk_buff *ath_tid_dequeue(struct ath_atx_tid *tid)\n{\n\tstruct sk_buff *skb;\n\n\tskb = __skb_dequeue(&tid->retry_q);\n\tif (!skb)\n\t\tskb = __skb_dequeue(&tid->buf_q);\n\n\treturn skb;\n}\n\n/*\n * ath_tx_tid_change_state:\n * - clears a-mpdu flag of previous session\n * - force sequence number allocation to fix next BlockAck Window\n */\nstatic void\nath_tx_tid_change_state(struct ath_softc *sc, struct ath_atx_tid *tid)\n{\n\tstruct ath_txq *txq = tid->ac->txq;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct sk_buff *skb, *tskb;\n\tstruct ath_buf *bf;\n\tstruct ath_frame_info *fi;\n\n\tskb_queue_walk_safe(&tid->buf_q, skb, tskb) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\ttx_info->flags &= ~IEEE80211_TX_CTL_AMPDU;\n\n\t\tif (bf)\n\t\t\tcontinue;\n\n\t\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\t\tif (!bf) {\n\t\t\t__skb_unlink(skb, &tid->buf_q);\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\t}\n\n}\n\nstatic void ath_tx_flush_tid(struct ath_softc *sc, struct ath_atx_tid *tid)\n{\n\tstruct ath_txq *txq = tid->ac->txq;\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\tstruct ath_frame_info *fi;\n\tbool sendbar = false;\n\n\tINIT_LIST_HEAD(&bf_head);\n\n\tmemset(&ts, 0, sizeof(ts));\n\n\twhile ((skb = __skb_dequeue(&tid->retry_q))) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\t\tif (!bf) {\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (fi->baw_tracked) {\n\t\t\tath_tx_update_baw(sc, tid, bf->bf_state.seqno);\n\t\t\tsendbar = true;\n\t\t}\n\n\t\tlist_add_tail(&bf->list, &bf_head);\n\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t}\n\n\tif (sendbar) {\n\t\tath_txq_unlock(sc, txq);\n\t\tath_send_bar(tid, tid->seq_start);\n\t\tath_txq_lock(sc, txq);\n\t}\n}\n\nstatic void ath_tx_update_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t      int seqno)\n{\n\tint index, cindex;\n\n\tindex  = ATH_BA_INDEX(tid->seq_start, seqno);\n\tcindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\n\n\t__clear_bit(cindex, tid->tx_buf);\n\n\twhile (tid->baw_head != tid->baw_tail && !test_bit(tid->baw_head, tid->tx_buf)) {\n\t\tINCR(tid->seq_start, IEEE80211_SEQ_MAX);\n\t\tINCR(tid->baw_head, ATH_TID_MAX_BUFS);\n\t\tif (tid->bar_index >= 0)\n\t\t\ttid->bar_index--;\n\t}\n}\n\nstatic void ath_tx_addto_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t     struct ath_buf *bf)\n{\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\tu16 seqno = bf->bf_state.seqno;\n\tint index, cindex;\n\n\tindex  = ATH_BA_INDEX(tid->seq_start, seqno);\n\tcindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\n\t__set_bit(cindex, tid->tx_buf);\n\tfi->baw_tracked = 1;\n\n\tif (index >= ((tid->baw_tail - tid->baw_head) &\n\t\t(ATH_TID_MAX_BUFS - 1))) {\n\t\ttid->baw_tail = cindex;\n\t\tINCR(tid->baw_tail, ATH_TID_MAX_BUFS);\n\t}\n}\n\nstatic void ath_tid_drain(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t  struct ath_atx_tid *tid)\n\n{\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\tstruct ath_frame_info *fi;\n\n\tmemset(&ts, 0, sizeof(ts));\n\tINIT_LIST_HEAD(&bf_head);\n\n\twhile ((skb = ath_tid_dequeue(tid))) {\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\n\t\tif (!bf) {\n\t\t\tath_tx_complete(sc, skb, ATH_TX_ERROR, txq);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_add_tail(&bf->list, &bf_head);\n\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t}\n}\n\nstatic void ath_tx_set_retry(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct sk_buff *skb, int count)\n{\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_buf *bf = fi->bf;\n\tstruct ieee80211_hdr *hdr;\n\tint prev = fi->retries;\n\n\tTX_STAT_INC(txq->axq_qnum, a_retries);\n\tfi->retries += count;\n\n\tif (prev > 0)\n\t\treturn;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\thdr->frame_control |= cpu_to_le16(IEEE80211_FCTL_RETRY);\n\tdma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\n\t\tsizeof(*hdr), DMA_TO_DEVICE);\n}\n\nstatic struct ath_buf *ath_tx_get_buffer(struct ath_softc *sc)\n{\n\tstruct ath_buf *bf = NULL;\n\n\tspin_lock_bh(&sc->tx.txbuflock);\n\n\tif (unlikely(list_empty(&sc->tx.txbuf))) {\n\t\tspin_unlock_bh(&sc->tx.txbuflock);\n\t\treturn NULL;\n\t}\n\n\tbf = list_first_entry(&sc->tx.txbuf, struct ath_buf, list);\n\tlist_del(&bf->list);\n\n\tspin_unlock_bh(&sc->tx.txbuflock);\n\n\treturn bf;\n}\n\nstatic void ath_tx_return_buffer(struct ath_softc *sc, struct ath_buf *bf)\n{\n\tspin_lock_bh(&sc->tx.txbuflock);\n\tlist_add_tail(&bf->list, &sc->tx.txbuf);\n\tspin_unlock_bh(&sc->tx.txbuflock);\n}\n\nstatic struct ath_buf* ath_clone_txbuf(struct ath_softc *sc, struct ath_buf *bf)\n{\n\tstruct ath_buf *tbf;\n\n\ttbf = ath_tx_get_buffer(sc);\n\tif (WARN_ON(!tbf))\n\t\treturn NULL;\n\n\tATH_TXBUF_RESET(tbf);\n\n\ttbf->bf_mpdu = bf->bf_mpdu;\n\ttbf->bf_buf_addr = bf->bf_buf_addr;\n\tmemcpy(tbf->bf_desc, bf->bf_desc, sc->sc_ah->caps.tx_desc_len);\n\ttbf->bf_state = bf->bf_state;\n\ttbf->bf_state.stale = false;\n\n\treturn tbf;\n}\n\nstatic void ath_tx_count_frames(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t        struct ath_tx_status *ts, int txok,\n\t\t\t        int *nframes, int *nbad)\n{\n\tstruct ath_frame_info *fi;\n\tu16 seq_st = 0;\n\tu32 ba[WME_BA_BMP_SIZE >> 5];\n\tint ba_index;\n\tint isaggr = 0;\n\n\t*nbad = 0;\n\t*nframes = 0;\n\n\tisaggr = bf_isaggr(bf);\n\tif (isaggr) {\n\t\tseq_st = ts->ts_seqnum;\n\t\tmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\n\t}\n\n\twhile (bf) {\n\t\tfi = get_frame_info(bf->bf_mpdu);\n\t\tba_index = ATH_BA_INDEX(seq_st, bf->bf_state.seqno);\n\n\t\t(*nframes)++;\n\t\tif (!txok || (isaggr && !ATH_BA_ISSET(ba, ba_index)))\n\t\t\t(*nbad)++;\n\n\t\tbf = bf->bf_next;\n\t}\n}\n\n\nstatic void ath_tx_complete_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t\t struct ath_buf *bf, struct list_head *bf_q,\n\t\t\t\t struct ath_tx_status *ts, int txok)\n{\n\tstruct ath_node *an = NULL;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_sta *sta;\n\tstruct ieee80211_hw *hw = sc->hw;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_atx_tid *tid = NULL;\n\tstruct ath_buf *bf_next, *bf_last = bf->bf_lastbf;\n\tstruct list_head bf_head;\n\tstruct sk_buff_head bf_pending;\n\tu16 seq_st = 0, acked_cnt = 0, txfail_cnt = 0, seq_first;\n\tu32 ba[WME_BA_BMP_SIZE >> 5];\n\tint isaggr, txfail, txpending, sendbar = 0, needreset = 0, nbad = 0;\n\tbool rc_update = true, isba;\n\tstruct ieee80211_tx_rate rates[4];\n\tstruct ath_frame_info *fi;\n\tint nframes;\n\tbool flush = !!(ts->ts_status & ATH9K_TX_FLUSH);\n\tint i, retries;\n\tint bar_index = -1;\n\n\tskb = bf->bf_mpdu;\n\thdr = (struct ieee80211_hdr *)skb->data;\n\n\ttx_info = IEEE80211_SKB_CB(skb);\n\n\tmemcpy(rates, bf->rates, sizeof(rates));\n\n\tretries = ts->ts_longretry + 1;\n\tfor (i = 0; i < ts->ts_rateindex; i++)\n\t\tretries += rates[i].count;\n\n\trcu_read_lock();\n\n\tsta = ieee80211_find_sta_by_ifaddr(hw, hdr->addr1, hdr->addr2);\n\tif (!sta) {\n\t\trcu_read_unlock();\n\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\twhile (bf) {\n\t\t\tbf_next = bf->bf_next;\n\n\t\t\tif (!bf->bf_state.stale || bf_next != NULL)\n\t\t\t\tlist_move_tail(&bf->list, &bf_head);\n\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, ts, 0);\n\n\t\t\tbf = bf_next;\n\t\t}\n\t\treturn;\n\t}\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttid = ath_get_skb_tid(sc, an, skb);\n\tseq_first = tid->seq_start;\n\tisba = ts->ts_flags & ATH9K_TX_BA;\n\n\t/*\n\t * The hardware occasionally sends a tx status for the wrong TID.\n\t * In this case, the BA status cannot be considered valid and all\n\t * subframes need to be retransmitted\n\t *\n\t * Only BlockAcks have a TID and therefore normal Acks cannot be\n\t * checked\n\t */\n\tif (isba && tid->tidno != ts->tid)\n\t\ttxok = false;\n\n\tisaggr = bf_isaggr(bf);\n\tmemset(ba, 0, WME_BA_BMP_SIZE >> 3);\n\n\tif (isaggr && txok) {\n\t\tif (ts->ts_flags & ATH9K_TX_BA) {\n\t\t\tseq_st = ts->ts_seqnum;\n\t\t\tmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\n\t\t} else {\n\t\t\t/*\n\t\t\t * AR5416 can become deaf/mute when BA\n\t\t\t * issue happens. Chip needs to be reset.\n\t\t\t * But AP code may have sychronization issues\n\t\t\t * when perform internal reset in this routine.\n\t\t\t * Only enable reset in STA mode for now.\n\t\t\t */\n\t\t\tif (sc->sc_ah->opmode == NL80211_IFTYPE_STATION)\n\t\t\t\tneedreset = 1;\n\t\t}\n\t}\n\n\t__skb_queue_head_init(&bf_pending);\n\n\tath_tx_count_frames(sc, bf, ts, txok, &nframes, &nbad);\n\twhile (bf) {\n\t\tu16 seqno = bf->bf_state.seqno;\n\n\t\ttxfail = txpending = sendbar = 0;\n\t\tbf_next = bf->bf_next;\n\n\t\tskb = bf->bf_mpdu;\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\tfi = get_frame_info(skb);\n\n\t\tif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno) ||\n\t\t    !tid->active) {\n\t\t\t/*\n\t\t\t * Outside of the current BlockAck window,\n\t\t\t * maybe part of a previous session\n\t\t\t */\n\t\t\ttxfail = 1;\n\t\t} else if (ATH_BA_ISSET(ba, ATH_BA_INDEX(seq_st, seqno))) {\n\t\t\t/* transmit completion, subframe is\n\t\t\t * acked by block ack */\n\t\t\tacked_cnt++;\n\t\t} else if (!isaggr && txok) {\n\t\t\t/* transmit completion */\n\t\t\tacked_cnt++;\n\t\t} else if (flush) {\n\t\t\ttxpending = 1;\n\t\t} else if (fi->retries < ATH_MAX_SW_RETRIES) {\n\t\t\tif (txok || !an->sleeping)\n\t\t\t\tath_tx_set_retry(sc, txq, bf->bf_mpdu,\n\t\t\t\t\t\t retries);\n\n\t\t\ttxpending = 1;\n\t\t} else {\n\t\t\ttxfail = 1;\n\t\t\ttxfail_cnt++;\n\t\t\tbar_index = max_t(int, bar_index,\n\t\t\t\tATH_BA_INDEX(seq_first, seqno));\n\t\t}\n\n\t\t/*\n\t\t * Make sure the last desc is reclaimed if it\n\t\t * not a holding desc.\n\t\t */\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (bf_next != NULL || !bf_last->bf_state.stale)\n\t\t\tlist_move_tail(&bf->list, &bf_head);\n\n\t\tif (!txpending) {\n\t\t\t/*\n\t\t\t * complete the acked-ones/xretried ones; update\n\t\t\t * block-ack window\n\t\t\t */\n\t\t\tath_tx_update_baw(sc, tid, seqno);\n\n\t\t\tif (rc_update && (acked_cnt == 1 || txfail_cnt == 1)) {\n\t\t\t\tmemcpy(tx_info->control.rates, rates, sizeof(rates));\n\t\t\t\tath_tx_rc_status(sc, bf, ts, nframes, nbad, txok);\n\t\t\t\trc_update = false;\n\t\t\t}\n\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, ts,\n\t\t\t\t!txfail);\n\t\t} else {\n\t\t\tif (tx_info->flags & IEEE80211_TX_STATUS_EOSP) {\n\t\t\t\ttx_info->flags &= ~IEEE80211_TX_STATUS_EOSP;\n\t\t\t\tieee80211_sta_eosp(sta);\n\t\t\t}\n\t\t\t/* retry the un-acked ones */\n\t\t\tif (bf->bf_next == NULL && bf_last->bf_state.stale) {\n\t\t\t\tstruct ath_buf *tbf;\n\n\t\t\t\ttbf = ath_clone_txbuf(sc, bf_last);\n\t\t\t\t/*\n\t\t\t\t * Update tx baw and complete the\n\t\t\t\t * frame with failed status if we\n\t\t\t\t * run out of tx buf.\n\t\t\t\t */\n\t\t\t\tif (!tbf) {\n\t\t\t\t\tath_tx_update_baw(sc, tid, seqno);\n\n\t\t\t\t\tath_tx_complete_buf(sc, bf, txq,\n\t\t\t\t\t\t\t    &bf_head, ts, 0);\n\t\t\t\t\tbar_index = max_t(int, bar_index,\n\t\t\t\t\t\tATH_BA_INDEX(seq_first, seqno));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tfi->bf = tbf;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Put this buffer to the temporary pending\n\t\t\t * queue to retain ordering\n\t\t\t */\n\t\t\t__skb_queue_tail(&bf_pending, skb);\n\t\t}\n\n\t\tbf = bf_next;\n\t}\n\n\t/* prepend un-acked frames to the beginning of the pending frame queue */\n\tif (!skb_queue_empty(&bf_pending)) {\n\t\tif (an->sleeping)\n\t\t\tieee80211_sta_set_buffered(sta, tid->tidno, true);\n\n\t\tskb_queue_splice_tail(&bf_pending, &tid->retry_q);\n\t\tif (!an->sleeping) {\n\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\t\tif (ts->ts_status & (ATH9K_TXERR_FILT | ATH9K_TXERR_XRETRY))\n\t\t\t\ttid->ac->clear_ps_filter = true;\n\t\t}\n\t}\n\n\tif (bar_index >= 0) {\n\t\tu16 bar_seq = ATH_BA_INDEX2SEQ(seq_first, bar_index);\n\n\t\tif (BAW_WITHIN(tid->seq_start, tid->baw_size, bar_seq))\n\t\t\ttid->bar_index = ATH_BA_INDEX(tid->seq_start, bar_seq);\n\n\t\tath_txq_unlock(sc, txq);\n\t\tath_send_bar(tid, ATH_BA_INDEX2SEQ(seq_first, bar_index + 1));\n\t\tath_txq_lock(sc, txq);\n\t}\n\n\trcu_read_unlock();\n\n\tif (needreset)\n\t\tath9k_queue_reset(sc, RESET_TYPE_TX_ERROR);\n}\n\nstatic bool bf_is_ampdu_not_probing(struct ath_buf *bf)\n{\n    struct ieee80211_tx_info *info = IEEE80211_SKB_CB(bf->bf_mpdu);\n    return bf_isampdu(bf) && !(info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE);\n}\n\nstatic void ath_tx_process_buffer(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t\t  struct ath_tx_status *ts, struct ath_buf *bf,\n\t\t\t\t  struct list_head *bf_head)\n{\n\tstruct ieee80211_tx_info *info;\n\tbool txok, flush;\n\n\ttxok = !(ts->ts_status & ATH9K_TXERR_MASK);\n\tflush = !!(ts->ts_status & ATH9K_TX_FLUSH);\n\ttxq->axq_tx_inprogress = false;\n\n\ttxq->axq_depth--;\n\tif (bf_is_ampdu_not_probing(bf))\n\t\ttxq->axq_ampdu_depth--;\n\n\tif (!bf_isampdu(bf)) {\n\t\tif (!flush) {\n\t\t\tinfo = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\t\tmemcpy(info->control.rates, bf->rates,\n\t\t\t       sizeof(info->control.rates));\n\t\t\tath_tx_rc_status(sc, bf, ts, 1, txok ? 0 : 1, txok);\n\t\t}\n\t\tath_tx_complete_buf(sc, bf, txq, bf_head, ts, txok);\n\t} else\n\t\tath_tx_complete_aggr(sc, txq, bf, bf_head, ts, txok);\n\n\tif (!flush)\n\t\tath_txq_schedule(sc, txq);\n}\n\nstatic bool ath_lookup_legacy(struct ath_buf *bf)\n{\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tint i;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = tx_info->control.rates;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tif (!rates[i].count || rates[i].idx < 0)\n\t\t\tbreak;\n\n\t\tif (!(rates[i].flags & IEEE80211_TX_RC_MCS))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic u32 ath_lookup_rate(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t   struct ath_atx_tid *tid)\n{\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tu32 max_4ms_framelen, frmlen;\n\tu16 aggr_limit, bt_aggr_limit, legacy = 0;\n\tint q = tid->ac->txq->mac80211_qnum;\n\tint i;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = bf->rates;\n\n\t/*\n\t * Find the lowest frame length among the rate series that will have a\n\t * 4ms (or TXOP limited) transmit duration.\n\t */\n\tmax_4ms_framelen = ATH_AMPDU_LIMIT_MAX;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tint modeidx;\n\n\t\tif (!rates[i].count)\n\t\t\tcontinue;\n\n\t\tif (!(rates[i].flags & IEEE80211_TX_RC_MCS)) {\n\t\t\tlegacy = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\n\t\t\tmodeidx = MCS_HT40;\n\t\telse\n\t\t\tmodeidx = MCS_HT20;\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\n\t\t\tmodeidx++;\n\n\t\tfrmlen = sc->tx.max_aggr_framelen[q][modeidx][rates[i].idx];\n\t\tmax_4ms_framelen = min(max_4ms_framelen, frmlen);\n\t}\n\n\t/*\n\t * limit aggregate size by the minimum rate if rate selected is\n\t * not a probe rate, if rate selected is a probe rate then\n\t * avoid aggregation of this packet.\n\t */\n\tif (tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE || legacy)\n\t\treturn 0;\n\n\taggr_limit = min(max_4ms_framelen, (u32)ATH_AMPDU_LIMIT_MAX);\n\n\t/*\n\t * Override the default aggregation limit for BTCOEX.\n\t */\n\tbt_aggr_limit = ath9k_btcoex_aggr_limit(sc, max_4ms_framelen);\n\tif (bt_aggr_limit)\n\t\taggr_limit = bt_aggr_limit;\n\n\tif (tid->an->maxampdu)\n\t\taggr_limit = min(aggr_limit, tid->an->maxampdu);\n\n\treturn aggr_limit;\n}\n\n/*\n * Returns the number of delimiters to be added to\n * meet the minimum required mpdudensity.\n */\nstatic int ath_compute_num_delims(struct ath_softc *sc, struct ath_atx_tid *tid,\n\t\t\t\t  struct ath_buf *bf, u16 frmlen,\n\t\t\t\t  bool first_subfrm)\n{\n#define FIRST_DESC_NDELIMS 60\n\tu32 nsymbits, nsymbols;\n\tu16 minlen;\n\tu8 flags, rix;\n\tint width, streams, half_gi, ndelim, mindelim;\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\n\t/* Select standard number of delimiters based on frame length alone */\n\tndelim = ATH_AGGR_GET_NDELIM(frmlen);\n\n\t/*\n\t * If encryption enabled, hardware requires some more padding between\n\t * subframes.\n\t * TODO - this could be improved to be dependent on the rate.\n\t *      The hardware can keep up at lower rates, but not higher rates\n\t */\n\tif ((fi->keyix != ATH9K_TXKEYIX_INVALID) &&\n\t    !(sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA))\n\t\tndelim += ATH_AGGR_ENCRYPTDELIM;\n\n\t/*\n\t * Add delimiter when using RTS/CTS with aggregation\n\t * and non enterprise AR9003 card\n\t */\n\tif (first_subfrm && !AR_SREV_9580_10_OR_LATER(sc->sc_ah) &&\n\t    (sc->sc_ah->ent_mode & AR_ENT_OTP_MIN_PKT_SIZE_DISABLE))\n\t\tndelim = max(ndelim, FIRST_DESC_NDELIMS);\n\n\t/*\n\t * Convert desired mpdu density from microeconds to bytes based\n\t * on highest rate in rate series (i.e. first rate) to determine\n\t * required minimum length for subframe. Take into account\n\t * whether high rate is 20 or 40Mhz and half or full GI.\n\t *\n\t * If there is no mpdu density restriction, no further calculation\n\t * is needed.\n\t */\n\n\tif (tid->an->mpdudensity == 0)\n\t\treturn ndelim;\n\n\trix = bf->rates[0].idx;\n\tflags = bf->rates[0].flags;\n\twidth = (flags & IEEE80211_TX_RC_40_MHZ_WIDTH) ? 1 : 0;\n\thalf_gi = (flags & IEEE80211_TX_RC_SHORT_GI) ? 1 : 0;\n\n\tif (half_gi)\n\t\tnsymbols = NUM_SYMBOLS_PER_USEC_HALFGI(tid->an->mpdudensity);\n\telse\n\t\tnsymbols = NUM_SYMBOLS_PER_USEC(tid->an->mpdudensity);\n\n\tif (nsymbols == 0)\n\t\tnsymbols = 1;\n\n\tstreams = HT_RC_2_STREAMS(rix);\n\tnsymbits = bits_per_symbol[rix % 8][width] * streams;\n\tminlen = (nsymbols * nsymbits) / BITS_PER_BYTE;\n\n\tif (frmlen < minlen) {\n\t\tmindelim = (minlen - frmlen) / ATH_AGGR_DELIM_SZ;\n\t\tndelim = max(mindelim, ndelim);\n\t}\n\n\treturn ndelim;\n}\n\nstatic struct ath_buf *\nath_tx_get_tid_subframe(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\tstruct ath_atx_tid *tid, struct sk_buff_head **q)\n{\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_frame_info *fi;\n\tstruct sk_buff *skb;\n\tstruct ath_buf *bf;\n\tu16 seqno;\n\n\twhile (1) {\n\t\t*q = &tid->retry_q;\n\t\tif (skb_queue_empty(*q))\n\t\t\t*q = &tid->buf_q;\n\n\t\tskb = skb_peek(*q);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tfi = get_frame_info(skb);\n\t\tbf = fi->bf;\n\t\tif (!fi->bf)\n\t\t\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\t\telse\n\t\t\tbf->bf_state.stale = false;\n\n\t\tif (!bf) {\n\t\t\t__skb_unlink(skb, *q);\n\t\t\tath_txq_skb_done(sc, txq, skb);\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbf->bf_next = NULL;\n\t\tbf->bf_lastbf = bf;\n\n\t\ttx_info = IEEE80211_SKB_CB(skb);\n\t\ttx_info->flags &= ~IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\t\tif (!(tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\n\t\t\tbf->bf_state.bf_type = 0;\n\t\t\treturn bf;\n\t\t}\n\n\t\tbf->bf_state.bf_type = BUF_AMPDU | BUF_AGGR;\n\t\tseqno = bf->bf_state.seqno;\n\n\t\t/* do not step over block-ack window */\n\t\tif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno))\n\t\t\tbreak;\n\n\t\tif (tid->bar_index > ATH_BA_INDEX(tid->seq_start, seqno)) {\n\t\t\tstruct ath_tx_status ts = {};\n\t\t\tstruct list_head bf_head;\n\n\t\t\tINIT_LIST_HEAD(&bf_head);\n\t\t\tlist_add(&bf->list, &bf_head);\n\t\t\t__skb_unlink(skb, *q);\n\t\t\tath_tx_update_baw(sc, tid, seqno);\n\t\t\tath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn bf;\n\t}\n\n\treturn NULL;\n}\n\nstatic bool\nath_tx_form_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t struct ath_atx_tid *tid, struct list_head *bf_q,\n\t\t struct ath_buf *bf_first, struct sk_buff_head *tid_q,\n\t\t int *aggr_len)\n{\n#define PADBYTES(_len) ((4 - ((_len) % 4)) % 4)\n\tstruct ath_buf *bf = bf_first, *bf_prev = NULL;\n\tint nframes = 0, ndelim;\n\tu16 aggr_limit = 0, al = 0, bpad = 0,\n\t    al_delta, h_baw = tid->baw_size / 2;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ath_frame_info *fi;\n\tstruct sk_buff *skb;\n\tbool closed = false;\n\n\tbf = bf_first;\n\taggr_limit = ath_lookup_rate(sc, bf, tid);\n\n\tdo {\n\t\tskb = bf->bf_mpdu;\n\t\tfi = get_frame_info(skb);\n\n\t\t/* do not exceed aggregation limit */\n\t\tal_delta = ATH_AGGR_DELIM_SZ + fi->framelen;\n\t\tif (nframes) {\n\t\t\tif (aggr_limit < al + bpad + al_delta ||\n\t\t\t    ath_lookup_legacy(bf) || nframes >= h_baw)\n\t\t\t\tbreak;\n\n\t\t\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\t\tif ((tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE) ||\n\t\t\t    !(tx_info->flags & IEEE80211_TX_CTL_AMPDU))\n\t\t\t\tbreak;\n\t\t}\n\n\t\t/* add padding for previous frame to aggregation length */\n\t\tal += bpad + al_delta;\n\n\t\t/*\n\t\t * Get the delimiters needed to meet the MPDU\n\t\t * density for this node.\n\t\t */\n\t\tndelim = ath_compute_num_delims(sc, tid, bf_first, fi->framelen,\n\t\t\t\t\t\t!nframes);\n\t\tbpad = PADBYTES(al_delta) + (ndelim << 2);\n\n\t\tnframes++;\n\t\tbf->bf_next = NULL;\n\n\t\t/* link buffers of this frame to the aggregate */\n\t\tif (!fi->baw_tracked)\n\t\t\tath_tx_addto_baw(sc, tid, bf);\n\t\tbf->bf_state.ndelim = ndelim;\n\n\t\t__skb_unlink(skb, tid_q);\n\t\tlist_add_tail(&bf->list, bf_q);\n\t\tif (bf_prev)\n\t\t\tbf_prev->bf_next = bf;\n\n\t\tbf_prev = bf;\n\n\t\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\t\tif (!bf) {\n\t\t\tclosed = true;\n\t\t\tbreak;\n\t\t}\n\t} while (ath_tid_has_buffered(tid));\n\n\tbf = bf_first;\n\tbf->bf_lastbf = bf_prev;\n\n\tif (bf == bf_prev) {\n\t\tal = get_frame_info(bf->bf_mpdu)->framelen;\n\t\tbf->bf_state.bf_type = BUF_AMPDU;\n\t} else {\n\t\tTX_STAT_INC(txq->axq_qnum, a_aggr);\n\t}\n\n\t*aggr_len = al;\n\n\treturn closed;\n#undef PADBYTES\n}\n\n/*\n * rix - rate index\n * pktlen - total bytes (delims + data + fcs + pads + pad delims)\n * width  - 0 for 20 MHz, 1 for 40 MHz\n * half_gi - to use 4us v/s 3.6 us for symbol time\n */\nstatic u32 ath_pkt_duration(struct ath_softc *sc, u8 rix, int pktlen,\n\t\t\t    int width, int half_gi, bool shortPreamble)\n{\n\tu32 nbits, nsymbits, duration, nsymbols;\n\tint streams;\n\n\t/* find number of symbols: PLCP + data */\n\tstreams = HT_RC_2_STREAMS(rix);\n\tnbits = (pktlen << 3) + OFDM_PLCP_BITS;\n\tnsymbits = bits_per_symbol[rix % 8][width] * streams;\n\tnsymbols = (nbits + nsymbits - 1) / nsymbits;\n\n\tif (!half_gi)\n\t\tduration = SYMBOL_TIME(nsymbols);\n\telse\n\t\tduration = SYMBOL_TIME_HALFGI(nsymbols);\n\n\t/* addup duration for legacy/ht training and signal fields */\n\tduration += L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\n\n\treturn duration;\n}\n\nstatic int ath_max_framelen(int usec, int mcs, bool ht40, bool sgi)\n{\n\tint streams = HT_RC_2_STREAMS(mcs);\n\tint symbols, bits;\n\tint bytes = 0;\n\n\tsymbols = sgi ? TIME_SYMBOLS_HALFGI(usec) : TIME_SYMBOLS(usec);\n\tbits = symbols * bits_per_symbol[mcs % 8][ht40] * streams;\n\tbits -= OFDM_PLCP_BITS;\n\tbytes = bits / 8;\n\tbytes -= L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\n\tif (bytes > 65532)\n\t\tbytes = 65532;\n\n\treturn bytes;\n}\n\nvoid ath_update_max_aggr_framelen(struct ath_softc *sc, int queue, int txop)\n{\n\tu16 *cur_ht20, *cur_ht20_sgi, *cur_ht40, *cur_ht40_sgi;\n\tint mcs;\n\n\t/* 4ms is the default (and maximum) duration */\n\tif (!txop || txop > 4096)\n\t\ttxop = 4096;\n\n\tcur_ht20 = sc->tx.max_aggr_framelen[queue][MCS_HT20];\n\tcur_ht20_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT20_SGI];\n\tcur_ht40 = sc->tx.max_aggr_framelen[queue][MCS_HT40];\n\tcur_ht40_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT40_SGI];\n\tfor (mcs = 0; mcs < 32; mcs++) {\n\t\tcur_ht20[mcs] = ath_max_framelen(txop, mcs, false, false);\n\t\tcur_ht20_sgi[mcs] = ath_max_framelen(txop, mcs, false, true);\n\t\tcur_ht40[mcs] = ath_max_framelen(txop, mcs, true, false);\n\t\tcur_ht40_sgi[mcs] = ath_max_framelen(txop, mcs, true, true);\n\t}\n}\n\nstatic void ath_buf_set_rate(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_info *info, int len, bool rts)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct ieee80211_tx_rate *rates;\n\tconst struct ieee80211_rate *rate;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\n\tu32 rts_thresh = sc->hw->wiphy->rts_threshold;\n\tint i;\n\tu8 rix = 0;\n\n\tskb = bf->bf_mpdu;\n\ttx_info = IEEE80211_SKB_CB(skb);\n\trates = bf->rates;\n\thdr = (struct ieee80211_hdr *)skb->data;\n\n\t/* set dur_update_en for l-sig computation except for PS-Poll frames */\n\tinfo->dur_update = !ieee80211_is_pspoll(hdr->frame_control);\n\tinfo->rtscts_rate = fi->rtscts_rate;\n\n\tfor (i = 0; i < ARRAY_SIZE(bf->rates); i++) {\n\t\tbool is_40, is_sgi, is_sp;\n\t\tint phy;\n\n\t\tif (!rates[i].count || (rates[i].idx < 0))\n\t\t\tcontinue;\n\n\t\trix = rates[i].idx;\n\t\tinfo->rates[i].Tries = rates[i].count;\n\n\t\t/*\n\t\t * Handle RTS threshold for unaggregated HT frames.\n\t\t */\n\t\tif (bf_isampdu(bf) && !bf_isaggr(bf) &&\n\t\t    (rates[i].flags & IEEE80211_TX_RC_MCS) &&\n\t\t    unlikely(rts_thresh != (u32) -1)) {\n\t\t\tif (!rts_thresh || (len > rts_thresh))\n\t\t\t\trts = true;\n\t\t}\n\n\t\tif (rts || rates[i].flags & IEEE80211_TX_RC_USE_RTS_CTS) {\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\n\t\t\tinfo->flags |= ATH9K_TXDESC_RTSENA;\n\t\t} else if (rates[i].flags & IEEE80211_TX_RC_USE_CTS_PROTECT) {\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\n\t\t\tinfo->flags |= ATH9K_TXDESC_CTSENA;\n\t\t}\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_2040;\n\t\tif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\n\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_HALFGI;\n\n\t\tis_sgi = !!(rates[i].flags & IEEE80211_TX_RC_SHORT_GI);\n\t\tis_40 = !!(rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH);\n\t\tis_sp = !!(rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE);\n\n\t\tif (rates[i].flags & IEEE80211_TX_RC_MCS) {\n\t\t\t/* MCS rates */\n\t\t\tinfo->rates[i].Rate = rix | 0x80;\n\t\t\tinfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\n\t\t\t\t\tah->txchainmask, info->rates[i].Rate);\n\t\t\tinfo->rates[i].PktDuration = ath_pkt_duration(sc, rix, len,\n\t\t\t\t is_40, is_sgi, is_sp);\n\t\t\tif (rix < 8 && (tx_info->flags & IEEE80211_TX_CTL_STBC))\n\t\t\t\tinfo->rates[i].RateFlags |= ATH9K_RATESERIES_STBC;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* legacy rates */\n\t\trate = &sc->sbands[tx_info->band].bitrates[rates[i].idx];\n\t\tif ((tx_info->band == IEEE80211_BAND_2GHZ) &&\n\t\t    !(rate->flags & IEEE80211_RATE_ERP_G))\n\t\t\tphy = WLAN_RC_PHY_CCK;\n\t\telse\n\t\t\tphy = WLAN_RC_PHY_OFDM;\n\n\t\tinfo->rates[i].Rate = rate->hw_value;\n\t\tif (rate->hw_value_short) {\n\t\t\tif (rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE)\n\t\t\t\tinfo->rates[i].Rate |= rate->hw_value_short;\n\t\t} else {\n\t\t\tis_sp = false;\n\t\t}\n\n\t\tif (bf->bf_state.bfs_paprd)\n\t\t\tinfo->rates[i].ChSel = ah->txchainmask;\n\t\telse\n\t\t\tinfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\n\t\t\t\t\tah->txchainmask, info->rates[i].Rate);\n\n\t\tinfo->rates[i].PktDuration = ath9k_hw_computetxtime(sc->sc_ah,\n\t\t\tphy, rate->bitrate * 100, len, rix, is_sp);\n\t}\n\n\t/* For AR5416 - RTS cannot be followed by a frame larger than 8K */\n\tif (bf_isaggr(bf) && (len > sc->sc_ah->caps.rts_aggr_limit))\n\t\tinfo->flags &= ~ATH9K_TXDESC_RTSENA;\n\n\t/* ATH9K_TXDESC_RTSENA and ATH9K_TXDESC_CTSENA are mutually exclusive. */\n\tif (info->flags & ATH9K_TXDESC_RTSENA)\n\t\tinfo->flags &= ~ATH9K_TXDESC_CTSENA;\n}\n\nstatic enum ath9k_pkt_type get_hw_packet_type(struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\tenum ath9k_pkt_type htype;\n\t__le16 fc;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tfc = hdr->frame_control;\n\n\tif (ieee80211_is_beacon(fc))\n\t\thtype = ATH9K_PKT_TYPE_BEACON;\n\telse if (ieee80211_is_probe_resp(fc))\n\t\thtype = ATH9K_PKT_TYPE_PROBE_RESP;\n\telse if (ieee80211_is_atim(fc))\n\t\thtype = ATH9K_PKT_TYPE_ATIM;\n\telse if (ieee80211_is_pspoll(fc))\n\t\thtype = ATH9K_PKT_TYPE_PSPOLL;\n\telse\n\t\thtype = ATH9K_PKT_TYPE_NORMAL;\n\n\treturn htype;\n}\n\nstatic void ath_tx_fill_desc(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_txq *txq, int len)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_buf *bf_first = NULL;\n\tstruct ath_tx_info info;\n\tu32 rts_thresh = sc->hw->wiphy->rts_threshold;\n\tbool rts = false;\n\n\tmemset(&info, 0, sizeof(info));\n\tinfo.is_first = true;\n\tinfo.is_last = true;\n\tinfo.txpower = MAX_RATE_POWER;\n\tinfo.qcu = txq->axq_qnum;\n\n\twhile (bf) {\n\t\tstruct sk_buff *skb = bf->bf_mpdu;\n\t\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\t\tstruct ath_frame_info *fi = get_frame_info(skb);\n\t\tbool aggr = !!(bf->bf_state.bf_type & BUF_AGGR);\n\n\t\tinfo.type = get_hw_packet_type(skb);\n\t\tif (bf->bf_next)\n\t\t\tinfo.link = bf->bf_next->bf_daddr;\n\t\telse\n\t\t\tinfo.link = (sc->tx99_state) ? bf->bf_daddr : 0;\n\n\t\tif (!bf_first) {\n\t\t\tbf_first = bf;\n\n\t\t\tif (!sc->tx99_state)\n\t\t\t\tinfo.flags = ATH9K_TXDESC_INTREQ;\n\t\t\tif ((tx_info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT) ||\n\t\t\t    txq == sc->tx.uapsdq)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_CLRDMASK;\n\n\t\t\tif (tx_info->flags & IEEE80211_TX_CTL_NO_ACK)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_NOACK;\n\t\t\tif (tx_info->flags & IEEE80211_TX_CTL_LDPC)\n\t\t\t\tinfo.flags |= ATH9K_TXDESC_LDPC;\n\n\t\t\tif (bf->bf_state.bfs_paprd)\n\t\t\t\tinfo.flags |= (u32) bf->bf_state.bfs_paprd <<\n\t\t\t\t\t      ATH9K_TXDESC_PAPRD_S;\n\n\t\t\t/*\n\t\t\t * mac80211 doesn't handle RTS threshold for HT because\n\t\t\t * the decision has to be taken based on AMPDU length\n\t\t\t * and aggregation is done entirely inside ath9k.\n\t\t\t * Set the RTS/CTS flag for the first subframe based\n\t\t\t * on the threshold.\n\t\t\t */\n\t\t\tif (aggr && (bf == bf_first) &&\n\t\t\t    unlikely(rts_thresh != (u32) -1)) {\n\t\t\t\t/*\n\t\t\t\t * \"len\" is the size of the entire AMPDU.\n\t\t\t\t */\n\t\t\t\tif (!rts_thresh || (len > rts_thresh))\n\t\t\t\t\trts = true;\n\t\t\t}\n\n\t\t\tif (!aggr)\n\t\t\t\tlen = fi->framelen;\n\n\t\t\tath_buf_set_rate(sc, bf, &info, len, rts);\n\t\t}\n\n\t\tinfo.buf_addr[0] = bf->bf_buf_addr;\n\t\tinfo.buf_len[0] = skb->len;\n\t\tinfo.pkt_len = fi->framelen;\n\t\tinfo.keyix = fi->keyix;\n\t\tinfo.keytype = fi->keytype;\n\n\t\tif (aggr) {\n\t\t\tif (bf == bf_first)\n\t\t\t\tinfo.aggr = AGGR_BUF_FIRST;\n\t\t\telse if (bf == bf_first->bf_lastbf)\n\t\t\t\tinfo.aggr = AGGR_BUF_LAST;\n\t\t\telse\n\t\t\t\tinfo.aggr = AGGR_BUF_MIDDLE;\n\n\t\t\tinfo.ndelim = bf->bf_state.ndelim;\n\t\t\tinfo.aggr_len = len;\n\t\t}\n\n\t\tif (bf == bf_first->bf_lastbf)\n\t\t\tbf_first = NULL;\n\n\t\tath9k_hw_set_txdesc(ah, bf->bf_desc, &info);\n\t\tbf = bf->bf_next;\n\t}\n}\n\nstatic void\nath_tx_form_burst(struct ath_softc *sc, struct ath_txq *txq,\n\t\t  struct ath_atx_tid *tid, struct list_head *bf_q,\n\t\t  struct ath_buf *bf_first, struct sk_buff_head *tid_q)\n{\n\tstruct ath_buf *bf = bf_first, *bf_prev = NULL;\n\tstruct sk_buff *skb;\n\tint nframes = 0;\n\n\tdo {\n\t\tstruct ieee80211_tx_info *tx_info;\n\t\tskb = bf->bf_mpdu;\n\n\t\tnframes++;\n\t\t__skb_unlink(skb, tid_q);\n\t\tlist_add_tail(&bf->list, bf_q);\n\t\tif (bf_prev)\n\t\t\tbf_prev->bf_next = bf;\n\t\tbf_prev = bf;\n\n\t\tif (nframes >= 2)\n\t\t\tbreak;\n\n\t\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\t\tif (!bf)\n\t\t\tbreak;\n\n\t\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\t\tif (tx_info->flags & IEEE80211_TX_CTL_AMPDU)\n\t\t\tbreak;\n\n\t\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\t} while (1);\n}\n\nstatic bool ath_tx_sched_aggr(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t      struct ath_atx_tid *tid, bool *stop)\n{\n\tstruct ath_buf *bf;\n\tstruct ieee80211_tx_info *tx_info;\n\tstruct sk_buff_head *tid_q;\n\tstruct list_head bf_q;\n\tint aggr_len = 0;\n\tbool aggr, last = true;\n\n\tif (!ath_tid_has_buffered(tid))\n\t\treturn false;\n\n\tINIT_LIST_HEAD(&bf_q);\n\n\tbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\n\tif (!bf)\n\t\treturn false;\n\n\ttx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\n\taggr = !!(tx_info->flags & IEEE80211_TX_CTL_AMPDU);\n\tif ((aggr && txq->axq_ampdu_depth >= ATH_AGGR_MIN_QDEPTH) ||\n\t\t(!aggr && txq->axq_depth >= ATH_NON_AGGR_MIN_QDEPTH)) {\n\t\t*stop = true;\n\t\treturn false;\n\t}\n\n\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\tif (aggr)\n\t\tlast = ath_tx_form_aggr(sc, txq, tid, &bf_q, bf,\n\t\t\t\t\ttid_q, &aggr_len);\n\telse\n\t\tath_tx_form_burst(sc, txq, tid, &bf_q, bf, tid_q);\n\n\tif (list_empty(&bf_q))\n\t\treturn false;\n\n\tif (tid->ac->clear_ps_filter || tid->an->no_ps_filter) {\n\t\ttid->ac->clear_ps_filter = false;\n\t\ttx_info->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\t}\n\n\tath_tx_fill_desc(sc, bf, txq, aggr_len);\n\tath_tx_txqaddbuf(sc, txq, &bf_q, false);\n\treturn true;\n}\n\nint ath_tx_aggr_start(struct ath_softc *sc, struct ieee80211_sta *sta,\n\t\t      u16 tid, u16 *ssn)\n{\n\tstruct ath_atx_tid *txtid;\n\tstruct ath_txq *txq;\n\tstruct ath_node *an;\n\tu8 density;\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttxtid = ATH_AN_2_TID(an, tid);\n\ttxq = txtid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\n\t/* update ampdu factor/density, they may have changed. This may happen\n\t * in HT IBSS when a beacon with HT-info is received after the station\n\t * has already been added.\n\t */\n\tif (sta->ht_cap.ht_supported) {\n\t\tan->maxampdu = (1 << (IEEE80211_HT_MAX_AMPDU_FACTOR +\n\t\t\t\t      sta->ht_cap.ampdu_factor)) - 1;\n\t\tdensity = ath9k_parse_mpdudensity(sta->ht_cap.ampdu_density);\n\t\tan->mpdudensity = density;\n\t}\n\n\t/* force sequence number allocation for pending frames */\n\tath_tx_tid_change_state(sc, txtid);\n\n\ttxtid->active = true;\n\ttxtid->paused = true;\n\t*ssn = txtid->seq_start = txtid->seq_next;\n\ttxtid->bar_index = -1;\n\n\tmemset(txtid->tx_buf, 0, sizeof(txtid->tx_buf));\n\ttxtid->baw_head = txtid->baw_tail = 0;\n\n\tath_txq_unlock_complete(sc, txq);\n\n\treturn 0;\n}\n\nvoid ath_tx_aggr_stop(struct ath_softc *sc, struct ieee80211_sta *sta, u16 tid)\n{\n\tstruct ath_node *an = (struct ath_node *)sta->drv_priv;\n\tstruct ath_atx_tid *txtid = ATH_AN_2_TID(an, tid);\n\tstruct ath_txq *txq = txtid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\ttxtid->active = false;\n\ttxtid->paused = false;\n\tath_tx_flush_tid(sc, txtid);\n\tath_tx_tid_change_state(sc, txtid);\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath_tx_aggr_sleep(struct ieee80211_sta *sta, struct ath_softc *sc,\n\t\t       struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tstruct ath_txq *txq;\n\tbool buffered;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tif (!tid->sched) {\n\t\t\tath_txq_unlock(sc, txq);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbuffered = ath_tid_has_buffered(tid);\n\n\t\ttid->sched = false;\n\t\tlist_del(&tid->list);\n\n\t\tif (ac->sched) {\n\t\t\tac->sched = false;\n\t\t\tlist_del(&ac->list);\n\t\t}\n\n\t\tath_txq_unlock(sc, txq);\n\n\t\tieee80211_sta_set_buffered(sta, tidno, buffered);\n\t}\n}\n\nvoid ath_tx_aggr_wakeup(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tstruct ath_txq *txq;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\t\tac->clear_ps_filter = true;\n\n\t\tif (!tid->paused && ath_tid_has_buffered(tid)) {\n\t\t\tath_tx_queue_tid(txq, tid);\n\t\t\tath_txq_schedule(sc, txq);\n\t\t}\n\n\t\tath_txq_unlock_complete(sc, txq);\n\t}\n}\n\nvoid ath_tx_aggr_resume(struct ath_softc *sc, struct ieee80211_sta *sta,\n\t\t\tu16 tidno)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_node *an;\n\tstruct ath_txq *txq;\n\n\tan = (struct ath_node *)sta->drv_priv;\n\ttid = ATH_AN_2_TID(an, tidno);\n\ttxq = tid->ac->txq;\n\n\tath_txq_lock(sc, txq);\n\n\ttid->baw_size = IEEE80211_MIN_AMPDU_BUF << sta->ht_cap.ampdu_factor;\n\ttid->paused = false;\n\n\tif (ath_tid_has_buffered(tid)) {\n\t\tath_tx_queue_tid(txq, tid);\n\t\tath_txq_schedule(sc, txq);\n\t}\n\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath9k_release_buffered_frames(struct ieee80211_hw *hw,\n\t\t\t\t   struct ieee80211_sta *sta,\n\t\t\t\t   u16 tids, int nframes,\n\t\t\t\t   enum ieee80211_frame_release_type reason,\n\t\t\t\t   bool more_data)\n{\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_node *an = (struct ath_node *)sta->drv_priv;\n\tstruct ath_txq *txq = sc->tx.uapsdq;\n\tstruct ieee80211_tx_info *info;\n\tstruct list_head bf_q;\n\tstruct ath_buf *bf_tail = NULL, *bf;\n\tstruct sk_buff_head *tid_q;\n\tint sent = 0;\n\tint i;\n\n\tINIT_LIST_HEAD(&bf_q);\n\tfor (i = 0; tids && nframes; i++, tids >>= 1) {\n\t\tstruct ath_atx_tid *tid;\n\n\t\tif (!(tids & 1))\n\t\t\tcontinue;\n\n\t\ttid = ATH_AN_2_TID(an, i);\n\t\tif (tid->paused)\n\t\t\tcontinue;\n\n\t\tath_txq_lock(sc, tid->ac->txq);\n\t\twhile (nframes > 0) {\n\t\t\tbf = ath_tx_get_tid_subframe(sc, sc->tx.uapsdq, tid, &tid_q);\n\t\t\tif (!bf)\n\t\t\t\tbreak;\n\n\t\t\t__skb_unlink(bf->bf_mpdu, tid_q);\n\t\t\tlist_add_tail(&bf->list, &bf_q);\n\t\t\tath_set_rates(tid->an->vif, tid->an->sta, bf);\n\t\t\tif (bf_isampdu(bf)) {\n\t\t\t\tath_tx_addto_baw(sc, tid, bf);\n\t\t\t\tbf->bf_state.bf_type &= ~BUF_AGGR;\n\t\t\t}\n\t\t\tif (bf_tail)\n\t\t\t\tbf_tail->bf_next = bf;\n\n\t\t\tbf_tail = bf;\n\t\t\tnframes--;\n\t\t\tsent++;\n\t\t\tTX_STAT_INC(txq->axq_qnum, a_queued_hw);\n\n\t\t\tif (an->sta && !ath_tid_has_buffered(tid))\n\t\t\t\tieee80211_sta_set_buffered(an->sta, i, false);\n\t\t}\n\t\tath_txq_unlock_complete(sc, tid->ac->txq);\n\t}\n\n\tif (list_empty(&bf_q))\n\t\treturn;\n\n\tinfo = IEEE80211_SKB_CB(bf_tail->bf_mpdu);\n\tinfo->flags |= IEEE80211_TX_STATUS_EOSP;\n\n\tbf = list_first_entry(&bf_q, struct ath_buf, list);\n\tath_txq_lock(sc, txq);\n\tath_tx_fill_desc(sc, bf, txq, 0);\n\tath_tx_txqaddbuf(sc, txq, &bf_q, false);\n\tath_txq_unlock(sc, txq);\n}\n\n/********************/\n/* Queue Management */\n/********************/\n\nstruct ath_txq *ath_txq_setup(struct ath_softc *sc, int qtype, int subtype)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath9k_tx_queue_info qi;\n\tstatic const int subtype_txq_to_hwq[] = {\n\t\t[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,\n\t\t[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,\n\t\t[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,\n\t\t[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,\n\t};\n\tint axq_qnum, i;\n\n\tmemset(&qi, 0, sizeof(qi));\n\tqi.tqi_subtype = subtype_txq_to_hwq[subtype];\n\tqi.tqi_aifs = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;\n\tqi.tqi_physCompBuf = 0;\n\n\t/*\n\t * Enable interrupts only for EOL and DESC conditions.\n\t * We mark tx descriptors to receive a DESC interrupt\n\t * when a tx queue gets deep; otherwise waiting for the\n\t * EOL to reap descriptors.  Note that this is done to\n\t * reduce interrupt load and this only defers reaping\n\t * descriptors, never transmitting frames.  Aside from\n\t * reducing interrupts this also permits more concurrency.\n\t * The only potential downside is if the tx queue backs\n\t * up in which case the top half of the kernel may backup\n\t * due to a lack of tx descriptors.\n\t *\n\t * The UAPSD queue is an exception, since we take a desc-\n\t * based intr on the EOSP frames.\n\t */\n\tif (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\n\t\tqi.tqi_qflags = TXQ_FLAG_TXINT_ENABLE;\n\t} else {\n\t\tif (qtype == ATH9K_TX_QUEUE_UAPSD)\n\t\t\tqi.tqi_qflags = TXQ_FLAG_TXDESCINT_ENABLE;\n\t\telse\n\t\t\tqi.tqi_qflags = TXQ_FLAG_TXEOLINT_ENABLE |\n\t\t\t\t\tTXQ_FLAG_TXDESCINT_ENABLE;\n\t}\n\taxq_qnum = ath9k_hw_setuptxqueue(ah, qtype, &qi);\n\tif (axq_qnum == -1) {\n\t\t/*\n\t\t * NB: don't print a message, this happens\n\t\t * normally on parts with too few tx queues\n\t\t */\n\t\treturn NULL;\n\t}\n\tif (!ATH_TXQ_SETUP(sc, axq_qnum)) {\n\t\tstruct ath_txq *txq = &sc->tx.txq[axq_qnum];\n\n\t\ttxq->axq_qnum = axq_qnum;\n\t\ttxq->mac80211_qnum = -1;\n\t\ttxq->axq_link = NULL;\n\t\t__skb_queue_head_init(&txq->complete_q);\n\t\tINIT_LIST_HEAD(&txq->axq_q);\n\t\tINIT_LIST_HEAD(&txq->axq_acq);\n\t\tspin_lock_init(&txq->axq_lock);\n\t\ttxq->axq_depth = 0;\n\t\ttxq->axq_ampdu_depth = 0;\n\t\ttxq->axq_tx_inprogress = false;\n\t\tsc->tx.txqsetup |= 1<<axq_qnum;\n\n\t\ttxq->txq_headidx = txq->txq_tailidx = 0;\n\t\tfor (i = 0; i < ATH_TXFIFO_DEPTH; i++)\n\t\t\tINIT_LIST_HEAD(&txq->txq_fifo[i]);\n\t}\n\treturn &sc->tx.txq[axq_qnum];\n}\n\nint ath_txq_update(struct ath_softc *sc, int qnum,\n\t\t   struct ath9k_tx_queue_info *qinfo)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tint error = 0;\n\tstruct ath9k_tx_queue_info qi;\n\n\tBUG_ON(sc->tx.txq[qnum].axq_qnum != qnum);\n\n\tath9k_hw_get_txq_props(ah, qnum, &qi);\n\tqi.tqi_aifs = qinfo->tqi_aifs;\n\tqi.tqi_cwmin = qinfo->tqi_cwmin;\n\tqi.tqi_cwmax = qinfo->tqi_cwmax;\n\tqi.tqi_burstTime = qinfo->tqi_burstTime;\n\tqi.tqi_readyTime = qinfo->tqi_readyTime;\n\n\tif (!ath9k_hw_set_txq_props(ah, qnum, &qi)) {\n\t\tath_err(ath9k_hw_common(sc->sc_ah),\n\t\t\t\"Unable to update hardware queue %u!\\n\", qnum);\n\t\terror = -EIO;\n\t} else {\n\t\tath9k_hw_resettxqueue(ah, qnum);\n\t}\n\n\treturn error;\n}\n\nint ath_cabq_update(struct ath_softc *sc)\n{\n\tstruct ath9k_tx_queue_info qi;\n\tstruct ath_beacon_config *cur_conf = &sc->cur_beacon_conf;\n\tint qnum = sc->beacon.cabq->axq_qnum;\n\n\tath9k_hw_get_txq_props(sc->sc_ah, qnum, &qi);\n\n\tqi.tqi_readyTime = (cur_conf->beacon_interval *\n\t\t\t    ATH_CABQ_READY_TIME) / 100;\n\tath_txq_update(sc, qnum, &qi);\n\n\treturn 0;\n}\n\nstatic void ath_drain_txq_list(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct list_head *list)\n{\n\tstruct ath_buf *bf, *lastbf;\n\tstruct list_head bf_head;\n\tstruct ath_tx_status ts;\n\n\tmemset(&ts, 0, sizeof(ts));\n\tts.ts_status = ATH9K_TX_FLUSH;\n\tINIT_LIST_HEAD(&bf_head);\n\n\twhile (!list_empty(list)) {\n\t\tbf = list_first_entry(list, struct ath_buf, list);\n\n\t\tif (bf->bf_state.stale) {\n\t\t\tlist_del(&bf->list);\n\n\t\t\tath_tx_return_buffer(sc, bf);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\t\tlist_cut_position(&bf_head, list, &lastbf->list);\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t}\n}\n\n/*\n * Drain a given TX queue (could be Beacon or Data)\n *\n * This assumes output has been stopped and\n * we do not need to block ath_tx_tasklet.\n */\nvoid ath_draintxq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tath_txq_lock(sc, txq);\n\n\tif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\n\t\tint idx = txq->txq_tailidx;\n\n\t\twhile (!list_empty(&txq->txq_fifo[idx])) {\n\t\t\tath_drain_txq_list(sc, txq, &txq->txq_fifo[idx]);\n\n\t\t\tINCR(idx, ATH_TXFIFO_DEPTH);\n\t\t}\n\t\ttxq->txq_tailidx = idx;\n\t}\n\n\ttxq->axq_link = NULL;\n\ttxq->axq_tx_inprogress = false;\n\tath_drain_txq_list(sc, txq, &txq->axq_q);\n\n\tath_txq_unlock_complete(sc, txq);\n}\n\nbool ath_drain_all_txq(struct ath_softc *sc)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_txq *txq;\n\tint i;\n\tu32 npend = 0;\n\n\tif (test_bit(SC_OP_INVALID, &sc->sc_flags))\n\t\treturn true;\n\n\tath9k_hw_abort_tx_dma(ah);\n\n\t/* Check if any queue remains active */\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (!ATH_TXQ_SETUP(sc, i))\n\t\t\tcontinue;\n\n\t\tif (!sc->tx.txq[i].axq_depth)\n\t\t\tcontinue;\n\n\t\tif (ath9k_hw_numtxpending(ah, sc->tx.txq[i].axq_qnum))\n\t\t\tnpend |= BIT(i);\n\t}\n\n\tif (npend)\n\t\tath_err(common, \"Failed to stop TX DMA, queues=0x%03x!\\n\", npend);\n\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (!ATH_TXQ_SETUP(sc, i))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * The caller will resume queues with ieee80211_wake_queues.\n\t\t * Mark the queue as not stopped to prevent ath_tx_complete\n\t\t * from waking the queue too early.\n\t\t */\n\t\ttxq = &sc->tx.txq[i];\n\t\ttxq->stopped = false;\n\t\tath_draintxq(sc, txq);\n\t}\n\n\treturn !npend;\n}\n\nvoid ath_tx_cleanupq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tath9k_hw_releasetxqueue(sc->sc_ah, txq->axq_qnum);\n\tsc->tx.txqsetup &= ~(1<<txq->axq_qnum);\n}\n\n/* For each axq_acq entry, for each tid, try to schedule packets\n * for transmit until ampdu_depth has reached min Q depth.\n */\nvoid ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tstruct ath_atx_ac *ac, *last_ac;\n\tstruct ath_atx_tid *tid, *last_tid;\n\tbool sent = false;\n\n\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags) ||\n\t    list_empty(&txq->axq_acq))\n\t\treturn;\n\n\trcu_read_lock();\n\n\tlast_ac = list_entry(txq->axq_acq.prev, struct ath_atx_ac, list);\n\twhile (!list_empty(&txq->axq_acq)) {\n\t\tbool stop = false;\n\n\t\tac = list_first_entry(&txq->axq_acq, struct ath_atx_ac, list);\n\t\tlast_tid = list_entry(ac->tid_q.prev, struct ath_atx_tid, list);\n\t\tlist_del(&ac->list);\n\t\tac->sched = false;\n\n\t\twhile (!list_empty(&ac->tid_q)) {\n\n\t\t\ttid = list_first_entry(&ac->tid_q, struct ath_atx_tid,\n\t\t\t\t\t       list);\n\t\t\tlist_del(&tid->list);\n\t\t\ttid->sched = false;\n\n\t\t\tif (tid->paused)\n\t\t\t\tcontinue;\n\n\t\t\tif (ath_tx_sched_aggr(sc, txq, tid, &stop))\n\t\t\t\tsent = true;\n\n\t\t\t/*\n\t\t\t * add tid to round-robin queue if more frames\n\t\t\t * are pending for the tid\n\t\t\t */\n\t\t\tif (ath_tid_has_buffered(tid))\n\t\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\t\tif (stop || tid == last_tid)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!list_empty(&ac->tid_q) && !ac->sched) {\n\t\t\tac->sched = true;\n\t\t\tlist_add_tail(&ac->list, &txq->axq_acq);\n\t\t}\n\n\t\tif (stop)\n\t\t\tbreak;\n\n\t\tif (ac == last_ac) {\n\t\t\tif (!sent)\n\t\t\t\tbreak;\n\n\t\t\tsent = false;\n\t\t\tlast_ac = list_entry(txq->axq_acq.prev,\n\t\t\t\t\t     struct ath_atx_ac, list);\n\t\t}\n\t}\n\n\trcu_read_unlock();\n}\n\n/***********/\n/* TX, DMA */\n/***********/\n\n/*\n * Insert a chain of ath_buf (descriptors) on a txq and\n * assume the descriptors are already chained together by caller.\n */\nstatic void ath_tx_txqaddbuf(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t     struct list_head *head, bool internal)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(ah);\n\tstruct ath_buf *bf, *bf_last;\n\tbool puttxbuf = false;\n\tbool edma;\n\n\t/*\n\t * Insert the frame on the outbound list and\n\t * pass it on to the hardware.\n\t */\n\n\tif (list_empty(head))\n\t\treturn;\n\n\tedma = !!(ah->caps.hw_caps & ATH9K_HW_CAP_EDMA);\n\tbf = list_first_entry(head, struct ath_buf, list);\n\tbf_last = list_entry(head->prev, struct ath_buf, list);\n\n\tath_dbg(common, QUEUE, \"qnum: %d, txq depth: %d\\n\",\n\t\ttxq->axq_qnum, txq->axq_depth);\n\n\tif (edma && list_empty(&txq->txq_fifo[txq->txq_headidx])) {\n\t\tlist_splice_tail_init(head, &txq->txq_fifo[txq->txq_headidx]);\n\t\tINCR(txq->txq_headidx, ATH_TXFIFO_DEPTH);\n\t\tputtxbuf = true;\n\t} else {\n\t\tlist_splice_tail_init(head, &txq->axq_q);\n\n\t\tif (txq->axq_link) {\n\t\t\tath9k_hw_set_desc_link(ah, txq->axq_link, bf->bf_daddr);\n\t\t\tath_dbg(common, XMIT, \"link[%u] (%p)=%llx (%p)\\n\",\n\t\t\t\ttxq->axq_qnum, txq->axq_link,\n\t\t\t\tito64(bf->bf_daddr), bf->bf_desc);\n\t\t} else if (!edma)\n\t\t\tputtxbuf = true;\n\n\t\ttxq->axq_link = bf_last->bf_desc;\n\t}\n\n\tif (puttxbuf) {\n\t\tTX_STAT_INC(txq->axq_qnum, puttxbuf);\n\t\tath9k_hw_puttxbuf(ah, txq->axq_qnum, bf->bf_daddr);\n\t\tath_dbg(common, XMIT, \"TXDP[%u] = %llx (%p)\\n\",\n\t\t\ttxq->axq_qnum, ito64(bf->bf_daddr), bf->bf_desc);\n\t}\n\n\tif (!edma || sc->tx99_state) {\n\t\tTX_STAT_INC(txq->axq_qnum, txstart);\n\t\tath9k_hw_txstart(ah, txq->axq_qnum);\n\t}\n\n\tif (!internal) {\n\t\twhile (bf) {\n\t\t\ttxq->axq_depth++;\n\t\t\tif (bf_is_ampdu_not_probing(bf))\n\t\t\t\ttxq->axq_ampdu_depth++;\n\n\t\t\tbf_last = bf->bf_lastbf;\n\t\t\tbf = bf_last->bf_next;\n\t\t\tbf_last->bf_next = NULL;\n\t\t}\n\t}\n}\n\nstatic void ath_tx_send_normal(struct ath_softc *sc, struct ath_txq *txq,\n\t\t\t       struct ath_atx_tid *tid, struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct list_head bf_head;\n\tstruct ath_buf *bf = fi->bf;\n\n\tINIT_LIST_HEAD(&bf_head);\n\tlist_add_tail(&bf->list, &bf_head);\n\tbf->bf_state.bf_type = 0;\n\tif (tid && (tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\n\t\tbf->bf_state.bf_type = BUF_AMPDU;\n\t\tath_tx_addto_baw(sc, tid, bf);\n\t}\n\n\tbf->bf_next = NULL;\n\tbf->bf_lastbf = bf;\n\tath_tx_fill_desc(sc, bf, txq, fi->framelen);\n\tath_tx_txqaddbuf(sc, txq, &bf_head, false);\n\tTX_STAT_INC(txq->axq_qnum, queued);\n}\n\nstatic void setup_frame_info(struct ieee80211_hw *hw,\n\t\t\t     struct ieee80211_sta *sta,\n\t\t\t     struct sk_buff *skb,\n\t\t\t     int framelen)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_key_conf *hw_key = tx_info->control.hw_key;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tconst struct ieee80211_rate *rate;\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_node *an = NULL;\n\tenum ath9k_key_type keytype;\n\tbool short_preamble = false;\n\n\t/*\n\t * We check if Short Preamble is needed for the CTS rate by\n\t * checking the BSS's global flag.\n\t * But for the rate series, IEEE80211_TX_RC_USE_SHORT_PREAMBLE is used.\n\t */\n\tif (tx_info->control.vif &&\n\t    tx_info->control.vif->bss_conf.use_short_preamble)\n\t\tshort_preamble = true;\n\n\trate = ieee80211_get_rts_cts_rate(hw, tx_info);\n\tkeytype = ath9k_cmn_get_hw_crypto_keytype(skb);\n\n\tif (sta)\n\t\tan = (struct ath_node *) sta->drv_priv;\n\n\tmemset(fi, 0, sizeof(*fi));\n\tif (hw_key)\n\t\tfi->keyix = hw_key->hw_key_idx;\n\telse if (an && ieee80211_is_data(hdr->frame_control) && an->ps_key > 0)\n\t\tfi->keyix = an->ps_key;\n\telse\n\t\tfi->keyix = ATH9K_TXKEYIX_INVALID;\n\tfi->keytype = keytype;\n\tfi->framelen = framelen;\n\n\tif (!rate)\n\t\treturn;\n\tfi->rtscts_rate = rate->hw_value;\n\tif (short_preamble)\n\t\tfi->rtscts_rate |= rate->hw_value_short;\n}\n\nu8 ath_txchainmask_reduction(struct ath_softc *sc, u8 chainmask, u32 rate)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath9k_channel *curchan = ah->curchan;\n\n\tif ((ah->caps.hw_caps & ATH9K_HW_CAP_APM) && IS_CHAN_5GHZ(curchan) &&\n\t    (chainmask == 0x7) && (rate < 0x90))\n\t\treturn 0x3;\n\telse if (AR_SREV_9462(ah) && ath9k_hw_btcoex_is_enabled(ah) &&\n\t\t IS_CCK_RATE(rate))\n\t\treturn 0x2;\n\telse\n\t\treturn chainmask;\n}\n\n/*\n * Assign a descriptor (and sequence number if necessary,\n * and map buffer for DMA. Frees skb on error\n */\nstatic struct ath_buf *ath_tx_setup_buffer(struct ath_softc *sc,\n\t\t\t\t\t   struct ath_txq *txq,\n\t\t\t\t\t   struct ath_atx_tid *tid,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tstruct ath_buf *bf;\n\tint fragno;\n\tu16 seqno;\n\n\tbf = ath_tx_get_buffer(sc);\n\tif (!bf) {\n\t\tath_dbg(common, XMIT, \"TX buffers are full\\n\");\n\t\treturn NULL;\n\t}\n\n\tATH_TXBUF_RESET(bf);\n\n\tif (tid) {\n\t\tfragno = le16_to_cpu(hdr->seq_ctrl) & IEEE80211_SCTL_FRAG;\n\t\tseqno = tid->seq_next;\n\t\thdr->seq_ctrl = cpu_to_le16(tid->seq_next << IEEE80211_SEQ_SEQ_SHIFT);\n\n\t\tif (fragno)\n\t\t\thdr->seq_ctrl |= cpu_to_le16(fragno);\n\n\t\tif (!ieee80211_has_morefrags(hdr->frame_control))\n\t\t\tINCR(tid->seq_next, IEEE80211_SEQ_MAX);\n\n\t\tbf->bf_state.seqno = seqno;\n\t}\n\n\tbf->bf_mpdu = skb;\n\n\tbf->bf_buf_addr = dma_map_single(sc->dev, skb->data,\n\t\t\t\t\t skb->len, DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(sc->dev, bf->bf_buf_addr))) {\n\t\tbf->bf_mpdu = NULL;\n\t\tbf->bf_buf_addr = 0;\n\t\tath_err(ath9k_hw_common(sc->sc_ah),\n\t\t\t\"dma_mapping_error() on TX\\n\");\n\t\tath_tx_return_buffer(sc, bf);\n\t\treturn NULL;\n\t}\n\n\tfi->bf = bf;\n\n\treturn bf;\n}\n\nstatic int ath_tx_prepare(struct ieee80211_hw *hw, struct sk_buff *skb,\n\t\t\t  struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_sta *sta = txctl->sta;\n\tstruct ieee80211_vif *vif = info->control.vif;\n\tstruct ath_vif *avp;\n\tstruct ath_softc *sc = hw->priv;\n\tint frmlen = skb->len + FCS_LEN;\n\tint padpos, padsize;\n\n\t/* NOTE:  sta can be NULL according to net/mac80211.h */\n\tif (sta)\n\t\ttxctl->an = (struct ath_node *)sta->drv_priv;\n\telse if (vif && ieee80211_is_data(hdr->frame_control)) {\n\t\tavp = (void *)vif->drv_priv;\n\t\ttxctl->an = &avp->mcast_node;\n\t}\n\n\tif (info->control.hw_key)\n\t\tfrmlen += info->control.hw_key->icv_len;\n\n\t/*\n\t * As a temporary workaround, assign seq# here; this will likely need\n\t * to be cleaned up to work better with Beacon transmission and virtual\n\t * BSSes.\n\t */\n\tif (info->flags & IEEE80211_TX_CTL_ASSIGN_SEQ) {\n\t\tif (info->flags & IEEE80211_TX_CTL_FIRST_FRAGMENT)\n\t\t\tsc->tx.seq_no += 0x10;\n\t\thdr->seq_ctrl &= cpu_to_le16(IEEE80211_SCTL_FRAG);\n\t\thdr->seq_ctrl |= cpu_to_le16(sc->tx.seq_no);\n\t}\n\n\tif ((vif && vif->type != NL80211_IFTYPE_AP &&\n\t            vif->type != NL80211_IFTYPE_AP_VLAN) ||\n\t    !ieee80211_is_data(hdr->frame_control))\n\t\tinfo->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\n\n\t/* Add the padding after the header if this is not already done */\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\tif (padsize && skb->len > padpos) {\n\t\tif (skb_headroom(skb) < padsize)\n\t\t\treturn -ENOMEM;\n\n\t\tskb_push(skb, padsize);\n\t\tmemmove(skb->data, skb->data + padsize, padpos);\n\t}\n\n\tsetup_frame_info(hw, sta, skb, frmlen);\n\treturn 0;\n}\n\n\n/* Upon failure caller should free skb */\nint ath_tx_start(struct ieee80211_hw *hw, struct sk_buff *skb,\n\t\t struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_sta *sta = txctl->sta;\n\tstruct ieee80211_vif *vif = info->control.vif;\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_txq *txq = txctl->txq;\n\tstruct ath_atx_tid *tid = NULL;\n\tstruct ath_buf *bf;\n\tint q;\n\tint ret;\n\n\tret = ath_tx_prepare(hw, skb, txctl);\n\tif (ret)\n\t    return ret;\n\n\thdr = (struct ieee80211_hdr *) skb->data;\n\t/*\n\t * At this point, the vif, hw_key and sta pointers in the tx control\n\t * info are no longer valid (overwritten by the ath_frame_info data.\n\t */\n\n\tq = skb_get_queue_mapping(skb);\n\n\tath_txq_lock(sc, txq);\n\tif (txq == sc->tx.txq_map[q] &&\n\t    ++txq->pending_frames > sc->tx.txq_max_pending[q] &&\n\t    !txq->stopped) {\n\t\tieee80211_stop_queue(sc->hw, q);\n\t\ttxq->stopped = true;\n\t}\n\n\tif (info->flags & IEEE80211_TX_CTL_PS_RESPONSE) {\n\t\tath_txq_unlock(sc, txq);\n\t\ttxq = sc->tx.uapsdq;\n\t\tath_txq_lock(sc, txq);\n\t} else if (txctl->an &&\n\t\t   ieee80211_is_data_present(hdr->frame_control)) {\n\t\ttid = ath_get_skb_tid(sc, txctl->an, skb);\n\n\t\tWARN_ON(tid->ac->txq != txctl->txq);\n\n\t\tif (info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT)\n\t\t\ttid->ac->clear_ps_filter = true;\n\n\t\t/*\n\t\t * Add this frame to software queue for scheduling later\n\t\t * for aggregation.\n\t\t */\n\t\tTX_STAT_INC(txq->axq_qnum, a_queued_sw);\n\t\t__skb_queue_tail(&tid->buf_q, skb);\n\t\tif (!txctl->an->sleeping)\n\t\t\tath_tx_queue_tid(txq, tid);\n\n\t\tath_txq_schedule(sc, txq);\n\t\tgoto out;\n\t}\n\n\tbf = ath_tx_setup_buffer(sc, txq, tid, skb);\n\tif (!bf) {\n\t\tath_txq_skb_done(sc, txq, skb);\n\t\tif (txctl->paprd)\n\t\t\tdev_kfree_skb_any(skb);\n\t\telse\n\t\t\tieee80211_free_txskb(sc->hw, skb);\n\t\tgoto out;\n\t}\n\n\tbf->bf_state.bfs_paprd = txctl->paprd;\n\n\tif (txctl->paprd)\n\t\tbf->bf_state.bfs_paprd_timestamp = jiffies;\n\n\tath_set_rates(vif, sta, bf);\n\tath_tx_send_normal(sc, txq, tid, skb);\n\nout:\n\tath_txq_unlock(sc, txq);\n\n\treturn 0;\n}\n\nvoid ath_tx_cabq(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t struct sk_buff *skb)\n{\n\tstruct ath_softc *sc = hw->priv;\n\tstruct ath_tx_control txctl = {\n\t\t.txq = sc->beacon.cabq\n\t};\n\tstruct ath_tx_info info = {};\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath_buf *bf_tail = NULL;\n\tstruct ath_buf *bf;\n\tLIST_HEAD(bf_q);\n\tint duration = 0;\n\tint max_duration;\n\n\tmax_duration =\n\t\tsc->cur_beacon_conf.beacon_interval * 1000 *\n\t\tsc->cur_beacon_conf.dtim_period / ATH_BCBUF;\n\n\tdo {\n\t\tstruct ath_frame_info *fi = get_frame_info(skb);\n\n\t\tif (ath_tx_prepare(hw, skb, &txctl))\n\t\t\tbreak;\n\n\t\tbf = ath_tx_setup_buffer(sc, txctl.txq, NULL, skb);\n\t\tif (!bf)\n\t\t\tbreak;\n\n\t\tbf->bf_lastbf = bf;\n\t\tath_set_rates(vif, NULL, bf);\n\t\tath_buf_set_rate(sc, bf, &info, fi->framelen, false);\n\t\tduration += info.rates[0].PktDuration;\n\t\tif (bf_tail)\n\t\t\tbf_tail->bf_next = bf;\n\n\t\tlist_add_tail(&bf->list, &bf_q);\n\t\tbf_tail = bf;\n\t\tskb = NULL;\n\n\t\tif (duration > max_duration)\n\t\t\tbreak;\n\n\t\tskb = ieee80211_get_buffered_bc(hw, vif);\n\t} while(skb);\n\n\tif (skb)\n\t\tieee80211_free_txskb(hw, skb);\n\n\tif (list_empty(&bf_q))\n\t\treturn;\n\n\tbf = list_first_entry(&bf_q, struct ath_buf, list);\n\thdr = (struct ieee80211_hdr *) bf->bf_mpdu->data;\n\n\tif (hdr->frame_control & IEEE80211_FCTL_MOREDATA) {\n\t\thdr->frame_control &= ~IEEE80211_FCTL_MOREDATA;\n\t\tdma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\n\t\t\tsizeof(*hdr), DMA_TO_DEVICE);\n\t}\n\n\tath_txq_lock(sc, txctl.txq);\n\tath_tx_fill_desc(sc, bf, txctl.txq, 0);\n\tath_tx_txqaddbuf(sc, txctl.txq, &bf_q, false);\n\tTX_STAT_INC(txctl.txq->axq_qnum, queued);\n\tath_txq_unlock(sc, txctl.txq);\n}\n\n/*****************/\n/* TX Completion */\n/*****************/\n\nstatic void ath_tx_complete(struct ath_softc *sc, struct sk_buff *skb,\n\t\t\t    int tx_flags, struct ath_txq *txq)\n{\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ieee80211_hdr * hdr = (struct ieee80211_hdr *)skb->data;\n\tint padpos, padsize;\n\tunsigned long flags;\n\n\tath_dbg(common, XMIT, \"TX complete: skb: %p\\n\", skb);\n\n\tif (sc->sc_ah->caldata)\n\t\tset_bit(PAPRD_PACKET_SENT, &sc->sc_ah->caldata->cal_flags);\n\n\tif (!(tx_flags & ATH_TX_ERROR))\n\t\t/* Frame was ACKed */\n\t\ttx_info->flags |= IEEE80211_TX_STAT_ACK;\n\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\tif (padsize && skb->len>padpos+padsize) {\n\t\t/*\n\t\t * Remove MAC header padding before giving the frame back to\n\t\t * mac80211.\n\t\t */\n\t\tmemmove(skb->data + padsize, skb->data, padpos);\n\t\tskb_pull(skb, padsize);\n\t}\n\n\tspin_lock_irqsave(&sc->sc_pm_lock, flags);\n\tif ((sc->ps_flags & PS_WAIT_FOR_TX_ACK) && !txq->axq_depth) {\n\t\tsc->ps_flags &= ~PS_WAIT_FOR_TX_ACK;\n\t\tath_dbg(common, PS,\n\t\t\t\"Going back to sleep after having received TX status (0x%lx)\\n\",\n\t\t\tsc->ps_flags & (PS_WAIT_FOR_BEACON |\n\t\t\t\t\tPS_WAIT_FOR_CAB |\n\t\t\t\t\tPS_WAIT_FOR_PSPOLL_DATA |\n\t\t\t\t\tPS_WAIT_FOR_TX_ACK));\n\t}\n\tspin_unlock_irqrestore(&sc->sc_pm_lock, flags);\n\n\t__skb_queue_tail(&txq->complete_q, skb);\n\tath_txq_skb_done(sc, txq, skb);\n}\n\nstatic void ath_tx_complete_buf(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t\tstruct ath_txq *txq, struct list_head *bf_q,\n\t\t\t\tstruct ath_tx_status *ts, int txok)\n{\n\tstruct sk_buff *skb = bf->bf_mpdu;\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tunsigned long flags;\n\tint tx_flags = 0;\n\n\tif (!txok)\n\t\ttx_flags |= ATH_TX_ERROR;\n\n\tif (ts->ts_status & ATH9K_TXERR_FILT)\n\t\ttx_info->flags |= IEEE80211_TX_STAT_TX_FILTERED;\n\n\tdma_unmap_single(sc->dev, bf->bf_buf_addr, skb->len, DMA_TO_DEVICE);\n\tbf->bf_buf_addr = 0;\n\tif (sc->tx99_state)\n\t\tgoto skip_tx_complete;\n\n\tif (bf->bf_state.bfs_paprd) {\n\t\tif (time_after(jiffies,\n\t\t\t\tbf->bf_state.bfs_paprd_timestamp +\n\t\t\t\tmsecs_to_jiffies(ATH_PAPRD_TIMEOUT)))\n\t\t\tdev_kfree_skb_any(skb);\n\t\telse\n\t\t\tcomplete(&sc->paprd_complete);\n\t} else {\n\t\tath_debug_stat_tx(sc, bf, ts, txq, tx_flags);\n\t\tath_tx_complete(sc, skb, tx_flags, txq);\n\t}\nskip_tx_complete:\n\t/* At this point, skb (bf->bf_mpdu) is consumed...make sure we don't\n\t * accidentally reference it later.\n\t */\n\tbf->bf_mpdu = NULL;\n\n\t/*\n\t * Return the list of ath_buf of this mpdu to free queue\n\t */\n\tspin_lock_irqsave(&sc->tx.txbuflock, flags);\n\tlist_splice_tail_init(bf_q, &sc->tx.txbuf);\n\tspin_unlock_irqrestore(&sc->tx.txbuflock, flags);\n}\n\nstatic void ath_tx_rc_status(struct ath_softc *sc, struct ath_buf *bf,\n\t\t\t     struct ath_tx_status *ts, int nframes, int nbad,\n\t\t\t     int txok)\n{\n\tstruct sk_buff *skb = bf->bf_mpdu;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_hw *hw = sc->hw;\n\tstruct ath_hw *ah = sc->sc_ah;\n\tu8 i, tx_rateindex;\n\n\tif (txok)\n\t\ttx_info->status.ack_signal = ts->ts_rssi;\n\n\ttx_rateindex = ts->ts_rateindex;\n\tWARN_ON(tx_rateindex >= hw->max_rates);\n\n\tif (tx_info->flags & IEEE80211_TX_CTL_AMPDU) {\n\t\ttx_info->flags |= IEEE80211_TX_STAT_AMPDU;\n\n\t\tBUG_ON(nbad > nframes);\n\t}\n\ttx_info->status.ampdu_len = nframes;\n\ttx_info->status.ampdu_ack_len = nframes - nbad;\n\n\tif ((ts->ts_status & ATH9K_TXERR_FILT) == 0 &&\n\t    (tx_info->flags & IEEE80211_TX_CTL_NO_ACK) == 0) {\n\t\t/*\n\t\t * If an underrun error is seen assume it as an excessive\n\t\t * retry only if max frame trigger level has been reached\n\t\t * (2 KB for single stream, and 4 KB for dual stream).\n\t\t * Adjust the long retry as if the frame was tried\n\t\t * hw->max_rate_tries times to affect how rate control updates\n\t\t * PER for the failed rate.\n\t\t * In case of congestion on the bus penalizing this type of\n\t\t * underruns should help hardware actually transmit new frames\n\t\t * successfully by eventually preferring slower rates.\n\t\t * This itself should also alleviate congestion on the bus.\n\t\t */\n\t\tif (unlikely(ts->ts_flags & (ATH9K_TX_DATA_UNDERRUN |\n\t\t                             ATH9K_TX_DELIM_UNDERRUN)) &&\n\t\t    ieee80211_is_data(hdr->frame_control) &&\n\t\t    ah->tx_trig_level >= sc->sc_ah->config.max_txtrig_level)\n\t\t\ttx_info->status.rates[tx_rateindex].count =\n\t\t\t\thw->max_rate_tries;\n\t}\n\n\tfor (i = tx_rateindex + 1; i < hw->max_rates; i++) {\n\t\ttx_info->status.rates[i].count = 0;\n\t\ttx_info->status.rates[i].idx = -1;\n\t}\n\n\ttx_info->status.rates[tx_rateindex].count = ts->ts_longretry + 1;\n}\n\nstatic void ath_tx_processq(struct ath_softc *sc, struct ath_txq *txq)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_common *common = ath9k_hw_common(ah);\n\tstruct ath_buf *bf, *lastbf, *bf_held = NULL;\n\tstruct list_head bf_head;\n\tstruct ath_desc *ds;\n\tstruct ath_tx_status ts;\n\tint status;\n\n\tath_dbg(common, QUEUE, \"tx queue %d (%x), link %p\\n\",\n\t\ttxq->axq_qnum, ath9k_hw_gettxbuf(sc->sc_ah, txq->axq_qnum),\n\t\ttxq->axq_link);\n\n\tath_txq_lock(sc, txq);\n\tfor (;;) {\n\t\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags))\n\t\t\tbreak;\n\n\t\tif (list_empty(&txq->axq_q)) {\n\t\t\ttxq->axq_link = NULL;\n\t\t\tath_txq_schedule(sc, txq);\n\t\t\tbreak;\n\t\t}\n\t\tbf = list_first_entry(&txq->axq_q, struct ath_buf, list);\n\n\t\t/*\n\t\t * There is a race condition that a BH gets scheduled\n\t\t * after sw writes TxE and before hw re-load the last\n\t\t * descriptor to get the newly chained one.\n\t\t * Software must keep the last DONE descriptor as a\n\t\t * holding descriptor - software does so by marking\n\t\t * it with the STALE flag.\n\t\t */\n\t\tbf_held = NULL;\n\t\tif (bf->bf_state.stale) {\n\t\t\tbf_held = bf;\n\t\t\tif (list_is_last(&bf_held->list, &txq->axq_q))\n\t\t\t\tbreak;\n\n\t\t\tbf = list_entry(bf_held->list.next, struct ath_buf,\n\t\t\t\t\tlist);\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\t\tds = lastbf->bf_desc;\n\n\t\tmemset(&ts, 0, sizeof(ts));\n\t\tstatus = ath9k_hw_txprocdesc(ah, ds, &ts);\n\t\tif (status == -EINPROGRESS)\n\t\t\tbreak;\n\n\t\tTX_STAT_INC(txq->axq_qnum, txprocdesc);\n\n\t\t/*\n\t\t * Remove ath_buf's of the same transmit unit from txq,\n\t\t * however leave the last descriptor back as the holding\n\t\t * descriptor for hw.\n\t\t */\n\t\tlastbf->bf_state.stale = true;\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (!list_is_singular(&lastbf->list))\n\t\t\tlist_cut_position(&bf_head,\n\t\t\t\t&txq->axq_q, lastbf->list.prev);\n\n\t\tif (bf_held) {\n\t\t\tlist_del(&bf_held->list);\n\t\t\tath_tx_return_buffer(sc, bf_held);\n\t\t}\n\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t}\n\tath_txq_unlock_complete(sc, txq);\n}\n\nvoid ath_tx_tasklet(struct ath_softc *sc)\n{\n\tstruct ath_hw *ah = sc->sc_ah;\n\tu32 qcumask = ((1 << ATH9K_NUM_TX_QUEUES) - 1) & ah->intr_txqs;\n\tint i;\n\n\tfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\n\t\tif (ATH_TXQ_SETUP(sc, i) && (qcumask & (1 << i)))\n\t\t\tath_tx_processq(sc, &sc->tx.txq[i]);\n\t}\n}\n\nvoid ath_tx_edma_tasklet(struct ath_softc *sc)\n{\n\tstruct ath_tx_status ts;\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_hw *ah = sc->sc_ah;\n\tstruct ath_txq *txq;\n\tstruct ath_buf *bf, *lastbf;\n\tstruct list_head bf_head;\n\tstruct list_head *fifo_list;\n\tint status;\n\n\tfor (;;) {\n\t\tif (test_bit(SC_OP_HW_RESET, &sc->sc_flags))\n\t\t\tbreak;\n\n\t\tstatus = ath9k_hw_txprocdesc(ah, NULL, (void *)&ts);\n\t\tif (status == -EINPROGRESS)\n\t\t\tbreak;\n\t\tif (status == -EIO) {\n\t\t\tath_dbg(common, XMIT, \"Error processing tx status\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Process beacon completions separately */\n\t\tif (ts.qid == sc->beacon.beaconq) {\n\t\t\tsc->beacon.tx_processed = true;\n\t\t\tsc->beacon.tx_last = !(ts.ts_status & ATH9K_TXERR_MASK);\n\n\t\t\tath9k_csa_is_finished(sc);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttxq = &sc->tx.txq[ts.qid];\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tTX_STAT_INC(txq->axq_qnum, txprocdesc);\n\n\t\tfifo_list = &txq->txq_fifo[txq->txq_tailidx];\n\t\tif (list_empty(fifo_list)) {\n\t\t\tath_txq_unlock(sc, txq);\n\t\t\treturn;\n\t\t}\n\n\t\tbf = list_first_entry(fifo_list, struct ath_buf, list);\n\t\tif (bf->bf_state.stale) {\n\t\t\tlist_del(&bf->list);\n\t\t\tath_tx_return_buffer(sc, bf);\n\t\t\tbf = list_first_entry(fifo_list, struct ath_buf, list);\n\t\t}\n\n\t\tlastbf = bf->bf_lastbf;\n\n\t\tINIT_LIST_HEAD(&bf_head);\n\t\tif (list_is_last(&lastbf->list, fifo_list)) {\n\t\t\tlist_splice_tail_init(fifo_list, &bf_head);\n\t\t\tINCR(txq->txq_tailidx, ATH_TXFIFO_DEPTH);\n\n\t\t\tif (!list_empty(&txq->axq_q)) {\n\t\t\t\tstruct list_head bf_q;\n\n\t\t\t\tINIT_LIST_HEAD(&bf_q);\n\t\t\t\ttxq->axq_link = NULL;\n\t\t\t\tlist_splice_tail_init(&txq->axq_q, &bf_q);\n\t\t\t\tath_tx_txqaddbuf(sc, txq, &bf_q, true);\n\t\t\t}\n\t\t} else {\n\t\t\tlastbf->bf_state.stale = true;\n\t\t\tif (bf != lastbf)\n\t\t\t\tlist_cut_position(&bf_head, fifo_list,\n\t\t\t\t\t\t  lastbf->list.prev);\n\t\t}\n\n\t\tath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\n\t\tath_txq_unlock_complete(sc, txq);\n\t}\n}\n\n/*****************/\n/* Init, Cleanup */\n/*****************/\n\nstatic int ath_txstatus_setup(struct ath_softc *sc, int size)\n{\n\tstruct ath_descdma *dd = &sc->txsdma;\n\tu8 txs_len = sc->sc_ah->caps.txs_len;\n\n\tdd->dd_desc_len = size * txs_len;\n\tdd->dd_desc = dmam_alloc_coherent(sc->dev, dd->dd_desc_len,\n\t\t\t\t\t  &dd->dd_desc_paddr, GFP_KERNEL);\n\tif (!dd->dd_desc)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int ath_tx_edma_init(struct ath_softc *sc)\n{\n\tint err;\n\n\terr = ath_txstatus_setup(sc, ATH_TXSTATUS_RING_SIZE);\n\tif (!err)\n\t\tath9k_hw_setup_statusring(sc->sc_ah, sc->txsdma.dd_desc,\n\t\t\t\t\t  sc->txsdma.dd_desc_paddr,\n\t\t\t\t\t  ATH_TXSTATUS_RING_SIZE);\n\n\treturn err;\n}\n\nint ath_tx_init(struct ath_softc *sc, int nbufs)\n{\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tint error = 0;\n\n\tspin_lock_init(&sc->tx.txbuflock);\n\n\terror = ath_descdma_setup(sc, &sc->tx.txdma, &sc->tx.txbuf,\n\t\t\t\t  \"tx\", nbufs, 1, 1);\n\tif (error != 0) {\n\t\tath_err(common,\n\t\t\t\"Failed to allocate tx descriptors: %d\\n\", error);\n\t\treturn error;\n\t}\n\n\terror = ath_descdma_setup(sc, &sc->beacon.bdma, &sc->beacon.bbuf,\n\t\t\t\t  \"beacon\", ATH_BCBUF, 1, 1);\n\tif (error != 0) {\n\t\tath_err(common,\n\t\t\t\"Failed to allocate beacon descriptors: %d\\n\", error);\n\t\treturn error;\n\t}\n\n\tINIT_DELAYED_WORK(&sc->tx_complete_work, ath_tx_complete_poll_work);\n\n\tif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)\n\t\terror = ath_tx_edma_init(sc);\n\n\treturn error;\n}\n\nvoid ath_tx_node_init(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_tid *tid;\n\tstruct ath_atx_ac *ac;\n\tint tidno, acno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS;\n\t     tidno++, tid++) {\n\t\ttid->an        = an;\n\t\ttid->tidno     = tidno;\n\t\ttid->seq_start = tid->seq_next = 0;\n\t\ttid->baw_size  = WME_MAX_BA;\n\t\ttid->baw_head  = tid->baw_tail = 0;\n\t\ttid->sched     = false;\n\t\ttid->paused    = false;\n\t\ttid->active\t   = false;\n\t\t__skb_queue_head_init(&tid->buf_q);\n\t\t__skb_queue_head_init(&tid->retry_q);\n\t\tacno = TID_TO_WME_AC(tidno);\n\t\ttid->ac = &an->ac[acno];\n\t}\n\n\tfor (acno = 0, ac = &an->ac[acno];\n\t     acno < IEEE80211_NUM_ACS; acno++, ac++) {\n\t\tac->sched    = false;\n\t\tac->clear_ps_filter = true;\n\t\tac->txq = sc->tx.txq_map[acno];\n\t\tINIT_LIST_HEAD(&ac->tid_q);\n\t}\n}\n\nvoid ath_tx_node_cleanup(struct ath_softc *sc, struct ath_node *an)\n{\n\tstruct ath_atx_ac *ac;\n\tstruct ath_atx_tid *tid;\n\tstruct ath_txq *txq;\n\tint tidno;\n\n\tfor (tidno = 0, tid = &an->tid[tidno];\n\t     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\n\n\t\tac = tid->ac;\n\t\ttxq = ac->txq;\n\n\t\tath_txq_lock(sc, txq);\n\n\t\tif (tid->sched) {\n\t\t\tlist_del(&tid->list);\n\t\t\ttid->sched = false;\n\t\t}\n\n\t\tif (ac->sched) {\n\t\t\tlist_del(&ac->list);\n\t\t\ttid->ac->sched = false;\n\t\t}\n\n\t\tath_tid_drain(sc, txq, tid);\n\t\ttid->active = false;\n\n\t\tath_txq_unlock(sc, txq);\n\t}\n}\n\n#ifdef CONFIG_ATH9K_TX99\n\nint ath9k_tx99_send(struct ath_softc *sc, struct sk_buff *skb,\n\t\t    struct ath_tx_control *txctl)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\n\tstruct ath_frame_info *fi = get_frame_info(skb);\n\tstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\n\tstruct ath_buf *bf;\n\tint padpos, padsize;\n\n\tpadpos = ieee80211_hdrlen(hdr->frame_control);\n\tpadsize = padpos & 3;\n\n\tif (padsize && skb->len > padpos) {\n\t\tif (skb_headroom(skb) < padsize) {\n\t\t\tath_dbg(common, XMIT,\n\t\t\t\t\"tx99 padding failed\\n\");\n\t\treturn -EINVAL;\n\t\t}\n\n\t\tskb_push(skb, padsize);\n\t\tmemmove(skb->data, skb->data + padsize, padpos);\n\t}\n\n\tfi->keyix = ATH9K_TXKEYIX_INVALID;\n\tfi->framelen = skb->len + FCS_LEN;\n\tfi->keytype = ATH9K_KEY_TYPE_CLEAR;\n\n\tbf = ath_tx_setup_buffer(sc, txctl->txq, NULL, skb);\n\tif (!bf) {\n\t\tath_dbg(common, XMIT, \"tx99 buffer setup failed\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tath_set_rates(sc->tx99_vif, NULL, bf);\n\n\tath9k_hw_set_desc_link(sc->sc_ah, bf->bf_desc, bf->bf_daddr);\n\tath9k_hw_tx99_start(sc->sc_ah, txctl->txq->axq_qnum);\n\n\tath_tx_send_normal(sc, txctl->txq, NULL, skb);\n\n\treturn 0;\n}\n\n#endif /* CONFIG_ATH9K_TX99 */\n"], "buggy_code_start_loc": [1447], "buggy_code_end_loc": [1453], "fixing_code_start_loc": [1446], "fixing_code_end_loc": [1456], "type": "CWE-362", "message": "Race condition in the ath_tx_aggr_sleep function in drivers/net/wireless/ath/ath9k/xmit.c in the Linux kernel before 3.13.7 allows remote attackers to cause a denial of service (system crash) via a large amount of network traffic that triggers certain list deletions.", "other": {"cve": {"id": "CVE-2014-2672", "sourceIdentifier": "cve@mitre.org", "published": "2014-04-01T06:35:53.747", "lastModified": "2023-05-19T16:50:49.677", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Race condition in the ath_tx_aggr_sleep function in drivers/net/wireless/ath/ath9k/xmit.c in the Linux kernel before 3.13.7 allows remote attackers to cause a denial of service (system crash) via a large amount of network traffic that triggers certain list deletions."}, {"lang": "es", "value": "Condici\u00f3n de carrera en la funci\u00f3n ath_tx_aggr_sleep en drivers/net/wireless/ath/ath9k/xmit.c en el kernel de Linux anterior a 3.13.7 permite a atacantes remotos causar una denegaci\u00f3n de servicio (ca\u00edda de sistema) a trav\u00e9s de una cantidad grande de tr\u00e1fico de red que provoca ciertas eliminaciones de lista."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.1}, "baseSeverity": "HIGH", "exploitabilityScore": 8.6, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.2", "versionEndExcluding": "3.2.56", "matchCriteriaId": "0D2B9685-650A-4324-957D-64C8DF52C942"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.4.92", "matchCriteriaId": "AB7FAE85-A7F7-403F-B3F8-51D26A7AD5CF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.5", "versionEndExcluding": "3.10.42", "matchCriteriaId": "2F7D3761-1031-4407-9D83-51387E0EFAE3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.11", "versionEndExcluding": "3.12.15", "matchCriteriaId": "4AE2B033-586E-48AC-95DC-880018601DFC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.13", "versionEndExcluding": "3.13.7", "matchCriteriaId": "B13865A2-6E9A-4FFE-A1C2-02B75D66C207"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=21f8aaee0c62708654988ce092838aa7df4d25d8", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v3.x/ChangeLog-3.13.7", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2014/03/30/5", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/66492", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.kernel.org/show_bug.cgi?id=70551", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/21f8aaee0c62708654988ce092838aa7df4d25d8", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://www.kernel.org/pub/linux/kernel/v3.x/ChangeLog-3.12.15", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/21f8aaee0c62708654988ce092838aa7df4d25d8"}}