{"buggy_code": ["#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/workqueue.h>\n#include <linux/rtnetlink.h>\n#include <linux/cache.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/delay.h>\n#include <linux/sched.h>\n#include <linux/idr.h>\n#include <linux/rculist.h>\n#include <linux/nsproxy.h>\n#include <linux/fs.h>\n#include <linux/proc_ns.h>\n#include <linux/file.h>\n#include <linux/export.h>\n#include <linux/user_namespace.h>\n#include <linux/net_namespace.h>\n#include <linux/sched/task.h>\n\n#include <net/sock.h>\n#include <net/netlink.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n\n/*\n *\tOur network namespace constructor/destructor lists\n */\n\nstatic LIST_HEAD(pernet_list);\nstatic struct list_head *first_device = &pernet_list;\nDEFINE_MUTEX(net_mutex);\n\nLIST_HEAD(net_namespace_list);\nEXPORT_SYMBOL_GPL(net_namespace_list);\n\nstruct net init_net = {\n\t.count\t\t= ATOMIC_INIT(1),\n\t.dev_base_head\t= LIST_HEAD_INIT(init_net.dev_base_head),\n};\nEXPORT_SYMBOL(init_net);\n\nstatic bool init_net_initialized;\n\n#define MIN_PERNET_OPS_ID\t\\\n\t((sizeof(struct net_generic) + sizeof(void *) - 1) / sizeof(void *))\n\n#define INITIAL_NET_GEN_PTRS\t13 /* +1 for len +2 for rcu_head */\n\nstatic unsigned int max_gen_ptrs = INITIAL_NET_GEN_PTRS;\n\nstatic struct net_generic *net_alloc_generic(void)\n{\n\tstruct net_generic *ng;\n\tunsigned int generic_size = offsetof(struct net_generic, ptr[max_gen_ptrs]);\n\n\tng = kzalloc(generic_size, GFP_KERNEL);\n\tif (ng)\n\t\tng->s.len = max_gen_ptrs;\n\n\treturn ng;\n}\n\nstatic int net_assign_generic(struct net *net, unsigned int id, void *data)\n{\n\tstruct net_generic *ng, *old_ng;\n\n\tBUG_ON(!mutex_is_locked(&net_mutex));\n\tBUG_ON(id < MIN_PERNET_OPS_ID);\n\n\told_ng = rcu_dereference_protected(net->gen,\n\t\t\t\t\t   lockdep_is_held(&net_mutex));\n\tif (old_ng->s.len > id) {\n\t\told_ng->ptr[id] = data;\n\t\treturn 0;\n\t}\n\n\tng = net_alloc_generic();\n\tif (ng == NULL)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Some synchronisation notes:\n\t *\n\t * The net_generic explores the net->gen array inside rcu\n\t * read section. Besides once set the net->gen->ptr[x]\n\t * pointer never changes (see rules in netns/generic.h).\n\t *\n\t * That said, we simply duplicate this array and schedule\n\t * the old copy for kfree after a grace period.\n\t */\n\n\tmemcpy(&ng->ptr[MIN_PERNET_OPS_ID], &old_ng->ptr[MIN_PERNET_OPS_ID],\n\t       (old_ng->s.len - MIN_PERNET_OPS_ID) * sizeof(void *));\n\tng->ptr[id] = data;\n\n\trcu_assign_pointer(net->gen, ng);\n\tkfree_rcu(old_ng, s.rcu);\n\treturn 0;\n}\n\nstatic int ops_init(const struct pernet_operations *ops, struct net *net)\n{\n\tint err = -ENOMEM;\n\tvoid *data = NULL;\n\n\tif (ops->id && ops->size) {\n\t\tdata = kzalloc(ops->size, GFP_KERNEL);\n\t\tif (!data)\n\t\t\tgoto out;\n\n\t\terr = net_assign_generic(net, *ops->id, data);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t}\n\terr = 0;\n\tif (ops->init)\n\t\terr = ops->init(net);\n\tif (!err)\n\t\treturn 0;\n\ncleanup:\n\tkfree(data);\n\nout:\n\treturn err;\n}\n\nstatic void ops_free(const struct pernet_operations *ops, struct net *net)\n{\n\tif (ops->id && ops->size) {\n\t\tkfree(net_generic(net, *ops->id));\n\t}\n}\n\nstatic void ops_exit_list(const struct pernet_operations *ops,\n\t\t\t  struct list_head *net_exit_list)\n{\n\tstruct net *net;\n\tif (ops->exit) {\n\t\tlist_for_each_entry(net, net_exit_list, exit_list)\n\t\t\tops->exit(net);\n\t}\n\tif (ops->exit_batch)\n\t\tops->exit_batch(net_exit_list);\n}\n\nstatic void ops_free_list(const struct pernet_operations *ops,\n\t\t\t  struct list_head *net_exit_list)\n{\n\tstruct net *net;\n\tif (ops->size && ops->id) {\n\t\tlist_for_each_entry(net, net_exit_list, exit_list)\n\t\t\tops_free(ops, net);\n\t}\n}\n\n/* should be called with nsid_lock held */\nstatic int alloc_netid(struct net *net, struct net *peer, int reqid)\n{\n\tint min = 0, max = 0;\n\n\tif (reqid >= 0) {\n\t\tmin = reqid;\n\t\tmax = reqid + 1;\n\t}\n\n\treturn idr_alloc(&net->netns_ids, peer, min, max, GFP_ATOMIC);\n}\n\n/* This function is used by idr_for_each(). If net is equal to peer, the\n * function returns the id so that idr_for_each() stops. Because we cannot\n * returns the id 0 (idr_for_each() will not stop), we return the magic value\n * NET_ID_ZERO (-1) for it.\n */\n#define NET_ID_ZERO -1\nstatic int net_eq_idr(int id, void *net, void *peer)\n{\n\tif (net_eq(net, peer))\n\t\treturn id ? : NET_ID_ZERO;\n\treturn 0;\n}\n\n/* Should be called with nsid_lock held. If a new id is assigned, the bool alloc\n * is set to true, thus the caller knows that the new id must be notified via\n * rtnl.\n */\nstatic int __peernet2id_alloc(struct net *net, struct net *peer, bool *alloc)\n{\n\tint id = idr_for_each(&net->netns_ids, net_eq_idr, peer);\n\tbool alloc_it = *alloc;\n\n\t*alloc = false;\n\n\t/* Magic value for id 0. */\n\tif (id == NET_ID_ZERO)\n\t\treturn 0;\n\tif (id > 0)\n\t\treturn id;\n\n\tif (alloc_it) {\n\t\tid = alloc_netid(net, peer, -1);\n\t\t*alloc = true;\n\t\treturn id >= 0 ? id : NETNSA_NSID_NOT_ASSIGNED;\n\t}\n\n\treturn NETNSA_NSID_NOT_ASSIGNED;\n}\n\n/* should be called with nsid_lock held */\nstatic int __peernet2id(struct net *net, struct net *peer)\n{\n\tbool no = false;\n\n\treturn __peernet2id_alloc(net, peer, &no);\n}\n\nstatic void rtnl_net_notifyid(struct net *net, int cmd, int id);\n/* This function returns the id of a peer netns. If no id is assigned, one will\n * be allocated and returned.\n */\nint peernet2id_alloc(struct net *net, struct net *peer)\n{\n\tbool alloc;\n\tint id;\n\n\tif (atomic_read(&net->count) == 0)\n\t\treturn NETNSA_NSID_NOT_ASSIGNED;\n\tspin_lock_bh(&net->nsid_lock);\n\talloc = atomic_read(&peer->count) == 0 ? false : true;\n\tid = __peernet2id_alloc(net, peer, &alloc);\n\tspin_unlock_bh(&net->nsid_lock);\n\tif (alloc && id >= 0)\n\t\trtnl_net_notifyid(net, RTM_NEWNSID, id);\n\treturn id;\n}\nEXPORT_SYMBOL_GPL(peernet2id_alloc);\n\n/* This function returns, if assigned, the id of a peer netns. */\nint peernet2id(struct net *net, struct net *peer)\n{\n\tint id;\n\n\tspin_lock_bh(&net->nsid_lock);\n\tid = __peernet2id(net, peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\treturn id;\n}\nEXPORT_SYMBOL(peernet2id);\n\n/* This function returns true is the peer netns has an id assigned into the\n * current netns.\n */\nbool peernet_has_id(struct net *net, struct net *peer)\n{\n\treturn peernet2id(net, peer) >= 0;\n}\n\nstruct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tget_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}\n\n/*\n * setup_net runs the initializers for the network namespace object.\n */\nstatic __net_init int setup_net(struct net *net, struct user_namespace *user_ns)\n{\n\t/* Must be called with net_mutex held */\n\tconst struct pernet_operations *ops, *saved_ops;\n\tint error = 0;\n\tLIST_HEAD(net_exit_list);\n\n\tatomic_set(&net->count, 1);\n\trefcount_set(&net->passive, 1);\n\tnet->dev_base_seq = 1;\n\tnet->user_ns = user_ns;\n\tidr_init(&net->netns_ids);\n\tspin_lock_init(&net->nsid_lock);\n\n\tlist_for_each_entry(ops, &pernet_list, list) {\n\t\terror = ops_init(ops, net);\n\t\tif (error < 0)\n\t\t\tgoto out_undo;\n\t}\nout:\n\treturn error;\n\nout_undo:\n\t/* Walk through the list backwards calling the exit functions\n\t * for the pernet modules whose init functions did not fail.\n\t */\n\tlist_add(&net->exit_list, &net_exit_list);\n\tsaved_ops = ops;\n\tlist_for_each_entry_continue_reverse(ops, &pernet_list, list)\n\t\tops_exit_list(ops, &net_exit_list);\n\n\tops = saved_ops;\n\tlist_for_each_entry_continue_reverse(ops, &pernet_list, list)\n\t\tops_free_list(ops, &net_exit_list);\n\n\trcu_barrier();\n\tgoto out;\n}\n\nstatic int __net_init net_defaults_init_net(struct net *net)\n{\n\tnet->core.sysctl_somaxconn = SOMAXCONN;\n\treturn 0;\n}\n\nstatic struct pernet_operations net_defaults_ops = {\n\t.init = net_defaults_init_net,\n};\n\nstatic __init int net_defaults_init(void)\n{\n\tif (register_pernet_subsys(&net_defaults_ops))\n\t\tpanic(\"Cannot initialize net default settings\");\n\n\treturn 0;\n}\n\ncore_initcall(net_defaults_init);\n\n#ifdef CONFIG_NET_NS\nstatic struct ucounts *inc_net_namespaces(struct user_namespace *ns)\n{\n\treturn inc_ucount(ns, current_euid(), UCOUNT_NET_NAMESPACES);\n}\n\nstatic void dec_net_namespaces(struct ucounts *ucounts)\n{\n\tdec_ucount(ucounts, UCOUNT_NET_NAMESPACES);\n}\n\nstatic struct kmem_cache *net_cachep;\nstatic struct workqueue_struct *netns_wq;\n\nstatic struct net *net_alloc(void)\n{\n\tstruct net *net = NULL;\n\tstruct net_generic *ng;\n\n\tng = net_alloc_generic();\n\tif (!ng)\n\t\tgoto out;\n\n\tnet = kmem_cache_zalloc(net_cachep, GFP_KERNEL);\n\tif (!net)\n\t\tgoto out_free;\n\n\trcu_assign_pointer(net->gen, ng);\nout:\n\treturn net;\n\nout_free:\n\tkfree(ng);\n\tgoto out;\n}\n\nstatic void net_free(struct net *net)\n{\n\tkfree(rcu_access_pointer(net->gen));\n\tkmem_cache_free(net_cachep, net);\n}\n\nvoid net_drop_ns(void *p)\n{\n\tstruct net *ns = p;\n\tif (ns && refcount_dec_and_test(&ns->passive))\n\t\tnet_free(ns);\n}\n\nstruct net *copy_net_ns(unsigned long flags,\n\t\t\tstruct user_namespace *user_ns, struct net *old_net)\n{\n\tstruct ucounts *ucounts;\n\tstruct net *net;\n\tint rv;\n\n\tif (!(flags & CLONE_NEWNET))\n\t\treturn get_net(old_net);\n\n\tucounts = inc_net_namespaces(user_ns);\n\tif (!ucounts)\n\t\treturn ERR_PTR(-ENOSPC);\n\n\tnet = net_alloc();\n\tif (!net) {\n\t\tdec_net_namespaces(ucounts);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tget_user_ns(user_ns);\n\n\trv = mutex_lock_killable(&net_mutex);\n\tif (rv < 0) {\n\t\tnet_free(net);\n\t\tdec_net_namespaces(ucounts);\n\t\tput_user_ns(user_ns);\n\t\treturn ERR_PTR(rv);\n\t}\n\n\tnet->ucounts = ucounts;\n\trv = setup_net(net, user_ns);\n\tif (rv == 0) {\n\t\trtnl_lock();\n\t\tlist_add_tail_rcu(&net->list, &net_namespace_list);\n\t\trtnl_unlock();\n\t}\n\tmutex_unlock(&net_mutex);\n\tif (rv < 0) {\n\t\tdec_net_namespaces(ucounts);\n\t\tput_user_ns(user_ns);\n\t\tnet_drop_ns(net);\n\t\treturn ERR_PTR(rv);\n\t}\n\treturn net;\n}\n\nstatic DEFINE_SPINLOCK(cleanup_list_lock);\nstatic LIST_HEAD(cleanup_list);  /* Must hold cleanup_list_lock to touch */\n\nstatic void cleanup_net(struct work_struct *work)\n{\n\tconst struct pernet_operations *ops;\n\tstruct net *net, *tmp;\n\tstruct list_head net_kill_list;\n\tLIST_HEAD(net_exit_list);\n\n\t/* Atomically snapshot the list of namespaces to cleanup */\n\tspin_lock_irq(&cleanup_list_lock);\n\tlist_replace_init(&cleanup_list, &net_kill_list);\n\tspin_unlock_irq(&cleanup_list_lock);\n\n\tmutex_lock(&net_mutex);\n\n\t/* Don't let anyone else find us. */\n\trtnl_lock();\n\tlist_for_each_entry(net, &net_kill_list, cleanup_list) {\n\t\tlist_del_rcu(&net->list);\n\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\t\tfor_each_net(tmp) {\n\t\t\tint id;\n\n\t\t\tspin_lock_bh(&tmp->nsid_lock);\n\t\t\tid = __peernet2id(tmp, net);\n\t\t\tif (id >= 0)\n\t\t\t\tidr_remove(&tmp->netns_ids, id);\n\t\t\tspin_unlock_bh(&tmp->nsid_lock);\n\t\t\tif (id >= 0)\n\t\t\t\trtnl_net_notifyid(tmp, RTM_DELNSID, id);\n\t\t}\n\t\tspin_lock_bh(&net->nsid_lock);\n\t\tidr_destroy(&net->netns_ids);\n\t\tspin_unlock_bh(&net->nsid_lock);\n\n\t}\n\trtnl_unlock();\n\n\t/*\n\t * Another CPU might be rcu-iterating the list, wait for it.\n\t * This needs to be before calling the exit() notifiers, so\n\t * the rcu_barrier() below isn't sufficient alone.\n\t */\n\tsynchronize_rcu();\n\n\t/* Run all of the network namespace exit methods */\n\tlist_for_each_entry_reverse(ops, &pernet_list, list)\n\t\tops_exit_list(ops, &net_exit_list);\n\n\t/* Free the net generic variables */\n\tlist_for_each_entry_reverse(ops, &pernet_list, list)\n\t\tops_free_list(ops, &net_exit_list);\n\n\tmutex_unlock(&net_mutex);\n\n\t/* Ensure there are no outstanding rcu callbacks using this\n\t * network namespace.\n\t */\n\trcu_barrier();\n\n\t/* Finally it is safe to free my network namespace structure */\n\tlist_for_each_entry_safe(net, tmp, &net_exit_list, exit_list) {\n\t\tlist_del_init(&net->exit_list);\n\t\tdec_net_namespaces(net->ucounts);\n\t\tput_user_ns(net->user_ns);\n\t\tnet_drop_ns(net);\n\t}\n}\n\n/**\n * net_ns_barrier - wait until concurrent net_cleanup_work is done\n *\n * cleanup_net runs from work queue and will first remove namespaces\n * from the global list, then run net exit functions.\n *\n * Call this in module exit path to make sure that all netns\n * ->exit ops have been invoked before the function is removed.\n */\nvoid net_ns_barrier(void)\n{\n\tmutex_lock(&net_mutex);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL(net_ns_barrier);\n\nstatic DECLARE_WORK(net_cleanup_work, cleanup_net);\n\nvoid __put_net(struct net *net)\n{\n\t/* Cleanup the network namespace in process context */\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cleanup_list_lock, flags);\n\tlist_add(&net->cleanup_list, &cleanup_list);\n\tspin_unlock_irqrestore(&cleanup_list_lock, flags);\n\n\tqueue_work(netns_wq, &net_cleanup_work);\n}\nEXPORT_SYMBOL_GPL(__put_net);\n\nstruct net *get_net_ns_by_fd(int fd)\n{\n\tstruct file *file;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\tfile = proc_ns_fget(fd);\n\tif (IS_ERR(file))\n\t\treturn ERR_CAST(file);\n\n\tns = get_proc_ns(file_inode(file));\n\tif (ns->ops == &netns_operations)\n\t\tnet = get_net(container_of(ns, struct net, ns));\n\telse\n\t\tnet = ERR_PTR(-EINVAL);\n\n\tfput(file);\n\treturn net;\n}\n\n#else\nstruct net *get_net_ns_by_fd(int fd)\n{\n\treturn ERR_PTR(-EINVAL);\n}\n#endif\nEXPORT_SYMBOL_GPL(get_net_ns_by_fd);\n\nstruct net *get_net_ns_by_pid(pid_t pid)\n{\n\tstruct task_struct *tsk;\n\tstruct net *net;\n\n\t/* Lookup the network namespace */\n\tnet = ERR_PTR(-ESRCH);\n\trcu_read_lock();\n\ttsk = find_task_by_vpid(pid);\n\tif (tsk) {\n\t\tstruct nsproxy *nsproxy;\n\t\ttask_lock(tsk);\n\t\tnsproxy = tsk->nsproxy;\n\t\tif (nsproxy)\n\t\t\tnet = get_net(nsproxy->net_ns);\n\t\ttask_unlock(tsk);\n\t}\n\trcu_read_unlock();\n\treturn net;\n}\nEXPORT_SYMBOL_GPL(get_net_ns_by_pid);\n\nstatic __net_init int net_ns_net_init(struct net *net)\n{\n#ifdef CONFIG_NET_NS\n\tnet->ns.ops = &netns_operations;\n#endif\n\treturn ns_alloc_inum(&net->ns);\n}\n\nstatic __net_exit void net_ns_net_exit(struct net *net)\n{\n\tns_free_inum(&net->ns);\n}\n\nstatic struct pernet_operations __net_initdata net_ns_ops = {\n\t.init = net_ns_net_init,\n\t.exit = net_ns_net_exit,\n};\n\nstatic const struct nla_policy rtnl_net_policy[NETNSA_MAX + 1] = {\n\t[NETNSA_NONE]\t\t= { .type = NLA_UNSPEC },\n\t[NETNSA_NSID]\t\t= { .type = NLA_S32 },\n\t[NETNSA_PID]\t\t= { .type = NLA_U32 },\n\t[NETNSA_FD]\t\t= { .type = NLA_U32 },\n};\n\nstatic int rtnl_net_newid(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[NETNSA_MAX + 1];\n\tstruct nlattr *nla;\n\tstruct net *peer;\n\tint nsid, err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct rtgenmsg), tb, NETNSA_MAX,\n\t\t\t  rtnl_net_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\tif (!tb[NETNSA_NSID]) {\n\t\tNL_SET_ERR_MSG(extack, \"nsid is missing\");\n\t\treturn -EINVAL;\n\t}\n\tnsid = nla_get_s32(tb[NETNSA_NSID]);\n\n\tif (tb[NETNSA_PID]) {\n\t\tpeer = get_net_ns_by_pid(nla_get_u32(tb[NETNSA_PID]));\n\t\tnla = tb[NETNSA_PID];\n\t} else if (tb[NETNSA_FD]) {\n\t\tpeer = get_net_ns_by_fd(nla_get_u32(tb[NETNSA_FD]));\n\t\tnla = tb[NETNSA_FD];\n\t} else {\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is missing\");\n\t\treturn -EINVAL;\n\t}\n\tif (IS_ERR(peer)) {\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is invalid\");\n\t\treturn PTR_ERR(peer);\n\t}\n\n\tspin_lock_bh(&net->nsid_lock);\n\tif (__peernet2id(net, peer) >= 0) {\n\t\tspin_unlock_bh(&net->nsid_lock);\n\t\terr = -EEXIST;\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Peer netns already has a nsid assigned\");\n\t\tgoto out;\n\t}\n\n\terr = alloc_netid(net, peer, nsid);\n\tspin_unlock_bh(&net->nsid_lock);\n\tif (err >= 0) {\n\t\trtnl_net_notifyid(net, RTM_NEWNSID, err);\n\t\terr = 0;\n\t} else if (err == -ENOSPC && nsid >= 0) {\n\t\terr = -EEXIST;\n\t\tNL_SET_BAD_ATTR(extack, tb[NETNSA_NSID]);\n\t\tNL_SET_ERR_MSG(extack, \"The specified nsid is already used\");\n\t}\nout:\n\tput_net(peer);\n\treturn err;\n}\n\nstatic int rtnl_net_get_size(void)\n{\n\treturn NLMSG_ALIGN(sizeof(struct rtgenmsg))\n\t       + nla_total_size(sizeof(s32)) /* NETNSA_NSID */\n\t       ;\n}\n\nstatic int rtnl_net_fill(struct sk_buff *skb, u32 portid, u32 seq, int flags,\n\t\t\t int cmd, struct net *net, int nsid)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct rtgenmsg *rth;\n\n\tnlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rth), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\trth = nlmsg_data(nlh);\n\trth->rtgen_family = AF_UNSPEC;\n\n\tif (nla_put_s32(skb, NETNSA_NSID, nsid))\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int rtnl_net_getid(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[NETNSA_MAX + 1];\n\tstruct nlattr *nla;\n\tstruct sk_buff *msg;\n\tstruct net *peer;\n\tint err, id;\n\n\terr = nlmsg_parse(nlh, sizeof(struct rtgenmsg), tb, NETNSA_MAX,\n\t\t\t  rtnl_net_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\tif (tb[NETNSA_PID]) {\n\t\tpeer = get_net_ns_by_pid(nla_get_u32(tb[NETNSA_PID]));\n\t\tnla = tb[NETNSA_PID];\n\t} else if (tb[NETNSA_FD]) {\n\t\tpeer = get_net_ns_by_fd(nla_get_u32(tb[NETNSA_FD]));\n\t\tnla = tb[NETNSA_FD];\n\t} else {\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (IS_ERR(peer)) {\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is invalid\");\n\t\treturn PTR_ERR(peer);\n\t}\n\n\tmsg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);\n\tif (!msg) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tid = peernet2id(net, peer);\n\terr = rtnl_net_fill(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq, 0,\n\t\t\t    RTM_NEWNSID, net, id);\n\tif (err < 0)\n\t\tgoto err_out;\n\n\terr = rtnl_unicast(msg, net, NETLINK_CB(skb).portid);\n\tgoto out;\n\nerr_out:\n\tnlmsg_free(msg);\nout:\n\tput_net(peer);\n\treturn err;\n}\n\nstruct rtnl_net_dump_cb {\n\tstruct net *net;\n\tstruct sk_buff *skb;\n\tstruct netlink_callback *cb;\n\tint idx;\n\tint s_idx;\n};\n\nstatic int rtnl_net_dumpid_one(int id, void *peer, void *data)\n{\n\tstruct rtnl_net_dump_cb *net_cb = (struct rtnl_net_dump_cb *)data;\n\tint ret;\n\n\tif (net_cb->idx < net_cb->s_idx)\n\t\tgoto cont;\n\n\tret = rtnl_net_fill(net_cb->skb, NETLINK_CB(net_cb->cb->skb).portid,\n\t\t\t    net_cb->cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t    RTM_NEWNSID, net_cb->net, id);\n\tif (ret < 0)\n\t\treturn ret;\n\ncont:\n\tnet_cb->idx++;\n\treturn 0;\n}\n\nstatic int rtnl_net_dumpid(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct rtnl_net_dump_cb net_cb = {\n\t\t.net = net,\n\t\t.skb = skb,\n\t\t.cb = cb,\n\t\t.idx = 0,\n\t\t.s_idx = cb->args[0],\n\t};\n\n\tspin_lock_bh(&net->nsid_lock);\n\tidr_for_each(&net->netns_ids, rtnl_net_dumpid_one, &net_cb);\n\tspin_unlock_bh(&net->nsid_lock);\n\n\tcb->args[0] = net_cb.idx;\n\treturn skb->len;\n}\n\nstatic void rtnl_net_notifyid(struct net *net, int cmd, int id)\n{\n\tstruct sk_buff *msg;\n\tint err = -ENOMEM;\n\n\tmsg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);\n\tif (!msg)\n\t\tgoto out;\n\n\terr = rtnl_net_fill(msg, 0, 0, 0, cmd, net, id);\n\tif (err < 0)\n\t\tgoto err_out;\n\n\trtnl_notify(msg, net, 0, RTNLGRP_NSID, NULL, 0);\n\treturn;\n\nerr_out:\n\tnlmsg_free(msg);\nout:\n\trtnl_set_sk_err(net, RTNLGRP_NSID, err);\n}\n\nstatic int __init net_ns_init(void)\n{\n\tstruct net_generic *ng;\n\n#ifdef CONFIG_NET_NS\n\tnet_cachep = kmem_cache_create(\"net_namespace\", sizeof(struct net),\n\t\t\t\t\tSMP_CACHE_BYTES,\n\t\t\t\t\tSLAB_PANIC, NULL);\n\n\t/* Create workqueue for cleanup */\n\tnetns_wq = create_singlethread_workqueue(\"netns\");\n\tif (!netns_wq)\n\t\tpanic(\"Could not create netns workq\");\n#endif\n\n\tng = net_alloc_generic();\n\tif (!ng)\n\t\tpanic(\"Could not allocate generic netns\");\n\n\trcu_assign_pointer(init_net.gen, ng);\n\n\tmutex_lock(&net_mutex);\n\tif (setup_net(&init_net, &init_user_ns))\n\t\tpanic(\"Could not setup the initial network namespace\");\n\n\tinit_net_initialized = true;\n\n\trtnl_lock();\n\tlist_add_tail_rcu(&init_net.list, &net_namespace_list);\n\trtnl_unlock();\n\n\tmutex_unlock(&net_mutex);\n\n\tregister_pernet_subsys(&net_ns_ops);\n\n\trtnl_register(PF_UNSPEC, RTM_NEWNSID, rtnl_net_newid, NULL,\n\t\t      RTNL_FLAG_DOIT_UNLOCKED);\n\trtnl_register(PF_UNSPEC, RTM_GETNSID, rtnl_net_getid, rtnl_net_dumpid,\n\t\t      RTNL_FLAG_DOIT_UNLOCKED);\n\n\treturn 0;\n}\n\npure_initcall(net_ns_init);\n\n#ifdef CONFIG_NET_NS\nstatic int __register_pernet_operations(struct list_head *list,\n\t\t\t\t\tstruct pernet_operations *ops)\n{\n\tstruct net *net;\n\tint error;\n\tLIST_HEAD(net_exit_list);\n\n\tlist_add_tail(&ops->list, list);\n\tif (ops->init || (ops->id && ops->size)) {\n\t\tfor_each_net(net) {\n\t\t\terror = ops_init(ops, net);\n\t\t\tif (error)\n\t\t\t\tgoto out_undo;\n\t\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\t\t}\n\t}\n\treturn 0;\n\nout_undo:\n\t/* If I have an error cleanup all namespaces I initialized */\n\tlist_del(&ops->list);\n\tops_exit_list(ops, &net_exit_list);\n\tops_free_list(ops, &net_exit_list);\n\treturn error;\n}\n\nstatic void __unregister_pernet_operations(struct pernet_operations *ops)\n{\n\tstruct net *net;\n\tLIST_HEAD(net_exit_list);\n\n\tlist_del(&ops->list);\n\tfor_each_net(net)\n\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\tops_exit_list(ops, &net_exit_list);\n\tops_free_list(ops, &net_exit_list);\n}\n\n#else\n\nstatic int __register_pernet_operations(struct list_head *list,\n\t\t\t\t\tstruct pernet_operations *ops)\n{\n\tif (!init_net_initialized) {\n\t\tlist_add_tail(&ops->list, list);\n\t\treturn 0;\n\t}\n\n\treturn ops_init(ops, &init_net);\n}\n\nstatic void __unregister_pernet_operations(struct pernet_operations *ops)\n{\n\tif (!init_net_initialized) {\n\t\tlist_del(&ops->list);\n\t} else {\n\t\tLIST_HEAD(net_exit_list);\n\t\tlist_add(&init_net.exit_list, &net_exit_list);\n\t\tops_exit_list(ops, &net_exit_list);\n\t\tops_free_list(ops, &net_exit_list);\n\t}\n}\n\n#endif /* CONFIG_NET_NS */\n\nstatic DEFINE_IDA(net_generic_ids);\n\nstatic int register_pernet_operations(struct list_head *list,\n\t\t\t\t      struct pernet_operations *ops)\n{\n\tint error;\n\n\tif (ops->id) {\nagain:\n\t\terror = ida_get_new_above(&net_generic_ids, MIN_PERNET_OPS_ID, ops->id);\n\t\tif (error < 0) {\n\t\t\tif (error == -EAGAIN) {\n\t\t\t\tida_pre_get(&net_generic_ids, GFP_KERNEL);\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\treturn error;\n\t\t}\n\t\tmax_gen_ptrs = max(max_gen_ptrs, *ops->id + 1);\n\t}\n\terror = __register_pernet_operations(list, ops);\n\tif (error) {\n\t\trcu_barrier();\n\t\tif (ops->id)\n\t\t\tida_remove(&net_generic_ids, *ops->id);\n\t}\n\n\treturn error;\n}\n\nstatic void unregister_pernet_operations(struct pernet_operations *ops)\n{\n\t\n\t__unregister_pernet_operations(ops);\n\trcu_barrier();\n\tif (ops->id)\n\t\tida_remove(&net_generic_ids, *ops->id);\n}\n\n/**\n *      register_pernet_subsys - register a network namespace subsystem\n *\t@ops:  pernet operations structure for the subsystem\n *\n *\tRegister a subsystem which has init and exit functions\n *\tthat are called when network namespaces are created and\n *\tdestroyed respectively.\n *\n *\tWhen registered all network namespace init functions are\n *\tcalled for every existing network namespace.  Allowing kernel\n *\tmodules to have a race free view of the set of network namespaces.\n *\n *\tWhen a new network namespace is created all of the init\n *\tmethods are called in the order in which they were registered.\n *\n *\tWhen a network namespace is destroyed all of the exit methods\n *\tare called in the reverse of the order with which they were\n *\tregistered.\n */\nint register_pernet_subsys(struct pernet_operations *ops)\n{\n\tint error;\n\tmutex_lock(&net_mutex);\n\terror =  register_pernet_operations(first_device, ops);\n\tmutex_unlock(&net_mutex);\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(register_pernet_subsys);\n\n/**\n *      unregister_pernet_subsys - unregister a network namespace subsystem\n *\t@ops: pernet operations structure to manipulate\n *\n *\tRemove the pernet operations structure from the list to be\n *\tused when network namespaces are created or destroyed.  In\n *\taddition run the exit method for all existing network\n *\tnamespaces.\n */\nvoid unregister_pernet_subsys(struct pernet_operations *ops)\n{\n\tmutex_lock(&net_mutex);\n\tunregister_pernet_operations(ops);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL_GPL(unregister_pernet_subsys);\n\n/**\n *      register_pernet_device - register a network namespace device\n *\t@ops:  pernet operations structure for the subsystem\n *\n *\tRegister a device which has init and exit functions\n *\tthat are called when network namespaces are created and\n *\tdestroyed respectively.\n *\n *\tWhen registered all network namespace init functions are\n *\tcalled for every existing network namespace.  Allowing kernel\n *\tmodules to have a race free view of the set of network namespaces.\n *\n *\tWhen a new network namespace is created all of the init\n *\tmethods are called in the order in which they were registered.\n *\n *\tWhen a network namespace is destroyed all of the exit methods\n *\tare called in the reverse of the order with which they were\n *\tregistered.\n */\nint register_pernet_device(struct pernet_operations *ops)\n{\n\tint error;\n\tmutex_lock(&net_mutex);\n\terror = register_pernet_operations(&pernet_list, ops);\n\tif (!error && (first_device == &pernet_list))\n\t\tfirst_device = &ops->list;\n\tmutex_unlock(&net_mutex);\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(register_pernet_device);\n\n/**\n *      unregister_pernet_device - unregister a network namespace netdevice\n *\t@ops: pernet operations structure to manipulate\n *\n *\tRemove the pernet operations structure from the list to be\n *\tused when network namespaces are created or destroyed.  In\n *\taddition run the exit method for all existing network\n *\tnamespaces.\n */\nvoid unregister_pernet_device(struct pernet_operations *ops)\n{\n\tmutex_lock(&net_mutex);\n\tif (&ops->list == first_device)\n\t\tfirst_device = first_device->next;\n\tunregister_pernet_operations(ops);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL_GPL(unregister_pernet_device);\n\n#ifdef CONFIG_NET_NS\nstatic struct ns_common *netns_get(struct task_struct *task)\n{\n\tstruct net *net = NULL;\n\tstruct nsproxy *nsproxy;\n\n\ttask_lock(task);\n\tnsproxy = task->nsproxy;\n\tif (nsproxy)\n\t\tnet = get_net(nsproxy->net_ns);\n\ttask_unlock(task);\n\n\treturn net ? &net->ns : NULL;\n}\n\nstatic inline struct net *to_net_ns(struct ns_common *ns)\n{\n\treturn container_of(ns, struct net, ns);\n}\n\nstatic void netns_put(struct ns_common *ns)\n{\n\tput_net(to_net_ns(ns));\n}\n\nstatic int netns_install(struct nsproxy *nsproxy, struct ns_common *ns)\n{\n\tstruct net *net = to_net_ns(ns);\n\n\tif (!ns_capable(net->user_ns, CAP_SYS_ADMIN) ||\n\t    !ns_capable(current_user_ns(), CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tput_net(nsproxy->net_ns);\n\tnsproxy->net_ns = get_net(net);\n\treturn 0;\n}\n\nstatic struct user_namespace *netns_owner(struct ns_common *ns)\n{\n\treturn to_net_ns(ns)->user_ns;\n}\n\nconst struct proc_ns_operations netns_operations = {\n\t.name\t\t= \"net\",\n\t.type\t\t= CLONE_NEWNET,\n\t.get\t\t= netns_get,\n\t.put\t\t= netns_put,\n\t.install\t= netns_install,\n\t.owner\t\t= netns_owner,\n};\n#endif\n"], "fixing_code": ["#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/workqueue.h>\n#include <linux/rtnetlink.h>\n#include <linux/cache.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/delay.h>\n#include <linux/sched.h>\n#include <linux/idr.h>\n#include <linux/rculist.h>\n#include <linux/nsproxy.h>\n#include <linux/fs.h>\n#include <linux/proc_ns.h>\n#include <linux/file.h>\n#include <linux/export.h>\n#include <linux/user_namespace.h>\n#include <linux/net_namespace.h>\n#include <linux/sched/task.h>\n\n#include <net/sock.h>\n#include <net/netlink.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n\n/*\n *\tOur network namespace constructor/destructor lists\n */\n\nstatic LIST_HEAD(pernet_list);\nstatic struct list_head *first_device = &pernet_list;\nDEFINE_MUTEX(net_mutex);\n\nLIST_HEAD(net_namespace_list);\nEXPORT_SYMBOL_GPL(net_namespace_list);\n\nstruct net init_net = {\n\t.count\t\t= ATOMIC_INIT(1),\n\t.dev_base_head\t= LIST_HEAD_INIT(init_net.dev_base_head),\n};\nEXPORT_SYMBOL(init_net);\n\nstatic bool init_net_initialized;\n\n#define MIN_PERNET_OPS_ID\t\\\n\t((sizeof(struct net_generic) + sizeof(void *) - 1) / sizeof(void *))\n\n#define INITIAL_NET_GEN_PTRS\t13 /* +1 for len +2 for rcu_head */\n\nstatic unsigned int max_gen_ptrs = INITIAL_NET_GEN_PTRS;\n\nstatic struct net_generic *net_alloc_generic(void)\n{\n\tstruct net_generic *ng;\n\tunsigned int generic_size = offsetof(struct net_generic, ptr[max_gen_ptrs]);\n\n\tng = kzalloc(generic_size, GFP_KERNEL);\n\tif (ng)\n\t\tng->s.len = max_gen_ptrs;\n\n\treturn ng;\n}\n\nstatic int net_assign_generic(struct net *net, unsigned int id, void *data)\n{\n\tstruct net_generic *ng, *old_ng;\n\n\tBUG_ON(!mutex_is_locked(&net_mutex));\n\tBUG_ON(id < MIN_PERNET_OPS_ID);\n\n\told_ng = rcu_dereference_protected(net->gen,\n\t\t\t\t\t   lockdep_is_held(&net_mutex));\n\tif (old_ng->s.len > id) {\n\t\told_ng->ptr[id] = data;\n\t\treturn 0;\n\t}\n\n\tng = net_alloc_generic();\n\tif (ng == NULL)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Some synchronisation notes:\n\t *\n\t * The net_generic explores the net->gen array inside rcu\n\t * read section. Besides once set the net->gen->ptr[x]\n\t * pointer never changes (see rules in netns/generic.h).\n\t *\n\t * That said, we simply duplicate this array and schedule\n\t * the old copy for kfree after a grace period.\n\t */\n\n\tmemcpy(&ng->ptr[MIN_PERNET_OPS_ID], &old_ng->ptr[MIN_PERNET_OPS_ID],\n\t       (old_ng->s.len - MIN_PERNET_OPS_ID) * sizeof(void *));\n\tng->ptr[id] = data;\n\n\trcu_assign_pointer(net->gen, ng);\n\tkfree_rcu(old_ng, s.rcu);\n\treturn 0;\n}\n\nstatic int ops_init(const struct pernet_operations *ops, struct net *net)\n{\n\tint err = -ENOMEM;\n\tvoid *data = NULL;\n\n\tif (ops->id && ops->size) {\n\t\tdata = kzalloc(ops->size, GFP_KERNEL);\n\t\tif (!data)\n\t\t\tgoto out;\n\n\t\terr = net_assign_generic(net, *ops->id, data);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t}\n\terr = 0;\n\tif (ops->init)\n\t\terr = ops->init(net);\n\tif (!err)\n\t\treturn 0;\n\ncleanup:\n\tkfree(data);\n\nout:\n\treturn err;\n}\n\nstatic void ops_free(const struct pernet_operations *ops, struct net *net)\n{\n\tif (ops->id && ops->size) {\n\t\tkfree(net_generic(net, *ops->id));\n\t}\n}\n\nstatic void ops_exit_list(const struct pernet_operations *ops,\n\t\t\t  struct list_head *net_exit_list)\n{\n\tstruct net *net;\n\tif (ops->exit) {\n\t\tlist_for_each_entry(net, net_exit_list, exit_list)\n\t\t\tops->exit(net);\n\t}\n\tif (ops->exit_batch)\n\t\tops->exit_batch(net_exit_list);\n}\n\nstatic void ops_free_list(const struct pernet_operations *ops,\n\t\t\t  struct list_head *net_exit_list)\n{\n\tstruct net *net;\n\tif (ops->size && ops->id) {\n\t\tlist_for_each_entry(net, net_exit_list, exit_list)\n\t\t\tops_free(ops, net);\n\t}\n}\n\n/* should be called with nsid_lock held */\nstatic int alloc_netid(struct net *net, struct net *peer, int reqid)\n{\n\tint min = 0, max = 0;\n\n\tif (reqid >= 0) {\n\t\tmin = reqid;\n\t\tmax = reqid + 1;\n\t}\n\n\treturn idr_alloc(&net->netns_ids, peer, min, max, GFP_ATOMIC);\n}\n\n/* This function is used by idr_for_each(). If net is equal to peer, the\n * function returns the id so that idr_for_each() stops. Because we cannot\n * returns the id 0 (idr_for_each() will not stop), we return the magic value\n * NET_ID_ZERO (-1) for it.\n */\n#define NET_ID_ZERO -1\nstatic int net_eq_idr(int id, void *net, void *peer)\n{\n\tif (net_eq(net, peer))\n\t\treturn id ? : NET_ID_ZERO;\n\treturn 0;\n}\n\n/* Should be called with nsid_lock held. If a new id is assigned, the bool alloc\n * is set to true, thus the caller knows that the new id must be notified via\n * rtnl.\n */\nstatic int __peernet2id_alloc(struct net *net, struct net *peer, bool *alloc)\n{\n\tint id = idr_for_each(&net->netns_ids, net_eq_idr, peer);\n\tbool alloc_it = *alloc;\n\n\t*alloc = false;\n\n\t/* Magic value for id 0. */\n\tif (id == NET_ID_ZERO)\n\t\treturn 0;\n\tif (id > 0)\n\t\treturn id;\n\n\tif (alloc_it) {\n\t\tid = alloc_netid(net, peer, -1);\n\t\t*alloc = true;\n\t\treturn id >= 0 ? id : NETNSA_NSID_NOT_ASSIGNED;\n\t}\n\n\treturn NETNSA_NSID_NOT_ASSIGNED;\n}\n\n/* should be called with nsid_lock held */\nstatic int __peernet2id(struct net *net, struct net *peer)\n{\n\tbool no = false;\n\n\treturn __peernet2id_alloc(net, peer, &no);\n}\n\nstatic void rtnl_net_notifyid(struct net *net, int cmd, int id);\n/* This function returns the id of a peer netns. If no id is assigned, one will\n * be allocated and returned.\n */\nint peernet2id_alloc(struct net *net, struct net *peer)\n{\n\tbool alloc;\n\tint id;\n\n\tif (atomic_read(&net->count) == 0)\n\t\treturn NETNSA_NSID_NOT_ASSIGNED;\n\tspin_lock_bh(&net->nsid_lock);\n\talloc = atomic_read(&peer->count) == 0 ? false : true;\n\tid = __peernet2id_alloc(net, peer, &alloc);\n\tspin_unlock_bh(&net->nsid_lock);\n\tif (alloc && id >= 0)\n\t\trtnl_net_notifyid(net, RTM_NEWNSID, id);\n\treturn id;\n}\nEXPORT_SYMBOL_GPL(peernet2id_alloc);\n\n/* This function returns, if assigned, the id of a peer netns. */\nint peernet2id(struct net *net, struct net *peer)\n{\n\tint id;\n\n\tspin_lock_bh(&net->nsid_lock);\n\tid = __peernet2id(net, peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\treturn id;\n}\nEXPORT_SYMBOL(peernet2id);\n\n/* This function returns true is the peer netns has an id assigned into the\n * current netns.\n */\nbool peernet_has_id(struct net *net, struct net *peer)\n{\n\treturn peernet2id(net, peer) >= 0;\n}\n\nstruct net *get_net_ns_by_id(struct net *net, int id)\n{\n\tstruct net *peer;\n\n\tif (id < 0)\n\t\treturn NULL;\n\n\trcu_read_lock();\n\tspin_lock_bh(&net->nsid_lock);\n\tpeer = idr_find(&net->netns_ids, id);\n\tif (peer)\n\t\tpeer = maybe_get_net(peer);\n\tspin_unlock_bh(&net->nsid_lock);\n\trcu_read_unlock();\n\n\treturn peer;\n}\n\n/*\n * setup_net runs the initializers for the network namespace object.\n */\nstatic __net_init int setup_net(struct net *net, struct user_namespace *user_ns)\n{\n\t/* Must be called with net_mutex held */\n\tconst struct pernet_operations *ops, *saved_ops;\n\tint error = 0;\n\tLIST_HEAD(net_exit_list);\n\n\tatomic_set(&net->count, 1);\n\trefcount_set(&net->passive, 1);\n\tnet->dev_base_seq = 1;\n\tnet->user_ns = user_ns;\n\tidr_init(&net->netns_ids);\n\tspin_lock_init(&net->nsid_lock);\n\n\tlist_for_each_entry(ops, &pernet_list, list) {\n\t\terror = ops_init(ops, net);\n\t\tif (error < 0)\n\t\t\tgoto out_undo;\n\t}\nout:\n\treturn error;\n\nout_undo:\n\t/* Walk through the list backwards calling the exit functions\n\t * for the pernet modules whose init functions did not fail.\n\t */\n\tlist_add(&net->exit_list, &net_exit_list);\n\tsaved_ops = ops;\n\tlist_for_each_entry_continue_reverse(ops, &pernet_list, list)\n\t\tops_exit_list(ops, &net_exit_list);\n\n\tops = saved_ops;\n\tlist_for_each_entry_continue_reverse(ops, &pernet_list, list)\n\t\tops_free_list(ops, &net_exit_list);\n\n\trcu_barrier();\n\tgoto out;\n}\n\nstatic int __net_init net_defaults_init_net(struct net *net)\n{\n\tnet->core.sysctl_somaxconn = SOMAXCONN;\n\treturn 0;\n}\n\nstatic struct pernet_operations net_defaults_ops = {\n\t.init = net_defaults_init_net,\n};\n\nstatic __init int net_defaults_init(void)\n{\n\tif (register_pernet_subsys(&net_defaults_ops))\n\t\tpanic(\"Cannot initialize net default settings\");\n\n\treturn 0;\n}\n\ncore_initcall(net_defaults_init);\n\n#ifdef CONFIG_NET_NS\nstatic struct ucounts *inc_net_namespaces(struct user_namespace *ns)\n{\n\treturn inc_ucount(ns, current_euid(), UCOUNT_NET_NAMESPACES);\n}\n\nstatic void dec_net_namespaces(struct ucounts *ucounts)\n{\n\tdec_ucount(ucounts, UCOUNT_NET_NAMESPACES);\n}\n\nstatic struct kmem_cache *net_cachep;\nstatic struct workqueue_struct *netns_wq;\n\nstatic struct net *net_alloc(void)\n{\n\tstruct net *net = NULL;\n\tstruct net_generic *ng;\n\n\tng = net_alloc_generic();\n\tif (!ng)\n\t\tgoto out;\n\n\tnet = kmem_cache_zalloc(net_cachep, GFP_KERNEL);\n\tif (!net)\n\t\tgoto out_free;\n\n\trcu_assign_pointer(net->gen, ng);\nout:\n\treturn net;\n\nout_free:\n\tkfree(ng);\n\tgoto out;\n}\n\nstatic void net_free(struct net *net)\n{\n\tkfree(rcu_access_pointer(net->gen));\n\tkmem_cache_free(net_cachep, net);\n}\n\nvoid net_drop_ns(void *p)\n{\n\tstruct net *ns = p;\n\tif (ns && refcount_dec_and_test(&ns->passive))\n\t\tnet_free(ns);\n}\n\nstruct net *copy_net_ns(unsigned long flags,\n\t\t\tstruct user_namespace *user_ns, struct net *old_net)\n{\n\tstruct ucounts *ucounts;\n\tstruct net *net;\n\tint rv;\n\n\tif (!(flags & CLONE_NEWNET))\n\t\treturn get_net(old_net);\n\n\tucounts = inc_net_namespaces(user_ns);\n\tif (!ucounts)\n\t\treturn ERR_PTR(-ENOSPC);\n\n\tnet = net_alloc();\n\tif (!net) {\n\t\tdec_net_namespaces(ucounts);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tget_user_ns(user_ns);\n\n\trv = mutex_lock_killable(&net_mutex);\n\tif (rv < 0) {\n\t\tnet_free(net);\n\t\tdec_net_namespaces(ucounts);\n\t\tput_user_ns(user_ns);\n\t\treturn ERR_PTR(rv);\n\t}\n\n\tnet->ucounts = ucounts;\n\trv = setup_net(net, user_ns);\n\tif (rv == 0) {\n\t\trtnl_lock();\n\t\tlist_add_tail_rcu(&net->list, &net_namespace_list);\n\t\trtnl_unlock();\n\t}\n\tmutex_unlock(&net_mutex);\n\tif (rv < 0) {\n\t\tdec_net_namespaces(ucounts);\n\t\tput_user_ns(user_ns);\n\t\tnet_drop_ns(net);\n\t\treturn ERR_PTR(rv);\n\t}\n\treturn net;\n}\n\nstatic DEFINE_SPINLOCK(cleanup_list_lock);\nstatic LIST_HEAD(cleanup_list);  /* Must hold cleanup_list_lock to touch */\n\nstatic void cleanup_net(struct work_struct *work)\n{\n\tconst struct pernet_operations *ops;\n\tstruct net *net, *tmp;\n\tstruct list_head net_kill_list;\n\tLIST_HEAD(net_exit_list);\n\n\t/* Atomically snapshot the list of namespaces to cleanup */\n\tspin_lock_irq(&cleanup_list_lock);\n\tlist_replace_init(&cleanup_list, &net_kill_list);\n\tspin_unlock_irq(&cleanup_list_lock);\n\n\tmutex_lock(&net_mutex);\n\n\t/* Don't let anyone else find us. */\n\trtnl_lock();\n\tlist_for_each_entry(net, &net_kill_list, cleanup_list) {\n\t\tlist_del_rcu(&net->list);\n\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\t\tfor_each_net(tmp) {\n\t\t\tint id;\n\n\t\t\tspin_lock_bh(&tmp->nsid_lock);\n\t\t\tid = __peernet2id(tmp, net);\n\t\t\tif (id >= 0)\n\t\t\t\tidr_remove(&tmp->netns_ids, id);\n\t\t\tspin_unlock_bh(&tmp->nsid_lock);\n\t\t\tif (id >= 0)\n\t\t\t\trtnl_net_notifyid(tmp, RTM_DELNSID, id);\n\t\t}\n\t\tspin_lock_bh(&net->nsid_lock);\n\t\tidr_destroy(&net->netns_ids);\n\t\tspin_unlock_bh(&net->nsid_lock);\n\n\t}\n\trtnl_unlock();\n\n\t/*\n\t * Another CPU might be rcu-iterating the list, wait for it.\n\t * This needs to be before calling the exit() notifiers, so\n\t * the rcu_barrier() below isn't sufficient alone.\n\t */\n\tsynchronize_rcu();\n\n\t/* Run all of the network namespace exit methods */\n\tlist_for_each_entry_reverse(ops, &pernet_list, list)\n\t\tops_exit_list(ops, &net_exit_list);\n\n\t/* Free the net generic variables */\n\tlist_for_each_entry_reverse(ops, &pernet_list, list)\n\t\tops_free_list(ops, &net_exit_list);\n\n\tmutex_unlock(&net_mutex);\n\n\t/* Ensure there are no outstanding rcu callbacks using this\n\t * network namespace.\n\t */\n\trcu_barrier();\n\n\t/* Finally it is safe to free my network namespace structure */\n\tlist_for_each_entry_safe(net, tmp, &net_exit_list, exit_list) {\n\t\tlist_del_init(&net->exit_list);\n\t\tdec_net_namespaces(net->ucounts);\n\t\tput_user_ns(net->user_ns);\n\t\tnet_drop_ns(net);\n\t}\n}\n\n/**\n * net_ns_barrier - wait until concurrent net_cleanup_work is done\n *\n * cleanup_net runs from work queue and will first remove namespaces\n * from the global list, then run net exit functions.\n *\n * Call this in module exit path to make sure that all netns\n * ->exit ops have been invoked before the function is removed.\n */\nvoid net_ns_barrier(void)\n{\n\tmutex_lock(&net_mutex);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL(net_ns_barrier);\n\nstatic DECLARE_WORK(net_cleanup_work, cleanup_net);\n\nvoid __put_net(struct net *net)\n{\n\t/* Cleanup the network namespace in process context */\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cleanup_list_lock, flags);\n\tlist_add(&net->cleanup_list, &cleanup_list);\n\tspin_unlock_irqrestore(&cleanup_list_lock, flags);\n\n\tqueue_work(netns_wq, &net_cleanup_work);\n}\nEXPORT_SYMBOL_GPL(__put_net);\n\nstruct net *get_net_ns_by_fd(int fd)\n{\n\tstruct file *file;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\tfile = proc_ns_fget(fd);\n\tif (IS_ERR(file))\n\t\treturn ERR_CAST(file);\n\n\tns = get_proc_ns(file_inode(file));\n\tif (ns->ops == &netns_operations)\n\t\tnet = get_net(container_of(ns, struct net, ns));\n\telse\n\t\tnet = ERR_PTR(-EINVAL);\n\n\tfput(file);\n\treturn net;\n}\n\n#else\nstruct net *get_net_ns_by_fd(int fd)\n{\n\treturn ERR_PTR(-EINVAL);\n}\n#endif\nEXPORT_SYMBOL_GPL(get_net_ns_by_fd);\n\nstruct net *get_net_ns_by_pid(pid_t pid)\n{\n\tstruct task_struct *tsk;\n\tstruct net *net;\n\n\t/* Lookup the network namespace */\n\tnet = ERR_PTR(-ESRCH);\n\trcu_read_lock();\n\ttsk = find_task_by_vpid(pid);\n\tif (tsk) {\n\t\tstruct nsproxy *nsproxy;\n\t\ttask_lock(tsk);\n\t\tnsproxy = tsk->nsproxy;\n\t\tif (nsproxy)\n\t\t\tnet = get_net(nsproxy->net_ns);\n\t\ttask_unlock(tsk);\n\t}\n\trcu_read_unlock();\n\treturn net;\n}\nEXPORT_SYMBOL_GPL(get_net_ns_by_pid);\n\nstatic __net_init int net_ns_net_init(struct net *net)\n{\n#ifdef CONFIG_NET_NS\n\tnet->ns.ops = &netns_operations;\n#endif\n\treturn ns_alloc_inum(&net->ns);\n}\n\nstatic __net_exit void net_ns_net_exit(struct net *net)\n{\n\tns_free_inum(&net->ns);\n}\n\nstatic struct pernet_operations __net_initdata net_ns_ops = {\n\t.init = net_ns_net_init,\n\t.exit = net_ns_net_exit,\n};\n\nstatic const struct nla_policy rtnl_net_policy[NETNSA_MAX + 1] = {\n\t[NETNSA_NONE]\t\t= { .type = NLA_UNSPEC },\n\t[NETNSA_NSID]\t\t= { .type = NLA_S32 },\n\t[NETNSA_PID]\t\t= { .type = NLA_U32 },\n\t[NETNSA_FD]\t\t= { .type = NLA_U32 },\n};\n\nstatic int rtnl_net_newid(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[NETNSA_MAX + 1];\n\tstruct nlattr *nla;\n\tstruct net *peer;\n\tint nsid, err;\n\n\terr = nlmsg_parse(nlh, sizeof(struct rtgenmsg), tb, NETNSA_MAX,\n\t\t\t  rtnl_net_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\tif (!tb[NETNSA_NSID]) {\n\t\tNL_SET_ERR_MSG(extack, \"nsid is missing\");\n\t\treturn -EINVAL;\n\t}\n\tnsid = nla_get_s32(tb[NETNSA_NSID]);\n\n\tif (tb[NETNSA_PID]) {\n\t\tpeer = get_net_ns_by_pid(nla_get_u32(tb[NETNSA_PID]));\n\t\tnla = tb[NETNSA_PID];\n\t} else if (tb[NETNSA_FD]) {\n\t\tpeer = get_net_ns_by_fd(nla_get_u32(tb[NETNSA_FD]));\n\t\tnla = tb[NETNSA_FD];\n\t} else {\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is missing\");\n\t\treturn -EINVAL;\n\t}\n\tif (IS_ERR(peer)) {\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is invalid\");\n\t\treturn PTR_ERR(peer);\n\t}\n\n\tspin_lock_bh(&net->nsid_lock);\n\tif (__peernet2id(net, peer) >= 0) {\n\t\tspin_unlock_bh(&net->nsid_lock);\n\t\terr = -EEXIST;\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Peer netns already has a nsid assigned\");\n\t\tgoto out;\n\t}\n\n\terr = alloc_netid(net, peer, nsid);\n\tspin_unlock_bh(&net->nsid_lock);\n\tif (err >= 0) {\n\t\trtnl_net_notifyid(net, RTM_NEWNSID, err);\n\t\terr = 0;\n\t} else if (err == -ENOSPC && nsid >= 0) {\n\t\terr = -EEXIST;\n\t\tNL_SET_BAD_ATTR(extack, tb[NETNSA_NSID]);\n\t\tNL_SET_ERR_MSG(extack, \"The specified nsid is already used\");\n\t}\nout:\n\tput_net(peer);\n\treturn err;\n}\n\nstatic int rtnl_net_get_size(void)\n{\n\treturn NLMSG_ALIGN(sizeof(struct rtgenmsg))\n\t       + nla_total_size(sizeof(s32)) /* NETNSA_NSID */\n\t       ;\n}\n\nstatic int rtnl_net_fill(struct sk_buff *skb, u32 portid, u32 seq, int flags,\n\t\t\t int cmd, struct net *net, int nsid)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct rtgenmsg *rth;\n\n\tnlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rth), flags);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\trth = nlmsg_data(nlh);\n\trth->rtgen_family = AF_UNSPEC;\n\n\tif (nla_put_s32(skb, NETNSA_NSID, nsid))\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int rtnl_net_getid(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[NETNSA_MAX + 1];\n\tstruct nlattr *nla;\n\tstruct sk_buff *msg;\n\tstruct net *peer;\n\tint err, id;\n\n\terr = nlmsg_parse(nlh, sizeof(struct rtgenmsg), tb, NETNSA_MAX,\n\t\t\t  rtnl_net_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\tif (tb[NETNSA_PID]) {\n\t\tpeer = get_net_ns_by_pid(nla_get_u32(tb[NETNSA_PID]));\n\t\tnla = tb[NETNSA_PID];\n\t} else if (tb[NETNSA_FD]) {\n\t\tpeer = get_net_ns_by_fd(nla_get_u32(tb[NETNSA_FD]));\n\t\tnla = tb[NETNSA_FD];\n\t} else {\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (IS_ERR(peer)) {\n\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\tNL_SET_ERR_MSG(extack, \"Peer netns reference is invalid\");\n\t\treturn PTR_ERR(peer);\n\t}\n\n\tmsg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);\n\tif (!msg) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tid = peernet2id(net, peer);\n\terr = rtnl_net_fill(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq, 0,\n\t\t\t    RTM_NEWNSID, net, id);\n\tif (err < 0)\n\t\tgoto err_out;\n\n\terr = rtnl_unicast(msg, net, NETLINK_CB(skb).portid);\n\tgoto out;\n\nerr_out:\n\tnlmsg_free(msg);\nout:\n\tput_net(peer);\n\treturn err;\n}\n\nstruct rtnl_net_dump_cb {\n\tstruct net *net;\n\tstruct sk_buff *skb;\n\tstruct netlink_callback *cb;\n\tint idx;\n\tint s_idx;\n};\n\nstatic int rtnl_net_dumpid_one(int id, void *peer, void *data)\n{\n\tstruct rtnl_net_dump_cb *net_cb = (struct rtnl_net_dump_cb *)data;\n\tint ret;\n\n\tif (net_cb->idx < net_cb->s_idx)\n\t\tgoto cont;\n\n\tret = rtnl_net_fill(net_cb->skb, NETLINK_CB(net_cb->cb->skb).portid,\n\t\t\t    net_cb->cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t    RTM_NEWNSID, net_cb->net, id);\n\tif (ret < 0)\n\t\treturn ret;\n\ncont:\n\tnet_cb->idx++;\n\treturn 0;\n}\n\nstatic int rtnl_net_dumpid(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct rtnl_net_dump_cb net_cb = {\n\t\t.net = net,\n\t\t.skb = skb,\n\t\t.cb = cb,\n\t\t.idx = 0,\n\t\t.s_idx = cb->args[0],\n\t};\n\n\tspin_lock_bh(&net->nsid_lock);\n\tidr_for_each(&net->netns_ids, rtnl_net_dumpid_one, &net_cb);\n\tspin_unlock_bh(&net->nsid_lock);\n\n\tcb->args[0] = net_cb.idx;\n\treturn skb->len;\n}\n\nstatic void rtnl_net_notifyid(struct net *net, int cmd, int id)\n{\n\tstruct sk_buff *msg;\n\tint err = -ENOMEM;\n\n\tmsg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);\n\tif (!msg)\n\t\tgoto out;\n\n\terr = rtnl_net_fill(msg, 0, 0, 0, cmd, net, id);\n\tif (err < 0)\n\t\tgoto err_out;\n\n\trtnl_notify(msg, net, 0, RTNLGRP_NSID, NULL, 0);\n\treturn;\n\nerr_out:\n\tnlmsg_free(msg);\nout:\n\trtnl_set_sk_err(net, RTNLGRP_NSID, err);\n}\n\nstatic int __init net_ns_init(void)\n{\n\tstruct net_generic *ng;\n\n#ifdef CONFIG_NET_NS\n\tnet_cachep = kmem_cache_create(\"net_namespace\", sizeof(struct net),\n\t\t\t\t\tSMP_CACHE_BYTES,\n\t\t\t\t\tSLAB_PANIC, NULL);\n\n\t/* Create workqueue for cleanup */\n\tnetns_wq = create_singlethread_workqueue(\"netns\");\n\tif (!netns_wq)\n\t\tpanic(\"Could not create netns workq\");\n#endif\n\n\tng = net_alloc_generic();\n\tif (!ng)\n\t\tpanic(\"Could not allocate generic netns\");\n\n\trcu_assign_pointer(init_net.gen, ng);\n\n\tmutex_lock(&net_mutex);\n\tif (setup_net(&init_net, &init_user_ns))\n\t\tpanic(\"Could not setup the initial network namespace\");\n\n\tinit_net_initialized = true;\n\n\trtnl_lock();\n\tlist_add_tail_rcu(&init_net.list, &net_namespace_list);\n\trtnl_unlock();\n\n\tmutex_unlock(&net_mutex);\n\n\tregister_pernet_subsys(&net_ns_ops);\n\n\trtnl_register(PF_UNSPEC, RTM_NEWNSID, rtnl_net_newid, NULL,\n\t\t      RTNL_FLAG_DOIT_UNLOCKED);\n\trtnl_register(PF_UNSPEC, RTM_GETNSID, rtnl_net_getid, rtnl_net_dumpid,\n\t\t      RTNL_FLAG_DOIT_UNLOCKED);\n\n\treturn 0;\n}\n\npure_initcall(net_ns_init);\n\n#ifdef CONFIG_NET_NS\nstatic int __register_pernet_operations(struct list_head *list,\n\t\t\t\t\tstruct pernet_operations *ops)\n{\n\tstruct net *net;\n\tint error;\n\tLIST_HEAD(net_exit_list);\n\n\tlist_add_tail(&ops->list, list);\n\tif (ops->init || (ops->id && ops->size)) {\n\t\tfor_each_net(net) {\n\t\t\terror = ops_init(ops, net);\n\t\t\tif (error)\n\t\t\t\tgoto out_undo;\n\t\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\t\t}\n\t}\n\treturn 0;\n\nout_undo:\n\t/* If I have an error cleanup all namespaces I initialized */\n\tlist_del(&ops->list);\n\tops_exit_list(ops, &net_exit_list);\n\tops_free_list(ops, &net_exit_list);\n\treturn error;\n}\n\nstatic void __unregister_pernet_operations(struct pernet_operations *ops)\n{\n\tstruct net *net;\n\tLIST_HEAD(net_exit_list);\n\n\tlist_del(&ops->list);\n\tfor_each_net(net)\n\t\tlist_add_tail(&net->exit_list, &net_exit_list);\n\tops_exit_list(ops, &net_exit_list);\n\tops_free_list(ops, &net_exit_list);\n}\n\n#else\n\nstatic int __register_pernet_operations(struct list_head *list,\n\t\t\t\t\tstruct pernet_operations *ops)\n{\n\tif (!init_net_initialized) {\n\t\tlist_add_tail(&ops->list, list);\n\t\treturn 0;\n\t}\n\n\treturn ops_init(ops, &init_net);\n}\n\nstatic void __unregister_pernet_operations(struct pernet_operations *ops)\n{\n\tif (!init_net_initialized) {\n\t\tlist_del(&ops->list);\n\t} else {\n\t\tLIST_HEAD(net_exit_list);\n\t\tlist_add(&init_net.exit_list, &net_exit_list);\n\t\tops_exit_list(ops, &net_exit_list);\n\t\tops_free_list(ops, &net_exit_list);\n\t}\n}\n\n#endif /* CONFIG_NET_NS */\n\nstatic DEFINE_IDA(net_generic_ids);\n\nstatic int register_pernet_operations(struct list_head *list,\n\t\t\t\t      struct pernet_operations *ops)\n{\n\tint error;\n\n\tif (ops->id) {\nagain:\n\t\terror = ida_get_new_above(&net_generic_ids, MIN_PERNET_OPS_ID, ops->id);\n\t\tif (error < 0) {\n\t\t\tif (error == -EAGAIN) {\n\t\t\t\tida_pre_get(&net_generic_ids, GFP_KERNEL);\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\treturn error;\n\t\t}\n\t\tmax_gen_ptrs = max(max_gen_ptrs, *ops->id + 1);\n\t}\n\terror = __register_pernet_operations(list, ops);\n\tif (error) {\n\t\trcu_barrier();\n\t\tif (ops->id)\n\t\t\tida_remove(&net_generic_ids, *ops->id);\n\t}\n\n\treturn error;\n}\n\nstatic void unregister_pernet_operations(struct pernet_operations *ops)\n{\n\t\n\t__unregister_pernet_operations(ops);\n\trcu_barrier();\n\tif (ops->id)\n\t\tida_remove(&net_generic_ids, *ops->id);\n}\n\n/**\n *      register_pernet_subsys - register a network namespace subsystem\n *\t@ops:  pernet operations structure for the subsystem\n *\n *\tRegister a subsystem which has init and exit functions\n *\tthat are called when network namespaces are created and\n *\tdestroyed respectively.\n *\n *\tWhen registered all network namespace init functions are\n *\tcalled for every existing network namespace.  Allowing kernel\n *\tmodules to have a race free view of the set of network namespaces.\n *\n *\tWhen a new network namespace is created all of the init\n *\tmethods are called in the order in which they were registered.\n *\n *\tWhen a network namespace is destroyed all of the exit methods\n *\tare called in the reverse of the order with which they were\n *\tregistered.\n */\nint register_pernet_subsys(struct pernet_operations *ops)\n{\n\tint error;\n\tmutex_lock(&net_mutex);\n\terror =  register_pernet_operations(first_device, ops);\n\tmutex_unlock(&net_mutex);\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(register_pernet_subsys);\n\n/**\n *      unregister_pernet_subsys - unregister a network namespace subsystem\n *\t@ops: pernet operations structure to manipulate\n *\n *\tRemove the pernet operations structure from the list to be\n *\tused when network namespaces are created or destroyed.  In\n *\taddition run the exit method for all existing network\n *\tnamespaces.\n */\nvoid unregister_pernet_subsys(struct pernet_operations *ops)\n{\n\tmutex_lock(&net_mutex);\n\tunregister_pernet_operations(ops);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL_GPL(unregister_pernet_subsys);\n\n/**\n *      register_pernet_device - register a network namespace device\n *\t@ops:  pernet operations structure for the subsystem\n *\n *\tRegister a device which has init and exit functions\n *\tthat are called when network namespaces are created and\n *\tdestroyed respectively.\n *\n *\tWhen registered all network namespace init functions are\n *\tcalled for every existing network namespace.  Allowing kernel\n *\tmodules to have a race free view of the set of network namespaces.\n *\n *\tWhen a new network namespace is created all of the init\n *\tmethods are called in the order in which they were registered.\n *\n *\tWhen a network namespace is destroyed all of the exit methods\n *\tare called in the reverse of the order with which they were\n *\tregistered.\n */\nint register_pernet_device(struct pernet_operations *ops)\n{\n\tint error;\n\tmutex_lock(&net_mutex);\n\terror = register_pernet_operations(&pernet_list, ops);\n\tif (!error && (first_device == &pernet_list))\n\t\tfirst_device = &ops->list;\n\tmutex_unlock(&net_mutex);\n\treturn error;\n}\nEXPORT_SYMBOL_GPL(register_pernet_device);\n\n/**\n *      unregister_pernet_device - unregister a network namespace netdevice\n *\t@ops: pernet operations structure to manipulate\n *\n *\tRemove the pernet operations structure from the list to be\n *\tused when network namespaces are created or destroyed.  In\n *\taddition run the exit method for all existing network\n *\tnamespaces.\n */\nvoid unregister_pernet_device(struct pernet_operations *ops)\n{\n\tmutex_lock(&net_mutex);\n\tif (&ops->list == first_device)\n\t\tfirst_device = first_device->next;\n\tunregister_pernet_operations(ops);\n\tmutex_unlock(&net_mutex);\n}\nEXPORT_SYMBOL_GPL(unregister_pernet_device);\n\n#ifdef CONFIG_NET_NS\nstatic struct ns_common *netns_get(struct task_struct *task)\n{\n\tstruct net *net = NULL;\n\tstruct nsproxy *nsproxy;\n\n\ttask_lock(task);\n\tnsproxy = task->nsproxy;\n\tif (nsproxy)\n\t\tnet = get_net(nsproxy->net_ns);\n\ttask_unlock(task);\n\n\treturn net ? &net->ns : NULL;\n}\n\nstatic inline struct net *to_net_ns(struct ns_common *ns)\n{\n\treturn container_of(ns, struct net, ns);\n}\n\nstatic void netns_put(struct ns_common *ns)\n{\n\tput_net(to_net_ns(ns));\n}\n\nstatic int netns_install(struct nsproxy *nsproxy, struct ns_common *ns)\n{\n\tstruct net *net = to_net_ns(ns);\n\n\tif (!ns_capable(net->user_ns, CAP_SYS_ADMIN) ||\n\t    !ns_capable(current_user_ns(), CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tput_net(nsproxy->net_ns);\n\tnsproxy->net_ns = get_net(net);\n\treturn 0;\n}\n\nstatic struct user_namespace *netns_owner(struct ns_common *ns)\n{\n\treturn to_net_ns(ns)->user_ns;\n}\n\nconst struct proc_ns_operations netns_operations = {\n\t.name\t\t= \"net\",\n\t.type\t\t= CLONE_NEWNET,\n\t.get\t\t= netns_get,\n\t.put\t\t= netns_put,\n\t.install\t= netns_install,\n\t.owner\t\t= netns_owner,\n};\n#endif\n"], "buggy_code_start_loc": [270], "buggy_code_end_loc": [271], "fixing_code_start_loc": [270], "fixing_code_end_loc": [271], "type": "CWE-362", "message": "A use-after-free vulnerability was found in network namespaces code affecting the Linux kernel before 4.14.11. The function get_net_ns_by_id() in net/core/net_namespace.c does not check for the net::count value after it has found a peer network in netns_ids idr, which could lead to double free and memory corruption. This vulnerability could allow an unprivileged local user to induce kernel memory corruption on the system, leading to a crash. Due to the nature of the flaw, privilege escalation cannot be fully ruled out, although it is thought to be unlikely.", "other": {"cve": {"id": "CVE-2017-15129", "sourceIdentifier": "secalert@redhat.com", "published": "2018-01-09T19:29:00.217", "lastModified": "2023-02-12T23:28:51.460", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "A use-after-free vulnerability was found in network namespaces code affecting the Linux kernel before 4.14.11. The function get_net_ns_by_id() in net/core/net_namespace.c does not check for the net::count value after it has found a peer network in netns_ids idr, which could lead to double free and memory corruption. This vulnerability could allow an unprivileged local user to induce kernel memory corruption on the system, leading to a crash. Due to the nature of the flaw, privilege escalation cannot be fully ruled out, although it is thought to be unlikely."}, {"lang": "es", "value": "Se ha descubierto una vulnerabilidad en los nombres de espacio de red que afecta al kernel de Linux en versiones anteriores a la 4.14.11. La funci\u00f3n get_net_ns_by_id() en net/core/net_namespace.c no verifica el valor net::count una vez que ha encontrado una red peer en el ids netns_ids, lo que podr\u00eda conducir a una doble liberaci\u00f3n (double free) y a una corrupci\u00f3n de memoria. Esta vulnerabilidad podr\u00eda permitir que un usuario local sin privilegios provoque una corrupci\u00f3n de memoria en el sistema, desembocando en un cierre inesperado. Debido a la naturaleza del error, no puede descartarse totalmente el escalado de privilegios, aunque se cree que es improbable."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "secalert@redhat.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "4.14.11", "matchCriteriaId": "A84E4D94-A9A4-424C-8262-0B7B89C8CB6D"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=21b5944350052d2583e82dd59b19a9ba94a007f0", "source": "secalert@redhat.com", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://seclists.org/oss-sec/2018/q1/7", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/102485", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2018:0654", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2018:0676", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2018:1062", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/errata/RHSA-2019:1946", "source": "secalert@redhat.com"}, {"url": "https://access.redhat.com/security/cve/CVE-2017-15129", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1531174", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/21b5944350052d2583e82dd59b19a9ba94a007f0", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://marc.info/?l=linux-netdev&m=151370451121029&w=2", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://marc.info/?t=151370468900001&r=1&w=2", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3617-1/", "source": "secalert@redhat.com"}, {"url": "https://usn.ubuntu.com/3617-2/", "source": "secalert@redhat.com"}, {"url": "https://usn.ubuntu.com/3617-3/", "source": "secalert@redhat.com"}, {"url": "https://usn.ubuntu.com/3619-1/", "source": "secalert@redhat.com"}, {"url": "https://usn.ubuntu.com/3619-2/", "source": "secalert@redhat.com"}, {"url": "https://usn.ubuntu.com/3632-1/", "source": "secalert@redhat.com"}, {"url": "https://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.14.11", "source": "secalert@redhat.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/21b5944350052d2583e82dd59b19a9ba94a007f0"}}