{"buggy_code": ["/******************************************************************************\n * Xen balloon driver - enables returning/claiming memory to/from Xen.\n *\n * Copyright (c) 2003, B Dragovic\n * Copyright (c) 2003-2004, M Williamson, K Fraser\n * Copyright (c) 2005 Dan M. Smith, IBM Corporation\n * Copyright (c) 2010 Daniel Kiper\n *\n * Memory hotplug support was written by Daniel Kiper. Work on\n * it was sponsored by Google under Google Summer of Code 2010\n * program. Jeremy Fitzhardinge from Citrix was the mentor for\n * this project.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License version 2\n * as published by the Free Software Foundation; or, when distributed\n * separately from the Linux kernel or incorporated into other\n * software packages, subject to the following license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/cpu.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/cred.h>\n#include <linux/errno.h>\n#include <linux/mm.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/gfp.h>\n#include <linux/notifier.h>\n#include <linux/memory.h>\n#include <linux/memory_hotplug.h>\n#include <linux/percpu-defs.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n\n#include <asm/page.h>\n#include <asm/pgalloc.h>\n#include <asm/pgtable.h>\n#include <asm/tlb.h>\n\n#include <asm/xen/hypervisor.h>\n#include <asm/xen/hypercall.h>\n\n#include <xen/xen.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/memory.h>\n#include <xen/balloon.h>\n#include <xen/features.h>\n#include <xen/page.h>\n#include <xen/mem-reservation.h>\n\nstatic int xen_hotplug_unpopulated;\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\n\nstatic int zero;\nstatic int one = 1;\n\nstatic struct ctl_table balloon_table[] = {\n\t{\n\t\t.procname\t= \"hotplug_unpopulated\",\n\t\t.data\t\t= &xen_hotplug_unpopulated,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1         = &zero,\n\t\t.extra2         = &one,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table balloon_root[] = {\n\t{\n\t\t.procname\t= \"balloon\",\n\t\t.mode\t\t= 0555,\n\t\t.child\t\t= balloon_table,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table xen_root[] = {\n\t{\n\t\t.procname\t= \"xen\",\n\t\t.mode\t\t= 0555,\n\t\t.child\t\t= balloon_root,\n\t},\n\t{ }\n};\n\n#endif\n\n/*\n * Use one extent per PAGE_SIZE to avoid to break down the page into\n * multiple frame.\n */\n#define EXTENT_ORDER (fls(XEN_PFN_PER_PAGE) - 1)\n\n/*\n * balloon_process() state:\n *\n * BP_DONE: done or nothing to do,\n * BP_WAIT: wait to be rescheduled,\n * BP_EAGAIN: error, go to sleep,\n * BP_ECANCELED: error, balloon operation canceled.\n */\n\nenum bp_state {\n\tBP_DONE,\n\tBP_WAIT,\n\tBP_EAGAIN,\n\tBP_ECANCELED\n};\n\n\nstatic DEFINE_MUTEX(balloon_mutex);\n\nstruct balloon_stats balloon_stats;\nEXPORT_SYMBOL_GPL(balloon_stats);\n\n/* We increase/decrease in batches which fit in a page */\nstatic xen_pfn_t frame_list[PAGE_SIZE / sizeof(xen_pfn_t)];\n\n\n/* List of ballooned pages, threaded through the mem_map array. */\nstatic LIST_HEAD(ballooned_pages);\nstatic DECLARE_WAIT_QUEUE_HEAD(balloon_wq);\n\n/* Main work function, always executed in process context. */\nstatic void balloon_process(struct work_struct *work);\nstatic DECLARE_DELAYED_WORK(balloon_worker, balloon_process);\n\n/* When ballooning out (allocating memory to return to Xen) we don't really\n   want the kernel to try too hard since that can trigger the oom killer. */\n#define GFP_BALLOON \\\n\t(GFP_HIGHUSER | __GFP_NOWARN | __GFP_NORETRY | __GFP_NOMEMALLOC)\n\n/* balloon_append: add the given page to the balloon. */\nstatic void __balloon_append(struct page *page)\n{\n\t/* Lowmem is re-populated first, so highmem pages go at list tail. */\n\tif (PageHighMem(page)) {\n\t\tlist_add_tail(&page->lru, &ballooned_pages);\n\t\tballoon_stats.balloon_high++;\n\t} else {\n\t\tlist_add(&page->lru, &ballooned_pages);\n\t\tballoon_stats.balloon_low++;\n\t}\n\twake_up(&balloon_wq);\n}\n\nstatic void balloon_append(struct page *page)\n{\n\t__balloon_append(page);\n}\n\n/* balloon_retrieve: rescue a page from the balloon, if it is not empty. */\nstatic struct page *balloon_retrieve(bool require_lowmem)\n{\n\tstruct page *page;\n\n\tif (list_empty(&ballooned_pages))\n\t\treturn NULL;\n\n\tpage = list_entry(ballooned_pages.next, struct page, lru);\n\tif (require_lowmem && PageHighMem(page))\n\t\treturn NULL;\n\tlist_del(&page->lru);\n\n\tif (PageHighMem(page))\n\t\tballoon_stats.balloon_high--;\n\telse\n\t\tballoon_stats.balloon_low--;\n\n\treturn page;\n}\n\nstatic struct page *balloon_next_page(struct page *page)\n{\n\tstruct list_head *next = page->lru.next;\n\tif (next == &ballooned_pages)\n\t\treturn NULL;\n\treturn list_entry(next, struct page, lru);\n}\n\nstatic enum bp_state update_schedule(enum bp_state state)\n{\n\tif (state == BP_WAIT)\n\t\treturn BP_WAIT;\n\n\tif (state == BP_ECANCELED)\n\t\treturn BP_ECANCELED;\n\n\tif (state == BP_DONE) {\n\t\tballoon_stats.schedule_delay = 1;\n\t\tballoon_stats.retry_count = 1;\n\t\treturn BP_DONE;\n\t}\n\n\t++balloon_stats.retry_count;\n\n\tif (balloon_stats.max_retry_count != RETRY_UNLIMITED &&\n\t\t\tballoon_stats.retry_count > balloon_stats.max_retry_count) {\n\t\tballoon_stats.schedule_delay = 1;\n\t\tballoon_stats.retry_count = 1;\n\t\treturn BP_ECANCELED;\n\t}\n\n\tballoon_stats.schedule_delay <<= 1;\n\n\tif (balloon_stats.schedule_delay > balloon_stats.max_schedule_delay)\n\t\tballoon_stats.schedule_delay = balloon_stats.max_schedule_delay;\n\n\treturn BP_EAGAIN;\n}\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\nstatic void release_memory_resource(struct resource *resource)\n{\n\tif (!resource)\n\t\treturn;\n\n\t/*\n\t * No need to reset region to identity mapped since we now\n\t * know that no I/O can be in this region\n\t */\n\trelease_resource(resource);\n\tkfree(resource);\n}\n\nstatic struct resource *additional_memory_resource(phys_addr_t size)\n{\n\tstruct resource *res;\n\tint ret;\n\n\tres = kzalloc(sizeof(*res), GFP_KERNEL);\n\tif (!res)\n\t\treturn NULL;\n\n\tres->name = \"System RAM\";\n\tres->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;\n\n\tret = allocate_resource(&iomem_resource, res,\n\t\t\t\tsize, 0, -1,\n\t\t\t\tPAGES_PER_SECTION * PAGE_SIZE, NULL, NULL);\n\tif (ret < 0) {\n\t\tpr_err(\"Cannot allocate new System RAM resource\\n\");\n\t\tkfree(res);\n\t\treturn NULL;\n\t}\n\n#ifdef CONFIG_SPARSEMEM\n\t{\n\t\tunsigned long limit = 1UL << (MAX_PHYSMEM_BITS - PAGE_SHIFT);\n\t\tunsigned long pfn = res->start >> PAGE_SHIFT;\n\n\t\tif (pfn > limit) {\n\t\t\tpr_err(\"New System RAM resource outside addressable RAM (%lu > %lu)\\n\",\n\t\t\t       pfn, limit);\n\t\t\trelease_memory_resource(res);\n\t\t\treturn NULL;\n\t\t}\n\t}\n#endif\n\n\treturn res;\n}\n\nstatic enum bp_state reserve_additional_memory(void)\n{\n\tlong credit;\n\tstruct resource *resource;\n\tint nid, rc;\n\tunsigned long balloon_hotplug;\n\n\tcredit = balloon_stats.target_pages + balloon_stats.target_unpopulated\n\t\t- balloon_stats.total_pages;\n\n\t/*\n\t * Already hotplugged enough pages?  Wait for them to be\n\t * onlined.\n\t */\n\tif (credit <= 0)\n\t\treturn BP_WAIT;\n\n\tballoon_hotplug = round_up(credit, PAGES_PER_SECTION);\n\n\tresource = additional_memory_resource(balloon_hotplug * PAGE_SIZE);\n\tif (!resource)\n\t\tgoto err;\n\n\tnid = memory_add_physaddr_to_nid(resource->start);\n\n#ifdef CONFIG_XEN_HAVE_PVMMU\n\t/*\n\t * We don't support PV MMU when Linux and Xen is using\n\t * different page granularity.\n\t */\n\tBUILD_BUG_ON(XEN_PAGE_SIZE != PAGE_SIZE);\n\n        /*\n         * add_memory() will build page tables for the new memory so\n         * the p2m must contain invalid entries so the correct\n         * non-present PTEs will be written.\n         *\n         * If a failure occurs, the original (identity) p2m entries\n         * are not restored since this region is now known not to\n         * conflict with any devices.\n         */ \n\tif (!xen_feature(XENFEAT_auto_translated_physmap)) {\n\t\tunsigned long pfn, i;\n\n\t\tpfn = PFN_DOWN(resource->start);\n\t\tfor (i = 0; i < balloon_hotplug; i++) {\n\t\t\tif (!set_phys_to_machine(pfn + i, INVALID_P2M_ENTRY)) {\n\t\t\t\tpr_warn(\"set_phys_to_machine() failed, no memory added\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n                }\n\t}\n#endif\n\n\t/*\n\t * add_memory_resource() will call online_pages() which in its turn\n\t * will call xen_online_page() callback causing deadlock if we don't\n\t * release balloon_mutex here. Unlocking here is safe because the\n\t * callers drop the mutex before trying again.\n\t */\n\tmutex_unlock(&balloon_mutex);\n\t/* add_memory_resource() requires the device_hotplug lock */\n\tlock_device_hotplug();\n\trc = add_memory_resource(nid, resource);\n\tunlock_device_hotplug();\n\tmutex_lock(&balloon_mutex);\n\n\tif (rc) {\n\t\tpr_warn(\"Cannot add additional memory (%i)\\n\", rc);\n\t\tgoto err;\n\t}\n\n\tballoon_stats.total_pages += balloon_hotplug;\n\n\treturn BP_WAIT;\n  err:\n\trelease_memory_resource(resource);\n\treturn BP_ECANCELED;\n}\n\nstatic void xen_online_page(struct page *page, unsigned int order)\n{\n\tunsigned long i, size = (1 << order);\n\tunsigned long start_pfn = page_to_pfn(page);\n\tstruct page *p;\n\n\tpr_debug(\"Online %lu pages starting at pfn 0x%lx\\n\", size, start_pfn);\n\tmutex_lock(&balloon_mutex);\n\tfor (i = 0; i < size; i++) {\n\t\tp = pfn_to_page(start_pfn + i);\n\t\t__online_page_set_limits(p);\n\t\t__SetPageOffline(p);\n\t\t__balloon_append(p);\n\t}\n\tmutex_unlock(&balloon_mutex);\n}\n\nstatic int xen_memory_notifier(struct notifier_block *nb, unsigned long val, void *v)\n{\n\tif (val == MEM_ONLINE)\n\t\tschedule_delayed_work(&balloon_worker, 0);\n\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block xen_memory_nb = {\n\t.notifier_call = xen_memory_notifier,\n\t.priority = 0\n};\n#else\nstatic enum bp_state reserve_additional_memory(void)\n{\n\tballoon_stats.target_pages = balloon_stats.current_pages;\n\treturn BP_ECANCELED;\n}\n#endif /* CONFIG_XEN_BALLOON_MEMORY_HOTPLUG */\n\nstatic long current_credit(void)\n{\n\treturn balloon_stats.target_pages - balloon_stats.current_pages;\n}\n\nstatic bool balloon_is_inflated(void)\n{\n\treturn balloon_stats.balloon_low || balloon_stats.balloon_high;\n}\n\nstatic enum bp_state increase_reservation(unsigned long nr_pages)\n{\n\tint rc;\n\tunsigned long i;\n\tstruct page   *page;\n\n\tif (nr_pages > ARRAY_SIZE(frame_list))\n\t\tnr_pages = ARRAY_SIZE(frame_list);\n\n\tpage = list_first_entry_or_null(&ballooned_pages, struct page, lru);\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (!page) {\n\t\t\tnr_pages = i;\n\t\t\tbreak;\n\t\t}\n\n\t\tframe_list[i] = page_to_xen_pfn(page);\n\t\tpage = balloon_next_page(page);\n\t}\n\n\trc = xenmem_reservation_increase(nr_pages, frame_list);\n\tif (rc <= 0)\n\t\treturn BP_EAGAIN;\n\n\tfor (i = 0; i < rc; i++) {\n\t\tpage = balloon_retrieve(false);\n\t\tBUG_ON(page == NULL);\n\n\t\txenmem_reservation_va_mapping_update(1, &page, &frame_list[i]);\n\n\t\t/* Relinquish the page back to the allocator. */\n\t\t__ClearPageOffline(page);\n\t\tfree_reserved_page(page);\n\t}\n\n\tballoon_stats.current_pages += rc;\n\n\treturn BP_DONE;\n}\n\nstatic enum bp_state decrease_reservation(unsigned long nr_pages, gfp_t gfp)\n{\n\tenum bp_state state = BP_DONE;\n\tunsigned long i;\n\tstruct page *page, *tmp;\n\tint ret;\n\tLIST_HEAD(pages);\n\n\tif (nr_pages > ARRAY_SIZE(frame_list))\n\t\tnr_pages = ARRAY_SIZE(frame_list);\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tpage = alloc_page(gfp);\n\t\tif (page == NULL) {\n\t\t\tnr_pages = i;\n\t\t\tstate = BP_EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\t__SetPageOffline(page);\n\t\tadjust_managed_page_count(page, -1);\n\t\txenmem_reservation_scrub_page(page);\n\t\tlist_add(&page->lru, &pages);\n\t}\n\n\t/*\n\t * Ensure that ballooned highmem pages don't have kmaps.\n\t *\n\t * Do this before changing the p2m as kmap_flush_unused()\n\t * reads PTEs to obtain pages (and hence needs the original\n\t * p2m entry).\n\t */\n\tkmap_flush_unused();\n\n\t/*\n\t * Setup the frame, update direct mapping, invalidate P2M,\n\t * and add to balloon.\n\t */\n\ti = 0;\n\tlist_for_each_entry_safe(page, tmp, &pages, lru) {\n\t\tframe_list[i++] = xen_page_to_gfn(page);\n\n\t\txenmem_reservation_va_mapping_reset(1, &page);\n\n\t\tlist_del(&page->lru);\n\n\t\tballoon_append(page);\n\t}\n\n\tflush_tlb_all();\n\n\tret = xenmem_reservation_decrease(nr_pages, frame_list);\n\tBUG_ON(ret != nr_pages);\n\n\tballoon_stats.current_pages -= nr_pages;\n\n\treturn state;\n}\n\n/*\n * As this is a work item it is guaranteed to run as a single instance only.\n * We may of course race updates of the target counts (which are protected\n * by the balloon lock), or with changes to the Xen hard limit, but we will\n * recover from these in time.\n */\nstatic void balloon_process(struct work_struct *work)\n{\n\tenum bp_state state = BP_DONE;\n\tlong credit;\n\n\n\tdo {\n\t\tmutex_lock(&balloon_mutex);\n\n\t\tcredit = current_credit();\n\n\t\tif (credit > 0) {\n\t\t\tif (balloon_is_inflated())\n\t\t\t\tstate = increase_reservation(credit);\n\t\t\telse\n\t\t\t\tstate = reserve_additional_memory();\n\t\t}\n\n\t\tif (credit < 0)\n\t\t\tstate = decrease_reservation(-credit, GFP_BALLOON);\n\n\t\tstate = update_schedule(state);\n\n\t\tmutex_unlock(&balloon_mutex);\n\n\t\tcond_resched();\n\n\t} while (credit && state == BP_DONE);\n\n\t/* Schedule more work if there is some still to be done. */\n\tif (state == BP_EAGAIN)\n\t\tschedule_delayed_work(&balloon_worker, balloon_stats.schedule_delay * HZ);\n}\n\n/* Resets the Xen limit, sets new target, and kicks off processing. */\nvoid balloon_set_new_target(unsigned long target)\n{\n\t/* No need for lock. Not read-modify-write updates. */\n\tballoon_stats.target_pages = target;\n\tschedule_delayed_work(&balloon_worker, 0);\n}\nEXPORT_SYMBOL_GPL(balloon_set_new_target);\n\nstatic int add_ballooned_pages(int nr_pages)\n{\n\tenum bp_state st;\n\n\tif (xen_hotplug_unpopulated) {\n\t\tst = reserve_additional_memory();\n\t\tif (st != BP_ECANCELED) {\n\t\t\tmutex_unlock(&balloon_mutex);\n\t\t\twait_event(balloon_wq,\n\t\t\t\t   !list_empty(&ballooned_pages));\n\t\t\tmutex_lock(&balloon_mutex);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tst = decrease_reservation(nr_pages, GFP_USER);\n\tif (st != BP_DONE)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * alloc_xenballooned_pages - get pages that have been ballooned out\n * @nr_pages: Number of pages to get\n * @pages: pages returned\n * @return 0 on success, error otherwise\n */\nint alloc_xenballooned_pages(int nr_pages, struct page **pages)\n{\n\tint pgno = 0;\n\tstruct page *page;\n\tint ret;\n\n\tmutex_lock(&balloon_mutex);\n\n\tballoon_stats.target_unpopulated += nr_pages;\n\n\twhile (pgno < nr_pages) {\n\t\tpage = balloon_retrieve(true);\n\t\tif (page) {\n\t\t\t__ClearPageOffline(page);\n\t\t\tpages[pgno++] = page;\n#ifdef CONFIG_XEN_HAVE_PVMMU\n\t\t\t/*\n\t\t\t * We don't support PV MMU when Linux and Xen is using\n\t\t\t * different page granularity.\n\t\t\t */\n\t\t\tBUILD_BUG_ON(XEN_PAGE_SIZE != PAGE_SIZE);\n\n\t\t\tif (!xen_feature(XENFEAT_auto_translated_physmap)) {\n\t\t\t\tret = xen_alloc_p2m_entry(page_to_pfn(page));\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tgoto out_undo;\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\tret = add_ballooned_pages(nr_pages - pgno);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_undo;\n\t\t}\n\t}\n\tmutex_unlock(&balloon_mutex);\n\treturn 0;\n out_undo:\n\tmutex_unlock(&balloon_mutex);\n\tfree_xenballooned_pages(pgno, pages);\n\treturn ret;\n}\nEXPORT_SYMBOL(alloc_xenballooned_pages);\n\n/**\n * free_xenballooned_pages - return pages retrieved with get_ballooned_pages\n * @nr_pages: Number of pages\n * @pages: pages to return\n */\nvoid free_xenballooned_pages(int nr_pages, struct page **pages)\n{\n\tint i;\n\n\tmutex_lock(&balloon_mutex);\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (pages[i]) {\n\t\t\t__SetPageOffline(pages[i]);\n\t\t\tballoon_append(pages[i]);\n\t\t}\n\t}\n\n\tballoon_stats.target_unpopulated -= nr_pages;\n\n\t/* The balloon may be too large now. Shrink it if needed. */\n\tif (current_credit())\n\t\tschedule_delayed_work(&balloon_worker, 0);\n\n\tmutex_unlock(&balloon_mutex);\n}\nEXPORT_SYMBOL(free_xenballooned_pages);\n\n#ifdef CONFIG_XEN_PV\nstatic void __init balloon_add_region(unsigned long start_pfn,\n\t\t\t\t      unsigned long pages)\n{\n\tunsigned long pfn, extra_pfn_end;\n\tstruct page *page;\n\n\t/*\n\t * If the amount of usable memory has been limited (e.g., with\n\t * the 'mem' command line parameter), don't add pages beyond\n\t * this limit.\n\t */\n\textra_pfn_end = min(max_pfn, start_pfn + pages);\n\n\tfor (pfn = start_pfn; pfn < extra_pfn_end; pfn++) {\n\t\tpage = pfn_to_page(pfn);\n\t\t/* totalram_pages and totalhigh_pages do not\n\t\t   include the boot-time balloon extension, so\n\t\t   don't subtract from it. */\n\t\t__balloon_append(page);\n\t}\n\n\tballoon_stats.total_pages += extra_pfn_end - start_pfn;\n}\n#endif\n\nstatic int __init balloon_init(void)\n{\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\tpr_info(\"Initialising balloon driver\\n\");\n\n#ifdef CONFIG_XEN_PV\n\tballoon_stats.current_pages = xen_pv_domain()\n\t\t? min(xen_start_info->nr_pages - xen_released_pages, max_pfn)\n\t\t: get_num_physpages();\n#else\n\tballoon_stats.current_pages = get_num_physpages();\n#endif\n\tballoon_stats.target_pages  = balloon_stats.current_pages;\n\tballoon_stats.balloon_low   = 0;\n\tballoon_stats.balloon_high  = 0;\n\tballoon_stats.total_pages   = balloon_stats.current_pages;\n\n\tballoon_stats.schedule_delay = 1;\n\tballoon_stats.max_schedule_delay = 32;\n\tballoon_stats.retry_count = 1;\n\tballoon_stats.max_retry_count = RETRY_UNLIMITED;\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\n\tset_online_page_callback(&xen_online_page);\n\tregister_memory_notifier(&xen_memory_nb);\n\tregister_sysctl_table(xen_root);\n#endif\n\n#ifdef CONFIG_XEN_PV\n\t{\n\t\tint i;\n\n\t\t/*\n\t\t * Initialize the balloon with pages from the extra memory\n\t\t * regions (see arch/x86/xen/setup.c).\n\t\t */\n\t\tfor (i = 0; i < XEN_EXTRA_MEM_MAX_REGIONS; i++)\n\t\t\tif (xen_extra_mem[i].n_pfns)\n\t\t\t\tballoon_add_region(xen_extra_mem[i].start_pfn,\n\t\t\t\t\t\t   xen_extra_mem[i].n_pfns);\n\t}\n#endif\n\n\t/* Init the xen-balloon driver. */\n\txen_balloon_init();\n\n\treturn 0;\n}\nsubsys_initcall(balloon_init);\n"], "fixing_code": ["/******************************************************************************\n * Xen balloon driver - enables returning/claiming memory to/from Xen.\n *\n * Copyright (c) 2003, B Dragovic\n * Copyright (c) 2003-2004, M Williamson, K Fraser\n * Copyright (c) 2005 Dan M. Smith, IBM Corporation\n * Copyright (c) 2010 Daniel Kiper\n *\n * Memory hotplug support was written by Daniel Kiper. Work on\n * it was sponsored by Google under Google Summer of Code 2010\n * program. Jeremy Fitzhardinge from Citrix was the mentor for\n * this project.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License version 2\n * as published by the Free Software Foundation; or, when distributed\n * separately from the Linux kernel or incorporated into other\n * software packages, subject to the following license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/cpu.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/cred.h>\n#include <linux/errno.h>\n#include <linux/mm.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/gfp.h>\n#include <linux/notifier.h>\n#include <linux/memory.h>\n#include <linux/memory_hotplug.h>\n#include <linux/percpu-defs.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n\n#include <asm/page.h>\n#include <asm/pgalloc.h>\n#include <asm/pgtable.h>\n#include <asm/tlb.h>\n\n#include <asm/xen/hypervisor.h>\n#include <asm/xen/hypercall.h>\n\n#include <xen/xen.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/memory.h>\n#include <xen/balloon.h>\n#include <xen/features.h>\n#include <xen/page.h>\n#include <xen/mem-reservation.h>\n\nstatic int xen_hotplug_unpopulated;\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\n\nstatic int zero;\nstatic int one = 1;\n\nstatic struct ctl_table balloon_table[] = {\n\t{\n\t\t.procname\t= \"hotplug_unpopulated\",\n\t\t.data\t\t= &xen_hotplug_unpopulated,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1         = &zero,\n\t\t.extra2         = &one,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table balloon_root[] = {\n\t{\n\t\t.procname\t= \"balloon\",\n\t\t.mode\t\t= 0555,\n\t\t.child\t\t= balloon_table,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table xen_root[] = {\n\t{\n\t\t.procname\t= \"xen\",\n\t\t.mode\t\t= 0555,\n\t\t.child\t\t= balloon_root,\n\t},\n\t{ }\n};\n\n#endif\n\n/*\n * Use one extent per PAGE_SIZE to avoid to break down the page into\n * multiple frame.\n */\n#define EXTENT_ORDER (fls(XEN_PFN_PER_PAGE) - 1)\n\n/*\n * balloon_process() state:\n *\n * BP_DONE: done or nothing to do,\n * BP_WAIT: wait to be rescheduled,\n * BP_EAGAIN: error, go to sleep,\n * BP_ECANCELED: error, balloon operation canceled.\n */\n\nenum bp_state {\n\tBP_DONE,\n\tBP_WAIT,\n\tBP_EAGAIN,\n\tBP_ECANCELED\n};\n\n\nstatic DEFINE_MUTEX(balloon_mutex);\n\nstruct balloon_stats balloon_stats;\nEXPORT_SYMBOL_GPL(balloon_stats);\n\n/* We increase/decrease in batches which fit in a page */\nstatic xen_pfn_t frame_list[PAGE_SIZE / sizeof(xen_pfn_t)];\n\n\n/* List of ballooned pages, threaded through the mem_map array. */\nstatic LIST_HEAD(ballooned_pages);\nstatic DECLARE_WAIT_QUEUE_HEAD(balloon_wq);\n\n/* Main work function, always executed in process context. */\nstatic void balloon_process(struct work_struct *work);\nstatic DECLARE_DELAYED_WORK(balloon_worker, balloon_process);\n\n/* When ballooning out (allocating memory to return to Xen) we don't really\n   want the kernel to try too hard since that can trigger the oom killer. */\n#define GFP_BALLOON \\\n\t(GFP_HIGHUSER | __GFP_NOWARN | __GFP_NORETRY | __GFP_NOMEMALLOC)\n\n/* balloon_append: add the given page to the balloon. */\nstatic void __balloon_append(struct page *page)\n{\n\t/* Lowmem is re-populated first, so highmem pages go at list tail. */\n\tif (PageHighMem(page)) {\n\t\tlist_add_tail(&page->lru, &ballooned_pages);\n\t\tballoon_stats.balloon_high++;\n\t} else {\n\t\tlist_add(&page->lru, &ballooned_pages);\n\t\tballoon_stats.balloon_low++;\n\t}\n\twake_up(&balloon_wq);\n}\n\nstatic void balloon_append(struct page *page)\n{\n\t__balloon_append(page);\n}\n\n/* balloon_retrieve: rescue a page from the balloon, if it is not empty. */\nstatic struct page *balloon_retrieve(bool require_lowmem)\n{\n\tstruct page *page;\n\n\tif (list_empty(&ballooned_pages))\n\t\treturn NULL;\n\n\tpage = list_entry(ballooned_pages.next, struct page, lru);\n\tif (require_lowmem && PageHighMem(page))\n\t\treturn NULL;\n\tlist_del(&page->lru);\n\n\tif (PageHighMem(page))\n\t\tballoon_stats.balloon_high--;\n\telse\n\t\tballoon_stats.balloon_low--;\n\n\treturn page;\n}\n\nstatic struct page *balloon_next_page(struct page *page)\n{\n\tstruct list_head *next = page->lru.next;\n\tif (next == &ballooned_pages)\n\t\treturn NULL;\n\treturn list_entry(next, struct page, lru);\n}\n\nstatic enum bp_state update_schedule(enum bp_state state)\n{\n\tif (state == BP_WAIT)\n\t\treturn BP_WAIT;\n\n\tif (state == BP_ECANCELED)\n\t\treturn BP_ECANCELED;\n\n\tif (state == BP_DONE) {\n\t\tballoon_stats.schedule_delay = 1;\n\t\tballoon_stats.retry_count = 1;\n\t\treturn BP_DONE;\n\t}\n\n\t++balloon_stats.retry_count;\n\n\tif (balloon_stats.max_retry_count != RETRY_UNLIMITED &&\n\t\t\tballoon_stats.retry_count > balloon_stats.max_retry_count) {\n\t\tballoon_stats.schedule_delay = 1;\n\t\tballoon_stats.retry_count = 1;\n\t\treturn BP_ECANCELED;\n\t}\n\n\tballoon_stats.schedule_delay <<= 1;\n\n\tif (balloon_stats.schedule_delay > balloon_stats.max_schedule_delay)\n\t\tballoon_stats.schedule_delay = balloon_stats.max_schedule_delay;\n\n\treturn BP_EAGAIN;\n}\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\nstatic void release_memory_resource(struct resource *resource)\n{\n\tif (!resource)\n\t\treturn;\n\n\t/*\n\t * No need to reset region to identity mapped since we now\n\t * know that no I/O can be in this region\n\t */\n\trelease_resource(resource);\n\tkfree(resource);\n}\n\nstatic struct resource *additional_memory_resource(phys_addr_t size)\n{\n\tstruct resource *res;\n\tint ret;\n\n\tres = kzalloc(sizeof(*res), GFP_KERNEL);\n\tif (!res)\n\t\treturn NULL;\n\n\tres->name = \"System RAM\";\n\tres->flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;\n\n\tret = allocate_resource(&iomem_resource, res,\n\t\t\t\tsize, 0, -1,\n\t\t\t\tPAGES_PER_SECTION * PAGE_SIZE, NULL, NULL);\n\tif (ret < 0) {\n\t\tpr_err(\"Cannot allocate new System RAM resource\\n\");\n\t\tkfree(res);\n\t\treturn NULL;\n\t}\n\n#ifdef CONFIG_SPARSEMEM\n\t{\n\t\tunsigned long limit = 1UL << (MAX_PHYSMEM_BITS - PAGE_SHIFT);\n\t\tunsigned long pfn = res->start >> PAGE_SHIFT;\n\n\t\tif (pfn > limit) {\n\t\t\tpr_err(\"New System RAM resource outside addressable RAM (%lu > %lu)\\n\",\n\t\t\t       pfn, limit);\n\t\t\trelease_memory_resource(res);\n\t\t\treturn NULL;\n\t\t}\n\t}\n#endif\n\n\treturn res;\n}\n\nstatic enum bp_state reserve_additional_memory(void)\n{\n\tlong credit;\n\tstruct resource *resource;\n\tint nid, rc;\n\tunsigned long balloon_hotplug;\n\n\tcredit = balloon_stats.target_pages + balloon_stats.target_unpopulated\n\t\t- balloon_stats.total_pages;\n\n\t/*\n\t * Already hotplugged enough pages?  Wait for them to be\n\t * onlined.\n\t */\n\tif (credit <= 0)\n\t\treturn BP_WAIT;\n\n\tballoon_hotplug = round_up(credit, PAGES_PER_SECTION);\n\n\tresource = additional_memory_resource(balloon_hotplug * PAGE_SIZE);\n\tif (!resource)\n\t\tgoto err;\n\n\tnid = memory_add_physaddr_to_nid(resource->start);\n\n#ifdef CONFIG_XEN_HAVE_PVMMU\n\t/*\n\t * We don't support PV MMU when Linux and Xen is using\n\t * different page granularity.\n\t */\n\tBUILD_BUG_ON(XEN_PAGE_SIZE != PAGE_SIZE);\n\n        /*\n         * add_memory() will build page tables for the new memory so\n         * the p2m must contain invalid entries so the correct\n         * non-present PTEs will be written.\n         *\n         * If a failure occurs, the original (identity) p2m entries\n         * are not restored since this region is now known not to\n         * conflict with any devices.\n         */ \n\tif (!xen_feature(XENFEAT_auto_translated_physmap)) {\n\t\tunsigned long pfn, i;\n\n\t\tpfn = PFN_DOWN(resource->start);\n\t\tfor (i = 0; i < balloon_hotplug; i++) {\n\t\t\tif (!set_phys_to_machine(pfn + i, INVALID_P2M_ENTRY)) {\n\t\t\t\tpr_warn(\"set_phys_to_machine() failed, no memory added\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n                }\n\t}\n#endif\n\n\t/*\n\t * add_memory_resource() will call online_pages() which in its turn\n\t * will call xen_online_page() callback causing deadlock if we don't\n\t * release balloon_mutex here. Unlocking here is safe because the\n\t * callers drop the mutex before trying again.\n\t */\n\tmutex_unlock(&balloon_mutex);\n\t/* add_memory_resource() requires the device_hotplug lock */\n\tlock_device_hotplug();\n\trc = add_memory_resource(nid, resource);\n\tunlock_device_hotplug();\n\tmutex_lock(&balloon_mutex);\n\n\tif (rc) {\n\t\tpr_warn(\"Cannot add additional memory (%i)\\n\", rc);\n\t\tgoto err;\n\t}\n\n\tballoon_stats.total_pages += balloon_hotplug;\n\n\treturn BP_WAIT;\n  err:\n\trelease_memory_resource(resource);\n\treturn BP_ECANCELED;\n}\n\nstatic void xen_online_page(struct page *page, unsigned int order)\n{\n\tunsigned long i, size = (1 << order);\n\tunsigned long start_pfn = page_to_pfn(page);\n\tstruct page *p;\n\n\tpr_debug(\"Online %lu pages starting at pfn 0x%lx\\n\", size, start_pfn);\n\tmutex_lock(&balloon_mutex);\n\tfor (i = 0; i < size; i++) {\n\t\tp = pfn_to_page(start_pfn + i);\n\t\t__online_page_set_limits(p);\n\t\t__SetPageOffline(p);\n\t\t__balloon_append(p);\n\t}\n\tmutex_unlock(&balloon_mutex);\n}\n\nstatic int xen_memory_notifier(struct notifier_block *nb, unsigned long val, void *v)\n{\n\tif (val == MEM_ONLINE)\n\t\tschedule_delayed_work(&balloon_worker, 0);\n\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block xen_memory_nb = {\n\t.notifier_call = xen_memory_notifier,\n\t.priority = 0\n};\n#else\nstatic enum bp_state reserve_additional_memory(void)\n{\n\tballoon_stats.target_pages = balloon_stats.current_pages;\n\treturn BP_ECANCELED;\n}\n#endif /* CONFIG_XEN_BALLOON_MEMORY_HOTPLUG */\n\nstatic long current_credit(void)\n{\n\treturn balloon_stats.target_pages - balloon_stats.current_pages;\n}\n\nstatic bool balloon_is_inflated(void)\n{\n\treturn balloon_stats.balloon_low || balloon_stats.balloon_high;\n}\n\nstatic enum bp_state increase_reservation(unsigned long nr_pages)\n{\n\tint rc;\n\tunsigned long i;\n\tstruct page   *page;\n\n\tif (nr_pages > ARRAY_SIZE(frame_list))\n\t\tnr_pages = ARRAY_SIZE(frame_list);\n\n\tpage = list_first_entry_or_null(&ballooned_pages, struct page, lru);\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (!page) {\n\t\t\tnr_pages = i;\n\t\t\tbreak;\n\t\t}\n\n\t\tframe_list[i] = page_to_xen_pfn(page);\n\t\tpage = balloon_next_page(page);\n\t}\n\n\trc = xenmem_reservation_increase(nr_pages, frame_list);\n\tif (rc <= 0)\n\t\treturn BP_EAGAIN;\n\n\tfor (i = 0; i < rc; i++) {\n\t\tpage = balloon_retrieve(false);\n\t\tBUG_ON(page == NULL);\n\n\t\txenmem_reservation_va_mapping_update(1, &page, &frame_list[i]);\n\n\t\t/* Relinquish the page back to the allocator. */\n\t\t__ClearPageOffline(page);\n\t\tfree_reserved_page(page);\n\t}\n\n\tballoon_stats.current_pages += rc;\n\n\treturn BP_DONE;\n}\n\nstatic enum bp_state decrease_reservation(unsigned long nr_pages, gfp_t gfp)\n{\n\tenum bp_state state = BP_DONE;\n\tunsigned long i;\n\tstruct page *page, *tmp;\n\tint ret;\n\tLIST_HEAD(pages);\n\n\tif (nr_pages > ARRAY_SIZE(frame_list))\n\t\tnr_pages = ARRAY_SIZE(frame_list);\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tpage = alloc_page(gfp);\n\t\tif (page == NULL) {\n\t\t\tnr_pages = i;\n\t\t\tstate = BP_EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\t__SetPageOffline(page);\n\t\tadjust_managed_page_count(page, -1);\n\t\txenmem_reservation_scrub_page(page);\n\t\tlist_add(&page->lru, &pages);\n\t}\n\n\t/*\n\t * Ensure that ballooned highmem pages don't have kmaps.\n\t *\n\t * Do this before changing the p2m as kmap_flush_unused()\n\t * reads PTEs to obtain pages (and hence needs the original\n\t * p2m entry).\n\t */\n\tkmap_flush_unused();\n\n\t/*\n\t * Setup the frame, update direct mapping, invalidate P2M,\n\t * and add to balloon.\n\t */\n\ti = 0;\n\tlist_for_each_entry_safe(page, tmp, &pages, lru) {\n\t\tframe_list[i++] = xen_page_to_gfn(page);\n\n\t\txenmem_reservation_va_mapping_reset(1, &page);\n\n\t\tlist_del(&page->lru);\n\n\t\tballoon_append(page);\n\t}\n\n\tflush_tlb_all();\n\n\tret = xenmem_reservation_decrease(nr_pages, frame_list);\n\tBUG_ON(ret != nr_pages);\n\n\tballoon_stats.current_pages -= nr_pages;\n\n\treturn state;\n}\n\n/*\n * As this is a work item it is guaranteed to run as a single instance only.\n * We may of course race updates of the target counts (which are protected\n * by the balloon lock), or with changes to the Xen hard limit, but we will\n * recover from these in time.\n */\nstatic void balloon_process(struct work_struct *work)\n{\n\tenum bp_state state = BP_DONE;\n\tlong credit;\n\n\n\tdo {\n\t\tmutex_lock(&balloon_mutex);\n\n\t\tcredit = current_credit();\n\n\t\tif (credit > 0) {\n\t\t\tif (balloon_is_inflated())\n\t\t\t\tstate = increase_reservation(credit);\n\t\t\telse\n\t\t\t\tstate = reserve_additional_memory();\n\t\t}\n\n\t\tif (credit < 0) {\n\t\t\tlong n_pages;\n\n\t\t\tn_pages = min(-credit, si_mem_available());\n\t\t\tstate = decrease_reservation(n_pages, GFP_BALLOON);\n\t\t\tif (state == BP_DONE && n_pages != -credit &&\n\t\t\t    n_pages < totalreserve_pages)\n\t\t\t\tstate = BP_EAGAIN;\n\t\t}\n\n\t\tstate = update_schedule(state);\n\n\t\tmutex_unlock(&balloon_mutex);\n\n\t\tcond_resched();\n\n\t} while (credit && state == BP_DONE);\n\n\t/* Schedule more work if there is some still to be done. */\n\tif (state == BP_EAGAIN)\n\t\tschedule_delayed_work(&balloon_worker, balloon_stats.schedule_delay * HZ);\n}\n\n/* Resets the Xen limit, sets new target, and kicks off processing. */\nvoid balloon_set_new_target(unsigned long target)\n{\n\t/* No need for lock. Not read-modify-write updates. */\n\tballoon_stats.target_pages = target;\n\tschedule_delayed_work(&balloon_worker, 0);\n}\nEXPORT_SYMBOL_GPL(balloon_set_new_target);\n\nstatic int add_ballooned_pages(int nr_pages)\n{\n\tenum bp_state st;\n\n\tif (xen_hotplug_unpopulated) {\n\t\tst = reserve_additional_memory();\n\t\tif (st != BP_ECANCELED) {\n\t\t\tmutex_unlock(&balloon_mutex);\n\t\t\twait_event(balloon_wq,\n\t\t\t\t   !list_empty(&ballooned_pages));\n\t\t\tmutex_lock(&balloon_mutex);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (si_mem_available() < nr_pages)\n\t\treturn -ENOMEM;\n\n\tst = decrease_reservation(nr_pages, GFP_USER);\n\tif (st != BP_DONE)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n/**\n * alloc_xenballooned_pages - get pages that have been ballooned out\n * @nr_pages: Number of pages to get\n * @pages: pages returned\n * @return 0 on success, error otherwise\n */\nint alloc_xenballooned_pages(int nr_pages, struct page **pages)\n{\n\tint pgno = 0;\n\tstruct page *page;\n\tint ret;\n\n\tmutex_lock(&balloon_mutex);\n\n\tballoon_stats.target_unpopulated += nr_pages;\n\n\twhile (pgno < nr_pages) {\n\t\tpage = balloon_retrieve(true);\n\t\tif (page) {\n\t\t\t__ClearPageOffline(page);\n\t\t\tpages[pgno++] = page;\n#ifdef CONFIG_XEN_HAVE_PVMMU\n\t\t\t/*\n\t\t\t * We don't support PV MMU when Linux and Xen is using\n\t\t\t * different page granularity.\n\t\t\t */\n\t\t\tBUILD_BUG_ON(XEN_PAGE_SIZE != PAGE_SIZE);\n\n\t\t\tif (!xen_feature(XENFEAT_auto_translated_physmap)) {\n\t\t\t\tret = xen_alloc_p2m_entry(page_to_pfn(page));\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tgoto out_undo;\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\tret = add_ballooned_pages(nr_pages - pgno);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_undo;\n\t\t}\n\t}\n\tmutex_unlock(&balloon_mutex);\n\treturn 0;\n out_undo:\n\tmutex_unlock(&balloon_mutex);\n\tfree_xenballooned_pages(pgno, pages);\n\treturn ret;\n}\nEXPORT_SYMBOL(alloc_xenballooned_pages);\n\n/**\n * free_xenballooned_pages - return pages retrieved with get_ballooned_pages\n * @nr_pages: Number of pages\n * @pages: pages to return\n */\nvoid free_xenballooned_pages(int nr_pages, struct page **pages)\n{\n\tint i;\n\n\tmutex_lock(&balloon_mutex);\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (pages[i]) {\n\t\t\t__SetPageOffline(pages[i]);\n\t\t\tballoon_append(pages[i]);\n\t\t}\n\t}\n\n\tballoon_stats.target_unpopulated -= nr_pages;\n\n\t/* The balloon may be too large now. Shrink it if needed. */\n\tif (current_credit())\n\t\tschedule_delayed_work(&balloon_worker, 0);\n\n\tmutex_unlock(&balloon_mutex);\n}\nEXPORT_SYMBOL(free_xenballooned_pages);\n\n#ifdef CONFIG_XEN_PV\nstatic void __init balloon_add_region(unsigned long start_pfn,\n\t\t\t\t      unsigned long pages)\n{\n\tunsigned long pfn, extra_pfn_end;\n\tstruct page *page;\n\n\t/*\n\t * If the amount of usable memory has been limited (e.g., with\n\t * the 'mem' command line parameter), don't add pages beyond\n\t * this limit.\n\t */\n\textra_pfn_end = min(max_pfn, start_pfn + pages);\n\n\tfor (pfn = start_pfn; pfn < extra_pfn_end; pfn++) {\n\t\tpage = pfn_to_page(pfn);\n\t\t/* totalram_pages and totalhigh_pages do not\n\t\t   include the boot-time balloon extension, so\n\t\t   don't subtract from it. */\n\t\t__balloon_append(page);\n\t}\n\n\tballoon_stats.total_pages += extra_pfn_end - start_pfn;\n}\n#endif\n\nstatic int __init balloon_init(void)\n{\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\tpr_info(\"Initialising balloon driver\\n\");\n\n#ifdef CONFIG_XEN_PV\n\tballoon_stats.current_pages = xen_pv_domain()\n\t\t? min(xen_start_info->nr_pages - xen_released_pages, max_pfn)\n\t\t: get_num_physpages();\n#else\n\tballoon_stats.current_pages = get_num_physpages();\n#endif\n\tballoon_stats.target_pages  = balloon_stats.current_pages;\n\tballoon_stats.balloon_low   = 0;\n\tballoon_stats.balloon_high  = 0;\n\tballoon_stats.total_pages   = balloon_stats.current_pages;\n\n\tballoon_stats.schedule_delay = 1;\n\tballoon_stats.max_schedule_delay = 32;\n\tballoon_stats.retry_count = 1;\n\tballoon_stats.max_retry_count = 4;\n\n#ifdef CONFIG_XEN_BALLOON_MEMORY_HOTPLUG\n\tset_online_page_callback(&xen_online_page);\n\tregister_memory_notifier(&xen_memory_nb);\n\tregister_sysctl_table(xen_root);\n#endif\n\n#ifdef CONFIG_XEN_PV\n\t{\n\t\tint i;\n\n\t\t/*\n\t\t * Initialize the balloon with pages from the extra memory\n\t\t * regions (see arch/x86/xen/setup.c).\n\t\t */\n\t\tfor (i = 0; i < XEN_EXTRA_MEM_MAX_REGIONS; i++)\n\t\t\tif (xen_extra_mem[i].n_pfns)\n\t\t\t\tballoon_add_region(xen_extra_mem[i].start_pfn,\n\t\t\t\t\t\t   xen_extra_mem[i].n_pfns);\n\t}\n#endif\n\n\t/* Init the xen-balloon driver. */\n\txen_balloon_init();\n\n\treturn 0;\n}\nsubsys_initcall(balloon_init);\n"], "buggy_code_start_loc": [541], "buggy_code_end_loc": [714], "fixing_code_start_loc": [541], "fixing_code_end_loc": [724], "type": "CWE-770", "message": "An issue was discovered in drivers/xen/balloon.c in the Linux kernel before 5.2.3, as used in Xen through 4.12.x, allowing guest OS users to cause a denial of service because of unrestricted resource consumption during the mapping of guest memory, aka CID-6ef36ab967c7.", "other": {"cve": {"id": "CVE-2019-17351", "sourceIdentifier": "cve@mitre.org", "published": "2019-10-08T00:15:10.617", "lastModified": "2020-08-24T17:37:01.140", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "An issue was discovered in drivers/xen/balloon.c in the Linux kernel before 5.2.3, as used in Xen through 4.12.x, allowing guest OS users to cause a denial of service because of unrestricted resource consumption during the mapping of guest memory, aka CID-6ef36ab967c7."}, {"lang": "es", "value": "Se detect\u00f3 un problema en el archivo drivers/xen/balloon.c en el kernel de Linux versiones anteriores a 5.2.3, como es usado en Xen versiones hasta 4.12.x, permitiendo a usuarios del sistema operativo invitado causar una denegaci\u00f3n de servicio debido al consumo de recursos sin restricciones durante la asignaci\u00f3n de la memoria de invitado , tambi\u00e9n se conoce como CID-6ef36ab967c7."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.0, "impactScore": 4.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:xen:xen:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.12.1", "matchCriteriaId": "44BCD11F-9BBA-47D2-94DF-C1E52317A7B3"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "5.2.3", "matchCriteriaId": "38844317-DEDF-4600-BA0E-C7D28D8EC200"}]}]}], "references": [{"url": "http://www.openwall.com/lists/oss-security/2019/10/25/9", "source": "cve@mitre.org"}, {"url": "http://xenbits.xen.org/xsa/advisory-300.html", "source": "cve@mitre.org"}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.2.3", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/6ef36ab967c71690ebe7e5ef997a8be4da3bc844", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20191031-0005/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/4286-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/4286-2/", "source": "cve@mitre.org"}, {"url": "https://xenbits.xen.org/xsa/advisory-300.html", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/6ef36ab967c71690ebe7e5ef997a8be4da3bc844"}}