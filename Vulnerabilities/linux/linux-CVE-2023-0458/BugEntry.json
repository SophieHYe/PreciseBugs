{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n *  linux/kernel/sys.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n */\n\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/mm_inline.h>\n#include <linux/utsname.h>\n#include <linux/mman.h>\n#include <linux/reboot.h>\n#include <linux/prctl.h>\n#include <linux/highuid.h>\n#include <linux/fs.h>\n#include <linux/kmod.h>\n#include <linux/perf_event.h>\n#include <linux/resource.h>\n#include <linux/kernel.h>\n#include <linux/workqueue.h>\n#include <linux/capability.h>\n#include <linux/device.h>\n#include <linux/key.h>\n#include <linux/times.h>\n#include <linux/posix-timers.h>\n#include <linux/security.h>\n#include <linux/random.h>\n#include <linux/suspend.h>\n#include <linux/tty.h>\n#include <linux/signal.h>\n#include <linux/cn_proc.h>\n#include <linux/getcpu.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/seccomp.h>\n#include <linux/cpu.h>\n#include <linux/personality.h>\n#include <linux/ptrace.h>\n#include <linux/fs_struct.h>\n#include <linux/file.h>\n#include <linux/mount.h>\n#include <linux/gfp.h>\n#include <linux/syscore_ops.h>\n#include <linux/version.h>\n#include <linux/ctype.h>\n#include <linux/syscall_user_dispatch.h>\n\n#include <linux/compat.h>\n#include <linux/syscalls.h>\n#include <linux/kprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/time_namespace.h>\n#include <linux/binfmts.h>\n\n#include <linux/sched.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/task.h>\n#include <linux/sched/cputime.h>\n#include <linux/rcupdate.h>\n#include <linux/uidgid.h>\n#include <linux/cred.h>\n\n#include <linux/nospec.h>\n\n#include <linux/kmsg_dump.h>\n/* Move somewhere else to avoid recompiling? */\n#include <generated/utsrelease.h>\n\n#include <linux/uaccess.h>\n#include <asm/io.h>\n#include <asm/unistd.h>\n\n#include \"uid16.h\"\n\n#ifndef SET_UNALIGN_CTL\n# define SET_UNALIGN_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_UNALIGN_CTL\n# define GET_UNALIGN_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_FPEMU_CTL\n# define SET_FPEMU_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_FPEMU_CTL\n# define GET_FPEMU_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_FPEXC_CTL\n# define SET_FPEXC_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_FPEXC_CTL\n# define GET_FPEXC_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_ENDIAN\n# define GET_ENDIAN(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_ENDIAN\n# define SET_ENDIAN(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_TSC_CTL\n# define GET_TSC_CTL(a)\t\t(-EINVAL)\n#endif\n#ifndef SET_TSC_CTL\n# define SET_TSC_CTL(a)\t\t(-EINVAL)\n#endif\n#ifndef GET_FP_MODE\n# define GET_FP_MODE(a)\t\t(-EINVAL)\n#endif\n#ifndef SET_FP_MODE\n# define SET_FP_MODE(a,b)\t(-EINVAL)\n#endif\n#ifndef SVE_SET_VL\n# define SVE_SET_VL(a)\t\t(-EINVAL)\n#endif\n#ifndef SVE_GET_VL\n# define SVE_GET_VL()\t\t(-EINVAL)\n#endif\n#ifndef SME_SET_VL\n# define SME_SET_VL(a)\t\t(-EINVAL)\n#endif\n#ifndef SME_GET_VL\n# define SME_GET_VL()\t\t(-EINVAL)\n#endif\n#ifndef PAC_RESET_KEYS\n# define PAC_RESET_KEYS(a, b)\t(-EINVAL)\n#endif\n#ifndef PAC_SET_ENABLED_KEYS\n# define PAC_SET_ENABLED_KEYS(a, b, c)\t(-EINVAL)\n#endif\n#ifndef PAC_GET_ENABLED_KEYS\n# define PAC_GET_ENABLED_KEYS(a)\t(-EINVAL)\n#endif\n#ifndef SET_TAGGED_ADDR_CTRL\n# define SET_TAGGED_ADDR_CTRL(a)\t(-EINVAL)\n#endif\n#ifndef GET_TAGGED_ADDR_CTRL\n# define GET_TAGGED_ADDR_CTRL()\t\t(-EINVAL)\n#endif\n\n/*\n * this is where the system-wide overflow UID and GID are defined, for\n * architectures that now have 32-bit UID/GID but didn't in the past\n */\n\nint overflowuid = DEFAULT_OVERFLOWUID;\nint overflowgid = DEFAULT_OVERFLOWGID;\n\nEXPORT_SYMBOL(overflowuid);\nEXPORT_SYMBOL(overflowgid);\n\n/*\n * the same as above, but for filesystems which can only store a 16-bit\n * UID and GID. as such, this is needed on all architectures\n */\n\nint fs_overflowuid = DEFAULT_FS_OVERFLOWUID;\nint fs_overflowgid = DEFAULT_FS_OVERFLOWGID;\n\nEXPORT_SYMBOL(fs_overflowuid);\nEXPORT_SYMBOL(fs_overflowgid);\n\n/*\n * Returns true if current's euid is same as p's uid or euid,\n * or has CAP_SYS_NICE to p's user_ns.\n *\n * Called with rcu_read_lock, creds are safe\n */\nstatic bool set_one_prio_perm(struct task_struct *p)\n{\n\tconst struct cred *cred = current_cred(), *pcred = __task_cred(p);\n\n\tif (uid_eq(pcred->uid,  cred->euid) ||\n\t    uid_eq(pcred->euid, cred->euid))\n\t\treturn true;\n\tif (ns_capable(pcred->user_ns, CAP_SYS_NICE))\n\t\treturn true;\n\treturn false;\n}\n\n/*\n * set the priority of a task\n * - the caller must hold the RCU read lock\n */\nstatic int set_one_prio(struct task_struct *p, int niceval, int error)\n{\n\tint no_nice;\n\n\tif (!set_one_prio_perm(p)) {\n\t\terror = -EPERM;\n\t\tgoto out;\n\t}\n\tif (niceval < task_nice(p) && !can_nice(p, niceval)) {\n\t\terror = -EACCES;\n\t\tgoto out;\n\t}\n\tno_nice = security_task_setnice(p, niceval);\n\tif (no_nice) {\n\t\terror = no_nice;\n\t\tgoto out;\n\t}\n\tif (error == -ESRCH)\n\t\terror = 0;\n\tset_user_nice(p, niceval);\nout:\n\treturn error;\n}\n\nSYSCALL_DEFINE3(setpriority, int, which, int, who, int, niceval)\n{\n\tstruct task_struct *g, *p;\n\tstruct user_struct *user;\n\tconst struct cred *cred = current_cred();\n\tint error = -EINVAL;\n\tstruct pid *pgrp;\n\tkuid_t uid;\n\n\tif (which > PRIO_USER || which < PRIO_PROCESS)\n\t\tgoto out;\n\n\t/* normalize: avoid signed division (rounding problems) */\n\terror = -ESRCH;\n\tif (niceval < MIN_NICE)\n\t\tniceval = MIN_NICE;\n\tif (niceval > MAX_NICE)\n\t\tniceval = MAX_NICE;\n\n\trcu_read_lock();\n\tswitch (which) {\n\tcase PRIO_PROCESS:\n\t\tif (who)\n\t\t\tp = find_task_by_vpid(who);\n\t\telse\n\t\t\tp = current;\n\t\tif (p)\n\t\t\terror = set_one_prio(p, niceval, error);\n\t\tbreak;\n\tcase PRIO_PGRP:\n\t\tif (who)\n\t\t\tpgrp = find_vpid(who);\n\t\telse\n\t\t\tpgrp = task_pgrp(current);\n\t\tread_lock(&tasklist_lock);\n\t\tdo_each_pid_thread(pgrp, PIDTYPE_PGID, p) {\n\t\t\terror = set_one_prio(p, niceval, error);\n\t\t} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);\n\t\tread_unlock(&tasklist_lock);\n\t\tbreak;\n\tcase PRIO_USER:\n\t\tuid = make_kuid(cred->user_ns, who);\n\t\tuser = cred->user;\n\t\tif (!who)\n\t\t\tuid = cred->uid;\n\t\telse if (!uid_eq(uid, cred->uid)) {\n\t\t\tuser = find_user(uid);\n\t\t\tif (!user)\n\t\t\t\tgoto out_unlock;\t/* No processes for this user */\n\t\t}\n\t\tfor_each_process_thread(g, p) {\n\t\t\tif (uid_eq(task_uid(p), uid) && task_pid_vnr(p))\n\t\t\t\terror = set_one_prio(p, niceval, error);\n\t\t}\n\t\tif (!uid_eq(uid, cred->uid))\n\t\t\tfree_uid(user);\t\t/* For find_user() */\n\t\tbreak;\n\t}\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn error;\n}\n\n/*\n * Ugh. To avoid negative return values, \"getpriority()\" will\n * not return the normal nice-value, but a negated value that\n * has been offset by 20 (ie it returns 40..1 instead of -20..19)\n * to stay compatible.\n */\nSYSCALL_DEFINE2(getpriority, int, which, int, who)\n{\n\tstruct task_struct *g, *p;\n\tstruct user_struct *user;\n\tconst struct cred *cred = current_cred();\n\tlong niceval, retval = -ESRCH;\n\tstruct pid *pgrp;\n\tkuid_t uid;\n\n\tif (which > PRIO_USER || which < PRIO_PROCESS)\n\t\treturn -EINVAL;\n\n\trcu_read_lock();\n\tswitch (which) {\n\tcase PRIO_PROCESS:\n\t\tif (who)\n\t\t\tp = find_task_by_vpid(who);\n\t\telse\n\t\t\tp = current;\n\t\tif (p) {\n\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\tif (niceval > retval)\n\t\t\t\tretval = niceval;\n\t\t}\n\t\tbreak;\n\tcase PRIO_PGRP:\n\t\tif (who)\n\t\t\tpgrp = find_vpid(who);\n\t\telse\n\t\t\tpgrp = task_pgrp(current);\n\t\tread_lock(&tasklist_lock);\n\t\tdo_each_pid_thread(pgrp, PIDTYPE_PGID, p) {\n\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\tif (niceval > retval)\n\t\t\t\tretval = niceval;\n\t\t} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);\n\t\tread_unlock(&tasklist_lock);\n\t\tbreak;\n\tcase PRIO_USER:\n\t\tuid = make_kuid(cred->user_ns, who);\n\t\tuser = cred->user;\n\t\tif (!who)\n\t\t\tuid = cred->uid;\n\t\telse if (!uid_eq(uid, cred->uid)) {\n\t\t\tuser = find_user(uid);\n\t\t\tif (!user)\n\t\t\t\tgoto out_unlock;\t/* No processes for this user */\n\t\t}\n\t\tfor_each_process_thread(g, p) {\n\t\t\tif (uid_eq(task_uid(p), uid) && task_pid_vnr(p)) {\n\t\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\t\tif (niceval > retval)\n\t\t\t\t\tretval = niceval;\n\t\t\t}\n\t\t}\n\t\tif (!uid_eq(uid, cred->uid))\n\t\t\tfree_uid(user);\t\t/* for find_user() */\n\t\tbreak;\n\t}\nout_unlock:\n\trcu_read_unlock();\n\n\treturn retval;\n}\n\n/*\n * Unprivileged users may change the real gid to the effective gid\n * or vice versa.  (BSD-style)\n *\n * If you set the real gid at all, or set the effective gid to a value not\n * equal to the real gid, then the saved gid is set to the new effective gid.\n *\n * This makes it possible for a setgid program to completely drop its\n * privileges, which is often a useful assertion to make when you are doing\n * a security audit over a program.\n *\n * The general idea is that a program which uses just setregid() will be\n * 100% compatible with BSD.  A program which uses just setgid() will be\n * 100% compatible with POSIX with saved IDs.\n *\n * SMP: There are not races, the GIDs are checked only by filesystem\n *      operations (as far as semantic preservation is concerned).\n */\n#ifdef CONFIG_MULTIUSER\nlong __sys_setregid(gid_t rgid, gid_t egid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t krgid, kegid;\n\n\tkrgid = make_kgid(ns, rgid);\n\tkegid = make_kgid(ns, egid);\n\n\tif ((rgid != (gid_t) -1) && !gid_valid(krgid))\n\t\treturn -EINVAL;\n\tif ((egid != (gid_t) -1) && !gid_valid(kegid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (rgid != (gid_t) -1) {\n\t\tif (gid_eq(old->gid, krgid) ||\n\t\t    gid_eq(old->egid, krgid) ||\n\t\t    ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\t\tnew->gid = krgid;\n\t\telse\n\t\t\tgoto error;\n\t}\n\tif (egid != (gid_t) -1) {\n\t\tif (gid_eq(old->gid, kegid) ||\n\t\t    gid_eq(old->egid, kegid) ||\n\t\t    gid_eq(old->sgid, kegid) ||\n\t\t    ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\t\tnew->egid = kegid;\n\t\telse\n\t\t\tgoto error;\n\t}\n\n\tif (rgid != (gid_t) -1 ||\n\t    (egid != (gid_t) -1 && !gid_eq(kegid, old->gid)))\n\t\tnew->sgid = new->egid;\n\tnew->fsgid = new->egid;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_RE);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(setregid, gid_t, rgid, gid_t, egid)\n{\n\treturn __sys_setregid(rgid, egid);\n}\n\n/*\n * setgid() is implemented like SysV w/ SAVED_IDS\n *\n * SMP: Same implicit races as above.\n */\nlong __sys_setgid(gid_t gid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t kgid;\n\n\tkgid = make_kgid(ns, gid);\n\tif (!gid_valid(kgid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\tnew->gid = new->egid = new->sgid = new->fsgid = kgid;\n\telse if (gid_eq(kgid, old->gid) || gid_eq(kgid, old->sgid))\n\t\tnew->egid = new->fsgid = kgid;\n\telse\n\t\tgoto error;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_ID);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(setgid, gid_t, gid)\n{\n\treturn __sys_setgid(gid);\n}\n\n/*\n * change the user struct in a credentials set to match the new UID\n */\nstatic int set_user(struct cred *new)\n{\n\tstruct user_struct *new_user;\n\n\tnew_user = alloc_uid(new->uid);\n\tif (!new_user)\n\t\treturn -EAGAIN;\n\n\tfree_uid(new->user);\n\tnew->user = new_user;\n\treturn 0;\n}\n\nstatic void flag_nproc_exceeded(struct cred *new)\n{\n\tif (new->ucounts == current_ucounts())\n\t\treturn;\n\n\t/*\n\t * We don't fail in case of NPROC limit excess here because too many\n\t * poorly written programs don't check set*uid() return code, assuming\n\t * it never fails if called by root.  We may still enforce NPROC limit\n\t * for programs doing set*uid()+execve() by harmlessly deferring the\n\t * failure to the execve() stage.\n\t */\n\tif (is_rlimit_overlimit(new->ucounts, UCOUNT_RLIMIT_NPROC, rlimit(RLIMIT_NPROC)) &&\n\t\t\tnew->user != INIT_USER)\n\t\tcurrent->flags |= PF_NPROC_EXCEEDED;\n\telse\n\t\tcurrent->flags &= ~PF_NPROC_EXCEEDED;\n}\n\n/*\n * Unprivileged users may change the real uid to the effective uid\n * or vice versa.  (BSD-style)\n *\n * If you set the real uid at all, or set the effective uid to a value not\n * equal to the real uid, then the saved uid is set to the new effective uid.\n *\n * This makes it possible for a setuid program to completely drop its\n * privileges, which is often a useful assertion to make when you are doing\n * a security audit over a program.\n *\n * The general idea is that a program which uses just setreuid() will be\n * 100% compatible with BSD.  A program which uses just setuid() will be\n * 100% compatible with POSIX with saved IDs.\n */\nlong __sys_setreuid(uid_t ruid, uid_t euid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kruid, keuid;\n\n\tkruid = make_kuid(ns, ruid);\n\tkeuid = make_kuid(ns, euid);\n\n\tif ((ruid != (uid_t) -1) && !uid_valid(kruid))\n\t\treturn -EINVAL;\n\tif ((euid != (uid_t) -1) && !uid_valid(keuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ruid != (uid_t) -1) {\n\t\tnew->uid = kruid;\n\t\tif (!uid_eq(old->uid, kruid) &&\n\t\t    !uid_eq(old->euid, kruid) &&\n\t\t    !ns_capable_setid(old->user_ns, CAP_SETUID))\n\t\t\tgoto error;\n\t}\n\n\tif (euid != (uid_t) -1) {\n\t\tnew->euid = keuid;\n\t\tif (!uid_eq(old->uid, keuid) &&\n\t\t    !uid_eq(old->euid, keuid) &&\n\t\t    !uid_eq(old->suid, keuid) &&\n\t\t    !ns_capable_setid(old->user_ns, CAP_SETUID))\n\t\t\tgoto error;\n\t}\n\n\tif (!uid_eq(new->uid, old->uid)) {\n\t\tretval = set_user(new);\n\t\tif (retval < 0)\n\t\t\tgoto error;\n\t}\n\tif (ruid != (uid_t) -1 ||\n\t    (euid != (uid_t) -1 && !uid_eq(keuid, old->uid)))\n\t\tnew->suid = new->euid;\n\tnew->fsuid = new->euid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_RE);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(setreuid, uid_t, ruid, uid_t, euid)\n{\n\treturn __sys_setreuid(ruid, euid);\n}\n\n/*\n * setuid() is implemented like SysV with SAVED_IDS\n *\n * Note that SAVED_ID's is deficient in that a setuid root program\n * like sendmail, for example, cannot set its uid to be a normal\n * user and then switch back, because if you're root, setuid() sets\n * the saved uid too.  If you don't like this, blame the bright people\n * in the POSIX committee and/or USG.  Note that the BSD-style setreuid()\n * will allow a root program to temporarily drop privileges and be able to\n * regain them by swapping the real and effective uid.\n */\nlong __sys_setuid(uid_t uid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kuid;\n\n\tkuid = make_kuid(ns, uid);\n\tif (!uid_valid(kuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tnew->suid = new->uid = kuid;\n\t\tif (!uid_eq(kuid, old->uid)) {\n\t\t\tretval = set_user(new);\n\t\t\tif (retval < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t} else if (!uid_eq(kuid, old->uid) && !uid_eq(kuid, new->suid)) {\n\t\tgoto error;\n\t}\n\n\tnew->fsuid = new->euid = kuid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_ID);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(setuid, uid_t, uid)\n{\n\treturn __sys_setuid(uid);\n}\n\n\n/*\n * This function implements a generic ability to update ruid, euid,\n * and suid.  This allows you to implement the 4.4 compatible seteuid().\n */\nlong __sys_setresuid(uid_t ruid, uid_t euid, uid_t suid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kruid, keuid, ksuid;\n\n\tkruid = make_kuid(ns, ruid);\n\tkeuid = make_kuid(ns, euid);\n\tksuid = make_kuid(ns, suid);\n\n\tif ((ruid != (uid_t) -1) && !uid_valid(kruid))\n\t\treturn -EINVAL;\n\n\tif ((euid != (uid_t) -1) && !uid_valid(keuid))\n\t\treturn -EINVAL;\n\n\tif ((suid != (uid_t) -1) && !uid_valid(ksuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (!ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tif (ruid != (uid_t) -1        && !uid_eq(kruid, old->uid) &&\n\t\t    !uid_eq(kruid, old->euid) && !uid_eq(kruid, old->suid))\n\t\t\tgoto error;\n\t\tif (euid != (uid_t) -1        && !uid_eq(keuid, old->uid) &&\n\t\t    !uid_eq(keuid, old->euid) && !uid_eq(keuid, old->suid))\n\t\t\tgoto error;\n\t\tif (suid != (uid_t) -1        && !uid_eq(ksuid, old->uid) &&\n\t\t    !uid_eq(ksuid, old->euid) && !uid_eq(ksuid, old->suid))\n\t\t\tgoto error;\n\t}\n\n\tif (ruid != (uid_t) -1) {\n\t\tnew->uid = kruid;\n\t\tif (!uid_eq(kruid, old->uid)) {\n\t\t\tretval = set_user(new);\n\t\t\tif (retval < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t}\n\tif (euid != (uid_t) -1)\n\t\tnew->euid = keuid;\n\tif (suid != (uid_t) -1)\n\t\tnew->suid = ksuid;\n\tnew->fsuid = new->euid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_RES);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE3(setresuid, uid_t, ruid, uid_t, euid, uid_t, suid)\n{\n\treturn __sys_setresuid(ruid, euid, suid);\n}\n\nSYSCALL_DEFINE3(getresuid, uid_t __user *, ruidp, uid_t __user *, euidp, uid_t __user *, suidp)\n{\n\tconst struct cred *cred = current_cred();\n\tint retval;\n\tuid_t ruid, euid, suid;\n\n\truid = from_kuid_munged(cred->user_ns, cred->uid);\n\teuid = from_kuid_munged(cred->user_ns, cred->euid);\n\tsuid = from_kuid_munged(cred->user_ns, cred->suid);\n\n\tretval = put_user(ruid, ruidp);\n\tif (!retval) {\n\t\tretval = put_user(euid, euidp);\n\t\tif (!retval)\n\t\t\treturn put_user(suid, suidp);\n\t}\n\treturn retval;\n}\n\n/*\n * Same as above, but for rgid, egid, sgid.\n */\nlong __sys_setresgid(gid_t rgid, gid_t egid, gid_t sgid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t krgid, kegid, ksgid;\n\n\tkrgid = make_kgid(ns, rgid);\n\tkegid = make_kgid(ns, egid);\n\tksgid = make_kgid(ns, sgid);\n\n\tif ((rgid != (gid_t) -1) && !gid_valid(krgid))\n\t\treturn -EINVAL;\n\tif ((egid != (gid_t) -1) && !gid_valid(kegid))\n\t\treturn -EINVAL;\n\tif ((sgid != (gid_t) -1) && !gid_valid(ksgid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (!ns_capable_setid(old->user_ns, CAP_SETGID)) {\n\t\tif (rgid != (gid_t) -1        && !gid_eq(krgid, old->gid) &&\n\t\t    !gid_eq(krgid, old->egid) && !gid_eq(krgid, old->sgid))\n\t\t\tgoto error;\n\t\tif (egid != (gid_t) -1        && !gid_eq(kegid, old->gid) &&\n\t\t    !gid_eq(kegid, old->egid) && !gid_eq(kegid, old->sgid))\n\t\t\tgoto error;\n\t\tif (sgid != (gid_t) -1        && !gid_eq(ksgid, old->gid) &&\n\t\t    !gid_eq(ksgid, old->egid) && !gid_eq(ksgid, old->sgid))\n\t\t\tgoto error;\n\t}\n\n\tif (rgid != (gid_t) -1)\n\t\tnew->gid = krgid;\n\tif (egid != (gid_t) -1)\n\t\tnew->egid = kegid;\n\tif (sgid != (gid_t) -1)\n\t\tnew->sgid = ksgid;\n\tnew->fsgid = new->egid;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_RES);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE3(setresgid, gid_t, rgid, gid_t, egid, gid_t, sgid)\n{\n\treturn __sys_setresgid(rgid, egid, sgid);\n}\n\nSYSCALL_DEFINE3(getresgid, gid_t __user *, rgidp, gid_t __user *, egidp, gid_t __user *, sgidp)\n{\n\tconst struct cred *cred = current_cred();\n\tint retval;\n\tgid_t rgid, egid, sgid;\n\n\trgid = from_kgid_munged(cred->user_ns, cred->gid);\n\tegid = from_kgid_munged(cred->user_ns, cred->egid);\n\tsgid = from_kgid_munged(cred->user_ns, cred->sgid);\n\n\tretval = put_user(rgid, rgidp);\n\tif (!retval) {\n\t\tretval = put_user(egid, egidp);\n\t\tif (!retval)\n\t\t\tretval = put_user(sgid, sgidp);\n\t}\n\n\treturn retval;\n}\n\n\n/*\n * \"setfsuid()\" sets the fsuid - the uid used for filesystem checks. This\n * is used for \"access()\" and for the NFS daemon (letting nfsd stay at\n * whatever uid it wants to). It normally shadows \"euid\", except when\n * explicitly set by setfsuid() or for access..\n */\nlong __sys_setfsuid(uid_t uid)\n{\n\tconst struct cred *old;\n\tstruct cred *new;\n\tuid_t old_fsuid;\n\tkuid_t kuid;\n\n\told = current_cred();\n\told_fsuid = from_kuid_munged(old->user_ns, old->fsuid);\n\n\tkuid = make_kuid(old->user_ns, uid);\n\tif (!uid_valid(kuid))\n\t\treturn old_fsuid;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn old_fsuid;\n\n\tif (uid_eq(kuid, old->uid)  || uid_eq(kuid, old->euid)  ||\n\t    uid_eq(kuid, old->suid) || uid_eq(kuid, old->fsuid) ||\n\t    ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tif (!uid_eq(kuid, old->fsuid)) {\n\t\t\tnew->fsuid = kuid;\n\t\t\tif (security_task_fix_setuid(new, old, LSM_SETID_FS) == 0)\n\t\t\t\tgoto change_okay;\n\t\t}\n\t}\n\n\tabort_creds(new);\n\treturn old_fsuid;\n\nchange_okay:\n\tcommit_creds(new);\n\treturn old_fsuid;\n}\n\nSYSCALL_DEFINE1(setfsuid, uid_t, uid)\n{\n\treturn __sys_setfsuid(uid);\n}\n\n/*\n * Samma p\u00e5 svenska..\n */\nlong __sys_setfsgid(gid_t gid)\n{\n\tconst struct cred *old;\n\tstruct cred *new;\n\tgid_t old_fsgid;\n\tkgid_t kgid;\n\n\told = current_cred();\n\told_fsgid = from_kgid_munged(old->user_ns, old->fsgid);\n\n\tkgid = make_kgid(old->user_ns, gid);\n\tif (!gid_valid(kgid))\n\t\treturn old_fsgid;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn old_fsgid;\n\n\tif (gid_eq(kgid, old->gid)  || gid_eq(kgid, old->egid)  ||\n\t    gid_eq(kgid, old->sgid) || gid_eq(kgid, old->fsgid) ||\n\t    ns_capable_setid(old->user_ns, CAP_SETGID)) {\n\t\tif (!gid_eq(kgid, old->fsgid)) {\n\t\t\tnew->fsgid = kgid;\n\t\t\tif (security_task_fix_setgid(new,old,LSM_SETID_FS) == 0)\n\t\t\t\tgoto change_okay;\n\t\t}\n\t}\n\n\tabort_creds(new);\n\treturn old_fsgid;\n\nchange_okay:\n\tcommit_creds(new);\n\treturn old_fsgid;\n}\n\nSYSCALL_DEFINE1(setfsgid, gid_t, gid)\n{\n\treturn __sys_setfsgid(gid);\n}\n#endif /* CONFIG_MULTIUSER */\n\n/**\n * sys_getpid - return the thread group id of the current process\n *\n * Note, despite the name, this returns the tgid not the pid.  The tgid and\n * the pid are identical unless CLONE_THREAD was specified on clone() in\n * which case the tgid is the same in all threads of the same group.\n *\n * This is SMP safe as current->tgid does not change.\n */\nSYSCALL_DEFINE0(getpid)\n{\n\treturn task_tgid_vnr(current);\n}\n\n/* Thread ID - the internal kernel \"pid\" */\nSYSCALL_DEFINE0(gettid)\n{\n\treturn task_pid_vnr(current);\n}\n\n/*\n * Accessing ->real_parent is not SMP-safe, it could\n * change from under us. However, we can use a stale\n * value of ->real_parent under rcu_read_lock(), see\n * release_task()->call_rcu(delayed_put_task_struct).\n */\nSYSCALL_DEFINE0(getppid)\n{\n\tint pid;\n\n\trcu_read_lock();\n\tpid = task_tgid_vnr(rcu_dereference(current->real_parent));\n\trcu_read_unlock();\n\n\treturn pid;\n}\n\nSYSCALL_DEFINE0(getuid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kuid_munged(current_user_ns(), current_uid());\n}\n\nSYSCALL_DEFINE0(geteuid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kuid_munged(current_user_ns(), current_euid());\n}\n\nSYSCALL_DEFINE0(getgid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kgid_munged(current_user_ns(), current_gid());\n}\n\nSYSCALL_DEFINE0(getegid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kgid_munged(current_user_ns(), current_egid());\n}\n\nstatic void do_sys_times(struct tms *tms)\n{\n\tu64 tgutime, tgstime, cutime, cstime;\n\n\tthread_group_cputime_adjusted(current, &tgutime, &tgstime);\n\tcutime = current->signal->cutime;\n\tcstime = current->signal->cstime;\n\ttms->tms_utime = nsec_to_clock_t(tgutime);\n\ttms->tms_stime = nsec_to_clock_t(tgstime);\n\ttms->tms_cutime = nsec_to_clock_t(cutime);\n\ttms->tms_cstime = nsec_to_clock_t(cstime);\n}\n\nSYSCALL_DEFINE1(times, struct tms __user *, tbuf)\n{\n\tif (tbuf) {\n\t\tstruct tms tmp;\n\n\t\tdo_sys_times(&tmp);\n\t\tif (copy_to_user(tbuf, &tmp, sizeof(struct tms)))\n\t\t\treturn -EFAULT;\n\t}\n\tforce_successful_syscall_return();\n\treturn (long) jiffies_64_to_clock_t(get_jiffies_64());\n}\n\n#ifdef CONFIG_COMPAT\nstatic compat_clock_t clock_t_to_compat_clock_t(clock_t x)\n{\n\treturn compat_jiffies_to_clock_t(clock_t_to_jiffies(x));\n}\n\nCOMPAT_SYSCALL_DEFINE1(times, struct compat_tms __user *, tbuf)\n{\n\tif (tbuf) {\n\t\tstruct tms tms;\n\t\tstruct compat_tms tmp;\n\n\t\tdo_sys_times(&tms);\n\t\t/* Convert our struct tms to the compat version. */\n\t\ttmp.tms_utime = clock_t_to_compat_clock_t(tms.tms_utime);\n\t\ttmp.tms_stime = clock_t_to_compat_clock_t(tms.tms_stime);\n\t\ttmp.tms_cutime = clock_t_to_compat_clock_t(tms.tms_cutime);\n\t\ttmp.tms_cstime = clock_t_to_compat_clock_t(tms.tms_cstime);\n\t\tif (copy_to_user(tbuf, &tmp, sizeof(tmp)))\n\t\t\treturn -EFAULT;\n\t}\n\tforce_successful_syscall_return();\n\treturn compat_jiffies_to_clock_t(jiffies);\n}\n#endif\n\n/*\n * This needs some heavy checking ...\n * I just haven't the stomach for it. I also don't fully\n * understand sessions/pgrp etc. Let somebody who does explain it.\n *\n * OK, I think I have the protection semantics right.... this is really\n * only important on a multi-user system anyway, to make sure one user\n * can't send a signal to a process owned by another.  -TYT, 12/12/91\n *\n * !PF_FORKNOEXEC check to conform completely to POSIX.\n */\nSYSCALL_DEFINE2(setpgid, pid_t, pid, pid_t, pgid)\n{\n\tstruct task_struct *p;\n\tstruct task_struct *group_leader = current->group_leader;\n\tstruct pid *pgrp;\n\tint err;\n\n\tif (!pid)\n\t\tpid = task_pid_vnr(group_leader);\n\tif (!pgid)\n\t\tpgid = pid;\n\tif (pgid < 0)\n\t\treturn -EINVAL;\n\trcu_read_lock();\n\n\t/* From this point forward we keep holding onto the tasklist lock\n\t * so that our parent does not change from under us. -DaveM\n\t */\n\twrite_lock_irq(&tasklist_lock);\n\n\terr = -ESRCH;\n\tp = find_task_by_vpid(pid);\n\tif (!p)\n\t\tgoto out;\n\n\terr = -EINVAL;\n\tif (!thread_group_leader(p))\n\t\tgoto out;\n\n\tif (same_thread_group(p->real_parent, group_leader)) {\n\t\terr = -EPERM;\n\t\tif (task_session(p) != task_session(group_leader))\n\t\t\tgoto out;\n\t\terr = -EACCES;\n\t\tif (!(p->flags & PF_FORKNOEXEC))\n\t\t\tgoto out;\n\t} else {\n\t\terr = -ESRCH;\n\t\tif (p != group_leader)\n\t\t\tgoto out;\n\t}\n\n\terr = -EPERM;\n\tif (p->signal->leader)\n\t\tgoto out;\n\n\tpgrp = task_pid(p);\n\tif (pgid != pid) {\n\t\tstruct task_struct *g;\n\n\t\tpgrp = find_vpid(pgid);\n\t\tg = pid_task(pgrp, PIDTYPE_PGID);\n\t\tif (!g || task_session(g) != task_session(group_leader))\n\t\t\tgoto out;\n\t}\n\n\terr = security_task_setpgid(p, pgid);\n\tif (err)\n\t\tgoto out;\n\n\tif (task_pgrp(p) != pgrp)\n\t\tchange_pid(p, PIDTYPE_PGID, pgrp);\n\n\terr = 0;\nout:\n\t/* All paths lead to here, thus we are safe. -DaveM */\n\twrite_unlock_irq(&tasklist_lock);\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int do_getpgid(pid_t pid)\n{\n\tstruct task_struct *p;\n\tstruct pid *grp;\n\tint retval;\n\n\trcu_read_lock();\n\tif (!pid)\n\t\tgrp = task_pgrp(current);\n\telse {\n\t\tretval = -ESRCH;\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto out;\n\t\tgrp = task_pgrp(p);\n\t\tif (!grp)\n\t\t\tgoto out;\n\n\t\tretval = security_task_getpgid(p);\n\t\tif (retval)\n\t\t\tgoto out;\n\t}\n\tretval = pid_vnr(grp);\nout:\n\trcu_read_unlock();\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(getpgid, pid_t, pid)\n{\n\treturn do_getpgid(pid);\n}\n\n#ifdef __ARCH_WANT_SYS_GETPGRP\n\nSYSCALL_DEFINE0(getpgrp)\n{\n\treturn do_getpgid(0);\n}\n\n#endif\n\nSYSCALL_DEFINE1(getsid, pid_t, pid)\n{\n\tstruct task_struct *p;\n\tstruct pid *sid;\n\tint retval;\n\n\trcu_read_lock();\n\tif (!pid)\n\t\tsid = task_session(current);\n\telse {\n\t\tretval = -ESRCH;\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto out;\n\t\tsid = task_session(p);\n\t\tif (!sid)\n\t\t\tgoto out;\n\n\t\tretval = security_task_getsid(p);\n\t\tif (retval)\n\t\t\tgoto out;\n\t}\n\tretval = pid_vnr(sid);\nout:\n\trcu_read_unlock();\n\treturn retval;\n}\n\nstatic void set_special_pids(struct pid *pid)\n{\n\tstruct task_struct *curr = current->group_leader;\n\n\tif (task_session(curr) != pid)\n\t\tchange_pid(curr, PIDTYPE_SID, pid);\n\n\tif (task_pgrp(curr) != pid)\n\t\tchange_pid(curr, PIDTYPE_PGID, pid);\n}\n\nint ksys_setsid(void)\n{\n\tstruct task_struct *group_leader = current->group_leader;\n\tstruct pid *sid = task_pid(group_leader);\n\tpid_t session = pid_vnr(sid);\n\tint err = -EPERM;\n\n\twrite_lock_irq(&tasklist_lock);\n\t/* Fail if I am already a session leader */\n\tif (group_leader->signal->leader)\n\t\tgoto out;\n\n\t/* Fail if a process group id already exists that equals the\n\t * proposed session id.\n\t */\n\tif (pid_task(sid, PIDTYPE_PGID))\n\t\tgoto out;\n\n\tgroup_leader->signal->leader = 1;\n\tset_special_pids(sid);\n\n\tproc_clear_tty(group_leader);\n\n\terr = session;\nout:\n\twrite_unlock_irq(&tasklist_lock);\n\tif (err > 0) {\n\t\tproc_sid_connector(group_leader);\n\t\tsched_autogroup_create_attach(group_leader);\n\t}\n\treturn err;\n}\n\nSYSCALL_DEFINE0(setsid)\n{\n\treturn ksys_setsid();\n}\n\nDECLARE_RWSEM(uts_sem);\n\n#ifdef COMPAT_UTS_MACHINE\n#define override_architecture(name) \\\n\t(personality(current->personality) == PER_LINUX32 && \\\n\t copy_to_user(name->machine, COMPAT_UTS_MACHINE, \\\n\t\t      sizeof(COMPAT_UTS_MACHINE)))\n#else\n#define override_architecture(name)\t0\n#endif\n\n/*\n * Work around broken programs that cannot handle \"Linux 3.0\".\n * Instead we map 3.x to 2.6.40+x, so e.g. 3.0 would be 2.6.40\n * And we map 4.x and later versions to 2.6.60+x, so 4.0/5.0/6.0/... would be\n * 2.6.60.\n */\nstatic int override_release(char __user *release, size_t len)\n{\n\tint ret = 0;\n\n\tif (current->personality & UNAME26) {\n\t\tconst char *rest = UTS_RELEASE;\n\t\tchar buf[65] = { 0 };\n\t\tint ndots = 0;\n\t\tunsigned v;\n\t\tsize_t copy;\n\n\t\twhile (*rest) {\n\t\t\tif (*rest == '.' && ++ndots >= 3)\n\t\t\t\tbreak;\n\t\t\tif (!isdigit(*rest) && *rest != '.')\n\t\t\t\tbreak;\n\t\t\trest++;\n\t\t}\n\t\tv = LINUX_VERSION_PATCHLEVEL + 60;\n\t\tcopy = clamp_t(size_t, len, 1, sizeof(buf));\n\t\tcopy = scnprintf(buf, copy, \"2.6.%u%s\", v, rest);\n\t\tret = copy_to_user(release, buf, copy + 1);\n\t}\n\treturn ret;\n}\n\nSYSCALL_DEFINE1(newuname, struct new_utsname __user *, name)\n{\n\tstruct new_utsname tmp;\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp, utsname(), sizeof(tmp));\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n#ifdef __ARCH_WANT_SYS_OLD_UNAME\n/*\n * Old cruft\n */\nSYSCALL_DEFINE1(uname, struct old_utsname __user *, name)\n{\n\tstruct old_utsname tmp;\n\n\tif (!name)\n\t\treturn -EFAULT;\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp, utsname(), sizeof(tmp));\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nSYSCALL_DEFINE1(olduname, struct oldold_utsname __user *, name)\n{\n\tstruct oldold_utsname tmp;\n\n\tif (!name)\n\t\treturn -EFAULT;\n\n\tmemset(&tmp, 0, sizeof(tmp));\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp.sysname, &utsname()->sysname, __OLD_UTS_LEN);\n\tmemcpy(&tmp.nodename, &utsname()->nodename, __OLD_UTS_LEN);\n\tmemcpy(&tmp.release, &utsname()->release, __OLD_UTS_LEN);\n\tmemcpy(&tmp.version, &utsname()->version, __OLD_UTS_LEN);\n\tmemcpy(&tmp.machine, &utsname()->machine, __OLD_UTS_LEN);\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif\n\nSYSCALL_DEFINE2(sethostname, char __user *, name, int, len)\n{\n\tint errno;\n\tchar tmp[__NEW_UTS_LEN];\n\n\tif (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (len < 0 || len > __NEW_UTS_LEN)\n\t\treturn -EINVAL;\n\terrno = -EFAULT;\n\tif (!copy_from_user(tmp, name, len)) {\n\t\tstruct new_utsname *u;\n\n\t\tadd_device_randomness(tmp, len);\n\t\tdown_write(&uts_sem);\n\t\tu = utsname();\n\t\tmemcpy(u->nodename, tmp, len);\n\t\tmemset(u->nodename + len, 0, sizeof(u->nodename) - len);\n\t\terrno = 0;\n\t\tuts_proc_notify(UTS_PROC_HOSTNAME);\n\t\tup_write(&uts_sem);\n\t}\n\treturn errno;\n}\n\n#ifdef __ARCH_WANT_SYS_GETHOSTNAME\n\nSYSCALL_DEFINE2(gethostname, char __user *, name, int, len)\n{\n\tint i;\n\tstruct new_utsname *u;\n\tchar tmp[__NEW_UTS_LEN + 1];\n\n\tif (len < 0)\n\t\treturn -EINVAL;\n\tdown_read(&uts_sem);\n\tu = utsname();\n\ti = 1 + strlen(u->nodename);\n\tif (i > len)\n\t\ti = len;\n\tmemcpy(tmp, u->nodename, i);\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, tmp, i))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n#endif\n\n/*\n * Only setdomainname; getdomainname can be implemented by calling\n * uname()\n */\nSYSCALL_DEFINE2(setdomainname, char __user *, name, int, len)\n{\n\tint errno;\n\tchar tmp[__NEW_UTS_LEN];\n\n\tif (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\tif (len < 0 || len > __NEW_UTS_LEN)\n\t\treturn -EINVAL;\n\n\terrno = -EFAULT;\n\tif (!copy_from_user(tmp, name, len)) {\n\t\tstruct new_utsname *u;\n\n\t\tadd_device_randomness(tmp, len);\n\t\tdown_write(&uts_sem);\n\t\tu = utsname();\n\t\tmemcpy(u->domainname, tmp, len);\n\t\tmemset(u->domainname + len, 0, sizeof(u->domainname) - len);\n\t\terrno = 0;\n\t\tuts_proc_notify(UTS_PROC_DOMAINNAME);\n\t\tup_write(&uts_sem);\n\t}\n\treturn errno;\n}\n\n/* make sure you are allowed to change @tsk limits before calling this */\nstatic int do_prlimit(struct task_struct *tsk, unsigned int resource,\n\t\t      struct rlimit *new_rlim, struct rlimit *old_rlim)\n{\n\tstruct rlimit *rlim;\n\tint retval = 0;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tif (new_rlim) {\n\t\tif (new_rlim->rlim_cur > new_rlim->rlim_max)\n\t\t\treturn -EINVAL;\n\t\tif (resource == RLIMIT_NOFILE &&\n\t\t\t\tnew_rlim->rlim_max > sysctl_nr_open)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Holding a refcount on tsk protects tsk->signal from disappearing. */\n\trlim = tsk->signal->rlim + resource;\n\ttask_lock(tsk->group_leader);\n\tif (new_rlim) {\n\t\t/*\n\t\t * Keep the capable check against init_user_ns until cgroups can\n\t\t * contain all limits.\n\t\t */\n\t\tif (new_rlim->rlim_max > rlim->rlim_max &&\n\t\t\t\t!capable(CAP_SYS_RESOURCE))\n\t\t\tretval = -EPERM;\n\t\tif (!retval)\n\t\t\tretval = security_task_setrlimit(tsk, resource, new_rlim);\n\t}\n\tif (!retval) {\n\t\tif (old_rlim)\n\t\t\t*old_rlim = *rlim;\n\t\tif (new_rlim)\n\t\t\t*rlim = *new_rlim;\n\t}\n\ttask_unlock(tsk->group_leader);\n\n\t/*\n\t * RLIMIT_CPU handling. Arm the posix CPU timer if the limit is not\n\t * infinite. In case of RLIM_INFINITY the posix CPU timer code\n\t * ignores the rlimit.\n\t */\n\tif (!retval && new_rlim && resource == RLIMIT_CPU &&\n\t    new_rlim->rlim_cur != RLIM_INFINITY &&\n\t    IS_ENABLED(CONFIG_POSIX_TIMERS)) {\n\t\t/*\n\t\t * update_rlimit_cpu can fail if the task is exiting, but there\n\t\t * may be other tasks in the thread group that are not exiting,\n\t\t * and they need their cpu timers adjusted.\n\t\t *\n\t\t * The group_leader is the last task to be released, so if we\n\t\t * cannot update_rlimit_cpu on it, then the entire process is\n\t\t * exiting and we do not need to update at all.\n\t\t */\n\t\tupdate_rlimit_cpu(tsk->group_leader, new_rlim->rlim_cur);\n\t}\n\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(getrlimit, unsigned int, resource, struct rlimit __user *, rlim)\n{\n\tstruct rlimit value;\n\tint ret;\n\n\tret = do_prlimit(current, resource, NULL, &value);\n\tif (!ret)\n\t\tret = copy_to_user(rlim, &value, sizeof(*rlim)) ? -EFAULT : 0;\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\n\nCOMPAT_SYSCALL_DEFINE2(setrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\tstruct compat_rlimit r32;\n\n\tif (copy_from_user(&r32, rlim, sizeof(struct compat_rlimit)))\n\t\treturn -EFAULT;\n\n\tif (r32.rlim_cur == COMPAT_RLIM_INFINITY)\n\t\tr.rlim_cur = RLIM_INFINITY;\n\telse\n\t\tr.rlim_cur = r32.rlim_cur;\n\tif (r32.rlim_max == COMPAT_RLIM_INFINITY)\n\t\tr.rlim_max = RLIM_INFINITY;\n\telse\n\t\tr.rlim_max = r32.rlim_max;\n\treturn do_prlimit(current, resource, &r, NULL);\n}\n\nCOMPAT_SYSCALL_DEFINE2(getrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\tint ret;\n\n\tret = do_prlimit(current, resource, NULL, &r);\n\tif (!ret) {\n\t\tstruct compat_rlimit r32;\n\t\tif (r.rlim_cur > COMPAT_RLIM_INFINITY)\n\t\t\tr32.rlim_cur = COMPAT_RLIM_INFINITY;\n\t\telse\n\t\t\tr32.rlim_cur = r.rlim_cur;\n\t\tif (r.rlim_max > COMPAT_RLIM_INFINITY)\n\t\t\tr32.rlim_max = COMPAT_RLIM_INFINITY;\n\t\telse\n\t\t\tr32.rlim_max = r.rlim_max;\n\n\t\tif (copy_to_user(rlim, &r32, sizeof(struct compat_rlimit)))\n\t\t\treturn -EFAULT;\n\t}\n\treturn ret;\n}\n\n#endif\n\n#ifdef __ARCH_WANT_SYS_OLD_GETRLIMIT\n\n/*\n *\tBack compatibility for getrlimit. Needed for some apps.\n */\nSYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,\n\t\tstruct rlimit __user *, rlim)\n{\n\tstruct rlimit x;\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\ttask_lock(current->group_leader);\n\tx = current->signal->rlim[resource];\n\ttask_unlock(current->group_leader);\n\tif (x.rlim_cur > 0x7FFFFFFF)\n\t\tx.rlim_cur = 0x7FFFFFFF;\n\tif (x.rlim_max > 0x7FFFFFFF)\n\t\tx.rlim_max = 0x7FFFFFFF;\n\treturn copy_to_user(rlim, &x, sizeof(x)) ? -EFAULT : 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\ttask_lock(current->group_leader);\n\tr = current->signal->rlim[resource];\n\ttask_unlock(current->group_leader);\n\tif (r.rlim_cur > 0x7FFFFFFF)\n\t\tr.rlim_cur = 0x7FFFFFFF;\n\tif (r.rlim_max > 0x7FFFFFFF)\n\t\tr.rlim_max = 0x7FFFFFFF;\n\n\tif (put_user(r.rlim_cur, &rlim->rlim_cur) ||\n\t    put_user(r.rlim_max, &rlim->rlim_max))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif\n\n#endif\n\nstatic inline bool rlim64_is_infinity(__u64 rlim64)\n{\n#if BITS_PER_LONG < 64\n\treturn rlim64 >= ULONG_MAX;\n#else\n\treturn rlim64 == RLIM64_INFINITY;\n#endif\n}\n\nstatic void rlim_to_rlim64(const struct rlimit *rlim, struct rlimit64 *rlim64)\n{\n\tif (rlim->rlim_cur == RLIM_INFINITY)\n\t\trlim64->rlim_cur = RLIM64_INFINITY;\n\telse\n\t\trlim64->rlim_cur = rlim->rlim_cur;\n\tif (rlim->rlim_max == RLIM_INFINITY)\n\t\trlim64->rlim_max = RLIM64_INFINITY;\n\telse\n\t\trlim64->rlim_max = rlim->rlim_max;\n}\n\nstatic void rlim64_to_rlim(const struct rlimit64 *rlim64, struct rlimit *rlim)\n{\n\tif (rlim64_is_infinity(rlim64->rlim_cur))\n\t\trlim->rlim_cur = RLIM_INFINITY;\n\telse\n\t\trlim->rlim_cur = (unsigned long)rlim64->rlim_cur;\n\tif (rlim64_is_infinity(rlim64->rlim_max))\n\t\trlim->rlim_max = RLIM_INFINITY;\n\telse\n\t\trlim->rlim_max = (unsigned long)rlim64->rlim_max;\n}\n\n/* rcu lock must be held */\nstatic int check_prlimit_permission(struct task_struct *task,\n\t\t\t\t    unsigned int flags)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\tbool id_match;\n\n\tif (current == task)\n\t\treturn 0;\n\n\ttcred = __task_cred(task);\n\tid_match = (uid_eq(cred->uid, tcred->euid) &&\n\t\t    uid_eq(cred->uid, tcred->suid) &&\n\t\t    uid_eq(cred->uid, tcred->uid)  &&\n\t\t    gid_eq(cred->gid, tcred->egid) &&\n\t\t    gid_eq(cred->gid, tcred->sgid) &&\n\t\t    gid_eq(cred->gid, tcred->gid));\n\tif (!id_match && !ns_capable(tcred->user_ns, CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\n\treturn security_task_prlimit(cred, tcred, flags);\n}\n\nSYSCALL_DEFINE4(prlimit64, pid_t, pid, unsigned int, resource,\n\t\tconst struct rlimit64 __user *, new_rlim,\n\t\tstruct rlimit64 __user *, old_rlim)\n{\n\tstruct rlimit64 old64, new64;\n\tstruct rlimit old, new;\n\tstruct task_struct *tsk;\n\tunsigned int checkflags = 0;\n\tint ret;\n\n\tif (old_rlim)\n\t\tcheckflags |= LSM_PRLIMIT_READ;\n\n\tif (new_rlim) {\n\t\tif (copy_from_user(&new64, new_rlim, sizeof(new64)))\n\t\t\treturn -EFAULT;\n\t\trlim64_to_rlim(&new64, &new);\n\t\tcheckflags |= LSM_PRLIMIT_WRITE;\n\t}\n\n\trcu_read_lock();\n\ttsk = pid ? find_task_by_vpid(pid) : current;\n\tif (!tsk) {\n\t\trcu_read_unlock();\n\t\treturn -ESRCH;\n\t}\n\tret = check_prlimit_permission(tsk, checkflags);\n\tif (ret) {\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\tget_task_struct(tsk);\n\trcu_read_unlock();\n\n\tret = do_prlimit(tsk, resource, new_rlim ? &new : NULL,\n\t\t\told_rlim ? &old : NULL);\n\n\tif (!ret && old_rlim) {\n\t\trlim_to_rlim64(&old, &old64);\n\t\tif (copy_to_user(old_rlim, &old64, sizeof(old64)))\n\t\t\tret = -EFAULT;\n\t}\n\n\tput_task_struct(tsk);\n\treturn ret;\n}\n\nSYSCALL_DEFINE2(setrlimit, unsigned int, resource, struct rlimit __user *, rlim)\n{\n\tstruct rlimit new_rlim;\n\n\tif (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))\n\t\treturn -EFAULT;\n\treturn do_prlimit(current, resource, &new_rlim, NULL);\n}\n\n/*\n * It would make sense to put struct rusage in the task_struct,\n * except that would make the task_struct be *really big*.  After\n * task_struct gets moved into malloc'ed memory, it would\n * make sense to do this.  It will make moving the rest of the information\n * a lot simpler!  (Which we're not doing right now because we're not\n * measuring them yet).\n *\n * When sampling multiple threads for RUSAGE_SELF, under SMP we might have\n * races with threads incrementing their own counters.  But since word\n * reads are atomic, we either get new values or old values and we don't\n * care which for the sums.  We always take the siglock to protect reading\n * the c* fields from p->signal from races with exit.c updating those\n * fields when reaping, so a sample either gets all the additions of a\n * given child after it's reaped, or none so this sample is before reaping.\n *\n * Locking:\n * We need to take the siglock for CHILDEREN, SELF and BOTH\n * for  the cases current multithreaded, non-current single threaded\n * non-current multithreaded.  Thread traversal is now safe with\n * the siglock held.\n * Strictly speaking, we donot need to take the siglock if we are current and\n * single threaded,  as no one else can take our signal_struct away, no one\n * else can  reap the  children to update signal->c* counters, and no one else\n * can race with the signal-> fields. If we do not take any lock, the\n * signal-> fields could be read out of order while another thread was just\n * exiting. So we should  place a read memory barrier when we avoid the lock.\n * On the writer side,  write memory barrier is implied in  __exit_signal\n * as __exit_signal releases  the siglock spinlock after updating the signal->\n * fields. But we don't do this yet to keep things simple.\n *\n */\n\nstatic void accumulate_thread_rusage(struct task_struct *t, struct rusage *r)\n{\n\tr->ru_nvcsw += t->nvcsw;\n\tr->ru_nivcsw += t->nivcsw;\n\tr->ru_minflt += t->min_flt;\n\tr->ru_majflt += t->maj_flt;\n\tr->ru_inblock += task_io_get_inblock(t);\n\tr->ru_oublock += task_io_get_oublock(t);\n}\n\nvoid getrusage(struct task_struct *p, int who, struct rusage *r)\n{\n\tstruct task_struct *t;\n\tunsigned long flags;\n\tu64 tgutime, tgstime, utime, stime;\n\tunsigned long maxrss = 0;\n\n\tmemset((char *)r, 0, sizeof (*r));\n\tutime = stime = 0;\n\n\tif (who == RUSAGE_THREAD) {\n\t\ttask_cputime_adjusted(current, &utime, &stime);\n\t\taccumulate_thread_rusage(p, r);\n\t\tmaxrss = p->signal->maxrss;\n\t\tgoto out;\n\t}\n\n\tif (!lock_task_sighand(p, &flags))\n\t\treturn;\n\n\tswitch (who) {\n\tcase RUSAGE_BOTH:\n\tcase RUSAGE_CHILDREN:\n\t\tutime = p->signal->cutime;\n\t\tstime = p->signal->cstime;\n\t\tr->ru_nvcsw = p->signal->cnvcsw;\n\t\tr->ru_nivcsw = p->signal->cnivcsw;\n\t\tr->ru_minflt = p->signal->cmin_flt;\n\t\tr->ru_majflt = p->signal->cmaj_flt;\n\t\tr->ru_inblock = p->signal->cinblock;\n\t\tr->ru_oublock = p->signal->coublock;\n\t\tmaxrss = p->signal->cmaxrss;\n\n\t\tif (who == RUSAGE_CHILDREN)\n\t\t\tbreak;\n\t\tfallthrough;\n\n\tcase RUSAGE_SELF:\n\t\tthread_group_cputime_adjusted(p, &tgutime, &tgstime);\n\t\tutime += tgutime;\n\t\tstime += tgstime;\n\t\tr->ru_nvcsw += p->signal->nvcsw;\n\t\tr->ru_nivcsw += p->signal->nivcsw;\n\t\tr->ru_minflt += p->signal->min_flt;\n\t\tr->ru_majflt += p->signal->maj_flt;\n\t\tr->ru_inblock += p->signal->inblock;\n\t\tr->ru_oublock += p->signal->oublock;\n\t\tif (maxrss < p->signal->maxrss)\n\t\t\tmaxrss = p->signal->maxrss;\n\t\tt = p;\n\t\tdo {\n\t\t\taccumulate_thread_rusage(t, r);\n\t\t} while_each_thread(p, t);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n\tunlock_task_sighand(p, &flags);\n\nout:\n\tr->ru_utime = ns_to_kernel_old_timeval(utime);\n\tr->ru_stime = ns_to_kernel_old_timeval(stime);\n\n\tif (who != RUSAGE_CHILDREN) {\n\t\tstruct mm_struct *mm = get_task_mm(p);\n\n\t\tif (mm) {\n\t\t\tsetmax_mm_hiwater_rss(&maxrss, mm);\n\t\t\tmmput(mm);\n\t\t}\n\t}\n\tr->ru_maxrss = maxrss * (PAGE_SIZE / 1024); /* convert pages to KBs */\n}\n\nSYSCALL_DEFINE2(getrusage, int, who, struct rusage __user *, ru)\n{\n\tstruct rusage r;\n\n\tif (who != RUSAGE_SELF && who != RUSAGE_CHILDREN &&\n\t    who != RUSAGE_THREAD)\n\t\treturn -EINVAL;\n\n\tgetrusage(current, who, &r);\n\treturn copy_to_user(ru, &r, sizeof(r)) ? -EFAULT : 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(getrusage, int, who, struct compat_rusage __user *, ru)\n{\n\tstruct rusage r;\n\n\tif (who != RUSAGE_SELF && who != RUSAGE_CHILDREN &&\n\t    who != RUSAGE_THREAD)\n\t\treturn -EINVAL;\n\n\tgetrusage(current, who, &r);\n\treturn put_compat_rusage(&r, ru);\n}\n#endif\n\nSYSCALL_DEFINE1(umask, int, mask)\n{\n\tmask = xchg(&current->fs->umask, mask & S_IRWXUGO);\n\treturn mask;\n}\n\nstatic int prctl_set_mm_exe_file(struct mm_struct *mm, unsigned int fd)\n{\n\tstruct fd exe;\n\tstruct inode *inode;\n\tint err;\n\n\texe = fdget(fd);\n\tif (!exe.file)\n\t\treturn -EBADF;\n\n\tinode = file_inode(exe.file);\n\n\t/*\n\t * Because the original mm->exe_file points to executable file, make\n\t * sure that this one is executable as well, to avoid breaking an\n\t * overall picture.\n\t */\n\terr = -EACCES;\n\tif (!S_ISREG(inode->i_mode) || path_noexec(&exe.file->f_path))\n\t\tgoto exit;\n\n\terr = file_permission(exe.file, MAY_EXEC);\n\tif (err)\n\t\tgoto exit;\n\n\terr = replace_mm_exe_file(mm, exe.file);\nexit:\n\tfdput(exe);\n\treturn err;\n}\n\n/*\n * Check arithmetic relations of passed addresses.\n *\n * WARNING: we don't require any capability here so be very careful\n * in what is allowed for modification from userspace.\n */\nstatic int validate_prctl_map_addr(struct prctl_mm_map *prctl_map)\n{\n\tunsigned long mmap_max_addr = TASK_SIZE;\n\tint error = -EINVAL, i;\n\n\tstatic const unsigned char offsets[] = {\n\t\toffsetof(struct prctl_mm_map, start_code),\n\t\toffsetof(struct prctl_mm_map, end_code),\n\t\toffsetof(struct prctl_mm_map, start_data),\n\t\toffsetof(struct prctl_mm_map, end_data),\n\t\toffsetof(struct prctl_mm_map, start_brk),\n\t\toffsetof(struct prctl_mm_map, brk),\n\t\toffsetof(struct prctl_mm_map, start_stack),\n\t\toffsetof(struct prctl_mm_map, arg_start),\n\t\toffsetof(struct prctl_mm_map, arg_end),\n\t\toffsetof(struct prctl_mm_map, env_start),\n\t\toffsetof(struct prctl_mm_map, env_end),\n\t};\n\n\t/*\n\t * Make sure the members are not somewhere outside\n\t * of allowed address space.\n\t */\n\tfor (i = 0; i < ARRAY_SIZE(offsets); i++) {\n\t\tu64 val = *(u64 *)((char *)prctl_map + offsets[i]);\n\n\t\tif ((unsigned long)val >= mmap_max_addr ||\n\t\t    (unsigned long)val < mmap_min_addr)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * Make sure the pairs are ordered.\n\t */\n#define __prctl_check_order(__m1, __op, __m2)\t\t\t\t\\\n\t((unsigned long)prctl_map->__m1 __op\t\t\t\t\\\n\t (unsigned long)prctl_map->__m2) ? 0 : -EINVAL\n\terror  = __prctl_check_order(start_code, <, end_code);\n\terror |= __prctl_check_order(start_data,<=, end_data);\n\terror |= __prctl_check_order(start_brk, <=, brk);\n\terror |= __prctl_check_order(arg_start, <=, arg_end);\n\terror |= __prctl_check_order(env_start, <=, env_end);\n\tif (error)\n\t\tgoto out;\n#undef __prctl_check_order\n\n\terror = -EINVAL;\n\n\t/*\n\t * Neither we should allow to override limits if they set.\n\t */\n\tif (check_data_rlimit(rlimit(RLIMIT_DATA), prctl_map->brk,\n\t\t\t      prctl_map->start_brk, prctl_map->end_data,\n\t\t\t      prctl_map->start_data))\n\t\t\tgoto out;\n\n\terror = 0;\nout:\n\treturn error;\n}\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\nstatic int prctl_set_mm_map(int opt, const void __user *addr, unsigned long data_size)\n{\n\tstruct prctl_mm_map prctl_map = { .exe_fd = (u32)-1, };\n\tunsigned long user_auxv[AT_VECTOR_SIZE];\n\tstruct mm_struct *mm = current->mm;\n\tint error;\n\n\tBUILD_BUG_ON(sizeof(user_auxv) != sizeof(mm->saved_auxv));\n\tBUILD_BUG_ON(sizeof(struct prctl_mm_map) > 256);\n\n\tif (opt == PR_SET_MM_MAP_SIZE)\n\t\treturn put_user((unsigned int)sizeof(prctl_map),\n\t\t\t\t(unsigned int __user *)addr);\n\n\tif (data_size != sizeof(prctl_map))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&prctl_map, addr, sizeof(prctl_map)))\n\t\treturn -EFAULT;\n\n\terror = validate_prctl_map_addr(&prctl_map);\n\tif (error)\n\t\treturn error;\n\n\tif (prctl_map.auxv_size) {\n\t\t/*\n\t\t * Someone is trying to cheat the auxv vector.\n\t\t */\n\t\tif (!prctl_map.auxv ||\n\t\t\t\tprctl_map.auxv_size > sizeof(mm->saved_auxv))\n\t\t\treturn -EINVAL;\n\n\t\tmemset(user_auxv, 0, sizeof(user_auxv));\n\t\tif (copy_from_user(user_auxv,\n\t\t\t\t   (const void __user *)prctl_map.auxv,\n\t\t\t\t   prctl_map.auxv_size))\n\t\t\treturn -EFAULT;\n\n\t\t/* Last entry must be AT_NULL as specification requires */\n\t\tuser_auxv[AT_VECTOR_SIZE - 2] = AT_NULL;\n\t\tuser_auxv[AT_VECTOR_SIZE - 1] = AT_NULL;\n\t}\n\n\tif (prctl_map.exe_fd != (u32)-1) {\n\t\t/*\n\t\t * Check if the current user is checkpoint/restore capable.\n\t\t * At the time of this writing, it checks for CAP_SYS_ADMIN\n\t\t * or CAP_CHECKPOINT_RESTORE.\n\t\t * Note that a user with access to ptrace can masquerade an\n\t\t * arbitrary program as any executable, even setuid ones.\n\t\t * This may have implications in the tomoyo subsystem.\n\t\t */\n\t\tif (!checkpoint_restore_ns_capable(current_user_ns()))\n\t\t\treturn -EPERM;\n\n\t\terror = prctl_set_mm_exe_file(mm, prctl_map.exe_fd);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\t/*\n\t * arg_lock protects concurrent updates but we still need mmap_lock for\n\t * read to exclude races with sys_brk.\n\t */\n\tmmap_read_lock(mm);\n\n\t/*\n\t * We don't validate if these members are pointing to\n\t * real present VMAs because application may have correspond\n\t * VMAs already unmapped and kernel uses these members for statistics\n\t * output in procfs mostly, except\n\t *\n\t *  - @start_brk/@brk which are used in do_brk_flags but kernel lookups\n\t *    for VMAs when updating these members so anything wrong written\n\t *    here cause kernel to swear at userspace program but won't lead\n\t *    to any problem in kernel itself\n\t */\n\n\tspin_lock(&mm->arg_lock);\n\tmm->start_code\t= prctl_map.start_code;\n\tmm->end_code\t= prctl_map.end_code;\n\tmm->start_data\t= prctl_map.start_data;\n\tmm->end_data\t= prctl_map.end_data;\n\tmm->start_brk\t= prctl_map.start_brk;\n\tmm->brk\t\t= prctl_map.brk;\n\tmm->start_stack\t= prctl_map.start_stack;\n\tmm->arg_start\t= prctl_map.arg_start;\n\tmm->arg_end\t= prctl_map.arg_end;\n\tmm->env_start\t= prctl_map.env_start;\n\tmm->env_end\t= prctl_map.env_end;\n\tspin_unlock(&mm->arg_lock);\n\n\t/*\n\t * Note this update of @saved_auxv is lockless thus\n\t * if someone reads this member in procfs while we're\n\t * updating -- it may get partly updated results. It's\n\t * known and acceptable trade off: we leave it as is to\n\t * not introduce additional locks here making the kernel\n\t * more complex.\n\t */\n\tif (prctl_map.auxv_size)\n\t\tmemcpy(mm->saved_auxv, user_auxv, sizeof(user_auxv));\n\n\tmmap_read_unlock(mm);\n\treturn 0;\n}\n#endif /* CONFIG_CHECKPOINT_RESTORE */\n\nstatic int prctl_set_auxv(struct mm_struct *mm, unsigned long addr,\n\t\t\t  unsigned long len)\n{\n\t/*\n\t * This doesn't move the auxiliary vector itself since it's pinned to\n\t * mm_struct, but it permits filling the vector with new values.  It's\n\t * up to the caller to provide sane values here, otherwise userspace\n\t * tools which use this vector might be unhappy.\n\t */\n\tunsigned long user_auxv[AT_VECTOR_SIZE] = {};\n\n\tif (len > sizeof(user_auxv))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(user_auxv, (const void __user *)addr, len))\n\t\treturn -EFAULT;\n\n\t/* Make sure the last entry is always AT_NULL */\n\tuser_auxv[AT_VECTOR_SIZE - 2] = 0;\n\tuser_auxv[AT_VECTOR_SIZE - 1] = 0;\n\n\tBUILD_BUG_ON(sizeof(user_auxv) != sizeof(mm->saved_auxv));\n\n\ttask_lock(current);\n\tmemcpy(mm->saved_auxv, user_auxv, len);\n\ttask_unlock(current);\n\n\treturn 0;\n}\n\nstatic int prctl_set_mm(int opt, unsigned long addr,\n\t\t\tunsigned long arg4, unsigned long arg5)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct prctl_mm_map prctl_map = {\n\t\t.auxv = NULL,\n\t\t.auxv_size = 0,\n\t\t.exe_fd = -1,\n\t};\n\tstruct vm_area_struct *vma;\n\tint error;\n\n\tif (arg5 || (arg4 && (opt != PR_SET_MM_AUXV &&\n\t\t\t      opt != PR_SET_MM_MAP &&\n\t\t\t      opt != PR_SET_MM_MAP_SIZE)))\n\t\treturn -EINVAL;\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\n\tif (opt == PR_SET_MM_MAP || opt == PR_SET_MM_MAP_SIZE)\n\t\treturn prctl_set_mm_map(opt, (const void __user *)addr, arg4);\n#endif\n\n\tif (!capable(CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\n\tif (opt == PR_SET_MM_EXE_FILE)\n\t\treturn prctl_set_mm_exe_file(mm, (unsigned int)addr);\n\n\tif (opt == PR_SET_MM_AUXV)\n\t\treturn prctl_set_auxv(mm, addr, arg4);\n\n\tif (addr >= TASK_SIZE || addr < mmap_min_addr)\n\t\treturn -EINVAL;\n\n\terror = -EINVAL;\n\n\t/*\n\t * arg_lock protects concurrent updates of arg boundaries, we need\n\t * mmap_lock for a) concurrent sys_brk, b) finding VMA for addr\n\t * validation.\n\t */\n\tmmap_read_lock(mm);\n\tvma = find_vma(mm, addr);\n\n\tspin_lock(&mm->arg_lock);\n\tprctl_map.start_code\t= mm->start_code;\n\tprctl_map.end_code\t= mm->end_code;\n\tprctl_map.start_data\t= mm->start_data;\n\tprctl_map.end_data\t= mm->end_data;\n\tprctl_map.start_brk\t= mm->start_brk;\n\tprctl_map.brk\t\t= mm->brk;\n\tprctl_map.start_stack\t= mm->start_stack;\n\tprctl_map.arg_start\t= mm->arg_start;\n\tprctl_map.arg_end\t= mm->arg_end;\n\tprctl_map.env_start\t= mm->env_start;\n\tprctl_map.env_end\t= mm->env_end;\n\n\tswitch (opt) {\n\tcase PR_SET_MM_START_CODE:\n\t\tprctl_map.start_code = addr;\n\t\tbreak;\n\tcase PR_SET_MM_END_CODE:\n\t\tprctl_map.end_code = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_DATA:\n\t\tprctl_map.start_data = addr;\n\t\tbreak;\n\tcase PR_SET_MM_END_DATA:\n\t\tprctl_map.end_data = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_STACK:\n\t\tprctl_map.start_stack = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_BRK:\n\t\tprctl_map.start_brk = addr;\n\t\tbreak;\n\tcase PR_SET_MM_BRK:\n\t\tprctl_map.brk = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ARG_START:\n\t\tprctl_map.arg_start = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ARG_END:\n\t\tprctl_map.arg_end = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ENV_START:\n\t\tprctl_map.env_start = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ENV_END:\n\t\tprctl_map.env_end = addr;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\terror = validate_prctl_map_addr(&prctl_map);\n\tif (error)\n\t\tgoto out;\n\n\tswitch (opt) {\n\t/*\n\t * If command line arguments and environment\n\t * are placed somewhere else on stack, we can\n\t * set them up here, ARG_START/END to setup\n\t * command line arguments and ENV_START/END\n\t * for environment.\n\t */\n\tcase PR_SET_MM_START_STACK:\n\tcase PR_SET_MM_ARG_START:\n\tcase PR_SET_MM_ARG_END:\n\tcase PR_SET_MM_ENV_START:\n\tcase PR_SET_MM_ENV_END:\n\t\tif (!vma) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmm->start_code\t= prctl_map.start_code;\n\tmm->end_code\t= prctl_map.end_code;\n\tmm->start_data\t= prctl_map.start_data;\n\tmm->end_data\t= prctl_map.end_data;\n\tmm->start_brk\t= prctl_map.start_brk;\n\tmm->brk\t\t= prctl_map.brk;\n\tmm->start_stack\t= prctl_map.start_stack;\n\tmm->arg_start\t= prctl_map.arg_start;\n\tmm->arg_end\t= prctl_map.arg_end;\n\tmm->env_start\t= prctl_map.env_start;\n\tmm->env_end\t= prctl_map.env_end;\n\n\terror = 0;\nout:\n\tspin_unlock(&mm->arg_lock);\n\tmmap_read_unlock(mm);\n\treturn error;\n}\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\nstatic int prctl_get_tid_address(struct task_struct *me, int __user * __user *tid_addr)\n{\n\treturn put_user(me->clear_child_tid, tid_addr);\n}\n#else\nstatic int prctl_get_tid_address(struct task_struct *me, int __user * __user *tid_addr)\n{\n\treturn -EINVAL;\n}\n#endif\n\nstatic int propagate_has_child_subreaper(struct task_struct *p, void *data)\n{\n\t/*\n\t * If task has has_child_subreaper - all its descendants\n\t * already have these flag too and new descendants will\n\t * inherit it on fork, skip them.\n\t *\n\t * If we've found child_reaper - skip descendants in\n\t * it's subtree as they will never get out pidns.\n\t */\n\tif (p->signal->has_child_subreaper ||\n\t    is_child_reaper(task_pid(p)))\n\t\treturn 0;\n\n\tp->signal->has_child_subreaper = 1;\n\treturn 1;\n}\n\nint __weak arch_prctl_spec_ctrl_get(struct task_struct *t, unsigned long which)\n{\n\treturn -EINVAL;\n}\n\nint __weak arch_prctl_spec_ctrl_set(struct task_struct *t, unsigned long which,\n\t\t\t\t    unsigned long ctrl)\n{\n\treturn -EINVAL;\n}\n\n#define PR_IO_FLUSHER (PF_MEMALLOC_NOIO | PF_LOCAL_THROTTLE)\n\n#ifdef CONFIG_ANON_VMA_NAME\n\n#define ANON_VMA_NAME_MAX_LEN\t\t80\n#define ANON_VMA_NAME_INVALID_CHARS\t\"\\\\`$[]\"\n\nstatic inline bool is_valid_name_char(char ch)\n{\n\t/* printable ascii characters, excluding ANON_VMA_NAME_INVALID_CHARS */\n\treturn ch > 0x1f && ch < 0x7f &&\n\t\t!strchr(ANON_VMA_NAME_INVALID_CHARS, ch);\n}\n\nstatic int prctl_set_vma(unsigned long opt, unsigned long addr,\n\t\t\t unsigned long size, unsigned long arg)\n{\n\tstruct mm_struct *mm = current->mm;\n\tconst char __user *uname;\n\tstruct anon_vma_name *anon_name = NULL;\n\tint error;\n\n\tswitch (opt) {\n\tcase PR_SET_VMA_ANON_NAME:\n\t\tuname = (const char __user *)arg;\n\t\tif (uname) {\n\t\t\tchar *name, *pch;\n\n\t\t\tname = strndup_user(uname, ANON_VMA_NAME_MAX_LEN);\n\t\t\tif (IS_ERR(name))\n\t\t\t\treturn PTR_ERR(name);\n\n\t\t\tfor (pch = name; *pch != '\\0'; pch++) {\n\t\t\t\tif (!is_valid_name_char(*pch)) {\n\t\t\t\t\tkfree(name);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* anon_vma has its own copy */\n\t\t\tanon_name = anon_vma_name_alloc(name);\n\t\t\tkfree(name);\n\t\t\tif (!anon_name)\n\t\t\t\treturn -ENOMEM;\n\n\t\t}\n\n\t\tmmap_write_lock(mm);\n\t\terror = madvise_set_anon_name(mm, addr, size, anon_name);\n\t\tmmap_write_unlock(mm);\n\t\tanon_vma_name_put(anon_name);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t}\n\n\treturn error;\n}\n\n#else /* CONFIG_ANON_VMA_NAME */\nstatic int prctl_set_vma(unsigned long opt, unsigned long start,\n\t\t\t unsigned long size, unsigned long arg)\n{\n\treturn -EINVAL;\n}\n#endif /* CONFIG_ANON_VMA_NAME */\n\nSYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,\n\t\tunsigned long, arg4, unsigned long, arg5)\n{\n\tstruct task_struct *me = current;\n\tunsigned char comm[sizeof(me->comm)];\n\tlong error;\n\n\terror = security_task_prctl(option, arg2, arg3, arg4, arg5);\n\tif (error != -ENOSYS)\n\t\treturn error;\n\n\terror = 0;\n\tswitch (option) {\n\tcase PR_SET_PDEATHSIG:\n\t\tif (!valid_signal(arg2)) {\n\t\t\terror = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tme->pdeath_signal = arg2;\n\t\tbreak;\n\tcase PR_GET_PDEATHSIG:\n\t\terror = put_user(me->pdeath_signal, (int __user *)arg2);\n\t\tbreak;\n\tcase PR_GET_DUMPABLE:\n\t\terror = get_dumpable(me->mm);\n\t\tbreak;\n\tcase PR_SET_DUMPABLE:\n\t\tif (arg2 != SUID_DUMP_DISABLE && arg2 != SUID_DUMP_USER) {\n\t\t\terror = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tset_dumpable(me->mm, arg2);\n\t\tbreak;\n\n\tcase PR_SET_UNALIGN:\n\t\terror = SET_UNALIGN_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_UNALIGN:\n\t\terror = GET_UNALIGN_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_SET_FPEMU:\n\t\terror = SET_FPEMU_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FPEMU:\n\t\terror = GET_FPEMU_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_SET_FPEXC:\n\t\terror = SET_FPEXC_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FPEXC:\n\t\terror = GET_FPEXC_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_TIMING:\n\t\terror = PR_TIMING_STATISTICAL;\n\t\tbreak;\n\tcase PR_SET_TIMING:\n\t\tif (arg2 != PR_TIMING_STATISTICAL)\n\t\t\terror = -EINVAL;\n\t\tbreak;\n\tcase PR_SET_NAME:\n\t\tcomm[sizeof(me->comm) - 1] = 0;\n\t\tif (strncpy_from_user(comm, (char __user *)arg2,\n\t\t\t\t      sizeof(me->comm) - 1) < 0)\n\t\t\treturn -EFAULT;\n\t\tset_task_comm(me, comm);\n\t\tproc_comm_connector(me);\n\t\tbreak;\n\tcase PR_GET_NAME:\n\t\tget_task_comm(comm, me);\n\t\tif (copy_to_user((char __user *)arg2, comm, sizeof(comm)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tcase PR_GET_ENDIAN:\n\t\terror = GET_ENDIAN(me, arg2);\n\t\tbreak;\n\tcase PR_SET_ENDIAN:\n\t\terror = SET_ENDIAN(me, arg2);\n\t\tbreak;\n\tcase PR_GET_SECCOMP:\n\t\terror = prctl_get_seccomp();\n\t\tbreak;\n\tcase PR_SET_SECCOMP:\n\t\terror = prctl_set_seccomp(arg2, (char __user *)arg3);\n\t\tbreak;\n\tcase PR_GET_TSC:\n\t\terror = GET_TSC_CTL(arg2);\n\t\tbreak;\n\tcase PR_SET_TSC:\n\t\terror = SET_TSC_CTL(arg2);\n\t\tbreak;\n\tcase PR_TASK_PERF_EVENTS_DISABLE:\n\t\terror = perf_event_task_disable();\n\t\tbreak;\n\tcase PR_TASK_PERF_EVENTS_ENABLE:\n\t\terror = perf_event_task_enable();\n\t\tbreak;\n\tcase PR_GET_TIMERSLACK:\n\t\tif (current->timer_slack_ns > ULONG_MAX)\n\t\t\terror = ULONG_MAX;\n\t\telse\n\t\t\terror = current->timer_slack_ns;\n\t\tbreak;\n\tcase PR_SET_TIMERSLACK:\n\t\tif (arg2 <= 0)\n\t\t\tcurrent->timer_slack_ns =\n\t\t\t\t\tcurrent->default_timer_slack_ns;\n\t\telse\n\t\t\tcurrent->timer_slack_ns = arg2;\n\t\tbreak;\n\tcase PR_MCE_KILL:\n\t\tif (arg4 | arg5)\n\t\t\treturn -EINVAL;\n\t\tswitch (arg2) {\n\t\tcase PR_MCE_KILL_CLEAR:\n\t\t\tif (arg3 != 0)\n\t\t\t\treturn -EINVAL;\n\t\t\tcurrent->flags &= ~PF_MCE_PROCESS;\n\t\t\tbreak;\n\t\tcase PR_MCE_KILL_SET:\n\t\t\tcurrent->flags |= PF_MCE_PROCESS;\n\t\t\tif (arg3 == PR_MCE_KILL_EARLY)\n\t\t\t\tcurrent->flags |= PF_MCE_EARLY;\n\t\t\telse if (arg3 == PR_MCE_KILL_LATE)\n\t\t\t\tcurrent->flags &= ~PF_MCE_EARLY;\n\t\t\telse if (arg3 == PR_MCE_KILL_DEFAULT)\n\t\t\t\tcurrent->flags &=\n\t\t\t\t\t\t~(PF_MCE_EARLY|PF_MCE_PROCESS);\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase PR_MCE_KILL_GET:\n\t\tif (arg2 | arg3 | arg4 | arg5)\n\t\t\treturn -EINVAL;\n\t\tif (current->flags & PF_MCE_PROCESS)\n\t\t\terror = (current->flags & PF_MCE_EARLY) ?\n\t\t\t\tPR_MCE_KILL_EARLY : PR_MCE_KILL_LATE;\n\t\telse\n\t\t\terror = PR_MCE_KILL_DEFAULT;\n\t\tbreak;\n\tcase PR_SET_MM:\n\t\terror = prctl_set_mm(arg2, arg3, arg4, arg5);\n\t\tbreak;\n\tcase PR_GET_TID_ADDRESS:\n\t\terror = prctl_get_tid_address(me, (int __user * __user *)arg2);\n\t\tbreak;\n\tcase PR_SET_CHILD_SUBREAPER:\n\t\tme->signal->is_child_subreaper = !!arg2;\n\t\tif (!arg2)\n\t\t\tbreak;\n\n\t\twalk_process_tree(me, propagate_has_child_subreaper, NULL);\n\t\tbreak;\n\tcase PR_GET_CHILD_SUBREAPER:\n\t\terror = put_user(me->signal->is_child_subreaper,\n\t\t\t\t (int __user *)arg2);\n\t\tbreak;\n\tcase PR_SET_NO_NEW_PRIVS:\n\t\tif (arg2 != 1 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\ttask_set_no_new_privs(current);\n\t\tbreak;\n\tcase PR_GET_NO_NEW_PRIVS:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\treturn task_no_new_privs(current) ? 1 : 0;\n\tcase PR_GET_THP_DISABLE:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = !!test_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\tbreak;\n\tcase PR_SET_THP_DISABLE:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\tif (mmap_write_lock_killable(me->mm))\n\t\t\treturn -EINTR;\n\t\tif (arg2)\n\t\t\tset_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\telse\n\t\t\tclear_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\tmmap_write_unlock(me->mm);\n\t\tbreak;\n\tcase PR_MPX_ENABLE_MANAGEMENT:\n\tcase PR_MPX_DISABLE_MANAGEMENT:\n\t\t/* No longer implemented: */\n\t\treturn -EINVAL;\n\tcase PR_SET_FP_MODE:\n\t\terror = SET_FP_MODE(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FP_MODE:\n\t\terror = GET_FP_MODE(me);\n\t\tbreak;\n\tcase PR_SVE_SET_VL:\n\t\terror = SVE_SET_VL(arg2);\n\t\tbreak;\n\tcase PR_SVE_GET_VL:\n\t\terror = SVE_GET_VL();\n\t\tbreak;\n\tcase PR_SME_SET_VL:\n\t\terror = SME_SET_VL(arg2);\n\t\tbreak;\n\tcase PR_SME_GET_VL:\n\t\terror = SME_GET_VL();\n\t\tbreak;\n\tcase PR_GET_SPECULATION_CTRL:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = arch_prctl_spec_ctrl_get(me, arg2);\n\t\tbreak;\n\tcase PR_SET_SPECULATION_CTRL:\n\t\tif (arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = arch_prctl_spec_ctrl_set(me, arg2, arg3);\n\t\tbreak;\n\tcase PR_PAC_RESET_KEYS:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_RESET_KEYS(me, arg2);\n\t\tbreak;\n\tcase PR_PAC_SET_ENABLED_KEYS:\n\t\tif (arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_SET_ENABLED_KEYS(me, arg2, arg3);\n\t\tbreak;\n\tcase PR_PAC_GET_ENABLED_KEYS:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_GET_ENABLED_KEYS(me);\n\t\tbreak;\n\tcase PR_SET_TAGGED_ADDR_CTRL:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = SET_TAGGED_ADDR_CTRL(arg2);\n\t\tbreak;\n\tcase PR_GET_TAGGED_ADDR_CTRL:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = GET_TAGGED_ADDR_CTRL();\n\t\tbreak;\n\tcase PR_SET_IO_FLUSHER:\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\tif (arg2 == 1)\n\t\t\tcurrent->flags |= PR_IO_FLUSHER;\n\t\telse if (!arg2)\n\t\t\tcurrent->flags &= ~PR_IO_FLUSHER;\n\t\telse\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase PR_GET_IO_FLUSHER:\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\terror = (current->flags & PR_IO_FLUSHER) == PR_IO_FLUSHER;\n\t\tbreak;\n\tcase PR_SET_SYSCALL_USER_DISPATCH:\n\t\terror = set_syscall_user_dispatch(arg2, arg3, arg4,\n\t\t\t\t\t\t  (char __user *) arg5);\n\t\tbreak;\n#ifdef CONFIG_SCHED_CORE\n\tcase PR_SCHED_CORE:\n\t\terror = sched_core_share_pid(arg2, arg3, arg4, arg5);\n\t\tbreak;\n#endif\n\tcase PR_SET_VMA:\n\t\terror = prctl_set_vma(arg2, arg3, arg4, arg5);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE3(getcpu, unsigned __user *, cpup, unsigned __user *, nodep,\n\t\tstruct getcpu_cache __user *, unused)\n{\n\tint err = 0;\n\tint cpu = raw_smp_processor_id();\n\n\tif (cpup)\n\t\terr |= put_user(cpu, cpup);\n\tif (nodep)\n\t\terr |= put_user(cpu_to_node(cpu), nodep);\n\treturn err ? -EFAULT : 0;\n}\n\n/**\n * do_sysinfo - fill in sysinfo struct\n * @info: pointer to buffer to fill\n */\nstatic int do_sysinfo(struct sysinfo *info)\n{\n\tunsigned long mem_total, sav_total;\n\tunsigned int mem_unit, bitcount;\n\tstruct timespec64 tp;\n\n\tmemset(info, 0, sizeof(struct sysinfo));\n\n\tktime_get_boottime_ts64(&tp);\n\ttimens_add_boottime(&tp);\n\tinfo->uptime = tp.tv_sec + (tp.tv_nsec ? 1 : 0);\n\n\tget_avenrun(info->loads, 0, SI_LOAD_SHIFT - FSHIFT);\n\n\tinfo->procs = nr_threads;\n\n\tsi_meminfo(info);\n\tsi_swapinfo(info);\n\n\t/*\n\t * If the sum of all the available memory (i.e. ram + swap)\n\t * is less than can be stored in a 32 bit unsigned long then\n\t * we can be binary compatible with 2.2.x kernels.  If not,\n\t * well, in that case 2.2.x was broken anyways...\n\t *\n\t *  -Erik Andersen <andersee@debian.org>\n\t */\n\n\tmem_total = info->totalram + info->totalswap;\n\tif (mem_total < info->totalram || mem_total < info->totalswap)\n\t\tgoto out;\n\tbitcount = 0;\n\tmem_unit = info->mem_unit;\n\twhile (mem_unit > 1) {\n\t\tbitcount++;\n\t\tmem_unit >>= 1;\n\t\tsav_total = mem_total;\n\t\tmem_total <<= 1;\n\t\tif (mem_total < sav_total)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * If mem_total did not overflow, multiply all memory values by\n\t * info->mem_unit and set it to 1.  This leaves things compatible\n\t * with 2.2.x, and also retains compatibility with earlier 2.4.x\n\t * kernels...\n\t */\n\n\tinfo->mem_unit = 1;\n\tinfo->totalram <<= bitcount;\n\tinfo->freeram <<= bitcount;\n\tinfo->sharedram <<= bitcount;\n\tinfo->bufferram <<= bitcount;\n\tinfo->totalswap <<= bitcount;\n\tinfo->freeswap <<= bitcount;\n\tinfo->totalhigh <<= bitcount;\n\tinfo->freehigh <<= bitcount;\n\nout:\n\treturn 0;\n}\n\nSYSCALL_DEFINE1(sysinfo, struct sysinfo __user *, info)\n{\n\tstruct sysinfo val;\n\n\tdo_sysinfo(&val);\n\n\tif (copy_to_user(info, &val, sizeof(struct sysinfo)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_sysinfo {\n\ts32 uptime;\n\tu32 loads[3];\n\tu32 totalram;\n\tu32 freeram;\n\tu32 sharedram;\n\tu32 bufferram;\n\tu32 totalswap;\n\tu32 freeswap;\n\tu16 procs;\n\tu16 pad;\n\tu32 totalhigh;\n\tu32 freehigh;\n\tu32 mem_unit;\n\tchar _f[20-2*sizeof(u32)-sizeof(int)];\n};\n\nCOMPAT_SYSCALL_DEFINE1(sysinfo, struct compat_sysinfo __user *, info)\n{\n\tstruct sysinfo s;\n\tstruct compat_sysinfo s_32;\n\n\tdo_sysinfo(&s);\n\n\t/* Check to see if any memory value is too large for 32-bit and scale\n\t *  down if needed\n\t */\n\tif (upper_32_bits(s.totalram) || upper_32_bits(s.totalswap)) {\n\t\tint bitcount = 0;\n\n\t\twhile (s.mem_unit < PAGE_SIZE) {\n\t\t\ts.mem_unit <<= 1;\n\t\t\tbitcount++;\n\t\t}\n\n\t\ts.totalram >>= bitcount;\n\t\ts.freeram >>= bitcount;\n\t\ts.sharedram >>= bitcount;\n\t\ts.bufferram >>= bitcount;\n\t\ts.totalswap >>= bitcount;\n\t\ts.freeswap >>= bitcount;\n\t\ts.totalhigh >>= bitcount;\n\t\ts.freehigh >>= bitcount;\n\t}\n\n\tmemset(&s_32, 0, sizeof(s_32));\n\ts_32.uptime = s.uptime;\n\ts_32.loads[0] = s.loads[0];\n\ts_32.loads[1] = s.loads[1];\n\ts_32.loads[2] = s.loads[2];\n\ts_32.totalram = s.totalram;\n\ts_32.freeram = s.freeram;\n\ts_32.sharedram = s.sharedram;\n\ts_32.bufferram = s.bufferram;\n\ts_32.totalswap = s.totalswap;\n\ts_32.freeswap = s.freeswap;\n\ts_32.procs = s.procs;\n\ts_32.totalhigh = s.totalhigh;\n\ts_32.freehigh = s.freehigh;\n\ts_32.mem_unit = s.mem_unit;\n\tif (copy_to_user(info, &s_32, sizeof(s_32)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif /* CONFIG_COMPAT */\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n/*\n *  linux/kernel/sys.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n */\n\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/mm_inline.h>\n#include <linux/utsname.h>\n#include <linux/mman.h>\n#include <linux/reboot.h>\n#include <linux/prctl.h>\n#include <linux/highuid.h>\n#include <linux/fs.h>\n#include <linux/kmod.h>\n#include <linux/perf_event.h>\n#include <linux/resource.h>\n#include <linux/kernel.h>\n#include <linux/workqueue.h>\n#include <linux/capability.h>\n#include <linux/device.h>\n#include <linux/key.h>\n#include <linux/times.h>\n#include <linux/posix-timers.h>\n#include <linux/security.h>\n#include <linux/random.h>\n#include <linux/suspend.h>\n#include <linux/tty.h>\n#include <linux/signal.h>\n#include <linux/cn_proc.h>\n#include <linux/getcpu.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/seccomp.h>\n#include <linux/cpu.h>\n#include <linux/personality.h>\n#include <linux/ptrace.h>\n#include <linux/fs_struct.h>\n#include <linux/file.h>\n#include <linux/mount.h>\n#include <linux/gfp.h>\n#include <linux/syscore_ops.h>\n#include <linux/version.h>\n#include <linux/ctype.h>\n#include <linux/syscall_user_dispatch.h>\n\n#include <linux/compat.h>\n#include <linux/syscalls.h>\n#include <linux/kprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/time_namespace.h>\n#include <linux/binfmts.h>\n\n#include <linux/sched.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/task.h>\n#include <linux/sched/cputime.h>\n#include <linux/rcupdate.h>\n#include <linux/uidgid.h>\n#include <linux/cred.h>\n\n#include <linux/nospec.h>\n\n#include <linux/kmsg_dump.h>\n/* Move somewhere else to avoid recompiling? */\n#include <generated/utsrelease.h>\n\n#include <linux/uaccess.h>\n#include <asm/io.h>\n#include <asm/unistd.h>\n\n#include \"uid16.h\"\n\n#ifndef SET_UNALIGN_CTL\n# define SET_UNALIGN_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_UNALIGN_CTL\n# define GET_UNALIGN_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_FPEMU_CTL\n# define SET_FPEMU_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_FPEMU_CTL\n# define GET_FPEMU_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_FPEXC_CTL\n# define SET_FPEXC_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_FPEXC_CTL\n# define GET_FPEXC_CTL(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_ENDIAN\n# define GET_ENDIAN(a, b)\t(-EINVAL)\n#endif\n#ifndef SET_ENDIAN\n# define SET_ENDIAN(a, b)\t(-EINVAL)\n#endif\n#ifndef GET_TSC_CTL\n# define GET_TSC_CTL(a)\t\t(-EINVAL)\n#endif\n#ifndef SET_TSC_CTL\n# define SET_TSC_CTL(a)\t\t(-EINVAL)\n#endif\n#ifndef GET_FP_MODE\n# define GET_FP_MODE(a)\t\t(-EINVAL)\n#endif\n#ifndef SET_FP_MODE\n# define SET_FP_MODE(a,b)\t(-EINVAL)\n#endif\n#ifndef SVE_SET_VL\n# define SVE_SET_VL(a)\t\t(-EINVAL)\n#endif\n#ifndef SVE_GET_VL\n# define SVE_GET_VL()\t\t(-EINVAL)\n#endif\n#ifndef SME_SET_VL\n# define SME_SET_VL(a)\t\t(-EINVAL)\n#endif\n#ifndef SME_GET_VL\n# define SME_GET_VL()\t\t(-EINVAL)\n#endif\n#ifndef PAC_RESET_KEYS\n# define PAC_RESET_KEYS(a, b)\t(-EINVAL)\n#endif\n#ifndef PAC_SET_ENABLED_KEYS\n# define PAC_SET_ENABLED_KEYS(a, b, c)\t(-EINVAL)\n#endif\n#ifndef PAC_GET_ENABLED_KEYS\n# define PAC_GET_ENABLED_KEYS(a)\t(-EINVAL)\n#endif\n#ifndef SET_TAGGED_ADDR_CTRL\n# define SET_TAGGED_ADDR_CTRL(a)\t(-EINVAL)\n#endif\n#ifndef GET_TAGGED_ADDR_CTRL\n# define GET_TAGGED_ADDR_CTRL()\t\t(-EINVAL)\n#endif\n\n/*\n * this is where the system-wide overflow UID and GID are defined, for\n * architectures that now have 32-bit UID/GID but didn't in the past\n */\n\nint overflowuid = DEFAULT_OVERFLOWUID;\nint overflowgid = DEFAULT_OVERFLOWGID;\n\nEXPORT_SYMBOL(overflowuid);\nEXPORT_SYMBOL(overflowgid);\n\n/*\n * the same as above, but for filesystems which can only store a 16-bit\n * UID and GID. as such, this is needed on all architectures\n */\n\nint fs_overflowuid = DEFAULT_FS_OVERFLOWUID;\nint fs_overflowgid = DEFAULT_FS_OVERFLOWGID;\n\nEXPORT_SYMBOL(fs_overflowuid);\nEXPORT_SYMBOL(fs_overflowgid);\n\n/*\n * Returns true if current's euid is same as p's uid or euid,\n * or has CAP_SYS_NICE to p's user_ns.\n *\n * Called with rcu_read_lock, creds are safe\n */\nstatic bool set_one_prio_perm(struct task_struct *p)\n{\n\tconst struct cred *cred = current_cred(), *pcred = __task_cred(p);\n\n\tif (uid_eq(pcred->uid,  cred->euid) ||\n\t    uid_eq(pcred->euid, cred->euid))\n\t\treturn true;\n\tif (ns_capable(pcred->user_ns, CAP_SYS_NICE))\n\t\treturn true;\n\treturn false;\n}\n\n/*\n * set the priority of a task\n * - the caller must hold the RCU read lock\n */\nstatic int set_one_prio(struct task_struct *p, int niceval, int error)\n{\n\tint no_nice;\n\n\tif (!set_one_prio_perm(p)) {\n\t\terror = -EPERM;\n\t\tgoto out;\n\t}\n\tif (niceval < task_nice(p) && !can_nice(p, niceval)) {\n\t\terror = -EACCES;\n\t\tgoto out;\n\t}\n\tno_nice = security_task_setnice(p, niceval);\n\tif (no_nice) {\n\t\terror = no_nice;\n\t\tgoto out;\n\t}\n\tif (error == -ESRCH)\n\t\terror = 0;\n\tset_user_nice(p, niceval);\nout:\n\treturn error;\n}\n\nSYSCALL_DEFINE3(setpriority, int, which, int, who, int, niceval)\n{\n\tstruct task_struct *g, *p;\n\tstruct user_struct *user;\n\tconst struct cred *cred = current_cred();\n\tint error = -EINVAL;\n\tstruct pid *pgrp;\n\tkuid_t uid;\n\n\tif (which > PRIO_USER || which < PRIO_PROCESS)\n\t\tgoto out;\n\n\t/* normalize: avoid signed division (rounding problems) */\n\terror = -ESRCH;\n\tif (niceval < MIN_NICE)\n\t\tniceval = MIN_NICE;\n\tif (niceval > MAX_NICE)\n\t\tniceval = MAX_NICE;\n\n\trcu_read_lock();\n\tswitch (which) {\n\tcase PRIO_PROCESS:\n\t\tif (who)\n\t\t\tp = find_task_by_vpid(who);\n\t\telse\n\t\t\tp = current;\n\t\tif (p)\n\t\t\terror = set_one_prio(p, niceval, error);\n\t\tbreak;\n\tcase PRIO_PGRP:\n\t\tif (who)\n\t\t\tpgrp = find_vpid(who);\n\t\telse\n\t\t\tpgrp = task_pgrp(current);\n\t\tread_lock(&tasklist_lock);\n\t\tdo_each_pid_thread(pgrp, PIDTYPE_PGID, p) {\n\t\t\terror = set_one_prio(p, niceval, error);\n\t\t} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);\n\t\tread_unlock(&tasklist_lock);\n\t\tbreak;\n\tcase PRIO_USER:\n\t\tuid = make_kuid(cred->user_ns, who);\n\t\tuser = cred->user;\n\t\tif (!who)\n\t\t\tuid = cred->uid;\n\t\telse if (!uid_eq(uid, cred->uid)) {\n\t\t\tuser = find_user(uid);\n\t\t\tif (!user)\n\t\t\t\tgoto out_unlock;\t/* No processes for this user */\n\t\t}\n\t\tfor_each_process_thread(g, p) {\n\t\t\tif (uid_eq(task_uid(p), uid) && task_pid_vnr(p))\n\t\t\t\terror = set_one_prio(p, niceval, error);\n\t\t}\n\t\tif (!uid_eq(uid, cred->uid))\n\t\t\tfree_uid(user);\t\t/* For find_user() */\n\t\tbreak;\n\t}\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn error;\n}\n\n/*\n * Ugh. To avoid negative return values, \"getpriority()\" will\n * not return the normal nice-value, but a negated value that\n * has been offset by 20 (ie it returns 40..1 instead of -20..19)\n * to stay compatible.\n */\nSYSCALL_DEFINE2(getpriority, int, which, int, who)\n{\n\tstruct task_struct *g, *p;\n\tstruct user_struct *user;\n\tconst struct cred *cred = current_cred();\n\tlong niceval, retval = -ESRCH;\n\tstruct pid *pgrp;\n\tkuid_t uid;\n\n\tif (which > PRIO_USER || which < PRIO_PROCESS)\n\t\treturn -EINVAL;\n\n\trcu_read_lock();\n\tswitch (which) {\n\tcase PRIO_PROCESS:\n\t\tif (who)\n\t\t\tp = find_task_by_vpid(who);\n\t\telse\n\t\t\tp = current;\n\t\tif (p) {\n\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\tif (niceval > retval)\n\t\t\t\tretval = niceval;\n\t\t}\n\t\tbreak;\n\tcase PRIO_PGRP:\n\t\tif (who)\n\t\t\tpgrp = find_vpid(who);\n\t\telse\n\t\t\tpgrp = task_pgrp(current);\n\t\tread_lock(&tasklist_lock);\n\t\tdo_each_pid_thread(pgrp, PIDTYPE_PGID, p) {\n\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\tif (niceval > retval)\n\t\t\t\tretval = niceval;\n\t\t} while_each_pid_thread(pgrp, PIDTYPE_PGID, p);\n\t\tread_unlock(&tasklist_lock);\n\t\tbreak;\n\tcase PRIO_USER:\n\t\tuid = make_kuid(cred->user_ns, who);\n\t\tuser = cred->user;\n\t\tif (!who)\n\t\t\tuid = cred->uid;\n\t\telse if (!uid_eq(uid, cred->uid)) {\n\t\t\tuser = find_user(uid);\n\t\t\tif (!user)\n\t\t\t\tgoto out_unlock;\t/* No processes for this user */\n\t\t}\n\t\tfor_each_process_thread(g, p) {\n\t\t\tif (uid_eq(task_uid(p), uid) && task_pid_vnr(p)) {\n\t\t\t\tniceval = nice_to_rlimit(task_nice(p));\n\t\t\t\tif (niceval > retval)\n\t\t\t\t\tretval = niceval;\n\t\t\t}\n\t\t}\n\t\tif (!uid_eq(uid, cred->uid))\n\t\t\tfree_uid(user);\t\t/* for find_user() */\n\t\tbreak;\n\t}\nout_unlock:\n\trcu_read_unlock();\n\n\treturn retval;\n}\n\n/*\n * Unprivileged users may change the real gid to the effective gid\n * or vice versa.  (BSD-style)\n *\n * If you set the real gid at all, or set the effective gid to a value not\n * equal to the real gid, then the saved gid is set to the new effective gid.\n *\n * This makes it possible for a setgid program to completely drop its\n * privileges, which is often a useful assertion to make when you are doing\n * a security audit over a program.\n *\n * The general idea is that a program which uses just setregid() will be\n * 100% compatible with BSD.  A program which uses just setgid() will be\n * 100% compatible with POSIX with saved IDs.\n *\n * SMP: There are not races, the GIDs are checked only by filesystem\n *      operations (as far as semantic preservation is concerned).\n */\n#ifdef CONFIG_MULTIUSER\nlong __sys_setregid(gid_t rgid, gid_t egid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t krgid, kegid;\n\n\tkrgid = make_kgid(ns, rgid);\n\tkegid = make_kgid(ns, egid);\n\n\tif ((rgid != (gid_t) -1) && !gid_valid(krgid))\n\t\treturn -EINVAL;\n\tif ((egid != (gid_t) -1) && !gid_valid(kegid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (rgid != (gid_t) -1) {\n\t\tif (gid_eq(old->gid, krgid) ||\n\t\t    gid_eq(old->egid, krgid) ||\n\t\t    ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\t\tnew->gid = krgid;\n\t\telse\n\t\t\tgoto error;\n\t}\n\tif (egid != (gid_t) -1) {\n\t\tif (gid_eq(old->gid, kegid) ||\n\t\t    gid_eq(old->egid, kegid) ||\n\t\t    gid_eq(old->sgid, kegid) ||\n\t\t    ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\t\tnew->egid = kegid;\n\t\telse\n\t\t\tgoto error;\n\t}\n\n\tif (rgid != (gid_t) -1 ||\n\t    (egid != (gid_t) -1 && !gid_eq(kegid, old->gid)))\n\t\tnew->sgid = new->egid;\n\tnew->fsgid = new->egid;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_RE);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(setregid, gid_t, rgid, gid_t, egid)\n{\n\treturn __sys_setregid(rgid, egid);\n}\n\n/*\n * setgid() is implemented like SysV w/ SAVED_IDS\n *\n * SMP: Same implicit races as above.\n */\nlong __sys_setgid(gid_t gid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t kgid;\n\n\tkgid = make_kgid(ns, gid);\n\tif (!gid_valid(kgid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ns_capable_setid(old->user_ns, CAP_SETGID))\n\t\tnew->gid = new->egid = new->sgid = new->fsgid = kgid;\n\telse if (gid_eq(kgid, old->gid) || gid_eq(kgid, old->sgid))\n\t\tnew->egid = new->fsgid = kgid;\n\telse\n\t\tgoto error;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_ID);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(setgid, gid_t, gid)\n{\n\treturn __sys_setgid(gid);\n}\n\n/*\n * change the user struct in a credentials set to match the new UID\n */\nstatic int set_user(struct cred *new)\n{\n\tstruct user_struct *new_user;\n\n\tnew_user = alloc_uid(new->uid);\n\tif (!new_user)\n\t\treturn -EAGAIN;\n\n\tfree_uid(new->user);\n\tnew->user = new_user;\n\treturn 0;\n}\n\nstatic void flag_nproc_exceeded(struct cred *new)\n{\n\tif (new->ucounts == current_ucounts())\n\t\treturn;\n\n\t/*\n\t * We don't fail in case of NPROC limit excess here because too many\n\t * poorly written programs don't check set*uid() return code, assuming\n\t * it never fails if called by root.  We may still enforce NPROC limit\n\t * for programs doing set*uid()+execve() by harmlessly deferring the\n\t * failure to the execve() stage.\n\t */\n\tif (is_rlimit_overlimit(new->ucounts, UCOUNT_RLIMIT_NPROC, rlimit(RLIMIT_NPROC)) &&\n\t\t\tnew->user != INIT_USER)\n\t\tcurrent->flags |= PF_NPROC_EXCEEDED;\n\telse\n\t\tcurrent->flags &= ~PF_NPROC_EXCEEDED;\n}\n\n/*\n * Unprivileged users may change the real uid to the effective uid\n * or vice versa.  (BSD-style)\n *\n * If you set the real uid at all, or set the effective uid to a value not\n * equal to the real uid, then the saved uid is set to the new effective uid.\n *\n * This makes it possible for a setuid program to completely drop its\n * privileges, which is often a useful assertion to make when you are doing\n * a security audit over a program.\n *\n * The general idea is that a program which uses just setreuid() will be\n * 100% compatible with BSD.  A program which uses just setuid() will be\n * 100% compatible with POSIX with saved IDs.\n */\nlong __sys_setreuid(uid_t ruid, uid_t euid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kruid, keuid;\n\n\tkruid = make_kuid(ns, ruid);\n\tkeuid = make_kuid(ns, euid);\n\n\tif ((ruid != (uid_t) -1) && !uid_valid(kruid))\n\t\treturn -EINVAL;\n\tif ((euid != (uid_t) -1) && !uid_valid(keuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ruid != (uid_t) -1) {\n\t\tnew->uid = kruid;\n\t\tif (!uid_eq(old->uid, kruid) &&\n\t\t    !uid_eq(old->euid, kruid) &&\n\t\t    !ns_capable_setid(old->user_ns, CAP_SETUID))\n\t\t\tgoto error;\n\t}\n\n\tif (euid != (uid_t) -1) {\n\t\tnew->euid = keuid;\n\t\tif (!uid_eq(old->uid, keuid) &&\n\t\t    !uid_eq(old->euid, keuid) &&\n\t\t    !uid_eq(old->suid, keuid) &&\n\t\t    !ns_capable_setid(old->user_ns, CAP_SETUID))\n\t\t\tgoto error;\n\t}\n\n\tif (!uid_eq(new->uid, old->uid)) {\n\t\tretval = set_user(new);\n\t\tif (retval < 0)\n\t\t\tgoto error;\n\t}\n\tif (ruid != (uid_t) -1 ||\n\t    (euid != (uid_t) -1 && !uid_eq(keuid, old->uid)))\n\t\tnew->suid = new->euid;\n\tnew->fsuid = new->euid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_RE);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(setreuid, uid_t, ruid, uid_t, euid)\n{\n\treturn __sys_setreuid(ruid, euid);\n}\n\n/*\n * setuid() is implemented like SysV with SAVED_IDS\n *\n * Note that SAVED_ID's is deficient in that a setuid root program\n * like sendmail, for example, cannot set its uid to be a normal\n * user and then switch back, because if you're root, setuid() sets\n * the saved uid too.  If you don't like this, blame the bright people\n * in the POSIX committee and/or USG.  Note that the BSD-style setreuid()\n * will allow a root program to temporarily drop privileges and be able to\n * regain them by swapping the real and effective uid.\n */\nlong __sys_setuid(uid_t uid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kuid;\n\n\tkuid = make_kuid(ns, uid);\n\tif (!uid_valid(kuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tnew->suid = new->uid = kuid;\n\t\tif (!uid_eq(kuid, old->uid)) {\n\t\t\tretval = set_user(new);\n\t\t\tif (retval < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t} else if (!uid_eq(kuid, old->uid) && !uid_eq(kuid, new->suid)) {\n\t\tgoto error;\n\t}\n\n\tnew->fsuid = new->euid = kuid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_ID);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(setuid, uid_t, uid)\n{\n\treturn __sys_setuid(uid);\n}\n\n\n/*\n * This function implements a generic ability to update ruid, euid,\n * and suid.  This allows you to implement the 4.4 compatible seteuid().\n */\nlong __sys_setresuid(uid_t ruid, uid_t euid, uid_t suid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkuid_t kruid, keuid, ksuid;\n\n\tkruid = make_kuid(ns, ruid);\n\tkeuid = make_kuid(ns, euid);\n\tksuid = make_kuid(ns, suid);\n\n\tif ((ruid != (uid_t) -1) && !uid_valid(kruid))\n\t\treturn -EINVAL;\n\n\tif ((euid != (uid_t) -1) && !uid_valid(keuid))\n\t\treturn -EINVAL;\n\n\tif ((suid != (uid_t) -1) && !uid_valid(ksuid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (!ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tif (ruid != (uid_t) -1        && !uid_eq(kruid, old->uid) &&\n\t\t    !uid_eq(kruid, old->euid) && !uid_eq(kruid, old->suid))\n\t\t\tgoto error;\n\t\tif (euid != (uid_t) -1        && !uid_eq(keuid, old->uid) &&\n\t\t    !uid_eq(keuid, old->euid) && !uid_eq(keuid, old->suid))\n\t\t\tgoto error;\n\t\tif (suid != (uid_t) -1        && !uid_eq(ksuid, old->uid) &&\n\t\t    !uid_eq(ksuid, old->euid) && !uid_eq(ksuid, old->suid))\n\t\t\tgoto error;\n\t}\n\n\tif (ruid != (uid_t) -1) {\n\t\tnew->uid = kruid;\n\t\tif (!uid_eq(kruid, old->uid)) {\n\t\t\tretval = set_user(new);\n\t\t\tif (retval < 0)\n\t\t\t\tgoto error;\n\t\t}\n\t}\n\tif (euid != (uid_t) -1)\n\t\tnew->euid = keuid;\n\tif (suid != (uid_t) -1)\n\t\tnew->suid = ksuid;\n\tnew->fsuid = new->euid;\n\n\tretval = security_task_fix_setuid(new, old, LSM_SETID_RES);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tretval = set_cred_ucounts(new);\n\tif (retval < 0)\n\t\tgoto error;\n\n\tflag_nproc_exceeded(new);\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE3(setresuid, uid_t, ruid, uid_t, euid, uid_t, suid)\n{\n\treturn __sys_setresuid(ruid, euid, suid);\n}\n\nSYSCALL_DEFINE3(getresuid, uid_t __user *, ruidp, uid_t __user *, euidp, uid_t __user *, suidp)\n{\n\tconst struct cred *cred = current_cred();\n\tint retval;\n\tuid_t ruid, euid, suid;\n\n\truid = from_kuid_munged(cred->user_ns, cred->uid);\n\teuid = from_kuid_munged(cred->user_ns, cred->euid);\n\tsuid = from_kuid_munged(cred->user_ns, cred->suid);\n\n\tretval = put_user(ruid, ruidp);\n\tif (!retval) {\n\t\tretval = put_user(euid, euidp);\n\t\tif (!retval)\n\t\t\treturn put_user(suid, suidp);\n\t}\n\treturn retval;\n}\n\n/*\n * Same as above, but for rgid, egid, sgid.\n */\nlong __sys_setresgid(gid_t rgid, gid_t egid, gid_t sgid)\n{\n\tstruct user_namespace *ns = current_user_ns();\n\tconst struct cred *old;\n\tstruct cred *new;\n\tint retval;\n\tkgid_t krgid, kegid, ksgid;\n\n\tkrgid = make_kgid(ns, rgid);\n\tkegid = make_kgid(ns, egid);\n\tksgid = make_kgid(ns, sgid);\n\n\tif ((rgid != (gid_t) -1) && !gid_valid(krgid))\n\t\treturn -EINVAL;\n\tif ((egid != (gid_t) -1) && !gid_valid(kegid))\n\t\treturn -EINVAL;\n\tif ((sgid != (gid_t) -1) && !gid_valid(ksgid))\n\t\treturn -EINVAL;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\told = current_cred();\n\n\tretval = -EPERM;\n\tif (!ns_capable_setid(old->user_ns, CAP_SETGID)) {\n\t\tif (rgid != (gid_t) -1        && !gid_eq(krgid, old->gid) &&\n\t\t    !gid_eq(krgid, old->egid) && !gid_eq(krgid, old->sgid))\n\t\t\tgoto error;\n\t\tif (egid != (gid_t) -1        && !gid_eq(kegid, old->gid) &&\n\t\t    !gid_eq(kegid, old->egid) && !gid_eq(kegid, old->sgid))\n\t\t\tgoto error;\n\t\tif (sgid != (gid_t) -1        && !gid_eq(ksgid, old->gid) &&\n\t\t    !gid_eq(ksgid, old->egid) && !gid_eq(ksgid, old->sgid))\n\t\t\tgoto error;\n\t}\n\n\tif (rgid != (gid_t) -1)\n\t\tnew->gid = krgid;\n\tif (egid != (gid_t) -1)\n\t\tnew->egid = kegid;\n\tif (sgid != (gid_t) -1)\n\t\tnew->sgid = ksgid;\n\tnew->fsgid = new->egid;\n\n\tretval = security_task_fix_setgid(new, old, LSM_SETID_RES);\n\tif (retval < 0)\n\t\tgoto error;\n\n\treturn commit_creds(new);\n\nerror:\n\tabort_creds(new);\n\treturn retval;\n}\n\nSYSCALL_DEFINE3(setresgid, gid_t, rgid, gid_t, egid, gid_t, sgid)\n{\n\treturn __sys_setresgid(rgid, egid, sgid);\n}\n\nSYSCALL_DEFINE3(getresgid, gid_t __user *, rgidp, gid_t __user *, egidp, gid_t __user *, sgidp)\n{\n\tconst struct cred *cred = current_cred();\n\tint retval;\n\tgid_t rgid, egid, sgid;\n\n\trgid = from_kgid_munged(cred->user_ns, cred->gid);\n\tegid = from_kgid_munged(cred->user_ns, cred->egid);\n\tsgid = from_kgid_munged(cred->user_ns, cred->sgid);\n\n\tretval = put_user(rgid, rgidp);\n\tif (!retval) {\n\t\tretval = put_user(egid, egidp);\n\t\tif (!retval)\n\t\t\tretval = put_user(sgid, sgidp);\n\t}\n\n\treturn retval;\n}\n\n\n/*\n * \"setfsuid()\" sets the fsuid - the uid used for filesystem checks. This\n * is used for \"access()\" and for the NFS daemon (letting nfsd stay at\n * whatever uid it wants to). It normally shadows \"euid\", except when\n * explicitly set by setfsuid() or for access..\n */\nlong __sys_setfsuid(uid_t uid)\n{\n\tconst struct cred *old;\n\tstruct cred *new;\n\tuid_t old_fsuid;\n\tkuid_t kuid;\n\n\told = current_cred();\n\told_fsuid = from_kuid_munged(old->user_ns, old->fsuid);\n\n\tkuid = make_kuid(old->user_ns, uid);\n\tif (!uid_valid(kuid))\n\t\treturn old_fsuid;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn old_fsuid;\n\n\tif (uid_eq(kuid, old->uid)  || uid_eq(kuid, old->euid)  ||\n\t    uid_eq(kuid, old->suid) || uid_eq(kuid, old->fsuid) ||\n\t    ns_capable_setid(old->user_ns, CAP_SETUID)) {\n\t\tif (!uid_eq(kuid, old->fsuid)) {\n\t\t\tnew->fsuid = kuid;\n\t\t\tif (security_task_fix_setuid(new, old, LSM_SETID_FS) == 0)\n\t\t\t\tgoto change_okay;\n\t\t}\n\t}\n\n\tabort_creds(new);\n\treturn old_fsuid;\n\nchange_okay:\n\tcommit_creds(new);\n\treturn old_fsuid;\n}\n\nSYSCALL_DEFINE1(setfsuid, uid_t, uid)\n{\n\treturn __sys_setfsuid(uid);\n}\n\n/*\n * Samma p\u00e5 svenska..\n */\nlong __sys_setfsgid(gid_t gid)\n{\n\tconst struct cred *old;\n\tstruct cred *new;\n\tgid_t old_fsgid;\n\tkgid_t kgid;\n\n\told = current_cred();\n\told_fsgid = from_kgid_munged(old->user_ns, old->fsgid);\n\n\tkgid = make_kgid(old->user_ns, gid);\n\tif (!gid_valid(kgid))\n\t\treturn old_fsgid;\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn old_fsgid;\n\n\tif (gid_eq(kgid, old->gid)  || gid_eq(kgid, old->egid)  ||\n\t    gid_eq(kgid, old->sgid) || gid_eq(kgid, old->fsgid) ||\n\t    ns_capable_setid(old->user_ns, CAP_SETGID)) {\n\t\tif (!gid_eq(kgid, old->fsgid)) {\n\t\t\tnew->fsgid = kgid;\n\t\t\tif (security_task_fix_setgid(new,old,LSM_SETID_FS) == 0)\n\t\t\t\tgoto change_okay;\n\t\t}\n\t}\n\n\tabort_creds(new);\n\treturn old_fsgid;\n\nchange_okay:\n\tcommit_creds(new);\n\treturn old_fsgid;\n}\n\nSYSCALL_DEFINE1(setfsgid, gid_t, gid)\n{\n\treturn __sys_setfsgid(gid);\n}\n#endif /* CONFIG_MULTIUSER */\n\n/**\n * sys_getpid - return the thread group id of the current process\n *\n * Note, despite the name, this returns the tgid not the pid.  The tgid and\n * the pid are identical unless CLONE_THREAD was specified on clone() in\n * which case the tgid is the same in all threads of the same group.\n *\n * This is SMP safe as current->tgid does not change.\n */\nSYSCALL_DEFINE0(getpid)\n{\n\treturn task_tgid_vnr(current);\n}\n\n/* Thread ID - the internal kernel \"pid\" */\nSYSCALL_DEFINE0(gettid)\n{\n\treturn task_pid_vnr(current);\n}\n\n/*\n * Accessing ->real_parent is not SMP-safe, it could\n * change from under us. However, we can use a stale\n * value of ->real_parent under rcu_read_lock(), see\n * release_task()->call_rcu(delayed_put_task_struct).\n */\nSYSCALL_DEFINE0(getppid)\n{\n\tint pid;\n\n\trcu_read_lock();\n\tpid = task_tgid_vnr(rcu_dereference(current->real_parent));\n\trcu_read_unlock();\n\n\treturn pid;\n}\n\nSYSCALL_DEFINE0(getuid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kuid_munged(current_user_ns(), current_uid());\n}\n\nSYSCALL_DEFINE0(geteuid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kuid_munged(current_user_ns(), current_euid());\n}\n\nSYSCALL_DEFINE0(getgid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kgid_munged(current_user_ns(), current_gid());\n}\n\nSYSCALL_DEFINE0(getegid)\n{\n\t/* Only we change this so SMP safe */\n\treturn from_kgid_munged(current_user_ns(), current_egid());\n}\n\nstatic void do_sys_times(struct tms *tms)\n{\n\tu64 tgutime, tgstime, cutime, cstime;\n\n\tthread_group_cputime_adjusted(current, &tgutime, &tgstime);\n\tcutime = current->signal->cutime;\n\tcstime = current->signal->cstime;\n\ttms->tms_utime = nsec_to_clock_t(tgutime);\n\ttms->tms_stime = nsec_to_clock_t(tgstime);\n\ttms->tms_cutime = nsec_to_clock_t(cutime);\n\ttms->tms_cstime = nsec_to_clock_t(cstime);\n}\n\nSYSCALL_DEFINE1(times, struct tms __user *, tbuf)\n{\n\tif (tbuf) {\n\t\tstruct tms tmp;\n\n\t\tdo_sys_times(&tmp);\n\t\tif (copy_to_user(tbuf, &tmp, sizeof(struct tms)))\n\t\t\treturn -EFAULT;\n\t}\n\tforce_successful_syscall_return();\n\treturn (long) jiffies_64_to_clock_t(get_jiffies_64());\n}\n\n#ifdef CONFIG_COMPAT\nstatic compat_clock_t clock_t_to_compat_clock_t(clock_t x)\n{\n\treturn compat_jiffies_to_clock_t(clock_t_to_jiffies(x));\n}\n\nCOMPAT_SYSCALL_DEFINE1(times, struct compat_tms __user *, tbuf)\n{\n\tif (tbuf) {\n\t\tstruct tms tms;\n\t\tstruct compat_tms tmp;\n\n\t\tdo_sys_times(&tms);\n\t\t/* Convert our struct tms to the compat version. */\n\t\ttmp.tms_utime = clock_t_to_compat_clock_t(tms.tms_utime);\n\t\ttmp.tms_stime = clock_t_to_compat_clock_t(tms.tms_stime);\n\t\ttmp.tms_cutime = clock_t_to_compat_clock_t(tms.tms_cutime);\n\t\ttmp.tms_cstime = clock_t_to_compat_clock_t(tms.tms_cstime);\n\t\tif (copy_to_user(tbuf, &tmp, sizeof(tmp)))\n\t\t\treturn -EFAULT;\n\t}\n\tforce_successful_syscall_return();\n\treturn compat_jiffies_to_clock_t(jiffies);\n}\n#endif\n\n/*\n * This needs some heavy checking ...\n * I just haven't the stomach for it. I also don't fully\n * understand sessions/pgrp etc. Let somebody who does explain it.\n *\n * OK, I think I have the protection semantics right.... this is really\n * only important on a multi-user system anyway, to make sure one user\n * can't send a signal to a process owned by another.  -TYT, 12/12/91\n *\n * !PF_FORKNOEXEC check to conform completely to POSIX.\n */\nSYSCALL_DEFINE2(setpgid, pid_t, pid, pid_t, pgid)\n{\n\tstruct task_struct *p;\n\tstruct task_struct *group_leader = current->group_leader;\n\tstruct pid *pgrp;\n\tint err;\n\n\tif (!pid)\n\t\tpid = task_pid_vnr(group_leader);\n\tif (!pgid)\n\t\tpgid = pid;\n\tif (pgid < 0)\n\t\treturn -EINVAL;\n\trcu_read_lock();\n\n\t/* From this point forward we keep holding onto the tasklist lock\n\t * so that our parent does not change from under us. -DaveM\n\t */\n\twrite_lock_irq(&tasklist_lock);\n\n\terr = -ESRCH;\n\tp = find_task_by_vpid(pid);\n\tif (!p)\n\t\tgoto out;\n\n\terr = -EINVAL;\n\tif (!thread_group_leader(p))\n\t\tgoto out;\n\n\tif (same_thread_group(p->real_parent, group_leader)) {\n\t\terr = -EPERM;\n\t\tif (task_session(p) != task_session(group_leader))\n\t\t\tgoto out;\n\t\terr = -EACCES;\n\t\tif (!(p->flags & PF_FORKNOEXEC))\n\t\t\tgoto out;\n\t} else {\n\t\terr = -ESRCH;\n\t\tif (p != group_leader)\n\t\t\tgoto out;\n\t}\n\n\terr = -EPERM;\n\tif (p->signal->leader)\n\t\tgoto out;\n\n\tpgrp = task_pid(p);\n\tif (pgid != pid) {\n\t\tstruct task_struct *g;\n\n\t\tpgrp = find_vpid(pgid);\n\t\tg = pid_task(pgrp, PIDTYPE_PGID);\n\t\tif (!g || task_session(g) != task_session(group_leader))\n\t\t\tgoto out;\n\t}\n\n\terr = security_task_setpgid(p, pgid);\n\tif (err)\n\t\tgoto out;\n\n\tif (task_pgrp(p) != pgrp)\n\t\tchange_pid(p, PIDTYPE_PGID, pgrp);\n\n\terr = 0;\nout:\n\t/* All paths lead to here, thus we are safe. -DaveM */\n\twrite_unlock_irq(&tasklist_lock);\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int do_getpgid(pid_t pid)\n{\n\tstruct task_struct *p;\n\tstruct pid *grp;\n\tint retval;\n\n\trcu_read_lock();\n\tif (!pid)\n\t\tgrp = task_pgrp(current);\n\telse {\n\t\tretval = -ESRCH;\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto out;\n\t\tgrp = task_pgrp(p);\n\t\tif (!grp)\n\t\t\tgoto out;\n\n\t\tretval = security_task_getpgid(p);\n\t\tif (retval)\n\t\t\tgoto out;\n\t}\n\tretval = pid_vnr(grp);\nout:\n\trcu_read_unlock();\n\treturn retval;\n}\n\nSYSCALL_DEFINE1(getpgid, pid_t, pid)\n{\n\treturn do_getpgid(pid);\n}\n\n#ifdef __ARCH_WANT_SYS_GETPGRP\n\nSYSCALL_DEFINE0(getpgrp)\n{\n\treturn do_getpgid(0);\n}\n\n#endif\n\nSYSCALL_DEFINE1(getsid, pid_t, pid)\n{\n\tstruct task_struct *p;\n\tstruct pid *sid;\n\tint retval;\n\n\trcu_read_lock();\n\tif (!pid)\n\t\tsid = task_session(current);\n\telse {\n\t\tretval = -ESRCH;\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto out;\n\t\tsid = task_session(p);\n\t\tif (!sid)\n\t\t\tgoto out;\n\n\t\tretval = security_task_getsid(p);\n\t\tif (retval)\n\t\t\tgoto out;\n\t}\n\tretval = pid_vnr(sid);\nout:\n\trcu_read_unlock();\n\treturn retval;\n}\n\nstatic void set_special_pids(struct pid *pid)\n{\n\tstruct task_struct *curr = current->group_leader;\n\n\tif (task_session(curr) != pid)\n\t\tchange_pid(curr, PIDTYPE_SID, pid);\n\n\tif (task_pgrp(curr) != pid)\n\t\tchange_pid(curr, PIDTYPE_PGID, pid);\n}\n\nint ksys_setsid(void)\n{\n\tstruct task_struct *group_leader = current->group_leader;\n\tstruct pid *sid = task_pid(group_leader);\n\tpid_t session = pid_vnr(sid);\n\tint err = -EPERM;\n\n\twrite_lock_irq(&tasklist_lock);\n\t/* Fail if I am already a session leader */\n\tif (group_leader->signal->leader)\n\t\tgoto out;\n\n\t/* Fail if a process group id already exists that equals the\n\t * proposed session id.\n\t */\n\tif (pid_task(sid, PIDTYPE_PGID))\n\t\tgoto out;\n\n\tgroup_leader->signal->leader = 1;\n\tset_special_pids(sid);\n\n\tproc_clear_tty(group_leader);\n\n\terr = session;\nout:\n\twrite_unlock_irq(&tasklist_lock);\n\tif (err > 0) {\n\t\tproc_sid_connector(group_leader);\n\t\tsched_autogroup_create_attach(group_leader);\n\t}\n\treturn err;\n}\n\nSYSCALL_DEFINE0(setsid)\n{\n\treturn ksys_setsid();\n}\n\nDECLARE_RWSEM(uts_sem);\n\n#ifdef COMPAT_UTS_MACHINE\n#define override_architecture(name) \\\n\t(personality(current->personality) == PER_LINUX32 && \\\n\t copy_to_user(name->machine, COMPAT_UTS_MACHINE, \\\n\t\t      sizeof(COMPAT_UTS_MACHINE)))\n#else\n#define override_architecture(name)\t0\n#endif\n\n/*\n * Work around broken programs that cannot handle \"Linux 3.0\".\n * Instead we map 3.x to 2.6.40+x, so e.g. 3.0 would be 2.6.40\n * And we map 4.x and later versions to 2.6.60+x, so 4.0/5.0/6.0/... would be\n * 2.6.60.\n */\nstatic int override_release(char __user *release, size_t len)\n{\n\tint ret = 0;\n\n\tif (current->personality & UNAME26) {\n\t\tconst char *rest = UTS_RELEASE;\n\t\tchar buf[65] = { 0 };\n\t\tint ndots = 0;\n\t\tunsigned v;\n\t\tsize_t copy;\n\n\t\twhile (*rest) {\n\t\t\tif (*rest == '.' && ++ndots >= 3)\n\t\t\t\tbreak;\n\t\t\tif (!isdigit(*rest) && *rest != '.')\n\t\t\t\tbreak;\n\t\t\trest++;\n\t\t}\n\t\tv = LINUX_VERSION_PATCHLEVEL + 60;\n\t\tcopy = clamp_t(size_t, len, 1, sizeof(buf));\n\t\tcopy = scnprintf(buf, copy, \"2.6.%u%s\", v, rest);\n\t\tret = copy_to_user(release, buf, copy + 1);\n\t}\n\treturn ret;\n}\n\nSYSCALL_DEFINE1(newuname, struct new_utsname __user *, name)\n{\n\tstruct new_utsname tmp;\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp, utsname(), sizeof(tmp));\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n#ifdef __ARCH_WANT_SYS_OLD_UNAME\n/*\n * Old cruft\n */\nSYSCALL_DEFINE1(uname, struct old_utsname __user *, name)\n{\n\tstruct old_utsname tmp;\n\n\tif (!name)\n\t\treturn -EFAULT;\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp, utsname(), sizeof(tmp));\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nSYSCALL_DEFINE1(olduname, struct oldold_utsname __user *, name)\n{\n\tstruct oldold_utsname tmp;\n\n\tif (!name)\n\t\treturn -EFAULT;\n\n\tmemset(&tmp, 0, sizeof(tmp));\n\n\tdown_read(&uts_sem);\n\tmemcpy(&tmp.sysname, &utsname()->sysname, __OLD_UTS_LEN);\n\tmemcpy(&tmp.nodename, &utsname()->nodename, __OLD_UTS_LEN);\n\tmemcpy(&tmp.release, &utsname()->release, __OLD_UTS_LEN);\n\tmemcpy(&tmp.version, &utsname()->version, __OLD_UTS_LEN);\n\tmemcpy(&tmp.machine, &utsname()->machine, __OLD_UTS_LEN);\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, &tmp, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tif (override_architecture(name))\n\t\treturn -EFAULT;\n\tif (override_release(name->release, sizeof(name->release)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif\n\nSYSCALL_DEFINE2(sethostname, char __user *, name, int, len)\n{\n\tint errno;\n\tchar tmp[__NEW_UTS_LEN];\n\n\tif (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (len < 0 || len > __NEW_UTS_LEN)\n\t\treturn -EINVAL;\n\terrno = -EFAULT;\n\tif (!copy_from_user(tmp, name, len)) {\n\t\tstruct new_utsname *u;\n\n\t\tadd_device_randomness(tmp, len);\n\t\tdown_write(&uts_sem);\n\t\tu = utsname();\n\t\tmemcpy(u->nodename, tmp, len);\n\t\tmemset(u->nodename + len, 0, sizeof(u->nodename) - len);\n\t\terrno = 0;\n\t\tuts_proc_notify(UTS_PROC_HOSTNAME);\n\t\tup_write(&uts_sem);\n\t}\n\treturn errno;\n}\n\n#ifdef __ARCH_WANT_SYS_GETHOSTNAME\n\nSYSCALL_DEFINE2(gethostname, char __user *, name, int, len)\n{\n\tint i;\n\tstruct new_utsname *u;\n\tchar tmp[__NEW_UTS_LEN + 1];\n\n\tif (len < 0)\n\t\treturn -EINVAL;\n\tdown_read(&uts_sem);\n\tu = utsname();\n\ti = 1 + strlen(u->nodename);\n\tif (i > len)\n\t\ti = len;\n\tmemcpy(tmp, u->nodename, i);\n\tup_read(&uts_sem);\n\tif (copy_to_user(name, tmp, i))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n#endif\n\n/*\n * Only setdomainname; getdomainname can be implemented by calling\n * uname()\n */\nSYSCALL_DEFINE2(setdomainname, char __user *, name, int, len)\n{\n\tint errno;\n\tchar tmp[__NEW_UTS_LEN];\n\n\tif (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\tif (len < 0 || len > __NEW_UTS_LEN)\n\t\treturn -EINVAL;\n\n\terrno = -EFAULT;\n\tif (!copy_from_user(tmp, name, len)) {\n\t\tstruct new_utsname *u;\n\n\t\tadd_device_randomness(tmp, len);\n\t\tdown_write(&uts_sem);\n\t\tu = utsname();\n\t\tmemcpy(u->domainname, tmp, len);\n\t\tmemset(u->domainname + len, 0, sizeof(u->domainname) - len);\n\t\terrno = 0;\n\t\tuts_proc_notify(UTS_PROC_DOMAINNAME);\n\t\tup_write(&uts_sem);\n\t}\n\treturn errno;\n}\n\n/* make sure you are allowed to change @tsk limits before calling this */\nstatic int do_prlimit(struct task_struct *tsk, unsigned int resource,\n\t\t      struct rlimit *new_rlim, struct rlimit *old_rlim)\n{\n\tstruct rlimit *rlim;\n\tint retval = 0;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\n\tif (new_rlim) {\n\t\tif (new_rlim->rlim_cur > new_rlim->rlim_max)\n\t\t\treturn -EINVAL;\n\t\tif (resource == RLIMIT_NOFILE &&\n\t\t\t\tnew_rlim->rlim_max > sysctl_nr_open)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Holding a refcount on tsk protects tsk->signal from disappearing. */\n\trlim = tsk->signal->rlim + resource;\n\ttask_lock(tsk->group_leader);\n\tif (new_rlim) {\n\t\t/*\n\t\t * Keep the capable check against init_user_ns until cgroups can\n\t\t * contain all limits.\n\t\t */\n\t\tif (new_rlim->rlim_max > rlim->rlim_max &&\n\t\t\t\t!capable(CAP_SYS_RESOURCE))\n\t\t\tretval = -EPERM;\n\t\tif (!retval)\n\t\t\tretval = security_task_setrlimit(tsk, resource, new_rlim);\n\t}\n\tif (!retval) {\n\t\tif (old_rlim)\n\t\t\t*old_rlim = *rlim;\n\t\tif (new_rlim)\n\t\t\t*rlim = *new_rlim;\n\t}\n\ttask_unlock(tsk->group_leader);\n\n\t/*\n\t * RLIMIT_CPU handling. Arm the posix CPU timer if the limit is not\n\t * infinite. In case of RLIM_INFINITY the posix CPU timer code\n\t * ignores the rlimit.\n\t */\n\tif (!retval && new_rlim && resource == RLIMIT_CPU &&\n\t    new_rlim->rlim_cur != RLIM_INFINITY &&\n\t    IS_ENABLED(CONFIG_POSIX_TIMERS)) {\n\t\t/*\n\t\t * update_rlimit_cpu can fail if the task is exiting, but there\n\t\t * may be other tasks in the thread group that are not exiting,\n\t\t * and they need their cpu timers adjusted.\n\t\t *\n\t\t * The group_leader is the last task to be released, so if we\n\t\t * cannot update_rlimit_cpu on it, then the entire process is\n\t\t * exiting and we do not need to update at all.\n\t\t */\n\t\tupdate_rlimit_cpu(tsk->group_leader, new_rlim->rlim_cur);\n\t}\n\n\treturn retval;\n}\n\nSYSCALL_DEFINE2(getrlimit, unsigned int, resource, struct rlimit __user *, rlim)\n{\n\tstruct rlimit value;\n\tint ret;\n\n\tret = do_prlimit(current, resource, NULL, &value);\n\tif (!ret)\n\t\tret = copy_to_user(rlim, &value, sizeof(*rlim)) ? -EFAULT : 0;\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\n\nCOMPAT_SYSCALL_DEFINE2(setrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\tstruct compat_rlimit r32;\n\n\tif (copy_from_user(&r32, rlim, sizeof(struct compat_rlimit)))\n\t\treturn -EFAULT;\n\n\tif (r32.rlim_cur == COMPAT_RLIM_INFINITY)\n\t\tr.rlim_cur = RLIM_INFINITY;\n\telse\n\t\tr.rlim_cur = r32.rlim_cur;\n\tif (r32.rlim_max == COMPAT_RLIM_INFINITY)\n\t\tr.rlim_max = RLIM_INFINITY;\n\telse\n\t\tr.rlim_max = r32.rlim_max;\n\treturn do_prlimit(current, resource, &r, NULL);\n}\n\nCOMPAT_SYSCALL_DEFINE2(getrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\tint ret;\n\n\tret = do_prlimit(current, resource, NULL, &r);\n\tif (!ret) {\n\t\tstruct compat_rlimit r32;\n\t\tif (r.rlim_cur > COMPAT_RLIM_INFINITY)\n\t\t\tr32.rlim_cur = COMPAT_RLIM_INFINITY;\n\t\telse\n\t\t\tr32.rlim_cur = r.rlim_cur;\n\t\tif (r.rlim_max > COMPAT_RLIM_INFINITY)\n\t\t\tr32.rlim_max = COMPAT_RLIM_INFINITY;\n\t\telse\n\t\t\tr32.rlim_max = r.rlim_max;\n\n\t\tif (copy_to_user(rlim, &r32, sizeof(struct compat_rlimit)))\n\t\t\treturn -EFAULT;\n\t}\n\treturn ret;\n}\n\n#endif\n\n#ifdef __ARCH_WANT_SYS_OLD_GETRLIMIT\n\n/*\n *\tBack compatibility for getrlimit. Needed for some apps.\n */\nSYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,\n\t\tstruct rlimit __user *, rlim)\n{\n\tstruct rlimit x;\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\ttask_lock(current->group_leader);\n\tx = current->signal->rlim[resource];\n\ttask_unlock(current->group_leader);\n\tif (x.rlim_cur > 0x7FFFFFFF)\n\t\tx.rlim_cur = 0x7FFFFFFF;\n\tif (x.rlim_max > 0x7FFFFFFF)\n\t\tx.rlim_max = 0x7FFFFFFF;\n\treturn copy_to_user(rlim, &x, sizeof(x)) ? -EFAULT : 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(old_getrlimit, unsigned int, resource,\n\t\t       struct compat_rlimit __user *, rlim)\n{\n\tstruct rlimit r;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\ttask_lock(current->group_leader);\n\tr = current->signal->rlim[resource];\n\ttask_unlock(current->group_leader);\n\tif (r.rlim_cur > 0x7FFFFFFF)\n\t\tr.rlim_cur = 0x7FFFFFFF;\n\tif (r.rlim_max > 0x7FFFFFFF)\n\t\tr.rlim_max = 0x7FFFFFFF;\n\n\tif (put_user(r.rlim_cur, &rlim->rlim_cur) ||\n\t    put_user(r.rlim_max, &rlim->rlim_max))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif\n\n#endif\n\nstatic inline bool rlim64_is_infinity(__u64 rlim64)\n{\n#if BITS_PER_LONG < 64\n\treturn rlim64 >= ULONG_MAX;\n#else\n\treturn rlim64 == RLIM64_INFINITY;\n#endif\n}\n\nstatic void rlim_to_rlim64(const struct rlimit *rlim, struct rlimit64 *rlim64)\n{\n\tif (rlim->rlim_cur == RLIM_INFINITY)\n\t\trlim64->rlim_cur = RLIM64_INFINITY;\n\telse\n\t\trlim64->rlim_cur = rlim->rlim_cur;\n\tif (rlim->rlim_max == RLIM_INFINITY)\n\t\trlim64->rlim_max = RLIM64_INFINITY;\n\telse\n\t\trlim64->rlim_max = rlim->rlim_max;\n}\n\nstatic void rlim64_to_rlim(const struct rlimit64 *rlim64, struct rlimit *rlim)\n{\n\tif (rlim64_is_infinity(rlim64->rlim_cur))\n\t\trlim->rlim_cur = RLIM_INFINITY;\n\telse\n\t\trlim->rlim_cur = (unsigned long)rlim64->rlim_cur;\n\tif (rlim64_is_infinity(rlim64->rlim_max))\n\t\trlim->rlim_max = RLIM_INFINITY;\n\telse\n\t\trlim->rlim_max = (unsigned long)rlim64->rlim_max;\n}\n\n/* rcu lock must be held */\nstatic int check_prlimit_permission(struct task_struct *task,\n\t\t\t\t    unsigned int flags)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\tbool id_match;\n\n\tif (current == task)\n\t\treturn 0;\n\n\ttcred = __task_cred(task);\n\tid_match = (uid_eq(cred->uid, tcred->euid) &&\n\t\t    uid_eq(cred->uid, tcred->suid) &&\n\t\t    uid_eq(cred->uid, tcred->uid)  &&\n\t\t    gid_eq(cred->gid, tcred->egid) &&\n\t\t    gid_eq(cred->gid, tcred->sgid) &&\n\t\t    gid_eq(cred->gid, tcred->gid));\n\tif (!id_match && !ns_capable(tcred->user_ns, CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\n\treturn security_task_prlimit(cred, tcred, flags);\n}\n\nSYSCALL_DEFINE4(prlimit64, pid_t, pid, unsigned int, resource,\n\t\tconst struct rlimit64 __user *, new_rlim,\n\t\tstruct rlimit64 __user *, old_rlim)\n{\n\tstruct rlimit64 old64, new64;\n\tstruct rlimit old, new;\n\tstruct task_struct *tsk;\n\tunsigned int checkflags = 0;\n\tint ret;\n\n\tif (old_rlim)\n\t\tcheckflags |= LSM_PRLIMIT_READ;\n\n\tif (new_rlim) {\n\t\tif (copy_from_user(&new64, new_rlim, sizeof(new64)))\n\t\t\treturn -EFAULT;\n\t\trlim64_to_rlim(&new64, &new);\n\t\tcheckflags |= LSM_PRLIMIT_WRITE;\n\t}\n\n\trcu_read_lock();\n\ttsk = pid ? find_task_by_vpid(pid) : current;\n\tif (!tsk) {\n\t\trcu_read_unlock();\n\t\treturn -ESRCH;\n\t}\n\tret = check_prlimit_permission(tsk, checkflags);\n\tif (ret) {\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\tget_task_struct(tsk);\n\trcu_read_unlock();\n\n\tret = do_prlimit(tsk, resource, new_rlim ? &new : NULL,\n\t\t\told_rlim ? &old : NULL);\n\n\tif (!ret && old_rlim) {\n\t\trlim_to_rlim64(&old, &old64);\n\t\tif (copy_to_user(old_rlim, &old64, sizeof(old64)))\n\t\t\tret = -EFAULT;\n\t}\n\n\tput_task_struct(tsk);\n\treturn ret;\n}\n\nSYSCALL_DEFINE2(setrlimit, unsigned int, resource, struct rlimit __user *, rlim)\n{\n\tstruct rlimit new_rlim;\n\n\tif (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))\n\t\treturn -EFAULT;\n\treturn do_prlimit(current, resource, &new_rlim, NULL);\n}\n\n/*\n * It would make sense to put struct rusage in the task_struct,\n * except that would make the task_struct be *really big*.  After\n * task_struct gets moved into malloc'ed memory, it would\n * make sense to do this.  It will make moving the rest of the information\n * a lot simpler!  (Which we're not doing right now because we're not\n * measuring them yet).\n *\n * When sampling multiple threads for RUSAGE_SELF, under SMP we might have\n * races with threads incrementing their own counters.  But since word\n * reads are atomic, we either get new values or old values and we don't\n * care which for the sums.  We always take the siglock to protect reading\n * the c* fields from p->signal from races with exit.c updating those\n * fields when reaping, so a sample either gets all the additions of a\n * given child after it's reaped, or none so this sample is before reaping.\n *\n * Locking:\n * We need to take the siglock for CHILDEREN, SELF and BOTH\n * for  the cases current multithreaded, non-current single threaded\n * non-current multithreaded.  Thread traversal is now safe with\n * the siglock held.\n * Strictly speaking, we donot need to take the siglock if we are current and\n * single threaded,  as no one else can take our signal_struct away, no one\n * else can  reap the  children to update signal->c* counters, and no one else\n * can race with the signal-> fields. If we do not take any lock, the\n * signal-> fields could be read out of order while another thread was just\n * exiting. So we should  place a read memory barrier when we avoid the lock.\n * On the writer side,  write memory barrier is implied in  __exit_signal\n * as __exit_signal releases  the siglock spinlock after updating the signal->\n * fields. But we don't do this yet to keep things simple.\n *\n */\n\nstatic void accumulate_thread_rusage(struct task_struct *t, struct rusage *r)\n{\n\tr->ru_nvcsw += t->nvcsw;\n\tr->ru_nivcsw += t->nivcsw;\n\tr->ru_minflt += t->min_flt;\n\tr->ru_majflt += t->maj_flt;\n\tr->ru_inblock += task_io_get_inblock(t);\n\tr->ru_oublock += task_io_get_oublock(t);\n}\n\nvoid getrusage(struct task_struct *p, int who, struct rusage *r)\n{\n\tstruct task_struct *t;\n\tunsigned long flags;\n\tu64 tgutime, tgstime, utime, stime;\n\tunsigned long maxrss = 0;\n\n\tmemset((char *)r, 0, sizeof (*r));\n\tutime = stime = 0;\n\n\tif (who == RUSAGE_THREAD) {\n\t\ttask_cputime_adjusted(current, &utime, &stime);\n\t\taccumulate_thread_rusage(p, r);\n\t\tmaxrss = p->signal->maxrss;\n\t\tgoto out;\n\t}\n\n\tif (!lock_task_sighand(p, &flags))\n\t\treturn;\n\n\tswitch (who) {\n\tcase RUSAGE_BOTH:\n\tcase RUSAGE_CHILDREN:\n\t\tutime = p->signal->cutime;\n\t\tstime = p->signal->cstime;\n\t\tr->ru_nvcsw = p->signal->cnvcsw;\n\t\tr->ru_nivcsw = p->signal->cnivcsw;\n\t\tr->ru_minflt = p->signal->cmin_flt;\n\t\tr->ru_majflt = p->signal->cmaj_flt;\n\t\tr->ru_inblock = p->signal->cinblock;\n\t\tr->ru_oublock = p->signal->coublock;\n\t\tmaxrss = p->signal->cmaxrss;\n\n\t\tif (who == RUSAGE_CHILDREN)\n\t\t\tbreak;\n\t\tfallthrough;\n\n\tcase RUSAGE_SELF:\n\t\tthread_group_cputime_adjusted(p, &tgutime, &tgstime);\n\t\tutime += tgutime;\n\t\tstime += tgstime;\n\t\tr->ru_nvcsw += p->signal->nvcsw;\n\t\tr->ru_nivcsw += p->signal->nivcsw;\n\t\tr->ru_minflt += p->signal->min_flt;\n\t\tr->ru_majflt += p->signal->maj_flt;\n\t\tr->ru_inblock += p->signal->inblock;\n\t\tr->ru_oublock += p->signal->oublock;\n\t\tif (maxrss < p->signal->maxrss)\n\t\t\tmaxrss = p->signal->maxrss;\n\t\tt = p;\n\t\tdo {\n\t\t\taccumulate_thread_rusage(t, r);\n\t\t} while_each_thread(p, t);\n\t\tbreak;\n\n\tdefault:\n\t\tBUG();\n\t}\n\tunlock_task_sighand(p, &flags);\n\nout:\n\tr->ru_utime = ns_to_kernel_old_timeval(utime);\n\tr->ru_stime = ns_to_kernel_old_timeval(stime);\n\n\tif (who != RUSAGE_CHILDREN) {\n\t\tstruct mm_struct *mm = get_task_mm(p);\n\n\t\tif (mm) {\n\t\t\tsetmax_mm_hiwater_rss(&maxrss, mm);\n\t\t\tmmput(mm);\n\t\t}\n\t}\n\tr->ru_maxrss = maxrss * (PAGE_SIZE / 1024); /* convert pages to KBs */\n}\n\nSYSCALL_DEFINE2(getrusage, int, who, struct rusage __user *, ru)\n{\n\tstruct rusage r;\n\n\tif (who != RUSAGE_SELF && who != RUSAGE_CHILDREN &&\n\t    who != RUSAGE_THREAD)\n\t\treturn -EINVAL;\n\n\tgetrusage(current, who, &r);\n\treturn copy_to_user(ru, &r, sizeof(r)) ? -EFAULT : 0;\n}\n\n#ifdef CONFIG_COMPAT\nCOMPAT_SYSCALL_DEFINE2(getrusage, int, who, struct compat_rusage __user *, ru)\n{\n\tstruct rusage r;\n\n\tif (who != RUSAGE_SELF && who != RUSAGE_CHILDREN &&\n\t    who != RUSAGE_THREAD)\n\t\treturn -EINVAL;\n\n\tgetrusage(current, who, &r);\n\treturn put_compat_rusage(&r, ru);\n}\n#endif\n\nSYSCALL_DEFINE1(umask, int, mask)\n{\n\tmask = xchg(&current->fs->umask, mask & S_IRWXUGO);\n\treturn mask;\n}\n\nstatic int prctl_set_mm_exe_file(struct mm_struct *mm, unsigned int fd)\n{\n\tstruct fd exe;\n\tstruct inode *inode;\n\tint err;\n\n\texe = fdget(fd);\n\tif (!exe.file)\n\t\treturn -EBADF;\n\n\tinode = file_inode(exe.file);\n\n\t/*\n\t * Because the original mm->exe_file points to executable file, make\n\t * sure that this one is executable as well, to avoid breaking an\n\t * overall picture.\n\t */\n\terr = -EACCES;\n\tif (!S_ISREG(inode->i_mode) || path_noexec(&exe.file->f_path))\n\t\tgoto exit;\n\n\terr = file_permission(exe.file, MAY_EXEC);\n\tif (err)\n\t\tgoto exit;\n\n\terr = replace_mm_exe_file(mm, exe.file);\nexit:\n\tfdput(exe);\n\treturn err;\n}\n\n/*\n * Check arithmetic relations of passed addresses.\n *\n * WARNING: we don't require any capability here so be very careful\n * in what is allowed for modification from userspace.\n */\nstatic int validate_prctl_map_addr(struct prctl_mm_map *prctl_map)\n{\n\tunsigned long mmap_max_addr = TASK_SIZE;\n\tint error = -EINVAL, i;\n\n\tstatic const unsigned char offsets[] = {\n\t\toffsetof(struct prctl_mm_map, start_code),\n\t\toffsetof(struct prctl_mm_map, end_code),\n\t\toffsetof(struct prctl_mm_map, start_data),\n\t\toffsetof(struct prctl_mm_map, end_data),\n\t\toffsetof(struct prctl_mm_map, start_brk),\n\t\toffsetof(struct prctl_mm_map, brk),\n\t\toffsetof(struct prctl_mm_map, start_stack),\n\t\toffsetof(struct prctl_mm_map, arg_start),\n\t\toffsetof(struct prctl_mm_map, arg_end),\n\t\toffsetof(struct prctl_mm_map, env_start),\n\t\toffsetof(struct prctl_mm_map, env_end),\n\t};\n\n\t/*\n\t * Make sure the members are not somewhere outside\n\t * of allowed address space.\n\t */\n\tfor (i = 0; i < ARRAY_SIZE(offsets); i++) {\n\t\tu64 val = *(u64 *)((char *)prctl_map + offsets[i]);\n\n\t\tif ((unsigned long)val >= mmap_max_addr ||\n\t\t    (unsigned long)val < mmap_min_addr)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * Make sure the pairs are ordered.\n\t */\n#define __prctl_check_order(__m1, __op, __m2)\t\t\t\t\\\n\t((unsigned long)prctl_map->__m1 __op\t\t\t\t\\\n\t (unsigned long)prctl_map->__m2) ? 0 : -EINVAL\n\terror  = __prctl_check_order(start_code, <, end_code);\n\terror |= __prctl_check_order(start_data,<=, end_data);\n\terror |= __prctl_check_order(start_brk, <=, brk);\n\terror |= __prctl_check_order(arg_start, <=, arg_end);\n\terror |= __prctl_check_order(env_start, <=, env_end);\n\tif (error)\n\t\tgoto out;\n#undef __prctl_check_order\n\n\terror = -EINVAL;\n\n\t/*\n\t * Neither we should allow to override limits if they set.\n\t */\n\tif (check_data_rlimit(rlimit(RLIMIT_DATA), prctl_map->brk,\n\t\t\t      prctl_map->start_brk, prctl_map->end_data,\n\t\t\t      prctl_map->start_data))\n\t\t\tgoto out;\n\n\terror = 0;\nout:\n\treturn error;\n}\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\nstatic int prctl_set_mm_map(int opt, const void __user *addr, unsigned long data_size)\n{\n\tstruct prctl_mm_map prctl_map = { .exe_fd = (u32)-1, };\n\tunsigned long user_auxv[AT_VECTOR_SIZE];\n\tstruct mm_struct *mm = current->mm;\n\tint error;\n\n\tBUILD_BUG_ON(sizeof(user_auxv) != sizeof(mm->saved_auxv));\n\tBUILD_BUG_ON(sizeof(struct prctl_mm_map) > 256);\n\n\tif (opt == PR_SET_MM_MAP_SIZE)\n\t\treturn put_user((unsigned int)sizeof(prctl_map),\n\t\t\t\t(unsigned int __user *)addr);\n\n\tif (data_size != sizeof(prctl_map))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&prctl_map, addr, sizeof(prctl_map)))\n\t\treturn -EFAULT;\n\n\terror = validate_prctl_map_addr(&prctl_map);\n\tif (error)\n\t\treturn error;\n\n\tif (prctl_map.auxv_size) {\n\t\t/*\n\t\t * Someone is trying to cheat the auxv vector.\n\t\t */\n\t\tif (!prctl_map.auxv ||\n\t\t\t\tprctl_map.auxv_size > sizeof(mm->saved_auxv))\n\t\t\treturn -EINVAL;\n\n\t\tmemset(user_auxv, 0, sizeof(user_auxv));\n\t\tif (copy_from_user(user_auxv,\n\t\t\t\t   (const void __user *)prctl_map.auxv,\n\t\t\t\t   prctl_map.auxv_size))\n\t\t\treturn -EFAULT;\n\n\t\t/* Last entry must be AT_NULL as specification requires */\n\t\tuser_auxv[AT_VECTOR_SIZE - 2] = AT_NULL;\n\t\tuser_auxv[AT_VECTOR_SIZE - 1] = AT_NULL;\n\t}\n\n\tif (prctl_map.exe_fd != (u32)-1) {\n\t\t/*\n\t\t * Check if the current user is checkpoint/restore capable.\n\t\t * At the time of this writing, it checks for CAP_SYS_ADMIN\n\t\t * or CAP_CHECKPOINT_RESTORE.\n\t\t * Note that a user with access to ptrace can masquerade an\n\t\t * arbitrary program as any executable, even setuid ones.\n\t\t * This may have implications in the tomoyo subsystem.\n\t\t */\n\t\tif (!checkpoint_restore_ns_capable(current_user_ns()))\n\t\t\treturn -EPERM;\n\n\t\terror = prctl_set_mm_exe_file(mm, prctl_map.exe_fd);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\t/*\n\t * arg_lock protects concurrent updates but we still need mmap_lock for\n\t * read to exclude races with sys_brk.\n\t */\n\tmmap_read_lock(mm);\n\n\t/*\n\t * We don't validate if these members are pointing to\n\t * real present VMAs because application may have correspond\n\t * VMAs already unmapped and kernel uses these members for statistics\n\t * output in procfs mostly, except\n\t *\n\t *  - @start_brk/@brk which are used in do_brk_flags but kernel lookups\n\t *    for VMAs when updating these members so anything wrong written\n\t *    here cause kernel to swear at userspace program but won't lead\n\t *    to any problem in kernel itself\n\t */\n\n\tspin_lock(&mm->arg_lock);\n\tmm->start_code\t= prctl_map.start_code;\n\tmm->end_code\t= prctl_map.end_code;\n\tmm->start_data\t= prctl_map.start_data;\n\tmm->end_data\t= prctl_map.end_data;\n\tmm->start_brk\t= prctl_map.start_brk;\n\tmm->brk\t\t= prctl_map.brk;\n\tmm->start_stack\t= prctl_map.start_stack;\n\tmm->arg_start\t= prctl_map.arg_start;\n\tmm->arg_end\t= prctl_map.arg_end;\n\tmm->env_start\t= prctl_map.env_start;\n\tmm->env_end\t= prctl_map.env_end;\n\tspin_unlock(&mm->arg_lock);\n\n\t/*\n\t * Note this update of @saved_auxv is lockless thus\n\t * if someone reads this member in procfs while we're\n\t * updating -- it may get partly updated results. It's\n\t * known and acceptable trade off: we leave it as is to\n\t * not introduce additional locks here making the kernel\n\t * more complex.\n\t */\n\tif (prctl_map.auxv_size)\n\t\tmemcpy(mm->saved_auxv, user_auxv, sizeof(user_auxv));\n\n\tmmap_read_unlock(mm);\n\treturn 0;\n}\n#endif /* CONFIG_CHECKPOINT_RESTORE */\n\nstatic int prctl_set_auxv(struct mm_struct *mm, unsigned long addr,\n\t\t\t  unsigned long len)\n{\n\t/*\n\t * This doesn't move the auxiliary vector itself since it's pinned to\n\t * mm_struct, but it permits filling the vector with new values.  It's\n\t * up to the caller to provide sane values here, otherwise userspace\n\t * tools which use this vector might be unhappy.\n\t */\n\tunsigned long user_auxv[AT_VECTOR_SIZE] = {};\n\n\tif (len > sizeof(user_auxv))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(user_auxv, (const void __user *)addr, len))\n\t\treturn -EFAULT;\n\n\t/* Make sure the last entry is always AT_NULL */\n\tuser_auxv[AT_VECTOR_SIZE - 2] = 0;\n\tuser_auxv[AT_VECTOR_SIZE - 1] = 0;\n\n\tBUILD_BUG_ON(sizeof(user_auxv) != sizeof(mm->saved_auxv));\n\n\ttask_lock(current);\n\tmemcpy(mm->saved_auxv, user_auxv, len);\n\ttask_unlock(current);\n\n\treturn 0;\n}\n\nstatic int prctl_set_mm(int opt, unsigned long addr,\n\t\t\tunsigned long arg4, unsigned long arg5)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct prctl_mm_map prctl_map = {\n\t\t.auxv = NULL,\n\t\t.auxv_size = 0,\n\t\t.exe_fd = -1,\n\t};\n\tstruct vm_area_struct *vma;\n\tint error;\n\n\tif (arg5 || (arg4 && (opt != PR_SET_MM_AUXV &&\n\t\t\t      opt != PR_SET_MM_MAP &&\n\t\t\t      opt != PR_SET_MM_MAP_SIZE)))\n\t\treturn -EINVAL;\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\n\tif (opt == PR_SET_MM_MAP || opt == PR_SET_MM_MAP_SIZE)\n\t\treturn prctl_set_mm_map(opt, (const void __user *)addr, arg4);\n#endif\n\n\tif (!capable(CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\n\tif (opt == PR_SET_MM_EXE_FILE)\n\t\treturn prctl_set_mm_exe_file(mm, (unsigned int)addr);\n\n\tif (opt == PR_SET_MM_AUXV)\n\t\treturn prctl_set_auxv(mm, addr, arg4);\n\n\tif (addr >= TASK_SIZE || addr < mmap_min_addr)\n\t\treturn -EINVAL;\n\n\terror = -EINVAL;\n\n\t/*\n\t * arg_lock protects concurrent updates of arg boundaries, we need\n\t * mmap_lock for a) concurrent sys_brk, b) finding VMA for addr\n\t * validation.\n\t */\n\tmmap_read_lock(mm);\n\tvma = find_vma(mm, addr);\n\n\tspin_lock(&mm->arg_lock);\n\tprctl_map.start_code\t= mm->start_code;\n\tprctl_map.end_code\t= mm->end_code;\n\tprctl_map.start_data\t= mm->start_data;\n\tprctl_map.end_data\t= mm->end_data;\n\tprctl_map.start_brk\t= mm->start_brk;\n\tprctl_map.brk\t\t= mm->brk;\n\tprctl_map.start_stack\t= mm->start_stack;\n\tprctl_map.arg_start\t= mm->arg_start;\n\tprctl_map.arg_end\t= mm->arg_end;\n\tprctl_map.env_start\t= mm->env_start;\n\tprctl_map.env_end\t= mm->env_end;\n\n\tswitch (opt) {\n\tcase PR_SET_MM_START_CODE:\n\t\tprctl_map.start_code = addr;\n\t\tbreak;\n\tcase PR_SET_MM_END_CODE:\n\t\tprctl_map.end_code = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_DATA:\n\t\tprctl_map.start_data = addr;\n\t\tbreak;\n\tcase PR_SET_MM_END_DATA:\n\t\tprctl_map.end_data = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_STACK:\n\t\tprctl_map.start_stack = addr;\n\t\tbreak;\n\tcase PR_SET_MM_START_BRK:\n\t\tprctl_map.start_brk = addr;\n\t\tbreak;\n\tcase PR_SET_MM_BRK:\n\t\tprctl_map.brk = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ARG_START:\n\t\tprctl_map.arg_start = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ARG_END:\n\t\tprctl_map.arg_end = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ENV_START:\n\t\tprctl_map.env_start = addr;\n\t\tbreak;\n\tcase PR_SET_MM_ENV_END:\n\t\tprctl_map.env_end = addr;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\terror = validate_prctl_map_addr(&prctl_map);\n\tif (error)\n\t\tgoto out;\n\n\tswitch (opt) {\n\t/*\n\t * If command line arguments and environment\n\t * are placed somewhere else on stack, we can\n\t * set them up here, ARG_START/END to setup\n\t * command line arguments and ENV_START/END\n\t * for environment.\n\t */\n\tcase PR_SET_MM_START_STACK:\n\tcase PR_SET_MM_ARG_START:\n\tcase PR_SET_MM_ARG_END:\n\tcase PR_SET_MM_ENV_START:\n\tcase PR_SET_MM_ENV_END:\n\t\tif (!vma) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmm->start_code\t= prctl_map.start_code;\n\tmm->end_code\t= prctl_map.end_code;\n\tmm->start_data\t= prctl_map.start_data;\n\tmm->end_data\t= prctl_map.end_data;\n\tmm->start_brk\t= prctl_map.start_brk;\n\tmm->brk\t\t= prctl_map.brk;\n\tmm->start_stack\t= prctl_map.start_stack;\n\tmm->arg_start\t= prctl_map.arg_start;\n\tmm->arg_end\t= prctl_map.arg_end;\n\tmm->env_start\t= prctl_map.env_start;\n\tmm->env_end\t= prctl_map.env_end;\n\n\terror = 0;\nout:\n\tspin_unlock(&mm->arg_lock);\n\tmmap_read_unlock(mm);\n\treturn error;\n}\n\n#ifdef CONFIG_CHECKPOINT_RESTORE\nstatic int prctl_get_tid_address(struct task_struct *me, int __user * __user *tid_addr)\n{\n\treturn put_user(me->clear_child_tid, tid_addr);\n}\n#else\nstatic int prctl_get_tid_address(struct task_struct *me, int __user * __user *tid_addr)\n{\n\treturn -EINVAL;\n}\n#endif\n\nstatic int propagate_has_child_subreaper(struct task_struct *p, void *data)\n{\n\t/*\n\t * If task has has_child_subreaper - all its descendants\n\t * already have these flag too and new descendants will\n\t * inherit it on fork, skip them.\n\t *\n\t * If we've found child_reaper - skip descendants in\n\t * it's subtree as they will never get out pidns.\n\t */\n\tif (p->signal->has_child_subreaper ||\n\t    is_child_reaper(task_pid(p)))\n\t\treturn 0;\n\n\tp->signal->has_child_subreaper = 1;\n\treturn 1;\n}\n\nint __weak arch_prctl_spec_ctrl_get(struct task_struct *t, unsigned long which)\n{\n\treturn -EINVAL;\n}\n\nint __weak arch_prctl_spec_ctrl_set(struct task_struct *t, unsigned long which,\n\t\t\t\t    unsigned long ctrl)\n{\n\treturn -EINVAL;\n}\n\n#define PR_IO_FLUSHER (PF_MEMALLOC_NOIO | PF_LOCAL_THROTTLE)\n\n#ifdef CONFIG_ANON_VMA_NAME\n\n#define ANON_VMA_NAME_MAX_LEN\t\t80\n#define ANON_VMA_NAME_INVALID_CHARS\t\"\\\\`$[]\"\n\nstatic inline bool is_valid_name_char(char ch)\n{\n\t/* printable ascii characters, excluding ANON_VMA_NAME_INVALID_CHARS */\n\treturn ch > 0x1f && ch < 0x7f &&\n\t\t!strchr(ANON_VMA_NAME_INVALID_CHARS, ch);\n}\n\nstatic int prctl_set_vma(unsigned long opt, unsigned long addr,\n\t\t\t unsigned long size, unsigned long arg)\n{\n\tstruct mm_struct *mm = current->mm;\n\tconst char __user *uname;\n\tstruct anon_vma_name *anon_name = NULL;\n\tint error;\n\n\tswitch (opt) {\n\tcase PR_SET_VMA_ANON_NAME:\n\t\tuname = (const char __user *)arg;\n\t\tif (uname) {\n\t\t\tchar *name, *pch;\n\n\t\t\tname = strndup_user(uname, ANON_VMA_NAME_MAX_LEN);\n\t\t\tif (IS_ERR(name))\n\t\t\t\treturn PTR_ERR(name);\n\n\t\t\tfor (pch = name; *pch != '\\0'; pch++) {\n\t\t\t\tif (!is_valid_name_char(*pch)) {\n\t\t\t\t\tkfree(name);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* anon_vma has its own copy */\n\t\t\tanon_name = anon_vma_name_alloc(name);\n\t\t\tkfree(name);\n\t\t\tif (!anon_name)\n\t\t\t\treturn -ENOMEM;\n\n\t\t}\n\n\t\tmmap_write_lock(mm);\n\t\terror = madvise_set_anon_name(mm, addr, size, anon_name);\n\t\tmmap_write_unlock(mm);\n\t\tanon_vma_name_put(anon_name);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t}\n\n\treturn error;\n}\n\n#else /* CONFIG_ANON_VMA_NAME */\nstatic int prctl_set_vma(unsigned long opt, unsigned long start,\n\t\t\t unsigned long size, unsigned long arg)\n{\n\treturn -EINVAL;\n}\n#endif /* CONFIG_ANON_VMA_NAME */\n\nSYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,\n\t\tunsigned long, arg4, unsigned long, arg5)\n{\n\tstruct task_struct *me = current;\n\tunsigned char comm[sizeof(me->comm)];\n\tlong error;\n\n\terror = security_task_prctl(option, arg2, arg3, arg4, arg5);\n\tif (error != -ENOSYS)\n\t\treturn error;\n\n\terror = 0;\n\tswitch (option) {\n\tcase PR_SET_PDEATHSIG:\n\t\tif (!valid_signal(arg2)) {\n\t\t\terror = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tme->pdeath_signal = arg2;\n\t\tbreak;\n\tcase PR_GET_PDEATHSIG:\n\t\terror = put_user(me->pdeath_signal, (int __user *)arg2);\n\t\tbreak;\n\tcase PR_GET_DUMPABLE:\n\t\terror = get_dumpable(me->mm);\n\t\tbreak;\n\tcase PR_SET_DUMPABLE:\n\t\tif (arg2 != SUID_DUMP_DISABLE && arg2 != SUID_DUMP_USER) {\n\t\t\terror = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tset_dumpable(me->mm, arg2);\n\t\tbreak;\n\n\tcase PR_SET_UNALIGN:\n\t\terror = SET_UNALIGN_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_UNALIGN:\n\t\terror = GET_UNALIGN_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_SET_FPEMU:\n\t\terror = SET_FPEMU_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FPEMU:\n\t\terror = GET_FPEMU_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_SET_FPEXC:\n\t\terror = SET_FPEXC_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FPEXC:\n\t\terror = GET_FPEXC_CTL(me, arg2);\n\t\tbreak;\n\tcase PR_GET_TIMING:\n\t\terror = PR_TIMING_STATISTICAL;\n\t\tbreak;\n\tcase PR_SET_TIMING:\n\t\tif (arg2 != PR_TIMING_STATISTICAL)\n\t\t\terror = -EINVAL;\n\t\tbreak;\n\tcase PR_SET_NAME:\n\t\tcomm[sizeof(me->comm) - 1] = 0;\n\t\tif (strncpy_from_user(comm, (char __user *)arg2,\n\t\t\t\t      sizeof(me->comm) - 1) < 0)\n\t\t\treturn -EFAULT;\n\t\tset_task_comm(me, comm);\n\t\tproc_comm_connector(me);\n\t\tbreak;\n\tcase PR_GET_NAME:\n\t\tget_task_comm(comm, me);\n\t\tif (copy_to_user((char __user *)arg2, comm, sizeof(comm)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\tcase PR_GET_ENDIAN:\n\t\terror = GET_ENDIAN(me, arg2);\n\t\tbreak;\n\tcase PR_SET_ENDIAN:\n\t\terror = SET_ENDIAN(me, arg2);\n\t\tbreak;\n\tcase PR_GET_SECCOMP:\n\t\terror = prctl_get_seccomp();\n\t\tbreak;\n\tcase PR_SET_SECCOMP:\n\t\terror = prctl_set_seccomp(arg2, (char __user *)arg3);\n\t\tbreak;\n\tcase PR_GET_TSC:\n\t\terror = GET_TSC_CTL(arg2);\n\t\tbreak;\n\tcase PR_SET_TSC:\n\t\terror = SET_TSC_CTL(arg2);\n\t\tbreak;\n\tcase PR_TASK_PERF_EVENTS_DISABLE:\n\t\terror = perf_event_task_disable();\n\t\tbreak;\n\tcase PR_TASK_PERF_EVENTS_ENABLE:\n\t\terror = perf_event_task_enable();\n\t\tbreak;\n\tcase PR_GET_TIMERSLACK:\n\t\tif (current->timer_slack_ns > ULONG_MAX)\n\t\t\terror = ULONG_MAX;\n\t\telse\n\t\t\terror = current->timer_slack_ns;\n\t\tbreak;\n\tcase PR_SET_TIMERSLACK:\n\t\tif (arg2 <= 0)\n\t\t\tcurrent->timer_slack_ns =\n\t\t\t\t\tcurrent->default_timer_slack_ns;\n\t\telse\n\t\t\tcurrent->timer_slack_ns = arg2;\n\t\tbreak;\n\tcase PR_MCE_KILL:\n\t\tif (arg4 | arg5)\n\t\t\treturn -EINVAL;\n\t\tswitch (arg2) {\n\t\tcase PR_MCE_KILL_CLEAR:\n\t\t\tif (arg3 != 0)\n\t\t\t\treturn -EINVAL;\n\t\t\tcurrent->flags &= ~PF_MCE_PROCESS;\n\t\t\tbreak;\n\t\tcase PR_MCE_KILL_SET:\n\t\t\tcurrent->flags |= PF_MCE_PROCESS;\n\t\t\tif (arg3 == PR_MCE_KILL_EARLY)\n\t\t\t\tcurrent->flags |= PF_MCE_EARLY;\n\t\t\telse if (arg3 == PR_MCE_KILL_LATE)\n\t\t\t\tcurrent->flags &= ~PF_MCE_EARLY;\n\t\t\telse if (arg3 == PR_MCE_KILL_DEFAULT)\n\t\t\t\tcurrent->flags &=\n\t\t\t\t\t\t~(PF_MCE_EARLY|PF_MCE_PROCESS);\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase PR_MCE_KILL_GET:\n\t\tif (arg2 | arg3 | arg4 | arg5)\n\t\t\treturn -EINVAL;\n\t\tif (current->flags & PF_MCE_PROCESS)\n\t\t\terror = (current->flags & PF_MCE_EARLY) ?\n\t\t\t\tPR_MCE_KILL_EARLY : PR_MCE_KILL_LATE;\n\t\telse\n\t\t\terror = PR_MCE_KILL_DEFAULT;\n\t\tbreak;\n\tcase PR_SET_MM:\n\t\terror = prctl_set_mm(arg2, arg3, arg4, arg5);\n\t\tbreak;\n\tcase PR_GET_TID_ADDRESS:\n\t\terror = prctl_get_tid_address(me, (int __user * __user *)arg2);\n\t\tbreak;\n\tcase PR_SET_CHILD_SUBREAPER:\n\t\tme->signal->is_child_subreaper = !!arg2;\n\t\tif (!arg2)\n\t\t\tbreak;\n\n\t\twalk_process_tree(me, propagate_has_child_subreaper, NULL);\n\t\tbreak;\n\tcase PR_GET_CHILD_SUBREAPER:\n\t\terror = put_user(me->signal->is_child_subreaper,\n\t\t\t\t (int __user *)arg2);\n\t\tbreak;\n\tcase PR_SET_NO_NEW_PRIVS:\n\t\tif (arg2 != 1 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\ttask_set_no_new_privs(current);\n\t\tbreak;\n\tcase PR_GET_NO_NEW_PRIVS:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\treturn task_no_new_privs(current) ? 1 : 0;\n\tcase PR_GET_THP_DISABLE:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = !!test_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\tbreak;\n\tcase PR_SET_THP_DISABLE:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\tif (mmap_write_lock_killable(me->mm))\n\t\t\treturn -EINTR;\n\t\tif (arg2)\n\t\t\tset_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\telse\n\t\t\tclear_bit(MMF_DISABLE_THP, &me->mm->flags);\n\t\tmmap_write_unlock(me->mm);\n\t\tbreak;\n\tcase PR_MPX_ENABLE_MANAGEMENT:\n\tcase PR_MPX_DISABLE_MANAGEMENT:\n\t\t/* No longer implemented: */\n\t\treturn -EINVAL;\n\tcase PR_SET_FP_MODE:\n\t\terror = SET_FP_MODE(me, arg2);\n\t\tbreak;\n\tcase PR_GET_FP_MODE:\n\t\terror = GET_FP_MODE(me);\n\t\tbreak;\n\tcase PR_SVE_SET_VL:\n\t\terror = SVE_SET_VL(arg2);\n\t\tbreak;\n\tcase PR_SVE_GET_VL:\n\t\terror = SVE_GET_VL();\n\t\tbreak;\n\tcase PR_SME_SET_VL:\n\t\terror = SME_SET_VL(arg2);\n\t\tbreak;\n\tcase PR_SME_GET_VL:\n\t\terror = SME_GET_VL();\n\t\tbreak;\n\tcase PR_GET_SPECULATION_CTRL:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = arch_prctl_spec_ctrl_get(me, arg2);\n\t\tbreak;\n\tcase PR_SET_SPECULATION_CTRL:\n\t\tif (arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = arch_prctl_spec_ctrl_set(me, arg2, arg3);\n\t\tbreak;\n\tcase PR_PAC_RESET_KEYS:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_RESET_KEYS(me, arg2);\n\t\tbreak;\n\tcase PR_PAC_SET_ENABLED_KEYS:\n\t\tif (arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_SET_ENABLED_KEYS(me, arg2, arg3);\n\t\tbreak;\n\tcase PR_PAC_GET_ENABLED_KEYS:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = PAC_GET_ENABLED_KEYS(me);\n\t\tbreak;\n\tcase PR_SET_TAGGED_ADDR_CTRL:\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = SET_TAGGED_ADDR_CTRL(arg2);\n\t\tbreak;\n\tcase PR_GET_TAGGED_ADDR_CTRL:\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\t\terror = GET_TAGGED_ADDR_CTRL();\n\t\tbreak;\n\tcase PR_SET_IO_FLUSHER:\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\tif (arg2 == 1)\n\t\t\tcurrent->flags |= PR_IO_FLUSHER;\n\t\telse if (!arg2)\n\t\t\tcurrent->flags &= ~PR_IO_FLUSHER;\n\t\telse\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase PR_GET_IO_FLUSHER:\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (arg2 || arg3 || arg4 || arg5)\n\t\t\treturn -EINVAL;\n\n\t\terror = (current->flags & PR_IO_FLUSHER) == PR_IO_FLUSHER;\n\t\tbreak;\n\tcase PR_SET_SYSCALL_USER_DISPATCH:\n\t\terror = set_syscall_user_dispatch(arg2, arg3, arg4,\n\t\t\t\t\t\t  (char __user *) arg5);\n\t\tbreak;\n#ifdef CONFIG_SCHED_CORE\n\tcase PR_SCHED_CORE:\n\t\terror = sched_core_share_pid(arg2, arg3, arg4, arg5);\n\t\tbreak;\n#endif\n\tcase PR_SET_VMA:\n\t\terror = prctl_set_vma(arg2, arg3, arg4, arg5);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\n\treturn error;\n}\n\nSYSCALL_DEFINE3(getcpu, unsigned __user *, cpup, unsigned __user *, nodep,\n\t\tstruct getcpu_cache __user *, unused)\n{\n\tint err = 0;\n\tint cpu = raw_smp_processor_id();\n\n\tif (cpup)\n\t\terr |= put_user(cpu, cpup);\n\tif (nodep)\n\t\terr |= put_user(cpu_to_node(cpu), nodep);\n\treturn err ? -EFAULT : 0;\n}\n\n/**\n * do_sysinfo - fill in sysinfo struct\n * @info: pointer to buffer to fill\n */\nstatic int do_sysinfo(struct sysinfo *info)\n{\n\tunsigned long mem_total, sav_total;\n\tunsigned int mem_unit, bitcount;\n\tstruct timespec64 tp;\n\n\tmemset(info, 0, sizeof(struct sysinfo));\n\n\tktime_get_boottime_ts64(&tp);\n\ttimens_add_boottime(&tp);\n\tinfo->uptime = tp.tv_sec + (tp.tv_nsec ? 1 : 0);\n\n\tget_avenrun(info->loads, 0, SI_LOAD_SHIFT - FSHIFT);\n\n\tinfo->procs = nr_threads;\n\n\tsi_meminfo(info);\n\tsi_swapinfo(info);\n\n\t/*\n\t * If the sum of all the available memory (i.e. ram + swap)\n\t * is less than can be stored in a 32 bit unsigned long then\n\t * we can be binary compatible with 2.2.x kernels.  If not,\n\t * well, in that case 2.2.x was broken anyways...\n\t *\n\t *  -Erik Andersen <andersee@debian.org>\n\t */\n\n\tmem_total = info->totalram + info->totalswap;\n\tif (mem_total < info->totalram || mem_total < info->totalswap)\n\t\tgoto out;\n\tbitcount = 0;\n\tmem_unit = info->mem_unit;\n\twhile (mem_unit > 1) {\n\t\tbitcount++;\n\t\tmem_unit >>= 1;\n\t\tsav_total = mem_total;\n\t\tmem_total <<= 1;\n\t\tif (mem_total < sav_total)\n\t\t\tgoto out;\n\t}\n\n\t/*\n\t * If mem_total did not overflow, multiply all memory values by\n\t * info->mem_unit and set it to 1.  This leaves things compatible\n\t * with 2.2.x, and also retains compatibility with earlier 2.4.x\n\t * kernels...\n\t */\n\n\tinfo->mem_unit = 1;\n\tinfo->totalram <<= bitcount;\n\tinfo->freeram <<= bitcount;\n\tinfo->sharedram <<= bitcount;\n\tinfo->bufferram <<= bitcount;\n\tinfo->totalswap <<= bitcount;\n\tinfo->freeswap <<= bitcount;\n\tinfo->totalhigh <<= bitcount;\n\tinfo->freehigh <<= bitcount;\n\nout:\n\treturn 0;\n}\n\nSYSCALL_DEFINE1(sysinfo, struct sysinfo __user *, info)\n{\n\tstruct sysinfo val;\n\n\tdo_sysinfo(&val);\n\n\tif (copy_to_user(info, &val, sizeof(struct sysinfo)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_sysinfo {\n\ts32 uptime;\n\tu32 loads[3];\n\tu32 totalram;\n\tu32 freeram;\n\tu32 sharedram;\n\tu32 bufferram;\n\tu32 totalswap;\n\tu32 freeswap;\n\tu16 procs;\n\tu16 pad;\n\tu32 totalhigh;\n\tu32 freehigh;\n\tu32 mem_unit;\n\tchar _f[20-2*sizeof(u32)-sizeof(int)];\n};\n\nCOMPAT_SYSCALL_DEFINE1(sysinfo, struct compat_sysinfo __user *, info)\n{\n\tstruct sysinfo s;\n\tstruct compat_sysinfo s_32;\n\n\tdo_sysinfo(&s);\n\n\t/* Check to see if any memory value is too large for 32-bit and scale\n\t *  down if needed\n\t */\n\tif (upper_32_bits(s.totalram) || upper_32_bits(s.totalswap)) {\n\t\tint bitcount = 0;\n\n\t\twhile (s.mem_unit < PAGE_SIZE) {\n\t\t\ts.mem_unit <<= 1;\n\t\t\tbitcount++;\n\t\t}\n\n\t\ts.totalram >>= bitcount;\n\t\ts.freeram >>= bitcount;\n\t\ts.sharedram >>= bitcount;\n\t\ts.bufferram >>= bitcount;\n\t\ts.totalswap >>= bitcount;\n\t\ts.freeswap >>= bitcount;\n\t\ts.totalhigh >>= bitcount;\n\t\ts.freehigh >>= bitcount;\n\t}\n\n\tmemset(&s_32, 0, sizeof(s_32));\n\ts_32.uptime = s.uptime;\n\ts_32.loads[0] = s.loads[0];\n\ts_32.loads[1] = s.loads[1];\n\ts_32.loads[2] = s.loads[2];\n\ts_32.totalram = s.totalram;\n\ts_32.freeram = s.freeram;\n\ts_32.sharedram = s.sharedram;\n\ts_32.bufferram = s.bufferram;\n\ts_32.totalswap = s.totalswap;\n\ts_32.freeswap = s.freeswap;\n\ts_32.procs = s.procs;\n\ts_32.totalhigh = s.totalhigh;\n\ts_32.freehigh = s.freehigh;\n\ts_32.mem_unit = s.mem_unit;\n\tif (copy_to_user(info, &s_32, sizeof(s_32)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n#endif /* CONFIG_COMPAT */\n"], "buggy_code_start_loc": [1444], "buggy_code_end_loc": [1444], "fixing_code_start_loc": [1445], "fixing_code_end_loc": [1447], "type": "CWE-476", "message": "A speculative pointer dereference problem exists in the Linux Kernel on the do_prlimit() function. The resource argument value is controlled and is used in pointer arithmetic for the 'rlim' variable and can be used to leak the contents. We recommend upgrading past version 6.1.8 or commit\u00a0739790605705ddcf18f21782b9c99ad7d53a8c11", "other": {"cve": {"id": "CVE-2023-0458", "sourceIdentifier": "cve-coordination@google.com", "published": "2023-04-26T19:15:08.720", "lastModified": "2023-05-09T13:58:53.077", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A speculative pointer dereference problem exists in the Linux Kernel on the do_prlimit() function. The resource argument value is controlled and is used in pointer arithmetic for the 'rlim' variable and can be used to leak the contents. We recommend upgrading past version 6.1.8 or commit\u00a0739790605705ddcf18f21782b9c99ad7d53a8c11"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.7, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.0, "impactScore": 3.6}, {"source": "cve-coordination@google.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}, {"source": "cve-coordination@google.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "6.1.8", "matchCriteriaId": "3D30DC5F-EE59-4C39-AC86-E4E52220E21A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.2:rc1:*:*:*:*:*:*", "matchCriteriaId": "FF501633-2F44-4913-A8EE-B021929F49F6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.2:rc2:*:*:*:*:*:*", "matchCriteriaId": "2BDA597B-CAC1-4DF0-86F0-42E142C654E9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.2:rc3:*:*:*:*:*:*", "matchCriteriaId": "725C78C9-12CE-406F-ABE8-0813A01D66E8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.2:rc4:*:*:*:*:*:*", "matchCriteriaId": "A127C155-689C-4F67-B146-44A57F4BFD85"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}], "references": [{"url": "https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/sys.c?id=v6.1.8&id2=v6.1.7", "source": "cve-coordination@google.com", "tags": ["Patch"]}, {"url": "https://github.com/torvalds/linux/commit/739790605705ddcf18f21782b9c99ad7d53a8c11", "source": "cve-coordination@google.com", "tags": ["Patch"]}, {"url": "https://lists.debian.org/debian-lts-announce/2023/05/msg00005.html", "source": "cve-coordination@google.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2023/05/msg00006.html", "source": "cve-coordination@google.com", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/739790605705ddcf18f21782b9c99ad7d53a8c11"}}