{"buggy_code": ["/*\n * linux/ipc/shm.c\n * Copyright (C) 1992, 1993 Krishna Balasubramanian\n *\t Many improvements/fixes by Bruno Haible.\n * Replaced `struct shm_desc' by `struct vm_area_struct', July 1994.\n * Fixed the shm swap deallocation (shm_unuse()), August 1998 Andrea Arcangeli.\n *\n * /proc/sysvipc/shm support (c) 1999 Dragos Acostachioaie <dragos@iname.com>\n * BIGMEM support, Andrea Arcangeli <andrea@suse.de>\n * SMP thread shm, Jean-Luc Boyard <jean-luc.boyard@siemens.fr>\n * HIGHMEM support, Ingo Molnar <mingo@redhat.com>\n * Make shmmax, shmall, shmmni sysctl'able, Christoph Rohland <cr@sap.com>\n * Shared /dev/zero support, Kanoj Sarcar <kanoj@sgi.com>\n * Move the mm functionality over to mm/shmem.c, Christoph Rohland <cr@sap.com>\n *\n * support for audit of ipc object properties and permission changes\n * Dustin Kirkland <dustin.kirkland@us.ibm.com>\n *\n * namespaces support\n * OpenVZ, SWsoft Inc.\n * Pavel Emelianov <xemul@openvz.org>\n *\n * Better ipc lock (kern_ipc_perm.lock) handling\n * Davidlohr Bueso <davidlohr.bueso@hp.com>, June 2013.\n */\n\n#include <linux/slab.h>\n#include <linux/mm.h>\n#include <linux/hugetlb.h>\n#include <linux/shm.h>\n#include <linux/init.h>\n#include <linux/file.h>\n#include <linux/mman.h>\n#include <linux/shmem_fs.h>\n#include <linux/security.h>\n#include <linux/syscalls.h>\n#include <linux/audit.h>\n#include <linux/capability.h>\n#include <linux/ptrace.h>\n#include <linux/seq_file.h>\n#include <linux/rwsem.h>\n#include <linux/nsproxy.h>\n#include <linux/mount.h>\n#include <linux/ipc_namespace.h>\n\n#include <linux/uaccess.h>\n\n#include \"util.h\"\n\nstruct shm_file_data {\n\tint id;\n\tstruct ipc_namespace *ns;\n\tstruct file *file;\n\tconst struct vm_operations_struct *vm_ops;\n};\n\n#define shm_file_data(file) (*((struct shm_file_data **)&(file)->private_data))\n\nstatic const struct file_operations shm_file_operations;\nstatic const struct vm_operations_struct shm_vm_ops;\n\n#define shm_ids(ns)\t((ns)->ids[IPC_SHM_IDS])\n\n#define shm_unlock(shp)\t\t\t\\\n\tipc_unlock(&(shp)->shm_perm)\n\nstatic int newseg(struct ipc_namespace *, struct ipc_params *);\nstatic void shm_open(struct vm_area_struct *vma);\nstatic void shm_close(struct vm_area_struct *vma);\nstatic void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp);\n#ifdef CONFIG_PROC_FS\nstatic int sysvipc_shm_proc_show(struct seq_file *s, void *it);\n#endif\n\nvoid shm_init_ns(struct ipc_namespace *ns)\n{\n\tns->shm_ctlmax = SHMMAX;\n\tns->shm_ctlall = SHMALL;\n\tns->shm_ctlmni = SHMMNI;\n\tns->shm_rmid_forced = 0;\n\tns->shm_tot = 0;\n\tipc_init_ids(&shm_ids(ns));\n}\n\n/*\n * Called with shm_ids.rwsem (writer) and the shp structure locked.\n * Only shm_ids.rwsem remains locked on exit.\n */\nstatic void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\tif (shp->shm_nattch) {\n\t\tshp->shm_perm.mode |= SHM_DEST;\n\t\t/* Do not find it any more */\n\t\tshp->shm_perm.key = IPC_PRIVATE;\n\t\tshm_unlock(shp);\n\t} else\n\t\tshm_destroy(ns, shp);\n}\n\n#ifdef CONFIG_IPC_NS\nvoid shm_exit_ns(struct ipc_namespace *ns)\n{\n\tfree_ipcs(ns, &shm_ids(ns), do_shm_rmid);\n\tidr_destroy(&ns->ids[IPC_SHM_IDS].ipcs_idr);\n}\n#endif\n\nstatic int __init ipc_ns_init(void)\n{\n\tshm_init_ns(&init_ipc_ns);\n\treturn 0;\n}\n\npure_initcall(ipc_ns_init);\n\nvoid __init shm_init(void)\n{\n\tipc_init_proc_interface(\"sysvipc/shm\",\n#if BITS_PER_LONG <= 32\n\t\t\t\t\"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime        rss       swap\\n\",\n#else\n\t\t\t\t\"       key      shmid perms                  size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime                   rss                  swap\\n\",\n#endif\n\t\t\t\tIPC_SHM_IDS, sysvipc_shm_proc_show);\n}\n\nstatic inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&shm_ids(ns), id);\n\n\tif (IS_ERR(ipcp))\n\t\treturn ERR_CAST(ipcp);\n\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\nstatic inline struct shmid_kernel *shm_obtain_object_check(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_check(&shm_ids(ns), id);\n\n\tif (IS_ERR(ipcp))\n\t\treturn ERR_CAST(ipcp);\n\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\n/*\n * shm_lock_(check_) routines are called in the paths where the rwsem\n * is not necessarily held.\n */\nstatic inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);\n\n\t/*\n\t * Callers of shm_lock() must validate the status of the returned ipc\n\t * object pointer (as returned by ipc_lock()), and error out as\n\t * appropriate.\n\t */\n\tif (IS_ERR(ipcp))\n\t\treturn (void *)ipcp;\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\nstatic inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)\n{\n\trcu_read_lock();\n\tipc_lock_object(&ipcp->shm_perm);\n}\n\nstatic void shm_rcu_free(struct rcu_head *head)\n{\n\tstruct ipc_rcu *p = container_of(head, struct ipc_rcu, rcu);\n\tstruct shmid_kernel *shp = ipc_rcu_to_struct(p);\n\n\tsecurity_shm_free(shp);\n\tipc_rcu_free(head);\n}\n\nstatic inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)\n{\n\tlist_del(&s->shm_clist);\n\tipc_rmid(&shm_ids(ns), &s->shm_perm);\n}\n\n\nstatic int __shm_open(struct vm_area_struct *vma)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct shmid_kernel *shp;\n\n\tshp = shm_lock(sfd->ns, sfd->id);\n\n\tif (IS_ERR(shp))\n\t\treturn PTR_ERR(shp);\n\n\tshp->shm_atim = get_seconds();\n\tshp->shm_lprid = task_tgid_vnr(current);\n\tshp->shm_nattch++;\n\tshm_unlock(shp);\n\treturn 0;\n}\n\n/* This is called by fork, once for every shm attach. */\nstatic void shm_open(struct vm_area_struct *vma)\n{\n\tint err = __shm_open(vma);\n\t/*\n\t * We raced in the idr lookup or with shm_destroy().\n\t * Either way, the ID is busted.\n\t */\n\tWARN_ON_ONCE(err);\n}\n\n/*\n * shm_destroy - free the struct shmid_kernel\n *\n * @ns: namespace\n * @shp: struct to free\n *\n * It has to be called with shp and shm_ids.rwsem (writer) locked,\n * but returns with shp unlocked and freed.\n */\nstatic void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)\n{\n\tstruct file *shm_file;\n\n\tshm_file = shp->shm_file;\n\tshp->shm_file = NULL;\n\tns->shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tshm_rmid(ns, shp);\n\tshm_unlock(shp);\n\tif (!is_file_hugepages(shm_file))\n\t\tshmem_lock(shm_file, 0, shp->mlock_user);\n\telse if (shp->mlock_user)\n\t\tuser_shm_unlock(i_size_read(file_inode(shm_file)),\n\t\t\t\tshp->mlock_user);\n\tfput(shm_file);\n\tipc_rcu_putref(shp, shm_rcu_free);\n}\n\n/*\n * shm_may_destroy - identifies whether shm segment should be destroyed now\n *\n * Returns true if and only if there are no active users of the segment and\n * one of the following is true:\n *\n * 1) shmctl(id, IPC_RMID, NULL) was called for this shp\n *\n * 2) sysctl kernel.shm_rmid_forced is set to 1.\n */\nstatic bool shm_may_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)\n{\n\treturn (shp->shm_nattch == 0) &&\n\t       (ns->shm_rmid_forced ||\n\t\t(shp->shm_perm.mode & SHM_DEST));\n}\n\n/*\n * remove the attach descriptor vma.\n * free memory for segment if it is marked destroyed.\n * The descriptor has already been removed from the current->mm->mmap list\n * and will later be kfree()d.\n */\nstatic void shm_close(struct vm_area_struct *vma)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct shmid_kernel *shp;\n\tstruct ipc_namespace *ns = sfd->ns;\n\n\tdown_write(&shm_ids(ns).rwsem);\n\t/* remove from the list of attaches of the shm segment */\n\tshp = shm_lock(ns, sfd->id);\n\n\t/*\n\t * We raced in the idr lookup or with shm_destroy().\n\t * Either way, the ID is busted.\n\t */\n\tif (WARN_ON_ONCE(IS_ERR(shp)))\n\t\tgoto done; /* no-op */\n\n\tshp->shm_lprid = task_tgid_vnr(current);\n\tshp->shm_dtim = get_seconds();\n\tshp->shm_nattch--;\n\tif (shm_may_destroy(ns, shp))\n\t\tshm_destroy(ns, shp);\n\telse\n\t\tshm_unlock(shp);\ndone:\n\tup_write(&shm_ids(ns).rwsem);\n}\n\n/* Called with ns->shm_ids(ns).rwsem locked */\nstatic int shm_try_destroy_orphaned(int id, void *p, void *data)\n{\n\tstruct ipc_namespace *ns = data;\n\tstruct kern_ipc_perm *ipcp = p;\n\tstruct shmid_kernel *shp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\t/*\n\t * We want to destroy segments without users and with already\n\t * exit'ed originating process.\n\t *\n\t * As shp->* are changed under rwsem, it's safe to skip shp locking.\n\t */\n\tif (shp->shm_creator != NULL)\n\t\treturn 0;\n\n\tif (shm_may_destroy(ns, shp)) {\n\t\tshm_lock_by_ptr(shp);\n\t\tshm_destroy(ns, shp);\n\t}\n\treturn 0;\n}\n\nvoid shm_destroy_orphaned(struct ipc_namespace *ns)\n{\n\tdown_write(&shm_ids(ns).rwsem);\n\tif (shm_ids(ns).in_use)\n\t\tidr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);\n\tup_write(&shm_ids(ns).rwsem);\n}\n\n/* Locking assumes this will only be called with task == current */\nvoid exit_shm(struct task_struct *task)\n{\n\tstruct ipc_namespace *ns = task->nsproxy->ipc_ns;\n\tstruct shmid_kernel *shp, *n;\n\n\tif (list_empty(&task->sysvshm.shm_clist))\n\t\treturn;\n\n\t/*\n\t * If kernel.shm_rmid_forced is not set then only keep track of\n\t * which shmids are orphaned, so that a later set of the sysctl\n\t * can clean them up.\n\t */\n\tif (!ns->shm_rmid_forced) {\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\tlist_for_each_entry(shp, &task->sysvshm.shm_clist, shm_clist)\n\t\t\tshp->shm_creator = NULL;\n\t\t/*\n\t\t * Only under read lock but we are only called on current\n\t\t * so no entry on the list will be shared.\n\t\t */\n\t\tlist_del(&task->sysvshm.shm_clist);\n\t\tup_read(&shm_ids(ns).rwsem);\n\t\treturn;\n\t}\n\n\t/*\n\t * Destroy all already created segments, that were not yet mapped,\n\t * and mark any mapped as orphan to cover the sysctl toggling.\n\t * Destroy is skipped if shm_may_destroy() returns false.\n\t */\n\tdown_write(&shm_ids(ns).rwsem);\n\tlist_for_each_entry_safe(shp, n, &task->sysvshm.shm_clist, shm_clist) {\n\t\tshp->shm_creator = NULL;\n\n\t\tif (shm_may_destroy(ns, shp)) {\n\t\t\tshm_lock_by_ptr(shp);\n\t\t\tshm_destroy(ns, shp);\n\t\t}\n\t}\n\n\t/* Remove the list head from any segments still attached. */\n\tlist_del(&task->sysvshm.shm_clist);\n\tup_write(&shm_ids(ns).rwsem);\n}\n\nstatic int shm_fault(struct vm_fault *vmf)\n{\n\tstruct file *file = vmf->vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\treturn sfd->vm_ops->fault(vmf);\n}\n\n#ifdef CONFIG_NUMA\nstatic int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tint err = 0;\n\n\tif (sfd->vm_ops->set_policy)\n\t\terr = sfd->vm_ops->set_policy(vma, new);\n\treturn err;\n}\n\nstatic struct mempolicy *shm_get_policy(struct vm_area_struct *vma,\n\t\t\t\t\tunsigned long addr)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct mempolicy *pol = NULL;\n\n\tif (sfd->vm_ops->get_policy)\n\t\tpol = sfd->vm_ops->get_policy(vma, addr);\n\telse if (vma->vm_policy)\n\t\tpol = vma->vm_policy;\n\n\treturn pol;\n}\n#endif\n\nstatic int shm_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tint ret;\n\n\t/*\n\t * In case of remap_file_pages() emulation, the file can represent\n\t * removed IPC ID: propogate shm_lock() error to caller.\n\t */\n\tret = __shm_open(vma);\n\tif (ret)\n\t\treturn ret;\n\n\tret = sfd->file->f_op->mmap(sfd->file, vma);\n\tif (ret) {\n\t\tshm_close(vma);\n\t\treturn ret;\n\t}\n\tsfd->vm_ops = vma->vm_ops;\n#ifdef CONFIG_MMU\n\tWARN_ON(!sfd->vm_ops->fault);\n#endif\n\tvma->vm_ops = &shm_vm_ops;\n\treturn 0;\n}\n\nstatic int shm_release(struct inode *ino, struct file *file)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tput_ipc_ns(sfd->ns);\n\tshm_file_data(file) = NULL;\n\tkfree(sfd);\n\treturn 0;\n}\n\nstatic int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tif (!sfd->file->f_op->fsync)\n\t\treturn -EINVAL;\n\treturn sfd->file->f_op->fsync(sfd->file, start, end, datasync);\n}\n\nstatic long shm_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t  loff_t len)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tif (!sfd->file->f_op->fallocate)\n\t\treturn -EOPNOTSUPP;\n\treturn sfd->file->f_op->fallocate(file, mode, offset, len);\n}\n\nstatic unsigned long shm_get_unmapped_area(struct file *file,\n\tunsigned long addr, unsigned long len, unsigned long pgoff,\n\tunsigned long flags)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\treturn sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,\n\t\t\t\t\t\tpgoff, flags);\n}\n\nstatic const struct file_operations shm_file_operations = {\n\t.mmap\t\t= shm_mmap,\n\t.fsync\t\t= shm_fsync,\n\t.release\t= shm_release,\n\t.get_unmapped_area\t= shm_get_unmapped_area,\n\t.llseek\t\t= noop_llseek,\n\t.fallocate\t= shm_fallocate,\n};\n\n/*\n * shm_file_operations_huge is now identical to shm_file_operations,\n * but we keep it distinct for the sake of is_file_shm_hugepages().\n */\nstatic const struct file_operations shm_file_operations_huge = {\n\t.mmap\t\t= shm_mmap,\n\t.fsync\t\t= shm_fsync,\n\t.release\t= shm_release,\n\t.get_unmapped_area\t= shm_get_unmapped_area,\n\t.llseek\t\t= noop_llseek,\n\t.fallocate\t= shm_fallocate,\n};\n\nbool is_file_shm_hugepages(struct file *file)\n{\n\treturn file->f_op == &shm_file_operations_huge;\n}\n\nstatic const struct vm_operations_struct shm_vm_ops = {\n\t.open\t= shm_open,\t/* callback for a new vm-area open */\n\t.close\t= shm_close,\t/* callback for when the vm-area is released */\n\t.fault\t= shm_fault,\n#if defined(CONFIG_NUMA)\n\t.set_policy = shm_set_policy,\n\t.get_policy = shm_get_policy,\n#endif\n};\n\n/**\n * newseg - Create a new shared memory segment\n * @ns: namespace\n * @params: ptr to the structure that contains key, size and shmflg\n *\n * Called with shm_ids.rwsem held as a writer.\n */\nstatic int newseg(struct ipc_namespace *ns, struct ipc_params *params)\n{\n\tkey_t key = params->key;\n\tint shmflg = params->flg;\n\tsize_t size = params->u.size;\n\tint error;\n\tstruct shmid_kernel *shp;\n\tsize_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tstruct file *file;\n\tchar name[13];\n\tint id;\n\tvm_flags_t acctflag = 0;\n\n\tif (size < SHMMIN || size > ns->shm_ctlmax)\n\t\treturn -EINVAL;\n\n\tif (numpages << PAGE_SHIFT < size)\n\t\treturn -ENOSPC;\n\n\tif (ns->shm_tot + numpages < ns->shm_tot ||\n\t\t\tns->shm_tot + numpages > ns->shm_ctlall)\n\t\treturn -ENOSPC;\n\n\tshp = ipc_rcu_alloc(sizeof(*shp));\n\tif (!shp)\n\t\treturn -ENOMEM;\n\n\tshp->shm_perm.key = key;\n\tshp->shm_perm.mode = (shmflg & S_IRWXUGO);\n\tshp->mlock_user = NULL;\n\n\tshp->shm_perm.security = NULL;\n\terror = security_shm_alloc(shp);\n\tif (error) {\n\t\tipc_rcu_putref(shp, ipc_rcu_free);\n\t\treturn error;\n\t}\n\n\tsprintf(name, \"SYSV%08x\", key);\n\tif (shmflg & SHM_HUGETLB) {\n\t\tstruct hstate *hs;\n\t\tsize_t hugesize;\n\n\t\ths = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);\n\t\tif (!hs) {\n\t\t\terror = -EINVAL;\n\t\t\tgoto no_file;\n\t\t}\n\t\thugesize = ALIGN(size, huge_page_size(hs));\n\n\t\t/* hugetlb_file_setup applies strict accounting */\n\t\tif (shmflg & SHM_NORESERVE)\n\t\t\tacctflag = VM_NORESERVE;\n\t\tfile = hugetlb_file_setup(name, hugesize, acctflag,\n\t\t\t\t  &shp->mlock_user, HUGETLB_SHMFS_INODE,\n\t\t\t\t(shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);\n\t} else {\n\t\t/*\n\t\t * Do not allow no accounting for OVERCOMMIT_NEVER, even\n\t\t * if it's asked for.\n\t\t */\n\t\tif  ((shmflg & SHM_NORESERVE) &&\n\t\t\t\tsysctl_overcommit_memory != OVERCOMMIT_NEVER)\n\t\t\tacctflag = VM_NORESERVE;\n\t\tfile = shmem_kernel_file_setup(name, size, acctflag);\n\t}\n\terror = PTR_ERR(file);\n\tif (IS_ERR(file))\n\t\tgoto no_file;\n\n\tshp->shm_cprid = task_tgid_vnr(current);\n\tshp->shm_lprid = 0;\n\tshp->shm_atim = shp->shm_dtim = 0;\n\tshp->shm_ctim = get_seconds();\n\tshp->shm_segsz = size;\n\tshp->shm_nattch = 0;\n\tshp->shm_file = file;\n\tshp->shm_creator = current;\n\n\tid = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);\n\tif (id < 0) {\n\t\terror = id;\n\t\tgoto no_id;\n\t}\n\n\tlist_add(&shp->shm_clist, &current->sysvshm.shm_clist);\n\n\t/*\n\t * shmid gets reported as \"inode#\" in /proc/pid/maps.\n\t * proc-ps tools use this. Changing this will break them.\n\t */\n\tfile_inode(file)->i_ino = shp->shm_perm.id;\n\n\tns->shm_tot += numpages;\n\terror = shp->shm_perm.id;\n\n\tipc_unlock_object(&shp->shm_perm);\n\trcu_read_unlock();\n\treturn error;\n\nno_id:\n\tif (is_file_hugepages(file) && shp->mlock_user)\n\t\tuser_shm_unlock(size, shp->mlock_user);\n\tfput(file);\nno_file:\n\tipc_rcu_putref(shp, shm_rcu_free);\n\treturn error;\n}\n\n/*\n * Called with shm_ids.rwsem and ipcp locked.\n */\nstatic inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\treturn security_shm_associate(shp, shmflg);\n}\n\n/*\n * Called with shm_ids.rwsem and ipcp locked.\n */\nstatic inline int shm_more_checks(struct kern_ipc_perm *ipcp,\n\t\t\t\tstruct ipc_params *params)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\tif (shp->shm_segsz < params->u.size)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nSYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)\n{\n\tstruct ipc_namespace *ns;\n\tstatic const struct ipc_ops shm_ops = {\n\t\t.getnew = newseg,\n\t\t.associate = shm_security,\n\t\t.more_checks = shm_more_checks,\n\t};\n\tstruct ipc_params shm_params;\n\n\tns = current->nsproxy->ipc_ns;\n\n\tshm_params.key = key;\n\tshm_params.flg = shmflg;\n\tshm_params.u.size = size;\n\n\treturn ipcget(ns, &shm_ids(ns), &shm_ops, &shm_params);\n}\n\nstatic inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\treturn copy_to_user(buf, in, sizeof(*in));\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shmid_ds out;\n\n\t\tmemset(&out, 0, sizeof(out));\n\t\tipc64_perm_to_ipc_perm(&in->shm_perm, &out.shm_perm);\n\t\tout.shm_segsz\t= in->shm_segsz;\n\t\tout.shm_atime\t= in->shm_atime;\n\t\tout.shm_dtime\t= in->shm_dtime;\n\t\tout.shm_ctime\t= in->shm_ctime;\n\t\tout.shm_cpid\t= in->shm_cpid;\n\t\tout.shm_lpid\t= in->shm_lpid;\n\t\tout.shm_nattch\t= in->shm_nattch;\n\n\t\treturn copy_to_user(buf, &out, sizeof(out));\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic inline unsigned long\ncopy_shmid_from_user(struct shmid64_ds *out, void __user *buf, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\tif (copy_from_user(out, buf, sizeof(*out)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shmid_ds tbuf_old;\n\n\t\tif (copy_from_user(&tbuf_old, buf, sizeof(tbuf_old)))\n\t\t\treturn -EFAULT;\n\n\t\tout->shm_perm.uid\t= tbuf_old.shm_perm.uid;\n\t\tout->shm_perm.gid\t= tbuf_old.shm_perm.gid;\n\t\tout->shm_perm.mode\t= tbuf_old.shm_perm.mode;\n\n\t\treturn 0;\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminfo64 *in, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\treturn copy_to_user(buf, in, sizeof(*in));\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shminfo out;\n\n\t\tif (in->shmmax > INT_MAX)\n\t\t\tout.shmmax = INT_MAX;\n\t\telse\n\t\t\tout.shmmax = (int)in->shmmax;\n\n\t\tout.shmmin\t= in->shmmin;\n\t\tout.shmmni\t= in->shmmni;\n\t\tout.shmseg\t= in->shmseg;\n\t\tout.shmall\t= in->shmall;\n\n\t\treturn copy_to_user(buf, &out, sizeof(out));\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n/*\n * Calculate and add used RSS and swap pages of a shm.\n * Called with shm_ids.rwsem held as a reader\n */\nstatic void shm_add_rss_swap(struct shmid_kernel *shp,\n\tunsigned long *rss_add, unsigned long *swp_add)\n{\n\tstruct inode *inode;\n\n\tinode = file_inode(shp->shm_file);\n\n\tif (is_file_hugepages(shp->shm_file)) {\n\t\tstruct address_space *mapping = inode->i_mapping;\n\t\tstruct hstate *h = hstate_file(shp->shm_file);\n\t\t*rss_add += pages_per_huge_page(h) * mapping->nrpages;\n\t} else {\n#ifdef CONFIG_SHMEM\n\t\tstruct shmem_inode_info *info = SHMEM_I(inode);\n\n\t\tspin_lock_irq(&info->lock);\n\t\t*rss_add += inode->i_mapping->nrpages;\n\t\t*swp_add += info->swapped;\n\t\tspin_unlock_irq(&info->lock);\n#else\n\t\t*rss_add += inode->i_mapping->nrpages;\n#endif\n\t}\n}\n\n/*\n * Called with shm_ids.rwsem held as a reader\n */\nstatic void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,\n\t\tunsigned long *swp)\n{\n\tint next_id;\n\tint total, in_use;\n\n\t*rss = 0;\n\t*swp = 0;\n\n\tin_use = shm_ids(ns).in_use;\n\n\tfor (total = 0, next_id = 0; total < in_use; next_id++) {\n\t\tstruct kern_ipc_perm *ipc;\n\t\tstruct shmid_kernel *shp;\n\n\t\tipc = idr_find(&shm_ids(ns).ipcs_idr, next_id);\n\t\tif (ipc == NULL)\n\t\t\tcontinue;\n\t\tshp = container_of(ipc, struct shmid_kernel, shm_perm);\n\n\t\tshm_add_rss_swap(shp, rss, swp);\n\n\t\ttotal++;\n\t}\n}\n\n/*\n * This function handles some shmctl commands which require the rwsem\n * to be held in write mode.\n * NOTE: no locks must be held, the rwsem is taken inside this function.\n */\nstatic int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,\n\t\t       struct shmid_ds __user *buf, int version)\n{\n\tstruct kern_ipc_perm *ipcp;\n\tstruct shmid64_ds shmid64;\n\tstruct shmid_kernel *shp;\n\tint err;\n\n\tif (cmd == IPC_SET) {\n\t\tif (copy_shmid_from_user(&shmid64, buf, version))\n\t\t\treturn -EFAULT;\n\t}\n\n\tdown_write(&shm_ids(ns).rwsem);\n\trcu_read_lock();\n\n\tipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,\n\t\t\t\t      &shmid64.shm_perm, 0);\n\tif (IS_ERR(ipcp)) {\n\t\terr = PTR_ERR(ipcp);\n\t\tgoto out_unlock1;\n\t}\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\terr = security_shm_shmctl(shp, cmd);\n\tif (err)\n\t\tgoto out_unlock1;\n\n\tswitch (cmd) {\n\tcase IPC_RMID:\n\t\tipc_lock_object(&shp->shm_perm);\n\t\t/* do_shm_rmid unlocks the ipc object and rcu */\n\t\tdo_shm_rmid(ns, ipcp);\n\t\tgoto out_up;\n\tcase IPC_SET:\n\t\tipc_lock_object(&shp->shm_perm);\n\t\terr = ipc_update_perm(&shmid64.shm_perm, ipcp);\n\t\tif (err)\n\t\t\tgoto out_unlock0;\n\t\tshp->shm_ctim = get_seconds();\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto out_unlock1;\n\t}\n\nout_unlock0:\n\tipc_unlock_object(&shp->shm_perm);\nout_unlock1:\n\trcu_read_unlock();\nout_up:\n\tup_write(&shm_ids(ns).rwsem);\n\treturn err;\n}\n\nstatic int shmctl_nolock(struct ipc_namespace *ns, int shmid,\n\t\t\t int cmd, int version, void __user *buf)\n{\n\tint err;\n\tstruct shmid_kernel *shp;\n\n\t/* preliminary security checks for *_INFO */\n\tif (cmd == IPC_INFO || cmd == SHM_INFO) {\n\t\terr = security_shm_shmctl(NULL, cmd);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tswitch (cmd) {\n\tcase IPC_INFO:\n\t{\n\t\tstruct shminfo64 shminfo;\n\n\t\tmemset(&shminfo, 0, sizeof(shminfo));\n\t\tshminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;\n\t\tshminfo.shmmax = ns->shm_ctlmax;\n\t\tshminfo.shmall = ns->shm_ctlall;\n\n\t\tshminfo.shmmin = SHMMIN;\n\t\tif (copy_shminfo_to_user(buf, &shminfo, version))\n\t\t\treturn -EFAULT;\n\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\terr = ipc_get_maxid(&shm_ids(ns));\n\t\tup_read(&shm_ids(ns).rwsem);\n\n\t\tif (err < 0)\n\t\t\terr = 0;\n\t\tgoto out;\n\t}\n\tcase SHM_INFO:\n\t{\n\t\tstruct shm_info shm_info;\n\n\t\tmemset(&shm_info, 0, sizeof(shm_info));\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\tshm_info.used_ids = shm_ids(ns).in_use;\n\t\tshm_get_stat(ns, &shm_info.shm_rss, &shm_info.shm_swp);\n\t\tshm_info.shm_tot = ns->shm_tot;\n\t\tshm_info.swap_attempts = 0;\n\t\tshm_info.swap_successes = 0;\n\t\terr = ipc_get_maxid(&shm_ids(ns));\n\t\tup_read(&shm_ids(ns).rwsem);\n\t\tif (copy_to_user(buf, &shm_info, sizeof(shm_info))) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = err < 0 ? 0 : err;\n\t\tgoto out;\n\t}\n\tcase SHM_STAT:\n\tcase IPC_STAT:\n\t{\n\t\tstruct shmid64_ds tbuf;\n\t\tint result;\n\n\t\trcu_read_lock();\n\t\tif (cmd == SHM_STAT) {\n\t\t\tshp = shm_obtain_object(ns, shmid);\n\t\t\tif (IS_ERR(shp)) {\n\t\t\t\terr = PTR_ERR(shp);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tresult = shp->shm_perm.id;\n\t\t} else {\n\t\t\tshp = shm_obtain_object_check(ns, shmid);\n\t\t\tif (IS_ERR(shp)) {\n\t\t\t\terr = PTR_ERR(shp);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tresult = 0;\n\t\t}\n\n\t\terr = -EACCES;\n\t\tif (ipcperms(ns, &shp->shm_perm, S_IRUGO))\n\t\t\tgoto out_unlock;\n\n\t\terr = security_shm_shmctl(shp, cmd);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\n\t\tmemset(&tbuf, 0, sizeof(tbuf));\n\t\tkernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);\n\t\ttbuf.shm_segsz\t= shp->shm_segsz;\n\t\ttbuf.shm_atime\t= shp->shm_atim;\n\t\ttbuf.shm_dtime\t= shp->shm_dtim;\n\t\ttbuf.shm_ctime\t= shp->shm_ctim;\n\t\ttbuf.shm_cpid\t= shp->shm_cprid;\n\t\ttbuf.shm_lpid\t= shp->shm_lprid;\n\t\ttbuf.shm_nattch\t= shp->shm_nattch;\n\t\trcu_read_unlock();\n\n\t\tif (copy_shmid_to_user(buf, &tbuf, version))\n\t\t\terr = -EFAULT;\n\t\telse\n\t\t\terr = result;\n\t\tgoto out;\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn err;\n}\n\nSYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)\n{\n\tstruct shmid_kernel *shp;\n\tint err, version;\n\tstruct ipc_namespace *ns;\n\n\tif (cmd < 0 || shmid < 0)\n\t\treturn -EINVAL;\n\n\tversion = ipc_parse_version(&cmd);\n\tns = current->nsproxy->ipc_ns;\n\n\tswitch (cmd) {\n\tcase IPC_INFO:\n\tcase SHM_INFO:\n\tcase SHM_STAT:\n\tcase IPC_STAT:\n\t\treturn shmctl_nolock(ns, shmid, cmd, version, buf);\n\tcase IPC_RMID:\n\tcase IPC_SET:\n\t\treturn shmctl_down(ns, shmid, cmd, buf, version);\n\tcase SHM_LOCK:\n\tcase SHM_UNLOCK:\n\t{\n\t\tstruct file *shm_file;\n\n\t\trcu_read_lock();\n\t\tshp = shm_obtain_object_check(ns, shmid);\n\t\tif (IS_ERR(shp)) {\n\t\t\terr = PTR_ERR(shp);\n\t\t\tgoto out_unlock1;\n\t\t}\n\n\t\taudit_ipc_obj(&(shp->shm_perm));\n\t\terr = security_shm_shmctl(shp, cmd);\n\t\tif (err)\n\t\t\tgoto out_unlock1;\n\n\t\tipc_lock_object(&shp->shm_perm);\n\n\t\t/* check if shm_destroy() is tearing down shp */\n\t\tif (!ipc_valid_object(&shp->shm_perm)) {\n\t\t\terr = -EIDRM;\n\t\t\tgoto out_unlock0;\n\t\t}\n\n\t\tif (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {\n\t\t\tkuid_t euid = current_euid();\n\n\t\t\tif (!uid_eq(euid, shp->shm_perm.uid) &&\n\t\t\t    !uid_eq(euid, shp->shm_perm.cuid)) {\n\t\t\t\terr = -EPERM;\n\t\t\t\tgoto out_unlock0;\n\t\t\t}\n\t\t\tif (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK)) {\n\t\t\t\terr = -EPERM;\n\t\t\t\tgoto out_unlock0;\n\t\t\t}\n\t\t}\n\n\t\tshm_file = shp->shm_file;\n\t\tif (is_file_hugepages(shm_file))\n\t\t\tgoto out_unlock0;\n\n\t\tif (cmd == SHM_LOCK) {\n\t\t\tstruct user_struct *user = current_user();\n\n\t\t\terr = shmem_lock(shm_file, 1, user);\n\t\t\tif (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {\n\t\t\t\tshp->shm_perm.mode |= SHM_LOCKED;\n\t\t\t\tshp->mlock_user = user;\n\t\t\t}\n\t\t\tgoto out_unlock0;\n\t\t}\n\n\t\t/* SHM_UNLOCK */\n\t\tif (!(shp->shm_perm.mode & SHM_LOCKED))\n\t\t\tgoto out_unlock0;\n\t\tshmem_lock(shm_file, 0, shp->mlock_user);\n\t\tshp->shm_perm.mode &= ~SHM_LOCKED;\n\t\tshp->mlock_user = NULL;\n\t\tget_file(shm_file);\n\t\tipc_unlock_object(&shp->shm_perm);\n\t\trcu_read_unlock();\n\t\tshmem_unlock_mapping(shm_file->f_mapping);\n\n\t\tfput(shm_file);\n\t\treturn err;\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nout_unlock0:\n\tipc_unlock_object(&shp->shm_perm);\nout_unlock1:\n\trcu_read_unlock();\n\treturn err;\n}\n\n/*\n * Fix shmaddr, allocate descriptor, map shm, add attach descriptor to lists.\n *\n * NOTE! Despite the name, this is NOT a direct system call entrypoint. The\n * \"raddr\" thing points to kernel space, and there has to be a wrapper around\n * this.\n */\nlong do_shmat(int shmid, char __user *shmaddr, int shmflg, ulong *raddr,\n\t      unsigned long shmlba)\n{\n\tstruct shmid_kernel *shp;\n\tunsigned long addr;\n\tunsigned long size;\n\tstruct file *file;\n\tint    err;\n\tunsigned long flags;\n\tunsigned long prot;\n\tint acc_mode;\n\tstruct ipc_namespace *ns;\n\tstruct shm_file_data *sfd;\n\tstruct path path;\n\tfmode_t f_mode;\n\tunsigned long populate = 0;\n\n\terr = -EINVAL;\n\tif (shmid < 0)\n\t\tgoto out;\n\telse if ((addr = (ulong)shmaddr)) {\n\t\tif (addr & (shmlba - 1)) {\n\t\t\tif (shmflg & SHM_RND)\n\t\t\t\taddr &= ~(shmlba - 1);\t   /* round down */\n\t\t\telse\n#ifndef __ARCH_FORCE_SHMLBA\n\t\t\t\tif (addr & ~PAGE_MASK)\n#endif\n\t\t\t\t\tgoto out;\n\t\t}\n\t\tflags = MAP_SHARED | MAP_FIXED;\n\t} else {\n\t\tif ((shmflg & SHM_REMAP))\n\t\t\tgoto out;\n\n\t\tflags = MAP_SHARED;\n\t}\n\n\tif (shmflg & SHM_RDONLY) {\n\t\tprot = PROT_READ;\n\t\tacc_mode = S_IRUGO;\n\t\tf_mode = FMODE_READ;\n\t} else {\n\t\tprot = PROT_READ | PROT_WRITE;\n\t\tacc_mode = S_IRUGO | S_IWUGO;\n\t\tf_mode = FMODE_READ | FMODE_WRITE;\n\t}\n\tif (shmflg & SHM_EXEC) {\n\t\tprot |= PROT_EXEC;\n\t\tacc_mode |= S_IXUGO;\n\t}\n\n\t/*\n\t * We cannot rely on the fs check since SYSV IPC does have an\n\t * additional creator id...\n\t */\n\tns = current->nsproxy->ipc_ns;\n\trcu_read_lock();\n\tshp = shm_obtain_object_check(ns, shmid);\n\tif (IS_ERR(shp)) {\n\t\terr = PTR_ERR(shp);\n\t\tgoto out_unlock;\n\t}\n\n\terr = -EACCES;\n\tif (ipcperms(ns, &shp->shm_perm, acc_mode))\n\t\tgoto out_unlock;\n\n\terr = security_shm_shmat(shp, shmaddr, shmflg);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tipc_lock_object(&shp->shm_perm);\n\n\t/* check if shm_destroy() is tearing down shp */\n\tif (!ipc_valid_object(&shp->shm_perm)) {\n\t\tipc_unlock_object(&shp->shm_perm);\n\t\terr = -EIDRM;\n\t\tgoto out_unlock;\n\t}\n\n\tpath = shp->shm_file->f_path;\n\tpath_get(&path);\n\tshp->shm_nattch++;\n\tsize = i_size_read(d_inode(path.dentry));\n\tipc_unlock_object(&shp->shm_perm);\n\trcu_read_unlock();\n\n\terr = -ENOMEM;\n\tsfd = kzalloc(sizeof(*sfd), GFP_KERNEL);\n\tif (!sfd) {\n\t\tpath_put(&path);\n\t\tgoto out_nattch;\n\t}\n\n\tfile = alloc_file(&path, f_mode,\n\t\t\t  is_file_hugepages(shp->shm_file) ?\n\t\t\t\t&shm_file_operations_huge :\n\t\t\t\t&shm_file_operations);\n\terr = PTR_ERR(file);\n\tif (IS_ERR(file)) {\n\t\tkfree(sfd);\n\t\tpath_put(&path);\n\t\tgoto out_nattch;\n\t}\n\n\tfile->private_data = sfd;\n\tfile->f_mapping = shp->shm_file->f_mapping;\n\tsfd->id = shp->shm_perm.id;\n\tsfd->ns = get_ipc_ns(ns);\n\tsfd->file = shp->shm_file;\n\tsfd->vm_ops = NULL;\n\n\terr = security_mmap_file(file, prot, flags);\n\tif (err)\n\t\tgoto out_fput;\n\n\tif (down_write_killable(&current->mm->mmap_sem)) {\n\t\terr = -EINTR;\n\t\tgoto out_fput;\n\t}\n\n\tif (addr && !(shmflg & SHM_REMAP)) {\n\t\terr = -EINVAL;\n\t\tif (addr + size < addr)\n\t\t\tgoto invalid;\n\n\t\tif (find_vma_intersection(current->mm, addr, addr + size))\n\t\t\tgoto invalid;\n\t}\n\n\taddr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate, NULL);\n\t*raddr = addr;\n\terr = 0;\n\tif (IS_ERR_VALUE(addr))\n\t\terr = (long)addr;\ninvalid:\n\tup_write(&current->mm->mmap_sem);\n\tif (populate)\n\t\tmm_populate(addr, populate);\n\nout_fput:\n\tfput(file);\n\nout_nattch:\n\tdown_write(&shm_ids(ns).rwsem);\n\tshp = shm_lock(ns, shmid);\n\tshp->shm_nattch--;\n\tif (shm_may_destroy(ns, shp))\n\t\tshm_destroy(ns, shp);\n\telse\n\t\tshm_unlock(shp);\n\tup_write(&shm_ids(ns).rwsem);\n\treturn err;\n\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn err;\n}\n\nSYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)\n{\n\tunsigned long ret;\n\tlong err;\n\n\terr = do_shmat(shmid, shmaddr, shmflg, &ret, SHMLBA);\n\tif (err)\n\t\treturn err;\n\tforce_successful_syscall_return();\n\treturn (long)ret;\n}\n\n/*\n * detach and kill segment if marked destroyed.\n * The work is done in shm_close.\n */\nSYSCALL_DEFINE1(shmdt, char __user *, shmaddr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long addr = (unsigned long)shmaddr;\n\tint retval = -EINVAL;\n#ifdef CONFIG_MMU\n\tloff_t size = 0;\n\tstruct file *file;\n\tstruct vm_area_struct *next;\n#endif\n\n\tif (addr & ~PAGE_MASK)\n\t\treturn retval;\n\n\tif (down_write_killable(&mm->mmap_sem))\n\t\treturn -EINTR;\n\n\t/*\n\t * This function tries to be smart and unmap shm segments that\n\t * were modified by partial mlock or munmap calls:\n\t * - It first determines the size of the shm segment that should be\n\t *   unmapped: It searches for a vma that is backed by shm and that\n\t *   started at address shmaddr. It records it's size and then unmaps\n\t *   it.\n\t * - Then it unmaps all shm vmas that started at shmaddr and that\n\t *   are within the initially determined size and that are from the\n\t *   same shm segment from which we determined the size.\n\t * Errors from do_munmap are ignored: the function only fails if\n\t * it's called with invalid parameters or if it's called to unmap\n\t * a part of a vma. Both calls in this function are for full vmas,\n\t * the parameters are directly copied from the vma itself and always\n\t * valid - therefore do_munmap cannot fail. (famous last words?)\n\t */\n\t/*\n\t * If it had been mremap()'d, the starting address would not\n\t * match the usual checks anyway. So assume all vma's are\n\t * above the starting address given.\n\t */\n\tvma = find_vma(mm, addr);\n\n#ifdef CONFIG_MMU\n\twhile (vma) {\n\t\tnext = vma->vm_next;\n\n\t\t/*\n\t\t * Check if the starting address would match, i.e. it's\n\t\t * a fragment created by mprotect() and/or munmap(), or it\n\t\t * otherwise it starts at this address with no hassles.\n\t\t */\n\t\tif ((vma->vm_ops == &shm_vm_ops) &&\n\t\t\t(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {\n\n\t\t\t/*\n\t\t\t * Record the file of the shm segment being\n\t\t\t * unmapped.  With mremap(), someone could place\n\t\t\t * page from another segment but with equal offsets\n\t\t\t * in the range we are unmapping.\n\t\t\t */\n\t\t\tfile = vma->vm_file;\n\t\t\tsize = i_size_read(file_inode(vma->vm_file));\n\t\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\t\t/*\n\t\t\t * We discovered the size of the shm segment, so\n\t\t\t * break out of here and fall through to the next\n\t\t\t * loop that uses the size information to stop\n\t\t\t * searching for matching vma's.\n\t\t\t */\n\t\t\tretval = 0;\n\t\t\tvma = next;\n\t\t\tbreak;\n\t\t}\n\t\tvma = next;\n\t}\n\n\t/*\n\t * We need look no further than the maximum address a fragment\n\t * could possibly have landed at. Also cast things to loff_t to\n\t * prevent overflows and make comparisons vs. equal-width types.\n\t */\n\tsize = PAGE_ALIGN(size);\n\twhile (vma && (loff_t)(vma->vm_end - addr) <= size) {\n\t\tnext = vma->vm_next;\n\n\t\t/* finding a matching vma now does not alter retval */\n\t\tif ((vma->vm_ops == &shm_vm_ops) &&\n\t\t    ((vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) &&\n\t\t    (vma->vm_file == file))\n\t\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\tvma = next;\n\t}\n\n#else\t/* CONFIG_MMU */\n\t/* under NOMMU conditions, the exact address to be destroyed must be\n\t * given\n\t */\n\tif (vma && vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {\n\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\tretval = 0;\n\t}\n\n#endif\n\n\tup_write(&mm->mmap_sem);\n\treturn retval;\n}\n\n#ifdef CONFIG_PROC_FS\nstatic int sysvipc_shm_proc_show(struct seq_file *s, void *it)\n{\n\tstruct user_namespace *user_ns = seq_user_ns(s);\n\tstruct shmid_kernel *shp = it;\n\tunsigned long rss = 0, swp = 0;\n\n\tshm_add_rss_swap(shp, &rss, &swp);\n\n#if BITS_PER_LONG <= 32\n#define SIZE_SPEC \"%10lu\"\n#else\n#define SIZE_SPEC \"%21lu\"\n#endif\n\n\tseq_printf(s,\n\t\t   \"%10d %10d  %4o \" SIZE_SPEC \" %5u %5u  \"\n\t\t   \"%5lu %5u %5u %5u %5u %10lu %10lu %10lu \"\n\t\t   SIZE_SPEC \" \" SIZE_SPEC \"\\n\",\n\t\t   shp->shm_perm.key,\n\t\t   shp->shm_perm.id,\n\t\t   shp->shm_perm.mode,\n\t\t   shp->shm_segsz,\n\t\t   shp->shm_cprid,\n\t\t   shp->shm_lprid,\n\t\t   shp->shm_nattch,\n\t\t   from_kuid_munged(user_ns, shp->shm_perm.uid),\n\t\t   from_kgid_munged(user_ns, shp->shm_perm.gid),\n\t\t   from_kuid_munged(user_ns, shp->shm_perm.cuid),\n\t\t   from_kgid_munged(user_ns, shp->shm_perm.cgid),\n\t\t   shp->shm_atim,\n\t\t   shp->shm_dtim,\n\t\t   shp->shm_ctim,\n\t\t   rss * PAGE_SIZE,\n\t\t   swp * PAGE_SIZE);\n\n\treturn 0;\n}\n#endif\n"], "fixing_code": ["/*\n * linux/ipc/shm.c\n * Copyright (C) 1992, 1993 Krishna Balasubramanian\n *\t Many improvements/fixes by Bruno Haible.\n * Replaced `struct shm_desc' by `struct vm_area_struct', July 1994.\n * Fixed the shm swap deallocation (shm_unuse()), August 1998 Andrea Arcangeli.\n *\n * /proc/sysvipc/shm support (c) 1999 Dragos Acostachioaie <dragos@iname.com>\n * BIGMEM support, Andrea Arcangeli <andrea@suse.de>\n * SMP thread shm, Jean-Luc Boyard <jean-luc.boyard@siemens.fr>\n * HIGHMEM support, Ingo Molnar <mingo@redhat.com>\n * Make shmmax, shmall, shmmni sysctl'able, Christoph Rohland <cr@sap.com>\n * Shared /dev/zero support, Kanoj Sarcar <kanoj@sgi.com>\n * Move the mm functionality over to mm/shmem.c, Christoph Rohland <cr@sap.com>\n *\n * support for audit of ipc object properties and permission changes\n * Dustin Kirkland <dustin.kirkland@us.ibm.com>\n *\n * namespaces support\n * OpenVZ, SWsoft Inc.\n * Pavel Emelianov <xemul@openvz.org>\n *\n * Better ipc lock (kern_ipc_perm.lock) handling\n * Davidlohr Bueso <davidlohr.bueso@hp.com>, June 2013.\n */\n\n#include <linux/slab.h>\n#include <linux/mm.h>\n#include <linux/hugetlb.h>\n#include <linux/shm.h>\n#include <linux/init.h>\n#include <linux/file.h>\n#include <linux/mman.h>\n#include <linux/shmem_fs.h>\n#include <linux/security.h>\n#include <linux/syscalls.h>\n#include <linux/audit.h>\n#include <linux/capability.h>\n#include <linux/ptrace.h>\n#include <linux/seq_file.h>\n#include <linux/rwsem.h>\n#include <linux/nsproxy.h>\n#include <linux/mount.h>\n#include <linux/ipc_namespace.h>\n\n#include <linux/uaccess.h>\n\n#include \"util.h\"\n\nstruct shm_file_data {\n\tint id;\n\tstruct ipc_namespace *ns;\n\tstruct file *file;\n\tconst struct vm_operations_struct *vm_ops;\n};\n\n#define shm_file_data(file) (*((struct shm_file_data **)&(file)->private_data))\n\nstatic const struct file_operations shm_file_operations;\nstatic const struct vm_operations_struct shm_vm_ops;\n\n#define shm_ids(ns)\t((ns)->ids[IPC_SHM_IDS])\n\n#define shm_unlock(shp)\t\t\t\\\n\tipc_unlock(&(shp)->shm_perm)\n\nstatic int newseg(struct ipc_namespace *, struct ipc_params *);\nstatic void shm_open(struct vm_area_struct *vma);\nstatic void shm_close(struct vm_area_struct *vma);\nstatic void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp);\n#ifdef CONFIG_PROC_FS\nstatic int sysvipc_shm_proc_show(struct seq_file *s, void *it);\n#endif\n\nvoid shm_init_ns(struct ipc_namespace *ns)\n{\n\tns->shm_ctlmax = SHMMAX;\n\tns->shm_ctlall = SHMALL;\n\tns->shm_ctlmni = SHMMNI;\n\tns->shm_rmid_forced = 0;\n\tns->shm_tot = 0;\n\tipc_init_ids(&shm_ids(ns));\n}\n\n/*\n * Called with shm_ids.rwsem (writer) and the shp structure locked.\n * Only shm_ids.rwsem remains locked on exit.\n */\nstatic void do_shm_rmid(struct ipc_namespace *ns, struct kern_ipc_perm *ipcp)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\tif (shp->shm_nattch) {\n\t\tshp->shm_perm.mode |= SHM_DEST;\n\t\t/* Do not find it any more */\n\t\tshp->shm_perm.key = IPC_PRIVATE;\n\t\tshm_unlock(shp);\n\t} else\n\t\tshm_destroy(ns, shp);\n}\n\n#ifdef CONFIG_IPC_NS\nvoid shm_exit_ns(struct ipc_namespace *ns)\n{\n\tfree_ipcs(ns, &shm_ids(ns), do_shm_rmid);\n\tidr_destroy(&ns->ids[IPC_SHM_IDS].ipcs_idr);\n}\n#endif\n\nstatic int __init ipc_ns_init(void)\n{\n\tshm_init_ns(&init_ipc_ns);\n\treturn 0;\n}\n\npure_initcall(ipc_ns_init);\n\nvoid __init shm_init(void)\n{\n\tipc_init_proc_interface(\"sysvipc/shm\",\n#if BITS_PER_LONG <= 32\n\t\t\t\t\"       key      shmid perms       size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime        rss       swap\\n\",\n#else\n\t\t\t\t\"       key      shmid perms                  size  cpid  lpid nattch   uid   gid  cuid  cgid      atime      dtime      ctime                   rss                  swap\\n\",\n#endif\n\t\t\t\tIPC_SHM_IDS, sysvipc_shm_proc_show);\n}\n\nstatic inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&shm_ids(ns), id);\n\n\tif (IS_ERR(ipcp))\n\t\treturn ERR_CAST(ipcp);\n\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\nstatic inline struct shmid_kernel *shm_obtain_object_check(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_obtain_object_check(&shm_ids(ns), id);\n\n\tif (IS_ERR(ipcp))\n\t\treturn ERR_CAST(ipcp);\n\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\n/*\n * shm_lock_(check_) routines are called in the paths where the rwsem\n * is not necessarily held.\n */\nstatic inline struct shmid_kernel *shm_lock(struct ipc_namespace *ns, int id)\n{\n\tstruct kern_ipc_perm *ipcp = ipc_lock(&shm_ids(ns), id);\n\n\t/*\n\t * Callers of shm_lock() must validate the status of the returned ipc\n\t * object pointer (as returned by ipc_lock()), and error out as\n\t * appropriate.\n\t */\n\tif (IS_ERR(ipcp))\n\t\treturn (void *)ipcp;\n\treturn container_of(ipcp, struct shmid_kernel, shm_perm);\n}\n\nstatic inline void shm_lock_by_ptr(struct shmid_kernel *ipcp)\n{\n\trcu_read_lock();\n\tipc_lock_object(&ipcp->shm_perm);\n}\n\nstatic void shm_rcu_free(struct rcu_head *head)\n{\n\tstruct ipc_rcu *p = container_of(head, struct ipc_rcu, rcu);\n\tstruct shmid_kernel *shp = ipc_rcu_to_struct(p);\n\n\tsecurity_shm_free(shp);\n\tipc_rcu_free(head);\n}\n\nstatic inline void shm_rmid(struct ipc_namespace *ns, struct shmid_kernel *s)\n{\n\tlist_del(&s->shm_clist);\n\tipc_rmid(&shm_ids(ns), &s->shm_perm);\n}\n\n\nstatic int __shm_open(struct vm_area_struct *vma)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct shmid_kernel *shp;\n\n\tshp = shm_lock(sfd->ns, sfd->id);\n\n\tif (IS_ERR(shp))\n\t\treturn PTR_ERR(shp);\n\n\tshp->shm_atim = get_seconds();\n\tshp->shm_lprid = task_tgid_vnr(current);\n\tshp->shm_nattch++;\n\tshm_unlock(shp);\n\treturn 0;\n}\n\n/* This is called by fork, once for every shm attach. */\nstatic void shm_open(struct vm_area_struct *vma)\n{\n\tint err = __shm_open(vma);\n\t/*\n\t * We raced in the idr lookup or with shm_destroy().\n\t * Either way, the ID is busted.\n\t */\n\tWARN_ON_ONCE(err);\n}\n\n/*\n * shm_destroy - free the struct shmid_kernel\n *\n * @ns: namespace\n * @shp: struct to free\n *\n * It has to be called with shp and shm_ids.rwsem (writer) locked,\n * but returns with shp unlocked and freed.\n */\nstatic void shm_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)\n{\n\tstruct file *shm_file;\n\n\tshm_file = shp->shm_file;\n\tshp->shm_file = NULL;\n\tns->shm_tot -= (shp->shm_segsz + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tshm_rmid(ns, shp);\n\tshm_unlock(shp);\n\tif (!is_file_hugepages(shm_file))\n\t\tshmem_lock(shm_file, 0, shp->mlock_user);\n\telse if (shp->mlock_user)\n\t\tuser_shm_unlock(i_size_read(file_inode(shm_file)),\n\t\t\t\tshp->mlock_user);\n\tfput(shm_file);\n\tipc_rcu_putref(shp, shm_rcu_free);\n}\n\n/*\n * shm_may_destroy - identifies whether shm segment should be destroyed now\n *\n * Returns true if and only if there are no active users of the segment and\n * one of the following is true:\n *\n * 1) shmctl(id, IPC_RMID, NULL) was called for this shp\n *\n * 2) sysctl kernel.shm_rmid_forced is set to 1.\n */\nstatic bool shm_may_destroy(struct ipc_namespace *ns, struct shmid_kernel *shp)\n{\n\treturn (shp->shm_nattch == 0) &&\n\t       (ns->shm_rmid_forced ||\n\t\t(shp->shm_perm.mode & SHM_DEST));\n}\n\n/*\n * remove the attach descriptor vma.\n * free memory for segment if it is marked destroyed.\n * The descriptor has already been removed from the current->mm->mmap list\n * and will later be kfree()d.\n */\nstatic void shm_close(struct vm_area_struct *vma)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct shmid_kernel *shp;\n\tstruct ipc_namespace *ns = sfd->ns;\n\n\tdown_write(&shm_ids(ns).rwsem);\n\t/* remove from the list of attaches of the shm segment */\n\tshp = shm_lock(ns, sfd->id);\n\n\t/*\n\t * We raced in the idr lookup or with shm_destroy().\n\t * Either way, the ID is busted.\n\t */\n\tif (WARN_ON_ONCE(IS_ERR(shp)))\n\t\tgoto done; /* no-op */\n\n\tshp->shm_lprid = task_tgid_vnr(current);\n\tshp->shm_dtim = get_seconds();\n\tshp->shm_nattch--;\n\tif (shm_may_destroy(ns, shp))\n\t\tshm_destroy(ns, shp);\n\telse\n\t\tshm_unlock(shp);\ndone:\n\tup_write(&shm_ids(ns).rwsem);\n}\n\n/* Called with ns->shm_ids(ns).rwsem locked */\nstatic int shm_try_destroy_orphaned(int id, void *p, void *data)\n{\n\tstruct ipc_namespace *ns = data;\n\tstruct kern_ipc_perm *ipcp = p;\n\tstruct shmid_kernel *shp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\t/*\n\t * We want to destroy segments without users and with already\n\t * exit'ed originating process.\n\t *\n\t * As shp->* are changed under rwsem, it's safe to skip shp locking.\n\t */\n\tif (shp->shm_creator != NULL)\n\t\treturn 0;\n\n\tif (shm_may_destroy(ns, shp)) {\n\t\tshm_lock_by_ptr(shp);\n\t\tshm_destroy(ns, shp);\n\t}\n\treturn 0;\n}\n\nvoid shm_destroy_orphaned(struct ipc_namespace *ns)\n{\n\tdown_write(&shm_ids(ns).rwsem);\n\tif (shm_ids(ns).in_use)\n\t\tidr_for_each(&shm_ids(ns).ipcs_idr, &shm_try_destroy_orphaned, ns);\n\tup_write(&shm_ids(ns).rwsem);\n}\n\n/* Locking assumes this will only be called with task == current */\nvoid exit_shm(struct task_struct *task)\n{\n\tstruct ipc_namespace *ns = task->nsproxy->ipc_ns;\n\tstruct shmid_kernel *shp, *n;\n\n\tif (list_empty(&task->sysvshm.shm_clist))\n\t\treturn;\n\n\t/*\n\t * If kernel.shm_rmid_forced is not set then only keep track of\n\t * which shmids are orphaned, so that a later set of the sysctl\n\t * can clean them up.\n\t */\n\tif (!ns->shm_rmid_forced) {\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\tlist_for_each_entry(shp, &task->sysvshm.shm_clist, shm_clist)\n\t\t\tshp->shm_creator = NULL;\n\t\t/*\n\t\t * Only under read lock but we are only called on current\n\t\t * so no entry on the list will be shared.\n\t\t */\n\t\tlist_del(&task->sysvshm.shm_clist);\n\t\tup_read(&shm_ids(ns).rwsem);\n\t\treturn;\n\t}\n\n\t/*\n\t * Destroy all already created segments, that were not yet mapped,\n\t * and mark any mapped as orphan to cover the sysctl toggling.\n\t * Destroy is skipped if shm_may_destroy() returns false.\n\t */\n\tdown_write(&shm_ids(ns).rwsem);\n\tlist_for_each_entry_safe(shp, n, &task->sysvshm.shm_clist, shm_clist) {\n\t\tshp->shm_creator = NULL;\n\n\t\tif (shm_may_destroy(ns, shp)) {\n\t\t\tshm_lock_by_ptr(shp);\n\t\t\tshm_destroy(ns, shp);\n\t\t}\n\t}\n\n\t/* Remove the list head from any segments still attached. */\n\tlist_del(&task->sysvshm.shm_clist);\n\tup_write(&shm_ids(ns).rwsem);\n}\n\nstatic int shm_fault(struct vm_fault *vmf)\n{\n\tstruct file *file = vmf->vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\treturn sfd->vm_ops->fault(vmf);\n}\n\n#ifdef CONFIG_NUMA\nstatic int shm_set_policy(struct vm_area_struct *vma, struct mempolicy *new)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tint err = 0;\n\n\tif (sfd->vm_ops->set_policy)\n\t\terr = sfd->vm_ops->set_policy(vma, new);\n\treturn err;\n}\n\nstatic struct mempolicy *shm_get_policy(struct vm_area_struct *vma,\n\t\t\t\t\tunsigned long addr)\n{\n\tstruct file *file = vma->vm_file;\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tstruct mempolicy *pol = NULL;\n\n\tif (sfd->vm_ops->get_policy)\n\t\tpol = sfd->vm_ops->get_policy(vma, addr);\n\telse if (vma->vm_policy)\n\t\tpol = vma->vm_policy;\n\n\treturn pol;\n}\n#endif\n\nstatic int shm_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\tint ret;\n\n\t/*\n\t * In case of remap_file_pages() emulation, the file can represent\n\t * removed IPC ID: propogate shm_lock() error to caller.\n\t */\n\tret = __shm_open(vma);\n\tif (ret)\n\t\treturn ret;\n\n\tret = sfd->file->f_op->mmap(sfd->file, vma);\n\tif (ret) {\n\t\tshm_close(vma);\n\t\treturn ret;\n\t}\n\tsfd->vm_ops = vma->vm_ops;\n#ifdef CONFIG_MMU\n\tWARN_ON(!sfd->vm_ops->fault);\n#endif\n\tvma->vm_ops = &shm_vm_ops;\n\treturn 0;\n}\n\nstatic int shm_release(struct inode *ino, struct file *file)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tput_ipc_ns(sfd->ns);\n\tshm_file_data(file) = NULL;\n\tkfree(sfd);\n\treturn 0;\n}\n\nstatic int shm_fsync(struct file *file, loff_t start, loff_t end, int datasync)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tif (!sfd->file->f_op->fsync)\n\t\treturn -EINVAL;\n\treturn sfd->file->f_op->fsync(sfd->file, start, end, datasync);\n}\n\nstatic long shm_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t  loff_t len)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\tif (!sfd->file->f_op->fallocate)\n\t\treturn -EOPNOTSUPP;\n\treturn sfd->file->f_op->fallocate(file, mode, offset, len);\n}\n\nstatic unsigned long shm_get_unmapped_area(struct file *file,\n\tunsigned long addr, unsigned long len, unsigned long pgoff,\n\tunsigned long flags)\n{\n\tstruct shm_file_data *sfd = shm_file_data(file);\n\n\treturn sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,\n\t\t\t\t\t\tpgoff, flags);\n}\n\nstatic const struct file_operations shm_file_operations = {\n\t.mmap\t\t= shm_mmap,\n\t.fsync\t\t= shm_fsync,\n\t.release\t= shm_release,\n\t.get_unmapped_area\t= shm_get_unmapped_area,\n\t.llseek\t\t= noop_llseek,\n\t.fallocate\t= shm_fallocate,\n};\n\n/*\n * shm_file_operations_huge is now identical to shm_file_operations,\n * but we keep it distinct for the sake of is_file_shm_hugepages().\n */\nstatic const struct file_operations shm_file_operations_huge = {\n\t.mmap\t\t= shm_mmap,\n\t.fsync\t\t= shm_fsync,\n\t.release\t= shm_release,\n\t.get_unmapped_area\t= shm_get_unmapped_area,\n\t.llseek\t\t= noop_llseek,\n\t.fallocate\t= shm_fallocate,\n};\n\nbool is_file_shm_hugepages(struct file *file)\n{\n\treturn file->f_op == &shm_file_operations_huge;\n}\n\nstatic const struct vm_operations_struct shm_vm_ops = {\n\t.open\t= shm_open,\t/* callback for a new vm-area open */\n\t.close\t= shm_close,\t/* callback for when the vm-area is released */\n\t.fault\t= shm_fault,\n#if defined(CONFIG_NUMA)\n\t.set_policy = shm_set_policy,\n\t.get_policy = shm_get_policy,\n#endif\n};\n\n/**\n * newseg - Create a new shared memory segment\n * @ns: namespace\n * @params: ptr to the structure that contains key, size and shmflg\n *\n * Called with shm_ids.rwsem held as a writer.\n */\nstatic int newseg(struct ipc_namespace *ns, struct ipc_params *params)\n{\n\tkey_t key = params->key;\n\tint shmflg = params->flg;\n\tsize_t size = params->u.size;\n\tint error;\n\tstruct shmid_kernel *shp;\n\tsize_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tstruct file *file;\n\tchar name[13];\n\tint id;\n\tvm_flags_t acctflag = 0;\n\n\tif (size < SHMMIN || size > ns->shm_ctlmax)\n\t\treturn -EINVAL;\n\n\tif (numpages << PAGE_SHIFT < size)\n\t\treturn -ENOSPC;\n\n\tif (ns->shm_tot + numpages < ns->shm_tot ||\n\t\t\tns->shm_tot + numpages > ns->shm_ctlall)\n\t\treturn -ENOSPC;\n\n\tshp = ipc_rcu_alloc(sizeof(*shp));\n\tif (!shp)\n\t\treturn -ENOMEM;\n\n\tshp->shm_perm.key = key;\n\tshp->shm_perm.mode = (shmflg & S_IRWXUGO);\n\tshp->mlock_user = NULL;\n\n\tshp->shm_perm.security = NULL;\n\terror = security_shm_alloc(shp);\n\tif (error) {\n\t\tipc_rcu_putref(shp, ipc_rcu_free);\n\t\treturn error;\n\t}\n\n\tsprintf(name, \"SYSV%08x\", key);\n\tif (shmflg & SHM_HUGETLB) {\n\t\tstruct hstate *hs;\n\t\tsize_t hugesize;\n\n\t\ths = hstate_sizelog((shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);\n\t\tif (!hs) {\n\t\t\terror = -EINVAL;\n\t\t\tgoto no_file;\n\t\t}\n\t\thugesize = ALIGN(size, huge_page_size(hs));\n\n\t\t/* hugetlb_file_setup applies strict accounting */\n\t\tif (shmflg & SHM_NORESERVE)\n\t\t\tacctflag = VM_NORESERVE;\n\t\tfile = hugetlb_file_setup(name, hugesize, acctflag,\n\t\t\t\t  &shp->mlock_user, HUGETLB_SHMFS_INODE,\n\t\t\t\t(shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);\n\t} else {\n\t\t/*\n\t\t * Do not allow no accounting for OVERCOMMIT_NEVER, even\n\t\t * if it's asked for.\n\t\t */\n\t\tif  ((shmflg & SHM_NORESERVE) &&\n\t\t\t\tsysctl_overcommit_memory != OVERCOMMIT_NEVER)\n\t\t\tacctflag = VM_NORESERVE;\n\t\tfile = shmem_kernel_file_setup(name, size, acctflag);\n\t}\n\terror = PTR_ERR(file);\n\tif (IS_ERR(file))\n\t\tgoto no_file;\n\n\tshp->shm_cprid = task_tgid_vnr(current);\n\tshp->shm_lprid = 0;\n\tshp->shm_atim = shp->shm_dtim = 0;\n\tshp->shm_ctim = get_seconds();\n\tshp->shm_segsz = size;\n\tshp->shm_nattch = 0;\n\tshp->shm_file = file;\n\tshp->shm_creator = current;\n\n\tid = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);\n\tif (id < 0) {\n\t\terror = id;\n\t\tgoto no_id;\n\t}\n\n\tlist_add(&shp->shm_clist, &current->sysvshm.shm_clist);\n\n\t/*\n\t * shmid gets reported as \"inode#\" in /proc/pid/maps.\n\t * proc-ps tools use this. Changing this will break them.\n\t */\n\tfile_inode(file)->i_ino = shp->shm_perm.id;\n\n\tns->shm_tot += numpages;\n\terror = shp->shm_perm.id;\n\n\tipc_unlock_object(&shp->shm_perm);\n\trcu_read_unlock();\n\treturn error;\n\nno_id:\n\tif (is_file_hugepages(file) && shp->mlock_user)\n\t\tuser_shm_unlock(size, shp->mlock_user);\n\tfput(file);\nno_file:\n\tipc_rcu_putref(shp, shm_rcu_free);\n\treturn error;\n}\n\n/*\n * Called with shm_ids.rwsem and ipcp locked.\n */\nstatic inline int shm_security(struct kern_ipc_perm *ipcp, int shmflg)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\treturn security_shm_associate(shp, shmflg);\n}\n\n/*\n * Called with shm_ids.rwsem and ipcp locked.\n */\nstatic inline int shm_more_checks(struct kern_ipc_perm *ipcp,\n\t\t\t\tstruct ipc_params *params)\n{\n\tstruct shmid_kernel *shp;\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\tif (shp->shm_segsz < params->u.size)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nSYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)\n{\n\tstruct ipc_namespace *ns;\n\tstatic const struct ipc_ops shm_ops = {\n\t\t.getnew = newseg,\n\t\t.associate = shm_security,\n\t\t.more_checks = shm_more_checks,\n\t};\n\tstruct ipc_params shm_params;\n\n\tns = current->nsproxy->ipc_ns;\n\n\tshm_params.key = key;\n\tshm_params.flg = shmflg;\n\tshm_params.u.size = size;\n\n\treturn ipcget(ns, &shm_ids(ns), &shm_ops, &shm_params);\n}\n\nstatic inline unsigned long copy_shmid_to_user(void __user *buf, struct shmid64_ds *in, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\treturn copy_to_user(buf, in, sizeof(*in));\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shmid_ds out;\n\n\t\tmemset(&out, 0, sizeof(out));\n\t\tipc64_perm_to_ipc_perm(&in->shm_perm, &out.shm_perm);\n\t\tout.shm_segsz\t= in->shm_segsz;\n\t\tout.shm_atime\t= in->shm_atime;\n\t\tout.shm_dtime\t= in->shm_dtime;\n\t\tout.shm_ctime\t= in->shm_ctime;\n\t\tout.shm_cpid\t= in->shm_cpid;\n\t\tout.shm_lpid\t= in->shm_lpid;\n\t\tout.shm_nattch\t= in->shm_nattch;\n\n\t\treturn copy_to_user(buf, &out, sizeof(out));\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic inline unsigned long\ncopy_shmid_from_user(struct shmid64_ds *out, void __user *buf, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\tif (copy_from_user(out, buf, sizeof(*out)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shmid_ds tbuf_old;\n\n\t\tif (copy_from_user(&tbuf_old, buf, sizeof(tbuf_old)))\n\t\t\treturn -EFAULT;\n\n\t\tout->shm_perm.uid\t= tbuf_old.shm_perm.uid;\n\t\tout->shm_perm.gid\t= tbuf_old.shm_perm.gid;\n\t\tout->shm_perm.mode\t= tbuf_old.shm_perm.mode;\n\n\t\treturn 0;\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic inline unsigned long copy_shminfo_to_user(void __user *buf, struct shminfo64 *in, int version)\n{\n\tswitch (version) {\n\tcase IPC_64:\n\t\treturn copy_to_user(buf, in, sizeof(*in));\n\tcase IPC_OLD:\n\t    {\n\t\tstruct shminfo out;\n\n\t\tif (in->shmmax > INT_MAX)\n\t\t\tout.shmmax = INT_MAX;\n\t\telse\n\t\t\tout.shmmax = (int)in->shmmax;\n\n\t\tout.shmmin\t= in->shmmin;\n\t\tout.shmmni\t= in->shmmni;\n\t\tout.shmseg\t= in->shmseg;\n\t\tout.shmall\t= in->shmall;\n\n\t\treturn copy_to_user(buf, &out, sizeof(out));\n\t    }\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n/*\n * Calculate and add used RSS and swap pages of a shm.\n * Called with shm_ids.rwsem held as a reader\n */\nstatic void shm_add_rss_swap(struct shmid_kernel *shp,\n\tunsigned long *rss_add, unsigned long *swp_add)\n{\n\tstruct inode *inode;\n\n\tinode = file_inode(shp->shm_file);\n\n\tif (is_file_hugepages(shp->shm_file)) {\n\t\tstruct address_space *mapping = inode->i_mapping;\n\t\tstruct hstate *h = hstate_file(shp->shm_file);\n\t\t*rss_add += pages_per_huge_page(h) * mapping->nrpages;\n\t} else {\n#ifdef CONFIG_SHMEM\n\t\tstruct shmem_inode_info *info = SHMEM_I(inode);\n\n\t\tspin_lock_irq(&info->lock);\n\t\t*rss_add += inode->i_mapping->nrpages;\n\t\t*swp_add += info->swapped;\n\t\tspin_unlock_irq(&info->lock);\n#else\n\t\t*rss_add += inode->i_mapping->nrpages;\n#endif\n\t}\n}\n\n/*\n * Called with shm_ids.rwsem held as a reader\n */\nstatic void shm_get_stat(struct ipc_namespace *ns, unsigned long *rss,\n\t\tunsigned long *swp)\n{\n\tint next_id;\n\tint total, in_use;\n\n\t*rss = 0;\n\t*swp = 0;\n\n\tin_use = shm_ids(ns).in_use;\n\n\tfor (total = 0, next_id = 0; total < in_use; next_id++) {\n\t\tstruct kern_ipc_perm *ipc;\n\t\tstruct shmid_kernel *shp;\n\n\t\tipc = idr_find(&shm_ids(ns).ipcs_idr, next_id);\n\t\tif (ipc == NULL)\n\t\t\tcontinue;\n\t\tshp = container_of(ipc, struct shmid_kernel, shm_perm);\n\n\t\tshm_add_rss_swap(shp, rss, swp);\n\n\t\ttotal++;\n\t}\n}\n\n/*\n * This function handles some shmctl commands which require the rwsem\n * to be held in write mode.\n * NOTE: no locks must be held, the rwsem is taken inside this function.\n */\nstatic int shmctl_down(struct ipc_namespace *ns, int shmid, int cmd,\n\t\t       struct shmid_ds __user *buf, int version)\n{\n\tstruct kern_ipc_perm *ipcp;\n\tstruct shmid64_ds shmid64;\n\tstruct shmid_kernel *shp;\n\tint err;\n\n\tif (cmd == IPC_SET) {\n\t\tif (copy_shmid_from_user(&shmid64, buf, version))\n\t\t\treturn -EFAULT;\n\t}\n\n\tdown_write(&shm_ids(ns).rwsem);\n\trcu_read_lock();\n\n\tipcp = ipcctl_pre_down_nolock(ns, &shm_ids(ns), shmid, cmd,\n\t\t\t\t      &shmid64.shm_perm, 0);\n\tif (IS_ERR(ipcp)) {\n\t\terr = PTR_ERR(ipcp);\n\t\tgoto out_unlock1;\n\t}\n\n\tshp = container_of(ipcp, struct shmid_kernel, shm_perm);\n\n\terr = security_shm_shmctl(shp, cmd);\n\tif (err)\n\t\tgoto out_unlock1;\n\n\tswitch (cmd) {\n\tcase IPC_RMID:\n\t\tipc_lock_object(&shp->shm_perm);\n\t\t/* do_shm_rmid unlocks the ipc object and rcu */\n\t\tdo_shm_rmid(ns, ipcp);\n\t\tgoto out_up;\n\tcase IPC_SET:\n\t\tipc_lock_object(&shp->shm_perm);\n\t\terr = ipc_update_perm(&shmid64.shm_perm, ipcp);\n\t\tif (err)\n\t\t\tgoto out_unlock0;\n\t\tshp->shm_ctim = get_seconds();\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto out_unlock1;\n\t}\n\nout_unlock0:\n\tipc_unlock_object(&shp->shm_perm);\nout_unlock1:\n\trcu_read_unlock();\nout_up:\n\tup_write(&shm_ids(ns).rwsem);\n\treturn err;\n}\n\nstatic int shmctl_nolock(struct ipc_namespace *ns, int shmid,\n\t\t\t int cmd, int version, void __user *buf)\n{\n\tint err;\n\tstruct shmid_kernel *shp;\n\n\t/* preliminary security checks for *_INFO */\n\tif (cmd == IPC_INFO || cmd == SHM_INFO) {\n\t\terr = security_shm_shmctl(NULL, cmd);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tswitch (cmd) {\n\tcase IPC_INFO:\n\t{\n\t\tstruct shminfo64 shminfo;\n\n\t\tmemset(&shminfo, 0, sizeof(shminfo));\n\t\tshminfo.shmmni = shminfo.shmseg = ns->shm_ctlmni;\n\t\tshminfo.shmmax = ns->shm_ctlmax;\n\t\tshminfo.shmall = ns->shm_ctlall;\n\n\t\tshminfo.shmmin = SHMMIN;\n\t\tif (copy_shminfo_to_user(buf, &shminfo, version))\n\t\t\treturn -EFAULT;\n\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\terr = ipc_get_maxid(&shm_ids(ns));\n\t\tup_read(&shm_ids(ns).rwsem);\n\n\t\tif (err < 0)\n\t\t\terr = 0;\n\t\tgoto out;\n\t}\n\tcase SHM_INFO:\n\t{\n\t\tstruct shm_info shm_info;\n\n\t\tmemset(&shm_info, 0, sizeof(shm_info));\n\t\tdown_read(&shm_ids(ns).rwsem);\n\t\tshm_info.used_ids = shm_ids(ns).in_use;\n\t\tshm_get_stat(ns, &shm_info.shm_rss, &shm_info.shm_swp);\n\t\tshm_info.shm_tot = ns->shm_tot;\n\t\tshm_info.swap_attempts = 0;\n\t\tshm_info.swap_successes = 0;\n\t\terr = ipc_get_maxid(&shm_ids(ns));\n\t\tup_read(&shm_ids(ns).rwsem);\n\t\tif (copy_to_user(buf, &shm_info, sizeof(shm_info))) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = err < 0 ? 0 : err;\n\t\tgoto out;\n\t}\n\tcase SHM_STAT:\n\tcase IPC_STAT:\n\t{\n\t\tstruct shmid64_ds tbuf;\n\t\tint result;\n\n\t\trcu_read_lock();\n\t\tif (cmd == SHM_STAT) {\n\t\t\tshp = shm_obtain_object(ns, shmid);\n\t\t\tif (IS_ERR(shp)) {\n\t\t\t\terr = PTR_ERR(shp);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tresult = shp->shm_perm.id;\n\t\t} else {\n\t\t\tshp = shm_obtain_object_check(ns, shmid);\n\t\t\tif (IS_ERR(shp)) {\n\t\t\t\terr = PTR_ERR(shp);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tresult = 0;\n\t\t}\n\n\t\terr = -EACCES;\n\t\tif (ipcperms(ns, &shp->shm_perm, S_IRUGO))\n\t\t\tgoto out_unlock;\n\n\t\terr = security_shm_shmctl(shp, cmd);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\n\t\tmemset(&tbuf, 0, sizeof(tbuf));\n\t\tkernel_to_ipc64_perm(&shp->shm_perm, &tbuf.shm_perm);\n\t\ttbuf.shm_segsz\t= shp->shm_segsz;\n\t\ttbuf.shm_atime\t= shp->shm_atim;\n\t\ttbuf.shm_dtime\t= shp->shm_dtim;\n\t\ttbuf.shm_ctime\t= shp->shm_ctim;\n\t\ttbuf.shm_cpid\t= shp->shm_cprid;\n\t\ttbuf.shm_lpid\t= shp->shm_lprid;\n\t\ttbuf.shm_nattch\t= shp->shm_nattch;\n\t\trcu_read_unlock();\n\n\t\tif (copy_shmid_to_user(buf, &tbuf, version))\n\t\t\terr = -EFAULT;\n\t\telse\n\t\t\terr = result;\n\t\tgoto out;\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn err;\n}\n\nSYSCALL_DEFINE3(shmctl, int, shmid, int, cmd, struct shmid_ds __user *, buf)\n{\n\tstruct shmid_kernel *shp;\n\tint err, version;\n\tstruct ipc_namespace *ns;\n\n\tif (cmd < 0 || shmid < 0)\n\t\treturn -EINVAL;\n\n\tversion = ipc_parse_version(&cmd);\n\tns = current->nsproxy->ipc_ns;\n\n\tswitch (cmd) {\n\tcase IPC_INFO:\n\tcase SHM_INFO:\n\tcase SHM_STAT:\n\tcase IPC_STAT:\n\t\treturn shmctl_nolock(ns, shmid, cmd, version, buf);\n\tcase IPC_RMID:\n\tcase IPC_SET:\n\t\treturn shmctl_down(ns, shmid, cmd, buf, version);\n\tcase SHM_LOCK:\n\tcase SHM_UNLOCK:\n\t{\n\t\tstruct file *shm_file;\n\n\t\trcu_read_lock();\n\t\tshp = shm_obtain_object_check(ns, shmid);\n\t\tif (IS_ERR(shp)) {\n\t\t\terr = PTR_ERR(shp);\n\t\t\tgoto out_unlock1;\n\t\t}\n\n\t\taudit_ipc_obj(&(shp->shm_perm));\n\t\terr = security_shm_shmctl(shp, cmd);\n\t\tif (err)\n\t\t\tgoto out_unlock1;\n\n\t\tipc_lock_object(&shp->shm_perm);\n\n\t\t/* check if shm_destroy() is tearing down shp */\n\t\tif (!ipc_valid_object(&shp->shm_perm)) {\n\t\t\terr = -EIDRM;\n\t\t\tgoto out_unlock0;\n\t\t}\n\n\t\tif (!ns_capable(ns->user_ns, CAP_IPC_LOCK)) {\n\t\t\tkuid_t euid = current_euid();\n\n\t\t\tif (!uid_eq(euid, shp->shm_perm.uid) &&\n\t\t\t    !uid_eq(euid, shp->shm_perm.cuid)) {\n\t\t\t\terr = -EPERM;\n\t\t\t\tgoto out_unlock0;\n\t\t\t}\n\t\t\tif (cmd == SHM_LOCK && !rlimit(RLIMIT_MEMLOCK)) {\n\t\t\t\terr = -EPERM;\n\t\t\t\tgoto out_unlock0;\n\t\t\t}\n\t\t}\n\n\t\tshm_file = shp->shm_file;\n\t\tif (is_file_hugepages(shm_file))\n\t\t\tgoto out_unlock0;\n\n\t\tif (cmd == SHM_LOCK) {\n\t\t\tstruct user_struct *user = current_user();\n\n\t\t\terr = shmem_lock(shm_file, 1, user);\n\t\t\tif (!err && !(shp->shm_perm.mode & SHM_LOCKED)) {\n\t\t\t\tshp->shm_perm.mode |= SHM_LOCKED;\n\t\t\t\tshp->mlock_user = user;\n\t\t\t}\n\t\t\tgoto out_unlock0;\n\t\t}\n\n\t\t/* SHM_UNLOCK */\n\t\tif (!(shp->shm_perm.mode & SHM_LOCKED))\n\t\t\tgoto out_unlock0;\n\t\tshmem_lock(shm_file, 0, shp->mlock_user);\n\t\tshp->shm_perm.mode &= ~SHM_LOCKED;\n\t\tshp->mlock_user = NULL;\n\t\tget_file(shm_file);\n\t\tipc_unlock_object(&shp->shm_perm);\n\t\trcu_read_unlock();\n\t\tshmem_unlock_mapping(shm_file->f_mapping);\n\n\t\tfput(shm_file);\n\t\treturn err;\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nout_unlock0:\n\tipc_unlock_object(&shp->shm_perm);\nout_unlock1:\n\trcu_read_unlock();\n\treturn err;\n}\n\n/*\n * Fix shmaddr, allocate descriptor, map shm, add attach descriptor to lists.\n *\n * NOTE! Despite the name, this is NOT a direct system call entrypoint. The\n * \"raddr\" thing points to kernel space, and there has to be a wrapper around\n * this.\n */\nlong do_shmat(int shmid, char __user *shmaddr, int shmflg,\n\t      ulong *raddr, unsigned long shmlba)\n{\n\tstruct shmid_kernel *shp;\n\tunsigned long addr;\n\tunsigned long size;\n\tstruct file *file;\n\tint    err;\n\tunsigned long flags;\n\tunsigned long prot;\n\tint acc_mode;\n\tstruct ipc_namespace *ns;\n\tstruct shm_file_data *sfd;\n\tstruct path path;\n\tfmode_t f_mode;\n\tunsigned long populate = 0;\n\n\terr = -EINVAL;\n\tif (shmid < 0)\n\t\tgoto out;\n\telse if ((addr = (ulong)shmaddr)) {\n\t\tif (addr & (shmlba - 1)) {\n\t\t\t/*\n\t\t\t * Round down to the nearest multiple of shmlba.\n\t\t\t * For sane do_mmap_pgoff() parameters, avoid\n\t\t\t * round downs that trigger nil-page and MAP_FIXED.\n\t\t\t */\n\t\t\tif ((shmflg & SHM_RND) && addr >= shmlba)\n\t\t\t\taddr &= ~(shmlba - 1);\n\t\t\telse\n#ifndef __ARCH_FORCE_SHMLBA\n\t\t\t\tif (addr & ~PAGE_MASK)\n#endif\n\t\t\t\t\tgoto out;\n\t\t}\n\t\tflags = MAP_SHARED | MAP_FIXED;\n\t} else {\n\t\tif ((shmflg & SHM_REMAP))\n\t\t\tgoto out;\n\n\t\tflags = MAP_SHARED;\n\t}\n\n\tif (shmflg & SHM_RDONLY) {\n\t\tprot = PROT_READ;\n\t\tacc_mode = S_IRUGO;\n\t\tf_mode = FMODE_READ;\n\t} else {\n\t\tprot = PROT_READ | PROT_WRITE;\n\t\tacc_mode = S_IRUGO | S_IWUGO;\n\t\tf_mode = FMODE_READ | FMODE_WRITE;\n\t}\n\tif (shmflg & SHM_EXEC) {\n\t\tprot |= PROT_EXEC;\n\t\tacc_mode |= S_IXUGO;\n\t}\n\n\t/*\n\t * We cannot rely on the fs check since SYSV IPC does have an\n\t * additional creator id...\n\t */\n\tns = current->nsproxy->ipc_ns;\n\trcu_read_lock();\n\tshp = shm_obtain_object_check(ns, shmid);\n\tif (IS_ERR(shp)) {\n\t\terr = PTR_ERR(shp);\n\t\tgoto out_unlock;\n\t}\n\n\terr = -EACCES;\n\tif (ipcperms(ns, &shp->shm_perm, acc_mode))\n\t\tgoto out_unlock;\n\n\terr = security_shm_shmat(shp, shmaddr, shmflg);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tipc_lock_object(&shp->shm_perm);\n\n\t/* check if shm_destroy() is tearing down shp */\n\tif (!ipc_valid_object(&shp->shm_perm)) {\n\t\tipc_unlock_object(&shp->shm_perm);\n\t\terr = -EIDRM;\n\t\tgoto out_unlock;\n\t}\n\n\tpath = shp->shm_file->f_path;\n\tpath_get(&path);\n\tshp->shm_nattch++;\n\tsize = i_size_read(d_inode(path.dentry));\n\tipc_unlock_object(&shp->shm_perm);\n\trcu_read_unlock();\n\n\terr = -ENOMEM;\n\tsfd = kzalloc(sizeof(*sfd), GFP_KERNEL);\n\tif (!sfd) {\n\t\tpath_put(&path);\n\t\tgoto out_nattch;\n\t}\n\n\tfile = alloc_file(&path, f_mode,\n\t\t\t  is_file_hugepages(shp->shm_file) ?\n\t\t\t\t&shm_file_operations_huge :\n\t\t\t\t&shm_file_operations);\n\terr = PTR_ERR(file);\n\tif (IS_ERR(file)) {\n\t\tkfree(sfd);\n\t\tpath_put(&path);\n\t\tgoto out_nattch;\n\t}\n\n\tfile->private_data = sfd;\n\tfile->f_mapping = shp->shm_file->f_mapping;\n\tsfd->id = shp->shm_perm.id;\n\tsfd->ns = get_ipc_ns(ns);\n\tsfd->file = shp->shm_file;\n\tsfd->vm_ops = NULL;\n\n\terr = security_mmap_file(file, prot, flags);\n\tif (err)\n\t\tgoto out_fput;\n\n\tif (down_write_killable(&current->mm->mmap_sem)) {\n\t\terr = -EINTR;\n\t\tgoto out_fput;\n\t}\n\n\tif (addr && !(shmflg & SHM_REMAP)) {\n\t\terr = -EINVAL;\n\t\tif (addr + size < addr)\n\t\t\tgoto invalid;\n\n\t\tif (find_vma_intersection(current->mm, addr, addr + size))\n\t\t\tgoto invalid;\n\t}\n\n\taddr = do_mmap_pgoff(file, addr, size, prot, flags, 0, &populate, NULL);\n\t*raddr = addr;\n\terr = 0;\n\tif (IS_ERR_VALUE(addr))\n\t\terr = (long)addr;\ninvalid:\n\tup_write(&current->mm->mmap_sem);\n\tif (populate)\n\t\tmm_populate(addr, populate);\n\nout_fput:\n\tfput(file);\n\nout_nattch:\n\tdown_write(&shm_ids(ns).rwsem);\n\tshp = shm_lock(ns, shmid);\n\tshp->shm_nattch--;\n\tif (shm_may_destroy(ns, shp))\n\t\tshm_destroy(ns, shp);\n\telse\n\t\tshm_unlock(shp);\n\tup_write(&shm_ids(ns).rwsem);\n\treturn err;\n\nout_unlock:\n\trcu_read_unlock();\nout:\n\treturn err;\n}\n\nSYSCALL_DEFINE3(shmat, int, shmid, char __user *, shmaddr, int, shmflg)\n{\n\tunsigned long ret;\n\tlong err;\n\n\terr = do_shmat(shmid, shmaddr, shmflg, &ret, SHMLBA);\n\tif (err)\n\t\treturn err;\n\tforce_successful_syscall_return();\n\treturn (long)ret;\n}\n\n/*\n * detach and kill segment if marked destroyed.\n * The work is done in shm_close.\n */\nSYSCALL_DEFINE1(shmdt, char __user *, shmaddr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long addr = (unsigned long)shmaddr;\n\tint retval = -EINVAL;\n#ifdef CONFIG_MMU\n\tloff_t size = 0;\n\tstruct file *file;\n\tstruct vm_area_struct *next;\n#endif\n\n\tif (addr & ~PAGE_MASK)\n\t\treturn retval;\n\n\tif (down_write_killable(&mm->mmap_sem))\n\t\treturn -EINTR;\n\n\t/*\n\t * This function tries to be smart and unmap shm segments that\n\t * were modified by partial mlock or munmap calls:\n\t * - It first determines the size of the shm segment that should be\n\t *   unmapped: It searches for a vma that is backed by shm and that\n\t *   started at address shmaddr. It records it's size and then unmaps\n\t *   it.\n\t * - Then it unmaps all shm vmas that started at shmaddr and that\n\t *   are within the initially determined size and that are from the\n\t *   same shm segment from which we determined the size.\n\t * Errors from do_munmap are ignored: the function only fails if\n\t * it's called with invalid parameters or if it's called to unmap\n\t * a part of a vma. Both calls in this function are for full vmas,\n\t * the parameters are directly copied from the vma itself and always\n\t * valid - therefore do_munmap cannot fail. (famous last words?)\n\t */\n\t/*\n\t * If it had been mremap()'d, the starting address would not\n\t * match the usual checks anyway. So assume all vma's are\n\t * above the starting address given.\n\t */\n\tvma = find_vma(mm, addr);\n\n#ifdef CONFIG_MMU\n\twhile (vma) {\n\t\tnext = vma->vm_next;\n\n\t\t/*\n\t\t * Check if the starting address would match, i.e. it's\n\t\t * a fragment created by mprotect() and/or munmap(), or it\n\t\t * otherwise it starts at this address with no hassles.\n\t\t */\n\t\tif ((vma->vm_ops == &shm_vm_ops) &&\n\t\t\t(vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) {\n\n\t\t\t/*\n\t\t\t * Record the file of the shm segment being\n\t\t\t * unmapped.  With mremap(), someone could place\n\t\t\t * page from another segment but with equal offsets\n\t\t\t * in the range we are unmapping.\n\t\t\t */\n\t\t\tfile = vma->vm_file;\n\t\t\tsize = i_size_read(file_inode(vma->vm_file));\n\t\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\t\t/*\n\t\t\t * We discovered the size of the shm segment, so\n\t\t\t * break out of here and fall through to the next\n\t\t\t * loop that uses the size information to stop\n\t\t\t * searching for matching vma's.\n\t\t\t */\n\t\t\tretval = 0;\n\t\t\tvma = next;\n\t\t\tbreak;\n\t\t}\n\t\tvma = next;\n\t}\n\n\t/*\n\t * We need look no further than the maximum address a fragment\n\t * could possibly have landed at. Also cast things to loff_t to\n\t * prevent overflows and make comparisons vs. equal-width types.\n\t */\n\tsize = PAGE_ALIGN(size);\n\twhile (vma && (loff_t)(vma->vm_end - addr) <= size) {\n\t\tnext = vma->vm_next;\n\n\t\t/* finding a matching vma now does not alter retval */\n\t\tif ((vma->vm_ops == &shm_vm_ops) &&\n\t\t    ((vma->vm_start - addr)/PAGE_SIZE == vma->vm_pgoff) &&\n\t\t    (vma->vm_file == file))\n\t\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\tvma = next;\n\t}\n\n#else\t/* CONFIG_MMU */\n\t/* under NOMMU conditions, the exact address to be destroyed must be\n\t * given\n\t */\n\tif (vma && vma->vm_start == addr && vma->vm_ops == &shm_vm_ops) {\n\t\tdo_munmap(mm, vma->vm_start, vma->vm_end - vma->vm_start, NULL);\n\t\tretval = 0;\n\t}\n\n#endif\n\n\tup_write(&mm->mmap_sem);\n\treturn retval;\n}\n\n#ifdef CONFIG_PROC_FS\nstatic int sysvipc_shm_proc_show(struct seq_file *s, void *it)\n{\n\tstruct user_namespace *user_ns = seq_user_ns(s);\n\tstruct shmid_kernel *shp = it;\n\tunsigned long rss = 0, swp = 0;\n\n\tshm_add_rss_swap(shp, &rss, &swp);\n\n#if BITS_PER_LONG <= 32\n#define SIZE_SPEC \"%10lu\"\n#else\n#define SIZE_SPEC \"%21lu\"\n#endif\n\n\tseq_printf(s,\n\t\t   \"%10d %10d  %4o \" SIZE_SPEC \" %5u %5u  \"\n\t\t   \"%5lu %5u %5u %5u %5u %10lu %10lu %10lu \"\n\t\t   SIZE_SPEC \" \" SIZE_SPEC \"\\n\",\n\t\t   shp->shm_perm.key,\n\t\t   shp->shm_perm.id,\n\t\t   shp->shm_perm.mode,\n\t\t   shp->shm_segsz,\n\t\t   shp->shm_cprid,\n\t\t   shp->shm_lprid,\n\t\t   shp->shm_nattch,\n\t\t   from_kuid_munged(user_ns, shp->shm_perm.uid),\n\t\t   from_kgid_munged(user_ns, shp->shm_perm.gid),\n\t\t   from_kuid_munged(user_ns, shp->shm_perm.cuid),\n\t\t   from_kgid_munged(user_ns, shp->shm_perm.cgid),\n\t\t   shp->shm_atim,\n\t\t   shp->shm_dtim,\n\t\t   shp->shm_ctim,\n\t\t   rss * PAGE_SIZE,\n\t\t   swp * PAGE_SIZE);\n\n\treturn 0;\n}\n#endif\n"], "buggy_code_start_loc": [1094], "buggy_code_end_loc": [1118], "fixing_code_start_loc": [1094], "fixing_code_end_loc": [1123], "type": "NVD-CWE-noinfo", "message": "The do_shmat function in ipc/shm.c in the Linux kernel through 4.9.12 does not restrict the address calculated by a certain rounding operation, which allows local users to map page zero, and consequently bypass a protection mechanism that exists for the mmap system call, by making crafted shmget and shmat system calls in a privileged context.", "other": {"cve": {"id": "CVE-2017-5669", "sourceIdentifier": "cve@mitre.org", "published": "2017-02-24T15:59:00.150", "lastModified": "2020-10-09T14:49:28.933", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The do_shmat function in ipc/shm.c in the Linux kernel through 4.9.12 does not restrict the address calculated by a certain rounding operation, which allows local users to map page zero, and consequently bypass a protection mechanism that exists for the mmap system call, by making crafted shmget and shmat system calls in a privileged context."}, {"lang": "es", "value": "La funci\u00f3n do_shmat en ipc/shm.c en el kernel de Linux hasta la versi\u00f3n 4.9.12 no restringe la direcci\u00f3n calculada por cierta operaci\u00f3n de redondeo, lo que permite a usuarios locales asignar la p\u00e1gina cero, y como consecuencia, eludir un mecanismo de protecci\u00f3n que existe por la llamada de sistema mmap, haciendo llamadas a sistema shmget y shmat manipuladas en un contexto privilegiado."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "4.11", "matchCriteriaId": "68E74529-58C5-4D73-8176-DDDF25C71F22"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:esm:*:*:*", "matchCriteriaId": "8D305F7A-D159-4716-AB26-5E38BB5CD991"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}]}]}], "references": [{"url": "http://www.debian.org/security/2017/dsa-3804", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/96754", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1037918", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.kernel.org/show_bug.cgi?id=192931", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/95e91b831f87ac8e1f8ed50c14d709089b4e01b8", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/e1d35d4dc7f089e6c9c080d556feedf9c706f0c7", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3583-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3583-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/95e91b831f87ac8e1f8ed50c14d709089b4e01b8"}}