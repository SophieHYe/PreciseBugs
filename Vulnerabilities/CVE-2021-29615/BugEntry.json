{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/attr_value_util.h\"\n\n#include <string>\n#include <unordered_map>\n#include <vector>\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/attr_value.pb_text.h\"\n#include \"tensorflow/core/framework/tensor.pb_text.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb_text.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/hash/hash.h\"\n#include \"tensorflow/core/lib/strings/proto_serialization.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n\nnamespace tensorflow {\nnamespace {\n\n// Do not construct large tensors to compute their hash or compare for equality.\nconstexpr int kMaxAttrValueTensorByteSize = 32 * 1024 * 1024;  // 32mb\n\n// Return the size of the tensor represented by this TensorProto. If shape is\n// not fully defined return -1.\nint64 TensorByteSize(const TensorProto& t) {\n  // num_elements returns -1 if shape is not fully defined.\n  int64 num_elems = TensorShape(t.tensor_shape()).num_elements();\n  return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n}\n\n// Compute TensorProto hash by creating a Tensor, serializing it as tensor\n// content, and computing a hash of it's string representation. This is unsafe\n// operation, because large tensors can be represented as TensorProto, but can't\n// be serialized to tensor content.\nuint64 TensorProtoHash(const TensorProto& tp) {\n  Tensor tensor(tp.dtype());\n  bool success = tensor.FromProto(tp);\n  DCHECK(success);\n  TensorProto p;\n  tensor.AsProtoTensorContent(&p);\n  return DeterministicProtoHash64(p);\n}\n\n// Do not create large tensors in memory, compute hash based on TensorProto\n// string representation. Tensors with identical content potentially can have a\n// different hash code if they are defined with different TensorProto\n// representations.\nuint64 FastTensorProtoHash(const TensorProto& tp) {\n  if (TensorByteSize(tp) > kMaxAttrValueTensorByteSize) {\n    return DeterministicProtoHash64(tp);\n  } else {\n    return TensorProtoHash(tp);\n  }\n}\n\n// There are multiple equivalent representations of attr values containing\n// TensorProtos. Compare them by constructing Tensors and serializing them\n// back. Comparing Tensor objects is pretty tricky. This is unsafe operation,\n// because large tensors can be represented as TensorProto, but can't be\n// serialized to tensor content.\nbool AreTensorProtosEqual(const TensorProto& lhs, const TensorProto& rhs) {\n  Tensor lhs_t(lhs.dtype());\n  bool success = lhs_t.FromProto(lhs);\n  DCHECK(success);\n\n  Tensor rhs_t(rhs.dtype());\n  success = rhs_t.FromProto(rhs);\n  DCHECK(success);\n\n  TensorProto lhs_tp;\n  lhs_t.AsProtoTensorContent(&lhs_tp);\n\n  TensorProto rhs_tp;\n  rhs_t.AsProtoTensorContent(&rhs_tp);\n\n  return AreSerializedProtosEqual(lhs_tp, rhs_tp);\n}\n\n// Do not construct large tensors in memory, compare equality using TensorProto\n// string representation. Tensors with identical content potentially can have\n// different tensor proto representation.\nbool FastAreTensorProtosEqual(const TensorProto& lhs, const TensorProto& rhs) {\n  // A small TensorProto can expand into a giant Tensor.  So we avoid\n  // conversion to an actual Tensor if we can quickly rule out equality\n  // by comparing the Tensor size since different sized Tensors are definitely\n  // different.\n  const int64 lhs_tensor_bytes = TensorByteSize(lhs);\n  const int64 rhs_tensor_bytes = TensorByteSize(rhs);\n  if (lhs_tensor_bytes != rhs_tensor_bytes) {\n    return false;\n  }\n\n  // If the tensor is very large, we'll only compare the proto representation\n  // (even though this may miss some equivalent tensors whose actual tensor\n  // values are the same but which are described by different TensorProtos).\n  if (lhs_tensor_bytes > kMaxAttrValueTensorByteSize) {\n    return AreSerializedProtosEqual(lhs, rhs);\n  }\n\n  // If the TensorProto representation expands into a much bigger Tensor,\n  // we have a fast-path that first compares the protos.\n  const int64 lhs_proto_bytes = lhs.ByteSizeLong();\n  const bool large_expansion =\n      (lhs_proto_bytes < 512 && lhs_tensor_bytes > 4096);\n  if (large_expansion && AreSerializedProtosEqual(lhs, rhs)) {\n    return true;\n  }\n\n  // Fall back to the general code in AreTensorProtosEqual.\n  return AreTensorProtosEqual(lhs, rhs);\n}\n\nusing TensorProtoHasher = std::function<uint64(const TensorProto&)>;\n\nuint64 AttrValueHash(const AttrValue& a, const TensorProtoHasher& tensor_hash) {\n  if (a.has_tensor()) return tensor_hash(a.tensor());\n\n  if (a.has_func()) {\n    const NameAttrList& func = a.func();\n    uint64 h = Hash64(func.name());\n    std::map<string, AttrValue> map(func.attr().begin(), func.attr().end());\n    for (const auto& pair : map) {\n      h = Hash64(pair.first.data(), pair.first.size(), h);\n      h = Hash64Combine(AttrValueHash(pair.second, tensor_hash), h);\n    }\n    return h;\n  }\n\n  // If `a` is not a tensor or func, get a hash of serialized string.\n  return DeterministicProtoHash64(a);\n}\n\ntemplate <typename TensorProtosEquality>\nbool AreAttrValuesEqual(const AttrValue& a, const AttrValue& b,\n                        TensorProtosEquality tensor_equality) {\n  if (a.type() != b.type()) {\n    return false;\n  } else if (a.type() != DT_INVALID && b.type() != DT_INVALID) {\n    return a.type() == b.type();\n  }\n\n  if (a.has_tensor() != b.has_tensor()) {\n    return false;\n  } else if (a.has_tensor() && b.has_tensor()) {\n    return tensor_equality(a.tensor(), b.tensor());\n  }\n\n  // `func` field contains a nested AttrValue. Compare such AttrValues\n  // recursively.\n  if (a.has_func() != b.has_func()) {\n    return false;\n  } else if (a.has_func() && b.has_func()) {\n    const NameAttrList& af = a.func();\n    const NameAttrList& bf = b.func();\n    if (af.name() != bf.name()) return false;\n    std::unordered_map<string, AttrValue> am(af.attr().begin(),\n                                             af.attr().end());\n    for (const auto& bm_pair : bf.attr()) {\n      const auto& iter = am.find(bm_pair.first);\n      if (iter == am.end()) return false;\n      if (!AreAttrValuesEqual(iter->second, bm_pair.second, tensor_equality))\n        return false;\n      am.erase(iter);\n    }\n    if (!am.empty()) return false;\n    return true;\n  }\n\n  // All other fields in AttrValue have deterministic representations.\n  // It is safe to compare their serialized strings.\n  return AreSerializedProtosEqual(a, b);\n}\n\nstring SummarizeString(const string& str) {\n  string escaped = absl::CEscape(str);\n\n  // If the string is long, replace the middle with ellipses.\n  constexpr int kMaxStringSummarySize = 80;\n  if (escaped.size() >= kMaxStringSummarySize) {\n    StringPiece prefix(escaped);\n    StringPiece suffix = prefix;\n    prefix.remove_suffix(escaped.size() - 10);\n    suffix.remove_prefix(escaped.size() - 10);\n    return strings::StrCat(\"\\\"\", prefix, \"...\", suffix, \"\\\"\");\n  } else {\n    return strings::StrCat(\"\\\"\", escaped, \"\\\"\");\n  }\n}\n\nstring SummarizeTensor(const TensorProto& tensor_proto) {\n  Tensor t;\n  if (!t.FromProto(tensor_proto)) {\n    return strings::StrCat(\n        \"<Invalid TensorProto: \", tensor_proto.ShortDebugString(), \">\");\n  }\n  return t.DebugString();\n}\n\nstring SummarizeFunc(const NameAttrList& func) {\n  std::vector<string> entries;\n  for (const auto& p : func.attr()) {\n    entries.push_back(\n        strings::StrCat(p.first, \"=\", SummarizeAttrValue(p.second)));\n  }\n  std::sort(entries.begin(), entries.end());\n  return strings::StrCat(func.name(), \"[\", absl::StrJoin(entries, \", \"), \"]\");\n}\n\n}  // namespace\n\nstring SummarizeAttrValue(const AttrValue& attr_value) {\n  switch (attr_value.value_case()) {\n    case AttrValue::kS:\n      return SummarizeString(attr_value.s());\n    case AttrValue::kI:\n      return strings::StrCat(attr_value.i());\n    case AttrValue::kF:\n      return strings::StrCat(attr_value.f());\n    case AttrValue::kB:\n      return attr_value.b() ? \"true\" : \"false\";\n    case AttrValue::kType:\n      return EnumName_DataType(attr_value.type());\n    case AttrValue::kShape:\n      return PartialTensorShape::DebugString(attr_value.shape());\n    case AttrValue::kTensor:\n      return SummarizeTensor(attr_value.tensor());\n    case AttrValue::kList: {\n      std::vector<string> pieces;\n      if (attr_value.list().s_size() > 0) {\n        for (int i = 0; i < attr_value.list().s_size(); ++i) {\n          pieces.push_back(SummarizeString(attr_value.list().s(i)));\n        }\n      } else if (attr_value.list().i_size() > 0) {\n        for (int i = 0; i < attr_value.list().i_size(); ++i) {\n          pieces.push_back(strings::StrCat(attr_value.list().i(i)));\n        }\n      } else if (attr_value.list().f_size() > 0) {\n        for (int i = 0; i < attr_value.list().f_size(); ++i) {\n          pieces.push_back(strings::StrCat(attr_value.list().f(i)));\n        }\n      } else if (attr_value.list().b_size() > 0) {\n        for (int i = 0; i < attr_value.list().b_size(); ++i) {\n          pieces.push_back(attr_value.list().b(i) ? \"true\" : \"false\");\n        }\n      } else if (attr_value.list().type_size() > 0) {\n        for (int i = 0; i < attr_value.list().type_size(); ++i) {\n          pieces.push_back(EnumName_DataType(attr_value.list().type(i)));\n        }\n      } else if (attr_value.list().shape_size() > 0) {\n        for (int i = 0; i < attr_value.list().shape_size(); ++i) {\n          pieces.push_back(\n              TensorShape::DebugString(attr_value.list().shape(i)));\n        }\n      } else if (attr_value.list().tensor_size() > 0) {\n        for (int i = 0; i < attr_value.list().tensor_size(); ++i) {\n          pieces.push_back(SummarizeTensor(attr_value.list().tensor(i)));\n        }\n      } else if (attr_value.list().func_size() > 0) {\n        for (int i = 0; i < attr_value.list().func_size(); ++i) {\n          pieces.push_back(SummarizeFunc(attr_value.list().func(i)));\n        }\n      }\n      constexpr int kMaxListSummarySize = 50;\n      if (pieces.size() >= kMaxListSummarySize) {\n        pieces.erase(pieces.begin() + 5, pieces.begin() + (pieces.size() - 6));\n        pieces[5] = \"...\";\n      }\n      return strings::StrCat(\"[\", absl::StrJoin(pieces, \", \"), \"]\");\n    }\n    case AttrValue::kFunc: {\n      return SummarizeFunc(attr_value.func());\n    }\n    case AttrValue::kPlaceholder:\n      return strings::StrCat(\"$\", attr_value.placeholder());\n    case AttrValue::VALUE_NOT_SET:\n      return \"<Unknown AttrValue type>\";\n  }\n  return \"<Unknown AttrValue type>\";  // Prevent missing return warning\n}\n\nStatus AttrValueHasType(const AttrValue& attr_value, StringPiece type) {\n  int num_set = 0;\n\n#define VALIDATE_FIELD(name, type_string, oneof_case)                         \\\n  do {                                                                        \\\n    if (attr_value.has_list()) {                                              \\\n      if (attr_value.list().name##_size() > 0) {                              \\\n        if (type != \"list(\" type_string \")\") {                                \\\n          return errors::InvalidArgument(                                     \\\n              \"AttrValue had value with type 'list(\" type_string \")' when '\", \\\n              type, \"' expected\");                                            \\\n        }                                                                     \\\n        ++num_set;                                                            \\\n      }                                                                       \\\n    } else if (attr_value.value_case() == AttrValue::oneof_case) {            \\\n      if (type != type_string) {                                              \\\n        return errors::InvalidArgument(                                       \\\n            \"AttrValue had value with type '\" type_string \"' when '\", type,   \\\n            \"' expected\");                                                    \\\n      }                                                                       \\\n      ++num_set;                                                              \\\n    }                                                                         \\\n  } while (false)\n\n  VALIDATE_FIELD(s, \"string\", kS);\n  VALIDATE_FIELD(i, \"int\", kI);\n  VALIDATE_FIELD(f, \"float\", kF);\n  VALIDATE_FIELD(b, \"bool\", kB);\n  VALIDATE_FIELD(type, \"type\", kType);\n  VALIDATE_FIELD(shape, \"shape\", kShape);\n  VALIDATE_FIELD(tensor, \"tensor\", kTensor);\n  VALIDATE_FIELD(func, \"func\", kFunc);\n\n#undef VALIDATE_FIELD\n\n  if (attr_value.value_case() == AttrValue::kPlaceholder) {\n    return errors::InvalidArgument(\n        \"AttrValue had value with unexpected type 'placeholder'\");\n  }\n\n  // If the attr type is 'list', we expect attr_value.has_list() to be\n  // true.  However, proto3's attr_value.has_list() can be false when\n  // set to an empty list for GraphDef versions <= 4. So we simply\n  // check if has_list is false and some other field in attr_value is\n  // set to flag the error.  This test can be made more strict once\n  // support for GraphDef versions <= 4 is dropped.\n  if (absl::StartsWith(type, \"list(\") && !attr_value.has_list()) {\n    if (num_set) {\n      return errors::InvalidArgument(\n          \"AttrValue missing value with expected type '\", type, \"'\");\n    } else {\n      // Indicate that we have a list, but an empty one.\n      ++num_set;\n    }\n  }\n\n  // Okay to have an empty list, but not to be missing a non-list value.\n  if (num_set == 0 && !absl::StartsWith(type, \"list(\")) {\n    return errors::InvalidArgument(\n        \"AttrValue missing value with expected type '\", type, \"'\");\n  }\n\n  // Ref types and DT_INVALID are illegal, and DataTypes must\n  // be a valid enum type.\n  if (type == \"type\") {\n    if (!DataType_IsValid(attr_value.type())) {\n      return errors::InvalidArgument(\"AttrValue has invalid DataType enum: \",\n                                     attr_value.type());\n    }\n    if (IsRefType(attr_value.type())) {\n      return errors::InvalidArgument(\n          \"AttrValue must not have reference type value of \",\n          DataTypeString(attr_value.type()));\n    }\n    if (attr_value.type() == DT_INVALID) {\n      return errors::InvalidArgument(\"AttrValue has invalid DataType\");\n    }\n  } else if (type == \"list(type)\") {\n    for (auto as_int : attr_value.list().type()) {\n      const DataType dtype = static_cast<DataType>(as_int);\n      if (!DataType_IsValid(dtype)) {\n        return errors::InvalidArgument(\"AttrValue has invalid DataType enum: \",\n                                       as_int);\n      }\n      if (IsRefType(dtype)) {\n        return errors::InvalidArgument(\n            \"AttrValue must not have reference type value of \",\n            DataTypeString(dtype));\n      }\n      if (dtype == DT_INVALID) {\n        return errors::InvalidArgument(\"AttrValue contains invalid DataType\");\n      }\n    }\n  }\n\n  return Status::OK();\n}\n\nbool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n\n  return ProtoParseFromString(to_parse, out);\n}\n\nvoid SetAttrValue(const AttrValue& value, AttrValue* out) { *out = value; }\n\n#define DEFINE_SET_ATTR_VALUE_ONE(ARG_TYPE, FIELD) \\\n  void SetAttrValue(ARG_TYPE value, AttrValue* out) { out->set_##FIELD(value); }\n\n#define DEFINE_SET_ATTR_VALUE_LIST(ARG_TYPE, FIELD)                       \\\n  void SetAttrValue(ARG_TYPE value, AttrValue* out) {                     \\\n    out->mutable_list()->Clear(); /* create list() even if value empty */ \\\n    for (const auto& v : value) {                                         \\\n      out->mutable_list()->add_##FIELD(v);                                \\\n    }                                                                     \\\n  }\n\n#define DEFINE_SET_ATTR_VALUE_BOTH(ARG_TYPE, FIELD) \\\n  DEFINE_SET_ATTR_VALUE_ONE(ARG_TYPE, FIELD)        \\\n  DEFINE_SET_ATTR_VALUE_LIST(gtl::ArraySlice<ARG_TYPE>, FIELD)\n\nDEFINE_SET_ATTR_VALUE_ONE(const string&, s)\nDEFINE_SET_ATTR_VALUE_LIST(gtl::ArraySlice<string>, s)\nDEFINE_SET_ATTR_VALUE_BOTH(const char*, s)\nDEFINE_SET_ATTR_VALUE_BOTH(int64, i)\nDEFINE_SET_ATTR_VALUE_BOTH(int32, i)\nDEFINE_SET_ATTR_VALUE_BOTH(float, f)\nDEFINE_SET_ATTR_VALUE_BOTH(double, f)\nDEFINE_SET_ATTR_VALUE_BOTH(bool, b)\nDEFINE_SET_ATTR_VALUE_LIST(const std::vector<bool>&, b)\nDEFINE_SET_ATTR_VALUE_LIST(std::initializer_list<bool>, b)\nDEFINE_SET_ATTR_VALUE_BOTH(DataType, type)\n\nvoid SetAttrValue(const tstring& value, AttrValue* out) {\n  out->set_s(value.data(), value.size());\n}\n\nvoid SetAttrValue(gtl::ArraySlice<tstring> value, AttrValue* out) {\n  out->mutable_list()->Clear();\n  for (const auto& v : value) {\n    out->mutable_list()->add_s(v.data(), v.size());\n  }\n}\n\nvoid SetAttrValue(StringPiece value, AttrValue* out) {\n  out->set_s(value.data(), value.size());\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<StringPiece> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    out->mutable_list()->add_s(v.data(), v.size());\n  }\n}\n\nvoid MoveAttrValue(std::vector<string>&& value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (auto& v : value) {\n    out->mutable_list()->add_s(std::move(v));\n  }\n}\n\nvoid SetAttrValue(const TensorShape& value, AttrValue* out) {\n  value.AsProto(out->mutable_shape());\n}\n\nvoid SetAttrValue(const TensorShapeProto& value, AttrValue* out) {\n  *out->mutable_shape() = value;\n}\n\nvoid SetAttrValue(const PartialTensorShape& value, AttrValue* out) {\n  value.AsProto(out->mutable_shape());\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<TensorShape> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    v.AsProto(out->mutable_list()->add_shape());\n  }\n}\n\nvoid SetAttrValue(gtl::ArraySlice<TensorShapeProto> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_shape() = v;\n  }\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<PartialTensorShape> value,\n                  AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    v.AsProto(out->mutable_list()->add_shape());\n  }\n}\n\nvoid SetAttrValue(const Tensor& value, AttrValue* out) {\n  if (value.NumElements() > 1) {\n    value.AsProtoTensorContent(out->mutable_tensor());\n  } else {\n    value.AsProtoField(out->mutable_tensor());\n  }\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<Tensor> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    if (v.NumElements() > 1) {\n      v.AsProtoTensorContent(out->mutable_list()->add_tensor());\n    } else {\n      v.AsProtoField(out->mutable_list()->add_tensor());\n    }\n  }\n}\n\nvoid SetAttrValue(const TensorProto& value, AttrValue* out) {\n  *out->mutable_tensor() = value;\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<TensorProto> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_tensor() = v;\n  }\n}\n\nvoid SetAttrValue(const NameAttrList& value, AttrValue* out) {\n  *out->mutable_func() = value;\n}\n\nvoid SetAttrValue(gtl::ArraySlice<NameAttrList> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_func() = v;\n  }\n}\n\nbool AreAttrValuesEqual(const AttrValue& a, const AttrValue& b) {\n  return AreAttrValuesEqual(a, b, AreTensorProtosEqual);\n}\n\nuint64 AttrValueHash(const AttrValue& a) {\n  return AttrValueHash(a, TensorProtoHash);\n}\n\nbool FastAreAttrValuesEqual(const AttrValue& a, const AttrValue& b) {\n  return AreAttrValuesEqual(a, b, FastAreTensorProtosEqual);\n}\n\nuint64 FastAttrValueHash(const AttrValue& a) {\n  return AttrValueHash(a, FastTensorProtoHash);\n}\n\nbool HasPlaceHolder(const AttrValue& val) {\n  switch (val.value_case()) {\n    case AttrValue::kList: {\n      for (const NameAttrList& func : val.list().func()) {\n        for (const auto& p : func.attr()) {\n          if (HasPlaceHolder(p.second)) {\n            return true;\n          }\n        }\n      }\n      break;\n    }\n    case AttrValue::kFunc:\n      for (const auto& p : val.func().attr()) {\n        if (HasPlaceHolder(p.second)) {\n          return true;\n        }\n      }\n      break;\n    case AttrValue::kPlaceholder:\n      return true;\n    default:\n      break;\n  }\n  return false;\n}\n\nbool SubstitutePlaceholders(const SubstituteFunc& substitute,\n                            AttrValue* value) {\n  switch (value->value_case()) {\n    case AttrValue::kList: {\n      for (NameAttrList& func : *value->mutable_list()->mutable_func()) {\n        for (auto& p : *func.mutable_attr()) {\n          if (!SubstitutePlaceholders(substitute, &p.second)) {\n            return false;\n          }\n        }\n      }\n      break;\n    }\n    case AttrValue::kFunc:\n      for (auto& p : *(value->mutable_func()->mutable_attr())) {\n        if (!SubstitutePlaceholders(substitute, &p.second)) {\n          return false;\n        }\n      }\n      break;\n    case AttrValue::kPlaceholder:\n      return substitute(value->placeholder(), value);\n    case AttrValue::VALUE_NOT_SET:\n      return false;\n    default:\n      break;\n  }\n  return true;\n}\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/attr_value_util.h\"\n\n#include <string>\n#include <unordered_map>\n#include <vector>\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/attr_value.pb_text.h\"\n#include \"tensorflow/core/framework/tensor.pb_text.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb_text.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/hash/hash.h\"\n#include \"tensorflow/core/lib/strings/proto_serialization.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n\nnamespace tensorflow {\nnamespace {\n\n// Do not construct large tensors to compute their hash or compare for equality.\nconstexpr int kMaxAttrValueTensorByteSize = 32 * 1024 * 1024;  // 32mb\n\n// Limit nesting of tensors to 100 deep to prevent memory overflow.\nconstexpr int kMaxTensorNestDepth = 100;\n\n// Return the size of the tensor represented by this TensorProto. If shape is\n// not fully defined return -1.\nint64 TensorByteSize(const TensorProto& t) {\n  // num_elements returns -1 if shape is not fully defined.\n  int64 num_elems = TensorShape(t.tensor_shape()).num_elements();\n  return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n}\n\n// Compute TensorProto hash by creating a Tensor, serializing it as tensor\n// content, and computing a hash of it's string representation. This is unsafe\n// operation, because large tensors can be represented as TensorProto, but can't\n// be serialized to tensor content.\nuint64 TensorProtoHash(const TensorProto& tp) {\n  Tensor tensor(tp.dtype());\n  bool success = tensor.FromProto(tp);\n  DCHECK(success);\n  TensorProto p;\n  tensor.AsProtoTensorContent(&p);\n  return DeterministicProtoHash64(p);\n}\n\n// Do not create large tensors in memory, compute hash based on TensorProto\n// string representation. Tensors with identical content potentially can have a\n// different hash code if they are defined with different TensorProto\n// representations.\nuint64 FastTensorProtoHash(const TensorProto& tp) {\n  if (TensorByteSize(tp) > kMaxAttrValueTensorByteSize) {\n    return DeterministicProtoHash64(tp);\n  } else {\n    return TensorProtoHash(tp);\n  }\n}\n\n// There are multiple equivalent representations of attr values containing\n// TensorProtos. Compare them by constructing Tensors and serializing them\n// back. Comparing Tensor objects is pretty tricky. This is unsafe operation,\n// because large tensors can be represented as TensorProto, but can't be\n// serialized to tensor content.\nbool AreTensorProtosEqual(const TensorProto& lhs, const TensorProto& rhs) {\n  Tensor lhs_t(lhs.dtype());\n  bool success = lhs_t.FromProto(lhs);\n  DCHECK(success);\n\n  Tensor rhs_t(rhs.dtype());\n  success = rhs_t.FromProto(rhs);\n  DCHECK(success);\n\n  TensorProto lhs_tp;\n  lhs_t.AsProtoTensorContent(&lhs_tp);\n\n  TensorProto rhs_tp;\n  rhs_t.AsProtoTensorContent(&rhs_tp);\n\n  return AreSerializedProtosEqual(lhs_tp, rhs_tp);\n}\n\n// Do not construct large tensors in memory, compare equality using TensorProto\n// string representation. Tensors with identical content potentially can have\n// different tensor proto representation.\nbool FastAreTensorProtosEqual(const TensorProto& lhs, const TensorProto& rhs) {\n  // A small TensorProto can expand into a giant Tensor.  So we avoid\n  // conversion to an actual Tensor if we can quickly rule out equality\n  // by comparing the Tensor size since different sized Tensors are definitely\n  // different.\n  const int64 lhs_tensor_bytes = TensorByteSize(lhs);\n  const int64 rhs_tensor_bytes = TensorByteSize(rhs);\n  if (lhs_tensor_bytes != rhs_tensor_bytes) {\n    return false;\n  }\n\n  // If the tensor is very large, we'll only compare the proto representation\n  // (even though this may miss some equivalent tensors whose actual tensor\n  // values are the same but which are described by different TensorProtos).\n  if (lhs_tensor_bytes > kMaxAttrValueTensorByteSize) {\n    return AreSerializedProtosEqual(lhs, rhs);\n  }\n\n  // If the TensorProto representation expands into a much bigger Tensor,\n  // we have a fast-path that first compares the protos.\n  const int64 lhs_proto_bytes = lhs.ByteSizeLong();\n  const bool large_expansion =\n      (lhs_proto_bytes < 512 && lhs_tensor_bytes > 4096);\n  if (large_expansion && AreSerializedProtosEqual(lhs, rhs)) {\n    return true;\n  }\n\n  // Fall back to the general code in AreTensorProtosEqual.\n  return AreTensorProtosEqual(lhs, rhs);\n}\n\nusing TensorProtoHasher = std::function<uint64(const TensorProto&)>;\n\nuint64 AttrValueHash(const AttrValue& a, const TensorProtoHasher& tensor_hash) {\n  if (a.has_tensor()) return tensor_hash(a.tensor());\n\n  if (a.has_func()) {\n    const NameAttrList& func = a.func();\n    uint64 h = Hash64(func.name());\n    std::map<string, AttrValue> map(func.attr().begin(), func.attr().end());\n    for (const auto& pair : map) {\n      h = Hash64(pair.first.data(), pair.first.size(), h);\n      h = Hash64Combine(AttrValueHash(pair.second, tensor_hash), h);\n    }\n    return h;\n  }\n\n  // If `a` is not a tensor or func, get a hash of serialized string.\n  return DeterministicProtoHash64(a);\n}\n\ntemplate <typename TensorProtosEquality>\nbool AreAttrValuesEqual(const AttrValue& a, const AttrValue& b,\n                        TensorProtosEquality tensor_equality) {\n  if (a.type() != b.type()) {\n    return false;\n  } else if (a.type() != DT_INVALID && b.type() != DT_INVALID) {\n    return a.type() == b.type();\n  }\n\n  if (a.has_tensor() != b.has_tensor()) {\n    return false;\n  } else if (a.has_tensor() && b.has_tensor()) {\n    return tensor_equality(a.tensor(), b.tensor());\n  }\n\n  // `func` field contains a nested AttrValue. Compare such AttrValues\n  // recursively.\n  if (a.has_func() != b.has_func()) {\n    return false;\n  } else if (a.has_func() && b.has_func()) {\n    const NameAttrList& af = a.func();\n    const NameAttrList& bf = b.func();\n    if (af.name() != bf.name()) return false;\n    std::unordered_map<string, AttrValue> am(af.attr().begin(),\n                                             af.attr().end());\n    for (const auto& bm_pair : bf.attr()) {\n      const auto& iter = am.find(bm_pair.first);\n      if (iter == am.end()) return false;\n      if (!AreAttrValuesEqual(iter->second, bm_pair.second, tensor_equality))\n        return false;\n      am.erase(iter);\n    }\n    if (!am.empty()) return false;\n    return true;\n  }\n\n  // All other fields in AttrValue have deterministic representations.\n  // It is safe to compare their serialized strings.\n  return AreSerializedProtosEqual(a, b);\n}\n\nstring SummarizeString(const string& str) {\n  string escaped = absl::CEscape(str);\n\n  // If the string is long, replace the middle with ellipses.\n  constexpr int kMaxStringSummarySize = 80;\n  if (escaped.size() >= kMaxStringSummarySize) {\n    StringPiece prefix(escaped);\n    StringPiece suffix = prefix;\n    prefix.remove_suffix(escaped.size() - 10);\n    suffix.remove_prefix(escaped.size() - 10);\n    return strings::StrCat(\"\\\"\", prefix, \"...\", suffix, \"\\\"\");\n  } else {\n    return strings::StrCat(\"\\\"\", escaped, \"\\\"\");\n  }\n}\n\nstring SummarizeTensor(const TensorProto& tensor_proto) {\n  Tensor t;\n  if (!t.FromProto(tensor_proto)) {\n    return strings::StrCat(\n        \"<Invalid TensorProto: \", tensor_proto.ShortDebugString(), \">\");\n  }\n  return t.DebugString();\n}\n\nstring SummarizeFunc(const NameAttrList& func) {\n  std::vector<string> entries;\n  for (const auto& p : func.attr()) {\n    entries.push_back(\n        strings::StrCat(p.first, \"=\", SummarizeAttrValue(p.second)));\n  }\n  std::sort(entries.begin(), entries.end());\n  return strings::StrCat(func.name(), \"[\", absl::StrJoin(entries, \", \"), \"]\");\n}\n\nbool ParseAttrValueHelper_TensorNestsUnderLimit(int limit, string to_parse) {\n  int nests = 0;\n  int maxed_out = to_parse.length();\n  int open_curly = to_parse.find('{');\n  int open_bracket = to_parse.find('<');\n  int close_curly = to_parse.find('}');\n  int close_bracket = to_parse.find('>');\n  if (open_curly == -1) {\n    open_curly = maxed_out;\n  }\n  if (open_bracket == -1) {\n    open_bracket = maxed_out;\n  }\n  int min = std::min(open_curly, open_bracket);\n  do {\n    if (open_curly == maxed_out && open_bracket == maxed_out) {\n      return true;\n    }\n    if (min == open_curly) {\n      nests += 1;\n      open_curly = to_parse.find('{', open_curly + 1);\n      if (open_curly == -1) {\n        open_curly = maxed_out;\n      }\n    } else if (min == open_bracket) {\n      nests += 1;\n      open_bracket = to_parse.find('<', open_bracket + 1);\n      if (open_bracket == -1) {\n        open_bracket = maxed_out;\n      }\n    } else if (min == close_curly) {\n      nests -= 1;\n      close_curly = to_parse.find('}', close_curly + 1);\n      if (close_curly == -1) {\n        close_curly = maxed_out;\n      }\n    } else if (min == close_bracket) {\n      nests -= 1;\n      close_bracket = to_parse.find('>', close_bracket + 1);\n      if (close_bracket == -1) {\n        close_bracket = maxed_out;\n      }\n    }\n    min = std::min({open_curly, open_bracket, close_curly, close_bracket});\n  } while (nests < 100);\n  return false;\n}\n\n}  // namespace\n\nstring SummarizeAttrValue(const AttrValue& attr_value) {\n  switch (attr_value.value_case()) {\n    case AttrValue::kS:\n      return SummarizeString(attr_value.s());\n    case AttrValue::kI:\n      return strings::StrCat(attr_value.i());\n    case AttrValue::kF:\n      return strings::StrCat(attr_value.f());\n    case AttrValue::kB:\n      return attr_value.b() ? \"true\" : \"false\";\n    case AttrValue::kType:\n      return EnumName_DataType(attr_value.type());\n    case AttrValue::kShape:\n      return PartialTensorShape::DebugString(attr_value.shape());\n    case AttrValue::kTensor:\n      return SummarizeTensor(attr_value.tensor());\n    case AttrValue::kList: {\n      std::vector<string> pieces;\n      if (attr_value.list().s_size() > 0) {\n        for (int i = 0; i < attr_value.list().s_size(); ++i) {\n          pieces.push_back(SummarizeString(attr_value.list().s(i)));\n        }\n      } else if (attr_value.list().i_size() > 0) {\n        for (int i = 0; i < attr_value.list().i_size(); ++i) {\n          pieces.push_back(strings::StrCat(attr_value.list().i(i)));\n        }\n      } else if (attr_value.list().f_size() > 0) {\n        for (int i = 0; i < attr_value.list().f_size(); ++i) {\n          pieces.push_back(strings::StrCat(attr_value.list().f(i)));\n        }\n      } else if (attr_value.list().b_size() > 0) {\n        for (int i = 0; i < attr_value.list().b_size(); ++i) {\n          pieces.push_back(attr_value.list().b(i) ? \"true\" : \"false\");\n        }\n      } else if (attr_value.list().type_size() > 0) {\n        for (int i = 0; i < attr_value.list().type_size(); ++i) {\n          pieces.push_back(EnumName_DataType(attr_value.list().type(i)));\n        }\n      } else if (attr_value.list().shape_size() > 0) {\n        for (int i = 0; i < attr_value.list().shape_size(); ++i) {\n          pieces.push_back(\n              TensorShape::DebugString(attr_value.list().shape(i)));\n        }\n      } else if (attr_value.list().tensor_size() > 0) {\n        for (int i = 0; i < attr_value.list().tensor_size(); ++i) {\n          pieces.push_back(SummarizeTensor(attr_value.list().tensor(i)));\n        }\n      } else if (attr_value.list().func_size() > 0) {\n        for (int i = 0; i < attr_value.list().func_size(); ++i) {\n          pieces.push_back(SummarizeFunc(attr_value.list().func(i)));\n        }\n      }\n      constexpr int kMaxListSummarySize = 50;\n      if (pieces.size() >= kMaxListSummarySize) {\n        pieces.erase(pieces.begin() + 5, pieces.begin() + (pieces.size() - 6));\n        pieces[5] = \"...\";\n      }\n      return strings::StrCat(\"[\", absl::StrJoin(pieces, \", \"), \"]\");\n    }\n    case AttrValue::kFunc: {\n      return SummarizeFunc(attr_value.func());\n    }\n    case AttrValue::kPlaceholder:\n      return strings::StrCat(\"$\", attr_value.placeholder());\n    case AttrValue::VALUE_NOT_SET:\n      return \"<Unknown AttrValue type>\";\n  }\n  return \"<Unknown AttrValue type>\";  // Prevent missing return warning\n}\n\nStatus AttrValueHasType(const AttrValue& attr_value, StringPiece type) {\n  int num_set = 0;\n\n#define VALIDATE_FIELD(name, type_string, oneof_case)                         \\\n  do {                                                                        \\\n    if (attr_value.has_list()) {                                              \\\n      if (attr_value.list().name##_size() > 0) {                              \\\n        if (type != \"list(\" type_string \")\") {                                \\\n          return errors::InvalidArgument(                                     \\\n              \"AttrValue had value with type 'list(\" type_string \")' when '\", \\\n              type, \"' expected\");                                            \\\n        }                                                                     \\\n        ++num_set;                                                            \\\n      }                                                                       \\\n    } else if (attr_value.value_case() == AttrValue::oneof_case) {            \\\n      if (type != type_string) {                                              \\\n        return errors::InvalidArgument(                                       \\\n            \"AttrValue had value with type '\" type_string \"' when '\", type,   \\\n            \"' expected\");                                                    \\\n      }                                                                       \\\n      ++num_set;                                                              \\\n    }                                                                         \\\n  } while (false)\n\n  VALIDATE_FIELD(s, \"string\", kS);\n  VALIDATE_FIELD(i, \"int\", kI);\n  VALIDATE_FIELD(f, \"float\", kF);\n  VALIDATE_FIELD(b, \"bool\", kB);\n  VALIDATE_FIELD(type, \"type\", kType);\n  VALIDATE_FIELD(shape, \"shape\", kShape);\n  VALIDATE_FIELD(tensor, \"tensor\", kTensor);\n  VALIDATE_FIELD(func, \"func\", kFunc);\n\n#undef VALIDATE_FIELD\n\n  if (attr_value.value_case() == AttrValue::kPlaceholder) {\n    return errors::InvalidArgument(\n        \"AttrValue had value with unexpected type 'placeholder'\");\n  }\n\n  // If the attr type is 'list', we expect attr_value.has_list() to be\n  // true.  However, proto3's attr_value.has_list() can be false when\n  // set to an empty list for GraphDef versions <= 4. So we simply\n  // check if has_list is false and some other field in attr_value is\n  // set to flag the error.  This test can be made more strict once\n  // support for GraphDef versions <= 4 is dropped.\n  if (absl::StartsWith(type, \"list(\") && !attr_value.has_list()) {\n    if (num_set) {\n      return errors::InvalidArgument(\n          \"AttrValue missing value with expected type '\", type, \"'\");\n    } else {\n      // Indicate that we have a list, but an empty one.\n      ++num_set;\n    }\n  }\n\n  // Okay to have an empty list, but not to be missing a non-list value.\n  if (num_set == 0 && !absl::StartsWith(type, \"list(\")) {\n    return errors::InvalidArgument(\n        \"AttrValue missing value with expected type '\", type, \"'\");\n  }\n\n  // Ref types and DT_INVALID are illegal, and DataTypes must\n  // be a valid enum type.\n  if (type == \"type\") {\n    if (!DataType_IsValid(attr_value.type())) {\n      return errors::InvalidArgument(\"AttrValue has invalid DataType enum: \",\n                                     attr_value.type());\n    }\n    if (IsRefType(attr_value.type())) {\n      return errors::InvalidArgument(\n          \"AttrValue must not have reference type value of \",\n          DataTypeString(attr_value.type()));\n    }\n    if (attr_value.type() == DT_INVALID) {\n      return errors::InvalidArgument(\"AttrValue has invalid DataType\");\n    }\n  } else if (type == \"list(type)\") {\n    for (auto as_int : attr_value.list().type()) {\n      const DataType dtype = static_cast<DataType>(as_int);\n      if (!DataType_IsValid(dtype)) {\n        return errors::InvalidArgument(\"AttrValue has invalid DataType enum: \",\n                                       as_int);\n      }\n      if (IsRefType(dtype)) {\n        return errors::InvalidArgument(\n            \"AttrValue must not have reference type value of \",\n            DataTypeString(dtype));\n      }\n      if (dtype == DT_INVALID) {\n        return errors::InvalidArgument(\"AttrValue contains invalid DataType\");\n      }\n    }\n  }\n\n  return Status::OK();\n}\n\nbool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n  if (field_name == \"tensor\") {\n    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\n                                                    to_parse)) {\n      return false;\n    }\n  }\n  return ProtoParseFromString(to_parse, out);\n}\n\nvoid SetAttrValue(const AttrValue& value, AttrValue* out) { *out = value; }\n\n#define DEFINE_SET_ATTR_VALUE_ONE(ARG_TYPE, FIELD) \\\n  void SetAttrValue(ARG_TYPE value, AttrValue* out) { out->set_##FIELD(value); }\n\n#define DEFINE_SET_ATTR_VALUE_LIST(ARG_TYPE, FIELD)                       \\\n  void SetAttrValue(ARG_TYPE value, AttrValue* out) {                     \\\n    out->mutable_list()->Clear(); /* create list() even if value empty */ \\\n    for (const auto& v : value) {                                         \\\n      out->mutable_list()->add_##FIELD(v);                                \\\n    }                                                                     \\\n  }\n\n#define DEFINE_SET_ATTR_VALUE_BOTH(ARG_TYPE, FIELD) \\\n  DEFINE_SET_ATTR_VALUE_ONE(ARG_TYPE, FIELD)        \\\n  DEFINE_SET_ATTR_VALUE_LIST(gtl::ArraySlice<ARG_TYPE>, FIELD)\n\nDEFINE_SET_ATTR_VALUE_ONE(const string&, s)\nDEFINE_SET_ATTR_VALUE_LIST(gtl::ArraySlice<string>, s)\nDEFINE_SET_ATTR_VALUE_BOTH(const char*, s)\nDEFINE_SET_ATTR_VALUE_BOTH(int64, i)\nDEFINE_SET_ATTR_VALUE_BOTH(int32, i)\nDEFINE_SET_ATTR_VALUE_BOTH(float, f)\nDEFINE_SET_ATTR_VALUE_BOTH(double, f)\nDEFINE_SET_ATTR_VALUE_BOTH(bool, b)\nDEFINE_SET_ATTR_VALUE_LIST(const std::vector<bool>&, b)\nDEFINE_SET_ATTR_VALUE_LIST(std::initializer_list<bool>, b)\nDEFINE_SET_ATTR_VALUE_BOTH(DataType, type)\n\nvoid SetAttrValue(const tstring& value, AttrValue* out) {\n  out->set_s(value.data(), value.size());\n}\n\nvoid SetAttrValue(gtl::ArraySlice<tstring> value, AttrValue* out) {\n  out->mutable_list()->Clear();\n  for (const auto& v : value) {\n    out->mutable_list()->add_s(v.data(), v.size());\n  }\n}\n\nvoid SetAttrValue(StringPiece value, AttrValue* out) {\n  out->set_s(value.data(), value.size());\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<StringPiece> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    out->mutable_list()->add_s(v.data(), v.size());\n  }\n}\n\nvoid MoveAttrValue(std::vector<string>&& value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (auto& v : value) {\n    out->mutable_list()->add_s(std::move(v));\n  }\n}\n\nvoid SetAttrValue(const TensorShape& value, AttrValue* out) {\n  value.AsProto(out->mutable_shape());\n}\n\nvoid SetAttrValue(const TensorShapeProto& value, AttrValue* out) {\n  *out->mutable_shape() = value;\n}\n\nvoid SetAttrValue(const PartialTensorShape& value, AttrValue* out) {\n  value.AsProto(out->mutable_shape());\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<TensorShape> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    v.AsProto(out->mutable_list()->add_shape());\n  }\n}\n\nvoid SetAttrValue(gtl::ArraySlice<TensorShapeProto> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_shape() = v;\n  }\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<PartialTensorShape> value,\n                  AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    v.AsProto(out->mutable_list()->add_shape());\n  }\n}\n\nvoid SetAttrValue(const Tensor& value, AttrValue* out) {\n  if (value.NumElements() > 1) {\n    value.AsProtoTensorContent(out->mutable_tensor());\n  } else {\n    value.AsProtoField(out->mutable_tensor());\n  }\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<Tensor> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    if (v.NumElements() > 1) {\n      v.AsProtoTensorContent(out->mutable_list()->add_tensor());\n    } else {\n      v.AsProtoField(out->mutable_list()->add_tensor());\n    }\n  }\n}\n\nvoid SetAttrValue(const TensorProto& value, AttrValue* out) {\n  *out->mutable_tensor() = value;\n}\n\nvoid SetAttrValue(const gtl::ArraySlice<TensorProto> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_tensor() = v;\n  }\n}\n\nvoid SetAttrValue(const NameAttrList& value, AttrValue* out) {\n  *out->mutable_func() = value;\n}\n\nvoid SetAttrValue(gtl::ArraySlice<NameAttrList> value, AttrValue* out) {\n  out->mutable_list()->Clear();  // Create list() even if value empty.\n  for (const auto& v : value) {\n    *out->mutable_list()->add_func() = v;\n  }\n}\n\nbool AreAttrValuesEqual(const AttrValue& a, const AttrValue& b) {\n  return AreAttrValuesEqual(a, b, AreTensorProtosEqual);\n}\n\nuint64 AttrValueHash(const AttrValue& a) {\n  return AttrValueHash(a, TensorProtoHash);\n}\n\nbool FastAreAttrValuesEqual(const AttrValue& a, const AttrValue& b) {\n  return AreAttrValuesEqual(a, b, FastAreTensorProtosEqual);\n}\n\nuint64 FastAttrValueHash(const AttrValue& a) {\n  return AttrValueHash(a, FastTensorProtoHash);\n}\n\nbool HasPlaceHolder(const AttrValue& val) {\n  switch (val.value_case()) {\n    case AttrValue::kList: {\n      for (const NameAttrList& func : val.list().func()) {\n        for (const auto& p : func.attr()) {\n          if (HasPlaceHolder(p.second)) {\n            return true;\n          }\n        }\n      }\n      break;\n    }\n    case AttrValue::kFunc:\n      for (const auto& p : val.func().attr()) {\n        if (HasPlaceHolder(p.second)) {\n          return true;\n        }\n      }\n      break;\n    case AttrValue::kPlaceholder:\n      return true;\n    default:\n      break;\n  }\n  return false;\n}\n\nbool SubstitutePlaceholders(const SubstituteFunc& substitute,\n                            AttrValue* value) {\n  switch (value->value_case()) {\n    case AttrValue::kList: {\n      for (NameAttrList& func : *value->mutable_list()->mutable_func()) {\n        for (auto& p : *func.mutable_attr()) {\n          if (!SubstitutePlaceholders(substitute, &p.second)) {\n            return false;\n          }\n        }\n      }\n      break;\n    }\n    case AttrValue::kFunc:\n      for (auto& p : *(value->mutable_func()->mutable_attr())) {\n        if (!SubstitutePlaceholders(substitute, &p.second)) {\n          return false;\n        }\n      }\n      break;\n    case AttrValue::kPlaceholder:\n      return substitute(value->placeholder(), value);\n    case AttrValue::VALUE_NOT_SET:\n      return false;\n    default:\n      break;\n  }\n  return true;\n}\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/framework/attr_value_util.cc"], "buggy_code_start_loc": [39], "buggy_code_end_loc": [452], "fixing_code_start_loc": [40], "fixing_code_end_loc": [508], "type": "CWE-674", "message": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of `ParseAttrValue`(https://github.com/tensorflow/tensorflow/blob/c22d88d6ff33031aa113e48aa3fc9aa74ed79595/tensorflow/core/framework/attr_value_util.cc#L397-L453) can be tricked into stack overflow due to recursion by giving in a specially crafted input. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29615", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:16.127", "lastModified": "2021-05-18T18:22:57.967", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of `ParseAttrValue`(https://github.com/tensorflow/tensorflow/blob/c22d88d6ff33031aa113e48aa3fc9aa74ed79595/tensorflow/core/framework/attr_value_util.cc#L397-L453) can be tricked into stack overflow due to recursion by giving in a specially crafted input. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;La implementaci\u00f3n de \"ParseAttrValue\" (https://github.com/tensorflow/tensorflow/blob/c22d88d6ff33031aa113e48aa3fc9aa74ed79595/tensorflow/core/framework/attr_value_util.cc#L397-L453) puede ser enga\u00f1ado en el desbordamiento de la pila debido a una recursividad mediante la entrega de una entrada especialmente dise\u00f1ada.&#xa0;La correcci\u00f3n ser\u00e1 inclu\u00edda en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-674"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/e07e1c3d26492c06f078c7e5bf2d138043e199c1", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-qw5h-7f53-xrp6", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/e07e1c3d26492c06f078c7e5bf2d138043e199c1"}}