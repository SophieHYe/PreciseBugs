{"buggy_code": ["/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n#define TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n\n#include \"tensorflow/lite/kernels/internal/common.h\"\n#include \"tensorflow/lite/kernels/internal/types.h\"\n\nnamespace tflite {\nnamespace reference_ops {\n\ninline void Conv3DTranspose(\n    const Conv3DTransposeParams& params, const RuntimeShape& input_shape,\n    const float* input_data, const RuntimeShape& filter_shape,\n    const float* filter_data, const RuntimeShape& bias_shape,\n    const float* bias_data, const RuntimeShape& output_shape,\n    float* output_data) {\n  const int stride_width = params.stride_width;\n  const int stride_height = params.stride_height;\n  const int stride_depth = params.stride_depth;\n  const int pad_width = params.padding_values.width;\n  const int pad_height = params.padding_values.height;\n  const int pad_depth = params.padding_values.depth;\n  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 5);\n  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 5);\n  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 5);\n\n  const int batches = MatchingDim(input_shape, 0, output_shape, 0);\n  const int input_num_channels = MatchingDim(input_shape, 4, filter_shape, 4);\n  const int output_num_channels = output_shape.Dims(4);\n  const int input_depth = input_shape.Dims(1);\n  const int input_height = input_shape.Dims(2);\n  const int input_width = input_shape.Dims(3);\n  const int filter_depth = filter_shape.Dims(0);\n  const int filter_height = filter_shape.Dims(1);\n  const int filter_width = filter_shape.Dims(2);\n  const int output_depth = output_shape.Dims(1);\n  const int output_height = output_shape.Dims(2);\n  const int output_width = output_shape.Dims(3);\n  if (bias_data) {\n    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_num_channels);\n  }\n\n  // Initializes the output array to zero.\n  const int num_elements = output_shape.FlatSize();\n  for (int i = 0; i < num_elements; i++) {\n    output_data[i] = 0.0f;\n  }\n\n  // Loop through input elements one at a time.\n  for (int batch = 0; batch < batches; ++batch) {\n    for (int in_d = 0; in_d < input_depth; ++in_d) {\n      for (int in_y = 0; in_y < input_height; ++in_y) {\n        for (int in_x = 0; in_x < input_width; ++in_x) {\n          for (int in_channel = 0; in_channel < input_num_channels;\n               ++in_channel) {\n            // Loop through the output elements it will influence.\n            const int out_x_origin = (in_x * stride_width) - pad_width;\n            const int out_y_origin = (in_y * stride_height) - pad_height;\n            const int out_d_origin = (in_d * stride_depth) - pad_depth;\n            for (int filter_d = 0; filter_d < filter_depth; ++filter_d) {\n              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n                for (int filter_x = 0; filter_x < filter_width; ++filter_x) {\n                  for (int out_channel = 0; out_channel < output_num_channels;\n                       ++out_channel) {\n                    // Compute output element location.\n                    const int out_x =\n                        out_x_origin + params.dilation_width * filter_x;\n                    const int out_y =\n                        out_y_origin + params.dilation_height * filter_y;\n                    const int out_d =\n                        out_d_origin + params.dilation_depth * filter_d;\n                    // We cannot accumulate out of bounds.\n                    if ((out_x >= 0) && (out_x < output_width) &&\n                        (out_y >= 0) && (out_y < output_height) &&\n                        (out_d >= 0) && (out_d < output_depth)) {\n                      float input_value = input_data[Offset(\n                          input_shape, batch, in_d, in_y, in_x, in_channel)];\n                      float filter_value = filter_data[Offset(\n                          filter_shape, filter_d, filter_y, filter_x,\n                          out_channel, in_channel)];\n                      output_data[Offset(output_shape, batch, out_d, out_y,\n                                         out_x, out_channel)] +=\n                          input_value * filter_value;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  const float float_activation_min = params.float_activation_min;\n  const float float_activation_max = params.float_activation_max;\n  float* data_ptr = output_data;\n  if (bias_data) {\n    const int outer_size =\n        batches * output_depth * output_height * output_width;\n    const int num_channels = input_shape.Dims(4);\n    for (int n = 0; n < outer_size; ++n) {\n      for (int c = 0; c < output_num_channels; ++c) {\n        data_ptr[c] = ActivationFunctionWithMinMax(data_ptr[c] + bias_data[c],\n                                                   float_activation_min,\n                                                   float_activation_max);\n      }\n      data_ptr += num_channels;\n    }\n  } else {\n    const int flat_size = output_shape.FlatSize();\n    for (int i = 0; i < flat_size; ++i) {\n      data_ptr[i] = ActivationFunctionWithMinMax(\n          data_ptr[i], float_activation_min, float_activation_max);\n    }\n  }\n}\n\n}  // namespace reference_ops\n}  // namespace tflite\n\n#endif  // TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n"], "fixing_code": ["/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#ifndef TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n#define TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n\n#include \"tensorflow/lite/kernels/internal/common.h\"\n#include \"tensorflow/lite/kernels/internal/types.h\"\n\nnamespace tflite {\nnamespace reference_ops {\n\ninline void Conv3DTranspose(\n    const Conv3DTransposeParams& params, const RuntimeShape& input_shape,\n    const float* input_data, const RuntimeShape& filter_shape,\n    const float* filter_data, const RuntimeShape& bias_shape,\n    const float* bias_data, const RuntimeShape& output_shape,\n    float* output_data) {\n  const int stride_width = params.stride_width;\n  const int stride_height = params.stride_height;\n  const int stride_depth = params.stride_depth;\n  const int pad_width = params.padding_values.width;\n  const int pad_height = params.padding_values.height;\n  const int pad_depth = params.padding_values.depth;\n  TFLITE_DCHECK_EQ(input_shape.DimensionsCount(), 5);\n  TFLITE_DCHECK_EQ(filter_shape.DimensionsCount(), 5);\n  TFLITE_DCHECK_EQ(output_shape.DimensionsCount(), 5);\n\n  const int batches = MatchingDim(input_shape, 0, output_shape, 0);\n  const int input_num_channels = MatchingDim(input_shape, 4, filter_shape, 4);\n  const int output_num_channels = output_shape.Dims(4);\n  const int input_depth = input_shape.Dims(1);\n  const int input_height = input_shape.Dims(2);\n  const int input_width = input_shape.Dims(3);\n  const int filter_depth = filter_shape.Dims(0);\n  const int filter_height = filter_shape.Dims(1);\n  const int filter_width = filter_shape.Dims(2);\n  const int output_depth = output_shape.Dims(1);\n  const int output_height = output_shape.Dims(2);\n  const int output_width = output_shape.Dims(3);\n  if (bias_data) {\n    TFLITE_DCHECK_EQ(bias_shape.FlatSize(), output_num_channels);\n  }\n\n  // Initializes the output array to zero.\n  const int num_elements = output_shape.FlatSize();\n  for (int i = 0; i < num_elements; i++) {\n    output_data[i] = 0.0f;\n  }\n\n  // Loop through input elements one at a time.\n  for (int batch = 0; batch < batches; ++batch) {\n    for (int in_d = 0; in_d < input_depth; ++in_d) {\n      for (int in_y = 0; in_y < input_height; ++in_y) {\n        for (int in_x = 0; in_x < input_width; ++in_x) {\n          for (int in_channel = 0; in_channel < input_num_channels;\n               ++in_channel) {\n            // Loop through the output elements it will influence.\n            const int out_x_origin = (in_x * stride_width) - pad_width;\n            const int out_y_origin = (in_y * stride_height) - pad_height;\n            const int out_d_origin = (in_d * stride_depth) - pad_depth;\n            for (int filter_d = 0; filter_d < filter_depth; ++filter_d) {\n              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n                for (int filter_x = 0; filter_x < filter_width; ++filter_x) {\n                  for (int out_channel = 0; out_channel < output_num_channels;\n                       ++out_channel) {\n                    // Compute output element location.\n                    const int out_x =\n                        out_x_origin + params.dilation_width * filter_x;\n                    const int out_y =\n                        out_y_origin + params.dilation_height * filter_y;\n                    const int out_d =\n                        out_d_origin + params.dilation_depth * filter_d;\n                    // We cannot accumulate out of bounds.\n                    if ((out_x >= 0) && (out_x < output_width) &&\n                        (out_y >= 0) && (out_y < output_height) &&\n                        (out_d >= 0) && (out_d < output_depth)) {\n                      float input_value = input_data[Offset(\n                          input_shape, batch, in_d, in_y, in_x, in_channel)];\n                      float filter_value = filter_data[Offset(\n                          filter_shape, filter_d, filter_y, filter_x,\n                          out_channel, in_channel)];\n                      output_data[Offset(output_shape, batch, out_d, out_y,\n                                         out_x, out_channel)] +=\n                          input_value * filter_value;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  const float float_activation_min = params.float_activation_min;\n  const float float_activation_max = params.float_activation_max;\n  float* data_ptr = output_data;\n  if (bias_data) {\n    const int outer_size =\n        batches * output_depth * output_height * output_width;\n    for (int n = 0; n < outer_size; ++n) {\n      for (int c = 0; c < output_num_channels; ++c) {\n        data_ptr[c] = ActivationFunctionWithMinMax(data_ptr[c] + bias_data[c],\n                                                   float_activation_min,\n                                                   float_activation_max);\n      }\n      data_ptr += output_num_channels;\n    }\n  } else {\n    const int flat_size = output_shape.FlatSize();\n    for (int i = 0; i < flat_size; ++i) {\n      data_ptr[i] = ActivationFunctionWithMinMax(\n          data_ptr[i], float_activation_min, float_activation_max);\n    }\n  }\n}\n\n}  // namespace reference_ops\n}  // namespace tflite\n\n#endif  // TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_CONV3D_TRANSPOSE_H_\n"], "filenames": ["tensorflow/lite/kernels/internal/reference/conv3d_transpose.h"], "buggy_code_start_loc": [114], "buggy_code_end_loc": [122], "fixing_code_start_loc": [113], "fixing_code_end_loc": [121], "type": "CWE-120", "message": "TensorFlow is an open source platform for machine learning. The reference kernel of the `CONV_3D_TRANSPOSE` TensorFlow Lite operator wrongly increments the data_ptr when adding the bias to the result. Instead of `data_ptr += num_channels;` it should be `data_ptr += output_num_channels;` as if the number of input channels is different than the number of output channels, the wrong result will be returned and a buffer overflow will occur if num_channels > output_num_channels. An attacker can craft a model with a specific number of input channels. It is then possible to write specific values through the bias of the layer outside the bounds of the buffer. This attack only works if the reference kernel resolver is used in the interpreter. We have patched the issue in GitHub commit 72c0bdcb25305b0b36842d746cc61d72658d2941. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2022-41894", "sourceIdentifier": "security-advisories@github.com", "published": "2022-11-18T22:15:17.523", "lastModified": "2022-11-22T21:02:17.037", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. The reference kernel of the `CONV_3D_TRANSPOSE` TensorFlow Lite operator wrongly increments the data_ptr when adding the bias to the result. Instead of `data_ptr += num_channels;` it should be `data_ptr += output_num_channels;` as if the number of input channels is different than the number of output channels, the wrong result will be returned and a buffer overflow will occur if num_channels > output_num_channels. An attacker can craft a model with a specific number of input channels. It is then possible to write specific values through the bias of the layer outside the bounds of the buffer. This attack only works if the reference kernel resolver is used in the interpreter. We have patched the issue in GitHub commit 72c0bdcb25305b0b36842d746cc61d72658d2941. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.2, "impactScore": 5.9}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-120"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.8.4", "matchCriteriaId": "A694EEE1-BFB9-4E6C-B275-02DC2731961C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.3", "matchCriteriaId": "9057B403-719C-4F10-BAB6-67F84786A89E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.10.0", "versionEndExcluding": "2.10.1", "matchCriteriaId": "793BC396-7686-47FA-A107-DA6FC90704A2"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/blob/091e63f0ea33def7ecad661a5ac01dcafbafa90b/tensorflow/lite/kernels/internal/reference/conv3d_transpose.h#L121", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/72c0bdcb25305b0b36842d746cc61d72658d2941", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-h6q3-vv32-2cq5", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/72c0bdcb25305b0b36842d746cc61d72658d2941"}}