{"buggy_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/core/data/compression_utils.h\"\n\n#include \"tensorflow/core/common_runtime/dma_helper.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/platform/snappy.h\"\n\nnamespace tensorflow {\nnamespace data {\n\nStatus CompressElement(const std::vector<Tensor>& element,\n                       CompressedElement* out) {\n  // Step 1: Determine the total uncompressed size. This requires serializing\n  // non-memcopyable tensors, which we save to use again later.\n  std::vector<TensorProto> non_memcpy_components;\n  int64 total_size = 0;\n  for (auto& component : element) {\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      // Some datatypes can be memcopied, allowing us to save two copies\n      // (AsProtoTensorContent and SerializeToArray).\n      total_size += DMAHelper::buffer(&component)->size();\n    } else {\n      non_memcpy_components.emplace_back();\n      component.AsProtoTensorContent(&non_memcpy_components.back());\n      total_size += non_memcpy_components.back().ByteSizeLong();\n    }\n  }\n\n  // Step 2: Write the tensor data to a buffer, and compress that buffer.\n  // We use tstring for access to resize_uninitialized.\n  tstring uncompressed;\n  uncompressed.resize_uninitialized(total_size);\n  // Position in `uncompressed` to write the next component.\n  char* position = uncompressed.mdata();\n  int non_memcpy_component_index = 0;\n  for (auto& component : element) {\n    CompressedComponentMetadata* metadata =\n        out->mutable_component_metadata()->Add();\n    metadata->set_dtype(component.dtype());\n    component.shape().AsProto(metadata->mutable_tensor_shape());\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      memcpy(position, buffer->data(), buffer->size());\n      metadata->set_tensor_size_bytes(buffer->size());\n    } else {\n      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n      proto.SerializeToArray(position, proto.ByteSizeLong());\n      metadata->set_tensor_size_bytes(proto.ByteSizeLong());\n    }\n    position += metadata->tensor_size_bytes();\n  }\n  DCHECK_EQ(position, uncompressed.mdata() + total_size);\n\n  if (!port::Snappy_Compress(uncompressed.mdata(), total_size,\n                             out->mutable_data())) {\n    return errors::Internal(\"Failed to compress using snappy.\");\n  }\n  VLOG(3) << \"Compressed element from \" << total_size << \" bytes to \"\n          << out->data().size() << \" bytes\";\n  return Status::OK();\n}\n\nStatus UncompressElement(const CompressedElement& compressed,\n                         std::vector<Tensor>* out) {\n  int num_components = compressed.component_metadata_size();\n  out->clear();\n  out->reserve(num_components);\n\n  // Step 1: Prepare the memory that we will uncompress into.\n  std::vector<struct iovec> iov(num_components);\n  // We use tstring for access to resize_uninitialized.\n  std::vector<tstring> tensor_proto_strs;\n  // num_components is a conservative estimate. It is important to reserve\n  // vector space so that the vector doesn't resize itself, which could\n  // invalidate pointers to its strings' data.\n  tensor_proto_strs.reserve(num_components);\n  int64 total_size = 0;\n  for (int i = 0; i < num_components; ++i) {\n    const CompressedComponentMetadata& metadata =\n        compressed.component_metadata(i);\n    if (DataTypeCanUseMemcpy(metadata.dtype())) {\n      out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n      TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n      iov[i].iov_base = buffer->data();\n      iov[i].iov_len = buffer->size();\n    } else {\n      // Allocate an empty Tensor. We will fill it out later after\n      // uncompressing into the tensor_proto_str.\n      out->emplace_back();\n      tensor_proto_strs.emplace_back();\n      tstring& tensor_proto_str = tensor_proto_strs.back();\n      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());\n      iov[i].iov_base = tensor_proto_str.mdata();\n      iov[i].iov_len = tensor_proto_str.size();\n    }\n    total_size += iov[i].iov_len;\n  }\n\n  // Step 2: Uncompress into the iovec.\n  const std::string& compressed_data = compressed.data();\n  size_t uncompressed_size;\n  if (!port::Snappy_GetUncompressedLength(\n          compressed_data.data(), compressed_data.size(), &uncompressed_size)) {\n    return errors::Internal(\n        \"Could not get snappy uncompressed length. Compressed data size: \",\n        compressed_data.size());\n  }\n  if (uncompressed_size != static_cast<size_t>(total_size)) {\n    return errors::Internal(\n        \"Uncompressed size mismatch. Snappy expects \", uncompressed_size,\n        \" whereas the tensor metadata suggests \", total_size);\n  }\n  if (!port::Snappy_UncompressToIOVec(compressed_data.data(),\n                                      compressed_data.size(), iov.data(),\n                                      num_components)) {\n    return errors::Internal(\"Failed to perform snappy decompression.\");\n  }\n\n  // Step 3: Deserialize tensor proto strings to tensors.\n  int tensor_proto_strs_index = 0;\n  for (int i = 0; i < num_components; ++i) {\n    if (DataTypeCanUseMemcpy(compressed.component_metadata(i).dtype())) {\n      continue;\n    }\n    TensorProto tp;\n    if (!tp.ParseFromString(tensor_proto_strs[tensor_proto_strs_index++])) {\n      return errors::Internal(\"Could not parse TensorProto\");\n    }\n    if (!out->at(i).FromProto(tp)) {\n      return errors::Internal(\"Could not parse Tensor\");\n    }\n  }\n  return Status::OK();\n}\n\n}  // namespace data\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/core/data/compression_utils.h\"\n\n#include \"tensorflow/core/common_runtime/dma_helper.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/platform/snappy.h\"\n\nnamespace tensorflow {\nnamespace data {\n\nStatus CompressElement(const std::vector<Tensor>& element,\n                       CompressedElement* out) {\n  // Step 1: Determine the total uncompressed size. This requires serializing\n  // non-memcopyable tensors, which we save to use again later.\n  std::vector<TensorProto> non_memcpy_components;\n  int64 total_size = 0;\n  for (auto& component : element) {\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        total_size += buffer->size();\n      }\n    } else {\n      non_memcpy_components.emplace_back();\n      component.AsProtoTensorContent(&non_memcpy_components.back());\n      total_size += non_memcpy_components.back().ByteSizeLong();\n    }\n  }\n\n  // Step 2: Write the tensor data to a buffer, and compress that buffer.\n  // We use tstring for access to resize_uninitialized.\n  tstring uncompressed;\n  uncompressed.resize_uninitialized(total_size);\n  // Position in `uncompressed` to write the next component.\n  char* position = uncompressed.mdata();\n  int non_memcpy_component_index = 0;\n  for (auto& component : element) {\n    CompressedComponentMetadata* metadata =\n        out->mutable_component_metadata()->Add();\n    metadata->set_dtype(component.dtype());\n    component.shape().AsProto(metadata->mutable_tensor_shape());\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        memcpy(position, buffer->data(), buffer->size());\n        metadata->set_tensor_size_bytes(buffer->size());\n      }\n    } else {\n      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n      proto.SerializeToArray(position, proto.ByteSizeLong());\n      metadata->set_tensor_size_bytes(proto.ByteSizeLong());\n    }\n    position += metadata->tensor_size_bytes();\n  }\n  DCHECK_EQ(position, uncompressed.mdata() + total_size);\n\n  if (!port::Snappy_Compress(uncompressed.mdata(), total_size,\n                             out->mutable_data())) {\n    return errors::Internal(\"Failed to compress using snappy.\");\n  }\n  VLOG(3) << \"Compressed element from \" << total_size << \" bytes to \"\n          << out->data().size() << \" bytes\";\n  return Status::OK();\n}\n\nStatus UncompressElement(const CompressedElement& compressed,\n                         std::vector<Tensor>* out) {\n  int num_components = compressed.component_metadata_size();\n  out->clear();\n  out->reserve(num_components);\n\n  // Step 1: Prepare the memory that we will uncompress into.\n  std::vector<struct iovec> iov(num_components);\n  // We use tstring for access to resize_uninitialized.\n  std::vector<tstring> tensor_proto_strs;\n  // num_components is a conservative estimate. It is important to reserve\n  // vector space so that the vector doesn't resize itself, which could\n  // invalidate pointers to its strings' data.\n  tensor_proto_strs.reserve(num_components);\n  int64 total_size = 0;\n  for (int i = 0; i < num_components; ++i) {\n    const CompressedComponentMetadata& metadata =\n        compressed.component_metadata(i);\n    if (DataTypeCanUseMemcpy(metadata.dtype())) {\n      out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n      TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n      if (buffer) {\n        iov[i].iov_base = buffer->data();\n        iov[i].iov_len = buffer->size();\n      } else {\n        iov[i].iov_base = nullptr;\n        iov[i].iov_len = 0;\n      }\n    } else {\n      // Allocate an empty Tensor. We will fill it out later after\n      // uncompressing into the tensor_proto_str.\n      out->emplace_back();\n      tensor_proto_strs.emplace_back();\n      tstring& tensor_proto_str = tensor_proto_strs.back();\n      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());\n      iov[i].iov_base = tensor_proto_str.mdata();\n      iov[i].iov_len = tensor_proto_str.size();\n    }\n    total_size += iov[i].iov_len;\n  }\n\n  // Step 2: Uncompress into the iovec.\n  const std::string& compressed_data = compressed.data();\n  size_t uncompressed_size;\n  if (!port::Snappy_GetUncompressedLength(\n          compressed_data.data(), compressed_data.size(), &uncompressed_size)) {\n    return errors::Internal(\n        \"Could not get snappy uncompressed length. Compressed data size: \",\n        compressed_data.size());\n  }\n  if (uncompressed_size != static_cast<size_t>(total_size)) {\n    return errors::Internal(\n        \"Uncompressed size mismatch. Snappy expects \", uncompressed_size,\n        \" whereas the tensor metadata suggests \", total_size);\n  }\n  if (!port::Snappy_UncompressToIOVec(compressed_data.data(),\n                                      compressed_data.size(), iov.data(),\n                                      num_components)) {\n    return errors::Internal(\"Failed to perform snappy decompression.\");\n  }\n\n  // Step 3: Deserialize tensor proto strings to tensors.\n  int tensor_proto_strs_index = 0;\n  for (int i = 0; i < num_components; ++i) {\n    if (DataTypeCanUseMemcpy(compressed.component_metadata(i).dtype())) {\n      continue;\n    }\n    TensorProto tp;\n    if (!tp.ParseFromString(tensor_proto_strs[tensor_proto_strs_index++])) {\n      return errors::Internal(\"Could not parse TensorProto\");\n    }\n    if (!out->at(i).FromProto(tp)) {\n      return errors::Internal(\"Could not parse Tensor\");\n    }\n  }\n  return Status::OK();\n}\n\n}  // namespace data\n}  // namespace tensorflow\n"], "buggy_code_start_loc": [32], "buggy_code_end_loc": [99], "fixing_code_start_loc": [32], "fixing_code_end_loc": [107], "type": "CWE-476", "message": "TensorFlow is an end-to-end open source platform for machine learning. It is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to `tf.raw_ops.CompressElement`. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/data/compression_utils.cc#L34) was accessing the size of a buffer obtained from the return of a separate function call before validating that said buffer is valid. We have patched the issue in GitHub commit 5dc7f6981fdaf74c8c5be41f393df705841fb7c5. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-37637", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-12T19:15:08.500", "lastModified": "2021-08-18T17:20:04.167", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. It is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to `tf.raw_ops.CompressElement`. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/data/compression_utils.cc#L34) was accessing the size of a buffer obtained from the return of a separate function call before validating that said buffer is valid. We have patched the issue in GitHub commit 5dc7f6981fdaf74c8c5be41f393df705841fb7c5. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico. Es posible desencadenar una desreferencia de puntero null en TensorFlow pasando una entrada no v\u00e1lida a \"tf.raw_ops.CompressElement\". La [implementaci\u00f3n](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/data/compression_utils.cc#L34) estaba accediendo al tama\u00f1o de un buffer obtenido del retorno de una llamada a una funci\u00f3n separada antes de comprender que dicho buffer es v\u00e1lido. Hemos parcheado el problema en el commit 5dc7f6981fdaf74c8c5be41f393df705841fb7c5 de GitHub. La correcci\u00f3n se incluir\u00e1 en TensorFlow versi\u00f3n 2.6.0. Tambi\u00e9n se incluir\u00e1 este commit en TensorFlow versi\u00f3n 2.5.1, TensorFlow versi\u00f3n 2.4.3, y TensorFlow versi\u00f3n 2.3.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango de soporte."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.7, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.5, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.4", "matchCriteriaId": "0F83C081-51CC-415F-A8C0-0A44C75E2CD6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.3", "matchCriteriaId": "BD3F2BF8-EBA9-42BF-8F9B-D918B880B15A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.5.0:*:*:*:*:*:*:*", "matchCriteriaId": "D03E99A7-4E3D-427D-A156-C0713E9FB02A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "70FA6E48-6C57-40CA-809F-4E3D07CBF348"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "42187561-E491-434D-828C-F36701446634"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "C66B61C8-450A-4C5E-9174-F970D6DEE778"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/5dc7f6981fdaf74c8c5be41f393df705841fb7c5", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-c9qf-r67m-p7cg", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/5dc7f6981fdaf74c8c5be41f393df705841fb7c5"}}