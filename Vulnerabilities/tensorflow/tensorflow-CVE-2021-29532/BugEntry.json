{"buggy_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <limits>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/fingerprint.h\"\n#include \"tensorflow/core/util/util.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\nnamespace {\n\n//==============================================================================\n// Feature Readers\n//==============================================================================\n\n// A `FeatureReader` is used to read the feature values from a single input\n// tensor.  Subclasses are used for reading different tensor types:\n//   * RaggedFeatureReader<value_type, splits_type>\n//   * SparseFeatureReader<value_type>\n//   * DenseFeatureReader<value_type>\n//\n// Where value_type is one of: {tstring, int64}; and SplitsType is one of:\n// {int32, int64}.\nclass FeatureReader {\n public:\n  // Returns the number of feature values in the specified batch.\n  virtual int64 FeatureCount(int64 batch) const = 0;\n\n  // Copies the value for the specified feature to `out`.\n  virtual void ReadValue(int64 batch, int64 n, uint64* out) const = 0;\n  virtual void ReadValue(int64 batch, int64 n, tstring* out) const = 0;\n\n  virtual ~FeatureReader() {}\n};\n\nusing FeatureReaders = std::vector<std::unique_ptr<FeatureReader>>;\n\n// Copies a feature value `src` to a tstring `dst`, using a view if appropriate.\nvoid CopyToString(const tstring& src, tstring* dst) {\n  if (src.type() == tstring::SMALL) {\n    *dst = src;  // string buffer fits in the tstring object (under ~24 bytes)\n  } else {\n    dst->assign_as_view(src);\n  }\n}\nvoid CopyToString(int64 src, tstring* dst) { *dst = std::to_string(src); }\n\n// Copies a feature value `src` to an int64 fingerprint `dst`.\nvoid CopyToFingerprint(const tstring& feature, uint64* dst) {\n  *dst = Fingerprint64(feature);\n}\nvoid CopyToFingerprint(int64 feature, uint64* dst) { *dst = feature; }\n\n// A FeatureReader that is backed by a ragged tensor.\ntemplate <typename ValuesType, typename SplitsType>\nclass RaggedFeatureReader : public FeatureReader {\n public:\n  RaggedFeatureReader(const Tensor& values, const Tensor& row_splits)\n      : values_(values.flat<ValuesType>()),\n        row_splits_(row_splits.flat<SplitsType>()) {}\n\n  int64 FeatureCount(int64 batch) const override {\n    return row_splits_(batch + 1) - row_splits_(batch);\n  }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(row_splits_(batch) + n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(row_splits_(batch) + n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstFlat values_;\n  const typename TTypes<SplitsType>::ConstFlat row_splits_;\n};\n\n// A FeatureReader that is backed by a dense tensor.\ntemplate <typename ValuesType>\nclass DenseFeatureReader : public FeatureReader {\n public:\n  explicit DenseFeatureReader(const Tensor& tensor)\n      : values_(tensor.matrix<ValuesType>()),\n        feature_count_(tensor.dim_size(1)) {}\n\n  int64 FeatureCount(int64 batch) const override { return feature_count_; }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(batch, n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(batch, n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstMatrix values_;\n  const int64 feature_count_;\n};\n\n// A FeatureReader that is backed by a sparse tensor.\ntemplate <typename ValuesType>\nclass SparseFeatureReader : public FeatureReader {\n public:\n  SparseFeatureReader(const Tensor& indices_t, const Tensor& values_t,\n                      int64 batch_size)\n      : values_(values_t.flat<ValuesType>()) {\n    row_splits_.reserve(batch_size + 1);\n    row_splits_.push_back(0);\n    auto indices = indices_t.matrix<int64>();\n    int64 num_values = values_.size();\n    int64 i = 0;  // value index\n    for (int row = 0; row < batch_size; row++) {\n      while (i < num_values && indices(i, 0) <= row) ++i;\n      row_splits_.push_back(i);\n    }\n  }\n\n  int64 FeatureCount(int64 batch) const override {\n    return row_splits_[batch + 1] - row_splits_[batch];\n  }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(row_splits_[batch] + n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(row_splits_[batch] + n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstFlat values_;\n  std::vector<int64> row_splits_;\n};\n\n//==============================================================================\n// Output Writers\n//==============================================================================\n\n// An `OutputWriter` is used to write the feature crosses to the output values\n// tensor.  Different subclasses are used for writing different output dtypes:\n//   * OutputWriterImpl<tstring, SplitsType> (for tf.ragged.cross)\n//   * OutputWriterImpl<int64, SplitsType> (for tf.ragged.cross_hashed)\nclass OutputWriter {\n public:\n  virtual void WriteOutputSlice(int64 begin, int64 end) = 0;\n  virtual ~OutputWriter() {}\n};\n\ntemplate <typename ValuesType, typename SplitsType>\nclass OutputWriterImpl : public OutputWriter {\n public:\n  using FlatValues = typename TTypes<ValuesType>::Flat;\n  using FlatSplits = typename TTypes<SplitsType>::ConstFlat;\n\n  OutputWriterImpl(const FeatureReaders& features, int64 num_buckets,\n                   uint64 hash_key, const Tensor* splits_out,\n                   Tensor* values_out)\n      : features_(features),\n        num_buckets_(num_buckets),\n        hash_key_(hash_key),\n        splits_out_(splits_out->flat<SplitsType>()),\n        values_out_(values_out->flat<ValuesType>()) {}\n\n  // Reads features from the specified slice of batch indices, computes\n  // feature crosses for each one, and writes them to values_out_.\n  void WriteOutputSlice(int64 begin, int64 end) override {\n    std::vector<int> combination(features_.size(), 0);\n    for (int64 b = begin; b < end; ++b) {\n      auto row_start = splits_out_(b);\n      auto row_limit = splits_out_(b + 1);\n      for (auto i = row_start; i < row_limit; ++i) {\n        WriteCombination(b, combination, &values_out_(i));\n        NextCombination(b, &combination);\n      }\n      combination.assign(features_.size(), 0);  // reset for next batch.\n    }\n  }\n\n private:\n  // Joins the specified combination of input features into a single string,\n  // and writes it to *out.\n  void WriteCombination(int64 batch_index, const std::vector<int>& combination,\n                        tstring* out) {\n    static const auto k_feature_separator = \"_X_\";\n    gtl::InlinedVector<tstring, 6> cross_vec(features_.size());\n    for (int i = 0; i < combination.size(); ++i) {\n      features_[i]->ReadValue(batch_index, combination[i], &cross_vec[i]);\n    }\n    *out = absl::StrJoin(cross_vec, k_feature_separator);\n  }\n\n  // Joins the specified combination of input features into a single\n  // fingerprint, and writes it to *out.\n  void WriteCombination(int64 batch_index, const std::vector<int>& combination,\n                        int64* out) {\n    // Do the fingerprint concatenation on uint64.\n    uint64 hashed_output = hash_key_;\n    for (size_t i = 0; i < combination.size(); ++i) {\n      uint64 hash_i;\n      features_[i]->ReadValue(batch_index, combination[i], &hash_i);\n      hashed_output = FingerprintCat64(hashed_output, hash_i);\n    }\n    // The return value is int64 based on the number of buckets.\n    if (num_buckets_ > 0) {\n      *out = hashed_output % num_buckets_;\n    } else {\n      // To prevent negative output we take modulo to max int64.\n      *out = hashed_output % std::numeric_limits<int64>::max();\n    }\n  }\n\n  // Updates `combination` to the next combination of input features.\n  void NextCombination(int64 batch_index, std::vector<int>* combination) const {\n    bool carry = true;\n    for (int i = combination->size() - 1; i >= 0; i--) {\n      if (carry) {\n        (*combination)[i] = (*combination)[i] + 1;\n      }\n      if ((*combination)[i] == features_[i]->FeatureCount(batch_index)) {\n        (*combination)[i] = 0;\n      } else {\n        carry = false;\n        break;\n      }\n    }\n  }\n\n  const FeatureReaders& features_;\n  const int64 num_buckets_;\n  const uint64 hash_key_;\n  FlatSplits splits_out_;\n  FlatValues values_out_;\n};\n\n// Returns an appropriate OutputWriter, based on the dtypes of the\n// given tensors.\nstd::unique_ptr<OutputWriter> MakeOutputWriter(const FeatureReaders& features,\n                                               int64 num_buckets,\n                                               uint64 hash_key,\n                                               const Tensor* splits_out,\n                                               Tensor* values_out) {\n  if (values_out->dtype() == DT_INT64) {\n    if (splits_out->dtype() == DT_INT64) {\n      return std::make_unique<OutputWriterImpl<int64, int64>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    } else {\n      return std::make_unique<OutputWriterImpl<int64, int32>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    }\n  } else {\n    if (splits_out->dtype() == DT_INT64) {\n      return std::make_unique<OutputWriterImpl<tstring, int64>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    } else {\n      return std::make_unique<OutputWriterImpl<tstring, int32>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    }\n  }\n}\n\n//==============================================================================\n// RaggedCross Kernel\n//==============================================================================\n\ntemplate <typename SplitsType>\nclass RaggedCrossOp : public OpKernel {\n public:\n  explicit RaggedCrossOp(OpKernelConstruction* context) : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"num_buckets\", &num_buckets_));\n    // Read signed_hash_key_ as int64 since uint64 attributes are not\n    // supported by REGISTER_OP.\n    int64 signed_hash_key_;\n    OP_REQUIRES_OK(context, context->GetAttr(\"hash_key\", &signed_hash_key_));\n    hash_key_ = static_cast<uint64>(signed_hash_key_);\n\n    int num_sparse;\n    OP_REQUIRES_OK(context, context->GetAttr(\"Nsparse\", &num_sparse));\n\n    OP_REQUIRES_OK(context, context->GetAttr(\"ragged_values_types\",\n                                             &ragged_values_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ragged_splits_types\",\n                                             &ragged_splits_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"sparse_values_types\",\n                                             &sparse_values_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"dense_types\", &dense_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"input_order\", &input_order_));\n    OP_REQUIRES(context,\n                ragged_values_types_.size() == ragged_splits_types_.size(),\n                errors::InvalidArgument(\n                    \"ragged values and splits must have the same length\"));\n    OP_REQUIRES(context, num_sparse == sparse_values_types_.size(),\n                errors::InvalidArgument(\n                    \"sparse indices and values must have the same length\"));\n    OP_REQUIRES(context,\n                ragged_values_types_.size() + sparse_values_types_.size() +\n                        dense_types_.size() ==\n                    input_order_.size(),\n                errors::InvalidArgument(\"Invalid length for input_order\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    OpInputList ragged_values_list;\n    OpInputList ragged_splits_list;\n    OpInputList sparse_indices_list;\n    OpInputList sparse_values_list;\n    OpInputList sparse_shape_list;\n    OpInputList dense_list;\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"ragged_values\", &ragged_values_list));\n    OP_REQUIRES_OK(\n        context, context->input_list(\"ragged_row_splits\", &ragged_splits_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_indices\", &sparse_indices_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_values\", &sparse_values_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_shape\", &sparse_shape_list));\n    OP_REQUIRES_OK(context, context->input_list(\"dense_inputs\", &dense_list));\n    OP_REQUIRES_OK(context,\n                   ValidateInput(ragged_values_list, ragged_splits_list,\n                                 sparse_indices_list, sparse_values_list,\n                                 sparse_shape_list, dense_list));\n\n    int64 batch_size =\n        CalculateBatchSize(ragged_splits_list, sparse_shape_list, dense_list);\n\n    FeatureReaders features;\n    OP_REQUIRES_OK(context,\n                   BuildFeatureReaders(ragged_values_list, ragged_splits_list,\n                                       sparse_indices_list, sparse_values_list,\n                                       dense_list, batch_size, &features));\n\n    Tensor* values_out;\n    Tensor* row_splits_out;\n    OP_REQUIRES_OK(context, BuildOutputTensors(features, batch_size, context,\n                                               &values_out, &row_splits_out));\n\n    std::unique_ptr<OutputWriter> output_writer = MakeOutputWriter(\n        features, num_buckets_, hash_key_, row_splits_out, values_out);\n\n    auto do_work = [&output_writer](int64 begin, int64 end) {\n      output_writer->WriteOutputSlice(begin, end);\n    };\n\n    // TODO(edloper): optimize cost_per_batch\n    const int cost_per_batch = 5000 * ragged_values_list.size();\n    auto thread_pool =\n        context->device()->tensorflow_cpu_worker_threads()->workers;\n    thread_pool->ParallelFor(batch_size, cost_per_batch, do_work);\n  }\n\n private:\n  // Validates input tensors.\n  Status ValidateInput(const OpInputList& ragged_values_list,\n                       const OpInputList& ragged_splits_list,\n                       const OpInputList& sparse_indices_list,\n                       const OpInputList& sparse_values_list,\n                       const OpInputList& sparse_shape_list,\n                       const OpInputList& dense_list) {\n    const auto num_ragged = ragged_values_list.size();\n    const auto num_sparse = sparse_indices_list.size();\n\n    // Validate tensor shapes.\n    for (int i = 0; i < num_ragged; ++i) {\n      if (!TensorShapeUtils::IsVector(ragged_values_list[i].shape())) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n      if (!TensorShapeUtils::IsVector(ragged_splits_list[i].shape()) ||\n          (ragged_splits_list[i].NumElements() == 0)) {\n        return errors::InvalidArgument(\"Invalid RaggedTensor\");\n      }\n    }\n    for (int i = 0; i < num_sparse; ++i) {\n      if (!TensorShapeUtils::IsMatrix(sparse_indices_list[i].shape()) ||\n          !TensorShapeUtils::IsVector(sparse_values_list[i].shape()) ||\n          !TensorShapeUtils::IsVector(sparse_shape_list[i].shape())) {\n        return errors::InvalidArgument(\"Invalid SparseTensor \", i);\n      }\n      if (sparse_shape_list[i].NumElements() != 2) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n    }\n    for (int i = 0; i < dense_list.size(); ++i) {\n      if (!TensorShapeUtils::IsMatrix(dense_list[i].shape())) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n    }\n\n    // Check that batch sizes are consistent.\n    int64 batch_size =\n        CalculateBatchSize(ragged_splits_list, sparse_shape_list, dense_list);\n    for (int i = 0; i < num_ragged; ++i) {\n      if (ragged_splits_list[i].NumElements() - 1 != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n    for (int i = 0; i < num_sparse; ++i) {\n      if (sparse_shape_list[i].flat<int64>()(0) != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n    for (int i = 0; i < dense_list.size(); ++i) {\n      if (dense_list[i].dim_size(0) != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n\n    return Status::OK();\n  }\n\n  // Calculate the batch size from any input tensor.  (We check that all input\n  // tensors have the same batch size in `ValidateInput`).\n  int64 CalculateBatchSize(const OpInputList& ragged_splits_list,\n                           const OpInputList& sparse_shape_list,\n                           const OpInputList& dense_list) {\n    if (ragged_splits_list.size() > 0) {\n      return ragged_splits_list[0].NumElements() - 1;\n    } else if (dense_list.size() > 0) {\n      return dense_list[0].dim_size(0);\n    } else if (sparse_shape_list.size() > 0) {\n      return sparse_shape_list[0].flat<int64>()(0);\n    } else {\n      return 0;\n    }\n  }\n\n  // Build a feature reader for each input tensor, and store them in `features`.\n  Status BuildFeatureReaders(const OpInputList& ragged_values_list,\n                             const OpInputList& ragged_splits_list,\n                             const OpInputList& sparse_indices_list,\n                             const OpInputList& sparse_values_list,\n                             const OpInputList& dense_list, int64 batch_size,\n                             FeatureReaders* features) {\n    features->reserve(input_order_.size());\n\n    int next_ragged = 0;\n    int next_sparse = 0;\n    int next_dense = 0;\n    for (char c : input_order_) {\n      if (c == 'R') {\n        TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n            ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n            features));\n        next_ragged++;\n      } else if (c == 'S') {\n        TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n            sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n            batch_size, features));\n        next_sparse++;\n      } else if (c == 'D') {\n        TF_RETURN_IF_ERROR(\n            BuildDenseFeatureReader(dense_list[next_dense++], features));\n      } else {\n        return errors::InvalidArgument(\"Unexpected input_order value.\");\n      }\n    }\n\n    return Status::OK();\n  }\n\n  // Builds a RaggedReatureReader\n  static Status BuildRaggedFeatureReader(const Tensor& values,\n                                         const Tensor& splits,\n                                         FeatureReaders* features) {\n    if (values.dtype() != DT_INT64 && values.dtype() != DT_STRING) {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    if (splits.dtype() != DT_INT64 && splits.dtype() != DT_INT32) {\n      return errors::InvalidArgument(\"Unexpected row_splits.dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    if (values.dtype() == DT_INT64) {\n      if (splits.dtype() == DT_INT64) {\n        features->emplace_back(\n            new RaggedFeatureReader<int64, int64>(values, splits));\n      } else {\n        features->emplace_back(\n            new RaggedFeatureReader<int64, int32>(values, splits));\n      }\n    } else {\n      if (splits.dtype() == DT_INT64) {\n        features->emplace_back(\n            new RaggedFeatureReader<tstring, int64>(values, splits));\n      } else {\n        features->emplace_back(\n            new RaggedFeatureReader<tstring, int32>(values, splits));\n      }\n    }\n    return Status::OK();\n  }\n\n  // Builds a DenseFaggedReatureReader.\n  static Status BuildDenseFeatureReader(const Tensor& values,\n                                        FeatureReaders* features) {\n    if (values.dtype() == DT_INT64) {\n      features->emplace_back(new DenseFeatureReader<int64>(values));\n    } else if (values.dtype() == DT_STRING) {\n      features->emplace_back(new DenseFeatureReader<tstring>(values));\n    } else {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    return Status::OK();\n  }\n\n  // Builds a SparseFaggedReatureReader.\n  static Status BuildSparseFeatureReader(const Tensor& indices,\n                                         const Tensor& values, int64 batch_size,\n                                         FeatureReaders* features) {\n    if (values.dtype() == DT_INT64) {\n      features->emplace_back(\n          new SparseFeatureReader<int64>(indices, values, batch_size));\n    } else if (values.dtype() == DT_STRING) {\n      features->emplace_back(\n          new SparseFeatureReader<tstring>(indices, values, batch_size));\n    } else {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    return Status::OK();\n  }\n\n  // Allocates output tensors with proper size, and populates row_splits_out.\n  Status BuildOutputTensors(const FeatureReaders& features, int64 batch_size,\n                            OpKernelContext* context, Tensor** values_out,\n                            Tensor** row_splits_out) {\n    // Allocate and populate the row_splits output tensor.\n    TF_RETURN_IF_ERROR(context->allocate_output(\n        1, TensorShape({batch_size + 1}), row_splits_out));\n    auto flat_row_splits = (*row_splits_out)->flat<SplitsType>();\n    int64 cross_count_total = 0;\n    flat_row_splits(0) = 0;\n    for (int64 b = 0; b < batch_size; b++) {\n      cross_count_total += CrossCountByBatchIndex(features, b);\n      flat_row_splits(b + 1) = cross_count_total;\n    }\n\n    // Allocate the values output tensor.\n    TF_RETURN_IF_ERROR(context->allocate_output(\n        0, TensorShape({cross_count_total}), values_out));\n\n    return Status::OK();\n  }\n\n  // Returns number of crosses for a given batch_index\n  int64 CrossCountByBatchIndex(const FeatureReaders& features,\n                               int batch_index) {\n    int64 cross_count = 1;\n    for (int i = 0; i < features.size(); ++i) {\n      const auto feature_count = features[i]->FeatureCount(batch_index);\n      if (feature_count == 0) return 0;\n      cross_count *= feature_count;\n    }\n    return cross_count;\n  }\n\n  int64 num_buckets_;\n  uint64 hash_key_;\n  std::vector<DataType> ragged_values_types_;\n  std::vector<DataType> ragged_splits_types_;\n  std::vector<DataType> sparse_values_types_;\n  std::vector<DataType> dense_types_;\n  tstring input_order_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"RaggedCross\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<int32>(\"out_row_splits_type\"),\n                        RaggedCrossOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"RaggedCross\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<int64>(\"out_row_splits_type\"),\n                        RaggedCrossOp<int64>);\n\n}  // namespace\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <limits>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/fingerprint.h\"\n#include \"tensorflow/core/util/util.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\nnamespace {\n\n//==============================================================================\n// Feature Readers\n//==============================================================================\n\n// A `FeatureReader` is used to read the feature values from a single input\n// tensor.  Subclasses are used for reading different tensor types:\n//   * RaggedFeatureReader<value_type, splits_type>\n//   * SparseFeatureReader<value_type>\n//   * DenseFeatureReader<value_type>\n//\n// Where value_type is one of: {tstring, int64}; and SplitsType is one of:\n// {int32, int64}.\nclass FeatureReader {\n public:\n  // Returns the number of feature values in the specified batch.\n  virtual int64 FeatureCount(int64 batch) const = 0;\n\n  // Copies the value for the specified feature to `out`.\n  virtual void ReadValue(int64 batch, int64 n, uint64* out) const = 0;\n  virtual void ReadValue(int64 batch, int64 n, tstring* out) const = 0;\n\n  virtual ~FeatureReader() {}\n};\n\nusing FeatureReaders = std::vector<std::unique_ptr<FeatureReader>>;\n\n// Copies a feature value `src` to a tstring `dst`, using a view if appropriate.\nvoid CopyToString(const tstring& src, tstring* dst) {\n  if (src.type() == tstring::SMALL) {\n    *dst = src;  // string buffer fits in the tstring object (under ~24 bytes)\n  } else {\n    dst->assign_as_view(src);\n  }\n}\nvoid CopyToString(int64 src, tstring* dst) { *dst = std::to_string(src); }\n\n// Copies a feature value `src` to an int64 fingerprint `dst`.\nvoid CopyToFingerprint(const tstring& feature, uint64* dst) {\n  *dst = Fingerprint64(feature);\n}\nvoid CopyToFingerprint(int64 feature, uint64* dst) { *dst = feature; }\n\n// A FeatureReader that is backed by a ragged tensor.\ntemplate <typename ValuesType, typename SplitsType>\nclass RaggedFeatureReader : public FeatureReader {\n public:\n  RaggedFeatureReader(const Tensor& values, const Tensor& row_splits)\n      : values_(values.flat<ValuesType>()),\n        row_splits_(row_splits.flat<SplitsType>()) {}\n\n  int64 FeatureCount(int64 batch) const override {\n    return row_splits_(batch + 1) - row_splits_(batch);\n  }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(row_splits_(batch) + n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(row_splits_(batch) + n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstFlat values_;\n  const typename TTypes<SplitsType>::ConstFlat row_splits_;\n};\n\n// A FeatureReader that is backed by a dense tensor.\ntemplate <typename ValuesType>\nclass DenseFeatureReader : public FeatureReader {\n public:\n  explicit DenseFeatureReader(const Tensor& tensor)\n      : values_(tensor.matrix<ValuesType>()),\n        feature_count_(tensor.dim_size(1)) {}\n\n  int64 FeatureCount(int64 batch) const override { return feature_count_; }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(batch, n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(batch, n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstMatrix values_;\n  const int64 feature_count_;\n};\n\n// A FeatureReader that is backed by a sparse tensor.\ntemplate <typename ValuesType>\nclass SparseFeatureReader : public FeatureReader {\n public:\n  SparseFeatureReader(const Tensor& indices_t, const Tensor& values_t,\n                      int64 batch_size)\n      : values_(values_t.flat<ValuesType>()) {\n    row_splits_.reserve(batch_size + 1);\n    row_splits_.push_back(0);\n    auto indices = indices_t.matrix<int64>();\n    int64 num_values = values_.size();\n    int64 i = 0;  // value index\n    for (int row = 0; row < batch_size; row++) {\n      while (i < num_values && indices(i, 0) <= row) ++i;\n      row_splits_.push_back(i);\n    }\n  }\n\n  int64 FeatureCount(int64 batch) const override {\n    return row_splits_[batch + 1] - row_splits_[batch];\n  }\n\n  void ReadValue(int64 batch, int64 n, uint64* out) const override {\n    CopyToFingerprint(values_(row_splits_[batch] + n), out);\n  }\n\n  void ReadValue(int64 batch, int64 n, tstring* out) const override {\n    CopyToString(values_(row_splits_[batch] + n), out);\n  }\n\n private:\n  const typename TTypes<ValuesType>::ConstFlat values_;\n  std::vector<int64> row_splits_;\n};\n\n//==============================================================================\n// Output Writers\n//==============================================================================\n\n// An `OutputWriter` is used to write the feature crosses to the output values\n// tensor.  Different subclasses are used for writing different output dtypes:\n//   * OutputWriterImpl<tstring, SplitsType> (for tf.ragged.cross)\n//   * OutputWriterImpl<int64, SplitsType> (for tf.ragged.cross_hashed)\nclass OutputWriter {\n public:\n  virtual void WriteOutputSlice(int64 begin, int64 end) = 0;\n  virtual ~OutputWriter() {}\n};\n\ntemplate <typename ValuesType, typename SplitsType>\nclass OutputWriterImpl : public OutputWriter {\n public:\n  using FlatValues = typename TTypes<ValuesType>::Flat;\n  using FlatSplits = typename TTypes<SplitsType>::ConstFlat;\n\n  OutputWriterImpl(const FeatureReaders& features, int64 num_buckets,\n                   uint64 hash_key, const Tensor* splits_out,\n                   Tensor* values_out)\n      : features_(features),\n        num_buckets_(num_buckets),\n        hash_key_(hash_key),\n        splits_out_(splits_out->flat<SplitsType>()),\n        values_out_(values_out->flat<ValuesType>()) {}\n\n  // Reads features from the specified slice of batch indices, computes\n  // feature crosses for each one, and writes them to values_out_.\n  void WriteOutputSlice(int64 begin, int64 end) override {\n    std::vector<int> combination(features_.size(), 0);\n    for (int64 b = begin; b < end; ++b) {\n      auto row_start = splits_out_(b);\n      auto row_limit = splits_out_(b + 1);\n      for (auto i = row_start; i < row_limit; ++i) {\n        WriteCombination(b, combination, &values_out_(i));\n        NextCombination(b, &combination);\n      }\n      combination.assign(features_.size(), 0);  // reset for next batch.\n    }\n  }\n\n private:\n  // Joins the specified combination of input features into a single string,\n  // and writes it to *out.\n  void WriteCombination(int64 batch_index, const std::vector<int>& combination,\n                        tstring* out) {\n    static const auto k_feature_separator = \"_X_\";\n    gtl::InlinedVector<tstring, 6> cross_vec(features_.size());\n    for (int i = 0; i < combination.size(); ++i) {\n      features_[i]->ReadValue(batch_index, combination[i], &cross_vec[i]);\n    }\n    *out = absl::StrJoin(cross_vec, k_feature_separator);\n  }\n\n  // Joins the specified combination of input features into a single\n  // fingerprint, and writes it to *out.\n  void WriteCombination(int64 batch_index, const std::vector<int>& combination,\n                        int64* out) {\n    // Do the fingerprint concatenation on uint64.\n    uint64 hashed_output = hash_key_;\n    for (size_t i = 0; i < combination.size(); ++i) {\n      uint64 hash_i;\n      features_[i]->ReadValue(batch_index, combination[i], &hash_i);\n      hashed_output = FingerprintCat64(hashed_output, hash_i);\n    }\n    // The return value is int64 based on the number of buckets.\n    if (num_buckets_ > 0) {\n      *out = hashed_output % num_buckets_;\n    } else {\n      // To prevent negative output we take modulo to max int64.\n      *out = hashed_output % std::numeric_limits<int64>::max();\n    }\n  }\n\n  // Updates `combination` to the next combination of input features.\n  void NextCombination(int64 batch_index, std::vector<int>* combination) const {\n    bool carry = true;\n    for (int i = combination->size() - 1; i >= 0; i--) {\n      if (carry) {\n        (*combination)[i] = (*combination)[i] + 1;\n      }\n      if ((*combination)[i] == features_[i]->FeatureCount(batch_index)) {\n        (*combination)[i] = 0;\n      } else {\n        carry = false;\n        break;\n      }\n    }\n  }\n\n  const FeatureReaders& features_;\n  const int64 num_buckets_;\n  const uint64 hash_key_;\n  FlatSplits splits_out_;\n  FlatValues values_out_;\n};\n\n// Returns an appropriate OutputWriter, based on the dtypes of the\n// given tensors.\nstd::unique_ptr<OutputWriter> MakeOutputWriter(const FeatureReaders& features,\n                                               int64 num_buckets,\n                                               uint64 hash_key,\n                                               const Tensor* splits_out,\n                                               Tensor* values_out) {\n  if (values_out->dtype() == DT_INT64) {\n    if (splits_out->dtype() == DT_INT64) {\n      return std::make_unique<OutputWriterImpl<int64, int64>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    } else {\n      return std::make_unique<OutputWriterImpl<int64, int32>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    }\n  } else {\n    if (splits_out->dtype() == DT_INT64) {\n      return std::make_unique<OutputWriterImpl<tstring, int64>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    } else {\n      return std::make_unique<OutputWriterImpl<tstring, int32>>(\n          features, num_buckets, hash_key, splits_out, values_out);\n    }\n  }\n}\n\n//==============================================================================\n// RaggedCross Kernel\n//==============================================================================\n\ntemplate <typename SplitsType>\nclass RaggedCrossOp : public OpKernel {\n public:\n  explicit RaggedCrossOp(OpKernelConstruction* context) : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"num_buckets\", &num_buckets_));\n    // Read signed_hash_key_ as int64 since uint64 attributes are not\n    // supported by REGISTER_OP.\n    int64 signed_hash_key_;\n    OP_REQUIRES_OK(context, context->GetAttr(\"hash_key\", &signed_hash_key_));\n    hash_key_ = static_cast<uint64>(signed_hash_key_);\n\n    int num_sparse;\n    OP_REQUIRES_OK(context, context->GetAttr(\"Nsparse\", &num_sparse));\n\n    OP_REQUIRES_OK(context, context->GetAttr(\"ragged_values_types\",\n                                             &ragged_values_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ragged_splits_types\",\n                                             &ragged_splits_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"sparse_values_types\",\n                                             &sparse_values_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"dense_types\", &dense_types_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"input_order\", &input_order_));\n    OP_REQUIRES(context,\n                ragged_values_types_.size() == ragged_splits_types_.size(),\n                errors::InvalidArgument(\n                    \"ragged values and splits must have the same length\"));\n    OP_REQUIRES(context, num_sparse == sparse_values_types_.size(),\n                errors::InvalidArgument(\n                    \"sparse indices and values must have the same length\"));\n    OP_REQUIRES(context,\n                ragged_values_types_.size() + sparse_values_types_.size() +\n                        dense_types_.size() ==\n                    input_order_.size(),\n                errors::InvalidArgument(\"Invalid length for input_order\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    OpInputList ragged_values_list;\n    OpInputList ragged_splits_list;\n    OpInputList sparse_indices_list;\n    OpInputList sparse_values_list;\n    OpInputList sparse_shape_list;\n    OpInputList dense_list;\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"ragged_values\", &ragged_values_list));\n    OP_REQUIRES_OK(\n        context, context->input_list(\"ragged_row_splits\", &ragged_splits_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_indices\", &sparse_indices_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_values\", &sparse_values_list));\n    OP_REQUIRES_OK(context,\n                   context->input_list(\"sparse_shape\", &sparse_shape_list));\n    OP_REQUIRES_OK(context, context->input_list(\"dense_inputs\", &dense_list));\n    OP_REQUIRES_OK(context,\n                   ValidateInput(ragged_values_list, ragged_splits_list,\n                                 sparse_indices_list, sparse_values_list,\n                                 sparse_shape_list, dense_list));\n\n    int64 batch_size =\n        CalculateBatchSize(ragged_splits_list, sparse_shape_list, dense_list);\n\n    FeatureReaders features;\n    OP_REQUIRES_OK(context,\n                   BuildFeatureReaders(ragged_values_list, ragged_splits_list,\n                                       sparse_indices_list, sparse_values_list,\n                                       dense_list, batch_size, &features));\n\n    Tensor* values_out;\n    Tensor* row_splits_out;\n    OP_REQUIRES_OK(context, BuildOutputTensors(features, batch_size, context,\n                                               &values_out, &row_splits_out));\n\n    std::unique_ptr<OutputWriter> output_writer = MakeOutputWriter(\n        features, num_buckets_, hash_key_, row_splits_out, values_out);\n\n    auto do_work = [&output_writer](int64 begin, int64 end) {\n      output_writer->WriteOutputSlice(begin, end);\n    };\n\n    // TODO(edloper): optimize cost_per_batch\n    const int cost_per_batch = 5000 * ragged_values_list.size();\n    auto thread_pool =\n        context->device()->tensorflow_cpu_worker_threads()->workers;\n    thread_pool->ParallelFor(batch_size, cost_per_batch, do_work);\n  }\n\n private:\n  // Validates input tensors.\n  Status ValidateInput(const OpInputList& ragged_values_list,\n                       const OpInputList& ragged_splits_list,\n                       const OpInputList& sparse_indices_list,\n                       const OpInputList& sparse_values_list,\n                       const OpInputList& sparse_shape_list,\n                       const OpInputList& dense_list) {\n    const auto num_ragged = ragged_values_list.size();\n    const auto num_sparse = sparse_indices_list.size();\n\n    // Validate tensor shapes.\n    for (int i = 0; i < num_ragged; ++i) {\n      if (!TensorShapeUtils::IsVector(ragged_values_list[i].shape())) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n      if (!TensorShapeUtils::IsVector(ragged_splits_list[i].shape()) ||\n          (ragged_splits_list[i].NumElements() == 0)) {\n        return errors::InvalidArgument(\"Invalid RaggedTensor\");\n      }\n    }\n    for (int i = 0; i < num_sparse; ++i) {\n      if (!TensorShapeUtils::IsMatrix(sparse_indices_list[i].shape()) ||\n          !TensorShapeUtils::IsVector(sparse_values_list[i].shape()) ||\n          !TensorShapeUtils::IsVector(sparse_shape_list[i].shape())) {\n        return errors::InvalidArgument(\"Invalid SparseTensor \", i);\n      }\n      if (sparse_shape_list[i].NumElements() != 2) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n    }\n    for (int i = 0; i < dense_list.size(); ++i) {\n      if (!TensorShapeUtils::IsMatrix(dense_list[i].shape())) {\n        return errors::InvalidArgument(\n            \"tf.ragged.cross only supports inputs with rank=2.\");\n      }\n    }\n\n    // Check that batch sizes are consistent.\n    int64 batch_size =\n        CalculateBatchSize(ragged_splits_list, sparse_shape_list, dense_list);\n    for (int i = 0; i < num_ragged; ++i) {\n      if (ragged_splits_list[i].NumElements() - 1 != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n    for (int i = 0; i < num_sparse; ++i) {\n      if (sparse_shape_list[i].flat<int64>()(0) != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n    for (int i = 0; i < dense_list.size(); ++i) {\n      if (dense_list[i].dim_size(0) != batch_size) {\n        return errors::InvalidArgument(\n            \"inputs must all have the same batch dimension size.\");\n      }\n    }\n\n    return Status::OK();\n  }\n\n  // Calculate the batch size from any input tensor.  (We check that all input\n  // tensors have the same batch size in `ValidateInput`).\n  int64 CalculateBatchSize(const OpInputList& ragged_splits_list,\n                           const OpInputList& sparse_shape_list,\n                           const OpInputList& dense_list) {\n    if (ragged_splits_list.size() > 0) {\n      return ragged_splits_list[0].NumElements() - 1;\n    } else if (dense_list.size() > 0) {\n      return dense_list[0].dim_size(0);\n    } else if (sparse_shape_list.size() > 0) {\n      return sparse_shape_list[0].flat<int64>()(0);\n    } else {\n      return 0;\n    }\n  }\n\n  // Build a feature reader for each input tensor, and store them in `features`.\n  Status BuildFeatureReaders(const OpInputList& ragged_values_list,\n                             const OpInputList& ragged_splits_list,\n                             const OpInputList& sparse_indices_list,\n                             const OpInputList& sparse_values_list,\n                             const OpInputList& dense_list, int64 batch_size,\n                             FeatureReaders* features) {\n    features->reserve(input_order_.size());\n\n    int next_ragged = 0;\n    int next_sparse = 0;\n    int next_dense = 0;\n    for (char c : input_order_) {\n      if (c == 'R') {\n        if (next_ragged >= ragged_values_list.size())\n          return errors::InvalidArgument(\n              \"input_order \\\"\", input_order_,\n              \"\\\" specifies reading a ragged tensor value at index \",\n              next_ragged, \" from a list of \", ragged_values_list.size(),\n              \" values.\");\n        if (next_ragged >= ragged_splits_list.size())\n          return errors::InvalidArgument(\n              \"input_order \\\"\", input_order_,\n              \"\\\" specifies reading a ragged tensor split at index \",\n              next_ragged, \" from a list of \", ragged_splits_list.size(),\n              \" splits.\");\n        TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n            ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n            features));\n        next_ragged++;\n      } else if (c == 'S') {\n        if (next_sparse >= sparse_values_list.size())\n          return errors::InvalidArgument(\n              \"input_order \\\"\", input_order_,\n              \"\\\" specifies reading a sparse tensor value at index \",\n              next_sparse, \" from a list of \", sparse_values_list.size(),\n              \" values.\");\n        if (next_sparse >= sparse_indices_list.size())\n          return errors::InvalidArgument(\n              \"input_order \\\"\", input_order_,\n              \"\\\" specifies reading a sparse tensor index at index \",\n              next_sparse, \" from a list of \", sparse_indices_list.size(),\n              \" indices.\");\n        TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n            sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n            batch_size, features));\n        next_sparse++;\n      } else if (c == 'D') {\n        if (next_dense >= dense_list.size())\n          return errors::InvalidArgument(\n              \"input_order \\\"\", input_order_,\n              \"\\\" specifies reading a dense tensor at index \", next_dense,\n              \" from a list of \", dense_list.size(), \" tensors.\");\n        TF_RETURN_IF_ERROR(\n            BuildDenseFeatureReader(dense_list[next_dense++], features));\n      } else {\n        return errors::InvalidArgument(\"Unexpected input_order value.\");\n      }\n    }\n\n    return Status::OK();\n  }\n\n  // Builds a RaggedReatureReader\n  static Status BuildRaggedFeatureReader(const Tensor& values,\n                                         const Tensor& splits,\n                                         FeatureReaders* features) {\n    if (values.dtype() != DT_INT64 && values.dtype() != DT_STRING) {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    if (splits.dtype() != DT_INT64 && splits.dtype() != DT_INT32) {\n      return errors::InvalidArgument(\"Unexpected row_splits.dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    if (values.dtype() == DT_INT64) {\n      if (splits.dtype() == DT_INT64) {\n        features->emplace_back(\n            new RaggedFeatureReader<int64, int64>(values, splits));\n      } else {\n        features->emplace_back(\n            new RaggedFeatureReader<int64, int32>(values, splits));\n      }\n    } else {\n      if (splits.dtype() == DT_INT64) {\n        features->emplace_back(\n            new RaggedFeatureReader<tstring, int64>(values, splits));\n      } else {\n        features->emplace_back(\n            new RaggedFeatureReader<tstring, int32>(values, splits));\n      }\n    }\n    return Status::OK();\n  }\n\n  // Builds a DenseFaggedReatureReader.\n  static Status BuildDenseFeatureReader(const Tensor& values,\n                                        FeatureReaders* features) {\n    if (values.dtype() == DT_INT64) {\n      features->emplace_back(new DenseFeatureReader<int64>(values));\n    } else if (values.dtype() == DT_STRING) {\n      features->emplace_back(new DenseFeatureReader<tstring>(values));\n    } else {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    return Status::OK();\n  }\n\n  // Builds a SparseFaggedReatureReader.\n  static Status BuildSparseFeatureReader(const Tensor& indices,\n                                         const Tensor& values, int64 batch_size,\n                                         FeatureReaders* features) {\n    if (values.dtype() == DT_INT64) {\n      features->emplace_back(\n          new SparseFeatureReader<int64>(indices, values, batch_size));\n    } else if (values.dtype() == DT_STRING) {\n      features->emplace_back(\n          new SparseFeatureReader<tstring>(indices, values, batch_size));\n    } else {\n      return errors::InvalidArgument(\"Unexpected dtype for input \",\n                                     (features->size() + 1), \": \",\n                                     values.dtype());\n    }\n    return Status::OK();\n  }\n\n  // Allocates output tensors with proper size, and populates row_splits_out.\n  Status BuildOutputTensors(const FeatureReaders& features, int64 batch_size,\n                            OpKernelContext* context, Tensor** values_out,\n                            Tensor** row_splits_out) {\n    // Allocate and populate the row_splits output tensor.\n    TF_RETURN_IF_ERROR(context->allocate_output(\n        1, TensorShape({batch_size + 1}), row_splits_out));\n    auto flat_row_splits = (*row_splits_out)->flat<SplitsType>();\n    int64 cross_count_total = 0;\n    flat_row_splits(0) = 0;\n    for (int64 b = 0; b < batch_size; b++) {\n      cross_count_total += CrossCountByBatchIndex(features, b);\n      flat_row_splits(b + 1) = cross_count_total;\n    }\n\n    // Allocate the values output tensor.\n    TF_RETURN_IF_ERROR(context->allocate_output(\n        0, TensorShape({cross_count_total}), values_out));\n\n    return Status::OK();\n  }\n\n  // Returns number of crosses for a given batch_index\n  int64 CrossCountByBatchIndex(const FeatureReaders& features,\n                               int batch_index) {\n    int64 cross_count = 1;\n    for (int i = 0; i < features.size(); ++i) {\n      const auto feature_count = features[i]->FeatureCount(batch_index);\n      if (feature_count == 0) return 0;\n      cross_count *= feature_count;\n    }\n    return cross_count;\n  }\n\n  int64 num_buckets_;\n  uint64 hash_key_;\n  std::vector<DataType> ragged_values_types_;\n  std::vector<DataType> ragged_splits_types_;\n  std::vector<DataType> sparse_values_types_;\n  std::vector<DataType> dense_types_;\n  tstring input_order_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"RaggedCross\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<int32>(\"out_row_splits_type\"),\n                        RaggedCrossOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"RaggedCross\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<int64>(\"out_row_splits_type\"),\n                        RaggedCrossOp<int64>);\n\n}  // namespace\n}  // namespace tensorflow\n"], "buggy_code_start_loc": [23], "buggy_code_end_loc": [478], "fixing_code_start_loc": [24], "fixing_code_end_loc": [509], "type": "CWE-125", "message": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to `tf.raw_ops.RaggedCross`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/efea03b38fb8d3b81762237dc85e579cc5fc6e87/tensorflow/core/kernels/ragged_cross_op.cc#L456-L487) lacks validation for the user supplied arguments. Each of the above branches call a helper function after accessing array elements via a `*_list[next_*]` pattern, followed by incrementing the `next_*` index. However, as there is no validation that the `next_*` values are in the valid range for the corresponding `*_list` arrays, this results in heap OOB reads. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29532", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:12.073", "lastModified": "2021-07-26T15:56:40.590", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to `tf.raw_ops.RaggedCross`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/efea03b38fb8d3b81762237dc85e579cc5fc6e87/tensorflow/core/kernels/ragged_cross_op.cc#L456-L487) lacks validation for the user supplied arguments. Each of the above branches call a helper function after accessing array elements via a `*_list[next_*]` pattern, followed by incrementing the `next_*` index. However, as there is no validation that the `next_*` values are in the valid range for the corresponding `*_list` arrays, this results in heap OOB reads. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;Un atacante puede forzar accesos fuera de l\u00edmites de las matrices asignadas a la pila al pasar valores de tensor no comprobados a \"tf.raw_ops.RaggedCross\".&#xa0;Esto es debido a que la implementaci\u00f3n (https://github.com/tensorflow/tensorflow/blob/efea03b38fb8d3b81762237dc85e579cc5fc6e87/tensorflow/core/kernels/ragged_cross_op.cc#L456-L487) carece de comprobaci\u00f3n para los argumentos proporcionados por el usuario.&#xa0;Cada una de las ramas anteriores llama a una funci\u00f3n auxiliar despu\u00e9s de acceder a los elementos de la matriz por medio de un patr\u00f3n \"* _list [next _ *]\", seguido de incrementar el \u00edndice \"next_ *\".&#xa0;Sin embargo, como no hay comprobaci\u00f3n de que los valores \"next_ *\" est\u00e9n en el rango v\u00e1lido para las matrices \"* _list\" correspondientes, esto resulta en lecturas OOB de la pila.&#xa0;La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 3.6}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/44b7f486c0143f68b56c34e2d01e146ee445134a", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-j47f-4232-hvv8", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/44b7f486c0143f68b56c34e2d01e146ee445134a"}}