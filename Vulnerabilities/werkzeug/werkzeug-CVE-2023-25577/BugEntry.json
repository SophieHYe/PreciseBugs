{"buggy_code": [".. currentmodule:: werkzeug\n\nVersion 2.2.3\n-------------\n\nUnreleased\n\n-   Ensure that URL rules using path converters will redirect with strict slashes when\n    the trailing slash is missing. :issue:`2533`\n-   Type signature for ``get_json`` specifies that return type is not optional when\n    ``silent=False``. :issue:`2508`\n-   ``parse_content_range_header`` returns ``None`` for a value like ``bytes */-1``\n    where the length is invalid, instead of raising an ``AssertionError``. :issue:`2531`\n-   Address remaining ``ResourceWarning`` related to the socket used by ``run_simple``.\n    Remove ``prepare_socket``, which now happens when creating the server. :issue:`2421`\n-   Update pre-existing headers for ``multipart/form-data`` requests with the test\n    client. :issue:`2549`\n-   Fix handling of header extended parameters such that they are no longer quoted.\n    :issue:`2529`\n-   ``LimitedStream.read`` works correctly when wrapping a stream that may not return\n    the requested size in one ``read`` call. :issue:`2558`\n-   A cookie header that starts with ``=`` is treated as an empty key and discarded,\n    rather than stripping the leading ``==``.\n\n\nVersion 2.2.2\n-------------\n\nReleased 2022-08-08\n\n-   Fix router to restore the 2.1 ``strict_slashes == False`` behaviour\n    whereby leaf-requests match branch rules and vice\n    versa. :pr:`2489`\n-   Fix router to identify invalid rules rather than hang parsing them,\n    and to correctly parse ``/`` within converter arguments. :pr:`2489`\n-   Update subpackage imports in :mod:`werkzeug.routing` to use the\n    ``import as`` syntax for explicitly re-exporting public attributes.\n    :pr:`2493`\n-   Parsing of some invalid header characters is more robust. :pr:`2494`\n-   When starting the development server, a warning not to use it in a\n    production deployment is always shown. :issue:`2480`\n-   ``LocalProxy.__wrapped__`` is always set to the wrapped object when\n    the proxy is unbound, fixing an issue in doctest that would cause it\n    to fail. :issue:`2485`\n-   Address one ``ResourceWarning`` related to the socket used by\n    ``run_simple``. :issue:`2421`\n\n\nVersion 2.2.1\n-------------\n\nReleased 2022-07-27\n\n-   Fix router so that ``/path/`` will match a rule ``/path`` if strict\n    slashes mode is disabled for the rule. :issue:`2467`\n-   Fix router so that partial part matches are not allowed\n    i.e. ``/2df`` does not match ``/<int>``. :pr:`2470`\n-   Fix router static part weighting, so that simpler routes are matched\n    before more complex ones. :issue:`2471`\n-   Restore ``ValidationError`` to be importable from\n    ``werkzeug.routing``. :issue:`2465`\n\n\nVersion 2.2.0\n-------------\n\nReleased 2022-07-23\n\n-   Deprecated ``get_script_name``, ``get_query_string``,\n    ``peek_path_info``, ``pop_path_info``, and\n    ``extract_path_info``. :pr:`2461`\n-   Remove previously deprecated code. :pr:`2461`\n-   Add MarkupSafe as a dependency and use it to escape values when\n    rendering HTML. :issue:`2419`\n-   Added the ``werkzeug.debug.preserve_context`` mechanism for\n    restoring context-local data for a request when running code in the\n    debug console. :pr:`2439`\n-   Fix compatibility with Python 3.11 by ensuring that ``end_lineno``\n    and ``end_col_offset`` are present on AST nodes. :issue:`2425`\n-   Add a new faster URL matching router based on a state machine. If a custom converter\n    needs to match a ``/`` it must set the class variable ``part_isolating = False``.\n    :pr:`2433`\n-   Fix branch leaf path masking branch paths when strict-slashes is\n    disabled. :issue:`1074`\n-   Names within options headers are always converted to lowercase. This\n    matches :rfc:`6266` that the case is not relevant. :issue:`2442`\n-   ``AnyConverter`` validates the value passed for it when building\n    URLs. :issue:`2388`\n-   The debugger shows enhanced error locations in tracebacks in Python\n    3.11. :issue:`2407`\n-   Added Sans-IO ``is_resource_modified`` and ``parse_cookie`` functions\n    based on WSGI versions. :issue:`2408`\n-   Added Sans-IO ``get_content_length`` function. :pr:`2415`\n-   Don't assume a mimetype for test responses. :issue:`2450`\n-   Type checking ``FileStorage`` accepts ``os.PathLike``. :pr:`2418`\n\n\nVersion 2.1.2\n-------------\n\nReleased 2022-04-28\n\n-   The development server does not set ``Transfer-Encoding: chunked``\n    for 1xx, 204, 304, and HEAD responses. :issue:`2375`\n-   Response HTML for exceptions and redirects starts with\n    ``<!doctype html>`` and ``<html lang=en>``. :issue:`2390`\n-   Fix ability to set some ``cache_control`` attributes to ``False``.\n    :issue:`2379`\n-   Disable ``keep-alive`` connections in the development server, which\n    are not supported sufficiently by Python's ``http.server``.\n    :issue:`2397`\n\n\nVersion 2.1.1\n-------------\n\nReleased 2022-04-01\n\n-   ``ResponseCacheControl.s_maxage`` converts its value to an int, like\n    ``max_age``. :issue:`2364`\n\n\nVersion 2.1.0\n-------------\n\nReleased 2022-03-28\n\n-   Drop support for Python 3.6. :pr:`2277`\n-   Using gevent or eventlet requires greenlet>=1.0 or PyPy>=7.3.7.\n    ``werkzeug.locals`` and ``contextvars`` will not work correctly with\n    older versions. :pr:`2278`\n-   Remove previously deprecated code. :pr:`2276`\n\n    -   Remove the non-standard ``shutdown`` function from the WSGI\n        environ when running the development server. See the docs for\n        alternatives.\n    -   Request and response mixins have all been merged into the\n        ``Request`` and ``Response`` classes.\n    -   The user agent parser and the ``useragents`` module is removed.\n        The ``user_agent`` module provides an interface that can be\n        subclassed to add a parser, such as ua-parser. By default it\n        only stores the whole string.\n    -   The test client returns ``TestResponse`` instances and can no\n        longer be treated as a tuple. All data is available as\n        properties on the response.\n    -   Remove ``locals.get_ident`` and related thread-local code from\n        ``locals``, it no longer makes sense when moving to a\n        contextvars-based implementation.\n    -   Remove the ``python -m werkzeug.serving`` CLI.\n    -   The ``has_key`` method on some mapping datastructures; use\n        ``key in data`` instead.\n    -   ``Request.disable_data_descriptor`` is removed, pass\n        ``shallow=True`` instead.\n    -   Remove the ``no_etag`` parameter from ``Response.freeze()``.\n    -   Remove the ``HTTPException.wrap`` class method.\n    -   Remove the ``cookie_date`` function. Use ``http_date`` instead.\n    -   Remove the ``pbkdf2_hex``, ``pbkdf2_bin``, and ``safe_str_cmp``\n        functions. Use equivalents in ``hashlib`` and ``hmac`` modules\n        instead.\n    -   Remove the ``Href`` class.\n    -   Remove the ``HTMLBuilder`` class.\n    -   Remove the ``invalidate_cached_property`` function. Use\n        ``del obj.attr`` instead.\n    -   Remove ``bind_arguments`` and ``validate_arguments``. Use\n        :meth:`Signature.bind` and :func:`inspect.signature` instead.\n    -   Remove ``detect_utf_encoding``, it's built-in to ``json.loads``.\n    -   Remove ``format_string``, use :class:`string.Template` instead.\n    -   Remove ``escape`` and ``unescape``. Use MarkupSafe instead.\n\n-   The ``multiple`` parameter of ``parse_options_header`` is\n    deprecated. :pr:`2357`\n-   Rely on :pep:`538` and :pep:`540` to handle decoding file names\n    with the correct filesystem encoding. The ``filesystem`` module is\n    removed. :issue:`1760`\n-   Default values passed to ``Headers`` are validated the same way\n    values added later are. :issue:`1608`\n-   Setting ``CacheControl`` int properties, such as ``max_age``, will\n    convert the value to an int. :issue:`2230`\n-   Always use ``socket.fromfd`` when restarting the dev server.\n    :pr:`2287`\n-   When passing a dict of URL values to ``Map.build``, list values do\n    not filter out ``None`` or collapse to a single value. Passing a\n    ``MultiDict`` does collapse single items. This undoes a previous\n    change that made it difficult to pass a list, or ``None`` values in\n    a list, to custom URL converters. :issue:`2249`\n-   ``run_simple`` shows instructions for dealing with \"address already\n    in use\" errors, including extra instructions for macOS. :pr:`2321`\n-   Extend list of characters considered always safe in URLs based on\n    :rfc:`3986`. :issue:`2319`\n-   Optimize the stat reloader to avoid watching unnecessary files in\n    more cases. The watchdog reloader is still recommended for\n    performance and accuracy. :issue:`2141`\n-   The development server uses ``Transfer-Encoding: chunked`` for\n    streaming responses when it is configured for HTTP/1.1.\n    :issue:`2090, 1327`, :pr:`2091`\n-   The development server uses HTTP/1.1, which enables keep-alive\n    connections and chunked streaming responses, when ``threaded`` or\n    ``processes`` is enabled. :pr:`2323`\n-   ``cached_property`` works for classes with ``__slots__`` if a\n    corresponding ``_cache_{name}`` slot is added. :pr:`2332`\n-   Refactor the debugger traceback formatter to use Python's built-in\n    ``traceback`` module as much as possible. :issue:`1753`\n-   The ``TestResponse.text`` property is a shortcut for\n    ``r.get_data(as_text=True)``, for convenient testing against text\n    instead of bytes. :pr:`2337`\n-   ``safe_join`` ensures that the path remains relative if the trusted\n    directory is the empty string. :pr:`2349`\n-   Percent-encoded newlines (``%0a``), which are decoded by WSGI\n    servers, are considered when routing instead of terminating the\n    match early. :pr:`2350`\n-   The test client doesn't set duplicate headers for ``CONTENT_LENGTH``\n    and ``CONTENT_TYPE``. :pr:`2348`\n-   ``append_slash_redirect`` handles ``PATH_INFO`` with internal\n    slashes. :issue:`1972`, :pr:`2338`\n-   The default status code for ``append_slash_redirect`` is 308 instead\n    of 301. This preserves the request body, and matches a previous\n    change to ``strict_slashes`` in routing. :issue:`2351`\n-   Fix ``ValueError: I/O operation on closed file.`` with the test\n    client when following more than one redirect. :issue:`2353`\n-   ``Response.autocorrect_location_header`` is disabled by default.\n    The ``Location`` header URL will remain relative, and exclude the\n    scheme and domain, by default. :issue:`2352`\n-   ``Request.get_json()`` will raise a 400 ``BadRequest`` error if the\n    ``Content-Type`` header is not ``application/json``. This makes a\n    very common source of confusion more visible. :issue:`2339`\n\n\nVersion 2.0.3\n-------------\n\nReleased 2022-02-07\n\n-   ``ProxyFix`` supports IPv6 addresses. :issue:`2262`\n-   Type annotation for ``Response.make_conditional``,\n    ``HTTPException.get_response``, and ``Map.bind_to_environ`` accepts\n    ``Request`` in addition to ``WSGIEnvironment`` for the first\n    parameter. :pr:`2290`\n-   Fix type annotation for ``Request.user_agent_class``. :issue:`2273`\n-   Accessing ``LocalProxy.__class__`` and ``__doc__`` on an unbound\n    proxy returns the fallback value instead of a method object.\n    :issue:`2188`\n-   Redirects with the test client set ``RAW_URI`` and ``REQUEST_URI``\n    correctly. :issue:`2151`\n\n\nVersion 2.0.2\n-------------\n\nReleased 2021-10-05\n\n-   Handle multiple tokens in ``Connection`` header when routing\n    WebSocket requests. :issue:`2131`\n-   Set the debugger pin cookie secure flag when on https. :pr:`2150`\n-   Fix type annotation for ``MultiDict.update`` to accept iterable\n    values :pr:`2142`\n-   Prevent double encoding of redirect URL when ``merge_slash=True``\n    for ``Rule.match``. :issue:`2157`\n-   ``CombinedMultiDict.to_dict`` with ``flat=False`` considers all\n    component dicts when building value lists. :issue:`2189`\n-   ``send_file`` only sets a detected ``Content-Encoding`` if\n    ``as_attachment`` is disabled to avoid browsers saving\n    decompressed ``.tar.gz`` files. :issue:`2149`\n-   Fix type annotations for ``TypeConversionDict.get`` to not return an\n    ``Optional`` value if both ``default`` and ``type`` are not\n    ``None``. :issue:`2169`\n-   Fix type annotation for routing rule factories to accept\n    ``Iterable[RuleFactory]`` instead of ``Iterable[Rule]`` for the\n    ``rules`` parameter. :issue:`2183`\n-   Add missing type annotation for ``FileStorage.__getattr__``\n    :issue:`2155`\n-   The debugger pin cookie is set with ``SameSite`` set to ``Strict``\n    instead of ``None`` to be compatible with modern browser security.\n    :issue:`2156`\n-   Type annotations use ``IO[bytes]`` and ``IO[str]`` instead of\n    ``BinaryIO`` and ``TextIO`` for wider type compatibility.\n    :issue:`2130`\n-   Ad-hoc TLS certs are generated with SAN matching CN. :issue:`2158`\n-   Fix memory usage for locals when using Python 3.6 or pre 0.4.17\n    greenlet versions. :pr:`2212`\n-   Fix type annotation in ``CallbackDict``, because it is not\n    utilizing a bound TypeVar. :issue:`2235`\n-   Fix setting CSP header options on the response. :pr:`2237`\n-   Fix an issue with with the interactive debugger where lines would\n    not expand on click for very long tracebacks. :pr:`2239`\n-   The interactive debugger handles displaying an exception that does\n    not have a traceback, such as from ``ProcessPoolExecutor``.\n    :issue:`2217`\n\n\nVersion 2.0.1\n-------------\n\nReleased 2021-05-17\n\n-   Fix type annotation for ``send_file`` ``max_age`` callable. Don't\n    pass ``pathlib.Path`` to ``max_age``. :issue:`2119`\n-   Mark top-level names as exported so type checking understands\n    imports in user projects. :issue:`2122`\n-   Fix some types that weren't available in Python 3.6.0. :issue:`2123`\n-   ``cached_property`` is generic over its return type, properties\n    decorated with it report the correct type. :issue:`2113`\n-   Fix multipart parsing bug when boundary contains special regex\n    characters. :issue:`2125`\n-   Type checking understands that calling ``headers.get`` with a string\n    default will always return a string. :issue:`2128`\n-   If ``HTTPException.description`` is not a string,\n    ``get_description`` will convert it to a string. :issue:`2115`\n\n\nVersion 2.0.0\n-------------\n\nReleased 2021-05-11\n\n-   Drop support for Python 2 and 3.5. :pr:`1693`\n-   Deprecate :func:`utils.format_string`, use :class:`string.Template`\n    instead. :issue:`1756`\n-   Deprecate :func:`utils.bind_arguments` and\n    :func:`utils.validate_arguments`, use :meth:`Signature.bind` and\n    :func:`inspect.signature` instead. :issue:`1757`\n-   Deprecate :class:`utils.HTMLBuilder`. :issue:`1761`\n-   Deprecate :func:`utils.escape` and :func:`utils.unescape`, use\n    MarkupSafe instead. :issue:`1758`\n-   Deprecate the undocumented ``python -m werkzeug.serving`` CLI.\n    :issue:`1834`\n-   Deprecate the ``environ[\"werkzeug.server.shutdown\"]`` function\n    that is available when running the development server. :issue:`1752`\n-   Deprecate the ``useragents`` module and the built-in user agent\n    parser. Use a dedicated parser library instead by subclassing\n    ``user_agent.UserAgent`` and setting ``Request.user_agent_class``.\n    :issue:`2078`\n-   Remove the unused, internal ``posixemulation`` module. :issue:`1759`\n-   All ``datetime`` values are timezone-aware with\n    ``tzinfo=timezone.utc``. This applies to anything using\n    ``http.parse_date``: ``Request.date``, ``.if_modified_since``,\n    ``.if_unmodified_since``; ``Response.date``, ``.expires``,\n    ``.last_modified``, ``.retry_after``; ``parse_if_range_header``, and\n    ``IfRange.date``. When comparing values, the other values must also\n    be aware, or these values must be made naive. When passing\n    parameters or setting attributes, naive values are still assumed to\n    be in UTC. :pr:`2040`\n-   Merge all request and response wrapper mixin code into single\n    ``Request`` and ``Response`` classes. Using the mixin classes is no\n    longer necessary and will show a deprecation warning. Checking\n    ``isinstance`` or ``issubclass`` against ``BaseRequest`` and\n    ``BaseResponse`` will show a deprecation warning and check against\n    ``Request`` or ``Response`` instead. :issue:`1963`\n-   JSON support no longer uses simplejson if it's installed. To use\n    another JSON module, override ``Request.json_module`` and\n    ``Response.json_module``. :pr:`1766`\n-   ``Response.get_json()`` no longer caches the result, and the\n    ``cache`` parameter is removed. :issue:`1698`\n-   ``Response.freeze()`` generates an ``ETag`` header if one is not\n    set. The ``no_etag`` parameter (which usually wasn't visible\n    anyway) is no longer used. :issue:`1963`\n-   Add a ``url_scheme`` argument to :meth:`~routing.MapAdapter.build`\n    to override the bound scheme. :pr:`1721`\n-   Passing an empty list as a query string parameter to ``build()``\n    won't append an unnecessary ``?``. Also drop any number of ``None``\n    items in a list. :issue:`1992`\n-   When passing a ``Headers`` object to a test client method or\n    ``EnvironBuilder``, multiple values for a key are joined into one\n    comma separated value. This matches the HTTP spec on multi-value\n    headers. :issue:`1655`\n-   Setting ``Response.status`` and ``status_code`` uses identical\n    parsing and error checking. :issue:`1658`, :pr:`1728`\n-   ``MethodNotAllowed`` and ``RequestedRangeNotSatisfiable`` take a\n    ``response`` kwarg, consistent with other HTTP errors. :pr:`1748`\n-   The response generated by :exc:`~exceptions.Unauthorized` produces\n    one ``WWW-Authenticate`` header per value in ``www_authenticate``,\n    rather than joining them into a single value, to improve\n    interoperability with browsers and other clients. :pr:`1755`\n-   If ``parse_authorization_header`` can't decode the header value, it\n    returns ``None`` instead of raising a ``UnicodeDecodeError``.\n    :issue:`1816`\n-   The debugger no longer uses jQuery. :issue:`1807`\n-   The test client includes the query string in ``REQUEST_URI`` and\n    ``RAW_URI``. :issue:`1781`\n-   Switch the parameter order of ``default_stream_factory`` to match\n    the order used when calling it. :pr:`1085`\n-   Add ``send_file`` function to generate a response that serves a\n    file. Adapted from Flask's implementation. :issue:`265`, :pr:`1850`\n-   Add ``send_from_directory`` function to safely serve an untrusted\n    path within a trusted directory. Adapted from Flask's\n    implementation. :issue:`1880`\n-   ``send_file`` takes ``download_name``, which is passed even if\n    ``as_attachment=False`` by using ``Content-Disposition: inline``.\n    ``download_name`` replaces Flask's ``attachment_filename``.\n    :issue:`1869`\n-   ``send_file`` sets ``conditional=True`` and ``max_age=None`` by\n    default. ``Cache-Control`` is set to ``no-cache`` if ``max_age`` is\n    not set, otherwise ``public``. This tells browsers to validate\n    conditional requests instead of using a timed cache.\n    ``max_age=None`` replaces Flask's ``cache_timeout=43200``.\n    :issue:`1882`\n-   ``send_file`` can be called with ``etag=\"string\"`` to set a custom\n    ETag instead of generating one. ``etag`` replaces Flask's\n    ``add_etags``. :issue:`1868`\n-   ``send_file`` sets the ``Content-Encoding`` header if an encoding is\n    returned when guessing ``mimetype`` from ``download_name``.\n    :pr:`3896`\n-   Update the defaults used by ``generate_password_hash``. Increase\n    PBKDF2 iterations to 260000 from 150000. Increase salt length to 16\n    from 8. Use ``secrets`` module to generate salt. :pr:`1935`\n-   The reloader doesn't crash if ``sys.stdin`` is somehow ``None``.\n    :pr:`1915`\n-   Add arguments to ``delete_cookie`` to match ``set_cookie`` and the\n    attributes modern browsers expect. :pr:`1889`\n-   ``utils.cookie_date`` is deprecated, use ``utils.http_date``\n    instead. The value for ``Set-Cookie expires`` is no longer \"-\"\n    delimited. :pr:`2040`\n-   Use ``request.headers`` instead of ``request.environ`` to look up\n    header attributes. :pr:`1808`\n-   The test ``Client`` request methods (``client.get``, etc.) always\n    return an instance of ``TestResponse``. In addition to the normal\n    behavior of ``Response``, this class provides ``request`` with the\n    request that produced the response, and ``history`` to track\n    intermediate responses when ``follow_redirects`` is used.\n    :issue:`763, 1894`\n-   The test ``Client`` request methods takes an ``auth`` parameter to\n    add an ``Authorization`` header. It can be an ``Authorization``\n    object or a ``(username, password)`` tuple for ``Basic`` auth.\n    :pr:`1809`\n-   Calling ``response.close()`` on a response from the test ``Client``\n    will close the request input stream. This matches file behavior\n    and can prevent a ``ResourceWarning`` in some cases. :issue:`1785`\n-   ``EnvironBuilder.from_environ`` decodes values encoded for WSGI, to\n    avoid double encoding the new values. :pr:`1959`\n-   The default stat reloader will watch Python files under\n    non-system/virtualenv ``sys.path`` entries, which should contain\n    most user code. It will also watch all Python files under\n    directories given in ``extra_files``. :pr:`1945`\n-   The reloader ignores ``__pycache__`` directories again. :pr:`1945`\n-   ``run_simple`` takes ``exclude_patterns`` a list of ``fnmatch``\n    patterns that will not be scanned by the reloader. :issue:`1333`\n-   Cookie names are no longer unquoted. This was against :rfc:`6265`\n    and potentially allowed setting ``__Secure`` prefixed cookies.\n    :pr:`1965`\n-   Fix some word matches for user agent platform when the word can be a\n    substring. :issue:`1923`\n-   The development server logs ignored SSL errors. :pr:`1967`\n-   Temporary files for form data are opened in ``rb+`` instead of\n    ``wb+`` mode for better compatibility with some libraries.\n    :issue:`1961`\n-   Use SHA-1 instead of MD5 for generating ETags and the debugger pin,\n    and in some tests. MD5 is not available in some environments, such\n    as FIPS 140. This may invalidate some caches since the ETag will be\n    different. :issue:`1897`\n-   Add ``Cross-Origin-Opener-Policy`` and\n    ``Cross-Origin-Embedder-Policy`` response header properties.\n    :pr:`2008`\n-   ``run_simple`` tries to show a valid IP address when binding to all\n    addresses, instead of ``0.0.0.0`` or ``::``. It also warns about not\n    running the development server in production in this case.\n    :issue:`1964`\n-   Colors in the development server log are displayed if Colorama is\n    installed on Windows. For all platforms, style support no longer\n    requires Click. :issue:`1832`\n-   A range request for an empty file (or other data with length 0) will\n    return a 200 response with the empty file instead of a 416 error.\n    :issue:`1937`\n-   New sans-IO base classes for ``Request`` and ``Response`` have been\n    extracted to contain all the behavior that is not WSGI or IO\n    dependent. These are not a public API, they are part of an ongoing\n    refactor to let ASGI frameworks use Werkzeug. :pr:`2005`\n-   Parsing ``multipart/form-data`` has been refactored to use sans-io\n    patterns. This should also make parsing forms with large binary file\n    uploads significantly faster. :issue:`1788, 875`\n-   ``LocalProxy`` matches the current Python data model special\n    methods, including all r-ops, in-place ops, and async. ``__class__``\n    is proxied, so the proxy will look like the object in more cases,\n    including ``isinstance``. Use ``issubclass(type(obj), LocalProxy)``\n    to check if an object is actually a proxy. :issue:`1754`\n-   ``Local`` uses ``ContextVar`` on Python 3.7+ instead of\n    ``threading.local``. :pr:`1778`\n-   ``request.values`` does not include ``form`` for GET requests (even\n    though GET bodies are undefined). This prevents bad caching proxies\n    from caching form data instead of query strings. :pr:`2037`\n-   The development server adds the underlying socket to ``environ`` as\n    ``werkzeug.socket``. This is non-standard and specific to the dev\n    server, other servers may expose this under their own key. It is\n    useful for handling a WebSocket upgrade request. :issue:`2052`\n-   URL matching assumes ``websocket=True`` mode for WebSocket upgrade\n    requests. :issue:`2052`\n-   Updated ``UserAgentParser`` to handle more cases. :issue:`1971`\n-   ``werzeug.DechunkedInput.readinto`` will not read beyond the size of\n    the buffer. :issue:`2021`\n-   Fix connection reset when exceeding max content size. :pr:`2051`\n-   ``pbkdf2_hex``, ``pbkdf2_bin``, and ``safe_str_cmp`` are deprecated.\n    ``hashlib`` and ``hmac`` provide equivalents. :pr:`2083`\n-   ``invalidate_cached_property`` is deprecated. Use ``del obj.name``\n    instead. :pr:`2084`\n-   ``Href`` is deprecated. Use ``werkzeug.routing`` instead.\n    :pr:`2085`\n-   ``Request.disable_data_descriptor`` is deprecated. Create the\n    request with ``shallow=True`` instead. :pr:`2085`\n-   ``HTTPException.wrap`` is deprecated. Create a subclass manually\n    instead. :pr:`2085`\n\n\nVersion 1.0.1\n-------------\n\nReleased 2020-03-31\n\n-   Make the argument to ``RequestRedirect.get_response`` optional.\n    :issue:`1718`\n-   Only allow a single access control allow origin value. :pr:`1723`\n-   Fix crash when trying to parse a non-existent Content Security\n    Policy header. :pr:`1731`\n-   ``http_date`` zero fills years < 1000 to always output four digits.\n    :issue:`1739`\n-   Fix missing local variables in interactive debugger console.\n    :issue:`1746`\n-   Fix passing file-like objects like ``io.BytesIO`` to\n    ``FileStorage.save``. :issue:`1733`\n\n\nVersion 1.0.0\n-------------\n\nReleased 2020-02-06\n\n-   Drop support for Python 3.4. (:issue:`1478`)\n-   Remove code that issued deprecation warnings in version 0.15.\n    (:issue:`1477`)\n-   Remove most top-level attributes provided by the ``werkzeug``\n    module in favor of direct imports. For example, instead of\n    ``import werkzeug; werkzeug.url_quote``, do\n    ``from werkzeug.urls import url_quote``. Install version 0.16 first\n    to see deprecation warnings while upgrading. :issue:`2`, :pr:`1640`\n-   Added ``utils.invalidate_cached_property()`` to invalidate cached\n    properties. (:pr:`1474`)\n-   Directive keys for the ``Set-Cookie`` response header are not\n    ignored when parsing the ``Cookie`` request header. This allows\n    cookies with names such as \"expires\" and \"version\". (:issue:`1495`)\n-   Request cookies are parsed into a ``MultiDict`` to capture all\n    values for cookies with the same key. ``cookies[key]`` returns the\n    first value rather than the last. Use ``cookies.getlist(key)`` to\n    get all values. ``parse_cookie`` also defaults to a ``MultiDict``.\n    :issue:`1562`, :pr:`1458`\n-   Add ``charset=utf-8`` to an HTTP exception response's\n    ``CONTENT_TYPE`` header. (:pr:`1526`)\n-   The interactive debugger handles outer variables in nested scopes\n    such as lambdas and comprehensions. :issue:`913`, :issue:`1037`,\n    :pr:`1532`\n-   The user agent for Opera 60 on Mac is correctly reported as\n    \"opera\" instead of \"chrome\". :issue:`1556`\n-   The platform for Crosswalk on Android is correctly reported as\n    \"android\" instead of \"chromeos\". (:pr:`1572`)\n-   Issue a warning when the current server name does not match the\n    configured server name. :issue:`760`\n-   A configured server name with the default port for a scheme will\n    match the current server name without the port if the current scheme\n    matches. :pr:`1584`\n-   :exc:`~exceptions.InternalServerError` has a ``original_exception``\n    attribute that frameworks can use to track the original cause of the\n    error. :pr:`1590`\n-   Headers are tested for equality independent of the header key case,\n    such that ``X-Foo`` is the same as ``x-foo``. :pr:`1605`\n-   :meth:`http.dump_cookie` accepts ``'None'`` as a value for\n    ``samesite``. :issue:`1549`\n-   :meth:`~test.Client.set_cookie` accepts a ``samesite`` argument.\n    :pr:`1705`\n-   Support the Content Security Policy header through the\n    `Response.content_security_policy` data structure. :pr:`1617`\n-   ``LanguageAccept`` will fall back to matching \"en\" for \"en-US\" or\n    \"en-US\" for \"en\" to better support clients or translations that\n    only match at the primary language tag. :issue:`450`, :pr:`1507`\n-   ``MIMEAccept`` uses MIME parameters for specificity when matching.\n    :issue:`458`, :pr:`1574`\n-   If the development server is started with an ``SSLContext``\n    configured to verify client certificates, the certificate in PEM\n    format will be available as ``environ[\"SSL_CLIENT_CERT\"]``.\n    :pr:`1469`\n-   ``is_resource_modified`` will run for methods other than ``GET`` and\n    ``HEAD``, rather than always returning ``False``. :issue:`409`\n-   ``SharedDataMiddleware`` returns 404 rather than 500 when trying to\n    access a directory instead of a file with the package loader. The\n    dependency on setuptools and pkg_resources is removed.\n    :issue:`1599`\n-   Add a ``response.cache_control.immutable`` flag. Keep in mind that\n    browser support for this ``Cache-Control`` header option is still\n    experimental and may not be implemented. :issue:`1185`\n-   Optional request log highlighting with the development server is\n    handled by Click instead of termcolor. :issue:`1235`\n-   Optional ad-hoc TLS support for the development server is handled\n    by cryptography instead of pyOpenSSL. :pr:`1555`\n-   ``FileStorage.save()`` supports ``pathlib`` and :pep:`519`\n    ``PathLike`` objects. :issue:`1653`\n-   The debugger security pin is unique in containers managed by Podman.\n    :issue:`1661`\n-   Building a URL when ``host_matching`` is enabled takes into account\n    the current host when there are duplicate endpoints with different\n    hosts. :issue:`488`\n-   The ``429 TooManyRequests`` and ``503 ServiceUnavailable`` HTTP\n    exceptions takes a ``retry_after`` parameter to set the\n    ``Retry-After`` header. :issue:`1657`\n-   ``Map`` and ``Rule`` have a ``merge_slashes`` option to collapse\n    multiple slashes into one, similar to how many HTTP servers behave.\n    This is enabled by default. :pr:`1286, 1694`\n-   Add HTTP 103, 208, 306, 425, 506, 508, and 511 to the list of status\n    codes. :pr:`1678`\n-   Add ``update``, ``setlist``, and ``setlistdefault`` methods to the\n    ``Headers`` data structure. ``extend`` method can take ``MultiDict``\n    and kwargs. :pr:`1687, 1697`\n-   The development server accepts paths that start with two slashes,\n    rather than stripping off the first path segment. :issue:`491`\n-   Add access control (Cross Origin Request Sharing, CORS) header\n    properties to the ``Request`` and ``Response`` wrappers. :pr:`1699`\n-   ``Accept`` values are no longer ordered alphabetically for equal\n    quality tags. Instead the initial order is preserved. :issue:`1686`\n-   Added ``Map.lock_class`` attribute for alternative\n    implementations. :pr:`1702`\n-   Support matching and building WebSocket rules in the routing system,\n    for use by async frameworks. :pr:`1709`\n-   Range requests that span an entire file respond with 206 instead of\n    200, to be more compliant with :rfc:`7233`. This may help serving\n    media to older browsers. :issue:`410, 1704`\n-   The :class:`~middleware.shared_data.SharedDataMiddleware` default\n    ``fallback_mimetype`` is ``application/octet-stream``. If a filename\n    looks like a text mimetype, the ``utf-8`` charset is added to it.\n    This matches the behavior of :class:`~wrappers.BaseResponse` and\n    Flask's ``send_file()``. :issue:`1689`\n\n\nVersion 0.16.1\n--------------\n\nReleased 2020-01-27\n\n-   Fix import location in deprecation messages for subpackages.\n    :issue:`1663`\n-   Fix an SSL error on Python 3.5 when the dev server responds with no\n    content. :issue:`1659`\n\n\nVersion 0.16.0\n--------------\n\nReleased 2019-09-19\n\n-   Deprecate most top-level attributes provided by the ``werkzeug``\n    module in favor of direct imports. The deprecated imports will be\n    removed in version 1.0.\n\n    For example, instead of ``import werkzeug; werkzeug.url_quote``, do\n    ``from werkzeug.urls import url_quote``. A deprecation warning will\n    show the correct import to use. ``werkzeug.exceptions`` and\n    ``werkzeug.routing`` should also be imported instead of accessed,\n    but for technical reasons can't show a warning.\n\n    :issue:`2`, :pr:`1640`\n\n\nVersion 0.15.6\n--------------\n\nReleased 2019-09-04\n\n-   Work around a bug in pip that caused the reloader to fail on\n    Windows when the script was an entry point. This fixes the issue\n    with Flask's `flask run` command failing with \"No module named\n    Scripts\\flask\". :issue:`1614`\n-   ``ProxyFix`` trusts the ``X-Forwarded-Proto`` header by default.\n    :issue:`1630`\n-   The deprecated ``num_proxies`` argument to ``ProxyFix`` sets\n    ``x_for``, ``x_proto``, and ``x_host`` to match 0.14 behavior. This\n    is intended to make intermediate upgrades less disruptive, but the\n    argument will still be removed in 1.0. :issue:`1630`\n\n\nVersion 0.15.5\n--------------\n\nReleased 2019-07-17\n\n-   Fix a ``TypeError`` due to changes to ``ast.Module`` in Python 3.8.\n    :issue:`1551`\n-   Fix a C assertion failure in debug builds of some Python 2.7\n    releases. :issue:`1553`\n-   :class:`~exceptions.BadRequestKeyError` adds the ``KeyError``\n    message to the description if ``e.show_exception`` is set to\n    ``True``. This is a more secure default than the original 0.15.0\n    behavior and makes it easier to control without losing information.\n    :pr:`1592`\n-   Upgrade the debugger to jQuery 3.4.1. :issue:`1581`\n-   Work around an issue in some external debuggers that caused the\n    reloader to fail. :issue:`1607`\n-   Work around an issue where the reloader couldn't introspect a\n    setuptools script installed as an egg. :issue:`1600`\n-   The reloader will use ``sys.executable`` even if the script is\n    marked executable, reverting a behavior intended for NixOS\n    introduced in 0.15. The reloader should no longer cause\n    ``OSError: [Errno 8] Exec format error``. :issue:`1482`,\n    :issue:`1580`\n-   ``SharedDataMiddleware`` safely handles paths with Windows drive\n    names. :issue:`1589`\n\n\nVersion 0.15.4\n--------------\n\nReleased 2019-05-14\n\n-   Fix a ``SyntaxError`` on Python 2.7.5. (:issue:`1544`)\n\n\nVersion 0.15.3\n--------------\n\nReleased 2019-05-14\n\n-   Properly handle multi-line header folding in development server in\n    Python 2.7. (:issue:`1080`)\n-   Restore the ``response`` argument to :exc:`~exceptions.Unauthorized`.\n    (:pr:`1527`)\n-   :exc:`~exceptions.Unauthorized` doesn't add the ``WWW-Authenticate``\n    header if ``www_authenticate`` is not given. (:issue:`1516`)\n-   The default URL converter correctly encodes bytes to string rather\n    than representing them with ``b''``. (:issue:`1502`)\n-   Fix the filename format string in\n    :class:`~middleware.profiler.ProfilerMiddleware` to correctly handle\n    float values. (:issue:`1511`)\n-   Update :class:`~middleware.lint.LintMiddleware` to work on Python 3.\n    (:issue:`1510`)\n-   The debugger detects cycles in chained exceptions and does not time\n    out in that case. (:issue:`1536`)\n-   When running the development server in Docker, the debugger security\n    pin is now unique per container.\n\n\nVersion 0.15.2\n--------------\n\nReleased 2019-04-02\n\n-   ``Rule`` code generation uses a filename that coverage will ignore.\n    The previous value, \"generated\", was causing coverage to fail.\n    (:issue:`1487`)\n-   The test client removes the cookie header if there are no persisted\n    cookies. This fixes an issue introduced in 0.15.0 where the cookies\n    from the original request were used for redirects, causing functions\n    such as logout to fail. (:issue:`1491`)\n-   The test client copies the environ before passing it to the app, to\n    prevent in-place modifications from affecting redirect requests.\n    (:issue:`1498`)\n-   The ``\"werkzeug\"`` logger only adds a handler if there is no handler\n    configured for its level in the logging chain. This avoids double\n    logging if other code configures logging first. (:issue:`1492`)\n\n\nVersion 0.15.1\n--------------\n\nReleased 2019-03-21\n\n-   :exc:`~exceptions.Unauthorized` takes ``description`` as the first\n    argument, restoring previous behavior. The new ``www_authenticate``\n    argument is listed second. (:issue:`1483`)\n\n\nVersion 0.15.0\n--------------\n\nReleased 2019-03-19\n\n-   Building URLs is ~7x faster. Each :class:`~routing.Rule` compiles\n    an optimized function for building itself. (:pr:`1281`)\n-   :meth:`MapAdapter.build() <routing.MapAdapter.build>` can be passed\n    a :class:`~datastructures.MultiDict` to represent multiple values\n    for a key. It already did this when passing a dict with a list\n    value. (:pr:`724`)\n-   ``path_info`` defaults to ``'/'`` for\n    :meth:`Map.bind() <routing.Map.bind>`. (:issue:`740`, :pr:`768`,\n    :pr:`1316`)\n-   Change ``RequestRedirect`` code from 301 to 308, preserving the verb\n    and request body (form data) during redirect. (:pr:`1342`)\n-   ``int`` and ``float`` converters in URL rules will handle negative\n    values if passed the ``signed=True`` parameter. For example,\n    ``/jump/<int(signed=True):count>``. (:pr:`1355`)\n-   ``Location`` autocorrection in :func:`Response.get_wsgi_headers()\n    <wrappers.BaseResponse.get_wsgi_headers>` is relative to the current\n    path rather than the root path. (:issue:`693`, :pr:`718`,\n    :pr:`1315`)\n-   412 responses once again include entity headers and an error message\n    in the body. They were originally omitted when implementing\n    ``If-Match`` (:pr:`1233`), but the spec doesn't seem to disallow it.\n    (:issue:`1231`, :pr:`1255`)\n-   The Content-Length header is removed for 1xx and 204 responses. This\n    fixes a previous change where no body would be sent, but the header\n    would still be present. The new behavior matches RFC 7230.\n    (:pr:`1294`)\n-   :class:`~exceptions.Unauthorized` takes a ``www_authenticate``\n    parameter to set the ``WWW-Authenticate`` header for the response,\n    which is technically required for a valid 401 response.\n    (:issue:`772`, :pr:`795`)\n-   Add support for status code 424 :exc:`~exceptions.FailedDependency`.\n    (:pr:`1358`)\n-   :func:`http.parse_cookie` ignores empty segments rather than\n    producing a cookie with no key or value. (:issue:`1245`, :pr:`1301`)\n-   :func:`~http.parse_authorization_header` (and\n    :class:`~datastructures.Authorization`,\n    :attr:`~wrappers.Request.authorization`) treats the authorization\n    header as UTF-8. On Python 2, basic auth username and password are\n    ``unicode``. (:pr:`1325`)\n-   :func:`~http.parse_options_header` understands :rfc:`2231` parameter\n    continuations. (:pr:`1417`)\n-   :func:`~urls.uri_to_iri` does not unquote ASCII characters in the\n    unreserved class, such as space, and leaves invalid bytes quoted\n    when decoding. :func:`~urls.iri_to_uri` does not quote reserved\n    characters. See :rfc:`3987` for these character classes.\n    (:pr:`1433`)\n-   ``get_content_type`` appends a charset for any mimetype that ends\n    with ``+xml``, not just those that start with ``application/``.\n    Known text types such as ``application/javascript`` are also given\n    charsets. (:pr:`1439`)\n-   Clean up ``werkzeug.security`` module, remove outdated hashlib\n    support. (:pr:`1282`)\n-   In :func:`~security.generate_password_hash`, PBKDF2 uses 150000\n    iterations by default, increased from 50000. (:pr:`1377`)\n-   :class:`~wsgi.ClosingIterator` calls ``close`` on the wrapped\n    *iterable*, not the internal iterator. This doesn't affect objects\n    where ``__iter__`` returned ``self``. For other objects, the method\n    was not called before. (:issue:`1259`, :pr:`1260`)\n-   Bytes may be used as keys in :class:`~datastructures.Headers`, they\n    will be decoded as Latin-1 like values are. (:pr:`1346`)\n-   :class:`~datastructures.Range` validates that list of range tuples\n    passed to it would produce a valid ``Range`` header. (:pr:`1412`)\n-   :class:`~datastructures.FileStorage` looks up attributes on\n    ``stream._file`` if they don't exist on ``stream``, working around\n    an issue where :func:`tempfile.SpooledTemporaryFile` didn't\n    implement all of :class:`io.IOBase`. See\n    https://github.com/python/cpython/pull/3249. (:pr:`1409`)\n-   :class:`CombinedMultiDict.copy() <datastructures.CombinedMultiDict>`\n    returns a shallow mutable copy as a\n    :class:`~datastructures.MultiDict`. The copy no longer reflects\n    changes to the combined dicts, but is more generally useful.\n    (:pr:`1420`)\n-   The version of jQuery used by the debugger is updated to 3.3.1.\n    (:pr:`1390`)\n-   The debugger correctly renders long ``markupsafe.Markup`` instances.\n    (:pr:`1393`)\n-   The debugger can serve resources when Werkzeug is installed as a\n    zip file. ``DebuggedApplication.get_resource`` uses\n    ``pkgutil.get_data``. (:pr:`1401`)\n-   The debugger and server log support Python 3's chained exceptions.\n    (:pr:`1396`)\n-   The interactive debugger highlights frames that come from user code\n    to make them easy to pick out in a long stack trace. Note that if an\n    env was created with virtualenv instead of venv, the debugger may\n    incorrectly classify some frames. (:pr:`1421`)\n-   Clicking the error message at the top of the interactive debugger\n    will jump down to the bottom of the traceback. (:pr:`1422`)\n-   When generating a PIN, the debugger will ignore a ``KeyError``\n    raised when the current UID doesn't have an associated username,\n    which can happen in Docker. (:issue:`1471`)\n-   :class:`~exceptions.BadRequestKeyError` adds the ``KeyError``\n    message to the description, making it clearer what caused the 400\n    error. Frameworks like Flask can omit this information in production\n    by setting ``e.args = ()``. (:pr:`1395`)\n-   If a nested ``ImportError`` occurs from :func:`~utils.import_string`\n    the traceback mentions the nested import. Removes an untested code\n    path for handling \"modules not yet set up by the parent.\"\n    (:pr:`735`)\n-   Triggering a reload while using a tool such as PDB no longer hides\n    input. (:pr:`1318`)\n-   The reloader will not prepend the Python executable to the command\n    line if the Python file is marked executable. This allows the\n    reloader to work on NixOS. (:pr:`1242`)\n-   Fix an issue where ``sys.path`` would change between reloads when\n    running with ``python -m app``. The reloader can detect that a\n    module was run with \"-m\" and reconstructs that instead of the file\n    path in ``sys.argv`` when reloading. (:pr:`1416`)\n-   The dev server can bind to a Unix socket by passing a hostname like\n    ``unix://app.socket``. (:pr:`209`, :pr:`1019`)\n-   Server uses ``IPPROTO_TCP`` constant instead of ``SOL_TCP`` for\n    Jython compatibility. (:pr:`1375`)\n-   When using an adhoc SSL cert with :func:`~serving.run_simple`, the\n    cert is shown as self-signed rather than signed by an invalid\n    authority. (:pr:`1430`)\n-   The development server logs the unquoted IRI rather than the raw\n    request line, to make it easier to work with Unicode in request\n    paths during development. (:issue:`1115`)\n-   The development server recognizes ``ConnectionError`` on Python 3 to\n    silence client disconnects, and does not silence other ``OSErrors``\n    that may have been raised inside the application. (:pr:`1418`)\n-   The environ keys ``REQUEST_URI`` and ``RAW_URI`` contain the raw\n    path before it was percent-decoded. This is non-standard, but many\n    WSGI servers add them. Middleware could replace ``PATH_INFO`` with\n    this to route based on the raw value. (:pr:`1419`)\n-   :class:`~test.EnvironBuilder` doesn't set ``CONTENT_TYPE`` or\n    ``CONTENT_LENGTH`` in the environ if they aren't set. Previously\n    these used default values if they weren't set. Now it's possible to\n    distinguish between empty and unset values. (:pr:`1308`)\n-   The test client raises a ``ValueError`` if a query string argument\n    would overwrite a query string in the path. (:pr:`1338`)\n-   :class:`test.EnvironBuilder` and :class:`test.Client` take a\n    ``json`` argument instead of manually passing ``data`` and\n    ``content_type``. This is serialized using the\n    :meth:`test.EnvironBuilder.json_dumps` method. (:pr:`1404`)\n-   :class:`test.Client` redirect handling is rewritten. (:pr:`1402`)\n\n    -   The redirect environ is copied from the initial request environ.\n    -   Script root and path are correctly distinguished when\n        redirecting to a path under the root.\n    -   The HEAD method is not changed to GET.\n    -   307 and 308 codes preserve the method and body. All others\n        ignore the body and related headers.\n    -   Headers are passed to the new request for all codes, following\n        what browsers do.\n    -   :class:`test.EnvironBuilder` sets the content type and length\n        headers in addition to the WSGI keys when detecting them from\n        the data.\n    -   Intermediate response bodies are iterated over even when\n        ``buffered=False`` to ensure iterator middleware can run cleanup\n        code safely. Only the last response is not buffered. (:pr:`988`)\n\n-   :class:`~test.EnvironBuilder`, :class:`~datastructures.FileStorage`,\n    and :func:`wsgi.get_input_stream` no longer share a global\n    ``_empty_stream`` instance. This improves test isolation by\n    preventing cases where closing the stream in one request would\n    affect other usages. (:pr:`1340`)\n-   The default ``SecureCookie.serialization_method`` will change from\n    :mod:`pickle` to :mod:`json` in 1.0. To upgrade existing tokens,\n    override :meth:`~contrib.securecookie.SecureCookie.unquote` to try\n    ``pickle`` if ``json`` fails. (:pr:`1413`)\n-   ``CGIRootFix`` no longer modifies ``PATH_INFO`` for very old\n    versions of Lighttpd. ``LighttpdCGIRootFix`` was renamed to\n    ``CGIRootFix`` in 0.9. Both are deprecated and will be removed in\n    version 1.0. (:pr:`1141`)\n-   :class:`werkzeug.wrappers.json.JSONMixin` has been replaced with\n    Flask's implementation. Check the docs for the full API.\n    (:pr:`1445`)\n-   The contrib modules are deprecated and will either be moved into\n    ``werkzeug`` core or removed completely in version 1.0. Some modules\n    that already issued deprecation warnings have been removed. Be sure\n    to run or test your code with\n    ``python -W default::DeprecationWarning`` to catch any deprecated\n    code you're using. (:issue:`4`)\n\n    -   ``LintMiddleware`` has moved to :mod:`werkzeug.middleware.lint`.\n    -   ``ProfilerMiddleware`` has moved to\n        :mod:`werkzeug.middleware.profiler`.\n    -   ``ProxyFix`` has moved to :mod:`werkzeug.middleware.proxy_fix`.\n    -   ``JSONRequestMixin`` has moved to :mod:`werkzeug.wrappers.json`.\n    -   ``cache`` has been extracted into a separate project,\n        `cachelib <https://github.com/pallets/cachelib>`_. The version\n        in Werkzeug is deprecated.\n    -   ``securecookie`` and ``sessions`` have been extracted into a\n        separate project,\n        `secure-cookie <https://github.com/pallets/secure-cookie>`_. The\n        version in Werkzeug is deprecated.\n    -   Everything in ``fixers``, except ``ProxyFix``, is deprecated.\n    -   Everything in ``wrappers``, except ``JSONMixin``, is deprecated.\n    -   ``atom`` is deprecated. This did not fit in with the rest of\n        Werkzeug, and is better served by a dedicated library in the\n        community.\n    -   ``jsrouting`` is removed. Set URLs when rendering templates\n        or JSON responses instead.\n    -   ``limiter`` is removed. Its specific use is handled by Werkzeug\n        directly, but stream limiting is better handled by the WSGI\n        server in general.\n    -   ``testtools`` is removed. It did not offer significant benefit\n        over the default test client.\n    -   ``iterio`` is deprecated.\n\n-   :func:`wsgi.get_host` no longer looks at ``X-Forwarded-For``. Use\n    :class:`~middleware.proxy_fix.ProxyFix` to handle that.\n    (:issue:`609`, :pr:`1303`)\n-   :class:`~middleware.proxy_fix.ProxyFix` is refactored to support\n    more headers, multiple values, and more secure configuration.\n\n    -   Each header supports multiple values. The trusted number of\n        proxies is configured separately for each header. The\n        ``num_proxies`` argument is deprecated. (:pr:`1314`)\n    -   Sets ``SERVER_NAME`` and ``SERVER_PORT`` based on\n        ``X-Forwarded-Host``. (:pr:`1314`)\n    -   Sets ``SERVER_PORT`` and modifies ``HTTP_HOST`` based on\n        ``X-Forwarded-Port``. (:issue:`1023`, :pr:`1304`)\n    -   Sets ``SCRIPT_NAME`` based on ``X-Forwarded-Prefix``.\n        (:issue:`1237`)\n    -   The original WSGI environment values are stored in the\n        ``werkzeug.proxy_fix.orig`` key, a dict. The individual keys\n        ``werkzeug.proxy_fix.orig_remote_addr``,\n        ``werkzeug.proxy_fix.orig_wsgi_url_scheme``, and\n        ``werkzeug.proxy_fix.orig_http_host`` are deprecated.\n\n-   Middleware from ``werkzeug.wsgi`` has moved to separate modules\n    under ``werkzeug.middleware``, along with the middleware moved from\n    ``werkzeug.contrib``. The old ``werkzeug.wsgi`` imports are\n    deprecated and will be removed in version 1.0. (:pr:`1452`)\n\n    -   ``werkzeug.wsgi.DispatcherMiddleware`` has moved to\n        :class:`werkzeug.middleware.dispatcher.DispatcherMiddleware`.\n    -   ``werkzeug.wsgi.ProxyMiddleware`` as moved to\n        :class:`werkzeug.middleware.http_proxy.ProxyMiddleware`.\n    -   ``werkzeug.wsgi.SharedDataMiddleware`` has moved to\n        :class:`werkzeug.middleware.shared_data.SharedDataMiddleware`.\n\n-   :class:`~middleware.http_proxy.ProxyMiddleware` proxies the query\n    string. (:pr:`1252`)\n-   The filenames generated by\n    :class:`~middleware.profiler.ProfilerMiddleware` can be customized.\n    (:issue:`1283`)\n-   The ``werkzeug.wrappers`` module has been converted to a package,\n    and its various classes have been organized into separate modules.\n    Any previously documented classes, understood to be the existing\n    public API, are still importable from ``werkzeug.wrappers``, or may\n    be imported from their specific modules. (:pr:`1456`)\n\n\nVersion 0.14.1\n--------------\n\nReleased on December 31st 2017\n\n- Resolved a regression with status code handling in the integrated\n  development server.\n\nVersion 0.14\n------------\n\nReleased on December 31st 2017\n\n- HTTP exceptions are now automatically caught by\n  ``Request.application``.\n- Added support for edge as browser.\n- Added support for platforms that lack ``SpooledTemporaryFile``.\n- Add support for etag handling through if-match\n- Added support for the SameSite cookie attribute.\n- Added ``werkzeug.wsgi.ProxyMiddleware``\n- Implemented ``has`` for ``NullCache``\n- ``get_multi`` on cache clients now returns lists all the time.\n- Improved the watchdog observer shutdown for the reloader to not crash\n  on exit on older Python versions.\n- Added support for ``filename*`` filename attributes according to\n  RFC 2231\n- Resolved an issue where machine ID for the reloader PIN was not\n  read accurately on windows.\n- Added a workaround for syntax errors in init files in the reloader.\n- Added support for using the reloader with console scripts on windows.\n- The built-in HTTP server will no longer close a connection in cases\n  where no HTTP body is expected (204, 204, HEAD requests etc.)\n- The ``EnvironHeaders`` object now skips over empty content type and\n  lengths if they are set to falsy values.\n- Werkzeug will no longer send the content-length header on 1xx or\n  204/304 responses.\n- Cookie values are now also permitted to include slashes and equal\n  signs without quoting.\n- Relaxed the regex for the routing converter arguments.\n- If cookies are sent without values they are now assumed to have an\n  empty value and the parser accepts this.  Previously this could have\n  corrupted cookies that followed the value.\n- The test ``Client`` and ``EnvironBuilder`` now support mimetypes like\n  the request object does.\n- Added support for static weights in URL rules.\n- Better handle some more complex reloader scenarios where sys.path\n  contained non directory paths.\n- ``EnvironHeaders`` no longer raises weird errors if non string keys\n  are passed to it.\n\n\nVersion 0.13\n------------\n\nReleased on December 7th 2017\n\n- **Deprecate support for Python 2.6 and 3.3.** CI tests will not run\n  for these versions, and support will be dropped completely in the next\n  version. (:issue:`pallets/meta#24`)\n- Raise ``TypeError`` when port is not an integer. (:pr:`1088`)\n- Fully deprecate ``werkzeug.script``. Use `Click`_ instead.\n  (:pr:`1090`)\n- ``response.age`` is parsed as a ``timedelta``. Previously, it was\n  incorrectly treated as a ``datetime``. The header value is an integer\n  number of seconds, not a date string. (:pr:`414`)\n- Fix a bug in ``TypeConversionDict`` where errors are not propagated\n  when using the converter. (:issue:`1102`)\n- ``Authorization.qop`` is a string instead of a set, to comply with\n  RFC 2617. (:pr:`984`)\n- An exception is raised when an encoded cookie is larger than, by\n  default, 4093 bytes. Browsers may silently ignore cookies larger than\n  this. ``BaseResponse`` has a new attribute ``max_cookie_size`` and\n  ``dump_cookie`` has a new argument ``max_size`` to configure this.\n  (:pr:`780`, :pr:`1109`)\n- Fix a TypeError in ``werkzeug.contrib.lint.GuardedIterator.close``.\n  (:pr:`1116`)\n- ``BaseResponse.calculate_content_length`` now correctly works for\n  Unicode responses on Python 3. It first encodes using\n  ``iter_encoded``. (:issue:`705`)\n- Secure cookie contrib works with string secret key on Python 3.\n  (:pr:`1205`)\n- Shared data middleware accepts a list instead of a dict of static\n  locations to preserve lookup order. (:pr:`1197`)\n- HTTP header values without encoding can contain single quotes.\n  (:pr:`1208`)\n- The built-in dev server supports receiving requests with chunked\n  transfer encoding. (:pr:`1198`)\n\n.. _Click: https://palletsprojects.com/p/click/\n\n\nVersion 0.12.2\n--------------\n\nReleased on May 16 2017\n\n- Fix regression: Pull request ``#892`` prevented Werkzeug from correctly\n  logging the IP of a remote client behind a reverse proxy, even when using\n  `ProxyFix`.\n- Fix a bug in `safe_join` on Windows.\n\nVersion 0.12.1\n--------------\n\nReleased on March 15th 2017\n\n- Fix crash of reloader (used on debug mode) on Windows.\n  (`OSError: [WinError 10038]`). See pull request ``#1081``\n- Partially revert change to class hierarchy of `Headers`. See ``#1084``.\n\nVersion 0.12\n------------\n\nReleased on March 10th 2017\n\n- Spit out big deprecation warnings for werkzeug.script\n- Use `inspect.getfullargspec` internally when available as\n  `inspect.getargspec` is gone in 3.6\n- Added support for status code 451 and 423\n- Improved the build error suggestions.  In particular only if\n  someone stringifies the error will the suggestions be calculated.\n- Added support for uWSGI's caching backend.\n- Fix a bug where iterating over a `FileStorage` would result in an infinite\n  loop.\n- Datastructures now inherit from the relevant baseclasses from the\n  `collections` module in the stdlib. See #794.\n- Add support for recognizing NetBSD, OpenBSD, FreeBSD, DragonFlyBSD platforms\n  in the user agent string.\n- Recognize SeaMonkey browser name and version correctly\n- Recognize Baiduspider, and bingbot user agents\n- If `LocalProxy`'s wrapped object is a function, refer to it with __wrapped__\n  attribute.\n- The defaults of ``generate_password_hash`` have been changed to more secure\n  ones, see pull request ``#753``.\n- Add support for encoding in options header parsing, see pull request\n  ``#933``.\n- ``test.Client`` now properly handles Location headers with relative URLs, see\n  pull request ``#879``.\n- When `HTTPException` is raised, it now prints the description, for easier\n  debugging.\n- Werkzeug's dict-like datastructures now have ``view``-methods under Python 2,\n  see pull request ``#968``.\n- Fix a bug in ``MultiPartParser`` when no ``stream_factory`` was provided\n  during initialization, see pull request ``#973``.\n- Disable autocorrect and spellchecker in the debugger middleware's Python\n  prompt, see pull request ``#994``.\n- Don't redirect to slash route when method doesn't match, see pull request\n  ``#907``.\n- Fix a bug when using ``SharedDataMiddleware`` with frozen packages, see pull\n  request ``#959``.\n- `Range` header parsing function fixed for invalid values ``#974``.\n- Add support for byte Range Requests, see pull request ``#978``.\n- Use modern cryptographic defaults in the dev servers ``#1004``.\n- the post() method of the test client now accept file object through the data\n  parameter.\n- Color run_simple's terminal output based on HTTP codes ``#1013``.\n- Fix self-XSS in debugger console, see ``#1031``.\n- Fix IPython 5.x shell support, see ``#1033``.\n- Change Accept datastructure to sort by specificity first, allowing for more\n  accurate results when using ``best_match`` for mime types (for example in\n  ``requests.accept_mimetypes.best_match``)\n\nVersion 0.11.16\n---------------\n\n- werkzeug.serving: set CONTENT_TYPE / CONTENT_LENGTH if only they're provided by the client\n- werkzeug.serving: Fix crash of reloader when using `python -m werkzeug.serving`.\n\nVersion 0.11.15\n---------------\n\nReleased on December 30th 2016.\n\n- Bugfix for the bugfix in the previous release.\n\nVersion 0.11.14\n---------------\n\nReleased on December 30th 2016.\n\n- Check if platform can fork before importing ``ForkingMixIn``, raise exception\n  when creating ``ForkingWSGIServer`` on such a platform, see PR ``#999``.\n\nVersion 0.11.13\n---------------\n\nReleased on December 26th 2016.\n\n- Correct fix for the reloader issuer on certain Windows installations.\n\nVersion 0.11.12\n---------------\n\nReleased on December 26th 2016.\n\n- Fix more bugs in multidicts regarding empty lists. See ``#1000``.\n- Add some docstrings to some `EnvironBuilder` properties that were previously\n  unintentionally missing.\n- Added a workaround for the reloader on windows.\n\nVersion 0.11.11\n---------------\n\nReleased on August 31st 2016.\n\n- Fix JSONRequestMixin for Python3. See #731\n- Fix broken string handling in test client when passing integers. See #852\n- Fix a bug in ``parse_options_header`` where an invalid content type\n  starting with comma or semi-colon would result in an invalid return value,\n  see issue ``#995``.\n- Fix a bug in multidicts when passing empty lists as values, see issue\n  ``#979``.\n- Fix a security issue that allows XSS on the Werkzeug debugger. See ``#1001``.\n\nVersion 0.11.10\n---------------\n\nReleased on May 24th 2016.\n\n- Fixed a bug that occurs when running on Python 2.6 and using a broken locale.\n  See pull request #912.\n- Fixed a crash when running the debugger on Google App Engine. See issue #925.\n- Fixed an issue with multipart parsing that could cause memory exhaustion.\n\nVersion 0.11.9\n--------------\n\nReleased on April 24th 2016.\n\n- Corrected an issue that caused the debugger not to use the\n  machine GUID on POSIX systems.\n- Corrected a Unicode error on Python 3 for the debugger's\n  PIN usage.\n- Corrected the timestamp verification in the pin debug code.\n  Without this fix the pin was remembered for too long.\n\nVersion 0.11.8\n--------------\n\nReleased on April 15th 2016.\n\n- fixed a problem with the machine GUID detection code on OS X\n  on Python 3.\n\nVersion 0.11.7\n--------------\n\nReleased on April 14th 2016.\n\n- fixed a regression on Python 3 for the debugger.\n\nVersion 0.11.6\n--------------\n\nReleased on April 14th 2016.\n\n- werkzeug.serving: Still show the client address on bad requests.\n- improved the PIN based protection for the debugger to make it harder to\n  brute force via trying cookies.  Please keep in mind that the debugger\n  *is not intended for running on production environments*\n- increased the pin timeout to a week to make it less annoying for people\n  which should decrease the chance that users disable the pin check\n  entirely.\n- werkzeug.serving: Fix broken HTTP_HOST when path starts with double slash.\n\nVersion 0.11.5\n--------------\n\nReleased on March 22nd 2016.\n\n- werkzeug.serving: Fix crash when attempting SSL connection to HTTP server.\n\nVersion 0.11.4\n--------------\n\nReleased on February 14th 2016.\n\n- Fixed werkzeug.serving not working from -m flag.\n- Fixed incorrect weak etag handling.\n\nVersion 0.11.3\n--------------\n\nReleased on December 20th 2015.\n\n- Fixed an issue with copy operations not working against\n  proxies.\n- Changed the logging operations of the development server to\n  correctly log where the server is running in all situations\n  again.\n- Fixed another regression with SSL wrapping similar to the\n  fix in 0.11.2 but for a different code path.\n\nVersion 0.11.2\n--------------\n\nReleased on November 12th 2015.\n\n- Fix inheritable sockets on Windows on Python 3.\n- Fixed an issue with the forking server not starting any longer.\n- Fixed SSL wrapping on platforms that supported opening sockets\n  by file descriptor.\n- No longer log from the watchdog reloader.\n- Unicode errors in hosts are now better caught or converted into\n  bad request errors.\n\nVersion 0.11.1\n--------------\n\nReleased on November 10th 2015.\n\n- Fixed a regression on Python 3 in the debugger.\n\nVersion 0.11\n------------\n\nReleased on November 8th 2015, codename Gleisbaumaschine.\n\n- Added ``reloader_paths`` option to ``run_simple`` and other functions in\n  ``werkzeug.serving``. This allows the user to completely override the Python\n  module watching of Werkzeug with custom paths.\n- Many custom cached properties of Werkzeug's classes are now subclasses of\n  Python's ``property`` type (issue ``#616``).\n- ``bind_to_environ`` now doesn't differentiate between implicit and explicit\n  default port numbers in ``HTTP_HOST`` (pull request ``#204``).\n- ``BuildErrors`` are now more informative. They come with a complete sentence\n  as error message, and also provide suggestions (pull request ``#691``).\n- Fix a bug in the user agent parser where Safari's build number instead of\n  version would be extracted (pull request ``#703``).\n- Fixed issue where RedisCache set_many was broken for twemproxy, which doesn't\n  support the default MULTI command (pull request ``#702``).\n- ``mimetype`` parameters on request and response classes are now always\n  converted to lowercase.\n- Changed cache so that cache never expires if timeout is 0. This also fixes\n  an issue with redis setex (issue ``#550``)\n- Werkzeug now assumes ``UTF-8`` as filesystem encoding on Unix if Python\n  detected it as ASCII.\n- New optional `has` method on caches.\n- Fixed various bugs in `parse_options_header` (pull request ``#643``).\n- If the reloader is enabled the server will now open the socket in the parent\n  process if this is possible.  This means that when the reloader kicks in\n  the connection from client will wait instead of tearing down.  This does\n  not work on all Python versions.\n- Implemented PIN based authentication for the debugger.  This can optionally\n  be disabled but is discouraged.  This change was necessary as it has been\n  discovered that too many people run the debugger in production.\n- Devserver no longer requires SSL module to be installed.\n\nVersion 0.10.5\n--------------\n\n(bugfix release, release date yet to be decided)\n\n- Reloader: Correctly detect file changes made by moving temporary files over\n  the original, which is e.g. the case with PyCharm (pull request ``#722``).\n- Fix bool behavior of ``werkzeug.datastructures.ETags`` under Python 3 (issue\n  ``#744``).\n\nVersion 0.10.4\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Re-release of 0.10.3 with packaging artifacts manually removed.\n\nVersion 0.10.3\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Re-release of 0.10.2 without packaging artifacts.\n\nVersion 0.10.2\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Fixed issue where ``empty`` could break third-party libraries that relied on\n  keyword arguments (pull request ``#675``)\n- Improved ``Rule.empty`` by providing a ```get_empty_kwargs`` to allow setting\n  custom kwargs without having to override entire ``empty`` method. (pull\n  request ``#675``)\n- Fixed ```extra_files``` parameter for reloader to not cause startup\n  to crash when included in server params\n- Using `MultiDict` when building URLs is now not supported again. The behavior\n  introduced several regressions.\n- Fix performance problems with stat-reloader (pull request ``#715``).\n\nVersion 0.10.1\n--------------\n\n(bugfix release, released on February 3rd 2015)\n\n- Fixed regression with multiple query values for URLs (pull request ``#667``).\n- Fix issues with eventlet's monkeypatching and the builtin server (pull\n  request ``#663``).\n\nVersion 0.10\n------------\n\nReleased on January 30th 2015, codename Bagger.\n\n- Changed the error handling of and improved testsuite for the caches in\n  ``contrib.cache``.\n- Fixed a bug on Python 3 when creating adhoc ssl contexts, due to `sys.maxint`\n  not being defined.\n- Fixed a bug on Python 3, that caused\n  :func:`~werkzeug.serving.make_ssl_devcert` to fail with an exception.\n- Added exceptions for 504 and 505.\n- Added support for ChromeOS detection.\n- Added UUID converter to the routing system.\n- Added message that explains how to quit the server.\n- Fixed a bug on Python 2, that caused ``len`` for\n  :class:`werkzeug.datastructures.CombinedMultiDict` to crash.\n- Added support for stdlib pbkdf2 hmac if a compatible digest\n  is found.\n- Ported testsuite to use ``py.test``.\n- Minor optimizations to various middlewares (pull requests ``#496`` and\n  ``#571``).\n- Use stdlib ``ssl`` module instead of ``OpenSSL`` for the builtin server\n  (issue ``#434``). This means that OpenSSL contexts are not supported anymore,\n  but instead ``ssl.SSLContext`` from the stdlib.\n- Allow protocol-relative URLs when building external URLs.\n- Fixed Atom syndication to print time zone offset for tz-aware datetime\n  objects (pull request ``#254``).\n- Improved reloader to track added files and to recover from broken\n  sys.modules setups with syntax errors in packages.\n- ``cache.RedisCache`` now supports arbitrary ``**kwargs`` for the redis\n  object.\n- ``werkzeug.test.Client`` now uses the original request method when resolving\n  307 redirects (pull request ``#556``).\n- ``werkzeug.datastructures.MIMEAccept`` now properly deals with mimetype\n  parameters (pull request ``#205``).\n- ``werkzeug.datastructures.Accept`` now handles a quality of ``0`` as\n  intolerable, as per RFC 2616 (pull request ``#536``).\n- ``werkzeug.urls.url_fix`` now properly encodes hostnames with ``idna``\n  encoding (issue ``#559``). It also doesn't crash on malformed URLs anymore\n  (issue ``#582``).\n- ``werkzeug.routing.MapAdapter.match`` now recognizes the difference between\n  the path ``/`` and an empty one (issue ``#360``).\n- The interactive debugger now tries to decode non-ascii filenames (issue\n  ``#469``).\n- Increased default key size of generated SSL certificates to 1024 bits (issue\n  ``#611``).\n- Added support for specifying a ``Response`` subclass to use when calling\n  :func:`~werkzeug.utils.redirect`\\ .\n- ``werkzeug.test.EnvironBuilder`` now doesn't use the request method anymore\n  to guess the content type, and purely relies on the ``form``, ``files`` and\n  ``input_stream`` properties (issue ``#620``).\n- Added Symbian to the user agent platform list.\n- Fixed make_conditional to respect automatically_set_content_length\n- Unset ``Content-Length`` when writing to response.stream (issue ``#451``)\n- ``wrappers.Request.method`` is now always uppercase, eliminating\n  inconsistencies of the WSGI environment (issue ``647``).\n- ``routing.Rule.empty`` now works correctly with subclasses of ``Rule`` (pull\n  request ``#645``).\n- Made map updating safe in light of concurrent updates.\n- Allow multiple values for the same field for url building (issue ``#658``).\n\nVersion 0.9.7\n-------------\n\n(bugfix release, release date to be decided)\n\n- Fix unicode problems in ``werkzeug.debug.tbtools``.\n- Fix Python 3-compatibility problems in ``werkzeug.posixemulation``.\n- Backport fix of fatal typo for ``ImmutableList`` (issue ``#492``).\n- Make creation of the cache dir for ``FileSystemCache`` atomic (issue\n  ``#468``).\n- Use native strings for memcached keys to work with Python 3 client (issue\n  ``#539``).\n- Fix charset detection for ``werkzeug.debug.tbtools.Frame`` objects (issues\n  ``#547`` and ``#532``).\n- Fix ``AttributeError`` masking in ``werkzeug.utils.import_string`` (issue\n  ``#182``).\n- Explicitly shut down server (issue ``#519``).\n- Fix timeouts greater than 2592000 being misinterpreted as UNIX timestamps in\n  ``werkzeug.contrib.cache.MemcachedCache`` (issue ``#533``).\n- Fix bug where ``werkzeug.exceptions.abort`` would raise an arbitrary subclass\n  of the expected class (issue ``#422``).\n- Fix broken ``jsrouting`` (due to removal of ``werkzeug.templates``)\n- ``werkzeug.urls.url_fix`` now doesn't crash on malformed URLs anymore, but\n  returns them unmodified. This is a cheap workaround for ``#582``, the proper\n  fix is included in version 0.10.\n- The repr of ``werkzeug.wrappers.Request`` doesn't crash on non-ASCII-values\n  anymore (pull request ``#466``).\n- Fix bug in ``cache.RedisCache`` when combined with ``redis.StrictRedis``\n  object (pull request ``#583``).\n- The ``qop`` parameter for ``WWW-Authenticate`` headers is now always quoted,\n  as required by RFC 2617 (issue ``#633``).\n- Fix bug in ``werkzeug.contrib.cache.SimpleCache`` with Python 3 where add/set\n  may throw an exception when pruning old entries from the cache (pull request\n  ``#651``).\n\nVersion 0.9.6\n-------------\n\n(bugfix release, released on June 7th 2014)\n\n- Added a safe conversion for IRI to URI conversion and use that\n  internally to work around issues with spec violations for\n  protocols such as ``itms-service``.\n\nVersion 0.9.7\n-------------\n\n- Fixed uri_to_iri() not re-encoding hashes in query string parameters.\n\nVersion 0.9.5\n-------------\n\n(bugfix release, released on June 7th 2014)\n\n- Forward charset argument from request objects to the environ\n  builder.\n- Fixed error handling for missing boundaries in multipart data.\n- Fixed session creation on systems without ``os.urandom()``.\n- Fixed pluses in dictionary keys not being properly URL encoded.\n- Fixed a problem with deepcopy not working for multi dicts.\n- Fixed a double quoting issue on redirects.\n- Fixed a problem with unicode keys appearing in headers on 2.x.\n- Fixed a bug with unicode strings in the test builder.\n- Fixed a unicode bug on Python 3 in the WSGI profiler.\n- Fixed an issue with the safe string compare function on\n  Python 2.7.7 and Python 3.4.\n\nVersion 0.9.4\n-------------\n\n(bugfix release, released on August 26th 2013)\n\n- Fixed an issue with Python 3.3 and an edge case in cookie parsing.\n- Fixed decoding errors not handled properly through the WSGI\n  decoding dance.\n- Fixed URI to IRI conversion incorrectly decoding percent signs.\n\nVersion 0.9.3\n-------------\n\n(bugfix release, released on July 25th 2013)\n\n- Restored behavior of the ``data`` descriptor of the request class to pre 0.9\n  behavior.  This now also means that ``.data`` and ``.get_data()`` have\n  different behavior.  New code should use ``.get_data()`` always.\n\n  In addition to that there is now a flag for the ``.get_data()`` method that\n  controls what should happen with form data parsing and the form parser will\n  honor cached data.  This makes dealing with custom form data more consistent.\n\nVersion 0.9.2\n-------------\n\n(bugfix release, released on July 18th 2013)\n\n- Added `unsafe` parameter to :func:`~werkzeug.urls.url_quote`.\n- Fixed an issue with :func:`~werkzeug.urls.url_quote_plus` not quoting\n  `'+'` correctly.\n- Ported remaining parts of :class:`~werkzeug.contrib.RedisCache` to\n  Python 3.3.\n- Ported remaining parts of :class:`~werkzeug.contrib.MemcachedCache` to\n  Python 3.3\n- Fixed a deprecation warning in the contrib atom module.\n- Fixed a regression with setting of content types through the\n  headers dictionary instead with the content type parameter.\n- Use correct name for stdlib secure string comparison function.\n- Fixed a wrong reference in the docstring of\n  :func:`~werkzeug.local.release_local`.\n- Fixed an `AttributeError` that sometimes occurred when accessing the\n  :attr:`werkzeug.wrappers.BaseResponse.is_streamed` attribute.\n\nVersion 0.9.1\n-------------\n\n(bugfix release, released on June 14th 2013)\n\n- Fixed an issue with integers no longer being accepted in certain\n  parts of the routing system or URL quoting functions.\n- Fixed an issue with `url_quote` not producing the right escape\n  codes for single digit codepoints.\n- Fixed an issue with :class:`~werkzeug.wsgi.SharedDataMiddleware` not\n  reading the path correctly and breaking on etag generation in some\n  cases.\n- Properly handle `Expect: 100-continue` in the development server\n  to resolve issues with curl.\n- Automatically exhaust the input stream on request close.  This should\n  fix issues where not touching request files results in a timeout.\n- Fixed exhausting of streams not doing anything if a non-limited\n  stream was passed into the multipart parser.\n- Raised the buffer sizes for the multipart parser.\n\nVersion 0.9\n-----------\n\nReleased on June 13nd 2013, codename Planierraupe.\n\n- Added support for :meth:`~werkzeug.wsgi.LimitedStream.tell`\n  on the limited stream.\n- :class:`~werkzeug.datastructures.ETags` now is nonzero if it\n  contains at least one etag of any kind, including weak ones.\n- Added a workaround for a bug in the stdlib for SSL servers.\n- Improved SSL interface of the devserver so that it can generate\n  certificates easily and load them from files.\n- Refactored test client to invoke the open method on the class\n  for redirects.  This makes subclassing more powerful.\n- :func:`werkzeug.wsgi.make_chunk_iter` and\n  :func:`werkzeug.wsgi.make_line_iter` now support processing of\n  iterators and streams.\n- URL generation by the routing system now no longer quotes\n  ``+``.\n- URL fixing now no longer quotes certain reserved characters.\n- The :func:`werkzeug.security.generate_password_hash` and\n  check functions now support any of the hashlib algorithms.\n- `wsgi.get_current_url` is now ascii safe for browsers sending\n  non-ascii data in query strings.\n- improved parsing behavior for :func:`werkzeug.http.parse_options_header`\n- added more operators to local proxies.\n- added a hook to override the default converter in the routing\n  system.\n- The description field of HTTP exceptions is now always escaped.\n  Use markup objects to disable that.\n- Added number of proxy argument to the proxy fix to make it more\n  secure out of the box on common proxy setups.  It will by default\n  no longer trust the x-forwarded-for header as much as it did\n  before.\n- Added support for fragment handling in URI/IRI functions.\n- Added custom class support for :func:`werkzeug.http.parse_dict_header`.\n- Renamed `LighttpdCGIRootFix` to `CGIRootFix`.\n- Always treat `+` as safe when fixing URLs as people love misusing them.\n- Added support to profiling into directories in the contrib profiler.\n- The escape function now by default escapes quotes.\n- Changed repr of exceptions to be less magical.\n- Simplified exception interface to no longer require environments\n  to be passed to receive the response object.\n- Added sentinel argument to IterIO objects.\n- Added pbkdf2 support for the security module.\n- Added a plain request type that disables all form parsing to only\n  leave the stream behind.\n- Removed support for deprecated `fix_headers`.\n- Removed support for deprecated `header_list`.\n- Removed support for deprecated parameter for `iter_encoded`.\n- Removed support for deprecated non-silent usage of the limited\n  stream object.\n- Removed support for previous dummy `writable` parameter on\n  the cached property.\n- Added support for explicitly closing request objects to close\n  associated resources.\n- Conditional request handling or access to the data property on responses no\n  longer ignores direct passthrough mode.\n- Removed werkzeug.templates and werkzeug.contrib.kickstart.\n- Changed host lookup logic for forwarded hosts to allow lists of\n  hosts in which case only the first one is picked up.\n- Added `wsgi.get_query_string`, `wsgi.get_path_info` and\n  `wsgi.get_script_name` and made the `wsgi.pop_path_info` and\n  `wsgi.peek_path_info` functions perform unicode decoding.  This\n  was necessary to avoid having to expose the WSGI encoding dance\n  on Python 3.\n- Added `content_encoding` and `content_md5` to the request object's\n  common request descriptor mixin.\n- added `options` and `trace` to the test client.\n- Overhauled the utilization of the input stream to be easier to use\n  and better to extend.  The detection of content payload on the input\n  side is now more compliant with HTTP by detecting off the content\n  type header instead of the request method.  This also now means that\n  the stream property on the request class is always available instead\n  of just when the parsing fails.\n- Added support for using :class:`werkzeug.wrappers.BaseResponse` in a with\n  statement.\n- Changed `get_app_iter` to fetch the response early so that it does not\n  fail when wrapping a response iterable.  This makes filtering easier.\n- Introduced `get_data` and `set_data` methods for responses.\n- Introduced `get_data` for requests.\n- Soft deprecated the `data` descriptors for request and response objects.\n- Added `as_bytes` operations to some of the headers to simplify working\n  with things like cookies.\n- Made the debugger paste tracebacks into github's gist service as\n  private pastes.\n\nVersion 0.8.4\n-------------\n\n(bugfix release, release date to be announced)\n\n- Added a favicon to the debugger which fixes problem with\n  state changes being triggered through a request to\n  /favicon.ico in Google Chrome.  This should fix some\n  problems with Flask and other frameworks that use\n  context local objects on a stack with context preservation\n  on errors.\n- Fixed an issue with scrolling up in the debugger.\n- Fixed an issue with debuggers running on a different URL\n  than the URL root.\n- Fixed a problem with proxies not forwarding some rarely\n  used special methods properly.\n- Added a workaround to prevent the XSS protection from Chrome\n  breaking the debugger.\n- Skip redis tests if redis is not running.\n- Fixed a typo in the multipart parser that caused content-type\n  to not be picked up properly.\n\nVersion 0.8.3\n-------------\n\n(bugfix release, released on February 5th 2012)\n\n- Fixed another issue with :func:`werkzeug.wsgi.make_line_iter`\n  where lines longer than the buffer size were not handled\n  properly.\n- Restore stdout after debug console finished executing so\n  that the debugger can be used on GAE better.\n- Fixed a bug with the redis cache for int subclasses\n  (affects bool caching).\n- Fixed an XSS problem with redirect targets coming from\n  untrusted sources.\n- Redis cache backend now supports password authentication.\n\nVersion 0.8.2\n-------------\n\n(bugfix release, released on December 16th 2011)\n\n- Fixed a problem with request handling of the builtin server\n  not responding to socket errors properly.\n- The routing request redirect exception's code attribute is now\n  used properly.\n- Fixed a bug with shutdowns on Windows.\n- Fixed a few unicode issues with non-ascii characters being\n  hardcoded in URL rules.\n- Fixed two property docstrings being assigned to fdel instead\n  of ``__doc__``.\n- Fixed an issue where CRLF line endings could be split into two\n  by the line iter function, causing problems with multipart file\n  uploads.\n\nVersion 0.8.1\n-------------\n\n(bugfix release, released on September 30th 2011)\n\n- Fixed an issue with the memcache not working properly.\n- Fixed an issue for Python 2.7.1 and higher that broke\n  copying of multidicts with :func:`copy.copy`.\n- Changed hashing methodology of immutable ordered multi dicts\n  for a potential problem with alternative Python implementations.\n\nVersion 0.8\n-----------\n\nReleased on September 29th 2011, codename L\u00f6tkolben\n\n- Removed data structure specific KeyErrors for a general\n  purpose :exc:`~werkzeug.exceptions.BadRequestKeyError`.\n- Documented :meth:`werkzeug.wrappers.BaseRequest._load_form_data`.\n- The routing system now also accepts strings instead of\n  dictionaries for the `query_args` parameter since we're only\n  passing them through for redirects.\n- Werkzeug now automatically sets the content length immediately when\n  the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute is set\n  for efficiency and simplicity reasons.\n- The routing system will now normalize server names to lowercase.\n- The routing system will no longer raise ValueErrors in case the\n  configuration for the server name was incorrect.  This should make\n  deployment much easier because you can ignore that factor now.\n- Fixed a bug with parsing HTTP digest headers.  It rejected headers\n  with missing nc and nonce params.\n- Proxy fix now also updates wsgi.url_scheme based on X-Forwarded-Proto.\n- Added support for key prefixes to the redis cache.\n- Added the ability to suppress some auto corrections in the wrappers\n  that are now controlled via `autocorrect_location_header` and\n  `automatically_set_content_length` on the response objects.\n- Werkzeug now uses a new method to check that the length of incoming\n  data is complete and will raise IO errors by itself if the server\n  fails to do so.\n- :func:`~werkzeug.wsgi.make_line_iter` now requires a limit that is\n  not higher than the length the stream can provide.\n- Refactored form parsing into a form parser class that makes it possible\n  to hook into individual parts of the parsing process for debugging and\n  extending.\n- For conditional responses the content length is no longer set when it\n  is already there and added if missing.\n- Immutable datastructures are hashable now.\n- Headers datastructure no longer allows newlines in values to avoid\n  header injection attacks.\n- Made it possible through subclassing to select a different remote\n  addr in the proxy fix.\n- Added stream based URL decoding.  This reduces memory usage on large\n  transmitted form data that is URL decoded since Werkzeug will no longer\n  load all the unparsed data into memory.\n- Memcache client now no longer uses the buggy cmemcache module and\n  supports pylibmc.  GAE is not tried automatically and the dedicated\n  class is no longer necessary.\n- Redis cache now properly serializes data.\n- Removed support for Python 2.4\n\nVersion 0.7.2\n-------------\n\n(bugfix release, released on September 30th 2011)\n\n- Fixed a CSRF problem with the debugger.\n- The debugger is now generating private pastes on lodgeit.\n- If URL maps are now bound to environments the query arguments\n  are properly decoded from it for redirects.\n\nVersion 0.7.1\n-------------\n\n(bugfix release, released on July 26th 2011)\n\n- Fixed a problem with newer versions of IPython.\n- Disabled pyinotify based reloader which does not work reliably.\n\nVersion 0.7\n-----------\n\nReleased on July 24th 2011, codename Schraubschl\u00fcssel\n\n- Add support for python-libmemcached to the Werkzeug cache abstraction\n  layer.\n- Improved :func:`url_decode` and :func:`url_encode` performance.\n- Fixed an issue where the SharedDataMiddleware could cause an\n  internal server error on weird paths when loading via pkg_resources.\n- Fixed an URL generation bug that caused URLs to be invalid if a\n  generated component contains a colon.\n- :func:`werkzeug.import_string` now works with partially set up\n  packages properly.\n- Disabled automatic socket switching for IPv6 on the development\n  server due to problems it caused.\n- Werkzeug no longer overrides the Date header when creating a\n  conditional HTTP response.\n- The routing system provides a method to retrieve the matching\n  methods for a given path.\n- The routing system now accepts a parameter to change the encoding\n  error behaviour.\n- The local manager can now accept custom ident functions in the\n  constructor that are forwarded to the wrapped local objects.\n- url_unquote_plus now accepts unicode strings again.\n- Fixed an issue with the filesystem session support's prune\n  function and concurrent usage.\n- Fixed a problem with external URL generation discarding the port.\n- Added support for pylibmc to the Werkzeug cache abstraction layer.\n- Fixed an issue with the new multipart parser that happened when\n  a linebreak happened to be on the chunk limit.\n- Cookies are now set properly if ports are in use.  A runtime error\n  is raised if one tries to set a cookie for a domain without a dot.\n- Fixed an issue with Template.from_file not working for file\n  descriptors.\n- Reloader can now use inotify to track reloads.  This requires the\n  pyinotify library to be installed.\n- Werkzeug debugger can now submit to custom lodgeit installations.\n- redirect function's status code assertion now allows 201 to be used\n  as redirection code.  While it's not a real redirect, it shares\n  enough with redirects for the function to still be useful.\n- Fixed securecookie for pypy.\n- Fixed `ValueErrors` being raised on calls to `best_match` on\n  `MIMEAccept` objects when invalid user data was supplied.\n- Deprecated `werkzeug.contrib.kickstart` and `werkzeug.contrib.testtools`\n- URL routing now can be passed the URL arguments to keep them for\n  redirects.  In the future matching on URL arguments might also be\n  possible.\n- Header encoding changed from utf-8 to latin1 to support a port to\n  Python 3.  Bytestrings passed to the object stay untouched which\n  makes it possible to have utf-8 cookies.  This is a part where\n  the Python 3 version will later change in that it will always\n  operate on latin1 values.\n- Fixed a bug in the form parser that caused the last character to\n  be dropped off if certain values in multipart data are used.\n- Multipart parser now looks at the part-individual content type\n  header to override the global charset.\n- Introduced mimetype and mimetype_params attribute for the file\n  storage object.\n- Changed FileStorage filename fallback logic to skip special filenames\n  that Python uses for marking special files like stdin.\n- Introduced more HTTP exception classes.\n- `call_on_close` now can be used as a decorator.\n- Support for redis as cache backend.\n- Added `BaseRequest.scheme`.\n- Support for the RFC 5789 PATCH method.\n- New custom routing parser and better ordering.\n- Removed support for `is_behind_proxy`.  Use a WSGI middleware\n  instead that rewrites the `REMOTE_ADDR` according to your setup.\n  Also see the :class:`werkzeug.contrib.fixers.ProxyFix` for\n  a drop-in replacement.\n- Added cookie forging support to the test client.\n- Added support for host based matching in the routing system.\n- Switched from the default 'ignore' to the better 'replace'\n  unicode error handling mode.\n- The builtin server now adds a function named 'werkzeug.server.shutdown'\n  into the WSGI env to initiate a shutdown.  This currently only works\n  in Python 2.6 and later.\n- Headers are now assumed to be latin1 for better compatibility with\n  Python 3 once we have support.\n- Added :func:`werkzeug.security.safe_join`.\n- Added `accept_json` property analogous to `accept_html` on the\n  :class:`werkzeug.datastructures.MIMEAccept`.\n- :func:`werkzeug.utils.import_string` now fails with much better\n  error messages that pinpoint to the problem.\n- Added support for parsing of the `If-Range` header\n  (:func:`werkzeug.http.parse_if_range_header` and\n  :class:`werkzeug.datastructures.IfRange`).\n- Added support for parsing of the `Range` header\n  (:func:`werkzeug.http.parse_range_header` and\n  :class:`werkzeug.datastructures.Range`).\n- Added support for parsing of the `Content-Range` header of responses\n  and provided an accessor object for it\n  (:func:`werkzeug.http.parse_content_range_header` and\n  :class:`werkzeug.datastructures.ContentRange`).\n\nVersion 0.6.2\n-------------\n\n(bugfix release, released on April 23th 2010)\n\n- renamed the attribute `implicit_seqence_conversion` attribute of the\n  request object to `implicit_sequence_conversion`.\n\nVersion 0.6.1\n-------------\n\n(bugfix release, released on April 13th 2010)\n\n- heavily improved local objects.  Should pick up standalone greenlet\n  builds now and support proxies to free callables as well.  There is\n  also a stacked local now that makes it possible to invoke the same\n  application from within itself by pushing current request/response\n  on top of the stack.\n- routing build method will also build non-default method rules properly\n  if no method is provided.\n- added proper IPv6 support for the builtin server.\n- windows specific filesystem session store fixes.\n  (should now be more stable under high concurrency)\n- fixed a `NameError` in the session system.\n- fixed a bug with empty arguments in the werkzeug.script system.\n- fixed a bug where log lines will be duplicated if an application uses\n  :meth:`logging.basicConfig` (#499)\n- added secure password hashing and checking functions.\n- `HEAD` is now implicitly added as method in the routing system if\n  `GET` is present.  Not doing that was considered a bug because often\n  code assumed that this is the case and in web servers that do not\n  normalize `HEAD` to `GET` this could break `HEAD` requests.\n- the script support can start SSL servers now.\n\nVersion 0.6\n-----------\n\nReleased on Feb 19th 2010, codename Hammer.\n\n- removed pending deprecations\n- sys.path is now printed from the testapp.\n- fixed an RFC 2068 incompatibility with cookie value quoting.\n- the :class:`FileStorage` now gives access to the multipart headers.\n- `cached_property.writeable` has been deprecated.\n- :meth:`MapAdapter.match` now accepts a `return_rule` keyword argument\n  that returns the matched `Rule` instead of just the `endpoint`\n- :meth:`routing.Map.bind_to_environ` raises a more correct error message\n  now if the map was bound to an invalid WSGI environment.\n- added support for SSL to the builtin development server.\n- Response objects are no longer modified in place when they are evaluated\n  as WSGI applications.  For backwards compatibility the `fix_headers`\n  function is still called in case it was overridden.\n  You should however change your application to use `get_wsgi_headers` if\n  you need header modifications before responses are sent as the backwards\n  compatibility support will go away in future versions.\n- :func:`append_slash_redirect` no longer requires the QUERY_STRING to be\n  in the WSGI environment.\n- added :class:`~werkzeug.contrib.wrappers.DynamicCharsetResponseMixin`\n- added :class:`~werkzeug.contrib.wrappers.DynamicCharsetRequestMixin`\n- added :attr:`BaseRequest.url_charset`\n- request and response objects have a default `__repr__` now.\n- builtin data structures can be pickled now.\n- the form data parser will now look at the filename instead the\n  content type to figure out if it should treat the upload as regular\n  form data or file upload.  This fixes a bug with Google Chrome.\n- improved performance of `make_line_iter` and the multipart parser\n  for binary uploads.\n- fixed :attr:`~werkzeug.BaseResponse.is_streamed`\n- fixed a path quoting bug in `EnvironBuilder` that caused PATH_INFO and\n  SCRIPT_NAME to end up in the environ unquoted.\n- :meth:`werkzeug.BaseResponse.freeze` now sets the content length.\n- for unknown HTTP methods the request stream is now always limited\n  instead of being empty.  This makes it easier to implement DAV\n  and other protocols on top of Werkzeug.\n- added :meth:`werkzeug.MIMEAccept.best_match`\n- multi-value test-client posts from a standard dictionary are now\n  supported.  Previously you had to use a multi dict.\n- rule templates properly work with submounts, subdomains and\n  other rule factories now.\n- deprecated non-silent usage of the :class:`werkzeug.LimitedStream`.\n- added support for IRI handling to many parts of Werkzeug.\n- development server properly logs to the werkzeug logger now.\n- added :func:`werkzeug.extract_path_info`\n- fixed a querystring quoting bug in :func:`url_fix`\n- added `fallback_mimetype` to :class:`werkzeug.SharedDataMiddleware`.\n- deprecated :meth:`BaseResponse.iter_encoded`'s charset parameter.\n- added :meth:`BaseResponse.make_sequence`,\n  :attr:`BaseResponse.is_sequence` and\n  :meth:`BaseResponse._ensure_sequence`.\n- added better __repr__ of :class:`werkzeug.Map`\n- `import_string` accepts unicode strings as well now.\n- development server doesn't break on double slashes after the host name.\n- better `__repr__` and `__str__` of\n  :exc:`werkzeug.exceptions.HTTPException`\n- test client works correctly with multiple cookies now.\n- the :class:`werkzeug.routing.Map` now has a class attribute with\n  the default converter mapping.  This helps subclasses to override\n  the converters without passing them to the constructor.\n- implemented :class:`OrderedMultiDict`\n- improved the session support for more efficient session storing\n  on the filesystem.  Also added support for listing of sessions\n  currently stored in the filesystem session store.\n- werkzeug no longer utilizes the Python time module for parsing\n  which means that dates in a broader range can be parsed.\n- the wrappers have no class attributes that make it possible to\n  swap out the dict and list types it uses.\n- werkzeug debugger should work on the appengine dev server now.\n- the URL builder supports dropping of unexpected arguments now.\n  Previously they were always appended to the URL as query string.\n- profiler now writes to the correct stream.\n\nVersion 0.5.1\n-------------\n(bugfix release for 0.5, released on July 9th 2009)\n\n- fixed boolean check of :class:`FileStorage`\n- url routing system properly supports unicode URL rules now.\n- file upload streams no longer have to provide a truncate()\n  method.\n- implemented :meth:`BaseRequest._form_parsing_failed`.\n- fixed #394\n- :meth:`ImmutableDict.copy`, :meth:`ImmutableMultiDict.copy` and\n  :meth:`ImmutableTypeConversionDict.copy` return mutable shallow\n  copies.\n- fixed a bug with the `make_runserver` script action.\n- :meth:`MultiDict.items` and :meth:`MutiDict.iteritems` now accept an\n  argument to return a pair for each value of each key.\n- the multipart parser works better with hand-crafted multipart\n  requests now that have extra newlines added.  This fixes a bug\n  with setuptools uploads not handled properly (#390)\n- fixed some minor bugs in the atom feed generator.\n- fixed a bug with client cookie header parsing being case sensitive.\n- fixed a not-working deprecation warning.\n- fixed package loading for :class:`SharedDataMiddleware`.\n- fixed a bug in the secure cookie that made server-side expiration\n  on servers with a local time that was not set to UTC impossible.\n- fixed console of the interactive debugger.\n\n\nVersion 0.5\n-----------\n\nReleased on April 24th, codename Schlagbohrer.\n\n- requires Python 2.4 now\n- fixed a bug in :class:`~contrib.IterIO`\n- added :class:`MIMEAccept` and :class:`CharsetAccept` that work like the\n  regular :class:`Accept` but have extra special normalization for mimetypes\n  and charsets and extra convenience methods.\n- switched the serving system from wsgiref to something homebrew.\n- the :class:`Client` now supports cookies.\n- added the :mod:`~werkzeug.contrib.fixers` module with various\n  fixes for webserver bugs and hosting setup side-effects.\n- added :mod:`werkzeug.contrib.wrappers`\n- added :func:`is_hop_by_hop_header`\n- added :func:`is_entity_header`\n- added :func:`remove_hop_by_hop_headers`\n- added :func:`pop_path_info`\n- added :func:`peek_path_info`\n- added :func:`wrap_file` and :class:`FileWrapper`\n- moved `LimitedStream` from the contrib package into the regular\n  werkzeug one and changed the default behavior to raise exceptions\n  rather than stopping without warning.  The old class will stick in\n  the module until 0.6.\n- implemented experimental multipart parser that replaces the old CGI hack.\n- added :func:`dump_options_header` and :func:`parse_options_header`\n- added :func:`quote_header_value` and :func:`unquote_header_value`\n- :func:`url_encode` and :func:`url_decode` now accept a separator\n  argument to switch between `&` and `;` as pair separator.  The magic\n  switch is no longer in place.\n- all form data parsing functions as well as the :class:`BaseRequest`\n  object have parameters (or attributes) to limit the number of\n  incoming bytes (either totally or per field).\n- added :class:`LanguageAccept`\n- request objects are now enforced to be read only for all collections.\n- added many new collection classes, refactored collections in general.\n- test support was refactored, semi-undocumented `werkzeug.test.File`\n  was replaced by :class:`werkzeug.FileStorage`.\n- :class:`EnvironBuilder` was added and unifies the previous distinct\n  :func:`create_environ`, :class:`Client` and\n  :meth:`BaseRequest.from_values`.  They all work the same now which\n  is less confusing.\n- officially documented imports from the internal modules as undefined\n  behavior.  These modules were never exposed as public interfaces.\n- removed `FileStorage.__len__` which previously made the object\n  falsy for browsers not sending the content length which all browsers\n  do.\n- :class:`SharedDataMiddleware` uses `wrap_file` now and has a\n  configurable cache timeout.\n- added :class:`CommonRequestDescriptorsMixin`\n- added :attr:`CommonResponseDescriptorsMixin.mimetype_params`\n- added :mod:`werkzeug.contrib.lint`\n- added `passthrough_errors` to `run_simple`.\n- added `secure_filename`\n- added :func:`make_line_iter`\n- :class:`MultiDict` copies now instead of revealing internal\n  lists to the caller for `getlist` and iteration functions that\n  return lists.\n- added :attr:`follow_redirect` to the :func:`open` of :class:`Client`.\n- added support for `extra_files` in\n  :func:`~werkzeug.script.make_runserver`\n\nVersion 0.4.1\n-------------\n\n(Bugfix release, released on January 11th 2009)\n\n- `werkzeug.contrib.cache.Memcached` accepts now objects that\n  implement the memcache.Client interface as alternative to a list of\n  strings with server addresses.\n  There is also now a `GAEMemcachedCache` that connects to the Google\n  appengine cache.\n- explicitly convert secret keys to bytestrings now because Python\n  2.6 no longer does that.\n- `url_encode` and all interfaces that call it, support ordering of\n  options now which however is disabled by default.\n- the development server no longer resolves the addresses of clients.\n- Fixed a typo in `werkzeug.test` that broke `File`.\n- `Map.bind_to_environ` uses the `Host` header now if available.\n- Fixed `BaseCache.get_dict` (#345)\n- `werkzeug.test.Client` can now run the application buffered in which\n  case the application is properly closed automatically.\n- Fixed `Headers.set` (#354).  Caused header duplication before.\n- Fixed `Headers.pop` (#349).  default parameter was not properly\n  handled.\n- Fixed UnboundLocalError in `create_environ` (#351)\n- `Headers` is more compatible with wsgiref now.\n- `Template.render` accepts multidicts now.\n- dropped support for Python 2.3\n\nVersion 0.4\n-----------\n\nReleased on November 23rd 2008, codename Schraubenzieher.\n\n- `Client` supports an empty `data` argument now.\n- fixed a bug in `Response.application` that made it impossible to use it\n  as method decorator.\n- the session system should work on appengine now\n- the secure cookie works properly in load balanced environments with\n  different cpu architectures now.\n- `CacheControl.no_cache` and `CacheControl.private` behavior changed to\n  reflect the possibilities of the HTTP RFC.  Setting these attributes to\n  `None` or `True` now sets the value to \"the empty value\".\n  More details in the documentation.\n- fixed `werkzeug.contrib.atom.AtomFeed.__call__`. (#338)\n- `BaseResponse.make_conditional` now always returns `self`.  Previously\n  it didn't for post requests and such.\n- fixed a bug in boolean attribute handling of `html` and `xhtml`.\n- added graceful error handling to the debugger pastebin feature.\n- added a more list like interface to `Headers` (slicing and indexing\n  works now)\n- fixed a bug with the `__setitem__` method of `Headers` that didn't\n  properly remove all keys on replacing.\n- added `remove_entity_headers` which removes all entity headers from\n  a list of headers (or a `Headers` object)\n- the responses now automatically call `remove_entity_headers` if the\n  status code is 304.\n- fixed a bug with `Href` query parameter handling.  Previously the last\n  item of a call to `Href` was not handled properly if it was a dict.\n- headers now support a `pop` operation to better work with environ\n  properties.\n\n\nVersion 0.3.1\n-------------\n\n(bugfix release, released on June 24th 2008)\n\n- fixed a security problem with `werkzeug.contrib.SecureCookie`.\n\n\nVersion 0.3\n-----------\n\nReleased on June 14th 2008, codename EUR325CAT6.\n\n- added support for redirecting in url routing.\n- added `Authorization` and `AuthorizationMixin`\n- added `WWWAuthenticate` and `WWWAuthenticateMixin`\n- added `parse_list_header`\n- added `parse_dict_header`\n- added `parse_authorization_header`\n- added `parse_www_authenticate_header`\n- added `_get_current_object` method to `LocalProxy` objects\n- added `parse_form_data`\n- `MultiDict`, `CombinedMultiDict`, `Headers`, and `EnvironHeaders` raise\n  special key errors now that are subclasses of `BadRequest` so if you\n  don't catch them they give meaningful HTTP responses.\n- added support for alternative encoding error handling and the new\n  `HTTPUnicodeError` which (if not caught) behaves like a `BadRequest`.\n- added `BadRequest.wrap`.\n- added ETag support to the SharedDataMiddleware and added an option\n  to disable caching.\n- fixed `is_xhr` on the request objects.\n- fixed error handling of the url adapter's `dispatch` method. (#318)\n- fixed bug with `SharedDataMiddleware`.\n- fixed `Accept.values`.\n- `EnvironHeaders` contain content-type and content-length now\n- `url_encode` treats lists and tuples in dicts passed to it as multiple\n  values for the same key so that one doesn't have to pass a `MultiDict`\n  to the function.\n- added `validate_arguments`\n- added `BaseRequest.application`\n- improved Python 2.3 support\n- `run_simple` accepts `use_debugger` and `use_evalex` parameters now,\n  like the `make_runserver` factory function from the script module.\n- the `environ_property` is now read-only by default\n- it's now possible to initialize requests as \"shallow\" requests which\n  causes runtime errors if the request object tries to consume the\n  input stream.\n\n\nVersion 0.2\n-----------\n\nReleased Feb 14th 2008, codename Faustkeil.\n\n- Added `AnyConverter` to the routing system.\n- Added `werkzeug.contrib.securecookie`\n- Exceptions have a ``get_response()`` method that return a response object\n- fixed the path ordering bug (#293), thanks Thomas Johansson\n- `BaseReporterStream` is now part of the werkzeug contrib module.  From\n  Werkzeug 0.3 onwards you will have to import it from there.\n- added `DispatcherMiddleware`.\n- `RequestRedirect` is now a subclass of `HTTPException` and uses a\n  301 status code instead of 302.\n- `url_encode` and `url_decode` can optionally treat keys as unicode strings\n  now, too.\n- `werkzeug.script` has a different caller format for boolean arguments now.\n- renamed `lazy_property` to `cached_property`.\n- added `import_string`.\n- added is_* properties to request objects.\n- added `empty()` method to routing rules.\n- added `werkzeug.contrib.profiler`.\n- added `extends` to `Headers`.\n- added `dump_cookie` and `parse_cookie`.\n- added `as_tuple` to the `Client`.\n- added `werkzeug.contrib.testtools`.\n- added `werkzeug.unescape`\n- added `BaseResponse.freeze`\n- added `werkzeug.contrib.atom`\n- the HTTPExceptions accept an argument `description` now which overrides the\n  default description.\n- the `MapAdapter` has a default for path info now.  If you use\n  `bind_to_environ` you don't have to pass the path later.\n- the wsgiref subclass werkzeug uses for the dev server does not use direct\n  sys.stderr logging any more but a logger called \"werkzeug\".\n- implemented `Href`.\n- implemented `find_modules`\n- refactored request and response objects into base objects, mixins and\n  full featured subclasses that implement all mixins.\n- added simple user agent parser\n- werkzeug's routing raises `MethodNotAllowed` now if it matches a\n  rule but for a different method.\n- many fixes and small improvements\n\n\nVersion 0.1\n-----------\n\nReleased on Dec 9th 2007, codename Wictorinoxger.\n\n- Initial release\n", "Dealing with Request Data\n=========================\n\n.. currentmodule:: werkzeug\n\nThe most important rule about web development is \"Do not trust the user\".\nThis is especially true for incoming request data on the input stream.\nWith WSGI this is actually a bit harder than you would expect.  Because\nof that Werkzeug wraps the request stream for you to save you from the\nmost prominent problems with it.\n\n\nMissing EOF Marker on Input Stream\n----------------------------------\n\nThe input stream has no end-of-file marker.  If you would call the\n:meth:`~file.read` method on the `wsgi.input` stream you would cause your\napplication to hang on conforming servers.  This is actually intentional\nhowever painful.  Werkzeug solves that problem by wrapping the input\nstream in a special :class:`LimitedStream`.  The input stream is exposed\non the request objects as :attr:`~Request.stream`.  This one is either\nan empty stream (if the form data was parsed) or a limited stream with\nthe contents of the input stream.\n\n\nWhen does Werkzeug Parse?\n-------------------------\n\nWerkzeug parses the incoming data under the following situations:\n\n-   you access either :attr:`~Request.form`, :attr:`~Request.files`,\n    or :attr:`~Request.stream` and the request method was\n    `POST` or `PUT`.\n-   if you call :func:`parse_form_data`.\n\nThese calls are not interchangeable.  If you invoke :func:`parse_form_data`\nyou must not use the request object or at least not the attributes that\ntrigger the parsing process.\n\nThis is also true if you read from the `wsgi.input` stream before the\nparsing.\n\n**General rule:** Leave the WSGI input stream alone.  Especially in\nWSGI middlewares.  Use either the parsing functions or the request\nobject.  Do not mix multiple WSGI utility libraries for form data\nparsing or anything else that works on the input stream.\n\n\nHow does it Parse?\n------------------\n\nThe standard Werkzeug parsing behavior handles three cases:\n\n-   input content type was `multipart/form-data`.  In this situation the\n    :class:`~Request.stream` will be empty and\n    :class:`~Request.form` will contain the regular `POST` / `PUT`\n    data, :class:`~Request.files` will contain the uploaded\n    files as :class:`FileStorage` objects.\n-   input content type was `application/x-www-form-urlencoded`.  Then the\n    :class:`~Request.stream` will be empty and\n    :class:`~Request.form` will contain the regular `POST` / `PUT`\n    data and :class:`~Request.files` will be empty.\n-   the input content type was neither of them, :class:`~Request.stream`\n    points to a :class:`LimitedStream` with the input data for further\n    processing.\n\nSpecial note on the :attr:`~Request.get_data` method: Calling this\nloads the full request data into memory.  This is only safe to do if the\n:attr:`~Request.max_content_length` is set.  Also you can *either*\nread the stream *or* call :meth:`~Request.get_data`.\n\n\nLimiting Request Data\n---------------------\n\nTo avoid being the victim of a DDOS attack you can set the maximum\naccepted content length and request field sizes.  The :class:`Request`\nclass has two attributes for that: :attr:`~Request.max_content_length`\nand :attr:`~Request.max_form_memory_size`.\n\nThe first one can be used to limit the total content length.  For example\nby setting it to ``1024 * 1024 * 16`` the request won't accept more than\n16MB of transmitted data.\n\nBecause certain data can't be moved to the hard disk (regular post data)\nwhereas temporary files can, there is a second limit you can set.  The\n:attr:`~Request.max_form_memory_size` limits the size of `POST`\ntransmitted form data.  By setting it to ``1024 * 1024 * 2`` you can make\nsure that all in memory-stored fields are not more than 2MB in size.\n\nThis however does *not* affect in-memory stored files if the\n`stream_factory` used returns a in-memory file.\n\n\nHow to extend Parsing?\n----------------------\n\nModern web applications transmit a lot more than multipart form data or\nurl encoded data. To extend the capabilities, subclass :class:`Request`\nor :class:`Request` and add or extend methods.\n", "import typing as t\nfrom functools import update_wrapper\nfrom io import BytesIO\nfrom itertools import chain\nfrom typing import Union\n\nfrom . import exceptions\nfrom .datastructures import FileStorage\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartDecoder\nfrom .sansio.multipart import NeedData\nfrom .urls import url_decode_stream\nfrom .wsgi import _make_chunk_iter\nfrom .wsgi import get_content_length\nfrom .wsgi import get_input_stream\n\n# there are some platforms where SpooledTemporaryFile is not available.\n# In that case we need to provide a fallback.\ntry:\n    from tempfile import SpooledTemporaryFile\nexcept ImportError:\n    from tempfile import TemporaryFile\n\n    SpooledTemporaryFile = None  # type: ignore\n\nif t.TYPE_CHECKING:\n    import typing as te\n    from _typeshed.wsgi import WSGIEnvironment\n\n    t_parse_result = t.Tuple[t.IO[bytes], MultiDict, MultiDict]\n\n    class TStreamFactory(te.Protocol):\n        def __call__(\n            self,\n            total_content_length: t.Optional[int],\n            content_type: t.Optional[str],\n            filename: t.Optional[str],\n            content_length: t.Optional[int] = None,\n        ) -> t.IO[bytes]:\n            ...\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef _exhaust(stream: t.IO[bytes]) -> None:\n    bts = stream.read(64 * 1024)\n    while bts:\n        bts = stream.read(64 * 1024)\n\n\ndef default_stream_factory(\n    total_content_length: t.Optional[int],\n    content_type: t.Optional[str],\n    filename: t.Optional[str],\n    content_length: t.Optional[int] = None,\n) -> t.IO[bytes]:\n    max_size = 1024 * 500\n\n    if SpooledTemporaryFile is not None:\n        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))\n    elif total_content_length is None or total_content_length > max_size:\n        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))\n\n    return BytesIO()\n\n\ndef parse_form_data(\n    environ: \"WSGIEnvironment\",\n    stream_factory: t.Optional[\"TStreamFactory\"] = None,\n    charset: str = \"utf-8\",\n    errors: str = \"replace\",\n    max_form_memory_size: t.Optional[int] = None,\n    max_content_length: t.Optional[int] = None,\n    cls: t.Optional[t.Type[MultiDict]] = None,\n    silent: bool = True,\n) -> \"t_parse_result\":\n    \"\"\"Parse the form data in the environ and return it as tuple in the form\n    ``(stream, form, files)``.  You should only call this method if the\n    transport method is `POST`, `PUT`, or `PATCH`.\n\n    If the mimetype of the data transmitted is `multipart/form-data` the\n    files multidict will be filled with `FileStorage` objects.  If the\n    mimetype is unknown the input stream is wrapped and returned as first\n    argument, else the stream is empty.\n\n    This is a shortcut for the common usage of :class:`FormDataParser`.\n\n    Have a look at :doc:`/request_data` for more details.\n\n    .. versionadded:: 0.5\n       The `max_form_memory_size`, `max_content_length` and\n       `cls` parameters were added.\n\n    .. versionadded:: 0.5.1\n       The optional `silent` flag was added.\n\n    :param environ: the WSGI environment to be used for parsing.\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param charset: The character set for URL and url encoded form data.\n    :param errors: The encoding error behavior.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :return: A tuple in the form ``(stream, form, files)``.\n    \"\"\"\n    return FormDataParser(\n        stream_factory,\n        charset,\n        errors,\n        max_form_memory_size,\n        max_content_length,\n        cls,\n        silent,\n    ).parse_from_environ(environ)\n\n\ndef exhaust_stream(f: F) -> F:\n    \"\"\"Helper decorator for methods that exhausts the stream on return.\"\"\"\n\n    def wrapper(self, stream, *args, **kwargs):  # type: ignore\n        try:\n            return f(self, stream, *args, **kwargs)\n        finally:\n            exhaust = getattr(stream, \"exhaust\", None)\n\n            if exhaust is not None:\n                exhaust()\n            else:\n                while True:\n                    chunk = stream.read(1024 * 64)\n\n                    if not chunk:\n                        break\n\n    return update_wrapper(t.cast(F, wrapper), f)\n\n\nclass FormDataParser:\n    \"\"\"This class implements parsing of form data for Werkzeug.  By itself\n    it can parse multipart and url encoded form data.  It can be subclassed\n    and extended but for most mimetypes it is a better idea to use the\n    untouched stream and expose it as separate attributes on a request\n    object.\n\n    .. versionadded:: 0.8\n\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param charset: The character set for URL and url encoded form data.\n    :param errors: The encoding error behavior.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    \"\"\"\n\n    def __init__(\n        self,\n        stream_factory: t.Optional[\"TStreamFactory\"] = None,\n        charset: str = \"utf-8\",\n        errors: str = \"replace\",\n        max_form_memory_size: t.Optional[int] = None,\n        max_content_length: t.Optional[int] = None,\n        cls: t.Optional[t.Type[MultiDict]] = None,\n        silent: bool = True,\n    ) -> None:\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n        self.charset = charset\n        self.errors = errors\n        self.max_form_memory_size = max_form_memory_size\n        self.max_content_length = max_content_length\n\n        if cls is None:\n            cls = MultiDict\n\n        self.cls = cls\n        self.silent = silent\n\n    def get_parse_func(\n        self, mimetype: str, options: t.Dict[str, str]\n    ) -> t.Optional[\n        t.Callable[\n            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],\n            \"t_parse_result\",\n        ]\n    ]:\n        return self.parse_functions.get(mimetype)\n\n    def parse_from_environ(self, environ: \"WSGIEnvironment\") -> \"t_parse_result\":\n        \"\"\"Parses the information from the environment as form data.\n\n        :param environ: the WSGI environment to be used for parsing.\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        content_type = environ.get(\"CONTENT_TYPE\", \"\")\n        content_length = get_content_length(environ)\n        mimetype, options = parse_options_header(content_type)\n        return self.parse(get_input_stream(environ), mimetype, content_length, options)\n\n    def parse(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Optional[t.Dict[str, str]] = None,\n    ) -> \"t_parse_result\":\n        \"\"\"Parses the information from the given stream, mimetype,\n        content length and mimetype parameters.\n\n        :param stream: an input stream\n        :param mimetype: the mimetype of the data\n        :param content_length: the content length of the incoming data\n        :param options: optional mimetype parameters (used for\n                        the multipart boundary for instance)\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        if (\n            self.max_content_length is not None\n            and content_length is not None\n            and content_length > self.max_content_length\n        ):\n            # if the input stream is not exhausted, firefox reports Connection Reset\n            _exhaust(stream)\n            raise exceptions.RequestEntityTooLarge()\n\n        if options is None:\n            options = {}\n\n        parse_func = self.get_parse_func(mimetype, options)\n\n        if parse_func is not None:\n            try:\n                return parse_func(self, stream, mimetype, content_length, options)\n            except ValueError:\n                if not self.silent:\n                    raise\n\n        return stream, self.cls(), self.cls()\n\n    @exhaust_stream\n    def _parse_multipart(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Dict[str, str],\n    ) -> \"t_parse_result\":\n        parser = MultiPartParser(\n            self.stream_factory,\n            self.charset,\n            self.errors,\n            max_form_memory_size=self.max_form_memory_size,\n            cls=self.cls,\n        )\n        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")\n\n        if not boundary:\n            raise ValueError(\"Missing boundary\")\n\n        form, files = parser.parse(stream, boundary, content_length)\n        return stream, form, files\n\n    @exhaust_stream\n    def _parse_urlencoded(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Dict[str, str],\n    ) -> \"t_parse_result\":\n        if (\n            self.max_form_memory_size is not None\n            and content_length is not None\n            and content_length > self.max_form_memory_size\n        ):\n            # if the input stream is not exhausted, firefox reports Connection Reset\n            _exhaust(stream)\n            raise exceptions.RequestEntityTooLarge()\n\n        form = url_decode_stream(stream, self.charset, errors=self.errors, cls=self.cls)\n        return stream, form, self.cls()\n\n    #: mapping of mimetypes to parsing functions\n    parse_functions: t.Dict[\n        str,\n        t.Callable[\n            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],\n            \"t_parse_result\",\n        ],\n    ] = {\n        \"multipart/form-data\": _parse_multipart,\n        \"application/x-www-form-urlencoded\": _parse_urlencoded,\n        \"application/x-url-encoded\": _parse_urlencoded,\n    }\n\n\ndef _line_parse(line: str) -> t.Tuple[str, bool]:\n    \"\"\"Removes line ending characters and returns a tuple (`stripped_line`,\n    `is_terminated`).\n    \"\"\"\n    if line[-2:] == \"\\r\\n\":\n        return line[:-2], True\n\n    elif line[-1:] in {\"\\r\", \"\\n\"}:\n        return line[:-1], True\n\n    return line, False\n\n\nclass MultiPartParser:\n    def __init__(\n        self,\n        stream_factory: t.Optional[\"TStreamFactory\"] = None,\n        charset: str = \"utf-8\",\n        errors: str = \"replace\",\n        max_form_memory_size: t.Optional[int] = None,\n        cls: t.Optional[t.Type[MultiDict]] = None,\n        buffer_size: int = 64 * 1024,\n    ) -> None:\n        self.charset = charset\n        self.errors = errors\n        self.max_form_memory_size = max_form_memory_size\n\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n\n        if cls is None:\n            cls = MultiDict\n\n        self.cls = cls\n\n        self.buffer_size = buffer_size\n\n    def fail(self, message: str) -> \"te.NoReturn\":\n        raise ValueError(message)\n\n    def get_part_charset(self, headers: Headers) -> str:\n        # Figure out input charset for current part\n        content_type = headers.get(\"content-type\")\n\n        if content_type:\n            mimetype, ct_params = parse_options_header(content_type)\n            return ct_params.get(\"charset\", self.charset)\n\n        return self.charset\n\n    def start_file_streaming(\n        self, event: File, total_content_length: t.Optional[int]\n    ) -> t.IO[bytes]:\n        content_type = event.headers.get(\"content-type\")\n\n        try:\n            content_length = int(event.headers[\"content-length\"])\n        except (KeyError, ValueError):\n            content_length = 0\n\n        container = self.stream_factory(\n            total_content_length=total_content_length,\n            filename=event.filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n        return container\n\n    def parse(\n        self, stream: t.IO[bytes], boundary: bytes, content_length: t.Optional[int]\n    ) -> t.Tuple[MultiDict, MultiDict]:\n        container: t.Union[t.IO[bytes], t.List[bytes]]\n        _write: t.Callable[[bytes], t.Any]\n\n        iterator = chain(\n            _make_chunk_iter(\n                stream,\n                limit=content_length,\n                buffer_size=self.buffer_size,\n            ),\n            [None],\n        )\n\n        parser = MultipartDecoder(boundary, self.max_form_memory_size)\n\n        fields = []\n        files = []\n\n        current_part: Union[Field, File]\n        for data in iterator:\n            parser.receive_data(data)\n            event = parser.next_event()\n            while not isinstance(event, (Epilogue, NeedData)):\n                if isinstance(event, Field):\n                    current_part = event\n                    container = []\n                    _write = container.append\n                elif isinstance(event, File):\n                    current_part = event\n                    container = self.start_file_streaming(event, content_length)\n                    _write = container.write\n                elif isinstance(event, Data):\n                    _write(event.data)\n                    if not event.more_data:\n                        if isinstance(current_part, Field):\n                            value = b\"\".join(container).decode(\n                                self.get_part_charset(current_part.headers), self.errors\n                            )\n                            fields.append((current_part.name, value))\n                        else:\n                            container = t.cast(t.IO[bytes], container)\n                            container.seek(0)\n                            files.append(\n                                (\n                                    current_part.name,\n                                    FileStorage(\n                                        container,\n                                        current_part.filename,\n                                        current_part.name,\n                                        headers=current_part.headers,\n                                    ),\n                                )\n                            )\n\n                event = parser.next_event()\n\n        return self.cls(fields), self.cls(files)\n", "import re\nfrom dataclasses import dataclass\nfrom enum import auto\nfrom enum import Enum\nfrom typing import cast\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom .._internal import _to_bytes\nfrom .._internal import _to_str\nfrom ..datastructures import Headers\nfrom ..exceptions import RequestEntityTooLarge\nfrom ..http import parse_options_header\n\n\nclass Event:\n    pass\n\n\n@dataclass(frozen=True)\nclass Preamble(Event):\n    data: bytes\n\n\n@dataclass(frozen=True)\nclass Field(Event):\n    name: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass File(Event):\n    name: str\n    filename: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass Data(Event):\n    data: bytes\n    more_data: bool\n\n\n@dataclass(frozen=True)\nclass Epilogue(Event):\n    data: bytes\n\n\nclass NeedData(Event):\n    pass\n\n\nNEED_DATA = NeedData()\n\n\nclass State(Enum):\n    PREAMBLE = auto()\n    PART = auto()\n    DATA = auto()\n    EPILOGUE = auto()\n    COMPLETE = auto()\n\n\n# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that\n# many implementations break this and either use CR or LF alone.\nLINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"\nBLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)\nLINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)\n# Header values can be continued via a space or tab after the linebreak, as\n# per RFC2231\nHEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)\n# This must be long enough to contain any line breaks plus any\n# additional boundary markers (--) such that they will be found in a\n# subsequent search\nSEARCH_EXTRA_LENGTH = 8\n\n\nclass MultipartDecoder:\n    \"\"\"Decodes a multipart message as bytes into Python events.\n\n    The part data is returned as available to allow the caller to save\n    the data from memory to disk, if desired.\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: bytes,\n        max_form_memory_size: Optional[int] = None,\n    ) -> None:\n        self.buffer = bytearray()\n        self.complete = False\n        self.max_form_memory_size = max_form_memory_size\n        self.state = State.PREAMBLE\n        self.boundary = boundary\n\n        # Note in the below \\h i.e. horizontal whitespace is used\n        # as [^\\S\\n\\r] as \\h isn't supported in python.\n\n        # The preamble must end with a boundary where the boundary is\n        # prefixed by a line break, RFC2046. Except that many\n        # implementations including Werkzeug's tests omit the line\n        # break prefix. In addition the first boundary could be the\n        # epilogue boundary (for empty form-data) hence the matching\n        # group to understand if it is an epilogue boundary.\n        self.preamble_re = re.compile(\n            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        # A boundary must include a line break prefix and suffix, and\n        # may include trailing whitespace. In addition the boundary\n        # could be the epilogue boundary hence the matching group to\n        # understand if it is an epilogue boundary.\n        self.boundary_re = re.compile(\n            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        self._search_position = 0\n\n    def last_newline(self) -> int:\n        try:\n            last_nl = self.buffer.rindex(b\"\\n\")\n        except ValueError:\n            last_nl = len(self.buffer)\n        try:\n            last_cr = self.buffer.rindex(b\"\\r\")\n        except ValueError:\n            last_cr = len(self.buffer)\n\n        return min(last_nl, last_cr)\n\n    def receive_data(self, data: Optional[bytes]) -> None:\n        if data is None:\n            self.complete = True\n        elif (\n            self.max_form_memory_size is not None\n            and len(self.buffer) + len(data) > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n        else:\n            self.buffer.extend(data)\n\n    def next_event(self) -> Event:\n        event: Event = NEED_DATA\n\n        if self.state == State.PREAMBLE:\n            match = self.preamble_re.search(self.buffer, self._search_position)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data = bytes(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n                event = Preamble(data=data)\n                self._search_position = 0\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(\n                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH\n                )\n\n        elif self.state == State.PART:\n            match = BLANK_LINE_RE.search(self.buffer, self._search_position)\n            if match is not None:\n                headers = self._parse_headers(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n\n                if \"content-disposition\" not in headers:\n                    raise ValueError(\"Missing Content-Disposition header\")\n\n                disposition, extra = parse_options_header(\n                    headers[\"content-disposition\"]\n                )\n                name = cast(str, extra.get(\"name\"))\n                filename = extra.get(\"filename\")\n                if filename is not None:\n                    event = File(\n                        filename=filename,\n                        headers=headers,\n                        name=name,\n                    )\n                else:\n                    event = Field(\n                        headers=headers,\n                        name=name,\n                    )\n                self.state = State.DATA\n                self._search_position = 0\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)\n\n        elif self.state == State.DATA:\n            if self.buffer.find(b\"--\" + self.boundary) == -1:\n                # No complete boundary in the buffer, but there may be\n                # a partial boundary at the end. As the boundary\n                # starts with either a nl or cr find the earliest and\n                # return up to that as data.\n                data_length = del_index = self.last_newline()\n                more_data = True\n            else:\n                match = self.boundary_re.search(self.buffer)\n                if match is not None:\n                    if match.group(1).startswith(b\"--\"):\n                        self.state = State.EPILOGUE\n                    else:\n                        self.state = State.PART\n                    data_length = match.start()\n                    del_index = match.end()\n                else:\n                    data_length = del_index = self.last_newline()\n                more_data = match is None\n\n            data = bytes(self.buffer[:data_length])\n            del self.buffer[:del_index]\n            if data or not more_data:\n                event = Data(data=data, more_data=more_data)\n\n        elif self.state == State.EPILOGUE and self.complete:\n            event = Epilogue(data=bytes(self.buffer))\n            del self.buffer[:]\n            self.state = State.COMPLETE\n\n        if self.complete and isinstance(event, NeedData):\n            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")\n\n        return event\n\n    def _parse_headers(self, data: bytes) -> Headers:\n        headers: List[Tuple[str, str]] = []\n        # Merge the continued headers into one line\n        data = HEADER_CONTINUATION_RE.sub(b\" \", data)\n        # Now there is one header per line\n        for line in data.splitlines():\n            if line.strip() != b\"\":\n                name, value = _to_str(line).strip().split(\":\", 1)\n                headers.append((name.strip(), value.strip()))\n        return Headers(headers)\n\n\nclass MultipartEncoder:\n    def __init__(self, boundary: bytes) -> None:\n        self.boundary = boundary\n        self.state = State.PREAMBLE\n\n    def send_event(self, event: Event) -> bytes:\n        if isinstance(event, Preamble) and self.state == State.PREAMBLE:\n            self.state = State.PART\n            return event.data\n        elif isinstance(event, (Field, File)) and self.state in {\n            State.PREAMBLE,\n            State.PART,\n            State.DATA,\n        }:\n            self.state = State.DATA\n            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"\n            data += b'Content-Disposition: form-data; name=\"%s\"' % _to_bytes(event.name)\n            if isinstance(event, File):\n                data += b'; filename=\"%s\"' % _to_bytes(event.filename)\n            data += b\"\\r\\n\"\n            for name, value in cast(Field, event).headers:\n                if name.lower() != \"content-disposition\":\n                    data += _to_bytes(f\"{name}: {value}\\r\\n\")\n            data += b\"\\r\\n\"\n            return data\n        elif isinstance(event, Data) and self.state == State.DATA:\n            return event.data\n        elif isinstance(event, Epilogue):\n            self.state = State.COMPLETE\n            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data\n        else:\n            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")\n", "import functools\nimport json\nimport typing\nimport typing as t\nfrom io import BytesIO\n\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import CombinedMultiDict\nfrom ..datastructures import EnvironHeaders\nfrom ..datastructures import FileStorage\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import iter_multi_items\nfrom ..datastructures import MultiDict\nfrom ..formparser import default_stream_factory\nfrom ..formparser import FormDataParser\nfrom ..sansio.request import Request as _SansIORequest\nfrom ..utils import cached_property\nfrom ..utils import environ_property\nfrom ..wsgi import _get_server\nfrom ..wsgi import get_input_stream\nfrom werkzeug.exceptions import BadRequest\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass Request(_SansIORequest):\n    \"\"\"Represents an incoming WSGI HTTP request, with headers and body\n    taken from the WSGI environment. Has properties and methods for\n    using the functionality defined by various HTTP specs. The data in\n    requests object is read-only.\n\n    Text data is assumed to use UTF-8 encoding, which should be true for\n    the vast majority of modern clients. Using an encoding set by the\n    client is unsafe in Python due to extra encodings it provides, such\n    as ``zip``. To change the assumed encoding, subclass and replace\n    :attr:`charset`.\n\n    :param environ: The WSGI environ is generated by the WSGI server and\n        contains information about the server configuration and client\n        request.\n    :param populate_request: Add this request object to the WSGI environ\n        as ``environ['werkzeug.request']``. Can be useful when\n        debugging.\n    :param shallow: Makes reading from :attr:`stream` (and any method\n        that would read from it) raise a :exc:`RuntimeError`. Useful to\n        prevent consuming the form data in middleware, which would make\n        it unavailable to the final application.\n\n    .. versionchanged:: 2.1\n        Remove the ``disable_data_descriptor`` attribute.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseRequest`` and mixins into a single ``Request``\n        class. Using the old classes is deprecated and will be removed\n        in Werkzeug 2.1.\n\n    .. versionchanged:: 0.5\n        Read-only mode is enforced with immutable classes for all data.\n    \"\"\"\n\n    #: the maximum content length.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: parsing fails because more than the specified value is transmitted\n    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: Have a look at :doc:`/request_data` for more details.\n    #:\n    #: .. versionadded:: 0.5\n    max_content_length: t.Optional[int] = None\n\n    #: the maximum form field size.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: data in memory for post data is longer than the specified value a\n    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: Have a look at :doc:`/request_data` for more details.\n    #:\n    #: .. versionadded:: 0.5\n    max_form_memory_size: t.Optional[int] = None\n\n    #: The form data parser that should be used.  Can be replaced to customize\n    #: the form date parsing.\n    form_data_parser_class: t.Type[FormDataParser] = FormDataParser\n\n    #: The WSGI environment containing HTTP headers and information from\n    #: the WSGI server.\n    environ: \"WSGIEnvironment\"\n\n    #: Set when creating the request object. If ``True``, reading from\n    #: the request body will cause a ``RuntimeException``. Useful to\n    #: prevent modifying the stream from middleware.\n    shallow: bool\n\n    def __init__(\n        self,\n        environ: \"WSGIEnvironment\",\n        populate_request: bool = True,\n        shallow: bool = False,\n    ) -> None:\n        super().__init__(\n            method=environ.get(\"REQUEST_METHOD\", \"GET\"),\n            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),\n            server=_get_server(environ),\n            root_path=_wsgi_decoding_dance(\n                environ.get(\"SCRIPT_NAME\") or \"\", self.charset, self.encoding_errors\n            ),\n            path=_wsgi_decoding_dance(\n                environ.get(\"PATH_INFO\") or \"\", self.charset, self.encoding_errors\n            ),\n            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),\n            headers=EnvironHeaders(environ),\n            remote_addr=environ.get(\"REMOTE_ADDR\"),\n        )\n        self.environ = environ\n        self.shallow = shallow\n\n        if populate_request and not shallow:\n            self.environ[\"werkzeug.request\"] = self\n\n    @classmethod\n    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> \"Request\":\n        \"\"\"Create a new request object based on the values provided.  If\n        environ is given missing values are filled from there.  This method is\n        useful for small scripts when you need to simulate a request from an URL.\n        Do not use this method for unittesting, there is a full featured client\n        object (:class:`Client`) that allows to create multipart requests,\n        support for cookies etc.\n\n        This accepts the same options as the\n        :class:`~werkzeug.test.EnvironBuilder`.\n\n        .. versionchanged:: 0.5\n           This method now accepts the same arguments as\n           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the\n           `environ` parameter is now called `environ_overrides`.\n\n        :return: request object\n        \"\"\"\n        from ..test import EnvironBuilder\n\n        charset = kwargs.pop(\"charset\", cls.charset)\n        kwargs[\"charset\"] = charset\n        builder = EnvironBuilder(*args, **kwargs)\n        try:\n            return builder.get_request(cls)\n        finally:\n            builder.close()\n\n    @classmethod\n    def application(\n        cls, f: t.Callable[[\"Request\"], \"WSGIApplication\"]\n    ) -> \"WSGIApplication\":\n        \"\"\"Decorate a function as responder that accepts the request as\n        the last argument.  This works like the :func:`responder`\n        decorator but the function is passed the request object as the\n        last argument and the request object will be closed\n        automatically::\n\n            @Request.application\n            def my_wsgi_app(request):\n                return Response('Hello World!')\n\n        As of Werkzeug 0.14 HTTP exceptions are automatically caught and\n        converted to responses instead of failing.\n\n        :param f: the WSGI callable to decorate\n        :return: a new WSGI callable\n        \"\"\"\n        #: return a callable that wraps the -2nd argument with the request\n        #: and calls the function with all the arguments up to that one and\n        #: the request.  The return value is then called with the latest\n        #: two arguments.  This makes it possible to use this decorator for\n        #: both standalone WSGI functions as well as bound methods and\n        #: partially applied functions.\n        from ..exceptions import HTTPException\n\n        @functools.wraps(f)\n        def application(*args):  # type: ignore\n            request = cls(args[-2])\n            with request:\n                try:\n                    resp = f(*args[:-2] + (request,))\n                except HTTPException as e:\n                    resp = e.get_response(args[-2])\n                return resp(*args[-2:])\n\n        return t.cast(\"WSGIApplication\", application)\n\n    def _get_file_stream(\n        self,\n        total_content_length: t.Optional[int],\n        content_type: t.Optional[str],\n        filename: t.Optional[str] = None,\n        content_length: t.Optional[int] = None,\n    ) -> t.IO[bytes]:\n        \"\"\"Called to get a stream for the file upload.\n\n        This must provide a file-like class with `read()`, `readline()`\n        and `seek()` methods that is both writeable and readable.\n\n        The default implementation returns a temporary file if the total\n        content length is higher than 500KB.  Because many browsers do not\n        provide a content length for the files only the total content\n        length matters.\n\n        :param total_content_length: the total content length of all the\n                                     data in the request combined.  This value\n                                     is guaranteed to be there.\n        :param content_type: the mimetype of the uploaded file.\n        :param filename: the filename of the uploaded file.  May be `None`.\n        :param content_length: the length of this file.  This value is usually\n                               not provided because webbrowsers do not provide\n                               this value.\n        \"\"\"\n        return default_stream_factory(\n            total_content_length=total_content_length,\n            filename=filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n\n    @property\n    def want_form_data_parsed(self) -> bool:\n        \"\"\"``True`` if the request method carries content. By default\n        this is true if a ``Content-Type`` is sent.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return bool(self.environ.get(\"CONTENT_TYPE\"))\n\n    def make_form_data_parser(self) -> FormDataParser:\n        \"\"\"Creates the form data parser. Instantiates the\n        :attr:`form_data_parser_class` with some parameters.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return self.form_data_parser_class(\n            self._get_file_stream,\n            self.charset,\n            self.encoding_errors,\n            self.max_form_memory_size,\n            self.max_content_length,\n            self.parameter_storage_class,\n        )\n\n    def _load_form_data(self) -> None:\n        \"\"\"Method used internally to retrieve submitted data.  After calling\n        this sets `form` and `files` on the request object to multi dicts\n        filled with the incoming form data.  As a matter of fact the input\n        stream will be empty afterwards.  You can also call this method to\n        force the parsing of the form data.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        # abort early if we have already consumed the stream\n        if \"form\" in self.__dict__:\n            return\n\n        if self.want_form_data_parsed:\n            parser = self.make_form_data_parser()\n            data = parser.parse(\n                self._get_stream_for_parsing(),\n                self.mimetype,\n                self.content_length,\n                self.mimetype_params,\n            )\n        else:\n            data = (\n                self.stream,\n                self.parameter_storage_class(),\n                self.parameter_storage_class(),\n            )\n\n        # inject the values into the instance dict so that we bypass\n        # our cached_property non-data descriptor.\n        d = self.__dict__\n        d[\"stream\"], d[\"form\"], d[\"files\"] = data\n\n    def _get_stream_for_parsing(self) -> t.IO[bytes]:\n        \"\"\"This is the same as accessing :attr:`stream` with the difference\n        that if it finds cached data from calling :meth:`get_data` first it\n        will create a new stream out of the cached data.\n\n        .. versionadded:: 0.9.3\n        \"\"\"\n        cached_data = getattr(self, \"_cached_data\", None)\n        if cached_data is not None:\n            return BytesIO(cached_data)\n        return self.stream\n\n    def close(self) -> None:\n        \"\"\"Closes associated resources of this request object.  This\n        closes all file handles explicitly.  You can also use the request\n        object in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        files = self.__dict__.get(\"files\")\n        for _key, value in iter_multi_items(files or ()):\n            value.close()\n\n    def __enter__(self) -> \"Request\":\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore\n        self.close()\n\n    @cached_property\n    def stream(self) -> t.IO[bytes]:\n        \"\"\"\n        If the incoming form data was not encoded with a known mimetype\n        the data is stored unmodified in this stream for consumption.  Most\n        of the time it is a better idea to use :attr:`data` which will give\n        you that data as a string.  The stream only returns the data once.\n\n        Unlike :attr:`input_stream` this stream is properly guarded that you\n        can't accidentally read past the length of the input.  Werkzeug will\n        internally always refer to this stream to read data which makes it\n        possible to wrap this object with a stream that does filtering.\n\n        .. versionchanged:: 0.9\n           This stream is now always available but might be consumed by the\n           form parser later on.  Previously the stream was only set if no\n           parsing happened.\n        \"\"\"\n        if self.shallow:\n            raise RuntimeError(\n                \"This request was created with 'shallow=True', reading\"\n                \" from the input stream is disabled.\"\n            )\n\n        return get_input_stream(self.environ)\n\n    input_stream = environ_property[t.IO[bytes]](\n        \"wsgi.input\",\n        doc=\"\"\"The WSGI input stream.\n\n        In general it's a bad idea to use this one because you can\n        easily read past the boundary.  Use the :attr:`stream`\n        instead.\"\"\",\n    )\n\n    @cached_property\n    def data(self) -> bytes:\n        \"\"\"\n        Contains the incoming request data as string in case it came with\n        a mimetype Werkzeug does not handle.\n        \"\"\"\n        return self.get_data(parse_form_data=True)\n\n    @typing.overload\n    def get_data(  # type: ignore\n        self,\n        cache: bool = True,\n        as_text: \"te.Literal[False]\" = False,\n        parse_form_data: bool = False,\n    ) -> bytes:\n        ...\n\n    @typing.overload\n    def get_data(\n        self,\n        cache: bool = True,\n        as_text: \"te.Literal[True]\" = ...,\n        parse_form_data: bool = False,\n    ) -> str:\n        ...\n\n    def get_data(\n        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False\n    ) -> t.Union[bytes, str]:\n        \"\"\"This reads the buffered incoming data from the client into one\n        bytes object.  By default this is cached but that behavior can be\n        changed by setting `cache` to `False`.\n\n        Usually it's a bad idea to call this method without checking the\n        content length first as a client could send dozens of megabytes or more\n        to cause memory problems on the server.\n\n        Note that if the form data was already parsed this method will not\n        return anything as form data parsing does not cache the data like\n        this method does.  To implicitly invoke form data parsing function\n        set `parse_form_data` to `True`.  When this is done the return value\n        of this method will be an empty string if the form parser handles\n        the data.  This generally is not necessary as if the whole data is\n        cached (which is the default) the form parser will used the cached\n        data to parse the form data.  Please be generally aware of checking\n        the content length first in any case before calling this method\n        to avoid exhausting server memory.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        rv = getattr(self, \"_cached_data\", None)\n        if rv is None:\n            if parse_form_data:\n                self._load_form_data()\n            rv = self.stream.read()\n            if cache:\n                self._cached_data = rv\n        if as_text:\n            rv = rv.decode(self.charset, self.encoding_errors)\n        return rv\n\n    @cached_property\n    def form(self) -> \"ImmutableMultiDict[str, str]\":\n        \"\"\"The form parameters.  By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        Please keep in mind that file uploads will not end up here, but instead\n        in the :attr:`files` attribute.\n\n        .. versionchanged:: 0.9\n\n            Previous to Werkzeug 0.9 this would only contain form data for POST\n            and PUT requests.\n        \"\"\"\n        self._load_form_data()\n        return self.form\n\n    @cached_property\n    def values(self) -> \"CombinedMultiDict[str, str]\":\n        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that\n        combines :attr:`args` and :attr:`form`.\n\n        For GET requests, only ``args`` are present, not ``form``.\n\n        .. versionchanged:: 2.0\n            For GET requests, only ``args`` are present, not ``form``.\n        \"\"\"\n        sources = [self.args]\n\n        if self.method != \"GET\":\n            # GET requests can have a body, and some caching proxies\n            # might not treat that differently than a normal GET\n            # request, allowing form data to \"invisibly\" affect the\n            # cache without indication in the query string / URL.\n            sources.append(self.form)\n\n        args = []\n\n        for d in sources:\n            if not isinstance(d, MultiDict):\n                d = MultiDict(d)\n\n            args.append(d)\n\n        return CombinedMultiDict(args)\n\n    @cached_property\n    def files(self) -> \"ImmutableMultiDict[str, FileStorage]\":\n        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing\n        all uploaded files.  Each key in :attr:`files` is the name from the\n        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a\n        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.\n\n        It basically behaves like a standard file object you know from Python,\n        with the difference that it also has a\n        :meth:`~werkzeug.datastructures.FileStorage.save` function that can\n        store the file on the filesystem.\n\n        Note that :attr:`files` will only contain data if the request method was\n        POST, PUT or PATCH and the ``<form>`` that posted to the request had\n        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.\n\n        See the :class:`~werkzeug.datastructures.MultiDict` /\n        :class:`~werkzeug.datastructures.FileStorage` documentation for\n        more details about the used data structure.\n        \"\"\"\n        self._load_form_data()\n        return self.files\n\n    @property\n    def script_root(self) -> str:\n        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``\n        without a trailing slash.\n        \"\"\"\n        return self.root_path\n\n    @cached_property\n    def url_root(self) -> str:\n        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and\n        root path. For example, ``https://example.com/app/``.\n        \"\"\"\n        return self.root_url\n\n    remote_user = environ_property[str](\n        \"REMOTE_USER\",\n        doc=\"\"\"If the server supports user authentication, and the\n        script is protected, this attribute contains the username the\n        user has authenticated as.\"\"\",\n    )\n    is_multithread = environ_property[bool](\n        \"wsgi.multithread\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        multithreaded WSGI server.\"\"\",\n    )\n    is_multiprocess = environ_property[bool](\n        \"wsgi.multiprocess\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        WSGI server that spawns multiple processes.\"\"\",\n    )\n    is_run_once = environ_property[bool](\n        \"wsgi.run_once\",\n        doc=\"\"\"boolean that is `True` if the application will be\n        executed only once in a process lifetime.  This is the case for\n        CGI for example, but it's not guaranteed that the execution only\n        happens one time.\"\"\",\n    )\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Optional[t.Any]:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n\n        If the request content type is not ``application/json``, this\n        will raise a 400 Bad Request error.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        return self.get_json()\n\n    # Cached values for ``(silent=False, silent=True)``. Initialized\n    # with sentinel values.\n    _cached_json: t.Tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: \"te.Literal[False]\" = ..., cache: bool = ...\n    ) -> t.Any:\n        ...\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: bool = ..., cache: bool = ...\n    ) -> t.Optional[t.Any]:\n        ...\n\n    def get_json(\n        self, force: bool = False, silent: bool = False, cache: bool = True\n    ) -> t.Optional[t.Any]:\n        \"\"\"Parse :attr:`data` as JSON.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), or parsing\n        fails, :meth:`on_json_loading_failed` is called and\n        its return value is used as the return value. By default this\n        raises a 400 Bad Request error.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence mimetype and parsing errors, and\n            return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent\n            calls.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        if cache and self._cached_json[silent] is not Ellipsis:\n            return self._cached_json[silent]\n\n        if not (force or self.is_json):\n            if not silent:\n                return self.on_json_loading_failed(None)\n            else:\n                return None\n\n        data = self.get_data(cache=cache)\n\n        try:\n            rv = self.json_module.loads(data)\n        except ValueError as e:\n            if silent:\n                rv = None\n\n                if cache:\n                    normal_rv, _ = self._cached_json\n                    self._cached_json = (normal_rv, rv)\n            else:\n                rv = self.on_json_loading_failed(e)\n\n                if cache:\n                    _, silent_rv = self._cached_json\n                    self._cached_json = (rv, silent_rv)\n        else:\n            if cache:\n                self._cached_json = (rv, rv)\n\n        return rv\n\n    def on_json_loading_failed(self, e: t.Optional[ValueError]) -> t.Any:\n        \"\"\"Called if :meth:`get_json` fails and isn't silenced.\n\n        If this method returns a value, it is used as the return value\n        for :meth:`get_json`. The default implementation raises\n        :exc:`~werkzeug.exceptions.BadRequest`.\n\n        :param e: If parsing failed, this is the exception. It will be\n            ``None`` if the content type wasn't ``application/json``.\n        \"\"\"\n        if e is not None:\n            raise BadRequest(f\"Failed to decode JSON object: {e}\")\n\n        raise BadRequest(\n            \"Did not attempt to load JSON data because the request\"\n            \" Content-Type was not 'application/json'.\"\n        )\n", "import csv\nimport io\nfrom os.path import dirname\nfrom os.path import join\n\nimport pytest\n\nfrom werkzeug import formparser\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.exceptions import RequestEntityTooLarge\nfrom werkzeug.formparser import FormDataParser\nfrom werkzeug.formparser import parse_form_data\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef form_data_consumer(request):\n    result_object = request.args[\"object\"]\n    if result_object == \"text\":\n        return Response(repr(request.form[\"text\"]))\n    f = request.files[result_object]\n    return Response(\n        b\"\\n\".join(\n            (\n                repr(f.filename).encode(\"ascii\"),\n                repr(f.name).encode(\"ascii\"),\n                repr(f.content_type).encode(\"ascii\"),\n                f.stream.read(),\n            )\n        )\n    )\n\n\ndef get_contents(filename):\n    with open(filename, \"rb\") as f:\n        return f.read()\n\n\nclass TestFormParser:\n    def test_limiting(self):\n        data = b\"foo=Hello+World&bar=baz\"\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 4\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        # when the request entity is too large, the input stream should be\n        # drained so that firefox (and others) do not report connection reset\n        # when run through gunicorn\n        # a sufficiently large stream is necessary for block-based reads\n        input_stream = io.BytesIO(b\"foo=\" + b\"x\" * 128 * 1024)\n        req = Request.from_values(\n            input_stream=input_stream,\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 4\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n        # ensure that the stream is exhausted\n        assert input_stream.read() == b\"\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n    def test_missing_multipart_boundary(self):\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data\",\n            method=\"POST\",\n        )\n        assert req.form == {}\n\n    def test_parse_form_data_put_without_content(self):\n        # A PUT without a Content-Type header returns empty data\n\n        # Both rfc1945 and rfc2616 (1.0 and 1.1) say \"Any HTTP/[1.0/1.1] message\n        # containing an entity-body SHOULD include a Content-Type header field\n        # defining the media type of that body.\"  In the case where either\n        # headers are omitted, parse_form_data should still work.\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"PUT\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    def test_parse_form_data_get_without_content(self):\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"GET\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    @pytest.mark.parametrize(\n        (\"no_spooled\", \"size\"), ((False, 100), (False, 3000), (True, 100), (True, 3000))\n    )\n    def test_default_stream_factory(self, no_spooled, size, monkeypatch):\n        if no_spooled:\n            monkeypatch.setattr(\"werkzeug.formparser.SpooledTemporaryFile\", None)\n\n        data = b\"a,b,c\\n\" * size\n        with Request.from_values(\n            data={\"foo\": (io.BytesIO(data), \"test.txt\")}, method=\"POST\"\n        ) as req:\n            reader = csv.reader(io.TextIOWrapper(req.files[\"foo\"]))\n            # This fails if file_storage doesn't implement IOBase.\n            # https://github.com/pallets/werkzeug/issues/1344\n            # https://github.com/python/cpython/pull/3249\n            assert sum(1 for _ in reader) == size\n\n    def test_parse_bad_content_type(self):\n        parser = FormDataParser()\n        assert parser.parse(\"\", \"bad-mime-type\", 0) == (\n            \"\",\n            MultiDict([]),\n            MultiDict([]),\n        )\n\n    def test_parse_from_environ(self):\n        parser = FormDataParser()\n        stream, _, _ = parser.parse_from_environ({\"wsgi.input\": \"\"})\n        assert stream is not None\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\nclass TestMultiPart:\n    def test_basic(self):\n        resources = join(dirname(__file__), \"multipart\")\n        client = Client(form_data_consumer)\n\n        repository = [\n            (\n                \"firefox3-2png1txt\",\n                \"---------------------------186454651713519341951581030105\",\n                [\n                    (\"anchor.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"application_edit.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"example text\",\n            ),\n            (\n                \"firefox3-2pnglongtext\",\n                \"---------------------------14904044739787191031754711748\",\n                [\n                    (\"accept.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"add.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"--long text\\r\\n--with boundary\\r\\n--lookalikes--\",\n            ),\n            (\n                \"opera8-2png1txt\",\n                \"----------zEO9jQKmLc2Cq88c23Dx19\",\n                [\n                    (\"arrow_branch.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"award_star_bronze_1.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"blafasel \u00f6\u00e4\u00fc\",\n            ),\n            (\n                \"webkit3-2png1txt\",\n                \"----WebKitFormBoundaryjdSFhcARk8fyGNy6\",\n                [\n                    (\"gtk-apply.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"gtk-no.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"this is another text with \u00fcml\u00e4\u00fcts\",\n            ),\n            (\n                \"ie6-2png1txt\",\n                \"---------------------------7d91b03a20128\",\n                [\n                    (\"file1.png\", \"file1\", \"image/x-png\", \"file1.png\"),\n                    (\"file2.png\", \"file2\", \"image/x-png\", \"file2.png\"),\n                ],\n                \"ie6 sucks :-/\",\n            ),\n        ]\n\n        for name, boundary, files, text in repository:\n            folder = join(resources, name)\n            data = get_contents(join(folder, \"request.http\"))\n            for filename, field, content_type, fsname in files:\n                with client.post(\n                    f\"/?object={field}\",\n                    data=data,\n                    content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                    content_length=len(data),\n                ) as response:\n                    lines = response.get_data().split(b\"\\n\", 3)\n                    assert lines[0] == repr(filename).encode(\"ascii\")\n                    assert lines[1] == repr(field).encode(\"ascii\")\n                    assert lines[2] == repr(content_type).encode(\"ascii\")\n                    assert lines[3] == get_contents(join(folder, fsname))\n\n            with client.post(\n                \"/?object=text\",\n                data=data,\n                content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                content_length=len(data),\n            ) as response:\n                assert response.get_data() == repr(text).encode(\"utf-8\")\n\n    @pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n    def test_ie7_unc_path(self):\n        client = Client(form_data_consumer)\n        data_file = join(dirname(__file__), \"multipart\", \"ie7_full_path_request.http\")\n        data = get_contents(data_file)\n        boundary = \"---------------------------7da36d1b4a0164\"\n        with client.post(\n            \"/?object=cb_file_upload_multiple\",\n            data=data,\n            content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n            content_length=len(data),\n        ) as response:\n            lines = response.get_data().split(b\"\\n\", 3)\n            assert lines[0] == b\"'Sellersburg Town Council Meeting 02-22-2010doc.doc'\"\n\n    def test_end_of_file(self):\n        # This test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n'\n            b\"Content-Type: text/plain\\r\\n\\r\\n\"\n            b\"file contents and no end\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert not data.files\n            assert not data.form\n\n    def test_file_no_content_type(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert data.files[\"test\"].filename == \"test.txt\"\n            assert data.files[\"test\"].read() == b\"file contents\"\n\n    def test_extra_newline(self):\n        # this test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"\\r\\n\\r\\n--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"\\r\\n\\r\\n'\n            b\"a string\\r\\n\"\n            b\"--foo--\"\n        )\n        data = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert not data.files\n        assert data.form[\"foo\"] == \"a string\"\n\n    def test_headers(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\\r\\n'\n            b\"X-Custom-Header: blah\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\n\"\n            b\"file contents, just the contents\\r\\n\"\n            b\"--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as req:\n            foo = req.files[\"foo\"]\n            assert foo.mimetype == \"text/plain\"\n            assert foo.mimetype_params == {\"charset\": \"utf-8\"}\n            assert foo.headers[\"content-type\"] == foo.content_type\n            assert foo.content_type == \"text/plain; charset=utf-8\"\n            assert foo.headers[\"x-custom-header\"] == \"blah\"\n\n    @pytest.mark.parametrize(\"ending\", [b\"\\n\", b\"\\r\", b\"\\r\\n\"])\n    def test_nonstandard_line_endings(self, ending: bytes):\n        data = ending.join(\n            (\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=foo\",\n                b\"\",\n                b\"this is just bar\",\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=bar\",\n                b\"\",\n                b\"blafasel\",\n                b\"--foo--\",\n            )\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert req.form[\"foo\"] == \"this is just bar\"\n        assert req.form[\"bar\"] == \"blafasel\"\n\n    def test_failures(self):\n        def parse_multipart(stream, boundary, content_length):\n            parser = formparser.MultiPartParser(content_length)\n            return parser.parse(stream, boundary, content_length)\n\n        data = b\"--foo\\r\\n\\r\\nHello World\\r\\n--foo--\"\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\nHello World\\r\\n\"\n        )\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n    def test_empty_multipart(self):\n        environ = {}\n        data = b\"--boundary--\"\n        environ[\"REQUEST_METHOD\"] = \"POST\"\n        environ[\"CONTENT_TYPE\"] = \"multipart/form-data; boundary=boundary\"\n        environ[\"CONTENT_LENGTH\"] = str(len(data))\n        environ[\"wsgi.input\"] = io.BytesIO(data)\n        stream, form, files = parse_form_data(environ, silent=False)\n        rv = stream.read()\n        assert rv == b\"\"\n        assert form == MultiDict()\n        assert files == MultiDict()\n\n\nclass TestMultiPartParser:\n    def test_constructor_not_pass_stream_factory_and_cls(self):\n        parser = formparser.MultiPartParser()\n\n        assert parser.stream_factory is formparser.default_stream_factory\n        assert parser.cls is MultiDict\n\n    def test_constructor_pass_stream_factory_and_cls(self):\n        def stream_factory():\n            pass\n\n        parser = formparser.MultiPartParser(stream_factory=stream_factory, cls=dict)\n\n        assert parser.stream_factory is stream_factory\n        assert parser.cls is dict\n\n    def test_file_rfc2231_filename_continuations(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n            b\"Content-Disposition: form-data; name=rfc2231;\\r\\n\"\n            b\"\tfilename*0*=ascii''a%20b%20;\\r\\n\"\n            b\"\tfilename*1*=c%20d%20;\\r\\n\"\n            b'\tfilename*2=\"e f.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as request:\n            assert request.files[\"rfc2231\"].filename == \"a b c d e f.txt\"\n            assert request.files[\"rfc2231\"].read() == b\"file contents\"\n"], "fixing_code": [".. currentmodule:: werkzeug\n\nVersion 2.2.3\n-------------\n\nUnreleased\n\n-   Ensure that URL rules using path converters will redirect with strict slashes when\n    the trailing slash is missing. :issue:`2533`\n-   Type signature for ``get_json`` specifies that return type is not optional when\n    ``silent=False``. :issue:`2508`\n-   ``parse_content_range_header`` returns ``None`` for a value like ``bytes */-1``\n    where the length is invalid, instead of raising an ``AssertionError``. :issue:`2531`\n-   Address remaining ``ResourceWarning`` related to the socket used by ``run_simple``.\n    Remove ``prepare_socket``, which now happens when creating the server. :issue:`2421`\n-   Update pre-existing headers for ``multipart/form-data`` requests with the test\n    client. :issue:`2549`\n-   Fix handling of header extended parameters such that they are no longer quoted.\n    :issue:`2529`\n-   ``LimitedStream.read`` works correctly when wrapping a stream that may not return\n    the requested size in one ``read`` call. :issue:`2558`\n-   A cookie header that starts with ``=`` is treated as an empty key and discarded,\n    rather than stripping the leading ``==``.\n-   Specify a maximum number of multipart parts, default 1000, after which a\n    ``RequestEntityTooLarge`` exception is raised on parsing. This mitigates a DoS\n    attack where a larger number of form/file parts would result in disproportionate\n    resource use.\n\n\nVersion 2.2.2\n-------------\n\nReleased 2022-08-08\n\n-   Fix router to restore the 2.1 ``strict_slashes == False`` behaviour\n    whereby leaf-requests match branch rules and vice\n    versa. :pr:`2489`\n-   Fix router to identify invalid rules rather than hang parsing them,\n    and to correctly parse ``/`` within converter arguments. :pr:`2489`\n-   Update subpackage imports in :mod:`werkzeug.routing` to use the\n    ``import as`` syntax for explicitly re-exporting public attributes.\n    :pr:`2493`\n-   Parsing of some invalid header characters is more robust. :pr:`2494`\n-   When starting the development server, a warning not to use it in a\n    production deployment is always shown. :issue:`2480`\n-   ``LocalProxy.__wrapped__`` is always set to the wrapped object when\n    the proxy is unbound, fixing an issue in doctest that would cause it\n    to fail. :issue:`2485`\n-   Address one ``ResourceWarning`` related to the socket used by\n    ``run_simple``. :issue:`2421`\n\n\nVersion 2.2.1\n-------------\n\nReleased 2022-07-27\n\n-   Fix router so that ``/path/`` will match a rule ``/path`` if strict\n    slashes mode is disabled for the rule. :issue:`2467`\n-   Fix router so that partial part matches are not allowed\n    i.e. ``/2df`` does not match ``/<int>``. :pr:`2470`\n-   Fix router static part weighting, so that simpler routes are matched\n    before more complex ones. :issue:`2471`\n-   Restore ``ValidationError`` to be importable from\n    ``werkzeug.routing``. :issue:`2465`\n\n\nVersion 2.2.0\n-------------\n\nReleased 2022-07-23\n\n-   Deprecated ``get_script_name``, ``get_query_string``,\n    ``peek_path_info``, ``pop_path_info``, and\n    ``extract_path_info``. :pr:`2461`\n-   Remove previously deprecated code. :pr:`2461`\n-   Add MarkupSafe as a dependency and use it to escape values when\n    rendering HTML. :issue:`2419`\n-   Added the ``werkzeug.debug.preserve_context`` mechanism for\n    restoring context-local data for a request when running code in the\n    debug console. :pr:`2439`\n-   Fix compatibility with Python 3.11 by ensuring that ``end_lineno``\n    and ``end_col_offset`` are present on AST nodes. :issue:`2425`\n-   Add a new faster URL matching router based on a state machine. If a custom converter\n    needs to match a ``/`` it must set the class variable ``part_isolating = False``.\n    :pr:`2433`\n-   Fix branch leaf path masking branch paths when strict-slashes is\n    disabled. :issue:`1074`\n-   Names within options headers are always converted to lowercase. This\n    matches :rfc:`6266` that the case is not relevant. :issue:`2442`\n-   ``AnyConverter`` validates the value passed for it when building\n    URLs. :issue:`2388`\n-   The debugger shows enhanced error locations in tracebacks in Python\n    3.11. :issue:`2407`\n-   Added Sans-IO ``is_resource_modified`` and ``parse_cookie`` functions\n    based on WSGI versions. :issue:`2408`\n-   Added Sans-IO ``get_content_length`` function. :pr:`2415`\n-   Don't assume a mimetype for test responses. :issue:`2450`\n-   Type checking ``FileStorage`` accepts ``os.PathLike``. :pr:`2418`\n\n\nVersion 2.1.2\n-------------\n\nReleased 2022-04-28\n\n-   The development server does not set ``Transfer-Encoding: chunked``\n    for 1xx, 204, 304, and HEAD responses. :issue:`2375`\n-   Response HTML for exceptions and redirects starts with\n    ``<!doctype html>`` and ``<html lang=en>``. :issue:`2390`\n-   Fix ability to set some ``cache_control`` attributes to ``False``.\n    :issue:`2379`\n-   Disable ``keep-alive`` connections in the development server, which\n    are not supported sufficiently by Python's ``http.server``.\n    :issue:`2397`\n\n\nVersion 2.1.1\n-------------\n\nReleased 2022-04-01\n\n-   ``ResponseCacheControl.s_maxage`` converts its value to an int, like\n    ``max_age``. :issue:`2364`\n\n\nVersion 2.1.0\n-------------\n\nReleased 2022-03-28\n\n-   Drop support for Python 3.6. :pr:`2277`\n-   Using gevent or eventlet requires greenlet>=1.0 or PyPy>=7.3.7.\n    ``werkzeug.locals`` and ``contextvars`` will not work correctly with\n    older versions. :pr:`2278`\n-   Remove previously deprecated code. :pr:`2276`\n\n    -   Remove the non-standard ``shutdown`` function from the WSGI\n        environ when running the development server. See the docs for\n        alternatives.\n    -   Request and response mixins have all been merged into the\n        ``Request`` and ``Response`` classes.\n    -   The user agent parser and the ``useragents`` module is removed.\n        The ``user_agent`` module provides an interface that can be\n        subclassed to add a parser, such as ua-parser. By default it\n        only stores the whole string.\n    -   The test client returns ``TestResponse`` instances and can no\n        longer be treated as a tuple. All data is available as\n        properties on the response.\n    -   Remove ``locals.get_ident`` and related thread-local code from\n        ``locals``, it no longer makes sense when moving to a\n        contextvars-based implementation.\n    -   Remove the ``python -m werkzeug.serving`` CLI.\n    -   The ``has_key`` method on some mapping datastructures; use\n        ``key in data`` instead.\n    -   ``Request.disable_data_descriptor`` is removed, pass\n        ``shallow=True`` instead.\n    -   Remove the ``no_etag`` parameter from ``Response.freeze()``.\n    -   Remove the ``HTTPException.wrap`` class method.\n    -   Remove the ``cookie_date`` function. Use ``http_date`` instead.\n    -   Remove the ``pbkdf2_hex``, ``pbkdf2_bin``, and ``safe_str_cmp``\n        functions. Use equivalents in ``hashlib`` and ``hmac`` modules\n        instead.\n    -   Remove the ``Href`` class.\n    -   Remove the ``HTMLBuilder`` class.\n    -   Remove the ``invalidate_cached_property`` function. Use\n        ``del obj.attr`` instead.\n    -   Remove ``bind_arguments`` and ``validate_arguments``. Use\n        :meth:`Signature.bind` and :func:`inspect.signature` instead.\n    -   Remove ``detect_utf_encoding``, it's built-in to ``json.loads``.\n    -   Remove ``format_string``, use :class:`string.Template` instead.\n    -   Remove ``escape`` and ``unescape``. Use MarkupSafe instead.\n\n-   The ``multiple`` parameter of ``parse_options_header`` is\n    deprecated. :pr:`2357`\n-   Rely on :pep:`538` and :pep:`540` to handle decoding file names\n    with the correct filesystem encoding. The ``filesystem`` module is\n    removed. :issue:`1760`\n-   Default values passed to ``Headers`` are validated the same way\n    values added later are. :issue:`1608`\n-   Setting ``CacheControl`` int properties, such as ``max_age``, will\n    convert the value to an int. :issue:`2230`\n-   Always use ``socket.fromfd`` when restarting the dev server.\n    :pr:`2287`\n-   When passing a dict of URL values to ``Map.build``, list values do\n    not filter out ``None`` or collapse to a single value. Passing a\n    ``MultiDict`` does collapse single items. This undoes a previous\n    change that made it difficult to pass a list, or ``None`` values in\n    a list, to custom URL converters. :issue:`2249`\n-   ``run_simple`` shows instructions for dealing with \"address already\n    in use\" errors, including extra instructions for macOS. :pr:`2321`\n-   Extend list of characters considered always safe in URLs based on\n    :rfc:`3986`. :issue:`2319`\n-   Optimize the stat reloader to avoid watching unnecessary files in\n    more cases. The watchdog reloader is still recommended for\n    performance and accuracy. :issue:`2141`\n-   The development server uses ``Transfer-Encoding: chunked`` for\n    streaming responses when it is configured for HTTP/1.1.\n    :issue:`2090, 1327`, :pr:`2091`\n-   The development server uses HTTP/1.1, which enables keep-alive\n    connections and chunked streaming responses, when ``threaded`` or\n    ``processes`` is enabled. :pr:`2323`\n-   ``cached_property`` works for classes with ``__slots__`` if a\n    corresponding ``_cache_{name}`` slot is added. :pr:`2332`\n-   Refactor the debugger traceback formatter to use Python's built-in\n    ``traceback`` module as much as possible. :issue:`1753`\n-   The ``TestResponse.text`` property is a shortcut for\n    ``r.get_data(as_text=True)``, for convenient testing against text\n    instead of bytes. :pr:`2337`\n-   ``safe_join`` ensures that the path remains relative if the trusted\n    directory is the empty string. :pr:`2349`\n-   Percent-encoded newlines (``%0a``), which are decoded by WSGI\n    servers, are considered when routing instead of terminating the\n    match early. :pr:`2350`\n-   The test client doesn't set duplicate headers for ``CONTENT_LENGTH``\n    and ``CONTENT_TYPE``. :pr:`2348`\n-   ``append_slash_redirect`` handles ``PATH_INFO`` with internal\n    slashes. :issue:`1972`, :pr:`2338`\n-   The default status code for ``append_slash_redirect`` is 308 instead\n    of 301. This preserves the request body, and matches a previous\n    change to ``strict_slashes`` in routing. :issue:`2351`\n-   Fix ``ValueError: I/O operation on closed file.`` with the test\n    client when following more than one redirect. :issue:`2353`\n-   ``Response.autocorrect_location_header`` is disabled by default.\n    The ``Location`` header URL will remain relative, and exclude the\n    scheme and domain, by default. :issue:`2352`\n-   ``Request.get_json()`` will raise a 400 ``BadRequest`` error if the\n    ``Content-Type`` header is not ``application/json``. This makes a\n    very common source of confusion more visible. :issue:`2339`\n\n\nVersion 2.0.3\n-------------\n\nReleased 2022-02-07\n\n-   ``ProxyFix`` supports IPv6 addresses. :issue:`2262`\n-   Type annotation for ``Response.make_conditional``,\n    ``HTTPException.get_response``, and ``Map.bind_to_environ`` accepts\n    ``Request`` in addition to ``WSGIEnvironment`` for the first\n    parameter. :pr:`2290`\n-   Fix type annotation for ``Request.user_agent_class``. :issue:`2273`\n-   Accessing ``LocalProxy.__class__`` and ``__doc__`` on an unbound\n    proxy returns the fallback value instead of a method object.\n    :issue:`2188`\n-   Redirects with the test client set ``RAW_URI`` and ``REQUEST_URI``\n    correctly. :issue:`2151`\n\n\nVersion 2.0.2\n-------------\n\nReleased 2021-10-05\n\n-   Handle multiple tokens in ``Connection`` header when routing\n    WebSocket requests. :issue:`2131`\n-   Set the debugger pin cookie secure flag when on https. :pr:`2150`\n-   Fix type annotation for ``MultiDict.update`` to accept iterable\n    values :pr:`2142`\n-   Prevent double encoding of redirect URL when ``merge_slash=True``\n    for ``Rule.match``. :issue:`2157`\n-   ``CombinedMultiDict.to_dict`` with ``flat=False`` considers all\n    component dicts when building value lists. :issue:`2189`\n-   ``send_file`` only sets a detected ``Content-Encoding`` if\n    ``as_attachment`` is disabled to avoid browsers saving\n    decompressed ``.tar.gz`` files. :issue:`2149`\n-   Fix type annotations for ``TypeConversionDict.get`` to not return an\n    ``Optional`` value if both ``default`` and ``type`` are not\n    ``None``. :issue:`2169`\n-   Fix type annotation for routing rule factories to accept\n    ``Iterable[RuleFactory]`` instead of ``Iterable[Rule]`` for the\n    ``rules`` parameter. :issue:`2183`\n-   Add missing type annotation for ``FileStorage.__getattr__``\n    :issue:`2155`\n-   The debugger pin cookie is set with ``SameSite`` set to ``Strict``\n    instead of ``None`` to be compatible with modern browser security.\n    :issue:`2156`\n-   Type annotations use ``IO[bytes]`` and ``IO[str]`` instead of\n    ``BinaryIO`` and ``TextIO`` for wider type compatibility.\n    :issue:`2130`\n-   Ad-hoc TLS certs are generated with SAN matching CN. :issue:`2158`\n-   Fix memory usage for locals when using Python 3.6 or pre 0.4.17\n    greenlet versions. :pr:`2212`\n-   Fix type annotation in ``CallbackDict``, because it is not\n    utilizing a bound TypeVar. :issue:`2235`\n-   Fix setting CSP header options on the response. :pr:`2237`\n-   Fix an issue with with the interactive debugger where lines would\n    not expand on click for very long tracebacks. :pr:`2239`\n-   The interactive debugger handles displaying an exception that does\n    not have a traceback, such as from ``ProcessPoolExecutor``.\n    :issue:`2217`\n\n\nVersion 2.0.1\n-------------\n\nReleased 2021-05-17\n\n-   Fix type annotation for ``send_file`` ``max_age`` callable. Don't\n    pass ``pathlib.Path`` to ``max_age``. :issue:`2119`\n-   Mark top-level names as exported so type checking understands\n    imports in user projects. :issue:`2122`\n-   Fix some types that weren't available in Python 3.6.0. :issue:`2123`\n-   ``cached_property`` is generic over its return type, properties\n    decorated with it report the correct type. :issue:`2113`\n-   Fix multipart parsing bug when boundary contains special regex\n    characters. :issue:`2125`\n-   Type checking understands that calling ``headers.get`` with a string\n    default will always return a string. :issue:`2128`\n-   If ``HTTPException.description`` is not a string,\n    ``get_description`` will convert it to a string. :issue:`2115`\n\n\nVersion 2.0.0\n-------------\n\nReleased 2021-05-11\n\n-   Drop support for Python 2 and 3.5. :pr:`1693`\n-   Deprecate :func:`utils.format_string`, use :class:`string.Template`\n    instead. :issue:`1756`\n-   Deprecate :func:`utils.bind_arguments` and\n    :func:`utils.validate_arguments`, use :meth:`Signature.bind` and\n    :func:`inspect.signature` instead. :issue:`1757`\n-   Deprecate :class:`utils.HTMLBuilder`. :issue:`1761`\n-   Deprecate :func:`utils.escape` and :func:`utils.unescape`, use\n    MarkupSafe instead. :issue:`1758`\n-   Deprecate the undocumented ``python -m werkzeug.serving`` CLI.\n    :issue:`1834`\n-   Deprecate the ``environ[\"werkzeug.server.shutdown\"]`` function\n    that is available when running the development server. :issue:`1752`\n-   Deprecate the ``useragents`` module and the built-in user agent\n    parser. Use a dedicated parser library instead by subclassing\n    ``user_agent.UserAgent`` and setting ``Request.user_agent_class``.\n    :issue:`2078`\n-   Remove the unused, internal ``posixemulation`` module. :issue:`1759`\n-   All ``datetime`` values are timezone-aware with\n    ``tzinfo=timezone.utc``. This applies to anything using\n    ``http.parse_date``: ``Request.date``, ``.if_modified_since``,\n    ``.if_unmodified_since``; ``Response.date``, ``.expires``,\n    ``.last_modified``, ``.retry_after``; ``parse_if_range_header``, and\n    ``IfRange.date``. When comparing values, the other values must also\n    be aware, or these values must be made naive. When passing\n    parameters or setting attributes, naive values are still assumed to\n    be in UTC. :pr:`2040`\n-   Merge all request and response wrapper mixin code into single\n    ``Request`` and ``Response`` classes. Using the mixin classes is no\n    longer necessary and will show a deprecation warning. Checking\n    ``isinstance`` or ``issubclass`` against ``BaseRequest`` and\n    ``BaseResponse`` will show a deprecation warning and check against\n    ``Request`` or ``Response`` instead. :issue:`1963`\n-   JSON support no longer uses simplejson if it's installed. To use\n    another JSON module, override ``Request.json_module`` and\n    ``Response.json_module``. :pr:`1766`\n-   ``Response.get_json()`` no longer caches the result, and the\n    ``cache`` parameter is removed. :issue:`1698`\n-   ``Response.freeze()`` generates an ``ETag`` header if one is not\n    set. The ``no_etag`` parameter (which usually wasn't visible\n    anyway) is no longer used. :issue:`1963`\n-   Add a ``url_scheme`` argument to :meth:`~routing.MapAdapter.build`\n    to override the bound scheme. :pr:`1721`\n-   Passing an empty list as a query string parameter to ``build()``\n    won't append an unnecessary ``?``. Also drop any number of ``None``\n    items in a list. :issue:`1992`\n-   When passing a ``Headers`` object to a test client method or\n    ``EnvironBuilder``, multiple values for a key are joined into one\n    comma separated value. This matches the HTTP spec on multi-value\n    headers. :issue:`1655`\n-   Setting ``Response.status`` and ``status_code`` uses identical\n    parsing and error checking. :issue:`1658`, :pr:`1728`\n-   ``MethodNotAllowed`` and ``RequestedRangeNotSatisfiable`` take a\n    ``response`` kwarg, consistent with other HTTP errors. :pr:`1748`\n-   The response generated by :exc:`~exceptions.Unauthorized` produces\n    one ``WWW-Authenticate`` header per value in ``www_authenticate``,\n    rather than joining them into a single value, to improve\n    interoperability with browsers and other clients. :pr:`1755`\n-   If ``parse_authorization_header`` can't decode the header value, it\n    returns ``None`` instead of raising a ``UnicodeDecodeError``.\n    :issue:`1816`\n-   The debugger no longer uses jQuery. :issue:`1807`\n-   The test client includes the query string in ``REQUEST_URI`` and\n    ``RAW_URI``. :issue:`1781`\n-   Switch the parameter order of ``default_stream_factory`` to match\n    the order used when calling it. :pr:`1085`\n-   Add ``send_file`` function to generate a response that serves a\n    file. Adapted from Flask's implementation. :issue:`265`, :pr:`1850`\n-   Add ``send_from_directory`` function to safely serve an untrusted\n    path within a trusted directory. Adapted from Flask's\n    implementation. :issue:`1880`\n-   ``send_file`` takes ``download_name``, which is passed even if\n    ``as_attachment=False`` by using ``Content-Disposition: inline``.\n    ``download_name`` replaces Flask's ``attachment_filename``.\n    :issue:`1869`\n-   ``send_file`` sets ``conditional=True`` and ``max_age=None`` by\n    default. ``Cache-Control`` is set to ``no-cache`` if ``max_age`` is\n    not set, otherwise ``public``. This tells browsers to validate\n    conditional requests instead of using a timed cache.\n    ``max_age=None`` replaces Flask's ``cache_timeout=43200``.\n    :issue:`1882`\n-   ``send_file`` can be called with ``etag=\"string\"`` to set a custom\n    ETag instead of generating one. ``etag`` replaces Flask's\n    ``add_etags``. :issue:`1868`\n-   ``send_file`` sets the ``Content-Encoding`` header if an encoding is\n    returned when guessing ``mimetype`` from ``download_name``.\n    :pr:`3896`\n-   Update the defaults used by ``generate_password_hash``. Increase\n    PBKDF2 iterations to 260000 from 150000. Increase salt length to 16\n    from 8. Use ``secrets`` module to generate salt. :pr:`1935`\n-   The reloader doesn't crash if ``sys.stdin`` is somehow ``None``.\n    :pr:`1915`\n-   Add arguments to ``delete_cookie`` to match ``set_cookie`` and the\n    attributes modern browsers expect. :pr:`1889`\n-   ``utils.cookie_date`` is deprecated, use ``utils.http_date``\n    instead. The value for ``Set-Cookie expires`` is no longer \"-\"\n    delimited. :pr:`2040`\n-   Use ``request.headers`` instead of ``request.environ`` to look up\n    header attributes. :pr:`1808`\n-   The test ``Client`` request methods (``client.get``, etc.) always\n    return an instance of ``TestResponse``. In addition to the normal\n    behavior of ``Response``, this class provides ``request`` with the\n    request that produced the response, and ``history`` to track\n    intermediate responses when ``follow_redirects`` is used.\n    :issue:`763, 1894`\n-   The test ``Client`` request methods takes an ``auth`` parameter to\n    add an ``Authorization`` header. It can be an ``Authorization``\n    object or a ``(username, password)`` tuple for ``Basic`` auth.\n    :pr:`1809`\n-   Calling ``response.close()`` on a response from the test ``Client``\n    will close the request input stream. This matches file behavior\n    and can prevent a ``ResourceWarning`` in some cases. :issue:`1785`\n-   ``EnvironBuilder.from_environ`` decodes values encoded for WSGI, to\n    avoid double encoding the new values. :pr:`1959`\n-   The default stat reloader will watch Python files under\n    non-system/virtualenv ``sys.path`` entries, which should contain\n    most user code. It will also watch all Python files under\n    directories given in ``extra_files``. :pr:`1945`\n-   The reloader ignores ``__pycache__`` directories again. :pr:`1945`\n-   ``run_simple`` takes ``exclude_patterns`` a list of ``fnmatch``\n    patterns that will not be scanned by the reloader. :issue:`1333`\n-   Cookie names are no longer unquoted. This was against :rfc:`6265`\n    and potentially allowed setting ``__Secure`` prefixed cookies.\n    :pr:`1965`\n-   Fix some word matches for user agent platform when the word can be a\n    substring. :issue:`1923`\n-   The development server logs ignored SSL errors. :pr:`1967`\n-   Temporary files for form data are opened in ``rb+`` instead of\n    ``wb+`` mode for better compatibility with some libraries.\n    :issue:`1961`\n-   Use SHA-1 instead of MD5 for generating ETags and the debugger pin,\n    and in some tests. MD5 is not available in some environments, such\n    as FIPS 140. This may invalidate some caches since the ETag will be\n    different. :issue:`1897`\n-   Add ``Cross-Origin-Opener-Policy`` and\n    ``Cross-Origin-Embedder-Policy`` response header properties.\n    :pr:`2008`\n-   ``run_simple`` tries to show a valid IP address when binding to all\n    addresses, instead of ``0.0.0.0`` or ``::``. It also warns about not\n    running the development server in production in this case.\n    :issue:`1964`\n-   Colors in the development server log are displayed if Colorama is\n    installed on Windows. For all platforms, style support no longer\n    requires Click. :issue:`1832`\n-   A range request for an empty file (or other data with length 0) will\n    return a 200 response with the empty file instead of a 416 error.\n    :issue:`1937`\n-   New sans-IO base classes for ``Request`` and ``Response`` have been\n    extracted to contain all the behavior that is not WSGI or IO\n    dependent. These are not a public API, they are part of an ongoing\n    refactor to let ASGI frameworks use Werkzeug. :pr:`2005`\n-   Parsing ``multipart/form-data`` has been refactored to use sans-io\n    patterns. This should also make parsing forms with large binary file\n    uploads significantly faster. :issue:`1788, 875`\n-   ``LocalProxy`` matches the current Python data model special\n    methods, including all r-ops, in-place ops, and async. ``__class__``\n    is proxied, so the proxy will look like the object in more cases,\n    including ``isinstance``. Use ``issubclass(type(obj), LocalProxy)``\n    to check if an object is actually a proxy. :issue:`1754`\n-   ``Local`` uses ``ContextVar`` on Python 3.7+ instead of\n    ``threading.local``. :pr:`1778`\n-   ``request.values`` does not include ``form`` for GET requests (even\n    though GET bodies are undefined). This prevents bad caching proxies\n    from caching form data instead of query strings. :pr:`2037`\n-   The development server adds the underlying socket to ``environ`` as\n    ``werkzeug.socket``. This is non-standard and specific to the dev\n    server, other servers may expose this under their own key. It is\n    useful for handling a WebSocket upgrade request. :issue:`2052`\n-   URL matching assumes ``websocket=True`` mode for WebSocket upgrade\n    requests. :issue:`2052`\n-   Updated ``UserAgentParser`` to handle more cases. :issue:`1971`\n-   ``werzeug.DechunkedInput.readinto`` will not read beyond the size of\n    the buffer. :issue:`2021`\n-   Fix connection reset when exceeding max content size. :pr:`2051`\n-   ``pbkdf2_hex``, ``pbkdf2_bin``, and ``safe_str_cmp`` are deprecated.\n    ``hashlib`` and ``hmac`` provide equivalents. :pr:`2083`\n-   ``invalidate_cached_property`` is deprecated. Use ``del obj.name``\n    instead. :pr:`2084`\n-   ``Href`` is deprecated. Use ``werkzeug.routing`` instead.\n    :pr:`2085`\n-   ``Request.disable_data_descriptor`` is deprecated. Create the\n    request with ``shallow=True`` instead. :pr:`2085`\n-   ``HTTPException.wrap`` is deprecated. Create a subclass manually\n    instead. :pr:`2085`\n\n\nVersion 1.0.1\n-------------\n\nReleased 2020-03-31\n\n-   Make the argument to ``RequestRedirect.get_response`` optional.\n    :issue:`1718`\n-   Only allow a single access control allow origin value. :pr:`1723`\n-   Fix crash when trying to parse a non-existent Content Security\n    Policy header. :pr:`1731`\n-   ``http_date`` zero fills years < 1000 to always output four digits.\n    :issue:`1739`\n-   Fix missing local variables in interactive debugger console.\n    :issue:`1746`\n-   Fix passing file-like objects like ``io.BytesIO`` to\n    ``FileStorage.save``. :issue:`1733`\n\n\nVersion 1.0.0\n-------------\n\nReleased 2020-02-06\n\n-   Drop support for Python 3.4. (:issue:`1478`)\n-   Remove code that issued deprecation warnings in version 0.15.\n    (:issue:`1477`)\n-   Remove most top-level attributes provided by the ``werkzeug``\n    module in favor of direct imports. For example, instead of\n    ``import werkzeug; werkzeug.url_quote``, do\n    ``from werkzeug.urls import url_quote``. Install version 0.16 first\n    to see deprecation warnings while upgrading. :issue:`2`, :pr:`1640`\n-   Added ``utils.invalidate_cached_property()`` to invalidate cached\n    properties. (:pr:`1474`)\n-   Directive keys for the ``Set-Cookie`` response header are not\n    ignored when parsing the ``Cookie`` request header. This allows\n    cookies with names such as \"expires\" and \"version\". (:issue:`1495`)\n-   Request cookies are parsed into a ``MultiDict`` to capture all\n    values for cookies with the same key. ``cookies[key]`` returns the\n    first value rather than the last. Use ``cookies.getlist(key)`` to\n    get all values. ``parse_cookie`` also defaults to a ``MultiDict``.\n    :issue:`1562`, :pr:`1458`\n-   Add ``charset=utf-8`` to an HTTP exception response's\n    ``CONTENT_TYPE`` header. (:pr:`1526`)\n-   The interactive debugger handles outer variables in nested scopes\n    such as lambdas and comprehensions. :issue:`913`, :issue:`1037`,\n    :pr:`1532`\n-   The user agent for Opera 60 on Mac is correctly reported as\n    \"opera\" instead of \"chrome\". :issue:`1556`\n-   The platform for Crosswalk on Android is correctly reported as\n    \"android\" instead of \"chromeos\". (:pr:`1572`)\n-   Issue a warning when the current server name does not match the\n    configured server name. :issue:`760`\n-   A configured server name with the default port for a scheme will\n    match the current server name without the port if the current scheme\n    matches. :pr:`1584`\n-   :exc:`~exceptions.InternalServerError` has a ``original_exception``\n    attribute that frameworks can use to track the original cause of the\n    error. :pr:`1590`\n-   Headers are tested for equality independent of the header key case,\n    such that ``X-Foo`` is the same as ``x-foo``. :pr:`1605`\n-   :meth:`http.dump_cookie` accepts ``'None'`` as a value for\n    ``samesite``. :issue:`1549`\n-   :meth:`~test.Client.set_cookie` accepts a ``samesite`` argument.\n    :pr:`1705`\n-   Support the Content Security Policy header through the\n    `Response.content_security_policy` data structure. :pr:`1617`\n-   ``LanguageAccept`` will fall back to matching \"en\" for \"en-US\" or\n    \"en-US\" for \"en\" to better support clients or translations that\n    only match at the primary language tag. :issue:`450`, :pr:`1507`\n-   ``MIMEAccept`` uses MIME parameters for specificity when matching.\n    :issue:`458`, :pr:`1574`\n-   If the development server is started with an ``SSLContext``\n    configured to verify client certificates, the certificate in PEM\n    format will be available as ``environ[\"SSL_CLIENT_CERT\"]``.\n    :pr:`1469`\n-   ``is_resource_modified`` will run for methods other than ``GET`` and\n    ``HEAD``, rather than always returning ``False``. :issue:`409`\n-   ``SharedDataMiddleware`` returns 404 rather than 500 when trying to\n    access a directory instead of a file with the package loader. The\n    dependency on setuptools and pkg_resources is removed.\n    :issue:`1599`\n-   Add a ``response.cache_control.immutable`` flag. Keep in mind that\n    browser support for this ``Cache-Control`` header option is still\n    experimental and may not be implemented. :issue:`1185`\n-   Optional request log highlighting with the development server is\n    handled by Click instead of termcolor. :issue:`1235`\n-   Optional ad-hoc TLS support for the development server is handled\n    by cryptography instead of pyOpenSSL. :pr:`1555`\n-   ``FileStorage.save()`` supports ``pathlib`` and :pep:`519`\n    ``PathLike`` objects. :issue:`1653`\n-   The debugger security pin is unique in containers managed by Podman.\n    :issue:`1661`\n-   Building a URL when ``host_matching`` is enabled takes into account\n    the current host when there are duplicate endpoints with different\n    hosts. :issue:`488`\n-   The ``429 TooManyRequests`` and ``503 ServiceUnavailable`` HTTP\n    exceptions takes a ``retry_after`` parameter to set the\n    ``Retry-After`` header. :issue:`1657`\n-   ``Map`` and ``Rule`` have a ``merge_slashes`` option to collapse\n    multiple slashes into one, similar to how many HTTP servers behave.\n    This is enabled by default. :pr:`1286, 1694`\n-   Add HTTP 103, 208, 306, 425, 506, 508, and 511 to the list of status\n    codes. :pr:`1678`\n-   Add ``update``, ``setlist``, and ``setlistdefault`` methods to the\n    ``Headers`` data structure. ``extend`` method can take ``MultiDict``\n    and kwargs. :pr:`1687, 1697`\n-   The development server accepts paths that start with two slashes,\n    rather than stripping off the first path segment. :issue:`491`\n-   Add access control (Cross Origin Request Sharing, CORS) header\n    properties to the ``Request`` and ``Response`` wrappers. :pr:`1699`\n-   ``Accept`` values are no longer ordered alphabetically for equal\n    quality tags. Instead the initial order is preserved. :issue:`1686`\n-   Added ``Map.lock_class`` attribute for alternative\n    implementations. :pr:`1702`\n-   Support matching and building WebSocket rules in the routing system,\n    for use by async frameworks. :pr:`1709`\n-   Range requests that span an entire file respond with 206 instead of\n    200, to be more compliant with :rfc:`7233`. This may help serving\n    media to older browsers. :issue:`410, 1704`\n-   The :class:`~middleware.shared_data.SharedDataMiddleware` default\n    ``fallback_mimetype`` is ``application/octet-stream``. If a filename\n    looks like a text mimetype, the ``utf-8`` charset is added to it.\n    This matches the behavior of :class:`~wrappers.BaseResponse` and\n    Flask's ``send_file()``. :issue:`1689`\n\n\nVersion 0.16.1\n--------------\n\nReleased 2020-01-27\n\n-   Fix import location in deprecation messages for subpackages.\n    :issue:`1663`\n-   Fix an SSL error on Python 3.5 when the dev server responds with no\n    content. :issue:`1659`\n\n\nVersion 0.16.0\n--------------\n\nReleased 2019-09-19\n\n-   Deprecate most top-level attributes provided by the ``werkzeug``\n    module in favor of direct imports. The deprecated imports will be\n    removed in version 1.0.\n\n    For example, instead of ``import werkzeug; werkzeug.url_quote``, do\n    ``from werkzeug.urls import url_quote``. A deprecation warning will\n    show the correct import to use. ``werkzeug.exceptions`` and\n    ``werkzeug.routing`` should also be imported instead of accessed,\n    but for technical reasons can't show a warning.\n\n    :issue:`2`, :pr:`1640`\n\n\nVersion 0.15.6\n--------------\n\nReleased 2019-09-04\n\n-   Work around a bug in pip that caused the reloader to fail on\n    Windows when the script was an entry point. This fixes the issue\n    with Flask's `flask run` command failing with \"No module named\n    Scripts\\flask\". :issue:`1614`\n-   ``ProxyFix`` trusts the ``X-Forwarded-Proto`` header by default.\n    :issue:`1630`\n-   The deprecated ``num_proxies`` argument to ``ProxyFix`` sets\n    ``x_for``, ``x_proto``, and ``x_host`` to match 0.14 behavior. This\n    is intended to make intermediate upgrades less disruptive, but the\n    argument will still be removed in 1.0. :issue:`1630`\n\n\nVersion 0.15.5\n--------------\n\nReleased 2019-07-17\n\n-   Fix a ``TypeError`` due to changes to ``ast.Module`` in Python 3.8.\n    :issue:`1551`\n-   Fix a C assertion failure in debug builds of some Python 2.7\n    releases. :issue:`1553`\n-   :class:`~exceptions.BadRequestKeyError` adds the ``KeyError``\n    message to the description if ``e.show_exception`` is set to\n    ``True``. This is a more secure default than the original 0.15.0\n    behavior and makes it easier to control without losing information.\n    :pr:`1592`\n-   Upgrade the debugger to jQuery 3.4.1. :issue:`1581`\n-   Work around an issue in some external debuggers that caused the\n    reloader to fail. :issue:`1607`\n-   Work around an issue where the reloader couldn't introspect a\n    setuptools script installed as an egg. :issue:`1600`\n-   The reloader will use ``sys.executable`` even if the script is\n    marked executable, reverting a behavior intended for NixOS\n    introduced in 0.15. The reloader should no longer cause\n    ``OSError: [Errno 8] Exec format error``. :issue:`1482`,\n    :issue:`1580`\n-   ``SharedDataMiddleware`` safely handles paths with Windows drive\n    names. :issue:`1589`\n\n\nVersion 0.15.4\n--------------\n\nReleased 2019-05-14\n\n-   Fix a ``SyntaxError`` on Python 2.7.5. (:issue:`1544`)\n\n\nVersion 0.15.3\n--------------\n\nReleased 2019-05-14\n\n-   Properly handle multi-line header folding in development server in\n    Python 2.7. (:issue:`1080`)\n-   Restore the ``response`` argument to :exc:`~exceptions.Unauthorized`.\n    (:pr:`1527`)\n-   :exc:`~exceptions.Unauthorized` doesn't add the ``WWW-Authenticate``\n    header if ``www_authenticate`` is not given. (:issue:`1516`)\n-   The default URL converter correctly encodes bytes to string rather\n    than representing them with ``b''``. (:issue:`1502`)\n-   Fix the filename format string in\n    :class:`~middleware.profiler.ProfilerMiddleware` to correctly handle\n    float values. (:issue:`1511`)\n-   Update :class:`~middleware.lint.LintMiddleware` to work on Python 3.\n    (:issue:`1510`)\n-   The debugger detects cycles in chained exceptions and does not time\n    out in that case. (:issue:`1536`)\n-   When running the development server in Docker, the debugger security\n    pin is now unique per container.\n\n\nVersion 0.15.2\n--------------\n\nReleased 2019-04-02\n\n-   ``Rule`` code generation uses a filename that coverage will ignore.\n    The previous value, \"generated\", was causing coverage to fail.\n    (:issue:`1487`)\n-   The test client removes the cookie header if there are no persisted\n    cookies. This fixes an issue introduced in 0.15.0 where the cookies\n    from the original request were used for redirects, causing functions\n    such as logout to fail. (:issue:`1491`)\n-   The test client copies the environ before passing it to the app, to\n    prevent in-place modifications from affecting redirect requests.\n    (:issue:`1498`)\n-   The ``\"werkzeug\"`` logger only adds a handler if there is no handler\n    configured for its level in the logging chain. This avoids double\n    logging if other code configures logging first. (:issue:`1492`)\n\n\nVersion 0.15.1\n--------------\n\nReleased 2019-03-21\n\n-   :exc:`~exceptions.Unauthorized` takes ``description`` as the first\n    argument, restoring previous behavior. The new ``www_authenticate``\n    argument is listed second. (:issue:`1483`)\n\n\nVersion 0.15.0\n--------------\n\nReleased 2019-03-19\n\n-   Building URLs is ~7x faster. Each :class:`~routing.Rule` compiles\n    an optimized function for building itself. (:pr:`1281`)\n-   :meth:`MapAdapter.build() <routing.MapAdapter.build>` can be passed\n    a :class:`~datastructures.MultiDict` to represent multiple values\n    for a key. It already did this when passing a dict with a list\n    value. (:pr:`724`)\n-   ``path_info`` defaults to ``'/'`` for\n    :meth:`Map.bind() <routing.Map.bind>`. (:issue:`740`, :pr:`768`,\n    :pr:`1316`)\n-   Change ``RequestRedirect`` code from 301 to 308, preserving the verb\n    and request body (form data) during redirect. (:pr:`1342`)\n-   ``int`` and ``float`` converters in URL rules will handle negative\n    values if passed the ``signed=True`` parameter. For example,\n    ``/jump/<int(signed=True):count>``. (:pr:`1355`)\n-   ``Location`` autocorrection in :func:`Response.get_wsgi_headers()\n    <wrappers.BaseResponse.get_wsgi_headers>` is relative to the current\n    path rather than the root path. (:issue:`693`, :pr:`718`,\n    :pr:`1315`)\n-   412 responses once again include entity headers and an error message\n    in the body. They were originally omitted when implementing\n    ``If-Match`` (:pr:`1233`), but the spec doesn't seem to disallow it.\n    (:issue:`1231`, :pr:`1255`)\n-   The Content-Length header is removed for 1xx and 204 responses. This\n    fixes a previous change where no body would be sent, but the header\n    would still be present. The new behavior matches RFC 7230.\n    (:pr:`1294`)\n-   :class:`~exceptions.Unauthorized` takes a ``www_authenticate``\n    parameter to set the ``WWW-Authenticate`` header for the response,\n    which is technically required for a valid 401 response.\n    (:issue:`772`, :pr:`795`)\n-   Add support for status code 424 :exc:`~exceptions.FailedDependency`.\n    (:pr:`1358`)\n-   :func:`http.parse_cookie` ignores empty segments rather than\n    producing a cookie with no key or value. (:issue:`1245`, :pr:`1301`)\n-   :func:`~http.parse_authorization_header` (and\n    :class:`~datastructures.Authorization`,\n    :attr:`~wrappers.Request.authorization`) treats the authorization\n    header as UTF-8. On Python 2, basic auth username and password are\n    ``unicode``. (:pr:`1325`)\n-   :func:`~http.parse_options_header` understands :rfc:`2231` parameter\n    continuations. (:pr:`1417`)\n-   :func:`~urls.uri_to_iri` does not unquote ASCII characters in the\n    unreserved class, such as space, and leaves invalid bytes quoted\n    when decoding. :func:`~urls.iri_to_uri` does not quote reserved\n    characters. See :rfc:`3987` for these character classes.\n    (:pr:`1433`)\n-   ``get_content_type`` appends a charset for any mimetype that ends\n    with ``+xml``, not just those that start with ``application/``.\n    Known text types such as ``application/javascript`` are also given\n    charsets. (:pr:`1439`)\n-   Clean up ``werkzeug.security`` module, remove outdated hashlib\n    support. (:pr:`1282`)\n-   In :func:`~security.generate_password_hash`, PBKDF2 uses 150000\n    iterations by default, increased from 50000. (:pr:`1377`)\n-   :class:`~wsgi.ClosingIterator` calls ``close`` on the wrapped\n    *iterable*, not the internal iterator. This doesn't affect objects\n    where ``__iter__`` returned ``self``. For other objects, the method\n    was not called before. (:issue:`1259`, :pr:`1260`)\n-   Bytes may be used as keys in :class:`~datastructures.Headers`, they\n    will be decoded as Latin-1 like values are. (:pr:`1346`)\n-   :class:`~datastructures.Range` validates that list of range tuples\n    passed to it would produce a valid ``Range`` header. (:pr:`1412`)\n-   :class:`~datastructures.FileStorage` looks up attributes on\n    ``stream._file`` if they don't exist on ``stream``, working around\n    an issue where :func:`tempfile.SpooledTemporaryFile` didn't\n    implement all of :class:`io.IOBase`. See\n    https://github.com/python/cpython/pull/3249. (:pr:`1409`)\n-   :class:`CombinedMultiDict.copy() <datastructures.CombinedMultiDict>`\n    returns a shallow mutable copy as a\n    :class:`~datastructures.MultiDict`. The copy no longer reflects\n    changes to the combined dicts, but is more generally useful.\n    (:pr:`1420`)\n-   The version of jQuery used by the debugger is updated to 3.3.1.\n    (:pr:`1390`)\n-   The debugger correctly renders long ``markupsafe.Markup`` instances.\n    (:pr:`1393`)\n-   The debugger can serve resources when Werkzeug is installed as a\n    zip file. ``DebuggedApplication.get_resource`` uses\n    ``pkgutil.get_data``. (:pr:`1401`)\n-   The debugger and server log support Python 3's chained exceptions.\n    (:pr:`1396`)\n-   The interactive debugger highlights frames that come from user code\n    to make them easy to pick out in a long stack trace. Note that if an\n    env was created with virtualenv instead of venv, the debugger may\n    incorrectly classify some frames. (:pr:`1421`)\n-   Clicking the error message at the top of the interactive debugger\n    will jump down to the bottom of the traceback. (:pr:`1422`)\n-   When generating a PIN, the debugger will ignore a ``KeyError``\n    raised when the current UID doesn't have an associated username,\n    which can happen in Docker. (:issue:`1471`)\n-   :class:`~exceptions.BadRequestKeyError` adds the ``KeyError``\n    message to the description, making it clearer what caused the 400\n    error. Frameworks like Flask can omit this information in production\n    by setting ``e.args = ()``. (:pr:`1395`)\n-   If a nested ``ImportError`` occurs from :func:`~utils.import_string`\n    the traceback mentions the nested import. Removes an untested code\n    path for handling \"modules not yet set up by the parent.\"\n    (:pr:`735`)\n-   Triggering a reload while using a tool such as PDB no longer hides\n    input. (:pr:`1318`)\n-   The reloader will not prepend the Python executable to the command\n    line if the Python file is marked executable. This allows the\n    reloader to work on NixOS. (:pr:`1242`)\n-   Fix an issue where ``sys.path`` would change between reloads when\n    running with ``python -m app``. The reloader can detect that a\n    module was run with \"-m\" and reconstructs that instead of the file\n    path in ``sys.argv`` when reloading. (:pr:`1416`)\n-   The dev server can bind to a Unix socket by passing a hostname like\n    ``unix://app.socket``. (:pr:`209`, :pr:`1019`)\n-   Server uses ``IPPROTO_TCP`` constant instead of ``SOL_TCP`` for\n    Jython compatibility. (:pr:`1375`)\n-   When using an adhoc SSL cert with :func:`~serving.run_simple`, the\n    cert is shown as self-signed rather than signed by an invalid\n    authority. (:pr:`1430`)\n-   The development server logs the unquoted IRI rather than the raw\n    request line, to make it easier to work with Unicode in request\n    paths during development. (:issue:`1115`)\n-   The development server recognizes ``ConnectionError`` on Python 3 to\n    silence client disconnects, and does not silence other ``OSErrors``\n    that may have been raised inside the application. (:pr:`1418`)\n-   The environ keys ``REQUEST_URI`` and ``RAW_URI`` contain the raw\n    path before it was percent-decoded. This is non-standard, but many\n    WSGI servers add them. Middleware could replace ``PATH_INFO`` with\n    this to route based on the raw value. (:pr:`1419`)\n-   :class:`~test.EnvironBuilder` doesn't set ``CONTENT_TYPE`` or\n    ``CONTENT_LENGTH`` in the environ if they aren't set. Previously\n    these used default values if they weren't set. Now it's possible to\n    distinguish between empty and unset values. (:pr:`1308`)\n-   The test client raises a ``ValueError`` if a query string argument\n    would overwrite a query string in the path. (:pr:`1338`)\n-   :class:`test.EnvironBuilder` and :class:`test.Client` take a\n    ``json`` argument instead of manually passing ``data`` and\n    ``content_type``. This is serialized using the\n    :meth:`test.EnvironBuilder.json_dumps` method. (:pr:`1404`)\n-   :class:`test.Client` redirect handling is rewritten. (:pr:`1402`)\n\n    -   The redirect environ is copied from the initial request environ.\n    -   Script root and path are correctly distinguished when\n        redirecting to a path under the root.\n    -   The HEAD method is not changed to GET.\n    -   307 and 308 codes preserve the method and body. All others\n        ignore the body and related headers.\n    -   Headers are passed to the new request for all codes, following\n        what browsers do.\n    -   :class:`test.EnvironBuilder` sets the content type and length\n        headers in addition to the WSGI keys when detecting them from\n        the data.\n    -   Intermediate response bodies are iterated over even when\n        ``buffered=False`` to ensure iterator middleware can run cleanup\n        code safely. Only the last response is not buffered. (:pr:`988`)\n\n-   :class:`~test.EnvironBuilder`, :class:`~datastructures.FileStorage`,\n    and :func:`wsgi.get_input_stream` no longer share a global\n    ``_empty_stream`` instance. This improves test isolation by\n    preventing cases where closing the stream in one request would\n    affect other usages. (:pr:`1340`)\n-   The default ``SecureCookie.serialization_method`` will change from\n    :mod:`pickle` to :mod:`json` in 1.0. To upgrade existing tokens,\n    override :meth:`~contrib.securecookie.SecureCookie.unquote` to try\n    ``pickle`` if ``json`` fails. (:pr:`1413`)\n-   ``CGIRootFix`` no longer modifies ``PATH_INFO`` for very old\n    versions of Lighttpd. ``LighttpdCGIRootFix`` was renamed to\n    ``CGIRootFix`` in 0.9. Both are deprecated and will be removed in\n    version 1.0. (:pr:`1141`)\n-   :class:`werkzeug.wrappers.json.JSONMixin` has been replaced with\n    Flask's implementation. Check the docs for the full API.\n    (:pr:`1445`)\n-   The contrib modules are deprecated and will either be moved into\n    ``werkzeug`` core or removed completely in version 1.0. Some modules\n    that already issued deprecation warnings have been removed. Be sure\n    to run or test your code with\n    ``python -W default::DeprecationWarning`` to catch any deprecated\n    code you're using. (:issue:`4`)\n\n    -   ``LintMiddleware`` has moved to :mod:`werkzeug.middleware.lint`.\n    -   ``ProfilerMiddleware`` has moved to\n        :mod:`werkzeug.middleware.profiler`.\n    -   ``ProxyFix`` has moved to :mod:`werkzeug.middleware.proxy_fix`.\n    -   ``JSONRequestMixin`` has moved to :mod:`werkzeug.wrappers.json`.\n    -   ``cache`` has been extracted into a separate project,\n        `cachelib <https://github.com/pallets/cachelib>`_. The version\n        in Werkzeug is deprecated.\n    -   ``securecookie`` and ``sessions`` have been extracted into a\n        separate project,\n        `secure-cookie <https://github.com/pallets/secure-cookie>`_. The\n        version in Werkzeug is deprecated.\n    -   Everything in ``fixers``, except ``ProxyFix``, is deprecated.\n    -   Everything in ``wrappers``, except ``JSONMixin``, is deprecated.\n    -   ``atom`` is deprecated. This did not fit in with the rest of\n        Werkzeug, and is better served by a dedicated library in the\n        community.\n    -   ``jsrouting`` is removed. Set URLs when rendering templates\n        or JSON responses instead.\n    -   ``limiter`` is removed. Its specific use is handled by Werkzeug\n        directly, but stream limiting is better handled by the WSGI\n        server in general.\n    -   ``testtools`` is removed. It did not offer significant benefit\n        over the default test client.\n    -   ``iterio`` is deprecated.\n\n-   :func:`wsgi.get_host` no longer looks at ``X-Forwarded-For``. Use\n    :class:`~middleware.proxy_fix.ProxyFix` to handle that.\n    (:issue:`609`, :pr:`1303`)\n-   :class:`~middleware.proxy_fix.ProxyFix` is refactored to support\n    more headers, multiple values, and more secure configuration.\n\n    -   Each header supports multiple values. The trusted number of\n        proxies is configured separately for each header. The\n        ``num_proxies`` argument is deprecated. (:pr:`1314`)\n    -   Sets ``SERVER_NAME`` and ``SERVER_PORT`` based on\n        ``X-Forwarded-Host``. (:pr:`1314`)\n    -   Sets ``SERVER_PORT`` and modifies ``HTTP_HOST`` based on\n        ``X-Forwarded-Port``. (:issue:`1023`, :pr:`1304`)\n    -   Sets ``SCRIPT_NAME`` based on ``X-Forwarded-Prefix``.\n        (:issue:`1237`)\n    -   The original WSGI environment values are stored in the\n        ``werkzeug.proxy_fix.orig`` key, a dict. The individual keys\n        ``werkzeug.proxy_fix.orig_remote_addr``,\n        ``werkzeug.proxy_fix.orig_wsgi_url_scheme``, and\n        ``werkzeug.proxy_fix.orig_http_host`` are deprecated.\n\n-   Middleware from ``werkzeug.wsgi`` has moved to separate modules\n    under ``werkzeug.middleware``, along with the middleware moved from\n    ``werkzeug.contrib``. The old ``werkzeug.wsgi`` imports are\n    deprecated and will be removed in version 1.0. (:pr:`1452`)\n\n    -   ``werkzeug.wsgi.DispatcherMiddleware`` has moved to\n        :class:`werkzeug.middleware.dispatcher.DispatcherMiddleware`.\n    -   ``werkzeug.wsgi.ProxyMiddleware`` as moved to\n        :class:`werkzeug.middleware.http_proxy.ProxyMiddleware`.\n    -   ``werkzeug.wsgi.SharedDataMiddleware`` has moved to\n        :class:`werkzeug.middleware.shared_data.SharedDataMiddleware`.\n\n-   :class:`~middleware.http_proxy.ProxyMiddleware` proxies the query\n    string. (:pr:`1252`)\n-   The filenames generated by\n    :class:`~middleware.profiler.ProfilerMiddleware` can be customized.\n    (:issue:`1283`)\n-   The ``werkzeug.wrappers`` module has been converted to a package,\n    and its various classes have been organized into separate modules.\n    Any previously documented classes, understood to be the existing\n    public API, are still importable from ``werkzeug.wrappers``, or may\n    be imported from their specific modules. (:pr:`1456`)\n\n\nVersion 0.14.1\n--------------\n\nReleased on December 31st 2017\n\n- Resolved a regression with status code handling in the integrated\n  development server.\n\nVersion 0.14\n------------\n\nReleased on December 31st 2017\n\n- HTTP exceptions are now automatically caught by\n  ``Request.application``.\n- Added support for edge as browser.\n- Added support for platforms that lack ``SpooledTemporaryFile``.\n- Add support for etag handling through if-match\n- Added support for the SameSite cookie attribute.\n- Added ``werkzeug.wsgi.ProxyMiddleware``\n- Implemented ``has`` for ``NullCache``\n- ``get_multi`` on cache clients now returns lists all the time.\n- Improved the watchdog observer shutdown for the reloader to not crash\n  on exit on older Python versions.\n- Added support for ``filename*`` filename attributes according to\n  RFC 2231\n- Resolved an issue where machine ID for the reloader PIN was not\n  read accurately on windows.\n- Added a workaround for syntax errors in init files in the reloader.\n- Added support for using the reloader with console scripts on windows.\n- The built-in HTTP server will no longer close a connection in cases\n  where no HTTP body is expected (204, 204, HEAD requests etc.)\n- The ``EnvironHeaders`` object now skips over empty content type and\n  lengths if they are set to falsy values.\n- Werkzeug will no longer send the content-length header on 1xx or\n  204/304 responses.\n- Cookie values are now also permitted to include slashes and equal\n  signs without quoting.\n- Relaxed the regex for the routing converter arguments.\n- If cookies are sent without values they are now assumed to have an\n  empty value and the parser accepts this.  Previously this could have\n  corrupted cookies that followed the value.\n- The test ``Client`` and ``EnvironBuilder`` now support mimetypes like\n  the request object does.\n- Added support for static weights in URL rules.\n- Better handle some more complex reloader scenarios where sys.path\n  contained non directory paths.\n- ``EnvironHeaders`` no longer raises weird errors if non string keys\n  are passed to it.\n\n\nVersion 0.13\n------------\n\nReleased on December 7th 2017\n\n- **Deprecate support for Python 2.6 and 3.3.** CI tests will not run\n  for these versions, and support will be dropped completely in the next\n  version. (:issue:`pallets/meta#24`)\n- Raise ``TypeError`` when port is not an integer. (:pr:`1088`)\n- Fully deprecate ``werkzeug.script``. Use `Click`_ instead.\n  (:pr:`1090`)\n- ``response.age`` is parsed as a ``timedelta``. Previously, it was\n  incorrectly treated as a ``datetime``. The header value is an integer\n  number of seconds, not a date string. (:pr:`414`)\n- Fix a bug in ``TypeConversionDict`` where errors are not propagated\n  when using the converter. (:issue:`1102`)\n- ``Authorization.qop`` is a string instead of a set, to comply with\n  RFC 2617. (:pr:`984`)\n- An exception is raised when an encoded cookie is larger than, by\n  default, 4093 bytes. Browsers may silently ignore cookies larger than\n  this. ``BaseResponse`` has a new attribute ``max_cookie_size`` and\n  ``dump_cookie`` has a new argument ``max_size`` to configure this.\n  (:pr:`780`, :pr:`1109`)\n- Fix a TypeError in ``werkzeug.contrib.lint.GuardedIterator.close``.\n  (:pr:`1116`)\n- ``BaseResponse.calculate_content_length`` now correctly works for\n  Unicode responses on Python 3. It first encodes using\n  ``iter_encoded``. (:issue:`705`)\n- Secure cookie contrib works with string secret key on Python 3.\n  (:pr:`1205`)\n- Shared data middleware accepts a list instead of a dict of static\n  locations to preserve lookup order. (:pr:`1197`)\n- HTTP header values without encoding can contain single quotes.\n  (:pr:`1208`)\n- The built-in dev server supports receiving requests with chunked\n  transfer encoding. (:pr:`1198`)\n\n.. _Click: https://palletsprojects.com/p/click/\n\n\nVersion 0.12.2\n--------------\n\nReleased on May 16 2017\n\n- Fix regression: Pull request ``#892`` prevented Werkzeug from correctly\n  logging the IP of a remote client behind a reverse proxy, even when using\n  `ProxyFix`.\n- Fix a bug in `safe_join` on Windows.\n\nVersion 0.12.1\n--------------\n\nReleased on March 15th 2017\n\n- Fix crash of reloader (used on debug mode) on Windows.\n  (`OSError: [WinError 10038]`). See pull request ``#1081``\n- Partially revert change to class hierarchy of `Headers`. See ``#1084``.\n\nVersion 0.12\n------------\n\nReleased on March 10th 2017\n\n- Spit out big deprecation warnings for werkzeug.script\n- Use `inspect.getfullargspec` internally when available as\n  `inspect.getargspec` is gone in 3.6\n- Added support for status code 451 and 423\n- Improved the build error suggestions.  In particular only if\n  someone stringifies the error will the suggestions be calculated.\n- Added support for uWSGI's caching backend.\n- Fix a bug where iterating over a `FileStorage` would result in an infinite\n  loop.\n- Datastructures now inherit from the relevant baseclasses from the\n  `collections` module in the stdlib. See #794.\n- Add support for recognizing NetBSD, OpenBSD, FreeBSD, DragonFlyBSD platforms\n  in the user agent string.\n- Recognize SeaMonkey browser name and version correctly\n- Recognize Baiduspider, and bingbot user agents\n- If `LocalProxy`'s wrapped object is a function, refer to it with __wrapped__\n  attribute.\n- The defaults of ``generate_password_hash`` have been changed to more secure\n  ones, see pull request ``#753``.\n- Add support for encoding in options header parsing, see pull request\n  ``#933``.\n- ``test.Client`` now properly handles Location headers with relative URLs, see\n  pull request ``#879``.\n- When `HTTPException` is raised, it now prints the description, for easier\n  debugging.\n- Werkzeug's dict-like datastructures now have ``view``-methods under Python 2,\n  see pull request ``#968``.\n- Fix a bug in ``MultiPartParser`` when no ``stream_factory`` was provided\n  during initialization, see pull request ``#973``.\n- Disable autocorrect and spellchecker in the debugger middleware's Python\n  prompt, see pull request ``#994``.\n- Don't redirect to slash route when method doesn't match, see pull request\n  ``#907``.\n- Fix a bug when using ``SharedDataMiddleware`` with frozen packages, see pull\n  request ``#959``.\n- `Range` header parsing function fixed for invalid values ``#974``.\n- Add support for byte Range Requests, see pull request ``#978``.\n- Use modern cryptographic defaults in the dev servers ``#1004``.\n- the post() method of the test client now accept file object through the data\n  parameter.\n- Color run_simple's terminal output based on HTTP codes ``#1013``.\n- Fix self-XSS in debugger console, see ``#1031``.\n- Fix IPython 5.x shell support, see ``#1033``.\n- Change Accept datastructure to sort by specificity first, allowing for more\n  accurate results when using ``best_match`` for mime types (for example in\n  ``requests.accept_mimetypes.best_match``)\n\nVersion 0.11.16\n---------------\n\n- werkzeug.serving: set CONTENT_TYPE / CONTENT_LENGTH if only they're provided by the client\n- werkzeug.serving: Fix crash of reloader when using `python -m werkzeug.serving`.\n\nVersion 0.11.15\n---------------\n\nReleased on December 30th 2016.\n\n- Bugfix for the bugfix in the previous release.\n\nVersion 0.11.14\n---------------\n\nReleased on December 30th 2016.\n\n- Check if platform can fork before importing ``ForkingMixIn``, raise exception\n  when creating ``ForkingWSGIServer`` on such a platform, see PR ``#999``.\n\nVersion 0.11.13\n---------------\n\nReleased on December 26th 2016.\n\n- Correct fix for the reloader issuer on certain Windows installations.\n\nVersion 0.11.12\n---------------\n\nReleased on December 26th 2016.\n\n- Fix more bugs in multidicts regarding empty lists. See ``#1000``.\n- Add some docstrings to some `EnvironBuilder` properties that were previously\n  unintentionally missing.\n- Added a workaround for the reloader on windows.\n\nVersion 0.11.11\n---------------\n\nReleased on August 31st 2016.\n\n- Fix JSONRequestMixin for Python3. See #731\n- Fix broken string handling in test client when passing integers. See #852\n- Fix a bug in ``parse_options_header`` where an invalid content type\n  starting with comma or semi-colon would result in an invalid return value,\n  see issue ``#995``.\n- Fix a bug in multidicts when passing empty lists as values, see issue\n  ``#979``.\n- Fix a security issue that allows XSS on the Werkzeug debugger. See ``#1001``.\n\nVersion 0.11.10\n---------------\n\nReleased on May 24th 2016.\n\n- Fixed a bug that occurs when running on Python 2.6 and using a broken locale.\n  See pull request #912.\n- Fixed a crash when running the debugger on Google App Engine. See issue #925.\n- Fixed an issue with multipart parsing that could cause memory exhaustion.\n\nVersion 0.11.9\n--------------\n\nReleased on April 24th 2016.\n\n- Corrected an issue that caused the debugger not to use the\n  machine GUID on POSIX systems.\n- Corrected a Unicode error on Python 3 for the debugger's\n  PIN usage.\n- Corrected the timestamp verification in the pin debug code.\n  Without this fix the pin was remembered for too long.\n\nVersion 0.11.8\n--------------\n\nReleased on April 15th 2016.\n\n- fixed a problem with the machine GUID detection code on OS X\n  on Python 3.\n\nVersion 0.11.7\n--------------\n\nReleased on April 14th 2016.\n\n- fixed a regression on Python 3 for the debugger.\n\nVersion 0.11.6\n--------------\n\nReleased on April 14th 2016.\n\n- werkzeug.serving: Still show the client address on bad requests.\n- improved the PIN based protection for the debugger to make it harder to\n  brute force via trying cookies.  Please keep in mind that the debugger\n  *is not intended for running on production environments*\n- increased the pin timeout to a week to make it less annoying for people\n  which should decrease the chance that users disable the pin check\n  entirely.\n- werkzeug.serving: Fix broken HTTP_HOST when path starts with double slash.\n\nVersion 0.11.5\n--------------\n\nReleased on March 22nd 2016.\n\n- werkzeug.serving: Fix crash when attempting SSL connection to HTTP server.\n\nVersion 0.11.4\n--------------\n\nReleased on February 14th 2016.\n\n- Fixed werkzeug.serving not working from -m flag.\n- Fixed incorrect weak etag handling.\n\nVersion 0.11.3\n--------------\n\nReleased on December 20th 2015.\n\n- Fixed an issue with copy operations not working against\n  proxies.\n- Changed the logging operations of the development server to\n  correctly log where the server is running in all situations\n  again.\n- Fixed another regression with SSL wrapping similar to the\n  fix in 0.11.2 but for a different code path.\n\nVersion 0.11.2\n--------------\n\nReleased on November 12th 2015.\n\n- Fix inheritable sockets on Windows on Python 3.\n- Fixed an issue with the forking server not starting any longer.\n- Fixed SSL wrapping on platforms that supported opening sockets\n  by file descriptor.\n- No longer log from the watchdog reloader.\n- Unicode errors in hosts are now better caught or converted into\n  bad request errors.\n\nVersion 0.11.1\n--------------\n\nReleased on November 10th 2015.\n\n- Fixed a regression on Python 3 in the debugger.\n\nVersion 0.11\n------------\n\nReleased on November 8th 2015, codename Gleisbaumaschine.\n\n- Added ``reloader_paths`` option to ``run_simple`` and other functions in\n  ``werkzeug.serving``. This allows the user to completely override the Python\n  module watching of Werkzeug with custom paths.\n- Many custom cached properties of Werkzeug's classes are now subclasses of\n  Python's ``property`` type (issue ``#616``).\n- ``bind_to_environ`` now doesn't differentiate between implicit and explicit\n  default port numbers in ``HTTP_HOST`` (pull request ``#204``).\n- ``BuildErrors`` are now more informative. They come with a complete sentence\n  as error message, and also provide suggestions (pull request ``#691``).\n- Fix a bug in the user agent parser where Safari's build number instead of\n  version would be extracted (pull request ``#703``).\n- Fixed issue where RedisCache set_many was broken for twemproxy, which doesn't\n  support the default MULTI command (pull request ``#702``).\n- ``mimetype`` parameters on request and response classes are now always\n  converted to lowercase.\n- Changed cache so that cache never expires if timeout is 0. This also fixes\n  an issue with redis setex (issue ``#550``)\n- Werkzeug now assumes ``UTF-8`` as filesystem encoding on Unix if Python\n  detected it as ASCII.\n- New optional `has` method on caches.\n- Fixed various bugs in `parse_options_header` (pull request ``#643``).\n- If the reloader is enabled the server will now open the socket in the parent\n  process if this is possible.  This means that when the reloader kicks in\n  the connection from client will wait instead of tearing down.  This does\n  not work on all Python versions.\n- Implemented PIN based authentication for the debugger.  This can optionally\n  be disabled but is discouraged.  This change was necessary as it has been\n  discovered that too many people run the debugger in production.\n- Devserver no longer requires SSL module to be installed.\n\nVersion 0.10.5\n--------------\n\n(bugfix release, release date yet to be decided)\n\n- Reloader: Correctly detect file changes made by moving temporary files over\n  the original, which is e.g. the case with PyCharm (pull request ``#722``).\n- Fix bool behavior of ``werkzeug.datastructures.ETags`` under Python 3 (issue\n  ``#744``).\n\nVersion 0.10.4\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Re-release of 0.10.3 with packaging artifacts manually removed.\n\nVersion 0.10.3\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Re-release of 0.10.2 without packaging artifacts.\n\nVersion 0.10.2\n--------------\n\n(bugfix release, released on March 26th 2015)\n\n- Fixed issue where ``empty`` could break third-party libraries that relied on\n  keyword arguments (pull request ``#675``)\n- Improved ``Rule.empty`` by providing a ```get_empty_kwargs`` to allow setting\n  custom kwargs without having to override entire ``empty`` method. (pull\n  request ``#675``)\n- Fixed ```extra_files``` parameter for reloader to not cause startup\n  to crash when included in server params\n- Using `MultiDict` when building URLs is now not supported again. The behavior\n  introduced several regressions.\n- Fix performance problems with stat-reloader (pull request ``#715``).\n\nVersion 0.10.1\n--------------\n\n(bugfix release, released on February 3rd 2015)\n\n- Fixed regression with multiple query values for URLs (pull request ``#667``).\n- Fix issues with eventlet's monkeypatching and the builtin server (pull\n  request ``#663``).\n\nVersion 0.10\n------------\n\nReleased on January 30th 2015, codename Bagger.\n\n- Changed the error handling of and improved testsuite for the caches in\n  ``contrib.cache``.\n- Fixed a bug on Python 3 when creating adhoc ssl contexts, due to `sys.maxint`\n  not being defined.\n- Fixed a bug on Python 3, that caused\n  :func:`~werkzeug.serving.make_ssl_devcert` to fail with an exception.\n- Added exceptions for 504 and 505.\n- Added support for ChromeOS detection.\n- Added UUID converter to the routing system.\n- Added message that explains how to quit the server.\n- Fixed a bug on Python 2, that caused ``len`` for\n  :class:`werkzeug.datastructures.CombinedMultiDict` to crash.\n- Added support for stdlib pbkdf2 hmac if a compatible digest\n  is found.\n- Ported testsuite to use ``py.test``.\n- Minor optimizations to various middlewares (pull requests ``#496`` and\n  ``#571``).\n- Use stdlib ``ssl`` module instead of ``OpenSSL`` for the builtin server\n  (issue ``#434``). This means that OpenSSL contexts are not supported anymore,\n  but instead ``ssl.SSLContext`` from the stdlib.\n- Allow protocol-relative URLs when building external URLs.\n- Fixed Atom syndication to print time zone offset for tz-aware datetime\n  objects (pull request ``#254``).\n- Improved reloader to track added files and to recover from broken\n  sys.modules setups with syntax errors in packages.\n- ``cache.RedisCache`` now supports arbitrary ``**kwargs`` for the redis\n  object.\n- ``werkzeug.test.Client`` now uses the original request method when resolving\n  307 redirects (pull request ``#556``).\n- ``werkzeug.datastructures.MIMEAccept`` now properly deals with mimetype\n  parameters (pull request ``#205``).\n- ``werkzeug.datastructures.Accept`` now handles a quality of ``0`` as\n  intolerable, as per RFC 2616 (pull request ``#536``).\n- ``werkzeug.urls.url_fix`` now properly encodes hostnames with ``idna``\n  encoding (issue ``#559``). It also doesn't crash on malformed URLs anymore\n  (issue ``#582``).\n- ``werkzeug.routing.MapAdapter.match`` now recognizes the difference between\n  the path ``/`` and an empty one (issue ``#360``).\n- The interactive debugger now tries to decode non-ascii filenames (issue\n  ``#469``).\n- Increased default key size of generated SSL certificates to 1024 bits (issue\n  ``#611``).\n- Added support for specifying a ``Response`` subclass to use when calling\n  :func:`~werkzeug.utils.redirect`\\ .\n- ``werkzeug.test.EnvironBuilder`` now doesn't use the request method anymore\n  to guess the content type, and purely relies on the ``form``, ``files`` and\n  ``input_stream`` properties (issue ``#620``).\n- Added Symbian to the user agent platform list.\n- Fixed make_conditional to respect automatically_set_content_length\n- Unset ``Content-Length`` when writing to response.stream (issue ``#451``)\n- ``wrappers.Request.method`` is now always uppercase, eliminating\n  inconsistencies of the WSGI environment (issue ``647``).\n- ``routing.Rule.empty`` now works correctly with subclasses of ``Rule`` (pull\n  request ``#645``).\n- Made map updating safe in light of concurrent updates.\n- Allow multiple values for the same field for url building (issue ``#658``).\n\nVersion 0.9.7\n-------------\n\n(bugfix release, release date to be decided)\n\n- Fix unicode problems in ``werkzeug.debug.tbtools``.\n- Fix Python 3-compatibility problems in ``werkzeug.posixemulation``.\n- Backport fix of fatal typo for ``ImmutableList`` (issue ``#492``).\n- Make creation of the cache dir for ``FileSystemCache`` atomic (issue\n  ``#468``).\n- Use native strings for memcached keys to work with Python 3 client (issue\n  ``#539``).\n- Fix charset detection for ``werkzeug.debug.tbtools.Frame`` objects (issues\n  ``#547`` and ``#532``).\n- Fix ``AttributeError`` masking in ``werkzeug.utils.import_string`` (issue\n  ``#182``).\n- Explicitly shut down server (issue ``#519``).\n- Fix timeouts greater than 2592000 being misinterpreted as UNIX timestamps in\n  ``werkzeug.contrib.cache.MemcachedCache`` (issue ``#533``).\n- Fix bug where ``werkzeug.exceptions.abort`` would raise an arbitrary subclass\n  of the expected class (issue ``#422``).\n- Fix broken ``jsrouting`` (due to removal of ``werkzeug.templates``)\n- ``werkzeug.urls.url_fix`` now doesn't crash on malformed URLs anymore, but\n  returns them unmodified. This is a cheap workaround for ``#582``, the proper\n  fix is included in version 0.10.\n- The repr of ``werkzeug.wrappers.Request`` doesn't crash on non-ASCII-values\n  anymore (pull request ``#466``).\n- Fix bug in ``cache.RedisCache`` when combined with ``redis.StrictRedis``\n  object (pull request ``#583``).\n- The ``qop`` parameter for ``WWW-Authenticate`` headers is now always quoted,\n  as required by RFC 2617 (issue ``#633``).\n- Fix bug in ``werkzeug.contrib.cache.SimpleCache`` with Python 3 where add/set\n  may throw an exception when pruning old entries from the cache (pull request\n  ``#651``).\n\nVersion 0.9.6\n-------------\n\n(bugfix release, released on June 7th 2014)\n\n- Added a safe conversion for IRI to URI conversion and use that\n  internally to work around issues with spec violations for\n  protocols such as ``itms-service``.\n\nVersion 0.9.7\n-------------\n\n- Fixed uri_to_iri() not re-encoding hashes in query string parameters.\n\nVersion 0.9.5\n-------------\n\n(bugfix release, released on June 7th 2014)\n\n- Forward charset argument from request objects to the environ\n  builder.\n- Fixed error handling for missing boundaries in multipart data.\n- Fixed session creation on systems without ``os.urandom()``.\n- Fixed pluses in dictionary keys not being properly URL encoded.\n- Fixed a problem with deepcopy not working for multi dicts.\n- Fixed a double quoting issue on redirects.\n- Fixed a problem with unicode keys appearing in headers on 2.x.\n- Fixed a bug with unicode strings in the test builder.\n- Fixed a unicode bug on Python 3 in the WSGI profiler.\n- Fixed an issue with the safe string compare function on\n  Python 2.7.7 and Python 3.4.\n\nVersion 0.9.4\n-------------\n\n(bugfix release, released on August 26th 2013)\n\n- Fixed an issue with Python 3.3 and an edge case in cookie parsing.\n- Fixed decoding errors not handled properly through the WSGI\n  decoding dance.\n- Fixed URI to IRI conversion incorrectly decoding percent signs.\n\nVersion 0.9.3\n-------------\n\n(bugfix release, released on July 25th 2013)\n\n- Restored behavior of the ``data`` descriptor of the request class to pre 0.9\n  behavior.  This now also means that ``.data`` and ``.get_data()`` have\n  different behavior.  New code should use ``.get_data()`` always.\n\n  In addition to that there is now a flag for the ``.get_data()`` method that\n  controls what should happen with form data parsing and the form parser will\n  honor cached data.  This makes dealing with custom form data more consistent.\n\nVersion 0.9.2\n-------------\n\n(bugfix release, released on July 18th 2013)\n\n- Added `unsafe` parameter to :func:`~werkzeug.urls.url_quote`.\n- Fixed an issue with :func:`~werkzeug.urls.url_quote_plus` not quoting\n  `'+'` correctly.\n- Ported remaining parts of :class:`~werkzeug.contrib.RedisCache` to\n  Python 3.3.\n- Ported remaining parts of :class:`~werkzeug.contrib.MemcachedCache` to\n  Python 3.3\n- Fixed a deprecation warning in the contrib atom module.\n- Fixed a regression with setting of content types through the\n  headers dictionary instead with the content type parameter.\n- Use correct name for stdlib secure string comparison function.\n- Fixed a wrong reference in the docstring of\n  :func:`~werkzeug.local.release_local`.\n- Fixed an `AttributeError` that sometimes occurred when accessing the\n  :attr:`werkzeug.wrappers.BaseResponse.is_streamed` attribute.\n\nVersion 0.9.1\n-------------\n\n(bugfix release, released on June 14th 2013)\n\n- Fixed an issue with integers no longer being accepted in certain\n  parts of the routing system or URL quoting functions.\n- Fixed an issue with `url_quote` not producing the right escape\n  codes for single digit codepoints.\n- Fixed an issue with :class:`~werkzeug.wsgi.SharedDataMiddleware` not\n  reading the path correctly and breaking on etag generation in some\n  cases.\n- Properly handle `Expect: 100-continue` in the development server\n  to resolve issues with curl.\n- Automatically exhaust the input stream on request close.  This should\n  fix issues where not touching request files results in a timeout.\n- Fixed exhausting of streams not doing anything if a non-limited\n  stream was passed into the multipart parser.\n- Raised the buffer sizes for the multipart parser.\n\nVersion 0.9\n-----------\n\nReleased on June 13nd 2013, codename Planierraupe.\n\n- Added support for :meth:`~werkzeug.wsgi.LimitedStream.tell`\n  on the limited stream.\n- :class:`~werkzeug.datastructures.ETags` now is nonzero if it\n  contains at least one etag of any kind, including weak ones.\n- Added a workaround for a bug in the stdlib for SSL servers.\n- Improved SSL interface of the devserver so that it can generate\n  certificates easily and load them from files.\n- Refactored test client to invoke the open method on the class\n  for redirects.  This makes subclassing more powerful.\n- :func:`werkzeug.wsgi.make_chunk_iter` and\n  :func:`werkzeug.wsgi.make_line_iter` now support processing of\n  iterators and streams.\n- URL generation by the routing system now no longer quotes\n  ``+``.\n- URL fixing now no longer quotes certain reserved characters.\n- The :func:`werkzeug.security.generate_password_hash` and\n  check functions now support any of the hashlib algorithms.\n- `wsgi.get_current_url` is now ascii safe for browsers sending\n  non-ascii data in query strings.\n- improved parsing behavior for :func:`werkzeug.http.parse_options_header`\n- added more operators to local proxies.\n- added a hook to override the default converter in the routing\n  system.\n- The description field of HTTP exceptions is now always escaped.\n  Use markup objects to disable that.\n- Added number of proxy argument to the proxy fix to make it more\n  secure out of the box on common proxy setups.  It will by default\n  no longer trust the x-forwarded-for header as much as it did\n  before.\n- Added support for fragment handling in URI/IRI functions.\n- Added custom class support for :func:`werkzeug.http.parse_dict_header`.\n- Renamed `LighttpdCGIRootFix` to `CGIRootFix`.\n- Always treat `+` as safe when fixing URLs as people love misusing them.\n- Added support to profiling into directories in the contrib profiler.\n- The escape function now by default escapes quotes.\n- Changed repr of exceptions to be less magical.\n- Simplified exception interface to no longer require environments\n  to be passed to receive the response object.\n- Added sentinel argument to IterIO objects.\n- Added pbkdf2 support for the security module.\n- Added a plain request type that disables all form parsing to only\n  leave the stream behind.\n- Removed support for deprecated `fix_headers`.\n- Removed support for deprecated `header_list`.\n- Removed support for deprecated parameter for `iter_encoded`.\n- Removed support for deprecated non-silent usage of the limited\n  stream object.\n- Removed support for previous dummy `writable` parameter on\n  the cached property.\n- Added support for explicitly closing request objects to close\n  associated resources.\n- Conditional request handling or access to the data property on responses no\n  longer ignores direct passthrough mode.\n- Removed werkzeug.templates and werkzeug.contrib.kickstart.\n- Changed host lookup logic for forwarded hosts to allow lists of\n  hosts in which case only the first one is picked up.\n- Added `wsgi.get_query_string`, `wsgi.get_path_info` and\n  `wsgi.get_script_name` and made the `wsgi.pop_path_info` and\n  `wsgi.peek_path_info` functions perform unicode decoding.  This\n  was necessary to avoid having to expose the WSGI encoding dance\n  on Python 3.\n- Added `content_encoding` and `content_md5` to the request object's\n  common request descriptor mixin.\n- added `options` and `trace` to the test client.\n- Overhauled the utilization of the input stream to be easier to use\n  and better to extend.  The detection of content payload on the input\n  side is now more compliant with HTTP by detecting off the content\n  type header instead of the request method.  This also now means that\n  the stream property on the request class is always available instead\n  of just when the parsing fails.\n- Added support for using :class:`werkzeug.wrappers.BaseResponse` in a with\n  statement.\n- Changed `get_app_iter` to fetch the response early so that it does not\n  fail when wrapping a response iterable.  This makes filtering easier.\n- Introduced `get_data` and `set_data` methods for responses.\n- Introduced `get_data` for requests.\n- Soft deprecated the `data` descriptors for request and response objects.\n- Added `as_bytes` operations to some of the headers to simplify working\n  with things like cookies.\n- Made the debugger paste tracebacks into github's gist service as\n  private pastes.\n\nVersion 0.8.4\n-------------\n\n(bugfix release, release date to be announced)\n\n- Added a favicon to the debugger which fixes problem with\n  state changes being triggered through a request to\n  /favicon.ico in Google Chrome.  This should fix some\n  problems with Flask and other frameworks that use\n  context local objects on a stack with context preservation\n  on errors.\n- Fixed an issue with scrolling up in the debugger.\n- Fixed an issue with debuggers running on a different URL\n  than the URL root.\n- Fixed a problem with proxies not forwarding some rarely\n  used special methods properly.\n- Added a workaround to prevent the XSS protection from Chrome\n  breaking the debugger.\n- Skip redis tests if redis is not running.\n- Fixed a typo in the multipart parser that caused content-type\n  to not be picked up properly.\n\nVersion 0.8.3\n-------------\n\n(bugfix release, released on February 5th 2012)\n\n- Fixed another issue with :func:`werkzeug.wsgi.make_line_iter`\n  where lines longer than the buffer size were not handled\n  properly.\n- Restore stdout after debug console finished executing so\n  that the debugger can be used on GAE better.\n- Fixed a bug with the redis cache for int subclasses\n  (affects bool caching).\n- Fixed an XSS problem with redirect targets coming from\n  untrusted sources.\n- Redis cache backend now supports password authentication.\n\nVersion 0.8.2\n-------------\n\n(bugfix release, released on December 16th 2011)\n\n- Fixed a problem with request handling of the builtin server\n  not responding to socket errors properly.\n- The routing request redirect exception's code attribute is now\n  used properly.\n- Fixed a bug with shutdowns on Windows.\n- Fixed a few unicode issues with non-ascii characters being\n  hardcoded in URL rules.\n- Fixed two property docstrings being assigned to fdel instead\n  of ``__doc__``.\n- Fixed an issue where CRLF line endings could be split into two\n  by the line iter function, causing problems with multipart file\n  uploads.\n\nVersion 0.8.1\n-------------\n\n(bugfix release, released on September 30th 2011)\n\n- Fixed an issue with the memcache not working properly.\n- Fixed an issue for Python 2.7.1 and higher that broke\n  copying of multidicts with :func:`copy.copy`.\n- Changed hashing methodology of immutable ordered multi dicts\n  for a potential problem with alternative Python implementations.\n\nVersion 0.8\n-----------\n\nReleased on September 29th 2011, codename L\u00f6tkolben\n\n- Removed data structure specific KeyErrors for a general\n  purpose :exc:`~werkzeug.exceptions.BadRequestKeyError`.\n- Documented :meth:`werkzeug.wrappers.BaseRequest._load_form_data`.\n- The routing system now also accepts strings instead of\n  dictionaries for the `query_args` parameter since we're only\n  passing them through for redirects.\n- Werkzeug now automatically sets the content length immediately when\n  the :attr:`~werkzeug.wrappers.BaseResponse.data` attribute is set\n  for efficiency and simplicity reasons.\n- The routing system will now normalize server names to lowercase.\n- The routing system will no longer raise ValueErrors in case the\n  configuration for the server name was incorrect.  This should make\n  deployment much easier because you can ignore that factor now.\n- Fixed a bug with parsing HTTP digest headers.  It rejected headers\n  with missing nc and nonce params.\n- Proxy fix now also updates wsgi.url_scheme based on X-Forwarded-Proto.\n- Added support for key prefixes to the redis cache.\n- Added the ability to suppress some auto corrections in the wrappers\n  that are now controlled via `autocorrect_location_header` and\n  `automatically_set_content_length` on the response objects.\n- Werkzeug now uses a new method to check that the length of incoming\n  data is complete and will raise IO errors by itself if the server\n  fails to do so.\n- :func:`~werkzeug.wsgi.make_line_iter` now requires a limit that is\n  not higher than the length the stream can provide.\n- Refactored form parsing into a form parser class that makes it possible\n  to hook into individual parts of the parsing process for debugging and\n  extending.\n- For conditional responses the content length is no longer set when it\n  is already there and added if missing.\n- Immutable datastructures are hashable now.\n- Headers datastructure no longer allows newlines in values to avoid\n  header injection attacks.\n- Made it possible through subclassing to select a different remote\n  addr in the proxy fix.\n- Added stream based URL decoding.  This reduces memory usage on large\n  transmitted form data that is URL decoded since Werkzeug will no longer\n  load all the unparsed data into memory.\n- Memcache client now no longer uses the buggy cmemcache module and\n  supports pylibmc.  GAE is not tried automatically and the dedicated\n  class is no longer necessary.\n- Redis cache now properly serializes data.\n- Removed support for Python 2.4\n\nVersion 0.7.2\n-------------\n\n(bugfix release, released on September 30th 2011)\n\n- Fixed a CSRF problem with the debugger.\n- The debugger is now generating private pastes on lodgeit.\n- If URL maps are now bound to environments the query arguments\n  are properly decoded from it for redirects.\n\nVersion 0.7.1\n-------------\n\n(bugfix release, released on July 26th 2011)\n\n- Fixed a problem with newer versions of IPython.\n- Disabled pyinotify based reloader which does not work reliably.\n\nVersion 0.7\n-----------\n\nReleased on July 24th 2011, codename Schraubschl\u00fcssel\n\n- Add support for python-libmemcached to the Werkzeug cache abstraction\n  layer.\n- Improved :func:`url_decode` and :func:`url_encode` performance.\n- Fixed an issue where the SharedDataMiddleware could cause an\n  internal server error on weird paths when loading via pkg_resources.\n- Fixed an URL generation bug that caused URLs to be invalid if a\n  generated component contains a colon.\n- :func:`werkzeug.import_string` now works with partially set up\n  packages properly.\n- Disabled automatic socket switching for IPv6 on the development\n  server due to problems it caused.\n- Werkzeug no longer overrides the Date header when creating a\n  conditional HTTP response.\n- The routing system provides a method to retrieve the matching\n  methods for a given path.\n- The routing system now accepts a parameter to change the encoding\n  error behaviour.\n- The local manager can now accept custom ident functions in the\n  constructor that are forwarded to the wrapped local objects.\n- url_unquote_plus now accepts unicode strings again.\n- Fixed an issue with the filesystem session support's prune\n  function and concurrent usage.\n- Fixed a problem with external URL generation discarding the port.\n- Added support for pylibmc to the Werkzeug cache abstraction layer.\n- Fixed an issue with the new multipart parser that happened when\n  a linebreak happened to be on the chunk limit.\n- Cookies are now set properly if ports are in use.  A runtime error\n  is raised if one tries to set a cookie for a domain without a dot.\n- Fixed an issue with Template.from_file not working for file\n  descriptors.\n- Reloader can now use inotify to track reloads.  This requires the\n  pyinotify library to be installed.\n- Werkzeug debugger can now submit to custom lodgeit installations.\n- redirect function's status code assertion now allows 201 to be used\n  as redirection code.  While it's not a real redirect, it shares\n  enough with redirects for the function to still be useful.\n- Fixed securecookie for pypy.\n- Fixed `ValueErrors` being raised on calls to `best_match` on\n  `MIMEAccept` objects when invalid user data was supplied.\n- Deprecated `werkzeug.contrib.kickstart` and `werkzeug.contrib.testtools`\n- URL routing now can be passed the URL arguments to keep them for\n  redirects.  In the future matching on URL arguments might also be\n  possible.\n- Header encoding changed from utf-8 to latin1 to support a port to\n  Python 3.  Bytestrings passed to the object stay untouched which\n  makes it possible to have utf-8 cookies.  This is a part where\n  the Python 3 version will later change in that it will always\n  operate on latin1 values.\n- Fixed a bug in the form parser that caused the last character to\n  be dropped off if certain values in multipart data are used.\n- Multipart parser now looks at the part-individual content type\n  header to override the global charset.\n- Introduced mimetype and mimetype_params attribute for the file\n  storage object.\n- Changed FileStorage filename fallback logic to skip special filenames\n  that Python uses for marking special files like stdin.\n- Introduced more HTTP exception classes.\n- `call_on_close` now can be used as a decorator.\n- Support for redis as cache backend.\n- Added `BaseRequest.scheme`.\n- Support for the RFC 5789 PATCH method.\n- New custom routing parser and better ordering.\n- Removed support for `is_behind_proxy`.  Use a WSGI middleware\n  instead that rewrites the `REMOTE_ADDR` according to your setup.\n  Also see the :class:`werkzeug.contrib.fixers.ProxyFix` for\n  a drop-in replacement.\n- Added cookie forging support to the test client.\n- Added support for host based matching in the routing system.\n- Switched from the default 'ignore' to the better 'replace'\n  unicode error handling mode.\n- The builtin server now adds a function named 'werkzeug.server.shutdown'\n  into the WSGI env to initiate a shutdown.  This currently only works\n  in Python 2.6 and later.\n- Headers are now assumed to be latin1 for better compatibility with\n  Python 3 once we have support.\n- Added :func:`werkzeug.security.safe_join`.\n- Added `accept_json` property analogous to `accept_html` on the\n  :class:`werkzeug.datastructures.MIMEAccept`.\n- :func:`werkzeug.utils.import_string` now fails with much better\n  error messages that pinpoint to the problem.\n- Added support for parsing of the `If-Range` header\n  (:func:`werkzeug.http.parse_if_range_header` and\n  :class:`werkzeug.datastructures.IfRange`).\n- Added support for parsing of the `Range` header\n  (:func:`werkzeug.http.parse_range_header` and\n  :class:`werkzeug.datastructures.Range`).\n- Added support for parsing of the `Content-Range` header of responses\n  and provided an accessor object for it\n  (:func:`werkzeug.http.parse_content_range_header` and\n  :class:`werkzeug.datastructures.ContentRange`).\n\nVersion 0.6.2\n-------------\n\n(bugfix release, released on April 23th 2010)\n\n- renamed the attribute `implicit_seqence_conversion` attribute of the\n  request object to `implicit_sequence_conversion`.\n\nVersion 0.6.1\n-------------\n\n(bugfix release, released on April 13th 2010)\n\n- heavily improved local objects.  Should pick up standalone greenlet\n  builds now and support proxies to free callables as well.  There is\n  also a stacked local now that makes it possible to invoke the same\n  application from within itself by pushing current request/response\n  on top of the stack.\n- routing build method will also build non-default method rules properly\n  if no method is provided.\n- added proper IPv6 support for the builtin server.\n- windows specific filesystem session store fixes.\n  (should now be more stable under high concurrency)\n- fixed a `NameError` in the session system.\n- fixed a bug with empty arguments in the werkzeug.script system.\n- fixed a bug where log lines will be duplicated if an application uses\n  :meth:`logging.basicConfig` (#499)\n- added secure password hashing and checking functions.\n- `HEAD` is now implicitly added as method in the routing system if\n  `GET` is present.  Not doing that was considered a bug because often\n  code assumed that this is the case and in web servers that do not\n  normalize `HEAD` to `GET` this could break `HEAD` requests.\n- the script support can start SSL servers now.\n\nVersion 0.6\n-----------\n\nReleased on Feb 19th 2010, codename Hammer.\n\n- removed pending deprecations\n- sys.path is now printed from the testapp.\n- fixed an RFC 2068 incompatibility with cookie value quoting.\n- the :class:`FileStorage` now gives access to the multipart headers.\n- `cached_property.writeable` has been deprecated.\n- :meth:`MapAdapter.match` now accepts a `return_rule` keyword argument\n  that returns the matched `Rule` instead of just the `endpoint`\n- :meth:`routing.Map.bind_to_environ` raises a more correct error message\n  now if the map was bound to an invalid WSGI environment.\n- added support for SSL to the builtin development server.\n- Response objects are no longer modified in place when they are evaluated\n  as WSGI applications.  For backwards compatibility the `fix_headers`\n  function is still called in case it was overridden.\n  You should however change your application to use `get_wsgi_headers` if\n  you need header modifications before responses are sent as the backwards\n  compatibility support will go away in future versions.\n- :func:`append_slash_redirect` no longer requires the QUERY_STRING to be\n  in the WSGI environment.\n- added :class:`~werkzeug.contrib.wrappers.DynamicCharsetResponseMixin`\n- added :class:`~werkzeug.contrib.wrappers.DynamicCharsetRequestMixin`\n- added :attr:`BaseRequest.url_charset`\n- request and response objects have a default `__repr__` now.\n- builtin data structures can be pickled now.\n- the form data parser will now look at the filename instead the\n  content type to figure out if it should treat the upload as regular\n  form data or file upload.  This fixes a bug with Google Chrome.\n- improved performance of `make_line_iter` and the multipart parser\n  for binary uploads.\n- fixed :attr:`~werkzeug.BaseResponse.is_streamed`\n- fixed a path quoting bug in `EnvironBuilder` that caused PATH_INFO and\n  SCRIPT_NAME to end up in the environ unquoted.\n- :meth:`werkzeug.BaseResponse.freeze` now sets the content length.\n- for unknown HTTP methods the request stream is now always limited\n  instead of being empty.  This makes it easier to implement DAV\n  and other protocols on top of Werkzeug.\n- added :meth:`werkzeug.MIMEAccept.best_match`\n- multi-value test-client posts from a standard dictionary are now\n  supported.  Previously you had to use a multi dict.\n- rule templates properly work with submounts, subdomains and\n  other rule factories now.\n- deprecated non-silent usage of the :class:`werkzeug.LimitedStream`.\n- added support for IRI handling to many parts of Werkzeug.\n- development server properly logs to the werkzeug logger now.\n- added :func:`werkzeug.extract_path_info`\n- fixed a querystring quoting bug in :func:`url_fix`\n- added `fallback_mimetype` to :class:`werkzeug.SharedDataMiddleware`.\n- deprecated :meth:`BaseResponse.iter_encoded`'s charset parameter.\n- added :meth:`BaseResponse.make_sequence`,\n  :attr:`BaseResponse.is_sequence` and\n  :meth:`BaseResponse._ensure_sequence`.\n- added better __repr__ of :class:`werkzeug.Map`\n- `import_string` accepts unicode strings as well now.\n- development server doesn't break on double slashes after the host name.\n- better `__repr__` and `__str__` of\n  :exc:`werkzeug.exceptions.HTTPException`\n- test client works correctly with multiple cookies now.\n- the :class:`werkzeug.routing.Map` now has a class attribute with\n  the default converter mapping.  This helps subclasses to override\n  the converters without passing them to the constructor.\n- implemented :class:`OrderedMultiDict`\n- improved the session support for more efficient session storing\n  on the filesystem.  Also added support for listing of sessions\n  currently stored in the filesystem session store.\n- werkzeug no longer utilizes the Python time module for parsing\n  which means that dates in a broader range can be parsed.\n- the wrappers have no class attributes that make it possible to\n  swap out the dict and list types it uses.\n- werkzeug debugger should work on the appengine dev server now.\n- the URL builder supports dropping of unexpected arguments now.\n  Previously they were always appended to the URL as query string.\n- profiler now writes to the correct stream.\n\nVersion 0.5.1\n-------------\n(bugfix release for 0.5, released on July 9th 2009)\n\n- fixed boolean check of :class:`FileStorage`\n- url routing system properly supports unicode URL rules now.\n- file upload streams no longer have to provide a truncate()\n  method.\n- implemented :meth:`BaseRequest._form_parsing_failed`.\n- fixed #394\n- :meth:`ImmutableDict.copy`, :meth:`ImmutableMultiDict.copy` and\n  :meth:`ImmutableTypeConversionDict.copy` return mutable shallow\n  copies.\n- fixed a bug with the `make_runserver` script action.\n- :meth:`MultiDict.items` and :meth:`MutiDict.iteritems` now accept an\n  argument to return a pair for each value of each key.\n- the multipart parser works better with hand-crafted multipart\n  requests now that have extra newlines added.  This fixes a bug\n  with setuptools uploads not handled properly (#390)\n- fixed some minor bugs in the atom feed generator.\n- fixed a bug with client cookie header parsing being case sensitive.\n- fixed a not-working deprecation warning.\n- fixed package loading for :class:`SharedDataMiddleware`.\n- fixed a bug in the secure cookie that made server-side expiration\n  on servers with a local time that was not set to UTC impossible.\n- fixed console of the interactive debugger.\n\n\nVersion 0.5\n-----------\n\nReleased on April 24th, codename Schlagbohrer.\n\n- requires Python 2.4 now\n- fixed a bug in :class:`~contrib.IterIO`\n- added :class:`MIMEAccept` and :class:`CharsetAccept` that work like the\n  regular :class:`Accept` but have extra special normalization for mimetypes\n  and charsets and extra convenience methods.\n- switched the serving system from wsgiref to something homebrew.\n- the :class:`Client` now supports cookies.\n- added the :mod:`~werkzeug.contrib.fixers` module with various\n  fixes for webserver bugs and hosting setup side-effects.\n- added :mod:`werkzeug.contrib.wrappers`\n- added :func:`is_hop_by_hop_header`\n- added :func:`is_entity_header`\n- added :func:`remove_hop_by_hop_headers`\n- added :func:`pop_path_info`\n- added :func:`peek_path_info`\n- added :func:`wrap_file` and :class:`FileWrapper`\n- moved `LimitedStream` from the contrib package into the regular\n  werkzeug one and changed the default behavior to raise exceptions\n  rather than stopping without warning.  The old class will stick in\n  the module until 0.6.\n- implemented experimental multipart parser that replaces the old CGI hack.\n- added :func:`dump_options_header` and :func:`parse_options_header`\n- added :func:`quote_header_value` and :func:`unquote_header_value`\n- :func:`url_encode` and :func:`url_decode` now accept a separator\n  argument to switch between `&` and `;` as pair separator.  The magic\n  switch is no longer in place.\n- all form data parsing functions as well as the :class:`BaseRequest`\n  object have parameters (or attributes) to limit the number of\n  incoming bytes (either totally or per field).\n- added :class:`LanguageAccept`\n- request objects are now enforced to be read only for all collections.\n- added many new collection classes, refactored collections in general.\n- test support was refactored, semi-undocumented `werkzeug.test.File`\n  was replaced by :class:`werkzeug.FileStorage`.\n- :class:`EnvironBuilder` was added and unifies the previous distinct\n  :func:`create_environ`, :class:`Client` and\n  :meth:`BaseRequest.from_values`.  They all work the same now which\n  is less confusing.\n- officially documented imports from the internal modules as undefined\n  behavior.  These modules were never exposed as public interfaces.\n- removed `FileStorage.__len__` which previously made the object\n  falsy for browsers not sending the content length which all browsers\n  do.\n- :class:`SharedDataMiddleware` uses `wrap_file` now and has a\n  configurable cache timeout.\n- added :class:`CommonRequestDescriptorsMixin`\n- added :attr:`CommonResponseDescriptorsMixin.mimetype_params`\n- added :mod:`werkzeug.contrib.lint`\n- added `passthrough_errors` to `run_simple`.\n- added `secure_filename`\n- added :func:`make_line_iter`\n- :class:`MultiDict` copies now instead of revealing internal\n  lists to the caller for `getlist` and iteration functions that\n  return lists.\n- added :attr:`follow_redirect` to the :func:`open` of :class:`Client`.\n- added support for `extra_files` in\n  :func:`~werkzeug.script.make_runserver`\n\nVersion 0.4.1\n-------------\n\n(Bugfix release, released on January 11th 2009)\n\n- `werkzeug.contrib.cache.Memcached` accepts now objects that\n  implement the memcache.Client interface as alternative to a list of\n  strings with server addresses.\n  There is also now a `GAEMemcachedCache` that connects to the Google\n  appengine cache.\n- explicitly convert secret keys to bytestrings now because Python\n  2.6 no longer does that.\n- `url_encode` and all interfaces that call it, support ordering of\n  options now which however is disabled by default.\n- the development server no longer resolves the addresses of clients.\n- Fixed a typo in `werkzeug.test` that broke `File`.\n- `Map.bind_to_environ` uses the `Host` header now if available.\n- Fixed `BaseCache.get_dict` (#345)\n- `werkzeug.test.Client` can now run the application buffered in which\n  case the application is properly closed automatically.\n- Fixed `Headers.set` (#354).  Caused header duplication before.\n- Fixed `Headers.pop` (#349).  default parameter was not properly\n  handled.\n- Fixed UnboundLocalError in `create_environ` (#351)\n- `Headers` is more compatible with wsgiref now.\n- `Template.render` accepts multidicts now.\n- dropped support for Python 2.3\n\nVersion 0.4\n-----------\n\nReleased on November 23rd 2008, codename Schraubenzieher.\n\n- `Client` supports an empty `data` argument now.\n- fixed a bug in `Response.application` that made it impossible to use it\n  as method decorator.\n- the session system should work on appengine now\n- the secure cookie works properly in load balanced environments with\n  different cpu architectures now.\n- `CacheControl.no_cache` and `CacheControl.private` behavior changed to\n  reflect the possibilities of the HTTP RFC.  Setting these attributes to\n  `None` or `True` now sets the value to \"the empty value\".\n  More details in the documentation.\n- fixed `werkzeug.contrib.atom.AtomFeed.__call__`. (#338)\n- `BaseResponse.make_conditional` now always returns `self`.  Previously\n  it didn't for post requests and such.\n- fixed a bug in boolean attribute handling of `html` and `xhtml`.\n- added graceful error handling to the debugger pastebin feature.\n- added a more list like interface to `Headers` (slicing and indexing\n  works now)\n- fixed a bug with the `__setitem__` method of `Headers` that didn't\n  properly remove all keys on replacing.\n- added `remove_entity_headers` which removes all entity headers from\n  a list of headers (or a `Headers` object)\n- the responses now automatically call `remove_entity_headers` if the\n  status code is 304.\n- fixed a bug with `Href` query parameter handling.  Previously the last\n  item of a call to `Href` was not handled properly if it was a dict.\n- headers now support a `pop` operation to better work with environ\n  properties.\n\n\nVersion 0.3.1\n-------------\n\n(bugfix release, released on June 24th 2008)\n\n- fixed a security problem with `werkzeug.contrib.SecureCookie`.\n\n\nVersion 0.3\n-----------\n\nReleased on June 14th 2008, codename EUR325CAT6.\n\n- added support for redirecting in url routing.\n- added `Authorization` and `AuthorizationMixin`\n- added `WWWAuthenticate` and `WWWAuthenticateMixin`\n- added `parse_list_header`\n- added `parse_dict_header`\n- added `parse_authorization_header`\n- added `parse_www_authenticate_header`\n- added `_get_current_object` method to `LocalProxy` objects\n- added `parse_form_data`\n- `MultiDict`, `CombinedMultiDict`, `Headers`, and `EnvironHeaders` raise\n  special key errors now that are subclasses of `BadRequest` so if you\n  don't catch them they give meaningful HTTP responses.\n- added support for alternative encoding error handling and the new\n  `HTTPUnicodeError` which (if not caught) behaves like a `BadRequest`.\n- added `BadRequest.wrap`.\n- added ETag support to the SharedDataMiddleware and added an option\n  to disable caching.\n- fixed `is_xhr` on the request objects.\n- fixed error handling of the url adapter's `dispatch` method. (#318)\n- fixed bug with `SharedDataMiddleware`.\n- fixed `Accept.values`.\n- `EnvironHeaders` contain content-type and content-length now\n- `url_encode` treats lists and tuples in dicts passed to it as multiple\n  values for the same key so that one doesn't have to pass a `MultiDict`\n  to the function.\n- added `validate_arguments`\n- added `BaseRequest.application`\n- improved Python 2.3 support\n- `run_simple` accepts `use_debugger` and `use_evalex` parameters now,\n  like the `make_runserver` factory function from the script module.\n- the `environ_property` is now read-only by default\n- it's now possible to initialize requests as \"shallow\" requests which\n  causes runtime errors if the request object tries to consume the\n  input stream.\n\n\nVersion 0.2\n-----------\n\nReleased Feb 14th 2008, codename Faustkeil.\n\n- Added `AnyConverter` to the routing system.\n- Added `werkzeug.contrib.securecookie`\n- Exceptions have a ``get_response()`` method that return a response object\n- fixed the path ordering bug (#293), thanks Thomas Johansson\n- `BaseReporterStream` is now part of the werkzeug contrib module.  From\n  Werkzeug 0.3 onwards you will have to import it from there.\n- added `DispatcherMiddleware`.\n- `RequestRedirect` is now a subclass of `HTTPException` and uses a\n  301 status code instead of 302.\n- `url_encode` and `url_decode` can optionally treat keys as unicode strings\n  now, too.\n- `werkzeug.script` has a different caller format for boolean arguments now.\n- renamed `lazy_property` to `cached_property`.\n- added `import_string`.\n- added is_* properties to request objects.\n- added `empty()` method to routing rules.\n- added `werkzeug.contrib.profiler`.\n- added `extends` to `Headers`.\n- added `dump_cookie` and `parse_cookie`.\n- added `as_tuple` to the `Client`.\n- added `werkzeug.contrib.testtools`.\n- added `werkzeug.unescape`\n- added `BaseResponse.freeze`\n- added `werkzeug.contrib.atom`\n- the HTTPExceptions accept an argument `description` now which overrides the\n  default description.\n- the `MapAdapter` has a default for path info now.  If you use\n  `bind_to_environ` you don't have to pass the path later.\n- the wsgiref subclass werkzeug uses for the dev server does not use direct\n  sys.stderr logging any more but a logger called \"werkzeug\".\n- implemented `Href`.\n- implemented `find_modules`\n- refactored request and response objects into base objects, mixins and\n  full featured subclasses that implement all mixins.\n- added simple user agent parser\n- werkzeug's routing raises `MethodNotAllowed` now if it matches a\n  rule but for a different method.\n- many fixes and small improvements\n\n\nVersion 0.1\n-----------\n\nReleased on Dec 9th 2007, codename Wictorinoxger.\n\n- Initial release\n", "Dealing with Request Data\n=========================\n\n.. currentmodule:: werkzeug\n\nThe most important rule about web development is \"Do not trust the user\".\nThis is especially true for incoming request data on the input stream.\nWith WSGI this is actually a bit harder than you would expect.  Because\nof that Werkzeug wraps the request stream for you to save you from the\nmost prominent problems with it.\n\n\nMissing EOF Marker on Input Stream\n----------------------------------\n\nThe input stream has no end-of-file marker.  If you would call the\n:meth:`~file.read` method on the `wsgi.input` stream you would cause your\napplication to hang on conforming servers.  This is actually intentional\nhowever painful.  Werkzeug solves that problem by wrapping the input\nstream in a special :class:`LimitedStream`.  The input stream is exposed\non the request objects as :attr:`~Request.stream`.  This one is either\nan empty stream (if the form data was parsed) or a limited stream with\nthe contents of the input stream.\n\n\nWhen does Werkzeug Parse?\n-------------------------\n\nWerkzeug parses the incoming data under the following situations:\n\n-   you access either :attr:`~Request.form`, :attr:`~Request.files`,\n    or :attr:`~Request.stream` and the request method was\n    `POST` or `PUT`.\n-   if you call :func:`parse_form_data`.\n\nThese calls are not interchangeable.  If you invoke :func:`parse_form_data`\nyou must not use the request object or at least not the attributes that\ntrigger the parsing process.\n\nThis is also true if you read from the `wsgi.input` stream before the\nparsing.\n\n**General rule:** Leave the WSGI input stream alone.  Especially in\nWSGI middlewares.  Use either the parsing functions or the request\nobject.  Do not mix multiple WSGI utility libraries for form data\nparsing or anything else that works on the input stream.\n\n\nHow does it Parse?\n------------------\n\nThe standard Werkzeug parsing behavior handles three cases:\n\n-   input content type was `multipart/form-data`.  In this situation the\n    :class:`~Request.stream` will be empty and\n    :class:`~Request.form` will contain the regular `POST` / `PUT`\n    data, :class:`~Request.files` will contain the uploaded\n    files as :class:`FileStorage` objects.\n-   input content type was `application/x-www-form-urlencoded`.  Then the\n    :class:`~Request.stream` will be empty and\n    :class:`~Request.form` will contain the regular `POST` / `PUT`\n    data and :class:`~Request.files` will be empty.\n-   the input content type was neither of them, :class:`~Request.stream`\n    points to a :class:`LimitedStream` with the input data for further\n    processing.\n\nSpecial note on the :attr:`~Request.get_data` method: Calling this\nloads the full request data into memory.  This is only safe to do if the\n:attr:`~Request.max_content_length` is set.  Also you can *either*\nread the stream *or* call :meth:`~Request.get_data`.\n\n\nLimiting Request Data\n---------------------\n\nThe :class:`Request` class provides a few attributes to control how much data is\nprocessed from the request body. This can help mitigate DoS attacks that craft the\nrequest in such a way that the server uses too many resources to handle it. Each of\nthese limits will raise a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` if they are\nexceeded.\n\n-   :attr:`~Request.max_content_length` Stop reading request data after this number\n    of bytes. It's better to configure this in the WSGI server or HTTP server, rather\n    than the WSGI application.\n-   :attr:`~Request.max_form_memory_size` Stop reading request data if any form part is\n    larger than this number of bytes. While file parts can be moved to disk, regular\n    form field data is stored in memory only.\n-   :attr:`~Request.max_form_parts` Stop reading request data if more than this number\n    of parts are sent in multipart form data. This is useful to stop a very large number\n    of very small parts, especially file parts. The default is 1000.\n\nUsing Werkzeug to set these limits is only one layer of protection. WSGI servers\nand HTTPS servers should set their own limits on size and timeouts. The operating system\nor container manager should set limits on memory and processing time for server\nprocesses.\n\n\nHow to extend Parsing?\n----------------------\n\nModern web applications transmit a lot more than multipart form data or\nurl encoded data. To extend the capabilities, subclass :class:`Request`\nor :class:`Request` and add or extend methods.\n", "import typing as t\nfrom functools import update_wrapper\nfrom io import BytesIO\nfrom itertools import chain\nfrom typing import Union\n\nfrom . import exceptions\nfrom .datastructures import FileStorage\nfrom .datastructures import Headers\nfrom .datastructures import MultiDict\nfrom .http import parse_options_header\nfrom .sansio.multipart import Data\nfrom .sansio.multipart import Epilogue\nfrom .sansio.multipart import Field\nfrom .sansio.multipart import File\nfrom .sansio.multipart import MultipartDecoder\nfrom .sansio.multipart import NeedData\nfrom .urls import url_decode_stream\nfrom .wsgi import _make_chunk_iter\nfrom .wsgi import get_content_length\nfrom .wsgi import get_input_stream\n\n# there are some platforms where SpooledTemporaryFile is not available.\n# In that case we need to provide a fallback.\ntry:\n    from tempfile import SpooledTemporaryFile\nexcept ImportError:\n    from tempfile import TemporaryFile\n\n    SpooledTemporaryFile = None  # type: ignore\n\nif t.TYPE_CHECKING:\n    import typing as te\n    from _typeshed.wsgi import WSGIEnvironment\n\n    t_parse_result = t.Tuple[t.IO[bytes], MultiDict, MultiDict]\n\n    class TStreamFactory(te.Protocol):\n        def __call__(\n            self,\n            total_content_length: t.Optional[int],\n            content_type: t.Optional[str],\n            filename: t.Optional[str],\n            content_length: t.Optional[int] = None,\n        ) -> t.IO[bytes]:\n            ...\n\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef _exhaust(stream: t.IO[bytes]) -> None:\n    bts = stream.read(64 * 1024)\n    while bts:\n        bts = stream.read(64 * 1024)\n\n\ndef default_stream_factory(\n    total_content_length: t.Optional[int],\n    content_type: t.Optional[str],\n    filename: t.Optional[str],\n    content_length: t.Optional[int] = None,\n) -> t.IO[bytes]:\n    max_size = 1024 * 500\n\n    if SpooledTemporaryFile is not None:\n        return t.cast(t.IO[bytes], SpooledTemporaryFile(max_size=max_size, mode=\"rb+\"))\n    elif total_content_length is None or total_content_length > max_size:\n        return t.cast(t.IO[bytes], TemporaryFile(\"rb+\"))\n\n    return BytesIO()\n\n\ndef parse_form_data(\n    environ: \"WSGIEnvironment\",\n    stream_factory: t.Optional[\"TStreamFactory\"] = None,\n    charset: str = \"utf-8\",\n    errors: str = \"replace\",\n    max_form_memory_size: t.Optional[int] = None,\n    max_content_length: t.Optional[int] = None,\n    cls: t.Optional[t.Type[MultiDict]] = None,\n    silent: bool = True,\n) -> \"t_parse_result\":\n    \"\"\"Parse the form data in the environ and return it as tuple in the form\n    ``(stream, form, files)``.  You should only call this method if the\n    transport method is `POST`, `PUT`, or `PATCH`.\n\n    If the mimetype of the data transmitted is `multipart/form-data` the\n    files multidict will be filled with `FileStorage` objects.  If the\n    mimetype is unknown the input stream is wrapped and returned as first\n    argument, else the stream is empty.\n\n    This is a shortcut for the common usage of :class:`FormDataParser`.\n\n    Have a look at :doc:`/request_data` for more details.\n\n    .. versionadded:: 0.5\n       The `max_form_memory_size`, `max_content_length` and\n       `cls` parameters were added.\n\n    .. versionadded:: 0.5.1\n       The optional `silent` flag was added.\n\n    :param environ: the WSGI environment to be used for parsing.\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param charset: The character set for URL and url encoded form data.\n    :param errors: The encoding error behavior.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :return: A tuple in the form ``(stream, form, files)``.\n    \"\"\"\n    return FormDataParser(\n        stream_factory,\n        charset,\n        errors,\n        max_form_memory_size,\n        max_content_length,\n        cls,\n        silent,\n    ).parse_from_environ(environ)\n\n\ndef exhaust_stream(f: F) -> F:\n    \"\"\"Helper decorator for methods that exhausts the stream on return.\"\"\"\n\n    def wrapper(self, stream, *args, **kwargs):  # type: ignore\n        try:\n            return f(self, stream, *args, **kwargs)\n        finally:\n            exhaust = getattr(stream, \"exhaust\", None)\n\n            if exhaust is not None:\n                exhaust()\n            else:\n                while True:\n                    chunk = stream.read(1024 * 64)\n\n                    if not chunk:\n                        break\n\n    return update_wrapper(t.cast(F, wrapper), f)\n\n\nclass FormDataParser:\n    \"\"\"This class implements parsing of form data for Werkzeug.  By itself\n    it can parse multipart and url encoded form data.  It can be subclassed\n    and extended but for most mimetypes it is a better idea to use the\n    untouched stream and expose it as separate attributes on a request\n    object.\n\n    .. versionadded:: 0.8\n\n    :param stream_factory: An optional callable that returns a new read and\n                           writeable file descriptor.  This callable works\n                           the same as :meth:`Response._get_file_stream`.\n    :param charset: The character set for URL and url encoded form data.\n    :param errors: The encoding error behavior.\n    :param max_form_memory_size: the maximum number of bytes to be accepted for\n                           in-memory stored form data.  If the data\n                           exceeds the value specified an\n                           :exc:`~exceptions.RequestEntityTooLarge`\n                           exception is raised.\n    :param max_content_length: If this is provided and the transmitted data\n                               is longer than this value an\n                               :exc:`~exceptions.RequestEntityTooLarge`\n                               exception is raised.\n    :param cls: an optional dict class to use.  If this is not specified\n                       or `None` the default :class:`MultiDict` is used.\n    :param silent: If set to False parsing errors will not be caught.\n    :param max_form_parts: The maximum number of parts to be parsed. If this is\n        exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n    \"\"\"\n\n    def __init__(\n        self,\n        stream_factory: t.Optional[\"TStreamFactory\"] = None,\n        charset: str = \"utf-8\",\n        errors: str = \"replace\",\n        max_form_memory_size: t.Optional[int] = None,\n        max_content_length: t.Optional[int] = None,\n        cls: t.Optional[t.Type[MultiDict]] = None,\n        silent: bool = True,\n        *,\n        max_form_parts: t.Optional[int] = None,\n    ) -> None:\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n        self.charset = charset\n        self.errors = errors\n        self.max_form_memory_size = max_form_memory_size\n        self.max_content_length = max_content_length\n        self.max_form_parts = max_form_parts\n\n        if cls is None:\n            cls = MultiDict\n\n        self.cls = cls\n        self.silent = silent\n\n    def get_parse_func(\n        self, mimetype: str, options: t.Dict[str, str]\n    ) -> t.Optional[\n        t.Callable[\n            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],\n            \"t_parse_result\",\n        ]\n    ]:\n        return self.parse_functions.get(mimetype)\n\n    def parse_from_environ(self, environ: \"WSGIEnvironment\") -> \"t_parse_result\":\n        \"\"\"Parses the information from the environment as form data.\n\n        :param environ: the WSGI environment to be used for parsing.\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        content_type = environ.get(\"CONTENT_TYPE\", \"\")\n        content_length = get_content_length(environ)\n        mimetype, options = parse_options_header(content_type)\n        return self.parse(get_input_stream(environ), mimetype, content_length, options)\n\n    def parse(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Optional[t.Dict[str, str]] = None,\n    ) -> \"t_parse_result\":\n        \"\"\"Parses the information from the given stream, mimetype,\n        content length and mimetype parameters.\n\n        :param stream: an input stream\n        :param mimetype: the mimetype of the data\n        :param content_length: the content length of the incoming data\n        :param options: optional mimetype parameters (used for\n                        the multipart boundary for instance)\n        :return: A tuple in the form ``(stream, form, files)``.\n        \"\"\"\n        if (\n            self.max_content_length is not None\n            and content_length is not None\n            and content_length > self.max_content_length\n        ):\n            # if the input stream is not exhausted, firefox reports Connection Reset\n            _exhaust(stream)\n            raise exceptions.RequestEntityTooLarge()\n\n        if options is None:\n            options = {}\n\n        parse_func = self.get_parse_func(mimetype, options)\n\n        if parse_func is not None:\n            try:\n                return parse_func(self, stream, mimetype, content_length, options)\n            except ValueError:\n                if not self.silent:\n                    raise\n\n        return stream, self.cls(), self.cls()\n\n    @exhaust_stream\n    def _parse_multipart(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Dict[str, str],\n    ) -> \"t_parse_result\":\n        parser = MultiPartParser(\n            self.stream_factory,\n            self.charset,\n            self.errors,\n            max_form_memory_size=self.max_form_memory_size,\n            cls=self.cls,\n            max_form_parts=self.max_form_parts,\n        )\n        boundary = options.get(\"boundary\", \"\").encode(\"ascii\")\n\n        if not boundary:\n            raise ValueError(\"Missing boundary\")\n\n        form, files = parser.parse(stream, boundary, content_length)\n        return stream, form, files\n\n    @exhaust_stream\n    def _parse_urlencoded(\n        self,\n        stream: t.IO[bytes],\n        mimetype: str,\n        content_length: t.Optional[int],\n        options: t.Dict[str, str],\n    ) -> \"t_parse_result\":\n        if (\n            self.max_form_memory_size is not None\n            and content_length is not None\n            and content_length > self.max_form_memory_size\n        ):\n            # if the input stream is not exhausted, firefox reports Connection Reset\n            _exhaust(stream)\n            raise exceptions.RequestEntityTooLarge()\n\n        form = url_decode_stream(stream, self.charset, errors=self.errors, cls=self.cls)\n        return stream, form, self.cls()\n\n    #: mapping of mimetypes to parsing functions\n    parse_functions: t.Dict[\n        str,\n        t.Callable[\n            [\"FormDataParser\", t.IO[bytes], str, t.Optional[int], t.Dict[str, str]],\n            \"t_parse_result\",\n        ],\n    ] = {\n        \"multipart/form-data\": _parse_multipart,\n        \"application/x-www-form-urlencoded\": _parse_urlencoded,\n        \"application/x-url-encoded\": _parse_urlencoded,\n    }\n\n\ndef _line_parse(line: str) -> t.Tuple[str, bool]:\n    \"\"\"Removes line ending characters and returns a tuple (`stripped_line`,\n    `is_terminated`).\n    \"\"\"\n    if line[-2:] == \"\\r\\n\":\n        return line[:-2], True\n\n    elif line[-1:] in {\"\\r\", \"\\n\"}:\n        return line[:-1], True\n\n    return line, False\n\n\nclass MultiPartParser:\n    def __init__(\n        self,\n        stream_factory: t.Optional[\"TStreamFactory\"] = None,\n        charset: str = \"utf-8\",\n        errors: str = \"replace\",\n        max_form_memory_size: t.Optional[int] = None,\n        cls: t.Optional[t.Type[MultiDict]] = None,\n        buffer_size: int = 64 * 1024,\n        max_form_parts: t.Optional[int] = None,\n    ) -> None:\n        self.charset = charset\n        self.errors = errors\n        self.max_form_memory_size = max_form_memory_size\n        self.max_form_parts = max_form_parts\n\n        if stream_factory is None:\n            stream_factory = default_stream_factory\n\n        self.stream_factory = stream_factory\n\n        if cls is None:\n            cls = MultiDict\n\n        self.cls = cls\n\n        self.buffer_size = buffer_size\n\n    def fail(self, message: str) -> \"te.NoReturn\":\n        raise ValueError(message)\n\n    def get_part_charset(self, headers: Headers) -> str:\n        # Figure out input charset for current part\n        content_type = headers.get(\"content-type\")\n\n        if content_type:\n            mimetype, ct_params = parse_options_header(content_type)\n            return ct_params.get(\"charset\", self.charset)\n\n        return self.charset\n\n    def start_file_streaming(\n        self, event: File, total_content_length: t.Optional[int]\n    ) -> t.IO[bytes]:\n        content_type = event.headers.get(\"content-type\")\n\n        try:\n            content_length = int(event.headers[\"content-length\"])\n        except (KeyError, ValueError):\n            content_length = 0\n\n        container = self.stream_factory(\n            total_content_length=total_content_length,\n            filename=event.filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n        return container\n\n    def parse(\n        self, stream: t.IO[bytes], boundary: bytes, content_length: t.Optional[int]\n    ) -> t.Tuple[MultiDict, MultiDict]:\n        container: t.Union[t.IO[bytes], t.List[bytes]]\n        _write: t.Callable[[bytes], t.Any]\n\n        iterator = chain(\n            _make_chunk_iter(\n                stream,\n                limit=content_length,\n                buffer_size=self.buffer_size,\n            ),\n            [None],\n        )\n\n        parser = MultipartDecoder(\n            boundary, self.max_form_memory_size, max_parts=self.max_form_parts\n        )\n\n        fields = []\n        files = []\n\n        current_part: Union[Field, File]\n        for data in iterator:\n            parser.receive_data(data)\n            event = parser.next_event()\n            while not isinstance(event, (Epilogue, NeedData)):\n                if isinstance(event, Field):\n                    current_part = event\n                    container = []\n                    _write = container.append\n                elif isinstance(event, File):\n                    current_part = event\n                    container = self.start_file_streaming(event, content_length)\n                    _write = container.write\n                elif isinstance(event, Data):\n                    _write(event.data)\n                    if not event.more_data:\n                        if isinstance(current_part, Field):\n                            value = b\"\".join(container).decode(\n                                self.get_part_charset(current_part.headers), self.errors\n                            )\n                            fields.append((current_part.name, value))\n                        else:\n                            container = t.cast(t.IO[bytes], container)\n                            container.seek(0)\n                            files.append(\n                                (\n                                    current_part.name,\n                                    FileStorage(\n                                        container,\n                                        current_part.filename,\n                                        current_part.name,\n                                        headers=current_part.headers,\n                                    ),\n                                )\n                            )\n\n                event = parser.next_event()\n\n        return self.cls(fields), self.cls(files)\n", "import re\nfrom dataclasses import dataclass\nfrom enum import auto\nfrom enum import Enum\nfrom typing import cast\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom .._internal import _to_bytes\nfrom .._internal import _to_str\nfrom ..datastructures import Headers\nfrom ..exceptions import RequestEntityTooLarge\nfrom ..http import parse_options_header\n\n\nclass Event:\n    pass\n\n\n@dataclass(frozen=True)\nclass Preamble(Event):\n    data: bytes\n\n\n@dataclass(frozen=True)\nclass Field(Event):\n    name: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass File(Event):\n    name: str\n    filename: str\n    headers: Headers\n\n\n@dataclass(frozen=True)\nclass Data(Event):\n    data: bytes\n    more_data: bool\n\n\n@dataclass(frozen=True)\nclass Epilogue(Event):\n    data: bytes\n\n\nclass NeedData(Event):\n    pass\n\n\nNEED_DATA = NeedData()\n\n\nclass State(Enum):\n    PREAMBLE = auto()\n    PART = auto()\n    DATA = auto()\n    EPILOGUE = auto()\n    COMPLETE = auto()\n\n\n# Multipart line breaks MUST be CRLF (\\r\\n) by RFC-7578, except that\n# many implementations break this and either use CR or LF alone.\nLINE_BREAK = b\"(?:\\r\\n|\\n|\\r)\"\nBLANK_LINE_RE = re.compile(b\"(?:\\r\\n\\r\\n|\\r\\r|\\n\\n)\", re.MULTILINE)\nLINE_BREAK_RE = re.compile(LINE_BREAK, re.MULTILINE)\n# Header values can be continued via a space or tab after the linebreak, as\n# per RFC2231\nHEADER_CONTINUATION_RE = re.compile(b\"%s[ \\t]\" % LINE_BREAK, re.MULTILINE)\n# This must be long enough to contain any line breaks plus any\n# additional boundary markers (--) such that they will be found in a\n# subsequent search\nSEARCH_EXTRA_LENGTH = 8\n\n\nclass MultipartDecoder:\n    \"\"\"Decodes a multipart message as bytes into Python events.\n\n    The part data is returned as available to allow the caller to save\n    the data from memory to disk, if desired.\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: bytes,\n        max_form_memory_size: Optional[int] = None,\n        *,\n        max_parts: Optional[int] = None,\n    ) -> None:\n        self.buffer = bytearray()\n        self.complete = False\n        self.max_form_memory_size = max_form_memory_size\n        self.max_parts = max_parts\n        self.state = State.PREAMBLE\n        self.boundary = boundary\n\n        # Note in the below \\h i.e. horizontal whitespace is used\n        # as [^\\S\\n\\r] as \\h isn't supported in python.\n\n        # The preamble must end with a boundary where the boundary is\n        # prefixed by a line break, RFC2046. Except that many\n        # implementations including Werkzeug's tests omit the line\n        # break prefix. In addition the first boundary could be the\n        # epilogue boundary (for empty form-data) hence the matching\n        # group to understand if it is an epilogue boundary.\n        self.preamble_re = re.compile(\n            rb\"%s?--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        # A boundary must include a line break prefix and suffix, and\n        # may include trailing whitespace. In addition the boundary\n        # could be the epilogue boundary hence the matching group to\n        # understand if it is an epilogue boundary.\n        self.boundary_re = re.compile(\n            rb\"%s--%s(--[^\\S\\n\\r]*%s?|[^\\S\\n\\r]*%s)\"\n            % (LINE_BREAK, re.escape(boundary), LINE_BREAK, LINE_BREAK),\n            re.MULTILINE,\n        )\n        self._search_position = 0\n        self._parts_decoded = 0\n\n    def last_newline(self) -> int:\n        try:\n            last_nl = self.buffer.rindex(b\"\\n\")\n        except ValueError:\n            last_nl = len(self.buffer)\n        try:\n            last_cr = self.buffer.rindex(b\"\\r\")\n        except ValueError:\n            last_cr = len(self.buffer)\n\n        return min(last_nl, last_cr)\n\n    def receive_data(self, data: Optional[bytes]) -> None:\n        if data is None:\n            self.complete = True\n        elif (\n            self.max_form_memory_size is not None\n            and len(self.buffer) + len(data) > self.max_form_memory_size\n        ):\n            raise RequestEntityTooLarge()\n        else:\n            self.buffer.extend(data)\n\n    def next_event(self) -> Event:\n        event: Event = NEED_DATA\n\n        if self.state == State.PREAMBLE:\n            match = self.preamble_re.search(self.buffer, self._search_position)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data = bytes(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n                event = Preamble(data=data)\n                self._search_position = 0\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(\n                    0, len(self.buffer) - len(self.boundary) - SEARCH_EXTRA_LENGTH\n                )\n\n        elif self.state == State.PART:\n            match = BLANK_LINE_RE.search(self.buffer, self._search_position)\n            if match is not None:\n                headers = self._parse_headers(self.buffer[: match.start()])\n                del self.buffer[: match.end()]\n\n                if \"content-disposition\" not in headers:\n                    raise ValueError(\"Missing Content-Disposition header\")\n\n                disposition, extra = parse_options_header(\n                    headers[\"content-disposition\"]\n                )\n                name = cast(str, extra.get(\"name\"))\n                filename = extra.get(\"filename\")\n                if filename is not None:\n                    event = File(\n                        filename=filename,\n                        headers=headers,\n                        name=name,\n                    )\n                else:\n                    event = Field(\n                        headers=headers,\n                        name=name,\n                    )\n                self.state = State.DATA\n                self._search_position = 0\n                self._parts_decoded += 1\n\n                if self.max_parts is not None and self._parts_decoded > self.max_parts:\n                    raise RequestEntityTooLarge()\n            else:\n                # Update the search start position to be equal to the\n                # current buffer length (already searched) minus a\n                # safe buffer for part of the search target.\n                self._search_position = max(0, len(self.buffer) - SEARCH_EXTRA_LENGTH)\n\n        elif self.state == State.DATA:\n            if self.buffer.find(b\"--\" + self.boundary) == -1:\n                # No complete boundary in the buffer, but there may be\n                # a partial boundary at the end. As the boundary\n                # starts with either a nl or cr find the earliest and\n                # return up to that as data.\n                data_length = del_index = self.last_newline()\n                more_data = True\n            else:\n                match = self.boundary_re.search(self.buffer)\n                if match is not None:\n                    if match.group(1).startswith(b\"--\"):\n                        self.state = State.EPILOGUE\n                    else:\n                        self.state = State.PART\n                    data_length = match.start()\n                    del_index = match.end()\n                else:\n                    data_length = del_index = self.last_newline()\n                more_data = match is None\n\n            data = bytes(self.buffer[:data_length])\n            del self.buffer[:del_index]\n            if data or not more_data:\n                event = Data(data=data, more_data=more_data)\n\n        elif self.state == State.EPILOGUE and self.complete:\n            event = Epilogue(data=bytes(self.buffer))\n            del self.buffer[:]\n            self.state = State.COMPLETE\n\n        if self.complete and isinstance(event, NeedData):\n            raise ValueError(f\"Invalid form-data cannot parse beyond {self.state}\")\n\n        return event\n\n    def _parse_headers(self, data: bytes) -> Headers:\n        headers: List[Tuple[str, str]] = []\n        # Merge the continued headers into one line\n        data = HEADER_CONTINUATION_RE.sub(b\" \", data)\n        # Now there is one header per line\n        for line in data.splitlines():\n            if line.strip() != b\"\":\n                name, value = _to_str(line).strip().split(\":\", 1)\n                headers.append((name.strip(), value.strip()))\n        return Headers(headers)\n\n\nclass MultipartEncoder:\n    def __init__(self, boundary: bytes) -> None:\n        self.boundary = boundary\n        self.state = State.PREAMBLE\n\n    def send_event(self, event: Event) -> bytes:\n        if isinstance(event, Preamble) and self.state == State.PREAMBLE:\n            self.state = State.PART\n            return event.data\n        elif isinstance(event, (Field, File)) and self.state in {\n            State.PREAMBLE,\n            State.PART,\n            State.DATA,\n        }:\n            self.state = State.DATA\n            data = b\"\\r\\n--\" + self.boundary + b\"\\r\\n\"\n            data += b'Content-Disposition: form-data; name=\"%s\"' % _to_bytes(event.name)\n            if isinstance(event, File):\n                data += b'; filename=\"%s\"' % _to_bytes(event.filename)\n            data += b\"\\r\\n\"\n            for name, value in cast(Field, event).headers:\n                if name.lower() != \"content-disposition\":\n                    data += _to_bytes(f\"{name}: {value}\\r\\n\")\n            data += b\"\\r\\n\"\n            return data\n        elif isinstance(event, Data) and self.state == State.DATA:\n            return event.data\n        elif isinstance(event, Epilogue):\n            self.state = State.COMPLETE\n            return b\"\\r\\n--\" + self.boundary + b\"--\\r\\n\" + event.data\n        else:\n            raise ValueError(f\"Cannot generate {event} in state: {self.state}\")\n", "import functools\nimport json\nimport typing\nimport typing as t\nfrom io import BytesIO\n\nfrom .._internal import _wsgi_decoding_dance\nfrom ..datastructures import CombinedMultiDict\nfrom ..datastructures import EnvironHeaders\nfrom ..datastructures import FileStorage\nfrom ..datastructures import ImmutableMultiDict\nfrom ..datastructures import iter_multi_items\nfrom ..datastructures import MultiDict\nfrom ..formparser import default_stream_factory\nfrom ..formparser import FormDataParser\nfrom ..sansio.request import Request as _SansIORequest\nfrom ..utils import cached_property\nfrom ..utils import environ_property\nfrom ..wsgi import _get_server\nfrom ..wsgi import get_input_stream\nfrom werkzeug.exceptions import BadRequest\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n\nclass Request(_SansIORequest):\n    \"\"\"Represents an incoming WSGI HTTP request, with headers and body\n    taken from the WSGI environment. Has properties and methods for\n    using the functionality defined by various HTTP specs. The data in\n    requests object is read-only.\n\n    Text data is assumed to use UTF-8 encoding, which should be true for\n    the vast majority of modern clients. Using an encoding set by the\n    client is unsafe in Python due to extra encodings it provides, such\n    as ``zip``. To change the assumed encoding, subclass and replace\n    :attr:`charset`.\n\n    :param environ: The WSGI environ is generated by the WSGI server and\n        contains information about the server configuration and client\n        request.\n    :param populate_request: Add this request object to the WSGI environ\n        as ``environ['werkzeug.request']``. Can be useful when\n        debugging.\n    :param shallow: Makes reading from :attr:`stream` (and any method\n        that would read from it) raise a :exc:`RuntimeError`. Useful to\n        prevent consuming the form data in middleware, which would make\n        it unavailable to the final application.\n\n    .. versionchanged:: 2.1\n        Remove the ``disable_data_descriptor`` attribute.\n\n    .. versionchanged:: 2.0\n        Combine ``BaseRequest`` and mixins into a single ``Request``\n        class. Using the old classes is deprecated and will be removed\n        in Werkzeug 2.1.\n\n    .. versionchanged:: 0.5\n        Read-only mode is enforced with immutable classes for all data.\n    \"\"\"\n\n    #: the maximum content length.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: parsing fails because more than the specified value is transmitted\n    #: a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: Have a look at :doc:`/request_data` for more details.\n    #:\n    #: .. versionadded:: 0.5\n    max_content_length: t.Optional[int] = None\n\n    #: the maximum form field size.  This is forwarded to the form data\n    #: parsing function (:func:`parse_form_data`).  When set and the\n    #: :attr:`form` or :attr:`files` attribute is accessed and the\n    #: data in memory for post data is longer than the specified value a\n    #: :exc:`~werkzeug.exceptions.RequestEntityTooLarge` exception is raised.\n    #:\n    #: Have a look at :doc:`/request_data` for more details.\n    #:\n    #: .. versionadded:: 0.5\n    max_form_memory_size: t.Optional[int] = None\n\n    #: The maximum number of multipart parts to parse, passed to\n    #: :attr:`form_data_parser_class`. Parsing form data with more than this\n    #: many parts will raise :exc:`~.RequestEntityTooLarge`.\n    #:\n    #: .. versionadded:: 2.2.3\n    max_form_parts = 1000\n\n    #: The form data parser that should be used.  Can be replaced to customize\n    #: the form date parsing.\n    form_data_parser_class: t.Type[FormDataParser] = FormDataParser\n\n    #: The WSGI environment containing HTTP headers and information from\n    #: the WSGI server.\n    environ: \"WSGIEnvironment\"\n\n    #: Set when creating the request object. If ``True``, reading from\n    #: the request body will cause a ``RuntimeException``. Useful to\n    #: prevent modifying the stream from middleware.\n    shallow: bool\n\n    def __init__(\n        self,\n        environ: \"WSGIEnvironment\",\n        populate_request: bool = True,\n        shallow: bool = False,\n    ) -> None:\n        super().__init__(\n            method=environ.get(\"REQUEST_METHOD\", \"GET\"),\n            scheme=environ.get(\"wsgi.url_scheme\", \"http\"),\n            server=_get_server(environ),\n            root_path=_wsgi_decoding_dance(\n                environ.get(\"SCRIPT_NAME\") or \"\", self.charset, self.encoding_errors\n            ),\n            path=_wsgi_decoding_dance(\n                environ.get(\"PATH_INFO\") or \"\", self.charset, self.encoding_errors\n            ),\n            query_string=environ.get(\"QUERY_STRING\", \"\").encode(\"latin1\"),\n            headers=EnvironHeaders(environ),\n            remote_addr=environ.get(\"REMOTE_ADDR\"),\n        )\n        self.environ = environ\n        self.shallow = shallow\n\n        if populate_request and not shallow:\n            self.environ[\"werkzeug.request\"] = self\n\n    @classmethod\n    def from_values(cls, *args: t.Any, **kwargs: t.Any) -> \"Request\":\n        \"\"\"Create a new request object based on the values provided.  If\n        environ is given missing values are filled from there.  This method is\n        useful for small scripts when you need to simulate a request from an URL.\n        Do not use this method for unittesting, there is a full featured client\n        object (:class:`Client`) that allows to create multipart requests,\n        support for cookies etc.\n\n        This accepts the same options as the\n        :class:`~werkzeug.test.EnvironBuilder`.\n\n        .. versionchanged:: 0.5\n           This method now accepts the same arguments as\n           :class:`~werkzeug.test.EnvironBuilder`.  Because of this the\n           `environ` parameter is now called `environ_overrides`.\n\n        :return: request object\n        \"\"\"\n        from ..test import EnvironBuilder\n\n        charset = kwargs.pop(\"charset\", cls.charset)\n        kwargs[\"charset\"] = charset\n        builder = EnvironBuilder(*args, **kwargs)\n        try:\n            return builder.get_request(cls)\n        finally:\n            builder.close()\n\n    @classmethod\n    def application(\n        cls, f: t.Callable[[\"Request\"], \"WSGIApplication\"]\n    ) -> \"WSGIApplication\":\n        \"\"\"Decorate a function as responder that accepts the request as\n        the last argument.  This works like the :func:`responder`\n        decorator but the function is passed the request object as the\n        last argument and the request object will be closed\n        automatically::\n\n            @Request.application\n            def my_wsgi_app(request):\n                return Response('Hello World!')\n\n        As of Werkzeug 0.14 HTTP exceptions are automatically caught and\n        converted to responses instead of failing.\n\n        :param f: the WSGI callable to decorate\n        :return: a new WSGI callable\n        \"\"\"\n        #: return a callable that wraps the -2nd argument with the request\n        #: and calls the function with all the arguments up to that one and\n        #: the request.  The return value is then called with the latest\n        #: two arguments.  This makes it possible to use this decorator for\n        #: both standalone WSGI functions as well as bound methods and\n        #: partially applied functions.\n        from ..exceptions import HTTPException\n\n        @functools.wraps(f)\n        def application(*args):  # type: ignore\n            request = cls(args[-2])\n            with request:\n                try:\n                    resp = f(*args[:-2] + (request,))\n                except HTTPException as e:\n                    resp = e.get_response(args[-2])\n                return resp(*args[-2:])\n\n        return t.cast(\"WSGIApplication\", application)\n\n    def _get_file_stream(\n        self,\n        total_content_length: t.Optional[int],\n        content_type: t.Optional[str],\n        filename: t.Optional[str] = None,\n        content_length: t.Optional[int] = None,\n    ) -> t.IO[bytes]:\n        \"\"\"Called to get a stream for the file upload.\n\n        This must provide a file-like class with `read()`, `readline()`\n        and `seek()` methods that is both writeable and readable.\n\n        The default implementation returns a temporary file if the total\n        content length is higher than 500KB.  Because many browsers do not\n        provide a content length for the files only the total content\n        length matters.\n\n        :param total_content_length: the total content length of all the\n                                     data in the request combined.  This value\n                                     is guaranteed to be there.\n        :param content_type: the mimetype of the uploaded file.\n        :param filename: the filename of the uploaded file.  May be `None`.\n        :param content_length: the length of this file.  This value is usually\n                               not provided because webbrowsers do not provide\n                               this value.\n        \"\"\"\n        return default_stream_factory(\n            total_content_length=total_content_length,\n            filename=filename,\n            content_type=content_type,\n            content_length=content_length,\n        )\n\n    @property\n    def want_form_data_parsed(self) -> bool:\n        \"\"\"``True`` if the request method carries content. By default\n        this is true if a ``Content-Type`` is sent.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return bool(self.environ.get(\"CONTENT_TYPE\"))\n\n    def make_form_data_parser(self) -> FormDataParser:\n        \"\"\"Creates the form data parser. Instantiates the\n        :attr:`form_data_parser_class` with some parameters.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        return self.form_data_parser_class(\n            self._get_file_stream,\n            self.charset,\n            self.encoding_errors,\n            self.max_form_memory_size,\n            self.max_content_length,\n            self.parameter_storage_class,\n            max_form_parts=self.max_form_parts,\n        )\n\n    def _load_form_data(self) -> None:\n        \"\"\"Method used internally to retrieve submitted data.  After calling\n        this sets `form` and `files` on the request object to multi dicts\n        filled with the incoming form data.  As a matter of fact the input\n        stream will be empty afterwards.  You can also call this method to\n        force the parsing of the form data.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        # abort early if we have already consumed the stream\n        if \"form\" in self.__dict__:\n            return\n\n        if self.want_form_data_parsed:\n            parser = self.make_form_data_parser()\n            data = parser.parse(\n                self._get_stream_for_parsing(),\n                self.mimetype,\n                self.content_length,\n                self.mimetype_params,\n            )\n        else:\n            data = (\n                self.stream,\n                self.parameter_storage_class(),\n                self.parameter_storage_class(),\n            )\n\n        # inject the values into the instance dict so that we bypass\n        # our cached_property non-data descriptor.\n        d = self.__dict__\n        d[\"stream\"], d[\"form\"], d[\"files\"] = data\n\n    def _get_stream_for_parsing(self) -> t.IO[bytes]:\n        \"\"\"This is the same as accessing :attr:`stream` with the difference\n        that if it finds cached data from calling :meth:`get_data` first it\n        will create a new stream out of the cached data.\n\n        .. versionadded:: 0.9.3\n        \"\"\"\n        cached_data = getattr(self, \"_cached_data\", None)\n        if cached_data is not None:\n            return BytesIO(cached_data)\n        return self.stream\n\n    def close(self) -> None:\n        \"\"\"Closes associated resources of this request object.  This\n        closes all file handles explicitly.  You can also use the request\n        object in a with statement which will automatically close it.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        files = self.__dict__.get(\"files\")\n        for _key, value in iter_multi_items(files or ()):\n            value.close()\n\n    def __enter__(self) -> \"Request\":\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb) -> None:  # type: ignore\n        self.close()\n\n    @cached_property\n    def stream(self) -> t.IO[bytes]:\n        \"\"\"\n        If the incoming form data was not encoded with a known mimetype\n        the data is stored unmodified in this stream for consumption.  Most\n        of the time it is a better idea to use :attr:`data` which will give\n        you that data as a string.  The stream only returns the data once.\n\n        Unlike :attr:`input_stream` this stream is properly guarded that you\n        can't accidentally read past the length of the input.  Werkzeug will\n        internally always refer to this stream to read data which makes it\n        possible to wrap this object with a stream that does filtering.\n\n        .. versionchanged:: 0.9\n           This stream is now always available but might be consumed by the\n           form parser later on.  Previously the stream was only set if no\n           parsing happened.\n        \"\"\"\n        if self.shallow:\n            raise RuntimeError(\n                \"This request was created with 'shallow=True', reading\"\n                \" from the input stream is disabled.\"\n            )\n\n        return get_input_stream(self.environ)\n\n    input_stream = environ_property[t.IO[bytes]](\n        \"wsgi.input\",\n        doc=\"\"\"The WSGI input stream.\n\n        In general it's a bad idea to use this one because you can\n        easily read past the boundary.  Use the :attr:`stream`\n        instead.\"\"\",\n    )\n\n    @cached_property\n    def data(self) -> bytes:\n        \"\"\"\n        Contains the incoming request data as string in case it came with\n        a mimetype Werkzeug does not handle.\n        \"\"\"\n        return self.get_data(parse_form_data=True)\n\n    @typing.overload\n    def get_data(  # type: ignore\n        self,\n        cache: bool = True,\n        as_text: \"te.Literal[False]\" = False,\n        parse_form_data: bool = False,\n    ) -> bytes:\n        ...\n\n    @typing.overload\n    def get_data(\n        self,\n        cache: bool = True,\n        as_text: \"te.Literal[True]\" = ...,\n        parse_form_data: bool = False,\n    ) -> str:\n        ...\n\n    def get_data(\n        self, cache: bool = True, as_text: bool = False, parse_form_data: bool = False\n    ) -> t.Union[bytes, str]:\n        \"\"\"This reads the buffered incoming data from the client into one\n        bytes object.  By default this is cached but that behavior can be\n        changed by setting `cache` to `False`.\n\n        Usually it's a bad idea to call this method without checking the\n        content length first as a client could send dozens of megabytes or more\n        to cause memory problems on the server.\n\n        Note that if the form data was already parsed this method will not\n        return anything as form data parsing does not cache the data like\n        this method does.  To implicitly invoke form data parsing function\n        set `parse_form_data` to `True`.  When this is done the return value\n        of this method will be an empty string if the form parser handles\n        the data.  This generally is not necessary as if the whole data is\n        cached (which is the default) the form parser will used the cached\n        data to parse the form data.  Please be generally aware of checking\n        the content length first in any case before calling this method\n        to avoid exhausting server memory.\n\n        If `as_text` is set to `True` the return value will be a decoded\n        string.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        rv = getattr(self, \"_cached_data\", None)\n        if rv is None:\n            if parse_form_data:\n                self._load_form_data()\n            rv = self.stream.read()\n            if cache:\n                self._cached_data = rv\n        if as_text:\n            rv = rv.decode(self.charset, self.encoding_errors)\n        return rv\n\n    @cached_property\n    def form(self) -> \"ImmutableMultiDict[str, str]\":\n        \"\"\"The form parameters.  By default an\n        :class:`~werkzeug.datastructures.ImmutableMultiDict`\n        is returned from this function.  This can be changed by setting\n        :attr:`parameter_storage_class` to a different type.  This might\n        be necessary if the order of the form data is important.\n\n        Please keep in mind that file uploads will not end up here, but instead\n        in the :attr:`files` attribute.\n\n        .. versionchanged:: 0.9\n\n            Previous to Werkzeug 0.9 this would only contain form data for POST\n            and PUT requests.\n        \"\"\"\n        self._load_form_data()\n        return self.form\n\n    @cached_property\n    def values(self) -> \"CombinedMultiDict[str, str]\":\n        \"\"\"A :class:`werkzeug.datastructures.CombinedMultiDict` that\n        combines :attr:`args` and :attr:`form`.\n\n        For GET requests, only ``args`` are present, not ``form``.\n\n        .. versionchanged:: 2.0\n            For GET requests, only ``args`` are present, not ``form``.\n        \"\"\"\n        sources = [self.args]\n\n        if self.method != \"GET\":\n            # GET requests can have a body, and some caching proxies\n            # might not treat that differently than a normal GET\n            # request, allowing form data to \"invisibly\" affect the\n            # cache without indication in the query string / URL.\n            sources.append(self.form)\n\n        args = []\n\n        for d in sources:\n            if not isinstance(d, MultiDict):\n                d = MultiDict(d)\n\n            args.append(d)\n\n        return CombinedMultiDict(args)\n\n    @cached_property\n    def files(self) -> \"ImmutableMultiDict[str, FileStorage]\":\n        \"\"\":class:`~werkzeug.datastructures.MultiDict` object containing\n        all uploaded files.  Each key in :attr:`files` is the name from the\n        ``<input type=\"file\" name=\"\">``.  Each value in :attr:`files` is a\n        Werkzeug :class:`~werkzeug.datastructures.FileStorage` object.\n\n        It basically behaves like a standard file object you know from Python,\n        with the difference that it also has a\n        :meth:`~werkzeug.datastructures.FileStorage.save` function that can\n        store the file on the filesystem.\n\n        Note that :attr:`files` will only contain data if the request method was\n        POST, PUT or PATCH and the ``<form>`` that posted to the request had\n        ``enctype=\"multipart/form-data\"``.  It will be empty otherwise.\n\n        See the :class:`~werkzeug.datastructures.MultiDict` /\n        :class:`~werkzeug.datastructures.FileStorage` documentation for\n        more details about the used data structure.\n        \"\"\"\n        self._load_form_data()\n        return self.files\n\n    @property\n    def script_root(self) -> str:\n        \"\"\"Alias for :attr:`self.root_path`. ``environ[\"SCRIPT_ROOT\"]``\n        without a trailing slash.\n        \"\"\"\n        return self.root_path\n\n    @cached_property\n    def url_root(self) -> str:\n        \"\"\"Alias for :attr:`root_url`. The URL with scheme, host, and\n        root path. For example, ``https://example.com/app/``.\n        \"\"\"\n        return self.root_url\n\n    remote_user = environ_property[str](\n        \"REMOTE_USER\",\n        doc=\"\"\"If the server supports user authentication, and the\n        script is protected, this attribute contains the username the\n        user has authenticated as.\"\"\",\n    )\n    is_multithread = environ_property[bool](\n        \"wsgi.multithread\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        multithreaded WSGI server.\"\"\",\n    )\n    is_multiprocess = environ_property[bool](\n        \"wsgi.multiprocess\",\n        doc=\"\"\"boolean that is `True` if the application is served by a\n        WSGI server that spawns multiple processes.\"\"\",\n    )\n    is_run_once = environ_property[bool](\n        \"wsgi.run_once\",\n        doc=\"\"\"boolean that is `True` if the application will be\n        executed only once in a process lifetime.  This is the case for\n        CGI for example, but it's not guaranteed that the execution only\n        happens one time.\"\"\",\n    )\n\n    # JSON\n\n    #: A module or other object that has ``dumps`` and ``loads``\n    #: functions that match the API of the built-in :mod:`json` module.\n    json_module = json\n\n    @property\n    def json(self) -> t.Optional[t.Any]:\n        \"\"\"The parsed JSON data if :attr:`mimetype` indicates JSON\n        (:mimetype:`application/json`, see :attr:`is_json`).\n\n        Calls :meth:`get_json` with default arguments.\n\n        If the request content type is not ``application/json``, this\n        will raise a 400 Bad Request error.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        return self.get_json()\n\n    # Cached values for ``(silent=False, silent=True)``. Initialized\n    # with sentinel values.\n    _cached_json: t.Tuple[t.Any, t.Any] = (Ellipsis, Ellipsis)\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: \"te.Literal[False]\" = ..., cache: bool = ...\n    ) -> t.Any:\n        ...\n\n    @t.overload\n    def get_json(\n        self, force: bool = ..., silent: bool = ..., cache: bool = ...\n    ) -> t.Optional[t.Any]:\n        ...\n\n    def get_json(\n        self, force: bool = False, silent: bool = False, cache: bool = True\n    ) -> t.Optional[t.Any]:\n        \"\"\"Parse :attr:`data` as JSON.\n\n        If the mimetype does not indicate JSON\n        (:mimetype:`application/json`, see :attr:`is_json`), or parsing\n        fails, :meth:`on_json_loading_failed` is called and\n        its return value is used as the return value. By default this\n        raises a 400 Bad Request error.\n\n        :param force: Ignore the mimetype and always try to parse JSON.\n        :param silent: Silence mimetype and parsing errors, and\n            return ``None`` instead.\n        :param cache: Store the parsed JSON to return for subsequent\n            calls.\n\n        .. versionchanged:: 2.1\n            Raise a 400 error if the content type is incorrect.\n        \"\"\"\n        if cache and self._cached_json[silent] is not Ellipsis:\n            return self._cached_json[silent]\n\n        if not (force or self.is_json):\n            if not silent:\n                return self.on_json_loading_failed(None)\n            else:\n                return None\n\n        data = self.get_data(cache=cache)\n\n        try:\n            rv = self.json_module.loads(data)\n        except ValueError as e:\n            if silent:\n                rv = None\n\n                if cache:\n                    normal_rv, _ = self._cached_json\n                    self._cached_json = (normal_rv, rv)\n            else:\n                rv = self.on_json_loading_failed(e)\n\n                if cache:\n                    _, silent_rv = self._cached_json\n                    self._cached_json = (rv, silent_rv)\n        else:\n            if cache:\n                self._cached_json = (rv, rv)\n\n        return rv\n\n    def on_json_loading_failed(self, e: t.Optional[ValueError]) -> t.Any:\n        \"\"\"Called if :meth:`get_json` fails and isn't silenced.\n\n        If this method returns a value, it is used as the return value\n        for :meth:`get_json`. The default implementation raises\n        :exc:`~werkzeug.exceptions.BadRequest`.\n\n        :param e: If parsing failed, this is the exception. It will be\n            ``None`` if the content type wasn't ``application/json``.\n        \"\"\"\n        if e is not None:\n            raise BadRequest(f\"Failed to decode JSON object: {e}\")\n\n        raise BadRequest(\n            \"Did not attempt to load JSON data because the request\"\n            \" Content-Type was not 'application/json'.\"\n        )\n", "import csv\nimport io\nfrom os.path import dirname\nfrom os.path import join\n\nimport pytest\n\nfrom werkzeug import formparser\nfrom werkzeug.datastructures import MultiDict\nfrom werkzeug.exceptions import RequestEntityTooLarge\nfrom werkzeug.formparser import FormDataParser\nfrom werkzeug.formparser import parse_form_data\nfrom werkzeug.test import Client\nfrom werkzeug.test import create_environ\nfrom werkzeug.wrappers import Request\nfrom werkzeug.wrappers import Response\n\n\n@Request.application\ndef form_data_consumer(request):\n    result_object = request.args[\"object\"]\n    if result_object == \"text\":\n        return Response(repr(request.form[\"text\"]))\n    f = request.files[result_object]\n    return Response(\n        b\"\\n\".join(\n            (\n                repr(f.filename).encode(\"ascii\"),\n                repr(f.name).encode(\"ascii\"),\n                repr(f.content_type).encode(\"ascii\"),\n                f.stream.read(),\n            )\n        )\n    )\n\n\ndef get_contents(filename):\n    with open(filename, \"rb\") as f:\n        return f.read()\n\n\nclass TestFormParser:\n    def test_limiting(self):\n        data = b\"foo=Hello+World&bar=baz\"\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"application/x-www-form-urlencoded\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 4\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        # when the request entity is too large, the input stream should be\n        # drained so that firefox (and others) do not report connection reset\n        # when run through gunicorn\n        # a sufficiently large stream is necessary for block-based reads\n        input_stream = io.BytesIO(b\"foo=\" + b\"x\" * 128 * 1024)\n        req = Request.from_values(\n            input_stream=input_stream,\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 4\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n        # ensure that the stream is exhausted\n        assert input_stream.read() == b\"\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_content_length = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 7\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_memory_size = 400\n        assert req.form[\"foo\"] == \"Hello World\"\n\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        req.max_form_parts = 1\n        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n\n    def test_missing_multipart_boundary(self):\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\"\n            b\"Hello World\\r\\n\"\n            b\"--foo\\r\\nContent-Disposition: form-field; name=bar\\r\\n\\r\\n\"\n            b\"bar=baz\\r\\n--foo--\"\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data\",\n            method=\"POST\",\n        )\n        assert req.form == {}\n\n    def test_parse_form_data_put_without_content(self):\n        # A PUT without a Content-Type header returns empty data\n\n        # Both rfc1945 and rfc2616 (1.0 and 1.1) say \"Any HTTP/[1.0/1.1] message\n        # containing an entity-body SHOULD include a Content-Type header field\n        # defining the media type of that body.\"  In the case where either\n        # headers are omitted, parse_form_data should still work.\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"PUT\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    def test_parse_form_data_get_without_content(self):\n        env = create_environ(\"/foo\", \"http://example.org/\", method=\"GET\")\n\n        stream, form, files = formparser.parse_form_data(env)\n        assert stream.read() == b\"\"\n        assert len(form) == 0\n        assert len(files) == 0\n\n    @pytest.mark.parametrize(\n        (\"no_spooled\", \"size\"), ((False, 100), (False, 3000), (True, 100), (True, 3000))\n    )\n    def test_default_stream_factory(self, no_spooled, size, monkeypatch):\n        if no_spooled:\n            monkeypatch.setattr(\"werkzeug.formparser.SpooledTemporaryFile\", None)\n\n        data = b\"a,b,c\\n\" * size\n        with Request.from_values(\n            data={\"foo\": (io.BytesIO(data), \"test.txt\")}, method=\"POST\"\n        ) as req:\n            reader = csv.reader(io.TextIOWrapper(req.files[\"foo\"]))\n            # This fails if file_storage doesn't implement IOBase.\n            # https://github.com/pallets/werkzeug/issues/1344\n            # https://github.com/python/cpython/pull/3249\n            assert sum(1 for _ in reader) == size\n\n    def test_parse_bad_content_type(self):\n        parser = FormDataParser()\n        assert parser.parse(\"\", \"bad-mime-type\", 0) == (\n            \"\",\n            MultiDict([]),\n            MultiDict([]),\n        )\n\n    def test_parse_from_environ(self):\n        parser = FormDataParser()\n        stream, _, _ = parser.parse_from_environ({\"wsgi.input\": \"\"})\n        assert stream is not None\n\n\n@pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\nclass TestMultiPart:\n    def test_basic(self):\n        resources = join(dirname(__file__), \"multipart\")\n        client = Client(form_data_consumer)\n\n        repository = [\n            (\n                \"firefox3-2png1txt\",\n                \"---------------------------186454651713519341951581030105\",\n                [\n                    (\"anchor.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"application_edit.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"example text\",\n            ),\n            (\n                \"firefox3-2pnglongtext\",\n                \"---------------------------14904044739787191031754711748\",\n                [\n                    (\"accept.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"add.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"--long text\\r\\n--with boundary\\r\\n--lookalikes--\",\n            ),\n            (\n                \"opera8-2png1txt\",\n                \"----------zEO9jQKmLc2Cq88c23Dx19\",\n                [\n                    (\"arrow_branch.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"award_star_bronze_1.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"blafasel \u00f6\u00e4\u00fc\",\n            ),\n            (\n                \"webkit3-2png1txt\",\n                \"----WebKitFormBoundaryjdSFhcARk8fyGNy6\",\n                [\n                    (\"gtk-apply.png\", \"file1\", \"image/png\", \"file1.png\"),\n                    (\"gtk-no.png\", \"file2\", \"image/png\", \"file2.png\"),\n                ],\n                \"this is another text with \u00fcml\u00e4\u00fcts\",\n            ),\n            (\n                \"ie6-2png1txt\",\n                \"---------------------------7d91b03a20128\",\n                [\n                    (\"file1.png\", \"file1\", \"image/x-png\", \"file1.png\"),\n                    (\"file2.png\", \"file2\", \"image/x-png\", \"file2.png\"),\n                ],\n                \"ie6 sucks :-/\",\n            ),\n        ]\n\n        for name, boundary, files, text in repository:\n            folder = join(resources, name)\n            data = get_contents(join(folder, \"request.http\"))\n            for filename, field, content_type, fsname in files:\n                with client.post(\n                    f\"/?object={field}\",\n                    data=data,\n                    content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                    content_length=len(data),\n                ) as response:\n                    lines = response.get_data().split(b\"\\n\", 3)\n                    assert lines[0] == repr(filename).encode(\"ascii\")\n                    assert lines[1] == repr(field).encode(\"ascii\")\n                    assert lines[2] == repr(content_type).encode(\"ascii\")\n                    assert lines[3] == get_contents(join(folder, fsname))\n\n            with client.post(\n                \"/?object=text\",\n                data=data,\n                content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n                content_length=len(data),\n            ) as response:\n                assert response.get_data() == repr(text).encode(\"utf-8\")\n\n    @pytest.mark.filterwarnings(\"ignore::pytest.PytestUnraisableExceptionWarning\")\n    def test_ie7_unc_path(self):\n        client = Client(form_data_consumer)\n        data_file = join(dirname(__file__), \"multipart\", \"ie7_full_path_request.http\")\n        data = get_contents(data_file)\n        boundary = \"---------------------------7da36d1b4a0164\"\n        with client.post(\n            \"/?object=cb_file_upload_multiple\",\n            data=data,\n            content_type=f'multipart/form-data; boundary=\"{boundary}\"',\n            content_length=len(data),\n        ) as response:\n            lines = response.get_data().split(b\"\\n\", 3)\n            assert lines[0] == b\"'Sellersburg Town Council Meeting 02-22-2010doc.doc'\"\n\n    def test_end_of_file(self):\n        # This test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n'\n            b\"Content-Type: text/plain\\r\\n\\r\\n\"\n            b\"file contents and no end\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert not data.files\n            assert not data.form\n\n    def test_file_no_content_type(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"test\"; filename=\"test.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as data:\n            assert data.files[\"test\"].filename == \"test.txt\"\n            assert data.files[\"test\"].read() == b\"file contents\"\n\n    def test_extra_newline(self):\n        # this test looks innocent but it was actually timing out in\n        # the Werkzeug 0.5 release version (#394)\n        data = (\n            b\"\\r\\n\\r\\n--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"\\r\\n\\r\\n'\n            b\"a string\\r\\n\"\n            b\"--foo--\"\n        )\n        data = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert not data.files\n        assert data.form[\"foo\"] == \"a string\"\n\n    def test_headers(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b'Content-Disposition: form-data; name=\"foo\"; filename=\"foo.txt\"\\r\\n'\n            b\"X-Custom-Header: blah\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\\r\\n\"\n            b\"file contents, just the contents\\r\\n\"\n            b\"--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as req:\n            foo = req.files[\"foo\"]\n            assert foo.mimetype == \"text/plain\"\n            assert foo.mimetype_params == {\"charset\": \"utf-8\"}\n            assert foo.headers[\"content-type\"] == foo.content_type\n            assert foo.content_type == \"text/plain; charset=utf-8\"\n            assert foo.headers[\"x-custom-header\"] == \"blah\"\n\n    @pytest.mark.parametrize(\"ending\", [b\"\\n\", b\"\\r\", b\"\\r\\n\"])\n    def test_nonstandard_line_endings(self, ending: bytes):\n        data = ending.join(\n            (\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=foo\",\n                b\"\",\n                b\"this is just bar\",\n                b\"--foo\",\n                b\"Content-Disposition: form-data; name=bar\",\n                b\"\",\n                b\"blafasel\",\n                b\"--foo--\",\n            )\n        )\n        req = Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        )\n        assert req.form[\"foo\"] == \"this is just bar\"\n        assert req.form[\"bar\"] == \"blafasel\"\n\n    def test_failures(self):\n        def parse_multipart(stream, boundary, content_length):\n            parser = formparser.MultiPartParser(content_length)\n            return parser.parse(stream, boundary, content_length)\n\n        data = b\"--foo\\r\\n\\r\\nHello World\\r\\n--foo--\"\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n        data = (\n            b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\nHello World\\r\\n\"\n        )\n        pytest.raises(ValueError, parse_multipart, io.BytesIO(data), b\"foo\", len(data))\n\n    def test_empty_multipart(self):\n        environ = {}\n        data = b\"--boundary--\"\n        environ[\"REQUEST_METHOD\"] = \"POST\"\n        environ[\"CONTENT_TYPE\"] = \"multipart/form-data; boundary=boundary\"\n        environ[\"CONTENT_LENGTH\"] = str(len(data))\n        environ[\"wsgi.input\"] = io.BytesIO(data)\n        stream, form, files = parse_form_data(environ, silent=False)\n        rv = stream.read()\n        assert rv == b\"\"\n        assert form == MultiDict()\n        assert files == MultiDict()\n\n\nclass TestMultiPartParser:\n    def test_constructor_not_pass_stream_factory_and_cls(self):\n        parser = formparser.MultiPartParser()\n\n        assert parser.stream_factory is formparser.default_stream_factory\n        assert parser.cls is MultiDict\n\n    def test_constructor_pass_stream_factory_and_cls(self):\n        def stream_factory():\n            pass\n\n        parser = formparser.MultiPartParser(stream_factory=stream_factory, cls=dict)\n\n        assert parser.stream_factory is stream_factory\n        assert parser.cls is dict\n\n    def test_file_rfc2231_filename_continuations(self):\n        data = (\n            b\"--foo\\r\\n\"\n            b\"Content-Type: text/plain; charset=utf-8\\r\\n\"\n            b\"Content-Disposition: form-data; name=rfc2231;\\r\\n\"\n            b\"\tfilename*0*=ascii''a%20b%20;\\r\\n\"\n            b\"\tfilename*1*=c%20d%20;\\r\\n\"\n            b'\tfilename*2=\"e f.txt\"\\r\\n\\r\\n'\n            b\"file contents\\r\\n--foo--\"\n        )\n        with Request.from_values(\n            input_stream=io.BytesIO(data),\n            content_length=len(data),\n            content_type=\"multipart/form-data; boundary=foo\",\n            method=\"POST\",\n        ) as request:\n            assert request.files[\"rfc2231\"].filename == \"a b c d e f.txt\"\n            assert request.files[\"rfc2231\"].read() == b\"file contents\"\n"], "buggy_code_start_loc": [23, 76, 181, 89, 84, 128], "buggy_code_end_loc": [23, 93, 413, 193, 248, 128], "fixing_code_start_loc": [24, 76, 182, 90, 85, 129], "fixing_code_end_loc": [28, 96, 423, 202, 257, 138], "type": "CWE-770", "message": "Werkzeug is a comprehensive WSGI web application library. Prior to version 2.2.3, Werkzeug's multipart form data parser will parse an unlimited number of parts, including file parts. Parts can be a small amount of bytes, but each requires CPU time to parse and may use more memory as Python data. If a request can be made to an endpoint that accesses `request.data`, `request.form`, `request.files`, or `request.get_data(parse_form_data=False)`, it can cause unexpectedly high resource usage. This allows an attacker to cause a denial of service by sending crafted multipart data to an endpoint that will parse it. The amount of CPU time required can block worker processes from handling legitimate requests. The amount of RAM required can trigger an out of memory kill of the process. Unlimited file parts can use up memory and file handles. If many concurrent requests are sent continuously, this can exhaust or kill all available workers. Version 2.2.3 contains a patch for this issue.", "other": {"cve": {"id": "CVE-2023-25577", "sourceIdentifier": "security-advisories@github.com", "published": "2023-02-14T20:15:17.543", "lastModified": "2023-02-23T22:21:32.397", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Werkzeug is a comprehensive WSGI web application library. Prior to version 2.2.3, Werkzeug's multipart form data parser will parse an unlimited number of parts, including file parts. Parts can be a small amount of bytes, but each requires CPU time to parse and may use more memory as Python data. If a request can be made to an endpoint that accesses `request.data`, `request.form`, `request.files`, or `request.get_data(parse_form_data=False)`, it can cause unexpectedly high resource usage. This allows an attacker to cause a denial of service by sending crafted multipart data to an endpoint that will parse it. The amount of CPU time required can block worker processes from handling legitimate requests. The amount of RAM required can trigger an out of memory kill of the process. Unlimited file parts can use up memory and file handles. If many concurrent requests are sent continuously, this can exhaust or kill all available workers. Version 2.2.3 contains a patch for this issue."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:palletsprojects:werkzeug:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.2.3", "matchCriteriaId": "EE8F26B3-94E2-45A2-A114-56AF4D262414"}]}]}], "references": [{"url": "https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/pallets/werkzeug/releases/tag/2.2.3", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1"}}